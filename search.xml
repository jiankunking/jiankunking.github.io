<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>趣谈网络协议 学习笔记</title>
      <link href="/fun-talk-about-network-protocols.html"/>
      <url>/fun-talk-about-network-protocols.html</url>
      
        <content type="html"><![CDATA[<p>趣谈网络协议 学习笔记<br>作者： 刘超</p><a id="more"></a><h1 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h1><p><img src="/images/fun-talk-about-network-protocols/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE.png" alt></p><h1 id="网络分层"><a href="#网络分层" class="headerlink" title="网络分层"></a>网络分层</h1><p><img src="/images/fun-talk-about-network-protocols/%E8%AF%B7%E6%B1%82%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82.png" alt></p><h1 id="无类型域间选路（CIDR）"><a href="#无类型域间选路（CIDR）" class="headerlink" title="无类型域间选路（CIDR）"></a>无类型域间选路（CIDR）</h1><p>这种方式打破了原来设计的几类地址的做法，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个 IP 地址中有一个斜杠，斜杠后面有个数字 24。这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号。</p><p>伴随着 CIDR 存在的，一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。另一个是子网掩码，255.255.255.0。</p><blockquote><p>“无类型”的意思是选路决策是基于整个32位IP地址的掩码操作。而不管其IP地址是A类、B类或是C类。</p></blockquote><h1 id="DHCP：IP是怎么来的，又是怎么没的？"><a href="#DHCP：IP是怎么来的，又是怎么没的？" class="headerlink" title="DHCP：IP是怎么来的，又是怎么没的？"></a>DHCP：IP是怎么来的，又是怎么没的？</h1><h2 id="如何配置-IP-地址？"><a href="#如何配置-IP-地址？" class="headerlink" title="如何配置 IP 地址？"></a>如何配置 IP 地址？</h2><p>net-tools：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ifconfig eth1 10.0.0.1/24</span><br><span class="line">$ sudo ifconfig eth1 up</span><br></pre></td></tr></table></figure><p>iproute2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ip addr add 10.0.0.1/24 dev eth1</span><br><span class="line">$ sudo ip link set up eth1</span><br></pre></td></tr></table></figure><p>你可能会问了，自己配置这个自由度太大了吧，我是不是配置什么都可以？如果配置一个和谁都不搭边的地址呢？例如，旁边的机器都是 192.168.1.x，我非得配置一个 16.158.23.6，会出现什么现象呢？</p><p>不会出现任何现象，就是包发不出去呗。为什么发不出去呢？我来举例说明。</p><p>192.168.1.6 就在你这台机器的旁边，甚至是在同一个交换机上，而你把机器的地址设为了16.158.23.6。在这台机器上，你企图去 ping 192.168.1.6，你觉得只要将包发出去，同一个交换机的另一台机器马上就能收到，对不对？</p><p>可是 Linux 系统不是这样的，它没你想得那么智能。你用肉眼看到那台机器就在旁边，它则需要根据自己的逻辑进行处理。</p><p>要知道只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。</p><p>所以，你看着它有自己的源 IP 地址 16.158.23.6，也有目标 IP 地址 192.168.1.6，但是包发不出去，这是因为 MAC 层还没填。</p><p>自己的 MAC 地址自己知道，这个容易。但是目标 MAC 填什么呢？是不是填 192.168.1.6 这台机器的MAC 地址呢？</p><p>当然不是。Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址。如果发现不是呢？</p><p>Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。</p><p>如果你配置了网关的话，Linux 会获取网关的 MAC 地址，然后将包发出去。对于 192.168.1.6 这台机器来讲，虽然路过它家门的这个包，目标 IP 是它，但是无奈 MAC 地址不是它的，所以它的网卡是不会把包收进去的。</p><p>如果没有配置网关呢？那包压根就发不出去。</p><p>如果将网关配置为 192.168.1.6 呢？不可能，Linux 不会让你配置成功的，因为网关要和当前的网络至少一个网卡是同一个网段的，怎么可能 16.158.23.6 的网关是 192.168.1.6 呢？</p><p>所以，当你需要手动配置一台机器的网络 IP 时，一定要好好问问你的网络管理员。如果在机房里面，要去网络管理员那里申请，让他给你分配一段正确的 IP 地址。当然，真正配置的时候，一定不是直接用命令配置的，而是放在一个配置文件里面。不同系统的配置文件格式不同，但是无非就是 CIDR、子网掩码、广播地址和网关地址。</p><h2 id="动态主机配置协议（DHCP）"><a href="#动态主机配置协议（DHCP）" class="headerlink" title="动态主机配置协议（DHCP）"></a>动态主机配置协议（DHCP）</h2><p>动态主机配置协议（Dynamic Host Configuration Protocol），简称DHCP。</p><h3 id="解析-DHCP-的工作方式"><a href="#解析-DHCP-的工作方式" class="headerlink" title="解析 DHCP 的工作方式"></a>解析 DHCP 的工作方式</h3><p>当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，只知道自己的 MAC 地址。怎么办？先吼一句，我来啦，有人吗？这时候的沟通基本靠“吼”。这一步，我们称为DHCP Discover。</p><p>新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。广播包封装在UDP 里面，UDP 封装在 BOOTP 里面。其实 DHCP 是 BOOTP 的增强版，但是如果你去抓包的话，很可能看到的名称还是 BOOTP 协议。</p><p>在这个广播包里面，新人大声喊：我是新来的（Boot request），我的 MAC 地址是这个，我还没有IP，谁能给租给我个 IP 地址！</p><p>格式就像这样：</p><p>请求<br><img src="/images/fun-talk-about-network-protocols/%E8%AF%B7%E6%B1%82%E7%BD%91%E7%BB%9CIP%E7%9A%84%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="请求"></p><p>响应<br><img src="/images/fun-talk-about-network-protocols/%E5%93%8D%E5%BA%94%E8%AF%B7%E6%B1%82%E7%BD%91%E7%BB%9CIP%E7%9A%84%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="响应"></p><p>新来的机器很开心，它的“吼”得到了回复，并且有人愿意租给它一个 IP 地址了，这意味着它可以在网络上立足了。当然更令人开心的是，如果有多个 DHCP Server，这台新机器会收到多个 IP 地址，简直受宠若惊。</p><p><strong>它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址</strong>，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者。</p><p>当 DHCP Server 接收到客户机的 DHCP request 之后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。</p><h3 id="IP-地址的收回和续租"><a href="#IP-地址的收回和续租" class="headerlink" title="IP 地址的收回和续租"></a>IP 地址的收回和续租</h3><p>既然是租房子，就是有租期的。租期到了，管理员就要将 IP 收回。</p><p>如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP 也是这样。</p><p>客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。</p><h1 id="交换机与VLAN"><a href="#交换机与VLAN" class="headerlink" title="交换机与VLAN"></a>交换机与VLAN</h1><h2 id="拓扑结构是怎么形成的？"><a href="#拓扑结构是怎么形成的？" class="headerlink" title="拓扑结构是怎么形成的？"></a>拓扑结构是怎么形成的？</h2><p>我们常见到的办公室大多是一排排的桌子，每个桌子都有网口，一排十几个座位就有十几个网口，一个楼层就会有几十个甚至上百个网口。如果算上所有楼层，这个场景自然比你宿舍里的复杂多了。具体哪里复杂呢？我来给你具体讲解。</p><p>首先，这个时候，一个交换机肯定不够用，需要多台交换机，交换机之间连接起来，就形成一个稍微复杂的拓扑结构。</p><p>我们先来看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器1 只知道机器 4 的 IP 地址，当它想要访问机器 4，把包发出去的时候，它必须要知道机器 4 的 MAC 地址。</p><p><img src="/images/fun-talk-about-network-protocols/%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84.png" alt></p><p>于是机器 1 发起广播，机器 2 收到这个广播，但是这不是找它的，所以没它什么事。<strong>交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。</strong>于是机器 3 也收到广播信息了，但是这和它也没什么关系。</p><p>当然，交换机 B 也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广播的策略，将包转发到局域网三。这个时候，机器 4 和机器 5 都收到了广播信息。机器 4 主动响应说，这是找我的，这是我的 MAC 地址。于是一个 ARP 请求就成功完成了。</p><p>在上面的过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：机器 1 是在左边这个网口的。当了解到这些拓扑信息之后，情况就好转起来。当机器 2 要访问机器 1 的时候，机器 2 并不知道机器 1 的MAC 地址，所以机器 2 会发起一个 ARP 请求。这个广播消息会到达机器 1，也同时会到达交换机 A。这个时候交换机 A 已经知道机器 1 是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二和局域网三。</p><p>当机器 3 要访问机器 1 的时候，也需要发起一个广播的 ARP 请求。这个时候交换机 A 和交换机 B 都能够收到这个广播请求。交换机 A 当然知道主机 A 是在左边这个网口的，所以会把广播消息转发到局域网一。同时，交换机 B 收到这个广播消息之后，由于它知道机器 1 是不在右边这个网口的，所以不会将消息广播到局域网三。</p><h1 id="ICMP与ping"><a href="#ICMP与ping" class="headerlink" title="ICMP与ping"></a>ICMP与ping</h1><h2 id="ICMP-协议的格式"><a href="#ICMP-协议的格式" class="headerlink" title="ICMP 协议的格式"></a>ICMP 协议的格式</h2><p>ping 是基于 ICMP 协议工作的。ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，那具体是怎么控制的呢？</p><p>网络包在异常复杂的网络环境中传输时，常常会遇到各种各样的问题。当遇到问题的时候，总不能“死个不明不白”，要传出消息来，报告情况，这样才可以调整传输策略。</p><p>ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。</p><p><img src="/images/fun-talk-about-network-protocols/ICMP.png" alt></p><h2 id="ping：查询报文类型的使用"><a href="#ping：查询报文类型的使用" class="headerlink" title="ping：查询报文类型的使用"></a>ping：查询报文类型的使用</h2><p>接下来，我们重点来看 ping 的发送和接收过程。<br><img src="/images/fun-talk-about-network-protocols/ping.png" alt></p><p>假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那当你在主机 A 上运行“ping 192.168.1.2”后，会发生什么呢?</p><p>ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为8；另外一个是顺序号，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</p><p>然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。</p><p>接下来，需要加入 MAC 头。<strong>如果在ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址</strong>，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</p><p>主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。</p><p>主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。</p><p>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><p>当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。</p><h1 id="网关（Gateway）"><a href="#网关（Gateway）" class="headerlink" title="网关（Gateway）"></a>网关（Gateway）</h1><h2 id="你了解-MAC-头和-IP-头的细节吗？"><a href="#你了解-MAC-头和-IP-头的细节吗？" class="headerlink" title="你了解 MAC 头和 IP 头的细节吗？"></a>你了解 MAC 头和 IP 头的细节吗？</h2><p>一旦配置了 IP 地址和网关，往往就能够指定目标地址进行访问了。由于在跨网关访问的时候，牵扯到MAC 地址和 IP 地址的变化，这里有必要详细描述一下 MAC 头和 IP 头的细节。</p><p><img src="/images/fun-talk-about-network-protocols/MAC_IP.png" alt></p><p>在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断，这个目标 IP 地址，和当前机器的IP地址，是否在同一个网段。怎么判断同一个网段呢？需要 CIDR 和子网掩码。</p><p>如果不是同一网段，例如，你要访问你们校园网里面的 BBS，该怎么办？这就需要发往默认网关Gateway。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个。例如192.168.1.0/24 这个网段，Gateway 往往会是 192.168.1.1/24 或者 192.168.1.2/24。</p><p>如何发往默认网关呢？网关不是和源 IP 地址是一个网段的么？这个过程就和发往同一个网段的其他机器是一样的：将源地址和目标 IP 地址放入 IP 头中，通过 ARP 获得网关的 MAC 地址，将源 MAC 和网关的 MAC 放入 MAC 头中，发送出去。网关所在的端口，例如 192.168.1.1/24 将网络包收进来，然后接下来怎么做，就完全看网关的了。</p><p>网关往往是一个路由器，是一个三层转发的设备。啥叫三层设备？就是把 MAC 头和 IP头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。</p><blockquote><p>很多情况下，人们把网关就叫作路由器。其实不完全准确，而另一种比喻更加恰当：<font color="DeepPink"><strong>路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP地址相同的网段，每只手都是它握住的那个局域网的网关。</strong></font></p></blockquote><p>任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。</p><h2 id="IP-头和-MAC-头哪些变、哪些不变？"><a href="#IP-头和-MAC-头哪些变、哪些不变？" class="headerlink" title="IP 头和 MAC 头哪些变、哪些不变？"></a>IP 头和 MAC 头哪些变、哪些不变？</h2><p><font color="DeepPink"><strong>MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于 IP 地址是否改变。不改变 IP 地址的网关，我们称为转发网关；改变 IP 地址的网关，我们称为NAT 网关。</strong></font></p><h1 id="TCP-协议"><a href="#TCP-协议" class="headerlink" title="TCP 协议"></a>TCP 协议</h1><ul><li>顺序问题 ，稳重不乱；</li><li>丢包问题，承诺靠谱；</li><li>连接维护，有始有终；</li><li>流量控制，把握分寸；</li><li>拥塞控制，知进知退。</li></ul><blockquote><p>SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接</p></blockquote><h2 id="TCP-的三次握手"><a href="#TCP-的三次握手" class="headerlink" title="TCP 的三次握手"></a>TCP 的三次握手</h2><p><img src="/images/fun-talk-about-network-protocols/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><h2 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h2><p><img src="/images/fun-talk-about-network-protocols/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> 原创 </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 磁盘分区、挂载</title>
      <link href="/linux-mount-partition.html"/>
      <url>/linux-mount-partition.html</url>
      
        <content type="html"><![CDATA[<p>Linux 磁盘分区、挂载</p><a id="more"></a><p>查看已挂账的磁盘</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -hl /*</span><br></pre></td></tr></table></figure><p>查看分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure><p>分区指定文件系统（会格式化）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs.xfs -f /dev/vdb</span><br></pre></td></tr></table></figure><p>挂载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/vdb /data</span><br></pre></td></tr></table></figure><p><strong>以上挂载重启后失效</strong></p><p>查看挂载结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -TH</span><br></pre></td></tr></table></figure><p>blkid 磁盘分区，查询磁盘分区的UUID。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blkid /dev/vdb</span><br></pre></td></tr></table></figure><p>vim编辑/etc/fstab</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID=37aeb018-9dfd-412f-81c1-583f1eb1189f /data                   xfs     defaults        0 2</span><br></pre></td></tr></table></figure><p>lsblk 查看分区和磁盘</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Linux </tag>
            
            <tag> Mount </tag>
            
            <tag> Partition </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sentry 高可用部署</title>
      <link href="/sentry-high-availability-deploy.html"/>
      <url>/sentry-high-availability-deploy.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Sentry 高可用部署，部署分析基于Sentry 10.1.0.dev 05e720a7</p></blockquote><a id="more"></a><p>Sentry官方对于<a href="https://docs.sentry.io/server/" target="_blank" rel="noopener">自托管</a>推荐的部署方式是<a href="https://docs.sentry.io/server/installation/" target="_blank" rel="noopener">Docker Compose</a>,但这种方式有以下几个缺点：</p><ul><li>所有服务都部署在一台机器上</li><li>所有的组件都不是高可用的</li></ul><p>对于生产环境来说，组件高可用是一个必备的条件，所以有了下面的高可用部署，高可用部署分为两部分：</p><ul><li>Sentry依赖中间件的高可用</li><li>Sentry本身组件的高可用</li></ul><h1 id="Sentry-服务"><a href="#Sentry-服务" class="headerlink" title="Sentry 服务"></a>Sentry 服务</h1><p>Sentry具体的服务关系及依赖，具体见下图：</p><p><img src="/images/sentry-high-availability-deploy/Sentry.png" alt></p><p>需要注意以下几点：</p><ul><li>symbolicator、symbolicator-cleanup 依赖挂载卷sentry-symbolicator:/data</li><li>web、cron、worker、post-process-forwarder、sentry-cleanup 也依赖挂载卷，具体可以可见：<a href="https://docs.sentry.io/server/filestore/" target="_blank" rel="noopener">https://docs.sentry.io/server/filestore/</a></li></ul><p>为什么需要关注挂载卷？</p><p>因为挂载卷依赖存储服务，如果没用高可用的存储服务，Sentry自身组件就难以做到全部高可用。</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="Sentry依赖中间件"><a href="#Sentry依赖中间件" class="headerlink" title="Sentry依赖中间件"></a>Sentry依赖中间件</h2><ul><li>Sentry依赖中间件的高可用，可以通过购买云服务商的服务来实现或者自己搭建。</li><li>通过修改sentry onpremise将Sentry依赖的服务替换为相关的ip或者域名，具体代码可以参考：<a href="https://github.com/jiankunking/onpremise" target="_blank" rel="noopener">jiankunking/onpremise</a>。</li></ul><h2 id="Sentry自身服务"><a href="#Sentry自身服务" class="headerlink" title="Sentry自身服务"></a>Sentry自身服务</h2><p>将Sentry服务拆分，部署到kubernetes集群中，具体设置参考onpremise中docker-compose.yml中的启动命令、端口、环境变量来设置。</p><p>其中有以下几点需要注意：</p><ul><li>Sentry各个服务的启动命令，相比docker-compose.yml中command，不太一致，简单列一下：<ul><li>sentry run web –loglevel DEBUG</li><li>sentry run worker</li><li>snuba api</li><li>snuba consumer –auto-offset-reset=latest –max-batch-time-ms 750</li><li>symbolicator run</li><li>……</li></ul></li><li><a href="https://github.com/jiankunking/snuba" target="_blank" rel="noopener">snuba</a> api默认监听的是127.0.0.1，修改为0.0.0.0，具体修改位置参见：<br><a href="https://github.com/jiankunking/snuba/commit/69fee6253c6a78e7c2668bf6c86692e4df8fe012" target="_blank" rel="noopener">https://github.com/jiankunking/snuba/commit/69fee6253c6a78e7c2668bf6c86692e4df8fe012</a></li><li><a href="https://github.com/jiankunking/sentry" target="_blank" rel="noopener">sentry</a> sentry/conf/server.py中KAFKA_CLUSTERS默认是localhost:9092,修改方式参见：<br><a href="https://github.com/jiankunking/onpremise/blob/master/sentry/cover/server.py#L1640" target="_blank" rel="noopener">https://github.com/jiankunking/onpremise/blob/master/sentry/cover/server.py#L1640</a></li><li>构建sentry镜像，当启动命令为post-process-forwarder时，需要将自定义后的config.yml、sentry.conf.py拷贝到镜像/etc/sentry目录下，具体参见：<br><a href="https://github.com/jiankunking/onpremise/blob/master/sentry/Dockerfile#L10" target="_blank" rel="noopener">https://github.com/jiankunking/onpremise/blob/master/sentry/Dockerfile#L10</a></li><li>sentry 环境变量中添加C_FORCE_ROOT=true，可以强制以root身份运行</li><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh" target="_blank" rel="noopener">install.sh脚本</a><ul><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh#L113" target="_blank" rel="noopener">初始化clickhouse数据库结构</a></li><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh#L142" target="_blank" rel="noopener">添加初始用户</a></li></ul></li></ul><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>总的来说，将sentry部署到kubernetes中，需要注意的点还是挺多的，很多细节需要看代码来排查。</p>]]></content>
      
      
      <categories>
          
          <category> Sentry </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Sentry </tag>
            
            <tag> Deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL实战45讲 学习笔记</title>
      <link href="/45-lectures-on-mysql-in-practice-notes.html"/>
      <url>/45-lectures-on-mysql-in-practice-notes.html</url>
      
        <content type="html"><![CDATA[<p>MySQL实战45讲 学习笔记<br>作者： 林晓斌</p><a id="more"></a><h1 id="基础架构：一条SQL查询语句是如何执行的？"><a href="#基础架构：一条SQL查询语句是如何执行的？" class="headerlink" title="基础架构：一条SQL查询语句是如何执行的？"></a>基础架构：一条SQL查询语句是如何执行的？</h1><p><img src="/images/45-lectures-on-mysql-in-practice-notes/mysql_logical_architecture_diagram.png" alt></p><p><strong>⼤多数情况下我会建议你不要使⽤查询缓存，为什么呢？因为查询缓存往往弊⼤于利。</strong></p><p>查询缓存的失效⾮常频繁，只要有对⼀个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使⽤呢，就被⼀个更新全清空了。对于更新压⼒⼤的数据库来说，查询缓存的命中率会⾮常低。除⾮你的业务就是有⼀张静态表，很长时间才会更新⼀次。⽐如，⼀个系统配置表，那这张表上的查询才适合使⽤查询缓存。</p><p>好在MySQL也提供了这种“按需使⽤”的⽅式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使⽤查询缓存。⽽对于你确定要使⽤查询缓存的语句，可以⽤SQL_CACHE显式指定，像下⾯这个语句⼀样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select SQL_CACHE * from T where ID=10；</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p></blockquote><h1 id="日志系统：一条SQL更新语句是如何执行的？"><a href="#日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="日志系统：一条SQL更新语句是如何执行的？"></a>日志系统：一条SQL更新语句是如何执行的？</h1><h2 id="重要的⽇志模块：redo-log"><a href="#重要的⽇志模块：redo-log" class="headerlink" title="重要的⽇志模块：redo log"></a>重要的⽇志模块：redo log</h2><p>当有⼀条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log⾥⾯，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘⾥⾯，⽽这个更新往往是在系统⽐较空闲的时候做。</p><p>InnoDB的redo log是固定⼤⼩的，⽐如可以配置为⼀组4个⽂件，每个⽂件的⼤⼩是1GB，总共就可以记录4GB的操作。从头开始写，写到末尾就⼜回到开头循环写，如下⾯这个图所示。</p><p><img src="/images/45-lectures-on-mysql-in-practice-notes/checkpoint_and_write_pos.png" alt></p><p>write pos是当前记录的位置，⼀边写⼀边后移，写到第3号⽂件末尾后就回到0号⽂件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据⽂件。</p><p>如果write pos追上checkpoint，这时候不能再执⾏新的更新，得停下来先擦掉⼀些记录，把checkpoint推进⼀下。</p><p>有了redo log，InnoDB就可以保证即使数据库发⽣异常重启，之前提交的记录都不会丢失，这个能⼒称为crash-safe。</p><h2 id="重要的⽇志模块：binlog"><a href="#重要的⽇志模块：binlog" class="headerlink" title="重要的⽇志模块：binlog"></a>重要的⽇志模块：binlog</h2><p>MySQL整体来看，其实就有两块：⼀块是Server层，它主要做的是MySQL功能层⾯的事情；还有⼀块是引擎层，负责存储相关的具体事宜。上⾯我们聊到的redo log是InnoDB引擎特有的⽇志，⽽Server层也有⾃⼰的⽇志，称为binlog（归档⽇志）。</p><p>我想你肯定会问，为什么会有两份⽇志呢？</p><p>因为最开始MySQL⾥并没有InnoDB引擎。MySQL⾃带的引擎是MyISAM，但是MyISAM没有crash-safe的能⼒，binlog⽇志只能⽤于归档。⽽InnoDB是另⼀个公司以插件形式引⼊MySQL的，既然只依靠binlog是没有crash-safe能⼒的，所以InnoDB使⽤另外⼀套⽇志系统——也就是redo log来实现crash-safe能⼒。</p><p>这两种⽇志有以下三点不同。</p><ol><li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使⽤。</li><li>redo log是物理⽇志，记录的是“在某个数据上做了什么修改”；binlog是逻辑⽇志，记录的是这个语句的原始逻辑，⽐如“给ID=2这⼀⾏的c字段加1 ”。</li><li>redo log是循环写的，空间固定会⽤完；binlog是可以追加写⼊的。“追加写”是指binlog⽂件写到⼀定⼤⼩后会切换到下⼀个，并不会覆盖以前的⽇志。</li></ol><p>有了对这两个⽇志的概念性理解，我们再来看执⾏器和InnoDB引擎在执⾏这个简单的update语句时的内部流程。</p><ol><li>执⾏器先找引擎取ID=2这⼀⾏。ID是主键，引擎直接⽤树搜索找到这⼀⾏。如果ID=2这⼀⾏所在的数据本来就在内存中，就直接返回给执⾏器；否则，需要先从磁盘读⼊内存，然后再返回。</li><li>执⾏器拿到引擎给的⾏数据，把这个值加上1，⽐如原来是N，现在就是N+1，得到新的⼀⾏数据，再调⽤引擎接⼝写⼊这⾏新数据。</li><li>引擎将这⾏新数据更新到内存中，同时将这个更新操作记录到redo log⾥⾯，此时redo log处于prepare状态。然后告知执⾏器执⾏完成了，随时可以提交事务。</li><li>执⾏器⽣成这个操作的binlog，并把binlog写⼊磁盘。</li><li>执⾏器调⽤引擎的提交事务接⼝，引擎把刚刚写⼊的redo log改成提交（commit）状态，更新完成。</li></ol><p>最后三步看上去有点“绕”，将redo log的写⼊拆成了两个步骤：prepare和commit，这就是”两阶段提交”。</p><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>为什么必须有“两阶段提交”呢？这是为了让两份⽇志之间的逻辑⼀致。要说明这个问题，我们得从⽂章开头的那个问题说起：怎样让数据库恢复到半个⽉内任意⼀秒的状态？</p><p>前⾯我们说过了，binlog会记录所有的逻辑操作，并且是采⽤“追加写”的形式。如果你的DBA承诺说半个⽉内可以恢复，那么备份系统中⼀定会保存最近半个⽉的所有binlog，同时系统会定期做整库备份。这⾥的“定期”取决于系统的重要性，可以是⼀天⼀备，也可以是⼀周⼀备。</p><p>当需要恢复到指定的某⼀秒时，⽐如某天下午两点发现中午⼗⼆点有⼀次误删表，需要找回数据，那你可以这么做：</p><ul><li>⾸先，找到最近的⼀次全量备份，如果你运⽓好，可能就是昨天晚上的⼀个备份，从这个备份恢复到临时库；</li><li>然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li></ul><p>这样你的临时库就跟误删之前的线上库⼀样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p><p>好了，说完了数据恢复过程，我们回来说说，为什么⽇志需要“两阶段提交”。这⾥不妨⽤反证法来进⾏解释。</p><p>由于redo log和binlog是两个独⽴的逻辑，如果不⽤两阶段提交，要么就是先写完redo log再写binlog，或者采⽤反过来的顺序。我们看看这两种⽅式会有什么问题。</p><p>仍然⽤前⾯的update语句来做例⼦。假设当前ID=2的⾏，字段c的值是0，再假设执⾏update语句过程中在写完第⼀个⽇志后，第⼆个⽇志还没有写完期间发⽣了crash，会出现什么情况呢？</p><ol><li>先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前⾯说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这⼀⾏c的值是1。<br>但是由于binlog没写完就crash了，这时候binlog⾥⾯就没有记录这个语句。因此，之后备份⽇志的时候，存起来的binlog⾥⾯就没有这条语句。<br>然后你会发现，如果需要⽤这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这⼀次更新，恢复出来的这⼀⾏c的值就是0，与原库的值不同。</li><li>先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务⽆效，所以这⼀⾏c的值是0。但是binlog⾥⾯已经记录了“把c从0改成1”这个⽇志。所以，在之后⽤binlog来恢复的时候就多了⼀个事务出来，恢复出来的这⼀⾏c的值就是1，与原库的值不同。</li></ol><p>可以看到，如果不使⽤“两阶段提交”，那么数据库的状态就有可能和⽤它的⽇志恢复出来的库的状态不⼀致。</p><p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？<br>其实不是的，不只是误操作后需要⽤这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建⼀些备库来增加系统的读能⼒的时候，现在常见的做法也是⽤全量备份加上应⽤binlog来实现的，这个“不⼀致”就会导致你的线上出现主从数据库不⼀致的情况。</p><p>简单说，redo log和binlog都可以⽤于表示事务的提交状态，⽽两阶段提交就是让这两个状态保持逻辑上的⼀致。</p><h1 id="事务隔离：为什么你改了我还看不见？"><a href="#事务隔离：为什么你改了我还看不见？" class="headerlink" title="事务隔离：为什么你改了我还看不见？"></a>事务隔离：为什么你改了我还看不见？</h1><p>SQL标准的事务隔离级别包括：</p><ul><li>读未提交是指，⼀个事务还没提交时，它做的变更就能被别的事务看到。</li><li>读提交是指，⼀个事务提交之后，它做的变更才会被其他事务看到。</li><li><strong>可重复读是指，⼀个事务执⾏过程中看到的数据，总是跟这个事务在启动时看到的数据是⼀致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</strong></li><li>串⾏化，顾名思义是对于同⼀⾏记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前<br>⼀个事务执⾏完成，才能继续执⾏。</li></ul><p>在实现上，数据库⾥⾯会创建⼀个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都⽤这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执⾏的时候创建的。这⾥需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；⽽“串⾏化”隔离级别下直接⽤加锁的⽅式来避免并⾏访问。</p><p>总结来说，存在即合理，哪个隔离级别都有它⾃⼰的使⽤场景，你要根据⾃⼰的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看⼀个数据校对逻辑的案例。</p><p>假设你在管理⼀个个⼈银⾏账户表。⼀个表存了每个⽉⽉底的余额，⼀个表存了账单明细。这时候你要做数据校对，也就是判断上个⽉的余额和当前余额的差额，是否与本⽉的账单明细⼀致。你⼀定希望在校对过程中，即使有⽤户发⽣了⼀笔新的交易，也不影响你的校对结果。</p><p>这时候使⽤“可重复读”隔离级别就很⽅便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p><h2 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h2><p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这⾥我们展开说明“可重复读”。</p><p>在MySQL中，实际上每条记录在更新的时候都会同时记录⼀条回滚操作。记录上的最新值，通过回滚操作，都可以得到前⼀个状态的值。</p><p>假设⼀个值从1被按顺序改成了2、3、4，在回滚⽇志⾥⾯就会有类似下⾯的记录。</p><p><img src="/images/45-lectures-on-mysql-in-practice-notes/read-view.png" alt></p><p>当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，<strong>在视图A、B、C⾥⾯，这⼀个记录的值分别是1、2、4</strong>，同⼀条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执⾏图中所有的回滚操作得到。</p><p>同时你会发现，即使现在有另外⼀个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。</p><h1 id="深入浅出索引（上）"><a href="#深入浅出索引（上）" class="headerlink" title="深入浅出索引（上）"></a>深入浅出索引（上）</h1><p>为了让⼀个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使⽤⼆叉树，⽽是要使⽤“N叉”树。这⾥，“N叉”树中的“N”取决于数据块的⼤⼩。</p><p><font color="DeepPink"><strong>以InnoDB的⼀个整数字段索引为例，这个N差不多是1200。这棵树⾼是4的时候，就可以存1200的3次⽅个值，这已经17亿了。考虑到树根的数据块总是在内存中的，⼀个10亿⾏的表上⼀个整数字段的索引，查找⼀个值最多只需要访问3次磁盘。其实，树的第⼆层也有很⼤概率在内存中，那么访问磁盘的平均次数就更少了。</strong></font></p><p>N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被⼴泛应⽤在数据库引擎中了。</p><p>不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决⽅案。数据库技术发展到今天，跳表、LSM树等数据结构也被⽤于引擎设计中，这⾥我就不再⼀⼀展开了。</p><p><font color="DeepPink"><strong>你⼼⾥要有个概念，数据库底层存储的核⼼就是基于这些数据模型的。每碰到⼀个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适⽤场景。</strong></font></p><p>在MySQL中，索引是在存储引擎层实现的，所以并没有统⼀的索引标准，即不同存储引擎的索引的⼯作⽅式并不⼀样。⽽即使多个存储引擎⽀持同⼀种类型的索引，其底层的实现也可能不同。</p><h2 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h2><p><strong>主键索引的叶⼦节点存的是整⾏数据。</strong>在InnoDB⾥，主键索引也被称为聚簇索引（clustered index）。<br><strong>⾮主键索引的叶⼦节点内容是主键的值。</strong>在InnoDB⾥，⾮主键索引也被称为⼆级索引（secondary index）。<br>根据上⾯的索引结构说明，我们来讨论⼀个问题：基于主键索引和普通索引的查询有什么区别？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 主键列为ID的表，表中有字段k，并且在k上有索引。</span><br><span class="line">create table T(</span><br><span class="line">id int primary key,</span><br><span class="line">k int not null,</span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure><ul><li>如果语句是select * from T where ID=500，即主键查询⽅式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k=5，即普通索引查询⽅式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索⼀次。这个过程称为回表。</li></ul><p>也就是说，基于⾮主键索引的查询需要多扫描⼀棵索引树。因此，我们在应⽤中应该尽量使⽤主键查询。</p><h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h2><p>B+树为了维护索引有序性，在插⼊新值的时候需要做必要的维护。</p><blockquote><p>你可能在⼀些建表规范⾥⾯见到过类似的描述，要求建表语句⾥⼀定要有⾃增主键。当然事⽆绝对，我们来分析⼀下哪些场景下应该使⽤⾃增主键，⽽哪些场景下不应该。</p></blockquote><p>⾃增主键是指⾃增列上定义的主键，在建表语句中⼀般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。</p><p>插⼊新记录的时候可以不指定ID的值，系统会获取当前ID最⼤值加1作为下⼀条记录的ID值。</p><p>也就是说，<font color="DeepPink"><strong>⾃增主键的插⼊数据模式，正符合了我们前⾯提到的递增插⼊的场景。每次插⼊⼀条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶⼦节点的分裂。</strong></font></p><p>⽽有业务逻辑的字段做主键，则往往不容易保证有序插⼊，这样写数据成本相对较⾼。</p><p>除了考虑性能外，我们还可以从存储空间的⻆度来看。假设你的表中确实有⼀个唯⼀字段，⽐如字符串类型的身份证号，那应该⽤身份证号做主键，还是⽤⾃增字段做主键呢？</p><p>由于每个⾮主键索引的叶⼦节点上都是主键的值。如果⽤身份证号做主键，那么每个⼆级索引的叶⼦节点占⽤约20个字节，⽽如果⽤整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。</p><p>显然，主键长度越⼩，普通索引的叶⼦节点就越⼩，普通索引占⽤的空间也就越⼩。</p><p>所以，从性能和存储空间⽅⾯考量，⾃增主键往往是更合理的选择。</p><p>有没有什么场景适合⽤业务字段直接做主键的呢？还是有的。⽐如，有些业务的场景需求是这样的：</p><ol><li>只有⼀个索引；</li><li>该索引必须是唯⼀索引。</li></ol><p>你⼀定看出来了，这就是典型的KV场景。</p><p>由于没有其他索引，所以也就不⽤考虑其他索引的叶⼦节点⼤⼩的问题。</p><p>这时候我们就要优先考虑上⼀段提到的“尽量使⽤主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p><h1 id="深⼊浅出索引（下）"><a href="#深⼊浅出索引（下）" class="headerlink" title="深⼊浅出索引（下）"></a>深⼊浅出索引（下）</h1><p>在下⾯这个表T中，如果我执⾏ select * from T where k between 3 and 5，需要执⾏⼏次树的搜索操作，会扫描多少⾏？</p><p>下⾯是这个表的初始化语句。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table T (</span><br><span class="line">ID int primary key,</span><br><span class="line">k int NOT NULL DEFAULT 0,</span><br><span class="line">s varchar(16) NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">index k(k))</span><br><span class="line">engine=InnoDB;</span><br><span class="line">insert into T values(100,1, &apos;aa&apos;),(200,2,&apos;bb&apos;),(300,3,&apos;cc&apos;),(500,5,&apos;ee&apos;),(600,6,&apos;ff&apos;),(700,7,&apos;gg&apos;);</span><br></pre></td></tr></table></figure><p><img src="/images/45-lectures-on-mysql-in-practice-notes/InnoDB%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.png" alt></p><p>现在，我们⼀起来看看这条SQL查询语句的执⾏流程：</p><ol><li>在k索引树上找到k=3的记录，取得 ID = 300；</li><li>再到ID索引树查到ID=300对应的R3；</li><li>在k索引树取下⼀个值k=5，取得ID=500；</li><li>再回到ID索引树查到ID=500对应的R4；</li><li>在k索引树取下⼀个值k=6，不满⾜条件，循环结束。</li></ol><p>在这个过程中，<strong>回到主键索引树搜索的过程，我们称为回表</strong>。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。</p><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><p>如果执⾏的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，⽽ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询⾥⾯，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h2><p>⽽MySQL 5.6 引⼊的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满⾜条件的记录，减少回表次数。</p><h1 id="全局锁和表锁"><a href="#全局锁和表锁" class="headerlink" title="全局锁和表锁"></a>全局锁和表锁</h1><p>根据加锁的范围，MySQL⾥⾯的锁⼤致可以分成全局锁、表级锁和⾏锁三类。</p><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了⼀个加全局读锁的⽅法，命令是 Flush tables with read lock(FTWRL)。当你需要让整个库处于只读状态的时候，可以使⽤这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使⽤场景是，做全库逻辑备份。</strong>也就是把整库每个表都select出来存成⽂本。</p><p>官⽅⾃带的逻辑备份⼯具是mysqldump。当mysqldump使⽤参数–single-transaction的时候，导数据之前就会启动⼀个事务，来确保拿到⼀致性视图。⽽由于MVCC的⽀持，这个过程中数据是可以正常更新的。</p><p>你⼀定在疑惑，有了这个功能，为什么还需要FTWRL呢？<strong>⼀致性读是好，但前提是引擎要⽀持这个隔离级别</strong>。⽐如，对于MyISAM这种不⽀持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的⼀致性。这时，我们就需要使⽤FTWRL命令了。</p><p>所以，<strong>single-transaction⽅法只适⽤于所有的表使⽤事务引擎的库</strong>。如果有的表使⽤了不⽀持事务的引擎，那么备份就只能通过FTWRL⽅法。这往往是DBA要求业务开发⼈员使⽤InnoDB替代MyISAM的原因之⼀。</p><p>你也许会问，既然要全库只读，为什么不使⽤set global readonly=true的⽅式呢？确实readonly⽅式也可以让全库进⼊只读状态，但我还是会建议你⽤FTWRL⽅式，主要有两个原因：</p><ul><li>⼀是，在有些系统中，readonly的值会被⽤来做其他逻辑，⽐如⽤来判断⼀个库是主库还是备库。因此，修改global变量的⽅式影响⾯更⼤，我不建议你使⽤。</li><li>⼆是，在异常处理机制上有差异。如果执⾏FTWRL命令之后由于客户端发⽣异常断开，那么MySQL会⾃动释放这个全局锁，整个库回到可以正常更新的状态。⽽将整个库设置为readonly之后，如果客户端发⽣异常，则数据库就会⼀直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较⾼。</li></ul><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>MySQL⾥⾯表级别的锁有两种：⼀种是表锁，⼀种是元数据锁（meta data lock，MDL)。</p><p><strong>表锁的语法是 lock tables … read/write</strong>。与FTWRL类似，可以⽤unlock tables主动释放锁，也可以在客户端断开的时候⾃动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p><p>举个例⼦, 如果在某个线程A中执⾏lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执⾏unlock tables之前，也只能执⾏读t1、读写t2的操作。连写t1都不允许，⾃然也不能访问其他表。</p><p>在还没有出现更细粒度的锁的时候，表锁是最常⽤的处理并发的⽅式。⽽对于InnoDB这种⽀持⾏锁的引擎，⼀般不使⽤lock tables命令来控制并发，毕竟锁住整个表的影响⾯还是太⼤。</p><p><strong>另⼀类表级的锁是MDL（metadata lock)</strong>。MDL不需要显式使⽤，在访问⼀个表的时候会被⾃动加上。MDL的作⽤是，保证读写的正确性。你可以想象⼀下，如果⼀个查询正在遍历⼀个表中的数据，⽽执⾏期间另⼀个线程对这个表结构做变更，删了⼀列，那么查询线程拿到的结果跟表结构对不上，肯定是不⾏的。</p><p>因此，在MySQL 5.5版本中引⼊了MDL，当对⼀个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。</p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对⼀张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，⽤来保证变更表结构操作的安全性。因此，如果有两个线程要同时给⼀个表加字段，其中⼀个要等另⼀个执⾏完才能开始执⾏。</li></ul><p>你肯定知道，给⼀个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对⼤表操作的时候，你肯定会特别⼩⼼，以免对线上服务造成影响。⽽实际上，即使是⼩表，操作不慎也会出问题。我们来看⼀下下⾯的操作序列，假设表t是⼀个⼩表。</p><blockquote><p>备注：这⾥的实验环境是MySQL 5.6。</p></blockquote><p><img src="/images/45-lectures-on-mysql-in-practice-notes/MDL_LOCK_EXAMPLES.png" alt></p><p>我们可以看到session A先启动，这时候会对表t加⼀个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执⾏。之后session C会被blocked，是因为session A的MDL读锁还没有释放，⽽session C需要MDL写锁，因此只能被阻塞。</p><p>如果只有session C⾃⼰被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前⾯我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。</p><p>如果某个表上的查询语句频繁，⽽且客户端有重试机制，也就是说超时后会再起⼀个新session再请求的话，这个库的线程很快就会爆满。</p><p>你现在应该知道了，事务中的MDL锁，在语句执⾏开始时申请，但是语句结束后并不会马上释放，⽽会等到整个事务提交后再释放。</p><h1 id="⾏锁"><a href="#⾏锁" class="headerlink" title="⾏锁"></a>⾏锁</h1><p><strong>在InnoDB事务中，⾏锁是在需要的时候才加上的，但并不是不需要了就⽴刻释放，⽽是要等到事务结束时才释放</strong>。这个就是两阶段锁协议。</p><p>知道了这个设定，对我们使⽤事务有什么帮助呢？那就是，<font color="DeepPink"><strong>如果你的事务中需要锁多个⾏，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong></font>我给你举个例⼦。</p><p>假设你负责实现⼀个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化⼀点，这个业务需要涉及到以下操作：</p><ol><li>从顾客A账户余额中扣除电影票价；</li><li>给影院B的账户余额增加这张电影票价；</li><li>记录⼀条交易⽇志。</li></ol><p>也就是说，要完成这个交易，我们需要update两条记录，并insert⼀条记录。当然，为了保证交易的原⼦性，我们要把这三个操作放在⼀个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p><p>试想如果同时有另外⼀个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同⼀个影院账户的余额，需要修改同⼀⾏数据。</p><p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的⾏锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，⽐如按照3、1、2这样的顺序，那么影院账户余额这⼀⾏的锁时间就最少。这就最⼤程度地减少了事务之间的锁等待，提升了并发度。</p><h1 id="事务到底是隔离的还是不隔离的？"><a href="#事务到底是隔离的还是不隔离的？" class="headerlink" title="事务到底是隔离的还是不隔离的？"></a>事务到底是隔离的还是不隔离的？</h1><p>begin/start transaction 命令并不是⼀个事务的起点，在执⾏到它们之后的第⼀个操作InnoDB表的语句（第⼀个快照读语句），事务才真正启动。如果你想要马上启动⼀个事务，可以使⽤start transaction with consistent snapshot 这个命令。</p><p>在MySQL⾥，有两个“视图”的概念：</p><ul><li>⼀个是view。它是⼀个⽤查询语句定义的虚拟表，在调⽤的时候执⾏查询语句并⽣成结果。创建视图的语法是create view… ，⽽它的查询⽅法与表⼀样。</li><li>另⼀个是InnoDB在实现MVCC时⽤到的⼀致性读视图，即consistent read view，⽤于⽀持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。</li></ul><p>它没有物理结构，作⽤是事务执⾏期间⽤来定义“我能看到什么数据”。</p><h2 id="“快照”在MVCC⾥是怎么⼯作的？"><a href="#“快照”在MVCC⾥是怎么⼯作的？" class="headerlink" title="“快照”在MVCC⾥是怎么⼯作的？"></a>“快照”在MVCC⾥是怎么⼯作的？</h2><p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。</p><p>⼀个数据版本，对于⼀个事务视图来说，除了⾃⼰的更新总是可见以外，有三种情况：</p><ol><li>版本未提交，不可见；</li><li>版本已提交，但是是在视图创建后提交的，不可见；</li><li>版本已提交，⽽且是在视图创建前提交的，可见。</li></ol><p>更新数据都是先读后写的，⽽这个读，只能读当前的值，称为“当前读”（current read）。</p><blockquote><p><font color="DeepPink"><strong>当前读的规则，就是要能读到所有已经提交的记录的最新值。</strong></font></p></blockquote><p>这⾥我们提到了⼀个概念，叫作当前读。<font color="DeepPink"><strong>其实，除了update语句外，select语句如果加锁，也是当前读。</strong></font></p><blockquote><p>事务更新数据的时候，只能⽤当前读。如果当前的记录的⾏锁被其他事务占⽤的话，就需要进⼊锁等待。</p></blockquote><p><a href="/attachments/MySQL实战45讲/08讲事务到底是隔离的还是不隔离的.pdf" target="_blank">事务到底是隔离的还是不隔离的？</a></p><h1 id="普通索引和唯一索引，应该怎么选择"><a href="#普通索引和唯一索引，应该怎么选择" class="headerlink" title="普通索引和唯一索引，应该怎么选择?"></a>普通索引和唯一索引，应该怎么选择?</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T(</span><br><span class="line">id int primary key,</span><br><span class="line">k int not null,</span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure><p>假设字段 k 上的值都不重复。</p><p><img src="/images/45-lectures-on-mysql-in-practice-notes/InnoDB%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.png" alt></p><h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h2><p>假设，执⾏查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶⼦节点，也就是图中右下⻆的这个数据页，然后可以认为数据页内部通过⼆分法来定位记录。</p><ul><li>对于普通索引来说，查找到满⾜条件的第⼀个记录(5,500)后，需要查找下⼀个记录，直到碰到第⼀个不满⾜k=5条件的记录。</li><li>对于唯⼀索引来说，由于索引定义了唯⼀性，查找到第⼀个满⾜条件的记录后，就会停⽌继续检索。</li></ul><p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p><p>你知道的，InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读⼀条记录的时候，并不是将这个记录本身从磁盘读出来，⽽是以页为单位，将其整体读⼊内存。在InnoDB中，每个数据页的⼤⼩默认是16KB。</p><p>因为引擎是按页读写的，所以说，当找到k=5的记录的时候，它所在的数据页就都在内存⾥了。那么，对于普通索引来说，要多做的那⼀次“查找和判断下⼀条记录”的操作，就只需要⼀次指针寻找和⼀次计算。</p><p>当然，如果k=5这个记录刚好是这个数据页的最后⼀个记录，那么要取下⼀个记录，必须读取下⼀个数据页，这个操作会稍微复杂⼀些。</p><p>但是，我们之前计算过，对于整型字段，⼀个数据页可以放近千个key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。</p><h2 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a>更新过程</h2><p>当需要更新⼀个数据页时，如果数据页在内存中就直接更新，⽽如果这个数据页还没有在内存中的话，在不影响数据⼀致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读⼊这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读⼊内存，然后执⾏change buffer中与这个页有关的操作。通过这种⽅式就能保证这个数据逻辑的正确性。</p><p>需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写⼊到磁盘上。</p><p>将change buffer中的操作应⽤到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执⾏merge操作。</p><p>显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执⾏速度会得到明显的提升。⽽且，数据读⼊内存是需要占⽤buffer pool的，所以这种⽅式还能够避免占⽤内存，提⾼内存利⽤率。</p><p>那么，什么条件下可以使⽤change buffer呢？</p><p>对于唯⼀索引来说，所有的更新操作都要先判断这个操作是否违反唯⼀性约束。⽐如，要插⼊(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，⽽这必须要将数据页读⼊内存才能判断。如果都已经读⼊到内存了，那直接更新内存会更快，就没必要使⽤change buffer了。</p><p>因此，<strong>唯⼀索引的更新就不能使⽤change buffer，实际上也只有普通索引可以使⽤。</strong></p><p><a href="/attachments/MySQL实战45讲/09讲普通索引和唯一索引，应该怎么选择.pdf" target="_blank">普通索引和唯一索引，应该怎么选择?</a></p><h1 id="MySQL为什么有时候会选错索引"><a href="#MySQL为什么有时候会选错索引" class="headerlink" title="MySQL为什么有时候会选错索引?"></a>MySQL为什么有时候会选错索引?</h1><p>MySQL在真正开始执⾏语句之前，并不能精确地知道满⾜这个条件的记录有多少条，⽽只能根据统计信息来估算记录数。</p><p>估算出来的数字有可能会不准确，从而导致索引选择不对。</p><p><a href="/attachments/MySQL实战45讲/10讲MySQL为什么有时候会选错索引.pdf" target="_blank">MySQL为什么有时候会选错索引?</a></p><h1 id="怎么给字符串字段加索引？"><a href="#怎么给字符串字段加索引？" class="headerlink" title="怎么给字符串字段加索引？"></a>怎么给字符串字段加索引？</h1><ol><li>直接创建完整索引，这样可能⽐较占⽤空间；</li><li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使⽤覆盖索引；</li><li>倒序存储，再创建前缀索引，⽤于绕过字符串本身前缀的区分度不够的问题；</li><li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种⽅式⼀样，都不⽀持范围扫描。</li></ol><h1 id="为什么我的MySQL会“抖”一下？"><a href="#为什么我的MySQL会“抖”一下？" class="headerlink" title="为什么我的MySQL会“抖”一下？"></a>为什么我的MySQL会“抖”一下？</h1><p>MySQL偶尔“抖”⼀下的那个瞬间，可能就是在刷脏页（flush）。</p><p>那么，什么情况会引发数据库的flush过程呢？</p><p>第⼀种场景是，InnoDB的redo log写满了。这时候系统会停⽌所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。</p><p><img src="/images/45-lectures-on-mysql-in-practice-notes/redo_log%E7%8A%B6%E6%80%81%E5%9B%BE.png" alt></p><p>第⼆种场景是，就是系统内存不⾜。当需要新的内存页，⽽内存不够⽤的时候，就要淘汰⼀些数据页，空出内存给别的数据页使⽤。如果淘汰的是“脏页”，就要先将脏页写到磁盘。</p><p>你⼀定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读⼊数据页，然后拿redo log出来应⽤不就⾏了？这⾥其实是从性能考虑的。如果刷脏页⼀定会写盘，就保证了每个数据页有两种状态：</p><ul><li>⼀种是内存⾥存在，内存⾥就肯定是正确的结果，直接返回；</li><li>另⼀种是内存⾥没有数据，就可以肯定数据⽂件上是正确的结果，读⼊内存后返回。这样的效率最⾼。</li></ul><p>第三种场景是，就是MySQL认为系统“空闲”的时候。<br>第四种场景是，就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p><p>刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p><ol><li>⼀个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li><li>⽇志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</li></ol><p>所以，InnoDB需要有控制脏页⽐例的机制，来尽量避免上⾯的这两种情况。</p><h2 id="InnoDB刷脏页的控制策略"><a href="#InnoDB刷脏页的控制策略" class="headerlink" title="InnoDB刷脏页的控制策略"></a>InnoDB刷脏页的控制策略</h2><p>合理地设置innodb_io_capacity的值，并且平时要多关注脏页⽐例，不要让它经常接近75%。</p><p>更详细的关于innodb_io_capacity、innodb_max_dirty_pages_pct等参数的设置参见：<a href="/attachments/MySQL实战45讲/12讲为什么我的MySQL会“抖”一下.pdf" target="_blank">为什么我的MySQL会“抖”一下?</a></p><h1 id="为什么表数据删掉一半，表文件大小不变？"><a href="#为什么表数据删掉一半，表文件大小不变？" class="headerlink" title="为什么表数据删掉一半，表文件大小不变？"></a>为什么表数据删掉一半，表文件大小不变？</h1><p>delete命令其实只是把记录的位置，或者数据页标记为了“可复⽤”，但磁盘⽂件的⼤⼩是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复⽤，⽽没有被使⽤的空间，看起来就像是“空洞”。</p><p>实际上，不⽌是删除数据会造成空洞，插⼊数据也会。</p><p>如果数据是按照索引递增顺序插⼊的，那么索引是紧凑的。但如果数据是随机插⼊的，就可能造成索引的数据页分裂。</p><p>表空间收缩的方式：重建表</p><p>重建表的方式及需要注意的问题，参见：<a href="/attachments/MySQL实战45讲/13讲为什么表数据删掉一半，表文件大小不变.pdf" target="_blank">为什么表数据删掉一半，表文件大小不变?</a></p><h1 id="count-这么慢，我该怎么办？"><a href="#count-这么慢，我该怎么办？" class="headerlink" title="count()这么慢，我该怎么办？"></a>count()这么慢，我该怎么办？</h1><h2 id="count-的实现⽅式"><a href="#count-的实现⽅式" class="headerlink" title="count(*)的实现⽅式"></a>count(*)的实现⽅式</h2><p>在不同的MySQL引擎中，count(*)有不同的实现⽅式。</p><ul><li>MyISAM引擎把⼀个表的总⾏数存在了磁盘上，因此执⾏count(*)的时候会直接返回这个数，效率很⾼；</li><li>⽽InnoDB引擎就麻烦了，它执⾏count(*)的时候，需要把数据⼀⾏⼀⾏地从引擎⾥⾯读出来，然后累积计数。</li></ul><p>这⾥需要注意的是，我们在这篇⽂章⾥讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。</p><p>那为什么<strong>InnoDB不跟MyISAM⼀样，也把数字存起来呢？</strong><br>这是因为即使是在同⼀个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少⾏”也是不确定的。</p><p>由于InnoDB要⽀持事务，从⽽导致InnoDB表不能把count(*)直接存起来，然后查询的时候直接返回形成的。</p><p>所谓以⼦之⽭攻⼦之盾，现在我们就利⽤“事务”这个特性，把问题解决掉。</p><p><img src="/images/45-lectures-on-mysql-in-practice-notes/%E4%BC%9A%E8%AF%9DA%E3%80%81B%E7%9A%84%E6%89%A7%E2%BE%8F%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt></p><p>我们来看下现在的执⾏结果。虽然会话B的读操作仍然是在T3执⾏的，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还不可见。</p><p>因此，会话B看到的结果⾥， 查计数值和“最近100条记录”看到的结果，逻辑上就是⼀致的。</p><h2 id="不同的count⽤法"><a href="#不同的count⽤法" class="headerlink" title="不同的count⽤法"></a>不同的count⽤法</h2><p>count(*)、count(主键id)和count(1) 都表示返回满⾜条件的结果集的总⾏数；⽽count(字段），则表示返回满⾜条件的数据⾏⾥⾯，参数“字段”不为NULL的总个数。</p><p>⾄于分析性能差别的时候，你可以记住这么⼏个原则：</p><ol><li>server层要什么就给什么；</li><li>InnoDB只给必要的值；</li><li>现在的优化器只优化了count(*)的语义为“取⾏数”，其他“显⽽易见”的优化并没有做。</li></ol><p>对于count(主键id)来说，InnoDB引擎会遍历整张表，把每⼀⾏的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按⾏累加。</p><p>对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每⼀⾏，放⼀个数字“1”进去，判断是不可能为空的，按⾏累加。</p><p>单看这两个⽤法的差别的话，你能对⽐出来，count(1)执⾏得要⽐count(主键id)快。因为从引擎返回id会涉及到解析数据⾏，以及拷贝字段值的操作。</p><p>对于count(字段)来说：</p><ol><li>如果这个“字段”是定义为not null的话，⼀⾏⾏地从记录⾥⾯读出这个字段，判断不能为null，按⾏累加；</li><li>如果这个“字段”定义允许为null，那么执⾏的时候，判断到有可能是null，还要把值取出来再判断⼀下，不是null才累加。</li></ol><p>也就是前⾯的第⼀条原则，server层要什么字段，InnoDB就返回什么字段。<br>但是count(&#42;)是例外，并不会把全部字段取出来，⽽是专门做了优化，不取值。count(&#42;)肯定不是null，按⾏累加。</p><p>所以结论是：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(&#42;)，所以我建议你，尽量使⽤count(&#42;)。</p><!-- * 转义字符为 &#42; --><h1 id="答疑：日志和索引相关问题"><a href="#答疑：日志和索引相关问题" class="headerlink" title="答疑：日志和索引相关问题"></a>答疑：日志和索引相关问题</h1><ul><li>MySQL怎么知道binlog是完整的?</li><li>redo log 和 binlog是怎么关联起来的?</li><li>处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?</li><li>如果这样的话，为什么还要两阶段提交呢？⼲脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个⽇志都完整才可以。是不是⼀样的逻辑？</li><li>不引⼊两个⽇志，也就没有两阶段提交的必要了。只⽤binlog来⽀持崩溃恢复，⼜能⽀持归档，不就可以了？</li><li>那能不能反过来，只⽤redo log，不要binlog？</li><li>redo log⼀般设置多⼤？</li><li>正常运⾏中的实例，数据写⼊后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？</li><li>redo log buffer是什么？是先修改内存，还是先写redo log⽂件？</li></ul><p>详细解答参见：<a href="/attachments/MySQL实战45讲/15讲答疑文章（一）：日志和索引相关问题.pdf" target="_blank">答疑：日志和索引相关问题?</a></p><h1 id="“order-by”是怎么工作的？"><a href="#“order-by”是怎么工作的？" class="headerlink" title="“order by”是怎么工作的？"></a>“order by”是怎么工作的？</h1><p>sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的⼤⼩。如果要排序的数据量⼩于sort_buffer_size，排序就在内存中完成。但如果排序数据量太⼤，内存放不下，则不得不利⽤磁盘临时⽂件辅助排序。</p><p>optimizer_trace 可支持把MySQL查询执行计划树打印出来。</p><p><a href="/attachments/MySQL实战45讲/16讲“orderby”是怎么工作的.pdf" target="_blank">“order by”是怎么工作的？</a></p><h1 id="为什么这些SQL语句逻辑相同，性能却差异巨大？"><a href="#为什么这些SQL语句逻辑相同，性能却差异巨大？" class="headerlink" title="为什么这些SQL语句逻辑相同，性能却差异巨大？"></a>为什么这些SQL语句逻辑相同，性能却差异巨大？</h1><h2 id="隐式类型转换"><a href="#隐式类型转换" class="headerlink" title="隐式类型转换"></a>隐式类型转换</h2><p>数据库⾥⾯类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？</p><p>这⾥有⼀个简单的⽅法，看 select “10” &gt; 9 的结果：</p><ol><li>如果规则是“将字符串转成数字”，那么就是做数字⽐较，结果应该是1；</li><li>如果规则是“将数字转成字符串”，那么就是做字符串⽐较，结果应该是0。</li></ol><h2 id="隐式字符编码转换"><a href="#隐式字符编码转换" class="headerlink" title="隐式字符编码转换"></a>隐式字符编码转换</h2><p>不同表之间字符集不同，可能会导致索引失效。</p><p>具体例子可以参见下文，第3小结：<br><a href="/attachments/MySQL实战45讲/18讲为什么这些SQL语句逻辑相同，性能却差异巨大.pdf" target="_blank">为什么这些SQL语句逻辑相同，性能却差异巨大？</a></p><h1 id="为什么我只查一行的语句，也执行这么慢？"><a href="#为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="为什么我只查一行的语句，也执行这么慢？"></a>为什么我只查一行的语句，也执行这么慢？</h1><h2 id="查询长时间不返回"><a href="#查询长时间不返回" class="headerlink" title="查询长时间不返回"></a>查询长时间不返回</h2><p>等MDL锁<br>等flush<br>等⾏锁</p><h2 id="查询慢"><a href="#查询慢" class="headerlink" title="查询慢"></a>查询慢</h2><p>详细排查过程参见：<a href="/attachments/MySQL实战45讲/19讲为什么我只查一行的语句，也执行这么慢.pdf" target="_blank">为什么我只查一行的语句，也执行这么慢？</a></p><h1 id="幻读是什么，幻读有什么问题？"><a href="#幻读是什么，幻读有什么问题？" class="headerlink" title="幻读是什么，幻读有什么问题？"></a>幻读是什么，幻读有什么问题？</h1><h2 id="如何解决幻读？"><a href="#如何解决幻读？" class="headerlink" title="如何解决幻读？"></a>如何解决幻读？</h2><p>产⽣幻读的原因是，⾏锁只能锁住⾏，但是新插⼊记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引⼊新的锁，也就是间隙锁(Gap Lock)。</p><p>间隙锁和⾏锁合称next-key lock，每个next-key lock是前开后闭区间。</p><p>间隙锁是在可重复读隔离级别下才会⽣效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和⽇志不⼀致问题，需要把binlog格式设置为row。这，也是现在不少公司使⽤的配置组合。</p><h1 id="为什么我只改⼀⾏的语句，锁这么多？"><a href="#为什么我只改⼀⾏的语句，锁这么多？" class="headerlink" title="为什么我只改⼀⾏的语句，锁这么多？"></a>为什么我只改⼀⾏的语句，锁这么多？</h1><p>加锁规则⾥⾯，包含了两个“原则”、两个“优化”和⼀个“bug”。</p><ol><li>原则1：<font color="DeepPink"><strong>加锁的基本单位是next-key lock</strong></font>。希望你还记得，next-key lock是前开后闭区间。</li><li>原则2：查找过程中访问到的对象才会加锁。</li><li>优化1：索引上的等值查询，给唯⼀索引加锁的时候，next-key lock退化为⾏锁。</li><li>优化2：索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key lock退化为间隙锁。</li><li>⼀个bug：唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌。</li></ol><blockquote><p>MySQL后⾯的版本可能会改变加锁策略，所以这个规则只限于截⽌到现在的最新版本，即5.x系列&lt;=5.7.24，8.0系列&lt;=8.0.13。</p></blockquote><p>间隙锁、⾏锁、next-key lock案例分析：<a href="/attachments/MySQL实战45讲/21讲为什么我只改一行的语句，锁这么多.pdf" target="_blank">为什么我只改一行的语句，锁这么多？</a></p><h1 id="MySQL有哪些“饮鸩⽌渴”提⾼性能的⽅法"><a href="#MySQL有哪些“饮鸩⽌渴”提⾼性能的⽅法" class="headerlink" title="MySQL有哪些“饮鸩⽌渴”提⾼性能的⽅法"></a>MySQL有哪些“饮鸩⽌渴”提⾼性能的⽅法</h1><ul><li>短连接风暴<ul><li>先处理掉那些占着连接但是不⼯作的线程</li><li>减少连接过程的消耗</li></ul></li><li>慢查询性能问题<ul><li>索引没有设计好</li><li>语句没写好</li></ul></li><li>QPS突增问题</li></ul><p>更加详细的处理方法参见：<a href="/attachments/MySQL实战45讲/22讲MySQL有哪些“饮鸩止渴”提高性能的方法.pdf" target="_blank">MySQL有哪些“饮鸩止渴”提高性能的方法</a></p><h1 id="MySQL是怎么保证数据不丢的？"><a href="#MySQL是怎么保证数据不丢的？" class="headerlink" title="MySQL是怎么保证数据不丢的？"></a>MySQL是怎么保证数据不丢的？</h1><p>WAL机制主要得益于两个⽅⾯：</p><ol><li>redo log 和 binlog都是顺序写，磁盘的顺序写⽐随机写速度要快；</li><li>组提交机制，可以⼤幅度降低磁盘的IOPS消耗。</li></ol><p>事务执⾏期间，还没到提交阶段，如果发⽣crash的话，redo log肯定丢了，这会不会导致主备不⼀致呢？<br>回答：不会。因为这时候binlog 也还在binlog cache⾥，没发给备库。crash以后redo log和binlog都没有了，从业务⻆度看这个事务也没有提交，所以数据是⼀致的。</p><p><a href="/attachments/MySQL实战45讲/23讲MySQL是怎么保证数据不丢的.pdf" target="_blank">MySQL是怎么保证数据不丢的？</a></p><h1 id="MySQL是怎么保证主备一致的？"><a href="#MySQL是怎么保证主备一致的？" class="headerlink" title="MySQL是怎么保证主备一致的？"></a>MySQL是怎么保证主备一致的？</h1><p><a href="/attachments/MySQL实战45讲/24讲MySQL是怎么保证主备一致的.pdf" target="_blank">MySQL是怎么保证主备一致的？</a></p><h1 id="MySQL是怎么保证高可用的？"><a href="#MySQL是怎么保证高可用的？" class="headerlink" title="MySQL是怎么保证高可用的？"></a>MySQL是怎么保证高可用的？</h1><p><a href="/attachments/MySQL实战45讲/25讲MySQL是怎么保证高可用的.pdf" target="_blank">MySQL是怎么保证高可用的？</a></p><h1 id="备库为什么会延迟好几个小时？"><a href="#备库为什么会延迟好几个小时？" class="headerlink" title="备库为什么会延迟好几个小时？"></a>备库为什么会延迟好几个小时？</h1><ul><li>MySQL 5.5版本的并⾏复制策略<ul><li>按表分发策略</li><li>按⾏分发策略</li></ul></li><li>MySQL 5.6版本的并⾏复制策略</li><li>MariaDB的并⾏复制策略</li><li>MySQL 5.7的并⾏复制策略</li><li>MySQL 5.7.22的并⾏复制策略</li></ul><p><a href="/attachments/MySQL实战45讲/26讲备库为什么会延迟好几个小时.pdf" target="_blank">备库为什么会延迟好几个小时？</a></p><h1 id="主库出问题了从库怎么办？"><a href="#主库出问题了从库怎么办？" class="headerlink" title="主库出问题了从库怎么办？"></a>主库出问题了从库怎么办？</h1><ul><li>基于位点的主备切换</li><li>GTID</li><li>基于 GTID 的主备切换</li><li>GTID 和在线 DDL</li></ul><p><a href="/attachments/MySQL实战45讲/27讲主库出问题了从库怎么办.pdf" target="_blank">主库出问题了从库怎么办？</a></p><h1 id="读写分离有哪些坑？"><a href="#读写分离有哪些坑？" class="headerlink" title="读写分离有哪些坑？"></a>读写分离有哪些坑？</h1><ul><li>强制走主库方案</li><li>sleep 方案</li><li>判断主备无延迟方案</li><li>配合 semi-sync 方案</li><li>等主库位点方案</li><li>等 GTID 方案</li></ul><p><a href="/attachments/MySQL实战45讲/28讲读写分离有哪些坑.pdf" target="_blank">读写分离有哪些坑？</a></p><h1 id="如何判断一个数据库是不是出问题了？"><a href="#如何判断一个数据库是不是出问题了？" class="headerlink" title="如何判断一个数据库是不是出问题了？"></a>如何判断一个数据库是不是出问题了？</h1><ul><li>select 1 判断</li><li>查表判断</li><li>更新判断</li><li>内部统计</li></ul><p><a href="/attachments/MySQL实战45讲/29讲如何判断一个数据库是不是出问题了.pdf" target="_blank">如何判断一个数据库是不是出问题了？</a></p><h1 id="误删数据后除了跑路还能怎么办？"><a href="#误删数据后除了跑路还能怎么办？" class="headerlink" title="误删数据后除了跑路还能怎么办？"></a>误删数据后除了跑路还能怎么办？</h1><ul><li>误删行</li><li>误删库/表</li><li>延迟复制备库</li><li>预防误删库/表的方法</li><li>rm 删除数据</li></ul><p><a href="/attachments/MySQL实战45讲/31讲误删数据后除了跑路还能怎么办.pdf" target="_blank">误删数据后除了跑路还能怎么办？</a></p><h1 id="为什么还有kill不掉的语句？"><a href="#为什么还有kill不掉的语句？" class="headerlink" title="为什么还有kill不掉的语句？"></a>为什么还有kill不掉的语句？</h1><p><a href="/attachments/MySQL实战45讲/32讲为什么还有kill不掉的语句.pdf" target="_blank">为什么还有kill不掉的语句？</a></p><h1 id="关于Join"><a href="#关于Join" class="headerlink" title="关于Join"></a>关于Join</h1><p><a href="/attachments/MySQL实战45讲/34讲到底可不可以使用join.pdf" target="_blank">到底可不可以使用join？</a></p><p><a href="/attachments/MySQL实战45讲/35讲join语句怎么优化.pdf" target="_blank">join语句怎么优化？</a></p><h1 id="自增主键为什么不是连续的？"><a href="#自增主键为什么不是连续的？" class="headerlink" title="自增主键为什么不是连续的？"></a>自增主键为什么不是连续的？</h1><p>在 MyISAM 引擎里面，自增值是被写在数据文件上的。而在 InnoDB 中，自增值是被记录在内存的。 MySQL 直到 8.0 版本，才给 InnoDB 表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。</p><p><a href="/attachments/MySQL实战45讲/39讲自增主键为什么不是连续的.pdf" target="_blank">自增主键为什么不是连续的？</a></p><h1 id="insert语句的锁为什么这么多？"><a href="#insert语句的锁为什么这么多？" class="headerlink" title="insert语句的锁为什么这么多？"></a>insert语句的锁为什么这么多？</h1><p>insert … select  是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。<br>而如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。<br>insert  语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁 ) 。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</p><p>读到41</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> 原创 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP 状态图</title>
      <link href="/tcp-state-diagram.html"/>
      <url>/tcp-state-diagram.html</url>
      
        <content type="html"><![CDATA[<!-- > SYN_REVEIVED 的状态，通常被缩写为 SYN_RECV。 --><blockquote><p>SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接</p></blockquote><p><img src="/images/tcp-state-diagram/Tcp_state_diagram.png" alt></p><p>在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端 A 的状态变迁，加粗的虚线是服务端 B 的状态变迁。</p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> TCP </tag>
            
            <tag> IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能优化实战 笔记</title>
      <link href="/linux-performance-optimization-practices-notes.html"/>
      <url>/linux-performance-optimization-practices-notes.html</url>
      
        <content type="html"><![CDATA[<p>Linux性能优化实战 学习笔记<br>作者： 倪朋飞</p><a id="more"></a><h1 id="平均负载"><a href="#平均负载" class="headerlink" title="平均负载"></a>平均负载</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和CPU使用率并没有直接关系。这里我先解释下，可运行状态和不可中断状态这俩词儿。</p><p>所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态（Running或Runnable）的进程。</p><p>不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的I/O响应，也就是我们在ps命令中看到的D状态（Uninterruptible Sleep，也称为 Disk leep）的进程。<br>比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。</p><p>所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。</p><p>获取CPU核数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep &apos;model name&apos; /proc/cpuinfo | wc -l</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：</p><ul><li>平均负载高有可能是CPU密集型进程导致的；</li><li>平均负载高并不一定代表CPU使用率高，还有可能是I/O更繁忙了；</li><li>当发现负载高的时候，你可以使用mpstat、pidstat等工具，辅助分析负载的来源。</li></ul><h1 id="CPU上下文切换"><a href="#CPU上下文切换" class="headerlink" title="CPU上下文切换"></a>CPU上下文切换</h1><p>线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。</p><p>根据 <a href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="noopener">Tsuna</a> 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p><a href="/attachments/Linux性能优化实战/04经常说的CPU上下文切换是什么意思？.pdf" target="_blank">经常说的CPU上下文切换是什么意思？</a></p><h1 id="CPU-使用率"><a href="#CPU-使用率" class="headerlink" title="CPU 使用率"></a>CPU 使用率</h1><p>GDB 并不适合在性能分析的早期应用。</p><p>为什么呢？因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。</p><p>那么哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p><p>使用 perf 分析 CPU 性能问题，我来说两种最常见、也是我最喜欢的用法。<br>第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数，使用界面如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ perf top</span><br><span class="line">Samples: 833 of event &apos;cpu-clock&apos;, Event count (approx.): 97742399</span><br><span class="line">Overhead Shared Object Symbol</span><br><span class="line">7.28% perf [.] 0x00000000001f78a4</span><br><span class="line">4.72% [kernel] [k] vsnprintf</span><br><span class="line">4.32% [kernel] [k] module_get_kallsym</span><br><span class="line">3.65% [kernel] [k] _raw_spin_unlock_irqrestore</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 833 个 CPU 时钟事件，而总事件数则为 97742399。</p><p>另外，采样数需要我们特别注意。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。<br>再往下看是一个表格式样的数据，每一行包含四列，分别是：</p><p>第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。<br>第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。<br>第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。<br>最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。</p><p>还是以上面的输出为例，我们可以看到，占用 CPU 时钟最多的是 perf 工具自身，不过它的比例也只有 7.28%，说明系统并没有 CPU 性能问题。 perf top 的使用你应该很清楚了吧。</p><p>接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ perf record # 按 Ctrl+C 终止采样</span><br><span class="line">[ perf record: Woken up 1 times to write data ]</span><br><span class="line">[ perf record: Captured and wrote 0.452 MB perf.data (6093 samples) ]</span><br><span class="line">$ perf report # 展示类似于 perf top 的报告</span><br></pre></td></tr></table></figure><p>在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。</li><li>系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。</li><li>I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。</li><li>软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。</li></ul><p><font color="DeepPink"><strong>碰到 CPU 使用率升高的问题，你可以借助 top、pidstat 等工具，确认引发 CPU 性能问题的来源；再使用 perf 等工具，排查出引起性能问题的具体函数。</strong></font></p><p><font color="DeepPink"><strong>短时应用的运行时间比较短，很难在 top 或者 ps 这类展示系统概要和进程快照的工具中发现，你需要使用记录事件的工具来配合诊断，比如 execsnoop 或者 perf top。</strong></font></p><h2 id="实践-1"><a href="#实践-1" class="headerlink" title="实践"></a>实践</h2><p><a href="/attachments/Linux性能优化实战/06系统的CPU使用率很高但为啥却找不到高CPU？.pdf" target="_blank">系统的CPU使用率很高但为啥却找不到高CPU？</a></p><h1 id="系统中出现大量不可中断进程和僵尸进程怎么办？"><a href="#系统中出现大量不可中断进程和僵尸进程怎么办？" class="headerlink" title="系统中出现大量不可中断进程和僵尸进程怎么办？"></a>系统中出现大量不可中断进程和僵尸进程怎么办？</h1><h2 id="Top-输出分析"><a href="#Top-输出分析" class="headerlink" title="Top 输出分析"></a>Top 输出分析</h2><p>下面是一个 top 命令输出的示例，S 列（也就是 Status 列）表示进程的状态。从这个示例里，你可以看到<br>R、D、Z、S、I 等几个状态，它们分别是什么意思呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND</span><br><span class="line">28961 root 20 0 43816 3148 4040 R 3.2 0.0 0:00.01 top</span><br><span class="line">620 root 20 0 37280 33676 908 D 0.3 0.4 0:00.01 app</span><br><span class="line">1 root 20 0 160072 9416 6752 S 0.0 0.1 0:37.64 systemd</span><br><span class="line">1896 root 20 0 0 0 0 Z 0.0 0.0 0:00.00 devapp</span><br><span class="line">2 root 20 0 0 0 0 S 0.0 0.0 0:00.10 kthreadd</span><br><span class="line">4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0:0H</span><br><span class="line">6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 mm_percpu_wq</span><br><span class="line">7 root 20 0 0 0 0 S 0.0 0.0 0:06.37 ksoftirqd/0</span><br></pre></td></tr></table></figure><p>我们挨个来看一下：</p><ul><li>R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。</li><li>D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。</li><li>Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。</li><li>S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。</li><li>I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。</li></ul><p>当然了，上面的示例并没有包括进程的所有状态。除了以上 5 个状态，进程还包括下面这2个状态。</p><p>第一个是 T 或者 t，也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。</p><p>向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。</p><p>而当你用调试器（如 gdb）调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实也是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。</p><p>另一个是 X，也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。</p><blockquote><p>僵尸进程，这是多进程应用很容易碰到的问题。正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册SIGCHLD 信号的处理函数，异步回收资源。<br>如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。换句话说，父亲应该一直对儿子负责，善始善终，如果不作为或者跟不上，都会导致“问题少年”的出现。<br>通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。<br>一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。</p></blockquote><blockquote><p>不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 I/O 性能问题。</p></blockquote><h2 id="实践-2"><a href="#实践-2" class="headerlink" title="实践"></a>实践</h2><p>dstat命令 是一个用来替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具，是一个全能系统信息统计工具。与sysstat相比，dstat拥有一个彩色的界面，在手动观察性能状况时，数据比较显眼容易观察；而且dstat支持即时刷新，譬如输入dstat 3即每三秒收集一次，但最新的数据都会每秒刷新显示。和sysstat相同的是，dstat也可以收集指定的性能资源，譬如dstat -c即显示CPU的使用情况。</p><p><a href="/attachments/Linux性能优化实战/08系统中出现大量不可中断进程和僵尸进程怎么办？.pdf" target="_blank">系统中出现大量不可中断进程和僵尸进程怎么办？</a></p><h1 id="怎么理解Linux软中断？"><a href="#怎么理解Linux软中断？" class="headerlink" title="怎么理解Linux软中断？"></a>怎么理解Linux软中断？</h1><p><a href="/attachments/Linux性能优化实战/09怎么理解Linux软中断？.pdf" target="_blank">怎么理解Linux软中断？</a></p><h1 id="如何迅速分析出系统CPU的瓶颈在哪里？"><a href="#如何迅速分析出系统CPU的瓶颈在哪里？" class="headerlink" title="如何迅速分析出系统CPU的瓶颈在哪里？"></a>如何迅速分析出系统CPU的瓶颈在哪里？</h1><p><a href="/attachments/Linux性能优化实战/11如何迅速分析出系统CPU的瓶颈在哪里？.pdf" target="_blank">如何迅速分析出系统CPU的瓶颈在哪里？</a></p><blockquote><p>pidstat 中， %wait 表示进程等待 CPU 的时间百分比。<br>top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。</p></blockquote><h1 id="Linux性能优化答疑"><a href="#Linux性能优化答疑" class="headerlink" title="Linux性能优化答疑"></a>Linux性能优化答疑</h1><p>关注一下：【问题 2：如何用 perf 工具分析 Java 程序】</p><blockquote><p>像是 Java 这种通过 JVM 来运行的应用程序，运行堆栈用的都是 JVM 内置的函数和堆栈管理。所以，从系统层面你只能看到JVM的函数堆栈，而不能直接得到 Java 应用程序的堆栈。<br>perf_events 实际上已经支持了 JIT，但还需要一个 /tmp/perf-PID.map 文件，来进行符号翻译。当然，开源项目  perf-map-agent 可以帮你生成这个符号表。</p></blockquote><p><a href="/attachments/Linux性能优化实战/14Linux性能优化答疑（二）.pdf" target="_blank">Linux性能优化答疑</a></p><h1 id="怎么理解内存中的Buffer和Cache？"><a href="#怎么理解内存中的Buffer和Cache？" class="headerlink" title="怎么理解内存中的Buffer和Cache？"></a>怎么理解内存中的Buffer和Cache？</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 注意不同版本的 free 输出可能会有所不同</span><br><span class="line">$ free</span><br><span class="line">total used free shared buff/cache available</span><br><span class="line">Mem: 8169348 263524 6875352 668 1030472 7611064</span><br><span class="line">Swap: 0 0 0</span><br></pre></td></tr></table></figure><p>这里的大部分指标都比较容易理解，但 Buffer 和 Cache 可能不太好区分。从字面上来说，Buffer 是缓冲区，而 Cache 是缓存，两者都是数据在内存中的临时存储。那么，你知道这两种“临时存储”有什么区别吗？</p><h2 id="free-数据的来源"><a href="#free-数据的来源" class="headerlink" title="free 数据的来源"></a>free 数据的来源</h2><p>Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。<br>Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。</p><h2 id="proc-文件系统"><a href="#proc-文件系统" class="headerlink" title="proc 文件系统"></a>proc 文件系统</h2><p>/proc 是 Linux 内核提供的一种特殊文件系统，是用户跟内核交互的接口。比方说，用户可以从 /proc 中查询内核的运行状态和配置选项，查询进程的运行状态、统计数据等，当然，你也可以通过 /proc 来修改内核的配置。</p><p>proc 文件系统同时也是很多性能工具的最终数据来源。比如我们刚才看到的 free ，就是通过读取 /proc/meminfo ，得到内存的使用情况。</p><p>Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。</p><p>Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。</p><blockquote><p>Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。</p></blockquote><h2 id="磁盘与文件"><a href="#磁盘与文件" class="headerlink" title="磁盘与文件"></a>磁盘与文件</h2><p>磁盘是一个存储设备（确切地说是块设备），可以被划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以再创建文件系统，并挂载到系统的某个目录中。这样，系统就可以通过这个挂载目录，来读写文件。</p><p>换句话说，磁盘是存储数据的块设备，也是文件系统的载体。所以，文件系统确实还是要通过磁盘，来保证数据的持久化存储。</p><p>你在很多地方都会看到这句话， Linux 中一切皆文件。换句话说，你可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）。</p><p>在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而在读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸I/O”。</p><p>这两种读写方式使用的缓存自然不同。文件系统管理的缓存，其实就是 Cache 的一部分。而裸磁盘的缓存，用的正是 Buffer。</p><blockquote><p>cache是针对文件系统的缓存,而 buffers是对磁盘数据的缓存,是直接跟硬件那一层相关的,那一般来说, cache会比 buffers 的数量大了很多。</p></blockquote><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p><a href="/attachments/Linux性能优化实战/17如何利用系统缓存优化程序的运行效率？.pdf" target="_blank">如何利用系统缓存优化程序的运行效率？</a></p><h1 id="为什么系统的Swap变高了？"><a href="#为什么系统的Swap变高了？" class="headerlink" title="为什么系统的Swap变高了？"></a>为什么系统的Swap变高了？</h1><h2 id="NUMA-与-Swap"><a href="#NUMA-与-Swap" class="headerlink" title="NUMA 与 Swap"></a>NUMA 与 Swap</h2><p><a href="/attachments/Linux性能优化实战/19为什么系统的Swap变高了？.pdf" target="_blank">19为什么系统的Swap变高了？</a></p><p>在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。</p><p>当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。</p><h1 id="如何“快准狠”找到系统内存的问题？"><a href="#如何“快准狠”找到系统内存的问题？" class="headerlink" title="如何“快准狠”找到系统内存的问题？"></a>如何“快准狠”找到系统内存的问题？</h1><p>为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如free、top、vmstat、pidstat 等。</p><p>具体的分析思路主要有这几步。</p><ol><li>先用 free 和 top，查看系统整体的内存使用情况。</li><li>再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。</li><li>最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。</li></ol><h2 id="根据指标查找工具"><a href="#根据指标查找工具" class="headerlink" title="根据指标查找工具"></a>根据指标查找工具</h2><p><img src="/images/linux-performance-optimization-practices-notes/tools_memory.png" alt></p><h2 id="根据工具查找指标"><a href="#根据工具查找指标" class="headerlink" title="根据工具查找指标"></a>根据工具查找指标</h2><p><img src="/images/linux-performance-optimization-practices-notes/memory_tools.png" alt></p><h1 id="Linux-磁盘I-O是怎么工作的？"><a href="#Linux-磁盘I-O是怎么工作的？" class="headerlink" title="Linux 磁盘I/O是怎么工作的？"></a>Linux 磁盘I/O是怎么工作的？</h1><h2 id="磁盘性能指标"><a href="#磁盘性能指标" class="headerlink" title="磁盘性能指标"></a>磁盘性能指标</h2><p>说到磁盘性能的衡量标准，必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。</p><ul><li>使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。</li><li>饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。</li><li>IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。</li><li>吞吐量，是指每秒的 I/O 请求大小。</li><li>响应时间，是指 I/O 请求从发出到收到响应的间隔时间。</li></ul><p>这里要注意的是，使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求。</p><p>这些指标，很可能是你经常挂在嘴边的，一讨论磁盘性能必定提起的对象。不过我还是要强调一点，不要孤立地去比较某一指标，而要结合读写比例、I/O 类型（随机还是连续）以及 I/O 的大小，综合来分析。</p><h2 id="磁盘-I-O-观测"><a href="#磁盘-I-O-观测" class="headerlink" title="磁盘 I/O 观测"></a>磁盘 I/O 观测</h2><p><img src="/images/linux-performance-optimization-practices-notes/iostat.png" alt></p><p>这些指标中，你要注意：</p><ul><li>%util ，就是我们前面提到的磁盘 I/O 使用率；</li><li>r/s+ w/s ，就是 IOPS；</li><li>rkB/s+wkB/s ，就是吞吐量；</li><li>r_await+w_await ，就是响应时间。</li></ul><p>在观测指标时，也别忘了结合请求的大小（ rareq-sz 和 wareq-sz）一起分析。</p><h2 id="进程-I-O-观测"><a href="#进程-I-O-观测" class="headerlink" title="进程 I/O 观测"></a>进程 I/O 观测</h2><p>要观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。</p><h2 id="根据指标查找工具-1"><a href="#根据指标查找工具-1" class="headerlink" title="根据指标查找工具"></a>根据指标查找工具</h2><p><img src="/images/linux-performance-optimization-practices-notes/file_disk_io_tool.png" alt></p><h2 id="根据工具查找指标-1"><a href="#根据工具查找指标-1" class="headerlink" title="根据工具查找指标"></a>根据工具查找指标</h2><p><img src="/images/linux-performance-optimization-practices-notes/tool_file_disk_io.png" alt></p><h1 id="关于-Linux-网络，你必须知道这些"><a href="#关于-Linux-网络，你必须知道这些" class="headerlink" title="关于 Linux 网络，你必须知道这些"></a>关于 Linux 网络，你必须知道这些</h1><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>为了解决网络互联中异构设备的兼容性问题，并解耦复杂的网络包处理流程，OSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中：</p><ul><li>应用层，负责为应用程序提供统一的接口。</li><li>表示层，负责把数据转换成兼容接收系统的格式。</li><li>会话层，负责维护计算机之间的通信连接。</li><li>传输层，负责为数据加上传输表头，形成数据包。</li><li>网络层，负责数据的路由和转发。</li><li>数据链路层，负责 MAC 寻址、错误侦测和改错。</li><li>物理层，负责在物理网络中传输数据帧。</li></ul><p>但是 OSI 模型还是太复杂了，也没能提供一个可实现的方法。所以，在 Linux 中，我们实际上使用的是另一个更实用的四层模型，即 TCP/IP 网络模型。</p><p>TCP/IP 模型，把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层，其中：</p><ul><li>应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。</li><li>传输层，负责端到端的通信，比如 TCP、UDP 等。</li><li>网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。</li><li>网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。</li></ul><p><img src="/images/linux-performance-optimization-practices-notes/osi_tcp_ip.png" alt></p><h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h2><p>ifconfig 和 ip 分别属于软件包 net-tools 和 iproute2，iproute2 是 net-tools 的下一代。</p><blockquote><p>我个人更推荐使用 ip 工具，因为它提供了更丰富的功能和更易用的接口。</p></blockquote><p>以网络接口 ens160 为例，你可以运行下面的两个命令，查看它的配置和状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@jiankunking ~]# ip -s addr show dev ens160</span><br><span class="line">2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether 00:50:56:b1:ee:91 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.138.40.223/24 brd 10.138.40.255 scope global noprefixroute ens160</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    RX: bytes  packets  errors  dropped overrun mcast</span><br><span class="line">    105694689249 460305272 0       139334  0       78892</span><br><span class="line">    TX: bytes  packets  errors  dropped carrier collsns</span><br><span class="line">    501968646454 337674507 0       0       0       0</span><br><span class="line">[root@jiankunking ~]# ifconfig ens160</span><br><span class="line">ens160: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 10.138.40.223  netmask 255.255.255.0  broadcast 10.138.40.255</span><br><span class="line">        ether 00:50:56:b1:ee:91  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 460306226  bytes 105694760042 (98.4 GiB)</span><br><span class="line">        RX errors 0  dropped 139334  overruns 0  frame 0</span><br><span class="line">        TX packets 337674596  bytes 501968659316 (467.4 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>你可以看到，ifconfig 和 ip 命令输出的指标基本相同，只是显示格式略微不同。比如，它们都包括了网络接口的状态标志、MTU 大小、IP、子网、MAC 地址以及网络包收发的统计信息。</p><p>这里有几个跟网络性能密切相关的指标，需要你特别关注一下。</p><p>第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。</p><p>第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。</p><p>第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。</p><p>第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：</p><ul><li>errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；</li><li>dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；</li><li>overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；</li><li>carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；</li><li>collisions 表示碰撞数据包数。</li></ul><h2 id="套接字信息"><a href="#套接字信息" class="headerlink" title="套接字信息"></a>套接字信息</h2><p>可以用 netstat 或者 ss ，来查看套接字、网络栈、网络接口以及路由表的信息。</p><p>我个人更推荐，使用 ss 来查询网络的连接信息，因为它比 netstat 提供了更好的性能（速度更快）。</p><p>比如，你可以执行下面的命令，查询套接字信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># head -n 3 表示只显示前面 3 行</span><br><span class="line"># -l 表示只显示监听套接字</span><br><span class="line"># -n 表示显示数字地址和端口 (而不是名字)</span><br><span class="line"># -p 表示显示进程信息</span><br><span class="line">[root@jiankunking ~]# netstat -nlp | head -n 3</span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span><br><span class="line">tcp        0      0 0.0.0.0:18022           0.0.0.0:*               LISTEN      68726/sshd</span><br><span class="line"></span><br><span class="line"># -l 表示只显示监听套接字</span><br><span class="line"># -t 表示只显示 TCP 套接字</span><br><span class="line"># -n 表示显示数字地址和端口 (而不是名字)</span><br><span class="line"># -p 表示显示进程信息</span><br><span class="line">[root@jiankunking ~]# ss -ltnp | head -n 3</span><br><span class="line">State      Recv-Q Send-Q Local Address:Port               Peer Address:Port</span><br><span class="line">LISTEN     0      128          *:18022                    *:*                   users:((&quot;sshd&quot;,pid=68726,fd=3))</span><br><span class="line">LISTEN     0      128          *:111                      *:*                   users:((&quot;rpcbind&quot;,pid=767,fd=8))</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>netstat 和 ss 的输出也是类似的，都展示了套接字的状态、接收队列、发送队列、本地地址、远端地址、进程 PID 和进程名称等。</p><p>其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。</p><p>当套接字处于连接状态（Established）时，</p><ul><li>Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。</li><li>而 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。</li></ul><p>当套接字处于监听状态（Listening）时，</p><ul><li>Recv-Q 表示 syn backlog 的当前值。</li><li>而 Send-Q 表示最大的 syn backlog 值。</li></ul><p>而 syn backlog 是 TCP 协议栈中的半连接队列长度，相应的也有一个全连接队列（accept queue），它们都是维护 TCP 状态的重要机制。</p><p>顾名思义，所谓半连接，就是还没有完成 TCP 三次握手的连接，连接只进行了一半，而服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送SYN+ACK 包。</p><p>而全连接，则是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要再被 accept() 系统调用取走，这样，服务器就可以开始真正处理客户端的请求了。</p><h2 id="协议栈统计信息"><a href="#协议栈统计信息" class="headerlink" title="协议栈统计信息"></a>协议栈统计信息</h2><p>类似的，使用 netstat 或 ss ，也可以查看协议栈的信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">[root@jiankunking ~]# netstat -s</span><br><span class="line">Ip:</span><br><span class="line">    402945296 total packets received</span><br><span class="line">    226103155 forwarded</span><br><span class="line">    0 incoming packets discarded</span><br><span class="line">    176782594 incoming packets delivered</span><br><span class="line">    435480099 requests sent out</span><br><span class="line">    83 dropped because of missing route</span><br><span class="line">    10 fragments dropped after timeout</span><br><span class="line">    76066 reassemblies required</span><br><span class="line">    38028 packets reassembled ok</span><br><span class="line">    10 packet reassembles failed</span><br><span class="line">    38028 fragments received ok</span><br><span class="line">    76056 fragments created</span><br><span class="line">Icmp:</span><br><span class="line">    1556987 ICMP messages received</span><br><span class="line">    188 input ICMP message failed.</span><br><span class="line">    ICMP input histogram:</span><br><span class="line">        destination unreachable: 287</span><br><span class="line">        timeout in transit: 51</span><br><span class="line">        echo requests: 1556516</span><br><span class="line">        echo replies: 128</span><br><span class="line">        timestamp request: 1</span><br><span class="line">        address mask request: 3</span><br><span class="line">    1559315 ICMP messages sent</span><br><span class="line">    0 ICMP messages failed</span><br><span class="line">    ICMP output histogram:</span><br><span class="line">        destination unreachable: 1351</span><br><span class="line">        time exceeded: 9</span><br><span class="line">        echo request: 1477</span><br><span class="line">        echo replies: 1556477</span><br><span class="line">        timestamp replies: 1</span><br><span class="line">IcmpMsg:</span><br><span class="line">        InType0: 128</span><br><span class="line">        InType3: 287</span><br><span class="line">        InType8: 1556516</span><br><span class="line">        InType11: 51</span><br><span class="line">        InType13: 1</span><br><span class="line">        InType17: 3</span><br><span class="line">        InType37: 1</span><br><span class="line">        OutType0: 1556477</span><br><span class="line">        OutType3: 1351</span><br><span class="line">        OutType8: 1477</span><br><span class="line">        OutType11: 9</span><br><span class="line">        OutType14: 1</span><br><span class="line">Tcp:</span><br><span class="line">    139812 active connections openings</span><br><span class="line">    211060 passive connection openings</span><br><span class="line">    100597 failed connection attempts</span><br><span class="line">    62428 connection resets received</span><br><span class="line">    4 connections established</span><br><span class="line">    150899781 segments received</span><br><span class="line">    365986218 segments send out</span><br><span class="line">    10055307 segments retransmited</span><br><span class="line">    563 bad segments received.</span><br><span class="line">    11969603 resets sent</span><br><span class="line">Udp:</span><br><span class="line">    222705 packets received</span><br><span class="line">    1284 packets to unknown port received.</span><br><span class="line">    0 packet receive errors</span><br><span class="line">    144320 packets sent</span><br><span class="line">    0 receive buffer errors</span><br><span class="line">    0 send buffer errors</span><br><span class="line">UdpLite:</span><br><span class="line">TcpExt:</span><br><span class="line">    48 invalid SYN cookies received</span><br><span class="line">    66 resets received for embryonic SYN_RECV sockets</span><br><span class="line">    1 packets pruned from receive queue because of socket buffer overrun</span><br><span class="line">    29246 TCP sockets finished time wait in fast timer</span><br><span class="line">    122 packets rejects in established connections because of timestamp</span><br><span class="line">    244108 delayed acks sent</span><br><span class="line">    478 delayed acks further delayed because of locked socket</span><br><span class="line">    Quick ack mode was activated 72512 times</span><br><span class="line">    3 SYNs to LISTEN sockets dropped</span><br><span class="line">    1298878 packets directly queued to recvmsg prequeue.</span><br><span class="line">    25326935 bytes directly in process context from backlog</span><br><span class="line">    893754064 bytes directly received in process context from prequeue</span><br><span class="line">    21894596 packet headers predicted</span><br><span class="line">    464608 packets header predicted and directly queued to user</span><br><span class="line">    80559045 acknowledgments not containing data payload received</span><br><span class="line">    28273640 predicted acknowledgments</span><br><span class="line">    1683221 times recovered from packet loss by selective acknowledgements</span><br><span class="line">    Detected reordering 8 times using FACK</span><br><span class="line">    Detected reordering 29 times using SACK</span><br><span class="line">    Detected reordering 14 times using time stamp</span><br><span class="line">    7 congestion windows fully recovered without slow start</span><br><span class="line">    14 congestion windows partially recovered using Hoe heuristic</span><br><span class="line">    2422 congestion windows recovered without slow start by DSACK</span><br><span class="line">    26128 congestion windows recovered without slow start after partial ack</span><br><span class="line">    TCPLostRetransmit: 464900</span><br><span class="line">    64529 timeouts after SACK recovery</span><br><span class="line">    19702 timeouts in loss state</span><br><span class="line">    7514677 fast retransmits</span><br><span class="line">    64464 forward retransmits</span><br><span class="line">    1952441 retransmits in slow start</span><br><span class="line">    69482 other TCP timeouts</span><br><span class="line">    TCPLossProbes: 2063407</span><br><span class="line">    TCPLossProbeRecovery: 51490</span><br><span class="line">    285857 SACK retransmits failed</span><br><span class="line">    9 times receiver scheduled too late for direct processing</span><br><span class="line">    33 packets collapsed in receive queue due to low socket buffer</span><br><span class="line">    75591 DSACKs sent for old packets</span><br><span class="line">    2417 DSACKs sent for out of order packets</span><br><span class="line">    51166 DSACKs received</span><br><span class="line">    108 DSACKs for out of order packets received</span><br><span class="line">    818 connections reset due to unexpected data</span><br><span class="line">    2539 connections reset due to early user close</span><br><span class="line">    877 connections aborted due to timeout</span><br><span class="line">    TCPDSACKIgnoredOld: 86</span><br><span class="line">    TCPDSACKIgnoredNoUndo: 29967</span><br><span class="line">    TCPSpuriousRTOs: 18826</span><br><span class="line">    TCPSackShifted: 5442611</span><br><span class="line">    TCPSackMerged: 24407294</span><br><span class="line">    TCPSackShiftFallback: 6093474</span><br><span class="line">    IPReversePathFilter: 19377</span><br><span class="line">    TCPRetransFail: 2</span><br><span class="line">    TCPRcvCoalesce: 6972829</span><br><span class="line">    TCPOFOQueue: 1696509</span><br><span class="line">    TCPOFOMerge: 2507</span><br><span class="line">    TCPChallengeACK: 11895</span><br><span class="line">    TCPSYNChallenge: 583</span><br><span class="line">    TCPSpuriousRtxHostQueues: 85</span><br><span class="line">    TCPAutoCorking: 2372093</span><br><span class="line">    TCPFromZeroWindowAdv: 547</span><br><span class="line">    TCPToZeroWindowAdv: 547</span><br><span class="line">    TCPWantZeroWindowAdv: 15006</span><br><span class="line">    TCPSynRetrans: 3442</span><br><span class="line">    TCPOrigDataSent: 332599913</span><br><span class="line">    TCPHystartTrainDetect: 40604</span><br><span class="line">    TCPHystartTrainCwnd: 718075</span><br><span class="line">    TCPHystartDelayDetect: 162</span><br><span class="line">    TCPHystartDelayCwnd: 5279</span><br><span class="line">    TCPACKSkippedSynRecv: 41</span><br><span class="line">    TCPACKSkippedPAWS: 1</span><br><span class="line">    TCPACKSkippedSeq: 18</span><br><span class="line">    TCPACKSkippedChallenge: 7</span><br><span class="line">IpExt:</span><br><span class="line">    InNoRoutes: 3</span><br><span class="line">    InMcastPkts: 78849</span><br><span class="line">    OutMcastPkts: 129</span><br><span class="line">    InBcastPkts: 24101843</span><br><span class="line">    InOctets: 110759051551</span><br><span class="line">    OutOctets: 566785322634</span><br><span class="line">    InMcastOctets: 14057178</span><br><span class="line">    OutMcastOctets: 14779</span><br><span class="line">    InBcastOctets: 2175831088</span><br><span class="line">    InNoECTPkts: 429510271</span><br><span class="line">    InECT0Pkts: 183432</span><br><span class="line">Sctp:</span><br><span class="line">    0 Current Associations</span><br><span class="line">    0 Active Associations</span><br><span class="line">    0 Passive Associations</span><br><span class="line">    0 Number of Aborteds</span><br><span class="line">    0 Number of Graceful Terminations</span><br><span class="line">    0 Number of Out of Blue packets</span><br><span class="line">    0 Number of Packets with invalid Checksum</span><br><span class="line">    0 Number of control chunks sent</span><br><span class="line">    0 Number of ordered chunks sent</span><br><span class="line">    0 Number of Unordered chunks sent</span><br><span class="line">    0 Number of control chunks received</span><br><span class="line">    0 Number of ordered chunks received</span><br><span class="line">    0 Number of Unordered chunks received</span><br><span class="line">    0 Number of messages fragmented</span><br><span class="line">    0 Number of messages reassembled</span><br><span class="line">    0 Number of SCTP packets sent</span><br><span class="line">    0 Number of SCTP packets received</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]# ss -s</span><br><span class="line">Total: 5091 (kernel 5465)</span><br><span class="line">TCP:   51 (estab 4, closed 24, orphaned 0, synrecv 0, timewait 0/0), ports 0</span><br><span class="line"></span><br><span class="line">Transport Total     IP        IPv6</span><br><span class="line">*         5465      -         -</span><br><span class="line">RAW       0         0         0</span><br><span class="line">UDP       12        9         3</span><br><span class="line">TCP       27        10        17</span><br><span class="line">INET      39        19        20</span><br><span class="line">FRAG      0         0         0</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>这些协议栈的统计信息都很直观。ss 只显示已经连接、关闭、孤儿套接字等简要统计，而netstat 则提供的是更详细的网络协议栈信息。</p><h2 id="网络吞吐和-PPS"><a href="#网络吞吐和-PPS" class="headerlink" title="网络吞吐和 PPS"></a>网络吞吐和 PPS</h2><p>接下来，我们再来看看，如何查看系统当前的网络吞吐量和 PPS。在这里，我推荐使用我们的老朋友 sar，在前面的 CPU、内存和 I/O 模块中，我们已经多次用到它。</p><p>给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 数字 1 表示每隔 1 秒输出一组数据</span><br><span class="line">[root@jiankunking ~]# sar -n DEV 1</span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (hlhtapp36)         01/18/2020      _x86_64_        (4 CPU)</span><br><span class="line"></span><br><span class="line">08:44:18 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">08:44:19 AM br-0e096fe8aab3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth78a4161      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth4d5f845      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth2b3160e      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethf4ce5a2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth2a67a16      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth77ebe8e      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth9eb34b3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethf6f4fec      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth53108ef      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethecb9ea8      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth842d0d1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM    ens160      8.00      0.00      0.55      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure><p>这儿输出的指标比较多，我来简单解释下它们的含义。</p><ul><li>rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。</li><li>rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。</li><li>rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。</li><li>%ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。</li></ul><p>其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。如下你可以看到，我的 ens160 网卡就是一个千兆网卡：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@jiankunking ~]# ethtool ens160 | grep Speed</span><br><span class="line">        Speed: 10000Mb/s</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><h2 id="连通性和延时"><a href="#连通性和延时" class="headerlink" title="连通性和延时"></a>连通性和延时</h2><p>我们通常使用 ping ，来测试远程主机的连通性和延时，而这基于 ICMP 协议。比如，执行下面的命令，你就可以测试本机到 114.114.114.114 这个 IP 地址的连通性和延时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># -c3 表示发送三次 ICMP 包后停止</span><br><span class="line">[root@jiankunking ~]# ping -c3 114.114.114.114</span><br><span class="line">PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data.</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=1 ttl=66 time=17.1 ms</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=2 ttl=69 time=17.0 ms</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=3 ttl=72 time=16.9 ms</span><br><span class="line"></span><br><span class="line">--- 114.114.114.114 ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2002ms</span><br><span class="line">rtt min/avg/max/mdev = 16.919/17.023/17.128/0.173 ms</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>ping 的输出，可以分为两部分。</p><p>第一部分，是每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。<br>第二部分，则是三次 ICMP 请求的汇总。</p><p>比如上面的示例显示，发送了 3 个网络包，并且接收到 3 个响应，没有丢包发生，这说明测试主机到 114.114.114.114 是连通的；平均往返延时（RTT）是 17ms左右，也就是从发送 ICMP 开始，到接收到 114.114.114.114 回复的确认，总共经历 17ms左右。</p><h1 id="C10K-和-C1000K"><a href="#C10K-和-C1000K" class="headerlink" title="C10K 和 C1000K"></a>C10K 和 C1000K</h1><p><a href="/attachments/Linux性能优化实战/35C10K和C1000K回顾.pdf" target="_blank">C10K和C1000K</a></p><h1 id="DNS-解析"><a href="#DNS-解析" class="headerlink" title="DNS 解析"></a>DNS 解析</h1><h2 id="域名与-DNS-解析"><a href="#域名与-DNS-解析" class="headerlink" title="域名与 DNS 解析"></a>域名与 DNS 解析</h2><p>DNS 协议在 TCP/IP 栈中属于应用层，不过实际传输还是基于 UDP 或者 TCP 协议（UDP 居多） ，并且域名服务器一般监听在端口 53 上。</p><p>DNS 服务通过资源记录的方式，来管理所有数据，它支持 A、CNAME、MX、NS、PTR 等多种类型的记录。比如：</p><ul><li>A 记录，用来把域名转换成 IP 地址；</li><li>CNAME 记录，用来创建别名；</li><li>而 NS 记录，则表示该域名对应的域名服务器地址。</li></ul><p>如果没有命中缓存，DNS 查询实际上是一个递归过程，那有没有方法可以知道整个递归查询的执行呢？</p><p>其实除了 nslookup，另外一个常用的 DNS 解析工具 dig ，就提供了 trace 功能，可以展示递归查询的整个过程。比如你可以执行下面的命令，得到查询结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_3_centos ~]# dig +trace +nodnssec jiankunking.com</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; +trace +nodnssec jiankunking.com</span><br><span class="line">;; global options: +cmd</span><br><span class="line">.151746INNSe.root-servers.net.</span><br><span class="line">.151746INNSf.root-servers.net.</span><br><span class="line">.151746INNSg.root-servers.net.</span><br><span class="line">.151746INNSh.root-servers.net.</span><br><span class="line">.151746INNSi.root-servers.net.</span><br><span class="line">.151746INNSj.root-servers.net.</span><br><span class="line">.151746INNSk.root-servers.net.</span><br><span class="line">.151746INNSl.root-servers.net.</span><br><span class="line">.151746INNSm.root-servers.net.</span><br><span class="line">.151746INNSa.root-servers.net.</span><br><span class="line">.151746INNSb.root-servers.net.</span><br><span class="line">.151746INNSc.root-servers.net.</span><br><span class="line">.151746INNSd.root-servers.net.</span><br><span class="line">;; Received 239 bytes from 183.60.83.19#53(183.60.83.19) in 0 ms</span><br><span class="line"></span><br><span class="line">com.172800INNSa.gtld-servers.net.</span><br><span class="line">com.172800INNSb.gtld-servers.net.</span><br><span class="line">com.172800INNSc.gtld-servers.net.</span><br><span class="line">com.172800INNSd.gtld-servers.net.</span><br><span class="line">com.172800INNSe.gtld-servers.net.</span><br><span class="line">com.172800INNSf.gtld-servers.net.</span><br><span class="line">com.172800INNSg.gtld-servers.net.</span><br><span class="line">com.172800INNSh.gtld-servers.net.</span><br><span class="line">com.172800INNSi.gtld-servers.net.</span><br><span class="line">com.172800INNSj.gtld-servers.net.</span><br><span class="line">com.172800INNSk.gtld-servers.net.</span><br><span class="line">com.172800INNSl.gtld-servers.net.</span><br><span class="line">com.172800INNSm.gtld-servers.net.</span><br><span class="line">;; Received 840 bytes from 199.7.91.13#53(d.root-servers.net) in 236 ms</span><br><span class="line"></span><br><span class="line">jiankunking.com.172800INNSf1g1ns1.dnspod.net.</span><br><span class="line">jiankunking.com.172800INNSf1g1ns2.dnspod.net.</span><br><span class="line">;; Received 98 bytes from 192.52.178.30#53(k.gtld-servers.net) in 200 ms</span><br><span class="line"></span><br><span class="line">jiankunking.com.600INA139.199.31.69</span><br><span class="line">jiankunking.com.86400INNSf1g1ns1.dnspod.net.</span><br><span class="line">jiankunking.com.86400INNSf1g1ns2.dnspod.net.</span><br><span class="line">;; Received 124 bytes from 58.247.212.48#53(f1g1ns2.dnspod.net) in 21 ms</span><br><span class="line"></span><br><span class="line">[root@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>dig trace 的输出，主要包括四部分:<br>第一部分，是从 183.60.83.19 查到的一些根域名服务器（.）的 NS 记录。<br>第二部分，是从 NS 记录结果中选一个（d.root-servers.net），并查询顶级域名 com.的 NS 记录。<br>第三部分，是从 com. 的 NS 记录中选择一个（k.gtld-servers.net），并查询二级域名 jiankunking.com. 的 NS 服务器。<br>最后一部分，就是从 jiankunking.com. 的 NS 服务器（f1g1ns2.dnspod.net）查询最终主机 jiankunking.com. 的 A 记录。</p><p>当然，不仅仅是发布到互联网的服务需要域名，很多时候，我们也希望能对局域网内部的主机进行域名解析（即内网域名，大多数情况下为主机名）。Linux 也支持这种行为。<br>所以，你可以把主机名和 IP 地址的映射关系，写入本机的 /etc/hosts 文件中。这样，指定的主机名就可以在<strong>本地直接</strong>找到目标 IP。</p><p>或者，你还可以在内网中，搭建自定义的 DNS 服务器，专门用来解析内网中的域名。而内网 DNS 服务器，一般还会设置一个或多个上游 DNS 服务器，用来解析外网的域名。</p><h1 id="使用-tcpdump-和-Wireshark-分析网络流量"><a href="#使用-tcpdump-和-Wireshark-分析网络流量" class="headerlink" title="使用 tcpdump 和 Wireshark 分析网络流量"></a>使用 tcpdump 和 Wireshark 分析网络流量</h1><h2 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h2><p><img src="/images/linux-performance-optimization-practices-notes/tcpdump1.png" alt><br><img src="/images/linux-performance-optimization-practices-notes/tcpdump2.png" alt></p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p><a href="/attachments/Linux性能优化实战/38怎么使用tcpdump和Wireshark分析网络流量.pdf" target="_blank">怎么使用tcpdump和Wireshark分析网络流量？</a></p><blockquote><p>实际上，<font color="DeepPink"><strong>根据 IP 地址反查域名、根据端口号反查协议名称，是很多网络工具默认的行为，而这往往会导致性能工具的工作缓慢。</strong></font>所以，通常，网络性能工具都会提供一个选项（比如 -n 或者 -nn），来禁止名称解析。</p></blockquote><h1 id="NAT-原理"><a href="#NAT-原理" class="headerlink" title="NAT 原理"></a>NAT 原理</h1><p>NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。</p><p>NAT 的主要目的，是实现地址转换。根据实现方式的不同，NAT 可以分为三类：</p><ul><li>静态 NAT，即内网 IP 与公网 IP 是一对一的永久映射关系；</li><li>动态 NAT，即内网 IP 从公网 IP 池中，动态选择一个进行映射；</li><li>网络地址端口转换 NAPT（Network Address and Port Translation），即把内网 IP 映射到公网 IP 的不同端口上，让多个内网 IP 可以共享同一个公网 IP 地址。</li></ul><p>NAPT 是目前最流行的 NAT 类型，我们在 Linux 中配置的 NAT 也是这种类型。而根据转换方式的不同，我们又可以把 NAPT 分为三类。</p><p>第一类是源地址转换 SNAT，即目的地址不变，只替换源 IP 或源端口。SNAT 主要用于，多个内网 IP 共享同一个公网 IP ，来访问外网资源的场景。</p><p>第二类是目的地址转换 DNAT，即源 IP 保持不变，只替换目的 IP 或者目的端口。DNAT主要通过公网 IP 的不同端口号，来访问内网的多种服务，同时会隐藏后端服务器的真实IP 地址。</p><p>第三类是双向地址转换，即同时使用 SNAT 和 DNAT。当接收到网络包时，执行DNAT，把目的 IP 转换为内网 IP；而在发送网络包时，执行 SNAT，把源 IP 替换为外部IP。</p><p>双向地址转换，其实就是外网 IP 与内网 IP 的一对一映射关系，所以常用在虚拟化环境中，为虚拟机分配浮动的公网 IP 地址。</p><h1 id="网络性能优化的几个思路"><a href="#网络性能优化的几个思路" class="headerlink" title="网络性能优化的几个思路"></a>网络性能优化的几个思路</h1><h2 id="根据指标查找工具-2"><a href="#根据指标查找工具-2" class="headerlink" title="根据指标查找工具"></a>根据指标查找工具</h2><p><img src="/images/linux-performance-optimization-practices-notes/network_tools1.png" alt></p><h2 id="根据工具查找指标-2"><a href="#根据工具查找指标-2" class="headerlink" title="根据工具查找指标"></a>根据工具查找指标</h2><p><img src="/images/linux-performance-optimization-practices-notes/network_tools2.png" alt></p><h2 id="实践-3"><a href="#实践-3" class="headerlink" title="实践"></a>实践</h2><p><a href="/attachments/Linux性能优化实战/43网络性能优化的几个思路（上）.pdf" target="_blank">网络性能优化的几个思路（上）</a></p><p><a href="/attachments/Linux性能优化实战/44网络性能优化的几个思路（下）.pdf" target="_blank">网络性能优化的几个思路（下）</a></p><h1 id="服务器总是时不时丢包，我该怎么办？"><a href="#服务器总是时不时丢包，我该怎么办？" class="headerlink" title="服务器总是时不时丢包，我该怎么办？"></a>服务器总是时不时丢包，我该怎么办？</h1><p><a href="/attachments/Linux性能优化实战/47服务器总是时不时丢包，我该怎么办？（上）.pdf" target="_blank">服务器总是时不时丢包，我该怎么办？（上）</a></p><p><a href="/attachments/Linux性能优化实战/48服务器总是时不时丢包，我该怎么办？（下）.pdf" target="_blank">服务器总是时不时丢包，我该怎么办？（下）</a></p><h1 id="内核线程-CPU-利用率太高，我该怎么办？"><a href="#内核线程-CPU-利用率太高，我该怎么办？" class="headerlink" title="内核线程 CPU 利用率太高，我该怎么办？"></a>内核线程 CPU 利用率太高，我该怎么办？</h1><p><a href="/attachments/Linux性能优化实战/49内核线程CPU利用率太高，我该怎么办？.pdf" target="_blank">内核线程CPU利用率太高，我该怎么办？</a></p><h1 id="动态追踪怎么用？"><a href="#动态追踪怎么用？" class="headerlink" title="动态追踪怎么用？"></a>动态追踪怎么用？</h1><p><a href="/attachments/Linux性能优化实战/50动态追踪怎么用？（上）.pdf" target="_blank">动态追踪怎么用？（上）</a></p><p><a href="/attachments/Linux性能优化实战/51动态追踪怎么用？（下）.pdf" target="_blank">动态追踪怎么用？（下）</a></p><h1 id="服务吞吐量下降很厉害，怎么分析？"><a href="#服务吞吐量下降很厉害，怎么分析？" class="headerlink" title="服务吞吐量下降很厉害，怎么分析？"></a>服务吞吐量下降很厉害，怎么分析？</h1><p><a href="/attachments/Linux性能优化实战/52服务吞吐量下降很厉害，怎么分析？.pdf" target="_blank">服务吞吐量下降很厉害，怎么分析？</a></p><blockquote><p>注意套接字部分的排查，netstat -s | grep socket<br>套接字丢包?  套接字队列溢出?</p></blockquote><h1 id="排查问题注意的指标"><a href="#排查问题注意的指标" class="headerlink" title="排查问题注意的指标"></a>排查问题注意的指标</h1><p><img src="/images/linux-performance-optimization-practices-notes/%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87%E5%88%86%E7%B1%BB.png" alt></p><blockquote><p>注意网络部分</p></blockquote><h1 id="分析性能问题的一般步骤"><a href="#分析性能问题的一般步骤" class="headerlink" title="分析性能问题的一般步骤"></a>分析性能问题的一般步骤</h1><p><a href="/attachments/Linux性能优化实战/55分析性能问题的一般步骤.pdf" target="_blank">分析性能问题的一般步骤</a></p><p><a href="/attachments/Linux性能优化实战/56优化性能问题的一般方法.pdf" target="_blank">优化性能问题的一般方法</a></p><p><a href="/attachments/Linux性能优化实战/57Linux性能工具速查.pdf" target="_blank">Linux 性能工具速查</a></p><h1 id="书籍推荐"><a href="#书籍推荐" class="headerlink" title="书籍推荐"></a>书籍推荐</h1><p><a href="/attachments/Linux性能优化实战/书籍推荐1" target="_blank">书籍推荐1</a></p><p><a href="/attachments/Linux性能优化实战/书籍推荐2.pdf" target="_blank">书籍推荐2</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> 原创 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法之美：排序部分</title>
      <link href="/time-geekbang-sort-algorithm-recommend.html"/>
      <url>/time-geekbang-sort-algorithm-recommend.html</url>
      
        <content type="html"><![CDATA[<p>在线：</p><p><a href="/attachments/数据结构与算法之美/11讲排序（上）：为什么插入排序比冒泡排序更受欢迎.pdf" target="_blank">为什么插入排序比冒泡排序更受欢迎</a></p><p><a href="/attachments/数据结构与算法之美/12讲排序（下）：如何用快排思想在O(n)内查找第K大元素.pdf" target="_blank">如何用快排思想在O(n)内查找第K大元素</a></p><p><a href="/attachments/数据结构与算法之美/13讲线性排序：如何根据年龄给100万用户数据排序.pdf" target="_blank">如何根据年龄给100万用户数据排序</a></p><p><a href="/attachments/数据结构与算法之美/14讲排序优化：如何实现一个通用的、高性能的排序函数.pdf" target="_blank">如何实现一个通用的、高性能的排序函数</a></p><blockquote><p>以上PDF整理自网络</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> Sort </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2的幂表</title>
      <link href="/2-power-table.html"/>
      <url>/2-power-table.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>2的指数字节转与MB、GB换算关系</p></blockquote><a id="more"></a><table><thead><tr><th>2的幂</th><th>准确值（X）</th><th>近似值</th><th>X字节转换成MB、GB等</th></tr></thead><tbody><tr><td>7</td><td>128</td><td></td><td></td></tr><tr><td>8</td><td>256</td><td></td><td></td></tr><tr><td>10</td><td>1 024</td><td>一千</td><td>1K</td></tr><tr><td>16</td><td>65 536</td><td></td><td>64K</td></tr><tr><td>20</td><td>1 048 576</td><td>一百万</td><td>1MB</td></tr><tr><td>30</td><td>1 073 741 824</td><td>十亿</td><td>1GB</td></tr><tr><td>32</td><td>4 294 967 296</td><td></td><td>4GB</td></tr><tr><td>40</td><td>1 099 511 627 776</td><td>一万亿（trillion）</td><td>1TB</td></tr></tbody></table><p>这张表可以拿来做速算。例如，一个将每个32位整数映射成布尔值的向量表可以在一台普通计算机内存中放下。那样的整数有2^<sup>32</sup>个。因为每个整数只占位向量表中的一位，共需要2<sup>32</sup>位（或者2<sup>29</sup> 字节）来存储该映射表，大约是千兆字节的一半，普通机器很容易满足。</p><p><a href="https://www.jiankunking.com/unit-conversion.html" target="_blank" rel="noopener">计算机存储单位换算</a></p>]]></content>
      
      
      <categories>
          
          <category> Interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Performance </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 伪共享</title>
      <link href="/java-false-sharing.html"/>
      <url>/java-false-sharing.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Java False Sharing</p></blockquote><a id="more"></a><h1 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h1><p>先看一下wiki中对于伪共享的解释：</p><blockquote><p>In computer science, false sharing is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that will never be altered by another party, but those data share a cache block with data that are altered, the caching protocol may force the first participant to reload the whole unit despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource.</p></blockquote><blockquote><p>By far the most common usage of this term is in modern multiprocessor CPU caches, where memory is cached in lines of some small power of two word size (e.g., 64 aligned, contiguous bytes). If two processors operate on independent data in the same memory address region storable in a single line, the cache coherency mechanisms in the system may force the whole line across the bus or interconnect with every data write, forcing memory stalls in addition to wasting system bandwidth. False sharing is an inherent artifact of automatically synchronized cache protocols and can also exist in environments such as distributed file systems or databases, but current prevalence is limited to RAM caches.</p></blockquote><p>在计算机科学中，错误共享是会导致性能下降，它可能出现在使用由缓存机制管理的分布式、一致的缓存的系统中，系统中最小粒度是一个缓存块。当系统参与者试图周期性地访问部分数据，这部分数据只会被自己修改，但是这些数据可能与别的数据存储在同一个缓存块，当别的数据被修改的时候，缓存协议可能会强制第一个参与者重新加载整个单元，尽管缺乏逻辑上的必要性。</p><p>到目前为止，该术语最常见的用法是在现代多处理器CPU高速缓存中，在该高速缓存中，内存以两个字长（例如64个对齐的连续字节）的行高速缓存。如果两个处理器在同一内存地址区域中的独立数据上操作，而该内存地址区域可存储在一行中，则系统中的缓存一致性机制可能会强制每次数据写入都通过总线刷新整个行，除了浪费系统带宽外，还会导致内存暂停。错误共享是自动同步的缓存协议的固有产物，也可以存在于诸如分布式文件系统或数据库之类的环境中，但是当前的流行仅限于RAM缓存。</p><p><font color="DeepPink"><strong>多份数据共同存储于一个缓存行（缓存的最小单位），当其中一份数据发生更改的时候，内存系统强制更新整个缓存行。这么做的目的就是避免内存中同一地址的数据在不同缓存中的副本出现不一致。</strong></font></p><p>更多信息可以参见：<a href="https://www.jiankunking.com/the-garbage-collection-handbook-the-art-of-automatic-memory-management-note.html" target="_blank" rel="noopener">《垃圾回收算法手册：自动内存管理的艺术 笔记》中的 【高速缓存一致性】</a></p><h1 id="Java中的伪共享"><a href="#Java中的伪共享" class="headerlink" title="Java中的伪共享"></a>Java中的伪共享</h1><p>Hotspot为了优化内存占用会将字段自由地重新安排，以满足对齐要求，从而使间隙更小。也正是这种优化，导致出现了在同一缓存行上，有可能有多个数据，从而导致伪共享。</p><blockquote><p>伪共享说的是缓存，而缓存的目的就是加快读取速度，也就意味了被缓存的数据不应该频繁更改。<br>换个角度考虑伪共享就是硬件层面高速缓存的失效，导致性能的下降。</p></blockquote><p>以下图为例，当不同处理器上的线程修改驻留在同一高速缓存行上的变量时，会发生错误共享。这将使高速缓存行失效，并强制进行内存更新以保持高速缓存的一致性。</p><p><img src="/images/java-false-sharing/5-4-figure-1.gif" alt></p><h1 id="Java中的解决方案"><a href="#Java中的解决方案" class="headerlink" title="Java中的解决方案"></a>Java中的解决方案</h1><p>使用@Contended注解，<font color="DeepPink"><strong>使用该注解，我们可以将热的频繁写入的共享字段与其他主要为只读或冷的字段隔离开来。</strong></font>简单的规则是读共享很便宜，写共享很昂贵。我们还可以将经常由同一线程同时写入的字段打包。</p><p>更一般地说，我们试图影响相关字段的位置，以最小化一致性缺失。在一个简单的单线程环境中，在时间上紧密地一起访问的字段应该放在相邻的空间，以促进缓存局部性。也就是说，时间局部性应该制约空间局部性。在时间上一起访问的字段应该在空间上相邻。也就是说，当线程同时访问我们的字段时，我们必须小心避免错误共享和一致性通信的过度失效。因此，我们试图集群或以其他方式隔离在同一线程上大约在同一时间写入相同缓存行的字段。请注意，这里有一个竞争的因素：如果我们过于努力地将单线程容量丢失最小化，那么我们最终可能会在并行环境中运行过多的一致性丢失。在本机C/C++代码中，程序员通常使用通知并发的结构布局。@Contended应该在Java中提供相同的功能，尽管在本地代码中，字段与偏移量的绑定在编译时发生，而在Java的加载时发生。值得指出的是，在一般情况下，对于单线程和多线程环境都没有单一的最佳布局。而理想的布局问题本身就是<a href="https://en.wikipedia.org/wiki/NP-hardness" target="_blank" rel="noopener">NP-hard</a>。</p><p>理想情况下，JVM将使用硬件监控设施来检测共享行为并动态更改布局。这有点困难，因为我们还没有合适的方式来向JVM提供高效和方便的信息。提示：我们需要取消OS和hypervisor的中间层。另一个挑战是，在不安全的设施中使用原始字段偏移，因此我们需要解决这个问题，可能需要额外的间接级别。</p><p>最后，我也希望能够将最终字段打包在一起，因为这些字段是只读的。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p><font color="DeepPink"><strong>伪共享本质是就是在缓存中最小的颗粒度仍然大于某个对象的属性的内存占用，导致该缓存最小单元中存储了多个不相关的对象属性，多个不相关属性的（各自）修改会导致缓存状态的频繁变化。由于硬件一般支持高速缓存一致性协议，缓存状态的变化会导致多核CPU频繁更新缓存状态，导致性能下降。</strong></font></p><p>图片来自：<br><a href="https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads</a></p><p>参考资料：<br><a href="https://en.wikipedia.org/wiki/False_sharing" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/False_sharing</a><br><a href="http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html</a><br><a href="https://blogs.oracle.com/dave/java-contended-annotation-to-help-reduce-false-sharing" target="_blank" rel="noopener">https://blogs.oracle.com/dave/java-contended-annotation-to-help-reduce-false-sharing</a></p><p>拓展阅读：<br><a href="https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads</a><br><a href="https://software.intel.com/en-us/articles/intel-guide-for-developing-multithreaded-applications" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/intel-guide-for-developing-multithreaded-applications</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> Sharing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes权威指南：从Docker到Kubernetes实践全接触 笔记</title>
      <link href="/kubernetes-authoritative-guide-node.html"/>
      <url>/kubernetes-authoritative-guide-node.html</url>
      
        <content type="html"><![CDATA[<p>Kubernetes权威指南：从Docker到Kubernetes实践全接触（第2版)<br>作者： 龚正 吴治辉 王伟 崔秀龙 闫健勇 崔晓宁 刘晓红 </p><a id="more"></a><h1 id="Kubernetes-入门"><a href="#Kubernetes-入门" class="headerlink" title="Kubernetes 入门"></a>Kubernetes 入门</h1><h2 id="Kubernetes-是什么"><a href="#Kubernetes-是什么" class="headerlink" title="Kubernetes 是什么"></a>Kubernetes 是什么</h2><p>在Kubernetes中, Service(服务)是分布式集群架构的核心,一个Service对象拥有如下关键特征。</p><ul><li>拥有一个唯一指定的名字(比如mysql-server)</li><li>拥有一个虚拟IP(Cluster、 Service IP或VIP)和端口号。</li><li>能够提供某种远程服务能力。</li><li>被映射到了提供这种服务能力的一组容器应用上</li></ul><p>Service的服务进程目前都基于Socket通信方式对外提供服务,比如Redis、Memcache、MySQL、Web Server,或者是实现了某个具体业务的一个特定的TCP Server进程。虽然一个Service通常由多个相关的服务进程来提供服务,每个服务进程都有一个独立的 Endpoint(IP+Port)访问点,但Kubernetes能够让我们通过Service(虚拟Cluster IP+Service Port)连接到指定的Service上。有了 Kubernetes内建的透明负载均衡和故障恢复机制,不管后端有多少服务进程,也不管某个服务进程是否会由于发生故障而重新部署到其他机器,都不会影响到我们对服务的正常调用。更重要的是这个Service本身一旦创建就不再变化,这意味着,在Kubernetes集群中,我们再也不用为了服务的IP地址变来变去的问题而头疼了</p><p>在通常情况下,Cluster IP是在Service创建后由Kubernetes系统自动分配的,其他Pod无法预先知道某个 Service的Cluster IP地址,因此需要一个服务发现机制来找到这个服务。为此,最初的时候, Kubernetes巧妙地使用了 Linux环境变量(Environment Variable)来解决这个问题,后面会详细说明其机制。现在我们只需知道,根据 Service的唯一名字,容器可以从环境变量中获取到Service对应的Cluster IP地址和端口,从而发起TCP/IP连接请求了。</p><h2 id="Kubernetes-基本概念与术语"><a href="#Kubernetes-基本概念与术语" class="headerlink" title="Kubernetes 基本概念与术语"></a>Kubernetes 基本概念与术语</h2><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>Kubernetes里的Master指的是集群控制节点,每个Kubernetes集群里需要有一个Master节点来负责整个集群的管理和控制,基本上Kubernetes所有的控制命令都是发给它,它来负责具体的执行过程,我们后面所有执行的命令基本都是在Master节点上运行的。Master节点通常会占据一个独立的X86服务器(或者一个虚拟机),一个主要的原因是它太重要了,它是整个集群的“首脑”,如果它宕机或者不可用,那么我们所有的控制命令都将失效。</p><p>Master节点上运行着以下一组关键进程。</p><ul><li>Kubernetes API Server(kube-apipserver),提供了HTTP Rest接口的关键服务进程,是Kubernetes里所有资源的增、删、改、查等操作的唯一入口,也是集群控制的入口进程。</li><li>Kubernetes Controller Manager(kube-controller-manager), Kubernetes里所有资源对象的自动化控制中心,可以理解为资源对象的“大总管”。</li><li>Kubernetes Scheduler(kube-scheduler),负责资源调度(Pod调度)的进程,相当于公交公司的“调度室”。</li></ul><p>其实Master节点上往往还启动了一个etcd Server进程,因为Kubernetes里的所有资源对象的数据全部是保存在etcd中的。</p><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>除了Master, Kubernetes集群中的其他机器被称为Node节点,在较早的版本中也被称为Minion。与Master一样,Node节点可以是一台物理主机,也可以是一台虚拟机。Node节点才是Kubernetes集群中的工作负载节点,每个Node都会被Master分配一些工作负载(Docker容器),当某个Node宕机时,其上的工作负载会被Master自动转移到其他节点上去。</p><p>每个Node节点上都运行着以下一组关键进程。</p><ul><li>kubelet:负责Pod对应的容器的创建、启停等任务,同时与Master节点密切协作,实现集群管理的基本功能。</li><li>kube-proxy:实现Kubernetes service的通信与负载均衡机制的重要组件。</li><li>Docker Engine(docker): Docker引擎,负责本机的容器创建和管理工作。</li></ul><p>Node节点可以在运行期间动态增加到Kubernetes集群中,前提是这个节点上已经正确安装、配置和启动了上述关键进程,在默认情况下kubelet会向Master注册自己,这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范围,kubelet进程就会定时向 Master节点汇报自身的情报,例如操作系统、Docker版本、机器的CPU和内存情况,以及之前有哪些Pod在运行等,这样 Master可以获知每个Node的资源使用情况,并实现高效均衡的资源调度策略。而某个Node超过指定时间不上报信息时,会被 Master判定为“失联”,Noe的状态被标记为不可用(Not Ready),随后 Master会触发“工作负载大转移”的自动流程。</p><h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><p>Pod是Kubernetes的最重要也最基本的概念,如图1.6所示是Pod的组成示意图,我们看到每个Pod都有一个特殊的被称为“根容器”的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分,除了Pause容器,每个Pod还包含一个或多个紧密相关的用户业务容器。<br><img src="/images/kubernetes-authoritative-guide-node/1.6Pod%E7%9A%84%E7%BB%84%E6%88%90%E4%B8%8E%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt></p><p>为什么Kubernetes会设计出一个全新的Pod的概念并且Pod有这样特殊的组成结构?</p><p>原因之一:在一组容器作为一个单元的情况下,我们难以对“整体”简单地进行判断及有效地进行行动。比如,一个容器死亡了,此时算是整体死亡么?是N/M的死亡率么?引入业务无关并且不易死亡的Pause容器作为Pod的根容器,以它的状态代表整个容器组的状态,就简单、巧妙地解决了这个难题。</p><p>原因之二:Pod里的多个业务容器共享Pause容器的IP,共享Pause容器挂接的Volume,这样既简化了密切关联的业务容器之间的通信问题,也很好地解决了它们之间的文件共享问题。</p><p>Kubernetes为每个Pod都分配了唯一的IP地址,称之为Pod IP,一个Pod里的多个容器共享Pod IP地址。<font color="DeepPink"><strong>Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信,这通常采用虚拟二层网络技术来实现</strong></font>,例如Flannel、Openvswitch等,因此我们需要牢记一点:在Kubernetes里,一个Pod里的容器与另外主机上的Pod容器能够直接通信。</p><p>Pod其实有两种类型:普通的Pod及静态Pod(static Pod),后者比较特殊,它并不存放在Kubernetes的etcd存储里,而是存放在某个具体的Node上的一个具体文件中,并且只在此Node上启动运行。而普通的Pod一旦被创建,就会被放入到etcd中存储,随后会被Kubernetes master调度到某个具体的Node上并进行绑定(Binding),随后该Pod被对应的Node上的kubelet进程实例化成一组相关的 Docker容器并启动起来。在默认情况下,当Pod里的某个容器停止时Kubernetes会自动检测到这个问题并且重新启动这个Pod(重启Pod里的所有容器),如果Pod所在的Node宕机,则会将这个Node上的所有Pod重新调度到其他节点上。</p><p>每个Pod都可以对其能使用的服务器上的计算资源设置限额,当前可以设置限额的计算资源有CPU与 Memory两种,其中CPU的资源单位为CPU(Core)的数量,是一个绝对值而非相对值。</p><p>一个CPU的配额对于绝大多数容器来说是相当大的一个资源配额了,所以,在Kubernetes里,通常以千分之一的CPU配额为最小单位,用m来表示。通常一个容器的CPU配额被定义为100~300m,即占用0.1~0.3个CPU。由于CPU配额是一个绝对值,所以无论在拥有一个Core的机器上,还是在拥有48个Core的机器上,100m这个配额所代表的CPU的使用量都是样的。与CPU配额类似,Memory配额也是一个绝对值,它的单位是内存字节数。</p><p>在Kubernetes里,一个计算资源进行配额限定需要设定以下两个参数：</p><ul><li>Requests:该资源的最小申请量,系统必须满足要求。</li><li>Limits:该资源最大允许使用的量,不能被突破,当容器试图使用超过这个量的资源时可能会被Kubernetes kill并重启。</li></ul><p>通常我们会把Request设置为一个比较小的数值,符合容器平时的工作负载情况下的资源需求,而把 Limit设置为峰值负载情况下资源占用的最大量。</p><h3 id="Label-标签"><a href="#Label-标签" class="headerlink" title="Label(标签)"></a>Label(标签)</h3><p>Label是Kubernetes系统中另外一个核心概念。一个Label是一个key=value的键值对,其中key与 value由用户自己指定。 Label可以附加到各种资源对象上,例如Node、Pod、Service、RC等,一个资源对象可以定义任意数量的Label,同一个Label也可以被添加到任意数量的资源对象上去,Label通常在资源对象定义时确定,也可以在对象创建后动态添加或者删除。</p><p>我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能,以便于灵活、方便地进行资源分配、调度、配置、部署等管理工作。例如:部署不同版本的应用到不同的环境中;或者监控和分析应用(日志记录、监控、告警)等。一些常用的Label示例如下。</p><ul><li>版本标签:”release”:”stable”,”release”:”canary</li><li>环境标签:”environment”:”dev”,”environment”:”qa”,”environment”:”production”</li><li>架构标签:”tier”:”frontend”,”tier”:”backend”,”tier”:”middleware”</li><li>质量管控标签:”rack”:”daily”,”rack”:”week”</li></ul><p>Label相当于我们熟悉的“标签”,给某个资源对象定义一个Label,就相当于给它打了一个标签,随后可以通过Label Selector(标签选择器)查询和筛选拥有某些 Label的资源对象,Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制Label Selector可以被类比为SQL语句中的where查询条件,例如,name=redis-slave这个Label selector作用于Pod时,可以被类比为’select* from pod where pods name= redis-slave’这样的语句。当前有两种Label Selector的表达式:基于等式的(Equality-based)和基于集合的(Set-based),前者采用“等式类”的表达式匹配标签,下面是一些具体的例子。</p><ul><li>name=redis-slave:匹配所有具有标签name=redis-slave的资源对象。</li><li>env!= production:匹配所有不具有标签env= production的资源对象,比如env=test就是满足此条件的标签之一。</li></ul><p>而后者则使用集合操作的表达式匹配标签,下面是一些具体的例子。</p><ul><li>name in(redis-master, redis-save):匹配所有具有标签name=redis-master或者name=redis-slave的资源对象。</li><li>name not in(php-frontend):匹配所有不具有标签name=php-frontend的资源对象。</li></ul><p>可以通过多个Label Selector表达式的组合实现复杂的条件选择,多个表达式之间用”,”进行分隔即可,几个条件之间是“AND”的关系,即同时满足多个条件,比如下面的例子:</p><ul><li>name=redis-slave, env!=production</li><li>name not in (php-frontend), env!=production</li></ul><p>Label Selector在Kubernetes中的重要使用场景有以下几处。</p><ul><li><font color="DeepPink"><strong>kube-controller进程通过资源对象RC上定义的Label Selector来筛选要监控的Pod副本的数量,从而实现Pod副本的数量始终符合预期设定的全自动控制流程。</strong></font></li><li><font color="DeepPink"><strong>kube-proxy进程通过Service的Label selector来选择对应的Pod,自动建立起每个Service到对应Pod的请求转发路由表,从而实现 Service的智能负载均衡机制。</strong></font></li><li><font color="DeepPink"><strong>通过对某些Node定义特定的Label,并且在Pod定义文件中使用NodeSelector这种标签调度策略,kube-scheduler进程可以实现Pod“定向调度”的特性。</strong></font></li></ul><h3 id="Replication-Controller-RC"><a href="#Replication-Controller-RC" class="headerlink" title="Replication Controller (RC)"></a>Replication Controller (RC)</h3><p>RC是Kubernetes系统中的核心概念之一,简单来说,它其实是定义了一个期望的场景,即声明某种Pod的副本数量在任意时刻都符合某个预期值,所以RC的定义包括如下几个部分。</p><ul><li>Pod期待的副本数(replicas)。</li><li>用于筛选目标Pod的Label Selector</li><li>当Pod的副本数量小于预期数量的时候,用于创建新Pod的Pod模板(template)。</li></ul><p>当我们定义了一个RC并提交到Kubernetes集群中以后, Master节点上的Controller Manager组件就得到通知,定期巡检系统中当前存活的目标Pod,并确保目标Pod实例的数量刚好等于此RC的期望值,如果有过多的Pod副本在运行,系统就会停掉一些Pod,否则系统就会再自动创建一些Pod。可以说,通过RC,Kubernetes实现了用户应用集群的高可用性,并且大大减少了系统管理员在传统T环境中需要完成的许多手工运维工作(如主机监控脚本、应用监控脚本、故障恢复脚本等）。</p><p>Replica Set与Deployment这两个重要资源对象逐步替换了之前的RC的作用,是Kubernetes 1.3里Pod自动扩容(伸缩)这个告警功能实现的基础,也将继续在 Kubernetes未来的版本中发挥重要的作用。</p><p>最后我们总结一下关于RC(Replica Set)的一些特性与作用。</p><ul><li>在大多数情况下,我们通过定义一个RC实现Pod的创建过程及副本数量的自动控制。</li><li>RC里包括完整的Pod定义模板。</li><li>RC通过Label Selector机制实现对Pod副本的自动控制。</li><li>通过改变RC里的Pod副本数量,可以实现Pod的扩容或缩容功能。</li><li>通过改变RC里Pod模板中的镜像版本,可以实现Pod的滚动升级功能。</li></ul><h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><p>Deployment是Kubernetes12引入的新概念,引入的目的是为了更好地解决Pod的编排问题。为此, Deployment在内部使用了 Replica Set来实现目的,无论从Deployment的作用与目的、它的YAM定义,还是从它的具体命令行操作来看,我们都可以把它看作RC的一次升级两者的相似度超过90%。</p><p>Deployment相对于RC的一个最大升级是我们可以随时知道当前Pod“部署”的进度。实际上由于一个Pod的创建、调度、绑定节点及在目标Node上启动对应的容器这一完整过程需要一定的时间,所以我们期待系统启动N个Pod副本的目标状态,实际上是一个连续变化的“部署过程”导致的最终状态。</p><p>Deployment的典型使用场景有以下几个。</p><ul><li>创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。</li><li>检查Deployment的状态来看部署动作是否完成(Pod副本的数量是否达到预期的值)。</li><li>更新Deployment以创建新的Pod(比如镜像升级)。</li><li>如果当前Deployment不稳定,则回滚到一个早先的Deployment版本。</li><li>挂起或者恢复一个Deployment。</li></ul><h3 id="Horizontal-Pod-Autoscaler-HPA"><a href="#Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="Horizontal Pod Autoscaler(HPA)"></a>Horizontal Pod Autoscaler(HPA)</h3><p>Horizontal Pod Autoscaling简称HPA,意思是Pod横向自动扩容,与之前的RC、Deployment样,也属于一种Kubernetes资源对象。通过追踪分析RC控制的所有目标Pod的负载变化情况,来确定是否需要针对性地调整目标Pod的副本数,这是HPA的实现原理。当前,HPA可以有以下两种方式作为Pod负载的度量指标。</p><ul><li>CPUUtilization Percentage</li><li>应用程序自定义的度量指标,比如服务在每秒内的相应的请求数(TPS或QPS)。</li></ul><p>CPUUtilization Percentage是一个算术平均值,即目标Pod所有副本自身的CPU利用率的平均值。一个Pod自身的CPU利用率是该Pod当前CPU的使用量除以它的Pod Request的值,比如我们定义一个Pod的Pod Request为0.4,而当前Pod的CPU使用量为0.2,则它的CPU使用率为50%,如此一来,我们就可以就算出来一个RC控制的所有Pod副本的CPU利用率的算术平均值了。如果某一时刻CPUUtilization Percentage的值超过80%,则意味着当前的Pod副本数很可能不足以支撑接下来更多的请求,需要进行动态扩容,而当请求高峰时段过去后,Pod的CPU利用率又会降下来,此时对应的Pod副本数应该自动减少到一个合理的水平。</p><p>CPUUtilization Percentage计算过程中使用到的Pod的CPU使用量通常是1分钟内的平均值,目前通过查询Heapster扩展组件来得到这个值,所以需要安装部署Heapster,这样一来便增加了系统的复杂度和实施HPA特性的复杂度,因此,未来的计划是Kubernetes自身实现一个基础性能数据采集模块,从而更好地支持HPA和其他需要用到基础性能数据的功能模块。此外,我们也看到,如果目标Pod没有定义Pod Request的值,则无法使用CPUUtilization Percentage来实现Pod横向自动扩容的能力。除了使用CPUUtiliationPercentage, Kubernetes从1.2版本开始,尝试支持应用程序自定义的度量指标,目前仍然为实验特性,不建议在生产环境中使用。</p><h3 id="Service-服务"><a href="#Service-服务" class="headerlink" title="Service(服务)"></a>Service(服务)</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>Service也是Kubernetes里的最核心的资源对象之一,Kubernetes里的每个Service其实就是我们经常提起的微服务架构中的一个“微服务”,之前我们所说的Pod、RC等资源对象其实都是为这节所说的“服务”—Kubernetes Service做“嫁衣”的。图1.14显示了Pod、RC与 Service的逻辑关系。<br><img src="/images/kubernetes-authoritative-guide-node/1.14Pod_RC_Service%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt><br>从图1.14中我们看到,Kubernetes的 Service定义了一个服务的访问入口地址,前端的应用(Pod)通过这个入口地址访问其背后的一组由Pod副本组成的集群实例,<font color="DeepPink"><strong>Service与其后端Pod副本集群之间则是通过Label selector来实现“无缝对接”的。</strong></font>而RC的作用实际上是保证Service的服务能力和服务质量始终处于预期的标准。</p><p><font color="DeepPink"><strong>运行在每个Node上的kube-proxy进程其实就是一个智能的软件负载均衡器,它负责把对Service的请求转发到后端的某个Pod实例上,并在内部实现服务的负载均衡与会话保持机制。但 Kubernetes发明了一种很巧妙又影响深远的设计:Service不是共用一个负载均衡器的IP地址,而是每个Service分配了一个全局唯一的虚拟IP地址,这个虚拟IP被称为Cluster IP。这样一来,每个服务就变成了具备唯一IP地址的“通信节点”,服务调用就变成了最基础的TCP网络通信问题。</strong></font></p><p>我们知道,<font color="DeepPink"><strong>Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变,因为新Pod的IP地址与之前旧Pod的不同。而 Service一旦创建, Kubernetes就会自动为它分配一个可用的Cluster IP,而且在Service的整个生命周期内,它的Cluster IP不会发生改变。于是,服务发现这个棘手的问题在Kubernetes的架构里也得以轻松解决:只要用Service的Name与Service的Cluster IP地址做一个DNS域名映射即可完美解决问题。现在想想,这真是一个很棒的设计。</strong></font></p><h4 id="Kubernetes的服务发现机制"><a href="#Kubernetes的服务发现机制" class="headerlink" title="Kubernetes的服务发现机制"></a>Kubernetes的服务发现机制</h4><p>任何分布式系统都会涉及“服务发现”这个基础问题,大部分分布式系统通过提供特定的API接口来实现服务发现的功能,但这样做会导致平台的侵入性比较强,也增加了开发测试的困难。Kubernetes则采用了直观朴素的思路去解决这个棘手的问题。</p><p>首先,每个Kubernetes中的Service都有一个唯一的Cluster IP以及唯一的名字,而名字是由开发者自己定义的,部署的时候也没必要改变,所以完全可以固定在配置中。接下来的问题就是如何通过Service的名字找到对应的Cluster IP?</p><p>Kubernetes通过Add-On增值包的方式引入了DNS系统,把服务名作为DNs域名,这样一来,程序就可以直接使用服务名来建立通信连接了。</p><h4 id="外部系统访问Service的问题"><a href="#外部系统访问Service的问题" class="headerlink" title="外部系统访问Service的问题"></a>外部系统访问Service的问题</h4><p>为了更加深入地理解和掌握Kubernetes,我们需要弄明白Kubernetes里的“三种IP”这个关键问题,这三种IP分别如下。</p><ul><li>Node IP:Node节点的IP地址。</li><li>Pod IP:Pod的IP地址</li><li>Cluster IP: Service的IP地址。</li></ul><p>首先,Node IP是Kubernetes集群中每个节点的物理网卡的IP地址,这是一个真实存在的物理网络,所有属于这个网络的服务器之间都能通过这个网络直接通信,不管它们中是否有部分节点不属于这个Kubernetes集群。这也表明了Kubernetes集群之外的节点访问Kubernetes集群之内的某个节点或者TCP/IP服务的时候,必须要通过Node IP进行通信。</p><p>其次,Pod IP是每个Pod的IP地址,它是Docker Engine根据docker0网桥的IP地址段进行分配的,通常是一个虚拟的二层网络,前面我们说过,Kubernetes要求位于不同Node上的Pod能够彼此直接通信,所以Kubernetes里一个Pod里的容器访问另外一个Pod里的容器,就是通过Pod IP所在的虚拟二层网络进行通信的,而真实的TCP/IP流量则是通过Node IP所在的物理网卡流出的。</p><p>最后,我们说说Service的Cluster IP,它也是一个虚拟的IP,但更像是一个“伪造”的IP网络,原因有以下几点。</p><ul><li>Cluster IP仅仅作用于Kubernetes Service这个对象,并由Kubernetes管理和分配IP地址(来源于Cluster IP地址池)。</li><li>Cluster IP无法被Ping,因为没有一个“实体网络对象”来响应。</li><li>Cluster IP只能结合Service Port组成一个具体的通信端口,单独的Cluster IP不具备TCP/IP通信的基础,并且它们属于Kubernetes集群这样一个封闭的空间,集群之外的节点如果要访问这个通信端口,则需要做一些额外的工作。</li><li>在Kubernetes集群之内,Node IP网、Pod IP网与Cluster IP网之间的通信,采用的是Kubernetes自己设计的一种编程方式的特殊的路由规则,与我们所熟知的IP路由有很大的不同。</li></ul><p>NodePort的实现方式是在Kubernetes集群里的每个Node上为需要外部访问的Service开启个对应的TCP监听端口,外部系统只要用任意一个Node的IP地址+具体的NodePort端口号即可访问此服务。</p><p>但NodePort还没有完全解决外部访问Service的所有问题,比如负载均衡问题,假如我们的集群中有10个Node,则此时最好有一个负载均衡器,外部的请求只需访问此负载均衡器的IP地址,由负载均衡器负责转发流量到后面某个Node的NodePort上。如图1.17所示。</p><p><img src="/images/kubernetes-authoritative-guide-node/1.17_NodePort_LB.png" alt></p><p>图1.17中的Load balancer组件独立于Kubernetes集群之外,通常是一个硬件的负载均衡器,或者是以软件方式实现的,例如HAProxy或者Nginx。对于每个Service,我们通常需要配置个对应的Load balancer实例来转发流量到后端的Node上,这的确增加了工作量及出错的概率。于是Kubernetes提供了自动化的解决方案,如果我们的集群运行在谷歌的GCE公有云上,那么只要我们把Service的type=Node Port改为type=LoadBalancer,此时Kubernetes会自动创建个对应的Load balancer实例并返回它的IP地址供外部客户端使用。其他公有云提供商只要实现了支持此特性的驱动,则也可以达到上述目的。此外,裸机上的类似机制(Bare Metal Service Load Balancers)也正在被开发。</p><h3 id="Volume-存储卷"><a href="#Volume-存储卷" class="headerlink" title="Volume(存储卷)"></a>Volume(存储卷)</h3><p>Volume是Pod中能够被多个容器访问的共享目录Kubernetes Volume概念、用途和目的与Docker的Volume比较类似,但两者不能等价。首先,Kubernetes中的Volume定义在Pod上,然后被一个Pod里的多个容器挂载到具体的文件目录下;其次,Kubernetes中的Volume与Pod的生命周期相同,但与容器的生命周期不相关,当容器终止或者重启时,Volume中的数据也不会丢失。最后,Kubernetes支持多种类型的 Volume,例如GlusterFS、ceph等先进的分布式文件系统。</p><p>除了可以让一个Pod里的多个容器共享文件、让容器的数据写到宿主机的磁盘上或者写文件到网络存储中, Kubernetes的Volume还扩展出了一种非常有实用价值的功能,即容器配置文件集中化定义与管理,这是通过ConfigMap这个新的资源对象来实现的,后面我们会详细说明。</p><p>Kubernetes提供了非常丰富的Volume类型,下面逐一进行说明。</p><h4 id="empty-Dir"><a href="#empty-Dir" class="headerlink" title="empty Dir"></a>empty Dir</h4><p>一个empty Dir Volume是在Pod分配到Node时创建的。从它的名称就可以看出,它的初始内容为空,并且无须指定宿主机上对应的目录文件,因为这是 Kubernetes自动分配的一个目录当Pod从Node上移除时,empty Dir中的数据也会被永久删除。empty Dir的一些用途如下。</p><ul><li>临时空间,例如用于某些应用程序运行时所需的临时目录,且无须永久保留。</li><li>长时间任务的中间过程 Check Point的临时保存目录。</li><li>一个容器需要从另一个容器中获取数据的目录(多容器共享目录)。</li></ul><p>目前,用户无法控制emptyDir使用的介质种类。如果kubelet的配置是使用硬盘,那么所有empty都将创建在该硬盘上。Pod在将来可以设置empty Dir是位于硬盘、固态硬盘上还是基于内存的tmpfs上,上面的例子便采用了emptyDir类的 Volume。</p><h4 id="hostPath"><a href="#hostPath" class="headerlink" title="hostPath"></a>hostPath</h4><p>hostPath为在Pod上挂载宿主机上的文件或目录,它通常可以用于以下几方面：</p><ul><li>容器应用程序生成的日志文件需要永久保存时,可以使用宿主机的高速文件系统进行存储。</li><li>需要访问宿主机上Docker引擎内部数据结构的容器应用时,可以通过定义hostPath为宿主机/var/lib/docker目录,使容器内部应用可以直接访问Docker的文件系统。</li></ul><p>在使用这种类型的Volume时,需要注意以下几点。</p><ul><li>在不同的Node上具有相同配置的Pod可能会因为宿主机上的目录和文件不同而导致对Volume上目录和文件的访问结果不一致。</li><li>如果使用了资源配额管理,则 Kubernetes无法将 hostPath在宿主机上使用的资源纳入管理。</li></ul><h4 id="gcePersistentDisk"><a href="#gcePersistentDisk" class="headerlink" title="gcePersistentDisk"></a>gcePersistentDisk</h4><p>使用这种类型的Volume表示使用谷歌公有云提供的永久磁盘(Persistent Disk,PD)存放Volume的数据,它与Empty Dir不同,PD上的内容会被永久保存,当Pod被删除时,PD只是被卸载(Unmount),但不会被删除。需要注意的是,你需要先创建一个永久磁盘(PD),才能使用gcePersistent Disk。<br>使用gcePersistent Disk有以下一些限制条件。</p><ul><li>Node(运行 kubelet的节点)需要是GCE虚拟机。</li><li>这些虚拟机需要与PD存在于相同的GCE项目和Zone中。</li></ul><h4 id="awsElasticBlock-Store"><a href="#awsElasticBlock-Store" class="headerlink" title="awsElasticBlock Store"></a>awsElasticBlock Store</h4><p>与GCE类似,该类型的Volume使用亚马逊公有云提供的EBS Volume存储数据,需要先创建一个EBS Volume才能使用awsElasticBlockStore。</p><p>使用awsElasticBlockStore的一些限制条件如下。</p><ul><li>Node(运行kubelet的节点)需要是AWS EC2实例。</li><li>这些AWS EC2实例需要与EBS volume存在于相同的region和availability-zone中。</li><li>EBS只支持单个EC2实例mount一个volume。</li></ul><h4 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h4><p>使用NFS网络文件系统提供的共享目录存储数据时,我们需要在系统中部署一个NFS Server。</p><h4 id="其他类型的Volume"><a href="#其他类型的Volume" class="headerlink" title="其他类型的Volume"></a>其他类型的Volume</h4><ul><li>iscsi:使用 ISCSI存储设备上的目录挂载到Pod中。</li><li>flocker:使用 Flocker来管理存储卷。</li><li>glusterfs:使用开源GlusterFS网络文件系统的目录挂载到Pod中。</li><li>rbd:使用Linux块设备共享存储(Rados block device)挂载到Pod中。</li><li>gitRepo:通过挂载一个空目录,并从GIT库clone一个git repository以供Pod使用。</li><li>secret:一个secret volume用于为Pod提供加密的信息,你可以将定义在Kubernetes中的secret直接挂载为文件让Pod访问。secret volume是通过tmfs(内存文件系统)实现的,所以这种类型的volume总是不会持久化的。</li></ul><h3 id="Persistent-Volume"><a href="#Persistent-Volume" class="headerlink" title="Persistent Volume"></a>Persistent Volume</h3><p>之前我们提到的Volume是定义在Pod上的,属于“计算资源”的一部分,而实际上,“网络存储”是相对独立于“计算资源”而存在的一种实体资源。比如在使用虚机的情况下,我们通常会先定义一个网络存储,然后从中划出一个“网盘”并挂接到虚机上。Persistent Volume(简称PV)和与之相关联的Persistent Volume Claim(简称PVC)也起到了类似的作用。</p><p>PV可以理解成Kubernetes集群中的某个网络存储中对应的一块存储,它与Volume很类似,</p><p>但有以下区别。</p><ul><li>PV只能是网络存储,不属于任何Node,但可以在每个Node上访问。</li><li>PV并不是定义在Pod上的,而是独立于Pod之外定义。</li><li>PV目前只有几种类型: GCE Persistent Disks、NFS、RBD、 ISCSI、AWS、ElasticBlock Store、 GlusterFS等。</li></ul><p>比较重要的是PV的accessModes属性,目前有以下类型：</p><ul><li>Read WriteOnce:读写权限、并且只能被单个Node挂载。</li><li>ReadOnly Many:只读权限、允许被多个Node挂载。</li><li>Read WriteMany:读写权限、允许被多个Node挂载。</li></ul><p>如果某个Pod想申请某种条件的PV,则首先需要定义一个Persistent Volume Claim(PVC)。</p><p>最后,我们说说PV的状态,PV是有状态的对象,它有以下几种状态。</p><ul><li>Available:空闲状态。</li><li>Bound:已经绑定到某个PVC上。</li><li>Released:对应的PVC已经删除,但资源还没有被集群收回。</li><li>Failed:PⅤ自动回收失败。</li></ul><h3 id="Namespace-命名空间"><a href="#Namespace-命名空间" class="headerlink" title="Namespace(命名空间)"></a>Namespace(命名空间)</h3><p>Namespace(命名空间)是Kubernetes系统中的另一个非常重要的概念,Namespace在很多情况下用于实现多租户的资源隔离。Namespace通过将集群内部的资源对象“分配”到不同的Namespace中,形成逻辑上分组的不同项目、小组或用户组,便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。</p><h3 id="Annotation-注解"><a href="#Annotation-注解" class="headerlink" title="Annotation(注解)"></a>Annotation(注解)</h3><p>Annotation与Label类似,也使用key/value键值对的形式进行定义。不同的是Label具有严格的命名规则,它定义的是 Kubernetes对象的元数据(Metadata),并且用于Label Selector而Annotation则是用户任意定义的“附加”信息,以便于外部工具进行查找,很多时候,Kubernetes的模块自身会通过Annotation的方式标记资源对象的一些特殊信息。</p><p>通常来说,用Annotation来记录的信息如下。</p><ul><li>build信息、release信息、Docker镜像信息等,例如时间戳、release id号、PR号、镜像hash值、docker registry地址等。</li><li>日志库、监控库、分析库等资源库的地址信息</li><li>程序调试工具信息,例如工具名称、版本号等</li><li>团队的联系信息,例如电话号码、负责人名称、网址等。</li></ul><blockquote><p>只看了第一章</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 查询语句执行顺序</title>
      <link href="/order-of-execution-of-the-sql-query.html"/>
      <url>/order-of-execution-of-the-sql-query.html</url>
      
        <content type="html"><![CDATA[<p>MySQL 查询语句执行顺序</p><a id="more"></a><ul><li>FROM clause</li><li>WHERE clause</li><li>GROUP BY clause</li><li>HAVING clause</li><li>SELECT clause</li><li>ORDER BY clause</li></ul><p>该执行顺序整理自网络，<a href="https://qxf2.com/blog/mysql-query-execution/" target="_blank" rel="noopener">mysql-query-execution</a></p><blockquote><p>一直想找一个权威的解释出处，比如官网，但没有找到，如果有人知道，欢迎留言。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Query </tag>
            
            <tag> Execution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Uber Go 语言编码规范</title>
      <link href="/uber-go-guide.html"/>
      <url>/uber-go-guide.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>原文地址：<br><a href="https://github.com/xxjwxc/uber_go_guide_cn" target="_blank" rel="noopener">https://github.com/xxjwxc/uber_go_guide_cn</a></p></blockquote><a id="more"></a><!-- # Uber Go 语言编码规范 --><p> <a href="https://www.uber.com/" target="_blank" rel="noopener">Uber</a> 是一家美国硅谷的科技公司，也是 Go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 Gopher 圈熟知的 <a href="https://github.com/uber-go/zap" target="_blank" rel="noopener">zap</a>、<a href="https://github.com/jaegertracing/jaeger" target="_blank" rel="noopener">jaeger</a> 等。2018 年年末 Uber 将内部的 <a href="https://github.com/uber-go/guide" target="_blank" rel="noopener">Go 风格规范</a> 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 Gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。</p><h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><ul><li>当前更新版本：2019-11-13 版本地址：<a href="https://github.com/uber-go/guide/commit/85bf203f4371a8ae9e5e9a4d52ea77b17ca04ae6" target="_blank" rel="noopener">commit:#71</a></li><li>如果您发现任何更新、问题或改进，请随时 fork 和 PR</li><li>Please feel free to fork and PR if you find any updates, issues or improvement.</li></ul><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#介绍">介绍</a></li><li><a href="#指导原则">指导原则</a><ul><li><a href="#指向-interface-的指针">指向 interface 的指针</a></li><li><a href="#接收器-receiver-与接口">接收器 (receiver) 与接口</a></li><li><a href="#零值-Mutex-是有效的">零值 Mutex 是有效的</a></li><li><a href="#在边界处拷贝-Slices-和-Maps">在边界处拷贝 Slices 和 Maps</a></li><li><a href="#使用-defer-释放资源">使用 defer 释放资源</a></li><li><a href="#Channel-的-size-要么是-1要么是无缓冲的">Channel 的 size 要么是 1，要么是无缓冲的</a></li><li><a href="#枚举从-1-开始">枚举从 1 开始</a></li><li><a href="#错误类型">错误类型</a></li><li><a href="#错误包装-(Error-Wrapping)">错误包装 (Error Wrapping)</a></li><li><a href="#处理类型断言失败">处理类型断言失败</a></li><li><a href="#不要-panic">不要 panic</a></li><li><a href="#使用-gouberorgatomic">使用 go.uber.org/atomic</a></li></ul></li><li><a href="#性能">性能</a><ul><li><a href="#优先使用-strconv-而不是-fmt">优先使用 strconv 而不是 fmt</a></li><li><a href="#避免字符串到字节的转换">避免字符串到字节的转换</a></li><li><a href="#尽量初始化时指定-Map-容量">尽量初始化时指定 Map 容量</a></li></ul></li><li><a href="#规范">规范</a><ul><li><a href="#一致性">一致性</a></li><li><a href="#相似的声明放在一组">相似的声明放在一组</a></li><li><a href="#import-分组">import 分组</a></li><li><a href="#包名">包名</a></li><li><a href="#函数名">函数名</a></li><li><a href="#导入别名">导入别名</a></li><li><a href="#函数分组与顺序">函数分组与顺序</a></li><li><a href="#减少嵌套">减少嵌套</a></li><li><a href="#不必要的-else">不必要的 else</a></li><li><a href="#顶层变量声明">顶层变量声明</a></li><li><a href="#对于未导出的顶层常量和变量使用_作为前缀">对于未导出的顶层常量和变量，使用_作为前缀</a></li><li><a href="#结构体中的嵌入">结构体中的嵌入</a></li><li><a href="#使用字段名初始化结构体">使用字段名初始化结构体</a></li><li><a href="#本地变量声明">本地变量声明</a></li><li><a href="#nil-是一个有效的-slice">nil 是一个有效的 slice</a></li><li><a href="#小变量作用域">小变量作用域</a></li><li><a href="#避免参数语义不明确Avoid-Naked-Parameters">避免参数语义不明确（Avoid Naked Parameters）</a></li><li><a href="#使用原始字符串字面值避免转义">使用原始字符串字面值，避免转义</a></li><li><a href="#初始化-Struct-引用">初始化 Struct 引用</a></li><li><a href="#初始化-maps">初始化 Maps</a></li><li><a href="#字符串-string-format">字符串 string format </a></li><li><a href="#命名-Printf-样式的函数">命名 Printf 样式的函数</a></li></ul></li><li><a href="#编程模式">编程模式</a><ul><li><a href="#表驱动测试">表驱动测试</a></li><li><a href="#功能选项">功能选项</a></li></ul></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>样式 (style) 是支配我们代码的惯例。术语<code>样式</code>有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。</p><p>本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 Go 语言功能。</p><p>该指南最初由 <a href="https://github.com/prashantv" target="_blank" rel="noopener">Prashant Varanasi</a> 和 <a href="https://github.com/nomis52" target="_blank" rel="noopener">Simon Newton</a> 编写，目的是使一些同事能快速使用 Go。多年来，该指南已根据其他人的反馈进行了修改。</p><p>本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则，而其他扩展准则依赖于下面外部的指南：</p><ol><li><a href="https://golang.org/doc/effective_go.html" target="_blank" rel="noopener">Effective Go</a></li><li><a href="https://github.com/golang/go/wiki/CodeReviewComments" target="_blank" rel="noopener">The Go common mistakes guide</a></li></ol><p>所有代码都应该通过<code>golint</code>和<code>go vet</code>的检查并无错误。我们建议您将编辑器设置为：</p><ul><li>保存时运行 <code>goimports</code></li><li>运行 <code>golint</code> 和 <code>go vet</code> 检查错误</li></ul><p>您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息：<br><a href="https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins" target="_blank" rel="noopener">https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins</a></p><h2 id="指导原则"><a href="#指导原则" class="headerlink" title="指导原则"></a>指导原则</h2><h3 id="指向-interface-的指针"><a href="#指向-interface-的指针" class="headerlink" title="指向 interface 的指针"></a>指向 interface 的指针</h3><p>您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。</p><p>接口实质上在底层用两个字段表示：</p><ol><li>一个指向某些特定类型信息的指针。您可以将其视为”type”。</li><li>数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。</li></ol><p>如果希望接口方法修改基础数据，则必须使用指针传递。</p><h3 id="接收器-receiver-与接口"><a href="#接收器-receiver-与接口" class="headerlink" title="接收器 (receiver) 与接口"></a>接收器 (receiver) 与接口</h3><p>使用值接收器的方法既可以通过值调用，也可以通过指针调用。</p><p>例如，</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> S <span class="keyword">struct</span> &#123;</span><br><span class="line">  data <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s S)</span> <span class="title">Read</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> s.data</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *S)</span> <span class="title">Write</span><span class="params">(str <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">  s.data = str</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sVals := <span class="keyword">map</span>[<span class="keyword">int</span>]S&#123;<span class="number">1</span>: &#123;<span class="string">"A"</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 你只能通过值调用 Read</span></span><br><span class="line">sVals[<span class="number">1</span>].Read()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这不能编译通过：</span></span><br><span class="line"><span class="comment">//  sVals[1].Write("test")</span></span><br><span class="line"></span><br><span class="line">sPtrs := <span class="keyword">map</span>[<span class="keyword">int</span>]*S&#123;<span class="number">1</span>: &#123;<span class="string">"A"</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过指针既可以调用 Read，也可以调用 Write 方法</span></span><br><span class="line">sPtrs[<span class="number">1</span>].Read()</span><br><span class="line">sPtrs[<span class="number">1</span>].Write(<span class="string">"test"</span>)</span><br></pre></td></tr></table></figure><p>同样，即使该方法具有值接收器，也可以通过指针来满足接口。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> F <span class="keyword">interface</span> &#123;</span><br><span class="line">  f()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> S1 <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s S1)</span> <span class="title">f</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> S2 <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *S2)</span> <span class="title">f</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">s1Val := S1&#123;&#125;</span><br><span class="line">s1Ptr := &amp;S1&#123;&#125;</span><br><span class="line">s2Val := S2&#123;&#125;</span><br><span class="line">s2Ptr := &amp;S2&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i F</span><br><span class="line">i = s1Val</span><br><span class="line">i = s1Ptr</span><br><span class="line">i = s2Ptr</span><br><span class="line"></span><br><span class="line"><span class="comment">//  下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器</span></span><br><span class="line"><span class="comment">//   i = s2Val</span></span><br></pre></td></tr></table></figure><p><a href="https://golang.org/doc/effective_go.html" target="_blank" rel="noopener">Effective Go</a> 中有一段关于 <a href="https://golang.org/doc/effective_go.html#pointers_vs_values" target="_blank" rel="noopener">pointers vs. values</a> 的精彩讲解。</p><h3 id="零值-Mutex-是有效的"><a href="#零值-Mutex-是有效的" class="headerlink" title="零值 Mutex 是有效的"></a>零值 Mutex 是有效的</h3><p>零值 <code>sync.Mutex</code> 和 <code>sync.RWMutex</code> 是有效的。所以指向 mutex 的指针基本是不必要的。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mu := <span class="built_in">new</span>(sync.Mutex)</span><br><span class="line">mu.Lock()</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">mu.Lock()</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果你使用结构体指针，mutex 可以非指针形式作为结构体的组成字段，或者更好的方式是直接嵌入到结构体中。<br>如果是私有结构体类型或是要实现 Mutex 接口的类型，我们可以使用嵌入 mutex 的方法：</p><table><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> smap <span class="keyword">struct</span> &#123;</span><br><span class="line">  sync.Mutex <span class="comment">// only for unexported types（仅适用于非导出类型）</span></span><br><span class="line"></span><br><span class="line">  data <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSMap</span><span class="params">()</span> *<span class="title">smap</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;smap&#123;</span><br><span class="line">    data: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *smap)</span> <span class="title">Get</span><span class="params">(k <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  m.Lock()</span><br><span class="line">  <span class="keyword">defer</span> m.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> m.data[k]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> SMap <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex <span class="comment">// 对于导出类型，请使用私有锁</span></span><br><span class="line"></span><br><span class="line">  data <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewSMap</span><span class="params">()</span> *<span class="title">SMap</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;SMap&#123;</span><br><span class="line">    data: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *SMap)</span> <span class="title">Get</span><span class="params">(k <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  m.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> m.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> m.data[k]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td>为私有类型或需要实现互斥接口的类型嵌入。</td><td>对于导出的类型，请使用专用字段。</td></tr></tbody></table><h3 id="在边界处拷贝-Slices-和-Maps"><a href="#在边界处拷贝-Slices-和-Maps" class="headerlink" title="在边界处拷贝 Slices 和 Maps"></a>在边界处拷贝 Slices 和 Maps</h3><p>slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。</p><h4 id="接收-Slices-和-Maps"><a href="#接收-Slices-和-Maps" class="headerlink" title="接收 Slices 和 Maps"></a>接收 Slices 和 Maps</h4><p>请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。</p><table><thead><tr><th>Bad</th> <th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *Driver)</span> <span class="title">SetTrips</span><span class="params">(trips []Trip)</span></span> &#123;</span><br><span class="line">  d.trips = trips</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trips := ...</span><br><span class="line">d1.SetTrips(trips)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 你是要修改 d1.trips 吗？</span></span><br><span class="line">trips[<span class="number">0</span>] = ...</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *Driver)</span> <span class="title">SetTrips</span><span class="params">(trips []Trip)</span></span> &#123;</span><br><span class="line">  d.trips = <span class="built_in">make</span>([]Trip, <span class="built_in">len</span>(trips))</span><br><span class="line">  <span class="built_in">copy</span>(d.trips, trips)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trips := ...</span><br><span class="line">d1.SetTrips(trips)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里我们修改 trips[0]，但不会影响到 d1.trips</span></span><br><span class="line">trips[<span class="number">0</span>] = ...</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h4 id="返回-slices-或-maps"><a href="#返回-slices-或-maps" class="headerlink" title="返回 slices 或 maps"></a>返回 slices 或 maps</h4><p>同样，请注意用户对暴露内部状态的 map 或 slice 的修改。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Stats <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  counters <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Snapshot 返回当前状态。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Stats)</span> <span class="title">Snapshot</span><span class="params">()</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">int</span></span> &#123;</span><br><span class="line">  s.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> s.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> s.counters</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// snapshot 不再受互斥锁保护</span></span><br><span class="line"><span class="comment">// 因此对 snapshot 的任何访问都将受到数据竞争的影响</span></span><br><span class="line"><span class="comment">// 影响 stats.counters</span></span><br><span class="line">snapshot := stats.Snapshot()</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Stats <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  counters <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Stats)</span> <span class="title">Snapshot</span><span class="params">()</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">int</span></span> &#123;</span><br><span class="line">  s.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> s.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  result := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>, <span class="built_in">len</span>(s.counters))</span><br><span class="line">  <span class="keyword">for</span> k, v := <span class="keyword">range</span> s.counters &#123;</span><br><span class="line">    result[k] = v</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// snapshot 现在是一个拷贝</span></span><br><span class="line">snapshot := stats.Snapshot()</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="使用-defer-释放资源"><a href="#使用-defer-释放资源" class="headerlink" title="使用 defer 释放资源"></a>使用 defer 释放资源</h3><p>使用 defer 释放资源，诸如文件和锁。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">p.Lock()</span><br><span class="line"><span class="keyword">if</span> p.count &lt; <span class="number">10</span> &#123;</span><br><span class="line">  p.Unlock()</span><br><span class="line">  <span class="keyword">return</span> p.count</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.count++</span><br><span class="line">newCount := p.count</span><br><span class="line">p.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> newCount</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当有多个 return 分支时，很容易遗忘 unlock</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">p.Lock()</span><br><span class="line"><span class="keyword">defer</span> p.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.count &lt; <span class="number">10</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> p.count</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.count++</span><br><span class="line"><span class="keyword">return</span> p.count</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更可读</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 <code>defer</code>。</p><h3 id="Channel-的-size-要么是-1，要么是无缓冲的"><a href="#Channel-的-size-要么是-1，要么是无缓冲的" class="headerlink" title="Channel 的 size 要么是 1，要么是无缓冲的"></a>Channel 的 size 要么是 1，要么是无缓冲的</h3><p>channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。考虑如何确定大小，是什么阻止了 channel 在负载下被填满并阻止写入，以及发生这种情况时发生了什么。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 应该足以满足任何情况！</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">64</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 大小：1</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">1</span>) <span class="comment">// 或者</span></span><br><span class="line"><span class="comment">// 无缓冲 channel，大小为 0</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="枚举从-1-开始"><a href="#枚举从-1-开始" class="headerlink" title="枚举从 1 开始"></a>枚举从 1 开始</h3><p>在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add=0, Subtract=1, Multiply=2</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add=1, Subtract=2, Multiply=3</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> LogOutput <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  LogToStdout LogOutput = <span class="literal">iota</span></span><br><span class="line">  LogToFile</span><br><span class="line">  LogToRemote</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// LogToStdout=0, LogToFile=1, LogToRemote=2</span></span><br></pre></td></tr></table></figure><!-- TODO: section on String methods for enums --><h3 id="错误类型"><a href="#错误类型" class="headerlink" title="错误类型"></a>错误类型</h3><p>Go 中有多种声明错误（Error) 的选项：</p><ul><li><a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a> 对于简单静态字符串的错误</li><li><a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a> 用于格式化的错误字符串</li><li>实现 <code>Error()</code> 方法的自定义类型</li><li>用 <a href="https://godoc.org/github.com/pkg/errors#Wrap" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Wrap</code></a> 的 Wrapped errors</li></ul><p>返回错误时，请考虑以下因素以确定最佳选择：</p><ul><li>这是一个不需要额外信息的简单错误吗？如果是这样，<a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a> 足够了。</li><li>客户需要检测并处理此错误吗？如果是这样，则应使用自定义类型并实现该 <code>Error()</code> 方法。</li><li>您是否正在传播下游函数返回的错误？如果是这样，请查看本文后面有关错误包装 <a href="#错误包装" title="Error-Wrapping">section on error wrapping</a> 部分的内容。</li><li>否则 <a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a> 就可以了。</li></ul><p>如果客户端需要检测错误，并且您已使用创建了一个简单的错误 <a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a>，请使用一个错误变量。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errors.New(<span class="string">"could not open"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := foo.Open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err.Error() == <span class="string">"could not open"</span> &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> ErrCouldNotOpen = errors.New(<span class="string">"could not open"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> ErrCouldNotOpen</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := foo.Open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err == foo.ErrCouldNotOpen &#123;</span><br><span class="line">    <span class="comment">// handle</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果您有可能需要客户端检测的错误，并且想向其中添加更多信息（例如，它不是静态字符串），则应使用自定义类型。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Errorf(<span class="string">"file %q not found"</span>, file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> strings.Contains(err.Error(), <span class="string">"not found"</span>) &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> errNotFound <span class="keyword">struct</span> &#123;</span><br><span class="line">  file <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e errNotFound)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Sprintf(<span class="string">"file %q not found"</span>, e.file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errNotFound&#123;file: file&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> _, ok := err.(errNotFound); ok &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>直接导出自定义错误类型时要小心，因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> errNotFound <span class="keyword">struct</span> &#123;</span><br><span class="line">  file <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e errNotFound)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Sprintf(<span class="string">"file %q not found"</span>, e.file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">IsNotFoundError</span><span class="params">(err error)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  _, ok := err.(errNotFound)</span><br><span class="line">  <span class="keyword">return</span> ok</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errNotFound&#123;file: file&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := foo.Open(<span class="string">"foo"</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> foo.IsNotFoundError(err) &#123;</span><br><span class="line">    <span class="comment">// handle</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- TODO: Exposing the information to callers with accessor functions. --><h3 id="错误包装-Error-Wrapping"><a href="#错误包装-Error-Wrapping" class="headerlink" title="错误包装 (Error Wrapping)"></a>错误包装 (Error Wrapping)</h3><p>一个（函数/方法）调用失败时，有三种主要的错误传播方式：</p><ul><li><p>如果没有要添加的其他上下文，并且您想要维护原始错误类型，则返回原始错误。</p></li><li><p>添加上下文，使用 <a href="https://godoc.org/github.com/pkg/errors#Wrap" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Wrap</code></a> 以便错误消息提供更多上下文 ,<a href="https://godoc.org/github.com/pkg/errors#Cause" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Cause</code></a> 可用于提取原始错误。<br>Use fmt.Errorf if the callers do not need to detect or handle that specific error case.</p></li><li><p>如果调用者不需要检测或处理的特定错误情况，使用 <a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a>。</p></li></ul><p>建议在可能的地方添加上下文，以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误，而不是诸如“连接被拒绝”之类的模糊错误。</p><p>在将上下文添加到返回的错误时，请避免使用“failed to”之类的短语来保持上下文简洁，这些短语会陈述明显的内容，并随着错误在堆栈中的渗透而逐渐堆积：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s, err := store.New()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Errorf(</span><br><span class="line">        <span class="string">"failed to create new store: %s"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s, err := store.New()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Errorf(</span><br><span class="line">        <span class="string">"new store: %s"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">failed to x: failed to y: failed to create new store: the error</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x: y: new store: the error</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>但是，一旦将错误发送到另一个系统，就应该明确消息是错误消息（例如使用<code>err</code>标记，或在日志中以”Failed”为前缀）。</p><p>另请参见 <a href="https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully" target="_blank" rel="noopener">Don’t just check errors, handle them gracefully</a>. 不要只是检查错误，要优雅地处理错误</p><h3 id="处理类型断言失败"><a href="#处理类型断言失败" class="headerlink" title="处理类型断言失败"></a>处理类型断言失败</h3><p><a href="https://golang.org/ref/spec#Type_assertions" target="_blank" rel="noopener">type assertion</a> 的单个返回值形式针对不正确的类型将产生 panic。因此，请始终使用“comma ok”的惯用法。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t := i.(<span class="keyword">string</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t, ok := i.(<span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">  <span class="comment">// 优雅地处理错误</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><!-- TODO: There are a few situations where the single assignment form isfine. --><h3 id="不要-panic"><a href="#不要-panic" class="headerlink" title="不要 panic"></a>不要 panic</h3><p>在生产环境中运行的代码必须避免出现 panic。panic 是 <a href="https://en.wikipedia.org/wiki/Cascading_failure" target="_blank" rel="noopener">cascading failures</a> 级联失败的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(bar <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(bar) == <span class="number">0</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"bar must not be empty"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(os.Args) != <span class="number">2</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"USAGE: foo &lt;bar&gt;"</span>)</span><br><span class="line">    os.Exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  foo(os.Args[<span class="number">1</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(bar <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(bar) == <span class="number">0</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> errors.New(<span class="string">"bar must not be empty"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(os.Args) != <span class="number">2</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"USAGE: foo &lt;bar&gt;"</span>)</span><br><span class="line">    os.Exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> err := foo(os.Args[<span class="number">1</span>]); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> _statusTemplate = template.Must(template.New(<span class="string">"name"</span>).Parse(<span class="string">"_statusHTML"</span>))</span><br></pre></td></tr></table></figure><p>即使在测试代码中，也优先使用<code>t.Fatal</code>或者<code>t.FailNow</code>而不是 panic 来确保失败被标记。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func TestFoo(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">f, err := ioutil.TempFile(<span class="string">""</span>, <span class="string">"test"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="built_in">panic</span>(<span class="string">"failed to set up test"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func TestFoo(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">f, err := ioutil.TempFile(<span class="string">""</span>, <span class="string">"test"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  t.Fatal(<span class="string">"failed to set up test"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><!-- TODO: Explain how to use _test packages. --><h3 id="使用-go-uber-org-atomic"><a href="#使用-go-uber-org-atomic" class="headerlink" title="使用 go.uber.org/atomic"></a>使用 go.uber.org/atomic</h3><p>使用 <a href="https://golang.org/pkg/sync/atomic/" target="_blank" rel="noopener">sync/atomic</a> 包的原子操作对原始类型 (<code>int32</code>, <code>int64</code>等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。</p><p><a href="https://godoc.org/go.uber.org/atomic" target="_blank" rel="noopener">go.uber.org/atomic</a> 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的<code>atomic.Bool</code>类型。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> foo <span class="keyword">struct</span> &#123;</span><br><span class="line">  running <span class="keyword">int32</span>  <span class="comment">// atomic</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f* foo)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> atomic.SwapInt32(&amp;f.running, <span class="number">1</span>) == <span class="number">1</span> &#123;</span><br><span class="line">     <span class="comment">// already running…</span></span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// start the Foo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">isRunning</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> f.running == <span class="number">1</span>  <span class="comment">// race!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> foo <span class="keyword">struct</span> &#123;</span><br><span class="line">  running atomic.Bool</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> f.running.Swap(<span class="literal">true</span>) &#123;</span><br><span class="line">     <span class="comment">// already running…</span></span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// start the Foo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">isRunning</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> f.running.Load()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>性能方面的特定准则只适用于高频场景。</p><h3 id="优先使用-strconv-而不是-fmt"><a href="#优先使用-strconv-而不是-fmt" class="headerlink" title="优先使用 strconv 而不是 fmt"></a>优先使用 strconv 而不是 fmt</h3><p>将原语转换为字符串或从字符串转换时，<code>strconv</code>速度比<code>fmt</code>快。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  s := fmt.Sprint(rand.Int())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  s := strconv.Itoa(rand.Int())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkFmtSprint-4    143 ns/op    2 allocs/op</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkStrconv-4    64.2 ns/op    1 allocs/op</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="避免字符串到字节的转换"><a href="#避免字符串到字节的转换" class="headerlink" title="避免字符串到字节的转换"></a>避免字符串到字节的转换</h3><p>不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  w.Write([]<span class="keyword">byte</span>(<span class="string">"Hello world"</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data := []<span class="keyword">byte</span>(<span class="string">"Hello world"</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  w.Write(data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkBad-4   50000000   22.2 ns/op</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkGood-4  500000000   3.25 ns/op</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="尽量初始化时指定-Map-容量"><a href="#尽量初始化时指定-Map-容量" class="headerlink" title="尽量初始化时指定 Map 容量"></a>尽量初始化时指定 Map 容量</h3><p>在尽可能的情况下，在使用 <code>make()</code> 初始化的时候提供容量信息</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2, hint)</span><br></pre></td></tr></table></figure><p>为 <code>make()</code> 提供容量信息（hint）尝试在初始化时调整 map 大小，<br>这减少了在将元素添加到 map 时增长和分配的开销。<br>注意，map 不能保证分配 hint 个容量。因此，即使提供了容量，添加元素仍然可以进行分配。 </p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]os.FileInfo)</span><br><span class="line"></span><br><span class="line">files, _ := ioutil.ReadDir(<span class="string">"./files"</span>)</span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> files &#123;</span><br><span class="line">    m[f.Name()] = f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">files, _ := ioutil.ReadDir(<span class="string">"./files"</span>)</span><br><span class="line"></span><br><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]os.FileInfo, <span class="built_in">len</span>(files))</span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> files &#123;</span><br><span class="line">    m[f.Name()] = f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><p><code>m</code> 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。</p></td><td><p><code>m</code> 是有大小提示创建的；在运行时可能会有更少的分配。</p></td></tr></tbody></table><h2 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h2><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断；</p><p>但是最重要的是，<strong>保持一致</strong>.</p><p>一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug</p><p>相反，一个单一的代码库会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、<br>代码审查痛苦、而且增加 bug 数量</p><p>将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。</p><h3 id="相似的声明放在一组"><a href="#相似的声明放在一组" class="headerlink" title="相似的声明放在一组"></a>相似的声明放在一组</h3><p>Go 语言支持将相似的声明放在一个组内。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"a"</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">"b"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"a"</span></span><br><span class="line">  <span class="string">"b"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>这同样适用于常量、变量和类型声明：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">const</span> a = <span class="number">1</span></span><br><span class="line"><span class="keyword">const</span> b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> a = <span class="number">1</span></span><br><span class="line"><span class="keyword">var</span> b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Area <span class="keyword">float64</span></span><br><span class="line"><span class="keyword">type</span> Volume <span class="keyword">float64</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  a = <span class="number">1</span></span><br><span class="line">  b = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  a = <span class="number">1</span></span><br><span class="line">  b = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> (</span><br><span class="line">  Area <span class="keyword">float64</span></span><br><span class="line">  Volume <span class="keyword">float64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>仅将相关的声明放在一组。不要将不相关的声明放在一组。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">  ENV_VAR = <span class="string">"MY_ENV"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> ENV_VAR = <span class="string">"MY_ENV"</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>分组使用的位置没有限制，例如：你可以在函数内部使用它们：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> red = color.New(<span class="number">0xff</span>0000)</span><br><span class="line">  <span class="keyword">var</span> green = color.New(<span class="number">0x00ff</span>00)</span><br><span class="line">  <span class="keyword">var</span> blue = color.New(<span class="number">0x0000ff</span>)</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> (</span><br><span class="line">    red   = color.New(<span class="number">0xff</span>0000)</span><br><span class="line">    green = color.New(<span class="number">0x00ff</span>00)</span><br><span class="line">    blue  = color.New(<span class="number">0x0000ff</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="import-分组"><a href="#import-分组" class="headerlink" title="import 分组"></a>import 分组</h3><p>导入应该分为两组：</p><ul><li>标准库</li><li>其他库</li></ul><p>默认情况下，这是 goimports 应用的分组。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"go.uber.org/atomic"</span></span><br><span class="line">  <span class="string">"golang.org/x/sync/errgroup"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line"></span><br><span class="line">  <span class="string">"go.uber.org/atomic"</span></span><br><span class="line">  <span class="string">"golang.org/x/sync/errgroup"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="包名"><a href="#包名" class="headerlink" title="包名"></a>包名</h3><p>当命名包时，请按下面规则选择一个名称：</p><ul><li>全部小写。没有大写或下划线。</li><li>大多数使用命名导入的情况下，不需要重命名。</li><li>简短而简洁。请记住，在每个使用的地方都完整标识了该名称。</li><li>不用复数。例如<code>net/url</code>，而不是<code>net/urls</code>。</li><li>不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。</li></ul><p>另请参阅 <a href="https://blog.golang.org/package-names" target="_blank" rel="noopener">Package Names</a> 和 <a href="https://rakyll.org/style-packages/" target="_blank" rel="noopener">Go 包样式指南</a>.</p><h3 id="函数名"><a href="#函数名" class="headerlink" title="函数名"></a>函数名</h3><p>我们遵循 Go 社区关于使用 <a href="https://golang.org/doc/effective_go.html#mixed-caps" target="_blank" rel="noopener">MixedCaps 作为函数名</a> 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：<code>TestMyFunction_WhatIsBeingTested</code>.</p><h3 id="导入别名"><a href="#导入别名" class="headerlink" title="导入别名"></a>导入别名</h3><p>如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"net/http"</span></span><br><span class="line"></span><br><span class="line">  client <span class="string">"example.com/client-go"</span></span><br><span class="line">  trace <span class="string">"example.com/trace/v2"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line"></span><br><span class="line">  nettrace <span class="string">"golang.net/x/trace"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"runtime/trace"</span></span><br><span class="line"></span><br><span class="line">  nettrace <span class="string">"golang.net/x/trace"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="函数分组与顺序"><a href="#函数分组与顺序" class="headerlink" title="函数分组与顺序"></a>函数分组与顺序</h3><ul><li>函数应按粗略的调用顺序排序。</li><li>同一文件中的函数应按接收者分组。</li></ul><p>因此，导出的函数应先出现在文件中，放在<code>struct</code>, <code>const</code>, <code>var</code>定义的后面。</p><p>在定义类型之后，但在接收者的其余方法之前，可能会出现一个 <code>newXYZ()</code>/<code>NewXYZ()</code> </p><p>由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Cost</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> calcCost(s.weights)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> something <span class="keyword">struct</span>&#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">calcCost</span><span class="params">(n []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Stop</span><span class="params">()</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSomething</span><span class="params">()</span> *<span class="title">something</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;something&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> something <span class="keyword">struct</span>&#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSomething</span><span class="params">()</span> *<span class="title">something</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;something&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Cost</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> calcCost(s.weights)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Stop</span><span class="params">()</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">calcCost</span><span class="params">(n []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;...&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="减少嵌套"><a href="#减少嵌套" class="headerlink" title="减少嵌套"></a>减少嵌套</h3><p>代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> data &#123;</span><br><span class="line">  <span class="keyword">if</span> v.F1 == <span class="number">1</span> &#123;</span><br><span class="line">    v = process(v)</span><br><span class="line">    <span class="keyword">if</span> err := v.Call(); err == <span class="literal">nil</span> &#123;</span><br><span class="line">      v.Send()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.Printf(<span class="string">"Invalid v: %v"</span>, v)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> data &#123;</span><br><span class="line">  <span class="keyword">if</span> v.F1 != <span class="number">1</span> &#123;</span><br><span class="line">    log.Printf(<span class="string">"Invalid v: %v"</span>, v)</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  v = process(v)</span><br><span class="line">  <span class="keyword">if</span> err := v.Call(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line">  v.Send()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="不必要的-else"><a href="#不必要的-else" class="headerlink" title="不必要的 else"></a>不必要的 else</h3><p>如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">int</span></span><br><span class="line"><span class="keyword">if</span> b &#123;</span><br><span class="line">  a = <span class="number">100</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  a = <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a := <span class="number">10</span></span><br><span class="line"><span class="keyword">if</span> b &#123;</span><br><span class="line">  a = <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="顶层变量声明"><a href="#顶层变量声明" class="headerlink" title="顶层变量声明"></a>顶层变量声明</h3><p>在顶层，使用标准<code>var</code>关键字。请勿指定类型，除非它与表达式的类型不同。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> _s <span class="keyword">string</span> = F()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"A"</span> &#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> _s = F()</span><br><span class="line"><span class="comment">// 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型</span></span><br><span class="line"><span class="comment">// 还是那种类型</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"A"</span> &#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果表达式的类型与所需的类型不完全匹配，请指定类型。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> myError <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(myError)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"error"</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">myError</span></span> &#123; <span class="keyword">return</span> myError&#123;&#125; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> _e error = F()</span><br><span class="line"><span class="comment">// F 返回一个 myError 类型的实例，但是我们要 error 类型</span></span><br></pre></td></tr></table></figure><h3 id="对于未导出的顶层常量和变量，使用-作为前缀"><a href="#对于未导出的顶层常量和变量，使用-作为前缀" class="headerlink" title="对于未导出的顶层常量和变量，使用_作为前缀"></a>对于未导出的顶层常量和变量，使用_作为前缀</h3><p>在未导出的顶级<code>vars</code>和<code>consts</code>， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。</p><p>例外：未导出的错误值，应以<code>err</code>开头。</p><p>基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  defaultPort = <span class="number">8080</span></span><br><span class="line">  defaultUser = <span class="string">"user"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// bar.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Bar</span><span class="params">()</span></span> &#123;</span><br><span class="line">  defaultPort := <span class="number">9090</span></span><br><span class="line">  ...</span><br><span class="line">  fmt.Println(<span class="string">"Default port"</span>, defaultPort)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// We will not see a compile error if the first line of</span></span><br><span class="line">  <span class="comment">// Bar() is deleted.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  _defaultPort = <span class="number">8080</span></span><br><span class="line">  _defaultUser = <span class="string">"user"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="结构体中的嵌入"><a href="#结构体中的嵌入" class="headerlink" title="结构体中的嵌入"></a>结构体中的嵌入</h3><p>嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Client <span class="keyword">struct</span> &#123;</span><br><span class="line">  version <span class="keyword">int</span></span><br><span class="line">  http.Client</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Client <span class="keyword">struct</span> &#123;</span><br><span class="line">  http.Client</span><br><span class="line"></span><br><span class="line">  version <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="使用字段名初始化结构体"><a href="#使用字段名初始化结构体" class="headerlink" title="使用字段名初始化结构体"></a>使用字段名初始化结构体</h3><p>初始化结构体时，几乎始终应该指定字段名称。现在由 <a href="https://golang.org/cmd/vet/" target="_blank" rel="noopener"><code>go vet</code></a> 强制执行。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k := User&#123;<span class="string">"John"</span>, <span class="string">"Doe"</span>, <span class="literal">true</span>&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">k := User&#123;</span><br><span class="line">    FirstName: <span class="string">"John"</span>,</span><br><span class="line">    LastName: <span class="string">"Doe"</span>,</span><br><span class="line">    Admin: <span class="literal">true</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>例外：如果有 3 个或更少的字段，则可以在测试表中省略字段名称。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  op Operation</span><br><span class="line">  want <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  &#123;Add, <span class="string">"add"</span>&#125;,</span><br><span class="line">  &#123;Subtract, <span class="string">"subtract"</span>&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="本地变量声明"><a href="#本地变量声明" class="headerlink" title="本地变量声明"></a>本地变量声明</h3><p>如果将变量明确设置为某个值，则应使用短变量声明形式 (<code>:=</code>)。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> s = <span class="string">"foo"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s := <span class="string">"foo"</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>但是，在某些情况下，<code>var</code> 使用关键字时默认值会更清晰。例如，声明空切片。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(list []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  filtered := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> _, v := <span class="keyword">range</span> list &#123;</span><br><span class="line">    <span class="keyword">if</span> v &gt; <span class="number">10</span> &#123;</span><br><span class="line">      filtered = <span class="built_in">append</span>(filtered, v)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(list []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> filtered []<span class="keyword">int</span></span><br><span class="line">  <span class="keyword">for</span> _, v := <span class="keyword">range</span> list &#123;</span><br><span class="line">    <span class="keyword">if</span> v &gt; <span class="number">10</span> &#123;</span><br><span class="line">      filtered = <span class="built_in">append</span>(filtered, v)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="nil-是一个有效的-slice"><a href="#nil-是一个有效的-slice" class="headerlink" title="nil 是一个有效的 slice"></a>nil 是一个有效的 slice</h3><p><code>nil</code> 是一个有效的长度为 0 的 slice，这意味着，</p><ul><li><p>您不应明确返回长度为零的切片。应该返回<code>nil</code> 来代替。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="string">""</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="string">""</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li><li><p>要检查切片是否为空，请始终使用<code>len(s) == 0</code>。而非 <code>nil</code>。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isEmpty</span><span class="params">(s []<span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> s == <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isEmpty</span><span class="params">(s []<span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">len</span>(s) == <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li><li><p>零值切片（用<code>var</code>声明的切片）可立即使用，无需调用<code>make()</code>创建。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">nums := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"><span class="comment">// or, nums := make([]int)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add1 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add2 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> nums []<span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add1 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add2 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li></ul><h3 id="小变量作用域"><a href="#小变量作用域" class="headerlink" title="小变量作用域"></a>小变量作用域</h3><p>如果有可能，尽量缩小变量作用范围。除非它与 <a href="#减少嵌套">减少嵌套</a>的规则冲突。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">err := ioutil.WriteFile(name, data, <span class="number">0644</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> err := ioutil.WriteFile(name, data, <span class="number">0644</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> data, err := ioutil.ReadFile(name); err == <span class="literal">nil</span> &#123;</span><br><span class="line">  err = cfg.Decode(data)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  fmt.Println(cfg)</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data, err := ioutil.ReadFile(name)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := cfg.Decode(data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(cfg)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="避免参数语义不明确-Avoid-Naked-Parameters"><a href="#避免参数语义不明确-Avoid-Naked-Parameters" class="headerlink" title="避免参数语义不明确(Avoid Naked Parameters)"></a>避免参数语义不明确(Avoid Naked Parameters)</h3><p>函数调用中的<code>意义不明确的参数</code>可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (<code>/* ... */</code>)</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func printInfo(name string, isLocal, done bool)</span></span><br><span class="line"></span><br><span class="line">printInfo(<span class="string">"foo"</span>, <span class="literal">true</span>, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func printInfo(name string, isLocal, done bool)</span></span><br><span class="line"></span><br><span class="line">printInfo(<span class="string">"foo"</span>, <span class="literal">true</span> <span class="comment">/* isLocal */</span>, <span class="literal">true</span> <span class="comment">/* done */</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>对于上面的示例代码，还有一种更好的处理方式是将上面的 <code>bool</code> 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Region <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  UnknownRegion Region = <span class="literal">iota</span></span><br><span class="line">  Local</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Status <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  StatusReady = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  StatusDone</span><br><span class="line">  <span class="comment">// Maybe we will have a StatusInProgress in the future.</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printInfo</span><span class="params">(name <span class="keyword">string</span>, region Region, status Status)</span></span></span><br></pre></td></tr></table></figure><h3 id="使用原始字符串字面值，避免转义"><a href="#使用原始字符串字面值，避免转义" class="headerlink" title="使用原始字符串字面值，避免转义"></a>使用原始字符串字面值，避免转义</h3><p>Go 支持使用 <a href="https://golang.org/ref/spec#raw_string_lit" target="_blank" rel="noopener">原始字符串字面值</a>，也就是 “ ` “ 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。</p><p>可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wantError := <span class="string">"unknown name:\"test\""</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wantError := <span class="string">`unknown error:"test"`</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="初始化-Struct-引用"><a href="#初始化-Struct-引用" class="headerlink" title="初始化 Struct 引用"></a>初始化 Struct 引用</h3><p>在初始化结构引用时，请使用<code>&amp;T{}</code>代替<code>new(T)</code>，以使其与结构体初始化一致。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sval := T&#123;Name: <span class="string">"foo"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// inconsistent</span></span><br><span class="line">sptr := <span class="built_in">new</span>(T)</span><br><span class="line">sptr.Name = <span class="string">"bar"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sval := T&#123;Name: <span class="string">"foo"</span>&#125;</span><br><span class="line"></span><br><span class="line">sptr := &amp;T&#123;Name: <span class="string">"bar"</span>&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="初始化-Maps"><a href="#初始化-Maps" class="headerlink" title="初始化 Maps"></a>初始化 Maps</h3><p>对于空 map 请使用 <code>make(..)</code> 初始化， 并且 map 是通过编程方式填充的。<br>这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  <span class="comment">// m1 读写安全;</span></span><br><span class="line">  <span class="comment">// m2 在写入时会 panic</span></span><br><span class="line">  m1 = <span class="keyword">map</span>[T1]T2&#123;&#125;</span><br><span class="line">  m2 <span class="keyword">map</span>[T1]T2</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  <span class="comment">// m1 读写安全;</span></span><br><span class="line">  <span class="comment">// m2 在写入时会 panic</span></span><br><span class="line">  m1 = <span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2)</span><br><span class="line">  m2 <span class="keyword">map</span>[T1]T2</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr><tr><td><p>声明和初始化看起来非常相似的。</p></td><td><p>声明和初始化看起来差别非常大。</p></td></tr></tbody></table><p>在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 <a href="#尽量初始化时指定-Map-容量">尽量初始化时指定 Map 容量</a>。</p><p>另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2, <span class="number">3</span>)</span><br><span class="line">m[k1] = v1</span><br><span class="line">m[k2] = v2</span><br><span class="line">m[k3] = v3</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m := <span class="keyword">map</span>[T1]T2&#123;</span><br><span class="line">  k1: v1,</span><br><span class="line">  k2: v2,</span><br><span class="line">  k3: v3,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 <code>make</code> (如果可以，请尽量指定 map 容量)。</p><h3 id="字符串-string-format"><a href="#字符串-string-format" class="headerlink" title="字符串 string format"></a>字符串 string format</h3><p>如果你为<code>Printf</code>-style 函数声明格式字符串，请将格式化字符串放在外面，并将其设置为<code>const</code>常量。</p><p>这有助于<code>go vet</code>对格式字符串执行静态分析。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">msg := <span class="string">"unexpected values %v, %v\n"</span></span><br><span class="line">fmt.Printf(msg, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> msg = <span class="string">"unexpected values %v, %v\n"</span></span><br><span class="line">fmt.Printf(msg, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="命名-Printf-样式的函数"><a href="#命名-Printf-样式的函数" class="headerlink" title="命名 Printf 样式的函数"></a>命名 Printf 样式的函数</h3><p>声明<code>Printf</code>-style 函数时，请确保<code>go vet</code>可以检测到它并检查格式字符串。</p><p>这意味着您应尽可能使用预定义的<code>Printf</code>-style 函数名称。<code>go vet</code>将默认检查这些。有关更多信息，请参见 <a href="https://golang.org/cmd/vet/#hdr-Printf_family" target="_blank" rel="noopener">Printf 系列</a>。</p><p>如果不能使用预定义的名称，请以 f 结束选择的名称：<code>Wrapf</code>，而不是<code>Wrap</code>。<code>go vet</code>可以要求检查特定的 Printf 样式名称，但名称必须以<code>f</code>结尾。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go vet -printfuncs=wrapf,statusf</span></span><br></pre></td></tr></table></figure><p>另请参阅 <a href="https://kuzminva.wordpress.com/2017/11/07/go-vet-printf-family-check/" target="_blank" rel="noopener">go vet: Printf family check</a>.</p><h2 id="编程模式"><a href="#编程模式" class="headerlink" title="编程模式"></a>编程模式</h2><h3 id="表驱动测试"><a href="#表驱动测试" class="headerlink" title="表驱动测试"></a>表驱动测试</h3><p>当测试逻辑是重复的时候，通过  <a href="https://blog.golang.org/subtests" target="_blank" rel="noopener">subtests</a> 使用 table 驱动的方式编写 case 代码看上去会更简洁。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func TestSplitHostPort(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">host, port, err := net.SplitHostPort(<span class="string">"192.0.2.0:8000"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"192.0.2.0"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8000"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">"192.0.2.0:http"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"192.0.2.0"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"http"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">":8000"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">""</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8000"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">"1:8"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"1"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8"</span>, port)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func TestSplitHostPort(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  give     <span class="keyword">string</span></span><br><span class="line">  wantHost <span class="keyword">string</span></span><br><span class="line">  wantPort <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"192.0.2.0:8000"</span>,</span><br><span class="line">    wantHost: <span class="string">"192.0.2.0"</span>,</span><br><span class="line">    wantPort: <span class="string">"8000"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"192.0.2.0:http"</span>,</span><br><span class="line">    wantHost: <span class="string">"192.0.2.0"</span>,</span><br><span class="line">    wantPort: <span class="string">"http"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">":8000"</span>,</span><br><span class="line">    wantHost: <span class="string">""</span>,</span><br><span class="line">    wantPort: <span class="string">"8000"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"1:8"</span>,</span><br><span class="line">    wantHost: <span class="string">"1"</span>,</span><br><span class="line">    wantPort: <span class="string">"8"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, tt := <span class="keyword">range</span> tests &#123;</span><br><span class="line">  t.Run(tt.give, <span class="function"><span class="keyword">func</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">    host, port, err := net.SplitHostPort(tt.give)</span><br><span class="line">    require.NoError(t, err)</span><br><span class="line">    assert.Equal(t, tt.wantHost, host)</span><br><span class="line">    assert.Equal(t, tt.wantPort, port)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。</p><p>我们遵循这样的约定：将结构体切片称为<code>tests</code>。 每个测试用例称为<code>tt</code>。此外，我们鼓励使用<code>give</code>和<code>want</code>前缀说明每个测试用例的输入和输出值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  give     <span class="keyword">string</span></span><br><span class="line">  wantHost <span class="keyword">string</span></span><br><span class="line">  wantPort <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, tt := <span class="keyword">range</span> tests &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="功能选项"><a href="#功能选项" class="headerlink" title="功能选项"></a>功能选项</h3><p>功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。</p><p>将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// package db</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Connect</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  addr <span class="keyword">string</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  timeout time.Duration,</span></span></span><br><span class="line"><span class="function"><span class="params">  caching <span class="keyword">bool</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*Connection, error)</span></span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Timeout and caching must always be provided,</span></span><br><span class="line"><span class="comment">// even if the user wants to use the default.</span></span><br><span class="line"></span><br><span class="line">db.Connect(addr, db.DefaultTimeout, db.DefaultCaching)</span><br><span class="line">db.Connect(addr, newTimeout, db.DefaultCaching)</span><br><span class="line">db.Connect(addr, db.DefaultTimeout, <span class="literal">false</span> <span class="comment">/* caching */</span>)</span><br><span class="line">db.Connect(addr, newTimeout, <span class="literal">false</span> <span class="comment">/* caching */</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> options <span class="keyword">struct</span> &#123;</span><br><span class="line">  timeout time.Duration</span><br><span class="line">  caching <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Option overrides behavior of Connect.</span></span><br><span class="line"><span class="keyword">type</span> Option <span class="keyword">interface</span> &#123;</span><br><span class="line">  apply(*options)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> optionFunc <span class="function"><span class="keyword">func</span><span class="params">(*options)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(f optionFunc)</span> <span class="title">apply</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">  f(o)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(t time.Duration)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> optionFunc(<span class="function"><span class="keyword">func</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">    o.timeout = t</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCaching</span><span class="params">(cache <span class="keyword">bool</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> optionFunc(<span class="function"><span class="keyword">func</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">    o.caching = cache</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Connect creates a connection.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Connect</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  addr <span class="keyword">string</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  opts ...Option,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*Connection, error)</span></span> &#123;</span><br><span class="line">  options := options&#123;</span><br><span class="line">    timeout: defaultTimeout,</span><br><span class="line">    caching: defaultCaching,</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, o := <span class="keyword">range</span> opts &#123;</span><br><span class="line">    o.apply(&amp;options)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Options must be provided only if needed.</span></span><br><span class="line"></span><br><span class="line">db.Connect(addr)</span><br><span class="line">db.Connect(addr, db.WithTimeout(newTimeout))</span><br><span class="line">db.Connect(addr, db.WithCaching(<span class="literal">false</span>))</span><br><span class="line">db.Connect(</span><br><span class="line">  addr,</span><br><span class="line">  db.WithCaching(<span class="literal">false</span>),</span><br><span class="line">  db.WithTimeout(newTimeout),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>还可以参考下面资料：</p><ul><li><a href="https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html" target="_blank" rel="noopener">Self-referential functions and the design of options</a></li><li><a href="https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis" target="_blank" rel="noopener">Functional options for friendly APIs</a></li></ul><!-- TODO: replace this with parameter structs and functional options, when touse one vs other -->]]></content>
      
      
      <categories>
          
          <category> 编码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编码规范 </tag>
            
            <tag> Go </tag>
            
            <tag> Uber </tag>
            
            <tag> Style </tag>
            
            <tag> Guide </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[译]Spring WebFlux vs Spring MVC</title>
      <link href="/spring-webflux-vs-spring-mvc.html"/>
      <url>/spring-webflux-vs-spring-mvc.html</url>
      
        <content type="html"><![CDATA[<p>Spring MVC or WebFlux?</p><a id="more"></a><p><img src="/images/spring-webflux-vs-spring-mvc/spring-mvc-and-webflux-venn.png" alt></p><ul><li><font color="DeepPink"><strong>如果你的Spring MVC应用运行良好，则不需要改变。</strong></font>Spring MVC更容易编写、理解、调试，可以选择更多的库，因为目前大多数库都是阻塞的。<!-- * If you are already shopping for a non-blocking web stack, Spring WebFlux offers the same execution model benefits as others in this space and also provides a choice of servers (Netty, Tomcat, Jetty, Undertow, and Servlet 3.1+ containers), a choice of programming models (annotated controllers and functional web endpoints), and a choice of reactive libraries (Reactor, RxJava, or other). --></li><li>如果你对轻量的web框架感兴趣，并希望使用Java 8 lambdas或者Kotlin，则可以选择Spring WebFlux。对于小型应用程序或微服务来说，这也是一个不错的选择，因为它们可以从更大的透明性（transparency）和控制中获益。</li><li>在微服务体系架构中，可以混合使用带有Spring MVC或Spring WebFlux控制器或Spring WebFlux 函数式的应用程序。在两个框架中都支持相同的基于注释的编程模型，这使得重用知识更容易，同时也为正确的工作选择了正确的工具。</li><li>评估的一个简单方法是检查应用的依赖项。 <font color="DeepPink"><strong>如果你要使用阻塞持久性APIs (JPA、JDBC)或网络APIs，那么Spring MVC至少是通用架构的最佳选择。</strong></font>在技术上，Reactor和RxJava都可以在单独的线程上执行阻塞调用，但这时就无法充分利用非阻塞网络栈。</li><li><font color="DeepPink"><strong>如果你的Spring MVC应用程序需要远程调用别的服务，请尝试reactive WebClient。</strong></font>你可以直接从Spring MVC控制器方法返回反应类型（Reactor、RxJava或其他）。每次调用的延迟或调用之间的相互依赖性越大，好处就越显著。Spring MVC控制器也可以调用其他响应性组件。</li><li><font color="DeepPink"><strong>如果你有一个大型团队，请记住向非阻塞、函数式和声明式编程转变的陡峭学习曲线。一种不需要完全切换的实用方法是使用响应式的WebClient。</strong></font>除此之外，从小处着手，衡量收益。我们认为，对于广泛的应用程序，这种转变是不必要的。如果你不确定要寻找什么好处，可以从学习非阻塞I/O的工作原理（例如，在单线程Node.js上的并发性）及其效果开始。</li></ul><p>原文地址：<br><a href="https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html" target="_blank" rel="noopener">https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Spring </tag>
            
            <tag> WebFlux </tag>
            
            <tag> MVC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch Scroll and Search After</title>
      <link href="/elasticsearch-scroll-and-search-after.html"/>
      <url>/elasticsearch-scroll-and-search-after.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Elasticsearch From/Size、Scroll、Search After对比</p></blockquote><a id="more"></a><h1 id="From-Size"><a href="#From-Size" class="headerlink" title="From/Size"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-from-size" target="_blank" rel="noopener">From/Size</a></h1><p>可以使用from和size参数对结果进行分页。from参数定义要获取的第一个结果的偏移量。 size 参数允许您配置要返回的最大匹配数。</p><blockquote><p>简单来说，需要查询from + size 的条数时，coordinate node就向该index的其余的shards 发送同样的请求，等汇总到（shards * （from + size））条数时在coordinate node再做一次排序，最终抽取出真正的 from 后的 size 条结果。</p></blockquote><blockquote><p>注意from + size 不能超过 index.max_result_window 索引设置，默认为 10,000。 有关深入滚动的更有效方法，请参阅 Scroll 或 Search After API。</p></blockquote><h1 id="Search-Type"><a href="#Search-Type" class="headerlink" title="Search Type"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-body.html#request-body-search-search-type" target="_blank" rel="noopener">Search Type</a></h1><p>在执行分布式搜索时可以执行不同的执行路径。分布式搜索操作需要分散到所有相关的shard，然后收集所有的结果。当使用分散/集中类型执行时，有几种方法可以做到这一点，特别是使用搜索引擎。</p><p>执行分布式搜索时的一个问题是从每个shard检索多少结果。例如，如果我们有 10 个shard，则第一个shard可能保存从 0 到 10 的最相关的结果，而其他shard的结果排在后面。因此，在执行请求时，我们需要从所有shard中获取从0到10的结果，对它们进行排序，然后返回结果(如果我们希望确保得到正确的结果)。</p><p>与搜索引擎相关的另一个问题是每个shard独立存在的事实。当在特定shard上执行查询时，它不会考虑来自其他shard上term频率及（其他shard上）搜索引擎的信息。如果我们想要支持准确的排名，我们需要首先收集所有shard中的term频率，以计算全局term频率，然后使用这些term频率对每个shard执行查询。</p><p>此外，由于需要对结果进行排序，在维护正确的排序行为的同时，获取大型文档集，甚至是滚动它，可能是一个非常昂贵的操作。对于大型结果集滚动，如果返回文档的顺序不重要，则最好按_doc排序。</p><p>Elasticsearch非常灵活，可以根据每个搜索请求控制执行的搜索类型。可以通过设置查询字符串中的search_type参数来配置类型。类型是:</p><h2 id="Query-Then-Fetchedit"><a href="#Query-Then-Fetchedit" class="headerlink" title="Query Then Fetchedit"></a>Query Then Fetchedit</h2><p>参数值： query_then_fetch。</p><p>请求分两个阶段处理。 在第一阶段，查询被转发到所有涉及的分片。 每个分片执行搜索并生成对该分片本地的结果的排序列表。 <font color="DeepPink"><strong>每个分片只向协调节点返回足够的信息，以允许其合并并将分片级结果重新排序为全局排序的最大长度大小的结果集。</strong></font></p><p>在第二阶段期间，<font color="DeepPink"><strong>协调节点仅从相关分片请求文档内容（以及高亮显示的片段，如果有的话）。</strong></font></p><blockquote><p>如果您未在请求中指定 search_type，那么这是默认设置。</p></blockquote><h2 id="Dfs-Query-Then-Fetch"><a href="#Dfs-Query-Then-Fetch" class="headerlink" title="Dfs, Query Then Fetch"></a>Dfs, Query Then Fetch</h2><p>参数值：dfs_query_then_fetch</p><p>与 “Query Then Fetch” 相同，除了初始分散阶段，该阶段计算分布式term频率以获得更准确的评分。</p><blockquote><p>Scroll与Search After 都依赖于Search Type</p></blockquote><h1 id="Search-After"><a href="#Search-After" class="headerlink" title="Search After"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-search-after" target="_blank" rel="noopener">Search After</a></h1><p>在<a href="https://www.jiankunking.com/log-service-architecture-design.html" target="_blank" rel="noopener">日志服务架构设计</a>中日志搜索后翻页、日志上下文的功能就是通过search_after实现的。</p><p>在官网文档中可以看出Search After有以下特点：</p><ul><li>实时</li><li>可以深度分页（使用前一页的结果来帮助检索下一页）</li><li>不支持跳页</li></ul><blockquote><p>注意：每个文档具有一个唯一值的字段应用作排序规范的仲裁。 否则，具有相同排序值的文档的排序顺序将是未定义的。 建议的方法是使用字段 _uid（elasticsearch 6.x _uid 废弃 替换为_id），它确保每个文档包含一个唯一值。</p></blockquote><h1 id="Scroll"><a href="#Scroll" class="headerlink" title="Scroll"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-scroll" target="_blank" rel="noopener">Scroll</a></h1><p>虽然搜索请求返回单个 “page” 的结果，但是滚动 API 可以用于从<font color="DeepPink"><strong>单个搜索请求</strong></font>中检索大量结果（甚至是所有结果），与在传统数据库上使用游标的方式大致相同。</p><p>滚动不是用于实时用户请求，而是用于处理大量数据，例如， 以便将一个索引的内容重新索引到具有不同配置的新索引中。</p><blockquote><p>从滚动请求返回的结果反映了进行初始搜索请求时索引的状态，如时间快照。 对文档（索引，更新或删除）的后续更改只会影响以后的搜索请求。</p></blockquote><p>可以把 scroll 分为初始化和遍历两步，初始化时将所有符合搜索条件的搜索结果缓存起来，可以想象成快照，在遍历时，从这个快照里取数据，也就是说，在初始化后对索引插入、删除、更新数据都不会影响遍历结果。</p><blockquote><p>滚动请求具有优化，使排序顺序为_doc时更快。 如果你想迭代所有文档，无论顺序如何，这是最有效的选择：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?scroll=1m</span><br><span class="line">&#123;</span><br><span class="line">  &quot;sort&quot;: [</span><br><span class="line">    &quot;_doc&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Keeping-the-search-context-alive"><a href="#Keeping-the-search-context-alive" class="headerlink" title="Keeping the search context alive"></a>Keeping the search context alive</h2><p>滚动参数（传递到搜索请求和每个滚动请求）告诉Elasticsearch应该保持搜索上下文活动的时间。其值（例如，1m，请参阅 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/common-options.html#time-units" target="_blank" rel="noopener">“Time unit”</a> 一节）不需要足够长以处理所有数据 - 它只需要足够长的时间来处理前一批结果。每个滚动请求（具有滚动参数）设置新的到期时间。</p><p>通常，后台合并过程通过将较小的段合并在一起以创建新的较大段来优化索引，此时较小的段被删除。此过程在滚动期间继续，但是打开的搜索上下文防止旧段在它们仍在使用时被删除。这就是Elasticsearch如何能够返回初始搜索请求的结果，而不考虑对文档的后续更改。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>如果要做非常多页的查询时，search after是一个常量查询延迟和开销，并无什么副作用，可是，就像要查询结果全量导出那样，要在短时间内不断重复同一查询成百甚至上千次，效率就显得非常低了。</p><blockquote><p>本文内容来自官方文档，主要是做了翻译及汇总。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ElasticSearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> ElasticSearch </tag>
            
            <tag> Query </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务理想国</title>
      <link href="/microservice-ideal-country.html"/>
      <url>/microservice-ideal-country.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>微服务的现在、未来</p></blockquote><a id="more"></a><h1 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h1><ul><li><a href="https://jenkins.io/zh/" target="_blank" rel="noopener">Jenkins</a> CI&amp;CD</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a> 调度、负载、高可用<ul><li>自动化容器的部署和复制</li><li>随时扩展或收缩容器规模</li><li>将容器组织成组，并且提供容器间的负载均衡</li><li>很容易地升级应用程序容器的新版本</li><li>提供容器弹性，如果容器失效就替换它，等等…</li></ul></li><li><a href="https://istio.io/" target="_blank" rel="noopener">Istio</a> 监控、熔断、限流<ul><li>流量管理（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能</li><li>安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密。</li><li>控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配。</li><li>观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</li></ul></li><li><a href="http://skywalking.apache.org/zh/" target="_blank" rel="noopener">SkyWalking</a> 监控<ul><li>分布式系统的应用程序性能监视工具</li></ul></li><li>收集Kubernetes Pod日志到<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener">ElasticSearch</a>进行日志检索</li><li>通过<a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>监控机器、实例的运行情况</li><li>通过<a href="https://prometheus.io/docs/alerting/alertmanager/" target="_blank" rel="noopener">Alertmanager</a>将监控信息进行告警</li></ul><p>其中最重要的Kubernetes服务，<a href="https://cloud.tencent.com/product/tke" target="_blank" rel="noopener">腾讯云</a>、<a href="https://www.aliyun.com/product/kubernetes?spm=5176.13342246.1kquk9v2l.2.42243ccbAwomc4&aly_as=i7TpRzFx" target="_blank" rel="noopener">阿里云</a>都已经支持。</p><p>微服务的未来应该是开发人员只需要写Sping Boot或者Gin/Iris应用就可以了，剩下的就交给Kubernetes。</p><h1 id="Spring-Cloud-Kubernetes"><a href="#Spring-Cloud-Kubernetes" class="headerlink" title="Spring Cloud/Kubernetes"></a>Spring Cloud/Kubernetes</h1><p><img src="/images/microservice-ideal-country/Spring-Cloud.png" alt></p><h1 id="Istio-Knowledge-Map"><a href="#Istio-Knowledge-Map" class="headerlink" title="Istio Knowledge Map"></a>Istio Knowledge Map</h1><p>下图转自：<a href="https://github.com/servicemesher/istio-knowledge-map/blob/master/png/istio-knowledge-map.png" target="_blank" rel="noopener">istio-knowledge-map</a><br><img src="/images/microservice-ideal-country/istio-knowledge-map.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> Microservice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Explain</title>
      <link href="/mysql-explain.html"/>
      <url>/mysql-explain.html</url>
      
        <content type="html"><![CDATA[<p>Explain SQL</p><a id="more"></a><p>语法：explain + SQL</p><p>参数：</p><table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>type</td><td>system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all（至少达到 range 级别，最好达到 ref 级别）</td></tr><tr><td>possible_keys</td><td>显示可能应用在这张表中的索引</td></tr><tr><td>rows</td><td>扫描行数，越小越好</td></tr></tbody></table><p>说明：</p><ul><li>consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。</li><li>ref 指的是使用普通的索引（normal index）。</li><li>range 对索引进行范围检索。</li></ul><blockquote><p>反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比 range还低，与全表扫描是小巫见大巫。</p></blockquote><p>Extra字段显示Using temporary，表示的是需要使⽤临时表；Using filesort，表示的是需要执⾏排序操作。</p><p>推荐阅读阿里巴巴开发手册MySQL部分：<a href="/attachments/阿里巴巴Java开发手册（华山版）.pdf" target="_blank">阿里巴巴Java开发手册（华山版）.pdf</a></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Explain </tag>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Final</title>
      <link href="/java-final.html"/>
      <url>/java-final.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Java Final 内存语义</p></blockquote><a id="more"></a><h1 id="读"><a href="#读" class="headerlink" title="读"></a>读</h1><p>初次读对象引用与初次读该对象包含的final域，这两个操作之间存在间接依赖关系。由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，也不会重排序这两个操作。但有少数处理器允许对存在间接依赖关系的操作做重排序（比如alpha处理器），这个规则就是专门用来针对这种处理器的。</p><h1 id="写"><a href="#写" class="headerlink" title="写"></a>写</h1><p>在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中“逸出”。</p><h1 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h1><p><a href="https://dzone.com/articles/final-keyword-and-jvm-memory-impact" target="_blank" rel="noopener">final-keyword-and-jvm-memory-impact</a></p><p>在线JSR：<a href="/attachments/jsr133.pdf" target="_blank">JSR 133:3.2 Final Fields（第九页）</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Final </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机存储单位换算</title>
      <link href="/unit-conversion.html"/>
      <url>/unit-conversion.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>bit、byte、KB、MB、GB</p></blockquote><a id="more"></a><p>常见的单位换算如下：</p><ul><li>1 byte = 8 bit</li><li>1 KB = 2<sup>10</sup> byte = 1024 byte ≈ 10<sup>3</sup> byte</li><li>1 MB = 2<sup>20</sup> byte ≈ 10 <sup>6</sup> byte</li><li>1 GB = 2<sup>30</sup> byte ≈ 10 <sup>9</sup> byte</li><li>1 亿 = 10<sup>8</sup></li></ul><p>1 个整数占 4 byte，1 亿个整数占 4*10<sup>8</sup> byte ≈ 400 MB。</p>]]></content>
      
      
      <categories>
          
          <category> Basic </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Basic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>客户中心实现分析</title>
      <link href="/customer-center-design.html"/>
      <url>/customer-center-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>客户中心梳理</p></blockquote><a id="more"></a><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>客户数据分散在多个系统之间，而这多个系统中又有三个最为主要的系统：365、Y、E。</p><ul><li>365的客户账号登陆用的是CAS</li><li>E、Y系统定时同步CAS数据，自己维护了一份数据</li></ul><p>客户中心的目的是实现客户维度的账户数据统一，以替换掉目前客户多套账户数据，系统之间通过数据表同步实现账户数据同步的现状。</p><p>从客户中心的名称中就可以知道，该部分对应的主体是客户，而非平常To C的用户。</p><blockquote><p>这里的客户账号主要是公司的经销商、各级门店的员工。</p></blockquote><p>客户与To C用户两者之间最大的区别在于：账号注册、账户管理的不同。客户账号的注册主要是通过分配，而非自己注册。</p><h1 id="服务层面"><a href="#服务层面" class="headerlink" title="服务层面"></a>服务层面</h1><p>服务主要拆分为以下几部分：</p><ul><li>OpenApi：客户中心网关、OAuth部分</li><li>账户服务：与账户相关的服务</li><li>短信服务：<ul><li>将集团Web Services短信服务转换成HTTP REST服务（下面简称SMS服务）</li><li>Nginx 代理（组内服务发送短信是调用SMS服务，SMS服务再通过Nginx代理调用集团短信服务）</li></ul></li><li>后台管理服务：公告通知</li></ul><p>更新细致的描述如下图：<br><img src="/images/customer-center-design/%E5%AE%A2%E6%88%B7%E4%B8%AD%E5%BF%83%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.png" alt="服务架构图"></p><h1 id="OAuth"><a href="#OAuth" class="headerlink" title="OAuth"></a>OAuth</h1><!-- > 本文OAuth 2.0的授权类型为授权码（OAuth 2.0 Grant Types：Authorization Code） --><p>OAuth部分主要是熟悉下面这个图，只是有时扮演OAuth Server、有时扮演OAuth Client而已。</p><blockquote><p>比如微信登陆，OpenApi就是微信OAuth Server的client。</p></blockquote><p><img src="/images/customer-center-design/oauth_web_server_flow.png" alt="Authorization Code"></p><p>OAuth涉及的点有：</p><ul><li>Authorization Code：有效期内只能使用一次</li><li>Access Token是采用JWT还是一个随机字符串？<ul><li>JWT不依赖存储，但一旦颁发无法取消其有效性</li><li>随机字符串一般都是一个字符ID，具体的数据是存储在Redis中</li></ul></li><li>OAuth 框架选择<ul><li>Java<ul><li><a href="https://github.com/spring-projects/spring-security" target="_blank" rel="noopener">Spring Security</a></li><li><a href="http://shiro.apache.org" target="_blank" rel="noopener">Shiro</a></li></ul></li><li>Golang<ul><li><a href="https://github.com/openshift/osin" target="_blank" rel="noopener">OpenShift OSIN</a></li><li>……</li></ul></li></ul></li></ul><h2 id="OAuth-Server"><a href="#OAuth-Server" class="headerlink" title="OAuth Server"></a>OAuth Server</h2><p>OAuth Server需要做以下事情：</p><ul><li>/authorize接口，负责校验是否登录（比如校验Header中bear令牌）<ul><li>已登录，设置Cookie，跳转请求authorize接口参数中的redirect_uri并携带code及state</li><li>未登录，跳转鉴权中心的登陆页<ul><li>用户在鉴权中心的登录页输入用户名密码,校验通过，跳转请求authorize接口参数中的redirect_uri并携带code及state</li></ul></li></ul></li><li>/token接口，负责校验code，颁发access_token及refresh_token</li><li>/refresh_token接口，负责通过refresh_token刷新access_token</li><li>/logout接口，清理Cookie</li></ul><blockquote><p>code分为两种情况：一种是通过浏览器传递给接入方后端；一种是通过移动端获取到code后，通过调用接入方后端接口传递给接入方后端。<br>redirect_uri、post_logout_redirect_uri 需要校验是否与配置的一样。</p></blockquote><h2 id="OAuth-Client"><a href="#OAuth-Client" class="headerlink" title="OAuth Client"></a>OAuth Client</h2><p>OAuth Client对接OAuth Server需要做以下事情：</p><ul><li>拦截请求，校验是否已登录<ul><li>已登录，放行</li><li>未登录，跳转OAuth Server的/authorize接口接口<ul><li>根据code获取用户信息，设置Cookie、颁发自己的token（access_token、refresh_token）</li></ul></li></ul></li><li>/token接口，调用鉴权中心的密码模式校验密码，获取用户信息，颁发access_token、refresh_token</li><li>/refresh_token接口，负责通过refresh_token刷新access_token</li><li>对于Web端而言，打开首页的时候，先调用me或者profile等接口获取用户信息<ul><li>如果能获取到，则意味着登录成功</li><li>如果获取不到，则前端调用后端/login接口<ul><li>后端/login接口（接口需要传递参数redirect_uri）校验是否登录<ul><li>未登录，跳转鉴权中心的登陆页</li><li>已登录，跳转参数redirect_uri</li></ul></li></ul></li></ul></li><li>对于移动端而言，调用/token接口</li><li>/logout接口，清理自己设置的Cookie，再调用鉴权中心的登出接口</li><li>/callback接口，供OAuth Server回调</li></ul><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>从服务架构图中可以看出，业务逻辑最复杂的是账户服务。</p><p>账户服务的复杂的地方主要在：</p><ul><li>数据清理逻辑服务（多系统账户合并）</li><li>多系统迭代替换时间不一致</li></ul><h2 id="账户合并"><a href="#账户合并" class="headerlink" title="账户合并"></a>账户合并</h2><p>下面简单说一下多系统账户合并的逻辑：</p><ul><li>多账户合并在账户首次登陆的时候进行（账户登录，需要区分出是否是首次登陆）</li><li>检验账户是否需要合并的逻辑是：当前登陆账户名、手机号在多个系统之间重复<ul><li>账户名登陆不仅仅需要校验账户名，还需要校验账户名对应的手机号</li><li>手机号登陆不仅仅需要校验手机号，还需要校验手机号对应的账户名</li></ul></li><li>重复账户数据选择、修改、补充合并</li></ul><blockquote><p>这部分开发的时候，有个坑就是业务人员本身不熟悉自己的业务，合并的细节基本都是开发人员通过数据库数据自己梳理，再与业务人员确认。</p></blockquote><h2 id="切换"><a href="#切换" class="headerlink" title="切换"></a>切换</h2><p>系统很多，但登陆用到的主要有两部分：</p><ul><li>CAS登陆（大部分系统客户用的都是CAS登陆）</li><li>Y、E系统，该系统自己维护了一份客户账号数据</li></ul><p>初始的计划是在一期将所有系统客户登陆统一替换掉，后来由于Y、E系统自身业务优先级的原因，无法参与这次切换，又将替换范围调整为替换CAS。</p><p>业务范围调整造成了两个影响：</p><ul><li>不需要多系统账号合并</li><li>业务范围调整的时候，账户服务根据之前的逻辑已经开发完成</li></ul><p>这就引入了另一个问题，虽然最复杂的多系统账户合并不要了，但很多的功能点在CAS替换与多系统统一替换中基本都是一样的（由于需要合并多个系统间的账户数据，而多个系统目前的账户数据又是千奇百怪，所以根据账户数据来源的不同，分别存储在不同的表中，所以对于账户数据的操作这部分需要再次开发）。简单的CTRL+C CTRL+V再复制一份，再在公共部分加一些if else？还是通过别的方式实现？</p><p>主要的重复点在：</p><ul><li>账户绑定手机号</li><li>账户登录</li><li>账户密码通过手机号重置</li><li>发送短信验证码</li></ul><p>基本上都是输入一样，但最终处理的时候校验、操作的表都有所不同，这个可以通过命令模式来处理。</p><p>将统一账户的处理逻辑、CAS账户的处理逻辑分别放置到Receiver中，通过不同的Command来起到隔离而又不会重复代码的作用。 </p><blockquote><p>命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。</p></blockquote><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><h2 id="短信发送"><a href="#短信发送" class="headerlink" title="短信发送"></a>短信发送</h2><p>1、线程池发送（以防短信服务不稳，造成OOM,设定BlockingQueue长度）<br>2、抽象短信服务基类BaseVerificationCodeSender，因为有可能对接多个短信服务，但线程池及需要做的事是一样的。</p><p><img src="/images/customer-center-design/CocSmsVerificationCodeSender.png" alt="具体的实现类"></p><h2 id="验证码校验"><a href="#验证码校验" class="headerlink" title="验证码校验"></a>验证码校验</h2><p>由于集团短信服务不太稳定，所以每类（登陆、忘记密码、修改手机号等）验证码缓存最多三个未过期的短信验证码。</p><blockquote><p>只要验证了一个，该手机号缓存某类的验证码，均失效。</p></blockquote><h2 id="其它-1"><a href="#其它-1" class="headerlink" title="其它"></a>其它</h2><p>略</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+--------+                               +---------------+</span><br><span class="line">|        |--(A)- Authorization Request -&gt;|   Resource    |</span><br><span class="line">|        |                               |     Owner     |</span><br><span class="line">|        |&lt;-(B)-- Authorization Grant ---|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(C)-- Authorization Grant --&gt;| Authorization |</span><br><span class="line">| Client |                               |     Server    |</span><br><span class="line">|        |&lt;-(D)----- Access Token -------|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(E)----- Access Token ------&gt;|    Resource   |</span><br><span class="line">|        |                               |     Server    |</span><br><span class="line">|        |&lt;-(F)--- Protected Resource ---|               |</span><br><span class="line">+--------+                               +---------------+</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> OAuth </tag>
            
            <tag> Login </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 知识点 概要</title>
      <link href="/mysql-schema.html"/>
      <url>/mysql-schema.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>B+ Tree、索引、Explain、InnoDB、MyISAM、Sharding</p></blockquote><a id="more"></a><h1 id="一、索引"><a href="#一、索引" class="headerlink" title="一、索引"></a>一、索引</h1><h2 id="B-Tree-原理"><a href="#B-Tree-原理" class="headerlink" title="B+ Tree 原理"></a>B+ Tree 原理</h2><h3 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1. 数据结构"></a>1. 数据结构</h3><p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p><p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。</p><p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 key<sub>i</sub> 和 key<sub>i+1</sub>，且不为 null，则该指针指向节点的所有 key 大于等于 key<sub>i</sub> 且小于等于 key<sub>i+1</sub>。</p><div align="center"> <img src="/images/mysql-schema/33576849-9275-47bb-ada7-8ded5f5e7c73.png" width="350px"> </div><br><h3 id="2-操作"><a href="#2-操作" class="headerlink" title="2. 操作"></a>2. 操作</h3><p>进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。</p><p>插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。</p><h3 id="3-与红黑树的比较"><a href="#3-与红黑树的比较" class="headerlink" title="3. 与红黑树的比较"></a>3. 与红黑树的比较</h3><p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：</p><p>（一）更少的查找次数</p><p>平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(log<sub>d</sub>N)，其中 d 为每个节点的出度。</p><p>红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。</p><p>（二）利用磁盘预读特性</p><p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。</p><p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。</p><h2 id="MySQL-索引"><a href="#MySQL-索引" class="headerlink" title="MySQL 索引"></a>MySQL 索引</h2><p>索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。</p><h3 id="1-B-Tree-索引"><a href="#1-B-Tree-索引" class="headerlink" title="1. B+Tree 索引"></a>1. B+Tree 索引</h3><p>是大多数 MySQL 存储引擎的默认索引类型。</p><p>因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。</p><p>因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。</p><p>可以指定多个列作为索引列，多个索引列共同组成键。</p><p>适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。</p><p>InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。</p><div align="center"> <img src="/images/mysql-schema/45016e98-6879-4709-8569-262b2d6d60b9.png" width="350px"> </div><br><p>辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。</p><div align="center"> <img src="/images/mysql-schema/7c349b91-050b-4d72-a7f8-ec86320307ea.png" width="350px"> </div><br><h3 id="2-哈希索引"><a href="#2-哈希索引" class="headerlink" title="2. 哈希索引"></a>2. 哈希索引</h3><p>哈希索引能以 O(1) 时间进行查找，但是失去了有序性：</p><ul><li>无法用于排序与分组；</li><li>只支持精确查找，无法用于部分查找和范围查找。</li></ul><p>InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。</p><h3 id="3-全文索引"><a href="#3-全文索引" class="headerlink" title="3. 全文索引"></a>3. 全文索引</h3><p>MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。</p><p>查找条件使用 MATCH AGAINST，而不是普通的 WHERE。</p><p>全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。</p><p>InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。</p><h3 id="4-空间数据索引"><a href="#4-空间数据索引" class="headerlink" title="4. 空间数据索引"></a>4. 空间数据索引</h3><p>MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。</p><p>必须使用 GIS 相关的函数来维护数据。</p><h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><h3 id="1-独立的列"><a href="#1-独立的列" class="headerlink" title="1. 独立的列"></a>1. 独立的列</h3><p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。</p><p>例如下面的查询不能使用 actor_id 列的索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> actor_id <span class="keyword">FROM</span> sakila.actor <span class="keyword">WHERE</span> actor_id + <span class="number">1</span> = <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h3 id="2-多列索引"><a href="#2-多列索引" class="headerlink" title="2. 多列索引"></a>2. 多列索引</h3><p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> film_id, actor_ <span class="keyword">id</span> <span class="keyword">FROM</span> sakila.film_actor</span><br><span class="line"><span class="keyword">WHERE</span> actor_id = <span class="number">1</span> <span class="keyword">AND</span> film_id = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h3 id="3-索引列的顺序"><a href="#3-索引列的顺序" class="headerlink" title="3. 索引列的顺序"></a>3. 索引列的顺序</h3><p>让选择性最强的索引列放在前面。</p><p>索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。</p><p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> staff_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> staff_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> customer_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> payment;</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">   staff_id_selectivity: 0.0001</span><br><span class="line">customer_id_selectivity: 0.0373</span><br><span class="line">               COUNT(*): 16049</span><br></pre></td></tr></table></figure><h3 id="4-前缀索引"><a href="#4-前缀索引" class="headerlink" title="4. 前缀索引"></a>4. 前缀索引</h3><p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。</p><p>前缀长度的选取需要根据索引选择性来确定。</p><h3 id="5-覆盖索引"><a href="#5-覆盖索引" class="headerlink" title="5. 覆盖索引"></a>5. 覆盖索引</h3><p>索引包含所有需要查询的字段的值。</p><p>具有以下优点：</p><ul><li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。</li><li>一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。</li><li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。</li></ul><h2 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h2><ul><li><p>大大减少了服务器需要扫描的数据行数。</p></li><li><p>帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。</p></li><li><p>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。</p></li></ul><h2 id="索引的使用条件"><a href="#索引的使用条件" class="headerlink" title="索引的使用条件"></a>索引的使用条件</h2><ul><li><p>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；</p></li><li><p>对于中到大型的表，索引就非常有效；</p></li><li><p>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</p></li></ul><h1 id="二、查询性能优化"><a href="#二、查询性能优化" class="headerlink" title="二、查询性能优化"></a>二、查询性能优化</h1><h2 id="使用-Explain-进行分析"><a href="#使用-Explain-进行分析" class="headerlink" title="使用 Explain 进行分析"></a>使用 Explain 进行分析</h2><p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。</p><p>比较重要的字段有：</p><ul><li>select_type : 查询类型，有简单查询、联合查询、子查询等</li><li>key : 使用的索引</li><li>rows : 扫描的行数</li></ul><h2 id="优化数据访问"><a href="#优化数据访问" class="headerlink" title="优化数据访问"></a>优化数据访问</h2><h3 id="1-减少请求的数据量"><a href="#1-减少请求的数据量" class="headerlink" title="1. 减少请求的数据量"></a>1. 减少请求的数据量</h3><ul><li>只返回必要的列：最好不要使用 SELECT * 语句。</li><li>只返回必要的行：使用 LIMIT 语句来限制返回的数据。</li><li>缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。</li></ul><h3 id="2-减少服务器端扫描的行数"><a href="#2-减少服务器端扫描的行数" class="headerlink" title="2. 减少服务器端扫描的行数"></a>2. 减少服务器端扫描的行数</h3><p>最有效的方式是使用索引来覆盖查询。</p><h2 id="重构查询方式"><a href="#重构查询方式" class="headerlink" title="重构查询方式"></a>重构查询方式</h2><h3 id="1-切分大查询"><a href="#1-切分大查询" class="headerlink" title="1. 切分大查询"></a>1. 切分大查询</h3><p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> messages <span class="keyword">WHERE</span> <span class="keyword">create</span> &lt; <span class="keyword">DATE_SUB</span>(<span class="keyword">NOW</span>(), <span class="built_in">INTERVAL</span> <span class="number">3</span> <span class="keyword">MONTH</span>);</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rows_affected = 0</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    rows_affected = do_query(</span><br><span class="line">    <span class="string">"DELETE FROM messages WHERE create  &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000"</span>)</span><br><span class="line">&#125; <span class="keyword">while</span> rows_affected &gt; <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="2-分解大连接查询"><a href="#2-分解大连接查询" class="headerlink" title="2. 分解大连接查询"></a>2. 分解大连接查询</h3><p>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：</p><ul><li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。</li><li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。</li><li>减少锁竞争；</li><li>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。</li><li>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag</span><br><span class="line"><span class="keyword">JOIN</span> tag_post <span class="keyword">ON</span> tag_post.tag_id=tag.id</span><br><span class="line"><span class="keyword">JOIN</span> post <span class="keyword">ON</span> tag_post.post_id=post.id</span><br><span class="line"><span class="keyword">WHERE</span> tag.tag=<span class="string">'mysql'</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag <span class="keyword">WHERE</span> tag=<span class="string">'mysql'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag_post <span class="keyword">WHERE</span> tag_id=<span class="number">1234</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> post <span class="keyword">WHERE</span> post.id <span class="keyword">IN</span> (<span class="number">123</span>,<span class="number">456</span>,<span class="number">567</span>,<span class="number">9098</span>,<span class="number">8904</span>);</span><br></pre></td></tr></table></figure><h1 id="三、存储引擎"><a href="#三、存储引擎" class="headerlink" title="三、存储引擎"></a>三、存储引擎</h1><h2 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h2><p>是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。</p><p>实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。</p><p>主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。</p><p>内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。</p><p>支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。</p><h2 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h2><p>设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。</p><p>提供了大量的特性，包括压缩表、空间数据索引等。</p><p>不支持事务。</p><p>不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。</p><p>可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。</p><p>如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。</p><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><ul><li><p>事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。</p></li><li><p>并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。</p></li><li><p>外键：InnoDB 支持外键。</p></li><li><p>备份：InnoDB 支持在线热备份。</p></li><li><p>崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。</p></li><li><p>其它特性：MyISAM 支持压缩表和空间数据索引。</p></li></ul><h1 id="四、数据类型"><a href="#四、数据类型" class="headerlink" title="四、数据类型"></a>四、数据类型</h1><h2 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h2><p>TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。</p><p>INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。</p><h2 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h2><p>FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。</p><p>FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。</p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p>主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。</p><p>VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。</p><p>在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。</p><h2 id="时间和日期"><a href="#时间和日期" class="headerlink" title="时间和日期"></a>时间和日期</h2><p>MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。</p><h3 id="1-DATETIME"><a href="#1-DATETIME" class="headerlink" title="1. DATETIME"></a>1. DATETIME</h3><p>能够保存从 1000 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。</p><p>它与时区无关。</p><p>默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATETIME 值，例如“2008-01-16 22<span>:</span>37<span>:</span>08”，这是 ANSI 标准定义的日期和时间表示方法。</p><h3 id="2-TIMESTAMP"><a href="#2-TIMESTAMP" class="headerlink" title="2. TIMESTAMP"></a>2. TIMESTAMP</h3><p>和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。</p><p>它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。</p><p>MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。</p><p>默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。</p><p>应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。</p><h1 id="五、切分"><a href="#五、切分" class="headerlink" title="五、切分"></a>五、切分</h1><h2 id="水平切分"><a href="#水平切分" class="headerlink" title="水平切分"></a>水平切分</h2><p>水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。</p><p>当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。</p><div align="center"> <img src="/images/mysql-schema/63c2909f-0c5f-496f-9fe5-ee9176b31aba.jpg" width> </div><br><h2 id="垂直切分"><a href="#垂直切分" class="headerlink" title="垂直切分"></a>垂直切分</h2><p>垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。</p><p>在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。</p><div align="center"> <img src="/images/mysql-schema/e130e5b8-b19a-4f1e-b860-223040525cf6.jpg" width> </div><br><h2 id="Sharding-策略"><a href="#Sharding-策略" class="headerlink" title="Sharding 策略"></a>Sharding 策略</h2><ul><li>哈希取模：hash(key) % N；</li><li>范围：可以是 ID 范围也可以是时间范围；</li><li>映射表：使用单独的一个数据库来存储映射关系。</li></ul><h2 id="Sharding-存在的问题"><a href="#Sharding-存在的问题" class="headerlink" title="Sharding 存在的问题"></a>Sharding 存在的问题</h2><h3 id="1-事务问题"><a href="#1-事务问题" class="headerlink" title="1. 事务问题"></a>1. 事务问题</h3><p>使用分布式事务来解决，比如 XA 接口。</p><h3 id="2-连接"><a href="#2-连接" class="headerlink" title="2. 连接"></a>2. 连接</h3><p>可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。</p><h3 id="3-ID-唯一性"><a href="#3-ID-唯一性" class="headerlink" title="3. ID 唯一性"></a>3. ID 唯一性</h3><ul><li>使用全局唯一 ID（GUID）</li><li>为每个分片指定一个 ID 范围</li><li>分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)</li></ul><h1 id="六、复制"><a href="#六、复制" class="headerlink" title="六、复制"></a>六、复制</h1><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。</p><ul><li><strong>binlog 线程</strong> ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。</li><li><strong>I/O 线程</strong> ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。</li><li><strong>SQL 线程</strong> ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。</li></ul><div align="center"> <img src="/images/mysql-schema/master-slave.png" width> </div><br><h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。</p><p>读写分离能提高性能的原因在于：</p><ul><li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；</li><li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；</li><li>增加冗余，提高可用性。</li></ul><p>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。</p><div align="center"> <img src="/images/mysql-schema/master-slave-proxy.png" width> </div><br><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li>BaronScbwartz, PeterZaitsev, VadimTkacbenko, 等. 高性能 MySQL[M]. 电子工业出版社, 2013.</li><li>姜承尧. MySQL 技术内幕: InnoDB 存储引擎 [M]. 机械工业出版社, 2011.</li><li><a href="https://www.jfox.info/20-tiao-mysql-xing-nen-you-hua-de-zui-jia-jing-yan.html" target="_blank" rel="noopener">20+ 条 MySQL 性能优化的最佳经验</a></li><li><a href="http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/" title="服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策" target="_blank" rel="noopener">服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策</a></li><li><a href="https://stackoverflow.com/questions/788829/how-to-create-unique-row-id-in-sharded-databases" target="_blank" rel="noopener">How to create unique row ID in sharded databases?</a></li><li><a href="http://geekswithblogs.net/shaunxu/archive/2012/01/07/sql-azure-federation-ndash-introduction.aspx" title="Title of this entry." target="_blank" rel="noopener">SQL Azure Federation – Introduction</a></li><li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="noopener">MySQL 索引背后的数据结构及算法原理</a></li><li><a href="https://segmentfault.com/a/1190000008131735" target="_blank" rel="noopener">MySQL 性能优化神器 Explain 使用分析</a></li><li><a href="https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6" target="_blank" rel="noopener">How Sharding Works</a></li><li><a href="https://tech.meituan.com/dianping_order_db_sharding.html" target="_blank" rel="noopener">大众点评订单系统分库分表实践</a></li><li><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" target="_blank" rel="noopener">B + 树</a></li></ul><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/notes/MySQL.md#innodb" target="_blank" rel="noopener">https://github.com/CyC2018/CS-Notes/blob/master/notes/MySQL.md#innodb</a></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL union vs or 性能</title>
      <link href="/sql-performance-union-vs-or.html"/>
      <url>/sql-performance-union-vs-or.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：stackoverflow<br>地址：<br><a href="https://stackoverflow.com/questions/13750475/sql-performance-union-vs-or" target="_blank" rel="noopener">https://stackoverflow.com/questions/13750475/sql-performance-union-vs-or</a></p><a id="more"></a><p>翻译自Bill Karwin回答：</p><p>要么你读的那篇文章用了一个不好的例子，要么你误解了他们的观点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; or company = &apos;itv&apos;;</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select username from users where company IN (&apos;bbc&apos;, &apos;itv&apos;);</span><br></pre></td></tr></table></figure><p>在这个查询中MySQL会使用company上的索引。不需要改成UNION。</p><p>更棘手的情况是，OR条件涉及两个不同的列。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; or city = &apos;London&apos;;</span><br></pre></td></tr></table></figure><p>假设company列和city列都有一个独立的索引。MySQL通常在一个给定的查询中每个表只使用一个索引，那么应该使用哪个索引呢?如果它使用company上的索引，它仍然必须执行表扫描，以找到伦敦所在的行。如果它使用city上的索引，则必须对company为bbc的行进行表扫描。</p><p>UNION 解决方案适用于这种情况。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; </span><br><span class="line">union</span><br><span class="line">select username from users where city = &apos;London&apos;;</span><br></pre></td></tr></table></figure><p>这样的话每个子查询都可以使用索引进行搜索,然后再将子查询的结果合并在一起。</p><blockquote><p>union ? union all ? 取决于需求及where过滤后的数据量<br>对于索引列来最好使用union all，因复杂的查询【包含运算等】将使or、in放弃索引而全表扫描，除非你能确定or、in会使用索引。<br>对于只有非索引字段来说你就老老实实的用or或者in，因为 非索引字段本来要全表扫描而union all 只成倍增加表扫描的次数。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 原创 </tag>
            
            <tag> UNION </tag>
            
            <tag> OR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间量级</title>
      <link href="/time-scales.html"/>
      <url>/time-scales.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《性能之巅》<br>作者：【美】 Brendan Gregg<br>英文版出版时间：2014年</p><a id="more"></a><p>我们可以用数字来作为时间的比较方法,同时可以用时间的长短经验来判断延时的源头。系统各组件的操作所处的时间量级差别巨大,大到了难以体会的地步。表2.2提供的延时示例,从访问3.3GHz的CPU寄存器的延时开始,阐释了我们所打交道的时间量级的差别,表中是发生单次操作的时间均值,等比放大成为想象的系统,一次寄存器访问0.3ns(十亿分之一秒的三分之一)相当于现实生活中的1秒。</p><center>表2.2 系统的各种延时</center><table><thead><tr><th>事件</th><th>延时</th><th>相对时间比例</th></tr></thead><tbody><tr><td>1个CPU周期</td><td>0.3ns</td><td>1s</td></tr><tr><td>L1缓存访问</td><td>0.9ns</td><td>3s</td></tr><tr><td>L2缓存访问</td><td>2.8ns</td><td>9s</td></tr><tr><td>L3缓存访问</td><td>12.9ns</td><td>43s</td></tr><tr><td>主存访问(从CPU访问DRAM)</td><td>120ns</td><td>6分钟</td></tr><tr><td>固态硬盘I/O(闪存)</td><td>50-150us</td><td>2-6天</td></tr><tr><td>旋转磁盘I/O</td><td>1-10 ms</td><td>1-12月</td></tr><tr><td>互联网:从旧金山到纽约</td><td>40 ms</td><td>4年</td></tr><tr><td>互联网:从旧金山到英国</td><td>81 ms</td><td>8年</td></tr><tr><td>互联网:从旧金山到澳大利亚</td><td>183ms</td><td>19年</td></tr><tr><td>TCP包重传</td><td>1-3s</td><td>105-317年</td></tr><tr><td>OS虚拟化系统重启</td><td>4s</td><td>423年</td></tr><tr><td>SCSI命令超时</td><td>30s</td><td>3千年</td></tr><tr><td>硬件虚拟化系统重启</td><td>40s</td><td>4千年</td></tr><tr><td>物理系统重启</td><td>5m</td><td>32千年</td></tr></tbody></table><blockquote><p>这个表需要时刻记在心中。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Performance </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[译]ZGC: 未使用堆内存归还操作系统</title>
      <link href="/zgc-uncommit-unused-memory.html"/>
      <url>/zgc-uncommit-unused-memory.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>翻译自：JEP 351<br>地址：<a href="https://openjdk.java.net/jeps/351" target="_blank" rel="noopener">https://openjdk.java.net/jeps/351</a></p></blockquote><a id="more"></a><h1 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h1><p>增强ZGC，将未使用的堆内存返回给操作系统。</p><h1 id="二、动机"><a href="#二、动机" class="headerlink" title="二、动机"></a>二、动机</h1><p>目前ZGC不会将未使用的内存归还给操作系统，即使该内存已经很长时间没有使用了。这种行为并不适合所有类型的应用程序和环境，特别是那些需要考虑内存占用的应用程序和环境。例如：</p><ul><li>按资源使用付费的容器环境。</li><li>应用程序可能长时间处于空闲状态并与许多其他应用程序共享或竞争资源的环境。</li><li>应用程序在执行期间可能有非常不同的堆空间需求。例如，启动期间所需的堆可能大于稍后在稳定状态执行期间所需的堆。</li></ul><p>HotSpot中的其他垃圾收集器(如G1和Shenandoah)已经提供了这种功能，该功能对于一些用户非常有用。将此功能添加到ZGC将受到这些用户的欢迎。</p><h1 id="三、描述"><a href="#三、描述" class="headerlink" title="三、描述"></a>三、描述</h1><p>ZGC堆由一组称为ZPages的堆区域组成。每个Zpage与数量可变的已提交内存相关联。当ZGC压缩堆时，ZPages被释放并插入到页面缓存ZPageCache中。页面缓存中的ZPages可以重用，以满足新的堆分配，在这种情况下，它们将从缓存中删除。页面缓存对性能至关重要，因为提交和不提交内存都是昂贵的操作。</p><p>页面缓存中的ZPages集合表示堆中未使用的部分，这些部分可以归还给操作系统。因此，取消提交内存可以通过简单地从页面缓存中删除一组精心选择的ZPages，并取消与这些页面关联的内存的提交来完成。页面缓存已经将ZPages保持在最近最少使用(LRU)的顺序，并按大小(小、中、大)进行分隔，因此清除ZPages和取消提交内存的机制相对简单。挑战在于设计策略来决定何时从缓存中驱逐ZPage。</p><p><font color="DeepPink"><strong>一个简单的策略是设置一个timeout或delay值，该值指定ZPage在被清除之前可以在页面缓存中驻留多长时间。这个超时将有一些合理的默认值，可以使用命令行选项覆盖它。Shenandoah GC使用这样的策略，默认值为5分钟，命令行选项-XX:ShenandoahUncommitDelay=&lt;milliseconds&gt;来覆盖默认值。</strong></font></p><p><font color="DeepPink"><strong>类似上述策略的效果可能相当不错。然而，人们也可以设想更复杂的策略，不涉及添加新的命令行选项。例如，根据GC频率或其他数据找到合适超时值的启发式方法。我们将首先提供一个简单的超时策略，使用-XX:ZUncommitDelay=&lt;seconds&gt;选项，稍后再提供一个更复杂的策略(如果找到了)。</strong></font></p><p><font color="DeepPink"><strong>默认情况下将启用uncommit功能。但是无论策略如何决定，ZGC都不能把堆内存降到低于Xms。这就意味着，如果Xmx和Xms相等的话，这个能力就失效了，-XX:-ZUncommit这个参数也能让这个内存管理能力失效。</strong></font></p><p>最后，Linux/x64上的ZGC使用tmpfs或hugetlbfs文件来支持堆。这些文件使用的未提交内存需要fallocate(2)和FALLOC_FL_PUNCH_HOLE支持，FALLOC_FL_PUNCH_HOLE支持最早出现在Linux 3.5 (tmpfs)和4.3(hugetlbfs)中。在旧的Linux内核上运行时，ZGC应该像以前一样继续工作，但是禁用了uncommit功能。</p><blockquote><p>Java 越来越云原生了，下一个期盼就是fiber了。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> GC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> JVM </tag>
            
            <tag> ZGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何用Linux命令行管理网络：11个你必须知道的命令</title>
      <link href="/how-to-work-with-network-from-linux-terminal.html"/>
      <url>/how-to-work-with-network-from-linux-terminal.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>如何用Linux命令行管理网络：11个你必须知道的命令</p></blockquote><a id="more"></a><p><img src="/images/how-to-work-with-network-from-linux-terminal/network-commands-header.png" alt="网络命令"></p><p>无论你是要下载文件、诊断网络问题、管理网络接口，还是查看网络的统计数据，都有终端命令可以来完成。这篇文章收集了久经考验靠谱的命令，也收集了几个比较新的命令。</p><p>多数命令都可以在图形桌面执行，即使是没什么终端使用经验的<code>Linux</code>用户也会常常执行命令来使用<code>ping</code>或是其它的网络诊断工具。</p><h2 id="curl-amp-wget"><a href="#curl-amp-wget" class="headerlink" title="curl &amp; wget"></a><code>curl</code> &amp; <code>wget</code></h2><p>使用<code>curl</code>或<code>wget</code>命令，不用离开终端就可以下载文件。如你用<code>curl</code>，键入<code>curl -O</code>后面跟一个文件路径。<code>wget</code>则不需要任何选项。下载的文件在当前目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -O website.com/file</span><br><span class="line">wget website.com/file</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/curl.png" alt="curl"></p><h2 id="ping"><a href="#ping" class="headerlink" title="ping"></a><code>ping</code></h2><p><code>ping</code>发送<code>ECHO_REQUEST</code>包到你指定的地址。这样你可以很方便确认你的电脑和<code>Internet</code>或是一个指定的<code>IP</code>地址是不是通的。使用<code>-c</code>开关，可以指定发送<code>ECHO_REQUEST</code>包的个数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -c 4 google.com</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/ping.png" alt="ping"></p><h2 id="tracepath-amp-traceroute"><a href="#tracepath-amp-traceroute" class="headerlink" title="tracepath &amp; traceroute"></a><code>tracepath</code> &amp; <code>traceroute</code></h2><p><code>tracepath</code>命令和<code>traceroute</code>命令功能类似，但不需要<code>root</code>权限。并且<code>Ubuntu</code>预装了这个命令，<code>traceroute</code>命令没有预装的。<code>tracepath</code>追踪出到指定的目的地址的网络路径，并给出在路径上的每一跳（<code>hop</code>）。如果你的网络有问题或是慢了，<code>tracepath</code>可以查出网络在哪里断了或是慢了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tracepath example.com</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/tracepath.png" alt="tracepath"></p><h2 id="mtr"><a href="#mtr" class="headerlink" title="mtr"></a><code>mtr</code></h2><p><code>mtr</code>命令把<code>ping</code>命令和<code>tracepath</code>命令合成了一个。<code>mtr</code>会持续发包，并显示每一跳ping所用的时间。也会显示过程中的任何问题，在下面的示例中，可以看到在第6跳丢了超过20%的包。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtr howtogeek.com</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/mtr.png" alt="mtr"></p><p>键入<code>q</code>或是<code>CTRL + C</code>来退出命令。</p><h2 id="host"><a href="#host" class="headerlink" title="host"></a><code>host</code></h2><p><code>host</code>命令用来做<code>DNS</code>查询。如果命令参数是域名，命令会输出关联的<code>IP</code>；如果命令参数是<code>IP</code>，命令则输出关联的域名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">host howtogeek.com</span><br><span class="line">host 208.43.115.82</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/host.png" alt="host"></p><h2 id="whois"><a href="#whois" class="headerlink" title="whois"></a><code>whois</code></h2><p><code>whois</code>命令输出指定站点的<code>whois</code>记录，可以查看到更多如谁注册和持有这个站点这样的信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">whois example.com</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/whois.png" alt="whois"></p><h2 id="ifplugstatus"><a href="#ifplugstatus" class="headerlink" title="ifplugstatus"></a><code>ifplugstatus</code></h2><p><code>ifplugstatus</code>命令可以告诉你是否有网线插到在网络接口上。这个命令<code>Ubuntu</code>没有预装，通过下面的命令来安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ifplugd</span><br></pre></td></tr></table></figure><p>这个命令可以查看所有网络接口的状态，或是指定网络接口的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ifplugstatus</span><br><span class="line">ifplugstatus eth0</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/ifplugstatus.png" alt="ifplugstatus"></p><p>命令输出『<code>Link beat detected</code>』（检测到连接心跳）表示有网线插着，如没有则会输出『<code>unplugged</code>』（未插入）。</p><h2 id="ifconfig"><a href="#ifconfig" class="headerlink" title="ifconfig"></a><code>ifconfig</code></h2><p><code>ifconfig</code>用于输出网络接口配置、调优和Debug的各种选项。可以快捷地查看<code>IP</code>地址和其它网络接口的信息。键入<code>ifconfig</code>查看所有启用的网络接口的状态，包括它们的名字。可以指定网络接口的名字来只显示这一个接口的信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ifconfig</span><br><span class="line">ifconfig eth0</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/ifconfig.png" alt="ifconfig"></p><h2 id="ifdown-amp-ifup"><a href="#ifdown-amp-ifup" class="headerlink" title="ifdown &amp; ifup"></a><code>ifdown</code> &amp; <code>ifup</code></h2><p><code>ifdown</code>和<code>ifup</code>命令和运行<code>ifconfig up</code>，<code>ifconfig down</code>的功能一样。给定网络接口的名字可以只禁用或启用这一个接口。需要<code>root</code>权限，所以在<code>Ubuntu</code>上需要使用<code>sudo</code>来运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ifdown eth0</span><br><span class="line">sudo ifup eth0</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/ifdown-ifup.png" alt="ifdown &amp; ifup"></p><p>在<code>Linux</code>桌面系统上运行这2个命令，很可能会输出出错信息。<code>Linux</code>桌面通过使用网络管理器（<code>NetworkManager</code>）来管理你的网络接口。不过在没有安装网络管理器的服务器版上，这2个命令仍然可用。</p><p>如果确实要在命令行上配置网络管理器，用<code>nmcli</code>命令。</p><h2 id="dhclient"><a href="#dhclient" class="headerlink" title="dhclient"></a><code>dhclient</code></h2><p><code>dhclient</code>命令可以释放你的电脑的<code>IP</code>地址并从<code>DHCP</code>服务器上获得一个新的。需要<code>root</code>权限，所以在<code>Ubuntu</code>上需要<code>sudo</code>。无选项运行命令获取新<code>IP</code>，或指定<code>-r</code>开关来释放当前的<code>IP</code>地址。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo dhclient -r</span><br><span class="line">sudo dhclient</span><br></pre></td></tr></table></figure><p><img src="/images/how-to-work-with-network-from-linux-terminal/dhclient.png" alt="dhclient"></p><h2 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a><code>netstat</code></h2><p><code>netstat</code>命令可以显示网络接口的很多统计信息，包括打开的<code>socket</code>和路由表。无选项运行命令显示打开的<code>socket</code>。</p><p><img src="/images/how-to-work-with-network-from-linux-terminal/netstat.png" alt="netstat"></p><p>这条命令还有很多功能。比如，<code>netstat -p</code>命令可以显示打开的<code>socket</code>对应的程序。</p><p><img src="/images/how-to-work-with-network-from-linux-terminal/netstat-p.png" alt="netstat -p"></p><p><code>netstat -s</code>则显示所有端口的详细统计信息。</p><p><img src="/images/how-to-work-with-network-from-linux-terminal/netstat-s.png" alt="netstat -s"></p><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a><code>原文</code></h2><p><a href="https://github.com/oldratlee/translations/blob/master/how-to-work-with-network-from-linux-terminal/README.md" target="_blank" rel="noopener">https://github.com/oldratlee/translations/blob/master/how-to-work-with-network-from-linux-terminal/README.md</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>垃圾回收算法手册：自动内存管理的艺术 笔记</title>
      <link href="/the-garbage-collection-handbook-the-art-of-automatic-memory-management-notes.html"/>
      <url>/the-garbage-collection-handbook-the-art-of-automatic-memory-management-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《垃圾回收算法手册：自动内存管理的艺术》<br>作者：Richard Jones、Antony Hosking、Eliot Moss</p><a id="more"></a><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>几乎所有的现代编程语言都使用动态内存分配(allocation),即允许进程在运行时分配或者释放无法在编译期确定大小的对象,且允许对象的存活时间超出创建这些对象的子程序时间。<font color="DeepPink"><strong>动态分配的对象存在于堆(heap)中而非栈(stack)或者静态区(statically)中。所谓栈,即程序的活动记录(activation record)或者栈帧(stack frame);静态区则是指在编译期或者链接期就可以确定范围的存储区域。</strong></font>堆分配是十分重要的功能,它允许开发者:</p><ul><li>在运行时动态地确定新创建对象的大小(从而避免程序在运行时遭遇硬编码数组长度不足产生的失败)。</li><li>定义和使用具有递归特征的数据结构,例如链表(list)、树(tree)和映射(map)。</li><li>向父过程返回新创建的对象,例如工厂方法。</li><li>将一个函数作为另一个函数的返回值,例如函数式语言中的闭包(closure)或者悬挂(suspension)。</li></ul><p>在不支持自动化动态内存管理的语言中,众多研究者已经付出了相当大的努力来解决这一难题,其方法主要是管理对象的所有权(ownership)[Belotsky,2003; Cline, Lomo,1995]。Belotsky[2003]等人针对C++提出了几个可行策略:</p><ul><li>第一,开发者在任何情况下都应当避免堆分配,例如可以将对象分配在栈上,当创建对象的函数返回之后,栈的弹出(pop)操作会自动将对象释放。</li><li>第二,在传递参数与返回值时,应尽量传值而非引用。尽管这些方法避免了分配、释放错误,但其不仅会造成内存方面的压力,而且失去了对象共享的能力。</li></ul><p>另外,开发者也可以在一些特殊场景下使用自定义内存分配器,例如对象池(pool of object),在程序的一个阶段完成之后,池中的对象将作为一个整体全部释放。</p><h2 id="垃圾算法之间的比较"><a href="#垃圾算法之间的比较" class="headerlink" title="垃圾算法之间的比较"></a>垃圾算法之间的比较</h2><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><p>垃圾回收器首先要考虑的因素是安全性(safety),即在任何时候都不能回收存活对象。但安全性是需要付出一定代价的,特别是在并发回收器中。</p><h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p>对程序的最终用户而言,程序当然是运行得越快越好,但这是由几方面因素决定的。其中的一方面便是花费在垃圾回收上的时间应当越少越好,文献中通常用标记/构造率(mark/cons ratio)衡量这一指标。这一概念是在早期的Lisp语言中最先提出的,它表示回收器(对存活对象进行标记)与赋值器(mutator)(创建或者构造新的链表单元)活跃度的比值。然而<font color="DeepPink"><strong>在大多数设计良好的架构中,赋值器会比回收器占用更多的CPU时间,因此在适当牺牲回收器效率的基础上提升赋值器的吞吐量,并进一步提升整个程序(赋值器+回收器)的执行速度,一般来说是值得的。</strong></font>例如,使用标记一清扫回收的系统偶尔会执行存活对象整理以减少内存碎片,虽然这一操作开销较大,但它可以提升赋值器的分配性能。</p><h3 id="完整性与及时性"><a href="#完整性与及时性" class="headerlink" title="完整性与及时性"></a>完整性与及时性</h3><p>理想情况下,垃圾回收过程应当是完整的,即堆中的所有垃圾最终都应当得到回收,但这通常是不现实的,甚至是不可取的,例如纯粹的引用计数回收器便无法回收环状引用垃圾(自引用结构)。从性能方面考虑,在一次回收过程(collection cycle)中只处理堆中部分对象或许更加合理,例如分代回收器会依照堆中对象的年龄将其划分为两代或者更多代,并把回收的主要精力集中在年轻代,这样不仅可以提高回收效率,而且可以减少单次回收的平均停顿时间(pause time)。</p><p><font color="DeepPink"><strong>在并发垃圾回收器中,赋值器与回收器同时工作,其目的在于避免或者尽量减少用户程序的停顿。此类回收器会遇到浮动垃圾(floating garbage)问题,即如果某个对象在回收过程启动之后才变成垃圾,那么该对象只能在下一个回收周期内得到回收。因此在并发回收器中,衡量完整性更好的方法是统计所有垃圾的最终回收情况,而不是单个回收周期的回收情况。不同的回收算法在回收及时性(promptness)方面存在较大差异,进而需要在时间和空间上进行权衡。</strong></font></p><h3 id="停顿时间"><a href="#停顿时间" class="headerlink" title="停顿时间"></a>停顿时间</h3><p>许多回收器在进行垃圾回收时需要中断赋值器线程,因此会导致在程序执行过程中出现停顿。回收器应当尽量减少对程序主要执行过程的影响,因此要求停顿时间越短越好,这点对于交互式程序或者事务处理服务器(超时将引发事务的重试,进而导致事务的积压)尤为重要。但正如我们在后面章节中将要看到的,限制停顿时间会带来一些副作用。例如,分代式回收器通过频繁且快速地回收较小的、较为年轻的对象来缩短停顿时间,而对较大的、较为年老对象的回收则只是偶尔进行。<font color="DeepPink"><strong>显然,在对分代回收器进行调优时,需要平衡不同分代的大小,进而才能平衡不同分代之间的停顿时间与回收频率。</strong></font>但由于分代回收器必须记录些分代间指针的来源,因此赋值器的指针写操作会存在少量的额外开销。</p><p>并行回收器(parallel collector)虽然也需要停顿整个程序,但它可以通过多线程回收的策略缩短停顿时间。为进一步减少停顿时间,<font color="DeepPink"><strong>并发回收器与增量回收器(incremental collector)偶尔会将部分回收工作与赋值器动作交替进行或者同时进行,但这一过程需要确保赋值器与回收器之间的同步,因而增大了赋值器的额外开销。</strong></font>回收机制的选择会影响程序在空间和时间两个方面的开销,也会影响垃圾回收周期的结束。<font color="DeepPink"><strong>赋值器在时间方面的额外开销取决于需要记录的赋值器操作类型(读或者写)及其如何记录。回收器在空间方面的开销以及回收周期的结束取决于系统可以容忍的浮动垃圾数量。</strong></font>多线程赋值器与回收器会增大设计复杂度。不论如何,缩短停顿时间的措施通常会增大整体处理时间(即降低整体处理速度)。</p><p>仅对最大或者平均停顿时间进行度量是不够的,必须要同时考虑赋值器的性能,因此停顿时间的分布也值得关注。</p><h3 id="空间开销"><a href="#空间开销" class="headerlink" title="空间开销"></a>空间开销</h3><p>内存管理的目的是安全且高效地使用内存空间。不论是显式内存管理还是自动内存管理,不同的管理策略均会产生不同程度的空间开销(space overhead)。某些垃圾回收器需要在每个对象内部占用一定的空间(例如保存引用计数),还有一些回收器会复用对象现有布局上已经存在的域(例如将标记位放在对象头部的某个字中,或者将转发指针(forwarding pointer)记录在用户数据上)。回收器也可能会引入堆级别的空间开销,例如复制式回收器需要将堆分为两个半区,任何时候赋值器只能使用一个半区,另一个半区会被回收器保留,并在回收过程中将存活对象复制到其中。<font color="DeepPink"><strong>回收器也可能需要一些辅助的数据结构,例如追踪式回收器需要通过标记栈来引导堆中指针图表的遍历,回收器在标记对象时也可以使用额外的位图(bitmap)而非对象中的域;对于并发回收器或者其他需要将堆划分为数个独立区域的回收器,其需要额外的记忆集(remembered set)来保存赋值器所修改的指针值或者跨区域指针的位置。</strong></font></p><h3 id="针对特定语言的优化"><a href="#针对特定语言的优化" class="headerlink" title="针对特定语言的优化"></a>针对特定语言的优化</h3><p>垃圾回收算法可以根据它们所服务的不同语言范式来归类。在函数式语言中,内存管理有着很大的优化空间。某些语言(例如ML)将可变数据与不可变数据进行区分,纯函数式语言(例如Haskell)则更为极端,它不允许用户改变任何数据,即程序是透明引用(referentially transparent)的。然而,在函数式语言内部,数据结构的更新一般不超过一次,即从待计算值(thunk)到一个弱头部范式(weak head normal form,WHNF),分代垃圾回收器可以据此尽快提升已经完成计算的数据结构。研究者们还提出了基于引用计数来处理环状数据结构的完整机制。声明式语言(declarative language)或许还可以使用其他策略来提升堆空间管理的效率,即如果某一对象创建于一个“选择点”(choice point)之后,那么当程序再次回到该选择点时,该对象将不可达,如果对象在堆中的布局是按照其分配时间排布的,那么某个选择点之后分配的内存可以在一个固定的时间内全部回收。不同种类的语言可能对回收器具有不同的要求,最显著的差异是语言中指针功能的不同,以及回收器调用对象终结的需求不同。</p><blockquote><p>所谓透明引用,即以相同的参数调用同一个函数两次,所得到的结果总是相同的,也可理解为函数没有副作用。<br>thunk和WHNF均为函数式语言中的与懒情计算相关的概念。</p></blockquote><h3 id="可扩展性与可移植性"><a href="#可扩展性与可移植性" class="headerlink" title="可扩展性与可移植性"></a>可扩展性与可移植性</h3><p>可扩展性(scalability)与可移植性(portability)是我们定义的最后两个指标。随着PC,甚至笔记本计算机中(且不说大型服务器)多核硬件的普及,借助硬件的并行优势来提升垃圾回收的性能将变得越来越重要。我们期待并行硬件在规模上(内核与套接字数量上)能有进一步发展,也希望异构处理器(heterogeneous processer)越来越普遍。在服务器方面,堆的大小可以达到数十甚至数百吉字节,事务型负载也越来越多,这些都给垃圾回收带来更多的要求。很多垃圾回收算法需要操作系统或者硬件的支持(例如需要依赖页保护机制,需要对虚拟内存空间进行二次映射,或者要求处理器能够提供特定的原子操作),但这些技术并不需要很强的可移植性。</p><h2 id="性能上的劣势"><a href="#性能上的劣势" class="headerlink" title="性能上的劣势"></a>性能上的劣势</h2><p>与显式内存管理相比,自动内存管理是否存在性能上的劣势?我们将通过对这一问题的分析,来对两者的优劣进行总结。一般来说,自动内存管理的运行开销很大程度上取决于程序的行为,甚至硬件条件,因而很难对其进行简单评估。一个长期以来的观点是,垃圾回收通常会在总内存吞吐量以及垃圾回收停顿时间方面引人一些不可接受的开销,从而导致应用程序的执行速度慢于显式内存管理策略。自动内存管理确实会牺牲程序的部分性能,但是远不如想象中那样严重。诸如ma1loc和free等显式内存操作也会带来一些显著开销。Herts, Feng, Herger[2005测量了多种Java基准测试程序和回收算法花费在垃圾回收上的真正开销。他们构建了一个Java虚拟机并用其精确地观察到对象何时不可达,同时使用可达追踪的方法驱动模拟器来测量回收周期与高速缓存不命中(cache miss)的情况。他们将许多不同种类的垃圾回收器配置与各种不同的ma1lo/free实现进行比较,比较的方法是:如果追踪发现某一对象变成垃圾,则调用free将其释放。 Herts等人发现,尽管用这两种方式的测量结果差异较大,但是<font color="DeepPink"><strong>如果堆足够大(达到所需最小空间的5倍),那么垃圾回收器的执行时间性能将可以与显式分配相匹敌,但对于一般大小的堆,垃圾回收的开销会平均增大17%。</strong></font></p><h2 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h2><p>内存管理涉及时间和空间两方面的权衡。<font color="DeepPink"><strong>大多数环境下,降低回收停顿时间的一种方法是增大堆的空间(增大到一定程度后将达到最优,但如果再增大,则由于局部性原理,执行时间将会变长)。</strong></font></p><h2 id="术语和符号"><a href="#术语和符号" class="headerlink" title="术语和符号"></a>术语和符号</h2><p>首先需要说明的是存储的单位。我们遵循一个字节包含八个位这一惯例。我们简单地使用KB(kilobyte)、MB(megabyte)、GB(gigabyte)、TB(terabyte)来描述对应的2的整数次幂内存单元(分别是20、20、20、20),而不使用SI数字前缀的标准定义。</p><h3 id="赋值器与回收器"><a href="#赋值器与回收器" class="headerlink" title="赋值器与回收器"></a>赋值器与回收器</h3><p>对于使用垃圾回收的程序, Dijkstra等[1976、1978]将其执行过程划分为两个半独立的部分:</p><ul><li>赋值器执行应用代码。这一过程会分配新的对象,并且修改对象之间的引用关系,进而改变堆中对象图的拓扑结构,引用域可能是堆中对象,也可能是根,例如静态变量、线程栈等。随着引用关系的不断变更,部分对象会失去与根的联系,即从根出发沿着对象图的任何一条边进行遍历都无法到达该对象。</li><li>回收器(collector)执行垃圾回收代码,即找到不可达对象并将其回收。</li></ul><p>一个程序可能拥有多个赋值器线程,但是它们共用同一个堆。相应的,也可能存在多个回收器线程。</p><h3 id="分配器"><a href="#分配器" class="headerlink" title="分配器"></a>分配器</h3><p>分配器(allocator)与回收器在功能上是正交关系。分配器支持两种操作:分配(allocate)和释放(free)。分配是为某一对象保留底层的内存存储,释放是将内存归还给分配器以便复用。分配存储空间的大小是由一个可选参数来控制的,如果我们在伪代码中忽略这一参数,意味着分配器将返回一个固定大小的对象,或者对象大小对于算法的理解并非必要。分配操作也可能支持更多参数,例如将数组的分配与单个对象的分配进行区分,或者将指针数组的分配和不包含指针的数组进行区分,或者包含其他一些必要信息以便初始化对象头部。</p><h1 id="标记-清扫回收"><a href="#标记-清扫回收" class="headerlink" title="标记-清扫回收"></a>标记-清扫回收</h1><p>标记一清扫算法是一种间接回收(indirect collection)算法,它并非直接检测垃圾本身而是先确定所有存活对象,然后反过来判定其他对象都是垃圾。需要注意的是,该算法的每次调用都需要重新计算存活对象集合,但并非所有的垃圾回收算法都需要如此。</p><h2 id="三色抽象"><a href="#三色抽象" class="headerlink" title="三色抽象"></a>三色抽象</h2><p>三色抽象(tricolour abstraction)[Dijkstra等,1976,1978]可以简洁地描述回收过程中对象状态的变化(是否已被标记、是否在工作列表中等)。三色抽象是描述追踪式回收器的种十分有用的方法,利用它可以推演回收器的正确性,这正是回收器必须保证的。<font color="DeepPink"><strong>在三色抽象中,回收器将对象图划分为黑色对象(确定存活)和白色对象(可能死亡)。任意对象在初始状态下均为白色,当回收器初次扫描到某一对象时将其着为灰色,当完成该对象的扫描并找到其所有子节点之后,回收器会将其着为黑色。从概念上讲,黑色意味着已经被回收器处理过,灰色意味着已经被回收器遍历但尚未完成处理(或者需要再次进行处理)。</strong></font>三色抽象也可以推广到对象的域中:灰色表示正在处理的域,黑色表示已经处理过的域。如果把赋值器也当作一个对象,则三色抽象也可用于推演赋值器根集合的状态变化[Pirinen,1998]灰色赋值器表示回收器尚未完成对其根集合的扫描,黑色赋值器表示回收器已经完成对其根集合的扫描(并且不需要再次扫描)。一次堆遍历过程可以形象地看作是回收器以灰色对象作为“波面”(wavefront),将黑色对象和白色对象分离,不断向前推进波面,直到所有可达对象都变成黑色的过程。</p><p>上述算法中存在一个重要的不变式:<font color="DeepPink"><strong>在标记过程完成后,对象图中将不可能存在从黑色对象指向白色对象的引用,因此在标记过程中,所有白色可达对象都只能是从灰色对象可达。如果这一不变式被打破,那么回收器将不会进一步处理黑色对象,从而可能导致某个黑色对象的后代可达但未被标记(进而被错误地释放)。</strong></font></p><h2 id="改进的标记-清扫算法"><a href="#改进的标记-清扫算法" class="headerlink" title="改进的标记-清扫算法"></a>改进的标记-清扫算法</h2><p>程序的性能通常与其高速缓存的相关行为有很大关系。从内存中加载一个值可能要花费上百个时钟周期,但从L1高速缓存(L1 cache)中加载可能只需要花费三到四个时钟周期。高速缓存之所以能够提升程序的性能,主要是因为程序在运行时表现出了良好的时间局部性」(temporal locality),即一旦程序访问了某个内存地址,则很可能在不久之后再次访问该地址,因此值得将它的值缓存。程序也可能表现出良好的空间局部性(space locality),即一旦程序访问了某个内存地址,则很有可能在不久之后访问该地址附近的数据。<font color="DeepPink"><strong>现代硬件可以从两个方面利用程序的局部性特征:一方面,高速缓存与更低级别内存之间不会进行单个字节的数据传输,而是以一个固定的字节数为最小传输单元(即高速缓存行或者高速缓存块的大小),通常是32~128字节;另一方面,处理器可能会使用硬件预取(prefetch)技术,例如Intel Core微处理器架构可以探测到有规律的步进内存访问操作,进而提前读取数据流。</strong></font>开发者也可以利用显式预取指令引导预取过程。</p><h2 id="位图标记"><a href="#位图标记" class="headerlink" title="位图标记"></a>位图标记</h2><p><font color="DeepPink"><strong>回收器可以将对象的标记位保存在其头部的某个字中,除此之外也可以使用一个独立的位图来维护标记位,即:位图中的每个位关联堆中每个可能分配对象的地址。位图所需的空间取决于虚拟机的字节对齐要求。</strong></font>位图可以只有一个,也可以存在多个,例如在块结构的堆中,回收器可以为每个内存块维护独立的位图,这一方式可以避免由于堆不连续导致的内存浪费。回收器可以将每个内存块的位图置于其自身内部,但如果所有内存块中位图的相对位置全部相同,则可能导致性能的下降,因为不同内存块的位图之间可能会争用相同的组相关高速缓存(set- associative cache)。对位图的访问同时也意味着对位图所在页的访问(即可能导致缺页异常——译者注),因此基于换页和高速缓存相关性的考虑,在访问位图时花费更多的指令以保持程序的局部性通常来说是值得的。为避免高速缓存的相关问题,可以将内存块中位图的位置增加一个简单偏移量,例如内存块地址的简单哈希值。还可以将位图存放在个额外的区域[Boehm and Weiser,1988年]中,并以其所对应内存块的哈希值等作为索引,这样既避免了换页问题,也避免了高速缓存冲突。</p><p>位图标记通常仅适用于单线程环境,因为多线程同时修改位图可能存在较大的写冲突风险。设置对象头部中的标记位通常是安全的,因为该操作是幂等的,即最多只会将标记位设置多次。相对于位图,实践中更常用的是字节图(byte-map),虽然它占用的空间是前者的8倍,但却解决了写冲突问题。另外还可以使用同步操作来设置位图中的位。<font color="DeepPink"><strong>在实际应用中,如果将标记位保存在对象头部通常会带来额外的复杂度,因为头部通常会存放一些赋值器共享数据,例如锁或者哈希值,那么当标记线程与赋值器线程并发执行时可能会产生冲突。</strong></font>因此,为了确保安全,标记位通常会占用头部中一个额外的字,以便与赋值器共享数据区分,当然也可以使用原子操作来设置头部中的标记位。</p><p>相对于将标记位放置在对象头部这一策略,位图可以使得标记位更加密集;对于使用位图的标记一清扫回收器,标记过程只需读取存活对象的指针域而不会修改任何对象;对于不包含引用的对象,回收器只需要读取其类型信息描述域;清扫器不会对存活对象进行任何读写操作,它只会在释放垃圾对象的过程中覆盖其某些域(例如将它们链接到空闲链表上)。因此,位图标记不仅可以减少内存中需要修改的字节数,而且减少了对高速缓存行的写入,进而减少需要写回内存的数据量。</p><p>位图标记最初应用在保守式回收器(conservative collector)中。保守式回收器的设计初衷是为C和C++等“不合作”的语言提供自动内存管理功能[Boehm and Weiser,1988]型精确(type-accurate)系统可以精确地识别每一个包含指针的槽,不论其位于对象中,是位于线程栈或者其他根集合中,而<font color="DeepPink"><strong>保守式回收器则无法得到编译器和运行时系统的支持因而其在识别指针时必须采用保守的判定方式,即:如果槽中某个值看起来像是指针引用,那么就必须假定它是一个指针。</strong></font>保守式回收器可能错误地将一个槽当作指针,这带来了两个安全上的要求:第一,回收器不能修改任何赋值器可能访问到的内存地址的值(包括对象和根集合)。这一要求导致保守式回收器不能使F任何可能移动对象的算法,因为对象被移动之后需要更新指向该对象的所有引用。这同时导致在头域中保存标记位的方案不可行,因为错误的指针会指向一个实际并不存在的象”,因此设置或者清理标记位可能会破坏用户数据。第二,应当尽可能减少赋值器破坏回收器数据的可能性。与将标记位等回收器元数据存放在一个单独区域的方案相比,为每个对象增加一个回收器专用头部数据会存在更高的风险。</p><p><font color="DeepPink"><strong>使用位图标记的另一个重要目的是减少回收过程中的换页次数</strong></font>[Boehm,2000在现代系统中,任何由回收器导致的换页行为通常都是不可接受的,因此位图标记是否可以提升高速缓存性能便成为一个值得关注的问题。许多证据表明,对象往往成簇诞生并成批死亡[Hayes,1991; Jones, Ryder,2008],而许多分配器往往也会将这些对象分配在相邻的空间。使用位图来引导清扫可以带来两个好处:第一,在位图/字节图中,一个字内部的每个位/字节全部都被设置/清空的情况会经常出现,因此回收器可以批量读取/清空一批对象的标记位;第二,通过位图标记可以更简单地判定某一内存块中的所有对象是否都是垃圾,进而可能一次性回收整个内存块。</p><p>许多内存管理器都使用块结构堆(如Boehm and Weiser[1988])。最直接的位图标记实现策略可能是在每个内存块的前端保留一块内存以用作位图。但正如我们前面所提到的,这策略可能会导致不必要的高速缓存冲突或者换页,因此回收器通常将位图与用户数据块分开并单独存放。</p><p>Garner等[2007]提出了一种<font color="DeepPink"><strong>混合标记策略,即将分区适应分配器(segregated fitsallocator)所管理的每个数据块与字节图中的一个字节相关联,同时依然保留对象头部的标记位。当且仅当内存块中至少存在一个存活对象时,该内存块所对应的标记字节才会被设置。清扫器可以根据字节图快速地判定某一内存块是否完全为空(即不包含存活对象),进而可以将其整体回收。</strong></font>这一策略有两个优点:第一,在并发情况下,无需使用同步操作来设置字节图中的标记字节以及对象头部的标记位;第二,写操作没有数据依赖(这可能导致高速缓存延迟),且对字节图中标记字节的写操作也是无条件的。</p><h2 id="标记过程中的高速缓存不命中问题"><a href="#标记过程中的高速缓存不命中问题" class="headerlink" title="标记过程中的高速缓存不命中问题"></a>标记过程中的高速缓存不命中问题</h2><p>Bohm[2000]发现标记过程的开销决定着回收时间:在 Intel PentiumⅢ系统中,预取对象第一个指针域的开销通常会占到标记该对象总开销的三分之一。为此 Boehm提出一种灰色预取( prefetching on gray)技术,即当对象为灰色时,预取其第一个高速缓存行中的数据,如果被扫描的对象很大,则预取适当数量的高速缓存行。然而,这种技术依赖于预取时间,如果过早地进行高速缓存行预取,则数据很可能在得到使用之前就被换出,而过晚地预取则会导致高速缓存不命中。</p><h2 id="需要考虑的问题"><a href="#需要考虑的问题" class="headerlink" title="需要考虑的问题"></a>需要考虑的问题</h2><h3 id="空间利用率"><a href="#空间利用率" class="headerlink" title="空间利用率"></a>空间利用率</h3><p>将标记位放在对象头部基本不会产生额外的空间开销,而如果使用位图来保存标记位,则额外空间开销的大小取决于对象的字节对齐要求,但其总大小不会超过堆的字节对齐要求的倒数(即堆空间的1/64或1/32,具体的值取决于堆的组织架构)。</p><h1 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h1><h2 id="环状引用计数"><a href="#环状引用计数" class="headerlink" title="环状引用计数"></a>环状引用计数</h2><p>对于环状数据结构而言,其内部对象的引用计数至少为1,因此仅靠引用计数本身无法回收环状垃圾。不论是在应用程序还是在运行时系统中,环状数据结构都十分普遍,如双向链表或者环状缓冲区。对象一关系映射(object-relations mapping)系统可能要求数据库和其中的表互相引用对方的一些信息。真实世界中的某些结构天然就是环状的,例如地理信息系统中的道路。懒惰函数式语言(lazy functional language)通常使用环来表示递归[urner 1979,Y组合子(Combinator)]。研究者们提出了多种解决环状引用计数问题的策略,我们介绍其中的几种。</p><p>最简单的策略是在引用计数之外偶尔使用追踪式回收作为补充。该方法假定大多数对象不会被环状数据结构所引用,因此可以通过引用计数方法实现快速回收,而追踪式回收则负责处理剩余的环状数据结构。这一方案简单地减少了追踪式回收的发起频率。在语言层面上, Friedman和wise[1979]发现,纯函数式语言中只有递归定义才会产生环,因此只要遵从一定的规则便可对这种情况下的环状引用计数进行特殊处理。在 Bobrow1980]的方法中,开发者可以把一组对象作为整体进行引用计数操作,当整体引用计数为零时便可将其集体回收。</p><p>许多学者建议将导致闭环出现的指针与其他指针进行区分[Friedman and Wise,1979;Brownbridge,1985; Salkeld,1987; Repels等,1988; Axford,19901。他们将普通引用称为强引用(strong reference),将导致闭环出现的引用称为弱引用(weak reference)。如果不允许强引用组成环,则强引用图可以使用标准引用计数算法处理。Brownbridge的算法得到了广泛应用,简而言之,每个对象需要包含一个强引用计数以及一个弱引用计数,在进行写操作时,写屏障会检测指针以及目标对象的强弱,并将所有可能产生环的引用设置为弱引用。为维护“所有可达对象均为强可达,且强引用不产生环”这一不变式,赋值器在删除引用时可能需要改变指针的强弱属性。但是,这一算法并不安全,且可能导致对象提前被回收,具体可以参见Salkeld的引用计数示例[Jones,1996,6.5节]。Salkeld[1987]对该算法进行修正并提升了它的安全性,但代价是在某些情况下算法将无法结束。Repels等[1988]提出了一种非常复杂的解决方案,但该算法在空间以及性能方面的开销却更加明显:与普通的引用计数相比,其所需的空间开销翻倍,在大多数情况下,其性能开销是标准引用计数的两倍,在极端情况下,甚至会呈现指数级增长。</p><p>在所有能够处理环状数据结构的引用计数算法中,得到了最广泛认可的是试验删除(trial deletion)算法。该算法无须使用后备的追踪式回收器来进行整个存活对象图的扫描,相反,它将注意力集中在可能会因删除引用而产生环状垃圾的局部对象图上。在引用计数算法中:</p><ul><li>在环状垃圾指针结构内部,所有对象的引用计数均由其内部对象之间的指针产生。</li><li>只有在删除某一对象的某个引用后该对象的引用计数仍大于零时,才有可能出现环状垃圾。</li></ul><p>部分追踪(partial tracing)算法充分利用上述两个结论,该算法从一个可能是垃圾的对象开始进行子图追踪。对于遍历到的每个引用,算法将对其目标对象进行试验删除,即临时性地减少目标对象的引用计数,从而移除由内部指针产生的引用计数。追踪完成后,如果某个对象的引用计数仍然不是零,则必然是因为子图之外的其他对象引用了该对象,进而可以判定该对象及其传递闭包都不是垃圾。</p><p>Recycler算法[Bacon等,2001; Bacon and Rajan,2001;Paz等,2007]支持环状引用计数的并发回收。环状数据结构的回收分为3个阶段:</p><ul><li>首先,回收器从某个可能是环状垃圾成员的对象出发进行子图追踪,同时减少由内部指针产生的引用计数。算法将遍历到的对象着为灰色。</li><li>其次,对子图中的所有对象进行检测,如果某一对象的引用计数不是零,则该对象必然被子图外的其他对象引用。此时需要对第一阶段的试验删除操作进行修正,算法将存活的灰色对象重新着为黑色,同时将其他灰色对象着为白色。</li><li>最后,子图中所有依然为白色的对象必然是垃圾,算法可以将其回收。</li></ul><h1 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h1><p>对于首次适应或循环首次适应分配而言,将空闲内存单元依照地址进行排序的另一种有效策略是位图适应分配(bitmapped- fits allocation)。该算法使用额外的位图来记录堆中每个可分配内存颗粒的状态,因此在进行内存分配时,分配器可以基于位图而非堆本身进行搜索。借助一张预先计算好的映射表,分配器仅需要对位图中一个字节进行计算,便可得知其所对应的8个连续内存颗粒所能组成的最长连续可用空间。也可以使用额外的长度信息记录较大的空闲内存单元或者已分配内存单元,从而快速将其跳过以提升分配性能。位图适应分配具有如下一些优点:</p><ul><li>位图本身与对象相互隔离,因此不容易遭到破坏。这一特性不仅对于诸如C和C++等安全性稍低的语言十分重要,而且对于安全性更高的语言也十分有用,因为这可以提升回收器的可靠性以及可调试性。</li><li>引入位图之后,无论是对于空闲内存单元还是已分配内存单元,回收器都不需要占据其中的任何空间来记录回收相关信息,从而最大限度地降低了对内存单元大小的要求。如果以一个32位的字作为最小内存分配单元,该策略会引入大约3%的空间开销,但其所带来收益却远大于这一开销。不过,基于其他一些方面的考虑,对象可能依然需要一个头部,因而这一优点并非始终能够得到体现。</li><li>相对于堆中的内存单元,位图更加紧凑,因此基于位图进行扫描可以提升高速缓存命中率,从而提升分配器的局部性。</li></ul><h2 id="分区适应分配"><a href="#分区适应分配" class="headerlink" title="分区适应分配"></a>分区适应分配</h2><h3 id="空间大小分级的填充"><a href="#空间大小分级的填充" class="headerlink" title="空间大小分级的填充"></a>空间大小分级的填充</h3><p>伙伴系统(buddy system)其空间大小分级均为2的整数次幂[Knowlton,1965; Peterson and Norman,1977]。我们可以将一个大小为2^(i+1)的空闲内存单元分裂为两个大小为2^i的空闲内存单元,同时也可以将两个相邻的大小为2^i的空闲内存单元合并成大小为2^(i+1)的一个,但进行合并的前提是两个相邻空闲内存单元原本就是由同一个较大的空闲内存单元分裂得到的。在该算法中,大小为2^i的空闲内存单元两两成对,因而称之为伙伴。<font color="DeepPink"><strong>由于伙伴系统的内部碎片通常较为严重(对于任意的内存分配需求,其平均空间浪费率会达到25%),因此该算法基本已经成为历史,在实践中较少使用。</strong></font></p><p>斐波那契伙伴系统(Fibonacci buddy system)[Hirschberg,1973; Burton,1976; Peterson and<br>Norman,1977是伙伴系统的一个变种,其空间大小分级符合斐波那契序列,即s<sub>i+2</sub> = s<sub>i+1</sub> + s<sub>i</sub>,同时需要选定合适的s0和s1。与传统的伙伴系统相比,该算法相邻空闲内存单元的大小比值更小,因而在一定程度上缓解了内部碎片问题。但该算法的问题在于,在回收完成后将相邻空闲内存单元合并的操作会更加复杂,因为回收器需要判定某一空闲内存单元究竟应当与相邻两个空闲内存单元中的哪一个进行合并。</p><h2 id="其它需要考虑的问题"><a href="#其它需要考虑的问题" class="headerlink" title="其它需要考虑的问题"></a>其它需要考虑的问题</h2><h3 id="字节对齐"><a href="#字节对齐" class="headerlink" title="字节对齐"></a>字节对齐</h3><p>将对象按照特定的边界要求进行对齐,一方面是底层硬件或者机器指令集的要求,另方面这样做有助于提升各层次存储器的性能(包括高速缓存、转译后备缓冲区、内存页以Java语言的 double数组为例,某些机器可能要求double这一双字浮点数必须以双字为边<br>界进行对齐,即其地址必须是8的整数倍(地址的后三位为零)。一种简单但稍显浪费的解决方案是将双字作为内存分配的颗粒,即所有已分配或未分配内存单元的大小均为8的整数倍,且均按照8字节边界对齐。但即便如此,当分配一个doub1e类型的数组时,分配器仍需要进行一些额外工作。假设Java语言中纯对象(即非数组对象)头部都必须保留两个字,一个指向对象的类型信息(用于虚函数调用、类型判定等),另一个用于记录对象的哈希值以及同步操作所需的锁(这也是一种典型的设计方式)。数组对象则需要第三个字来记录其中元素的个数。如果将这三个头部字保存在已分配内存单元的起始位置,则数组元素就不得不以奇数字为单位进行对齐。如果使用双字作为内存颗粒,则可以简单地用四个字(即两个双字)来保存这三个头部字,然后浪费掉一个。</p><p>但如果内存颗粒是一个字,我们则希望尽量减少上述的内存浪费。此时,如果某个空闲内存单元按照奇数字对齐(即其地址模8余4),则我们可以简单地将三个头部字放在内存单字对齐,则我们必须浪费一个字以满足对齐要求。这一方案增加了分配过程的复杂度,因为某一空闲内存单元是否满足分配需求不仅取决于所需空间的大小,还取决于字节对齐要求。</p><blockquote><p>字：16个位为一个字，它代表计算机处理指令或数据的二进制数位数，是计算机进行数据存储和数据处理的运算的单位。通常称16位是一个字，而32位呢，则是一个双字，64位是两个双字。</p></blockquote><h3 id="空间大小限制"><a href="#空间大小限制" class="headerlink" title="空间大小限制"></a>空间大小限制</h3><p>某些回收器要求对象(内存单元)的大小必须大于某一下界。例如,基本的整理式回收要求对象内部至少可以容纳一个指针,还有一些回收器可能需要用两个字来保存锁或状态以及转发指针,这就意味着即使开发者仅需要分配一个字,分配器也必须多分配两个字。如果开发者需要分配不包含任何数据、仅用作唯一标识的对象,原则上编译器无需分配任何空间,但在实际情况下这通常不可行:对象必须要有唯一的地址,因此对象的大小至少应为一个字节。</p><h3 id="边界标签"><a href="#边界标签" class="headerlink" title="边界标签"></a>边界标签</h3><p>为了确保在释放内存时可以将相邻空闲内存单元合并,许多内存分配系统为每个内存单元增加了额外的头部或者边界标签,它们通常不属于可用内存的范畴[Knuth,1973]。边界标签保存了内存单元的大小及其状态(即空闲或已分配),还可以在其中记录上一个内存单元的大小,从而可以快速读取上一个内存单元的状态并判断其是否为空。当内存单元空闲时,边界标签也可用于保存构建空闲链表的指针。基于这些原因,边界标签可能达到两个字或者更大,但如果使用一些额外的方法,并允许在分配和释放的过程中引入一定的额外开销,则仍有可能将边界标签压缩到一个字。</p><p>如果使用额外的位图来标记堆中每个内存颗粒的状态,则不仅无需使用边界标签,而且可以增加程序的鲁棒性。这一方法是否会减少空间开销,取决于对象的平均大小以及内存颗粒的大小。</p><p>我们进一步注意到,垃圾回收通常会一次性释放大量对象,因此某些特定的算法可能不再需要边界标签,或者其边界标签中需要包含的信息较少。另外,托管语言中对象的大小通常可以通过其类型得出,因而无需使用额外的边界标签来单独记录相关信息。</p><h3 id="局部性"><a href="#局部性" class="headerlink" title="局部性"></a>局部性</h3><p>事实证明,同一时刻分配的对象通常也会在同一时刻成为垃圾,因此非移动式回收器所面临的内存碎片问题比人们预想的要小[Hayes,1991; Dimpsey等,2000; Blackburn and McKinley,2008],这同时也说明,将连续两次分配的对象连续排列或者尽可能靠近排列的启发式方法是有价值的。</p><h3 id="并发系统中的内存分配"><a href="#并发系统中的内存分配" class="headerlink" title="并发系统中的内存分配"></a>并发系统中的内存分配</h3><p>在多线程环境下,分配过程的许多操作都需要原子化以确保分配数据结构的完整性,这些操作都必须使用原子操作或者锁,但这样一来,内存分配就可能成为性能瓶颈。最基本的解决方案是为每个线程开辟独立的内存分配空间,如果某个线程的可分配空间耗尽,则从全局内存池中为其分配一个新的空闲块,此时只有与全局内存池的交互才需要原子化。不同线程的内存分配频度可能不同,因此如果在为线程分配内存块时使用自适应算法(即:为分配速度较慢的线程分配较小的内存块,而为分配速度较快的线程分配较大的内存块),则程序的时间和空间性能均可获得提升。Dimpsey等[20001声称,在多处理器Java系统中,为每个线程配备一个合适的本地分配缓冲区(local allocation buffer,LAB)可以大幅提升性能。他们进一步指出,由于几乎所有的小对象都是从本地分配缓冲区分配的,因而我们有理由对全局(基于空闲链表的)分配器进行调整,以使其能够更加高效地分配用于线程本地分配缓冲区的内存块。</p><p>Garthwaite等[2005]讨论了如何对本地分配缓冲区的大小进行自适应调整,他们同时发现,将本地分配缓冲区与处理器而非线程相关联效果更佳。该算法通过如下方式对本地分配缓冲区的大小进行调整:线程初次申请本地分配缓冲区时将获得24个字的内存块,之后每次新申请的内存块均为上一次的1.5倍,同时每经历一次垃圾回收过程,回收器都会将线程的本地分配缓冲区的大小折半。该算法同时也会根据不同线程的分配次数调整年轻代的空间大小。每处理器(per-processor)本地分配缓冲区的实现依赖于多处理器的可重启临界区(restartable critical section),Garthwaite等人对此做了介绍。其基本原理是,线程可以判断自身是否被抢占(preempt)或者被重新调度(reschedule),然后可以据此判断自身是否被切换到其他处理器上运行。当线程抢占发生时,处理器会对某个本地寄存器进行修改,该操作会为抢占完成后的写入操作设置一个陷阱,而陷阱处理函数则会重启被中断的分配过程。尽管每处理器本地分配缓冲区需要更多的指令支持,但与每线程本地分配缓冲区相比,其分配时延相同,且不需要复杂的缓冲区调整机制。 Garthwaite同时发现,当线程数量较少时(特别是当线程数量小于处理器数量时),每线程(per-thread)本地分配缓冲区的性能较好,而在线程数量较多的情况下,每处理器本地分配缓冲区的表现更佳,因此他们将系统设计成可在两种方案之间进行动态切换。</p><p>本地分配缓冲区通常使用顺序分配策略。每个线程(或处理器)也可以独立维护自身对应的分区适应空闲链表,同时使用增量清扫策略。线程在内存分配过程中会执行增量清扫,并将清扫所得的空闲内存单元添加到自身空闲链表中,但Berger等[2000]指出,如果将该算法用于显式内存管理会存在一些问题。例如,在某一使用生产者一消费者模型的程序中消息对象通常由生产者创建并由消费者释放,因此两个线程之间将会产生单方向的内存转移。在垃圾回收环境下通常不会存在这一问题,因为回收器可以将空闲内存释放到全局内存池中。如果使用增量清扫,空闲内存单元将被执行清扫的线程所获取,从而自然地将回收所得的内存返还给分配最频繁的线程。</p><h2 id="需要考虑的问题-1"><a href="#需要考虑的问题-1" class="headerlink" title="需要考虑的问题"></a>需要考虑的问题</h2><p><font color="DeepPink"><strong>使用额外的位图表来标记内存颗粒的状态(空闲/已分配)以及内存单元/对象的起始地址,不仅能提升程序的鲁棒性,而且可以简化对象头部的设计。该策略同时可以加速回收器的操作,并可以在存储器层次结构方面提升回收器的性能。基于位图的分配策略空间开销不大,但其分配过程通常会存在额外的时间开销。</strong></font></p><h2 id="分代间指针"><a href="#分代间指针" class="headerlink" title="分代间指针"></a>分代间指针</h2><p>分代间指针的创建有3种方式:一是在对象创建时写入,二是在赋值器更新指针槽时写入,三是在将对象移动到其他分代时产生。回收器必须要对分代间指针进行记录,只有这样才能确保在对某一分代单独进行回收时根的完整性。</p><h3 id="记忆集"><a href="#记忆集" class="headerlink" title="记忆集"></a>记忆集</h3><p>因此,每个分代的记忆集均只需记录可能指向该分代内部对象的回收相关指针来源。不同的记忆集实现方式在来源地址的记录方面所能达到的精度也各不相同。精度并非越髙越好,较高的精度通常会增大赋值器的额外开销、记忆集空间开销以及回收器处理记忆集的时间开销。</p><h2 id="带式回收框架"><a href="#带式回收框架" class="headerlink" title="带式回收框架"></a>带式回收框架</h2><p>回收策略的基本指导思想大体上可以总结如下:</p><ul><li>“大多数对象都在年轻时死亡”,即弱分代假说。</li><li>分代回收器会避免对年老对象进行频繁回收。</li><li>增量回收可以改善回收停顿时间。在分代垃圾回收器中,新生代的空间通常较小;其他回收技术通常也会限制待回收空间的大小,例如成熟对象空间回收器(mature object space collector)(也称为火车回收器)。</li><li>在较小的诞生空间中使用顺序分配可以提升数据的局部性。</li><li>对象需要足够的时间到达死亡。</li></ul><h2 id="启发式方法在分代垃圾回收中的应用"><a href="#启发式方法在分代垃圾回收中的应用" class="headerlink" title="启发式方法在分代垃圾回收中的应用"></a>启发式方法在分代垃圾回收中的应用</h2><p>分代垃圾回收器可以较好地处理短命对象,但其对长寿对象的处理能力则略显不足,这一问题主要表现在两个方面:第一,年老代垃圾的回收不够及时,因为没有哪种策略可以确保在年老代出现大量垃圾时尽快将其回收;第二,年老代的所有长寿对象都必须是从年轻代复制而来的,同时为避免过早地提升对象,某些回收器要求年轻代对象在得到提升之前必须在年轻代中经历数次回收。对于长寿对象而言,这些复制操作都相当于是无用功,更好的解决方案是直接将长寿对象预分配到其最终可能到达的分代中。</p><p>一些研究者尝试通过分析程序特定代码位置所分配对象的生命周期分布来解决这一问题。这一方案对于虚拟机的开发者来说具有一定的可行性,因为他们可以知道在其具体的虚拟机中哪些数据结构会是永久性的、哪些库或者代码对象永远不会或者至少不太可能被卸载。这些对象的预分配逻辑可以在虚拟机内部实现。</p><h1 id="其他分区策略"><a href="#其他分区策略" class="headerlink" title="其他分区策略"></a>其他分区策略</h1><p>每种回收器都通过一种不同的方式来解决如下3个问题:</p><ul><li>如何最好地利用堆空间</li><li>如何避免对去碎片化操作(复制或标记一整理)的依赖</li><li>如何降低回收器循环的时间开销</li></ul><h1 id="运行时接口"><a href="#运行时接口" class="headerlink" title="运行时接口"></a>运行时接口</h1><p>我们将对象的分配以及初始化过程划分为3个阶段,但并非所有的语言或者所有情况下都需要完成所有阶段。</p><ul><li>阶段1:分配一块大小合适的、符合字节对齐要求的内存单元,这一工作是由内存管理器的分配子系统完成的。</li><li>阶段2:系统级初始化(system initialisation),即在对象被用户程序访问之前,其所有的域都必须初始化到适当的值。例如在面向对象语言中,设定新分配对象的方法分派向量(method dispatch vector)即是该阶段的任务之一。该阶段通常也需要在对象头部设置编程语言或内存管理器所需的头域,对Java对象而言,则包括哈希值以及同步相关信息,而Java数组则需要明确记录其长度。</li><li>阶段3:次级初始化(secondary initialisation),即在对象已经“脱离”分配子空间,并且可以潜在被程序的其他部分、线程访问时,进一步设置(或更新)其某些域。</li></ul><p>Java:阶段1和阶段2共同完成新对象的方法分派向量、哈希值、同步信息的初始化,同时将所有其他域设置为某一默认值(通常全为零)。数组的长度域也在这两个阶段完成初始化。字节码new所返回的对象便处于这一状态,此时尽管对象满足类型安全要求,但其依然是完全“空白”的对象。阶段3在Java语言中对应的表现形式是对象构造函数或者静态初始化程序中的代码,或者在对象创建完成后将某些域设置为非零值的代码段。final域的初始化也是在阶段3中完成的,因此一旦过早地将新创建的对象暴露给其他线程,同时又要避免其他线程感知到对象域的变化,实现起来将十分复杂。</p><h2 id="来自外部代码的引用"><a href="#来自外部代码的引用" class="headerlink" title="来自外部代码的引用"></a>来自外部代码的引用</h2><p>句柄不仅可以作为托管堆和非托管世界之间的一道桥梁,而且可以更好地适应移动式回收器,但并非所有的外部访问都可以遵从这一访问协议,特别是操作系统调用。此时回收器就必须避免移动被外部代码所引用的对象。为此,回收器可能需要提供一个钉住接口,并提供钉住(pin)和解钉(unpin)操作,当某一对象被钉住时,回收器将不会移动该对象,同时也意味着该对象可达且不会被回收。</p><p>如果我们在分配对象时便知道该对象可能需要钉住,则可以直接将其分配到非移动空间中。文件流IO缓冲区便是以这种方式进行分配的。但程序通常很难事先判断哪个对象未来需要钉住,因此某些语言支持pin和unpin函数以便开发者自主进行任何对象的钉住与解钉操作。</p><p>钉住操作在非移动式回收器中不会成为问题,但却会给移动式回收器造成一定不便,针对这一问题存在多种解决方案,每种方案各有优劣。</p><ul><li>延迟回收,或者至少对包含被钉住对象的区域延迟回收。该方案实现简单,但却有可能在解钉之前耗尽内存。</li><li>如果应用程序需要钉住某一对象,且对象当前位于可移动区域中,则我们可以立即回收该对象所在的区域(以及其他必须同时回收的区域)并将其移动到非移动区域中。该策略适用于钉住操作不频繁的场景,同时也适用于将新生代存活对象提升到非移动式成熟空间的回收器(例如分代回收器)。</li><li>对回收器进行扩展以便在回收时不移动被钉住的对象,但这会增加回收器的复杂度并可能引入新的效率问题。</li></ul><h2 id="针对代码的回收"><a href="#针对代码的回收" class="headerlink" title="针对代码的回收"></a>针对代码的回收</h2><p>许多系统会预先对所有代码进行静态编译,但也有一些程序可以在运行时构建并执行代码,例如垃圾回收技术的鼻祖—Lisp语言。尽管Lisp最初是解释型语言,但其在很早就已经能够编译成本地代码。目前,越来越多的系统已经能够动态加载或者构建代码,并在运行时进行优化。由于系统可以动态加载或者生成代码,所以我们自然会希望当这些代码不再使用时,其所占用的空间能够得到回收。面对这一问题,直接的追踪式或引用计数算法通常无法满足该要求,因为许多从全局变量或者符号表可达的函数代码将永远无法清空。某些语言只能靠开发者显式卸载这些代码实例,但语言本身甚至可能根本不支持这一操作。</p><p>另外,还有两个特殊场景值得进一步关注。首先是由一个函数和一组环境变量绑定而成的闭包。我们假设某一简单的闭包是由内嵌在函数f中的函数g,以及函数f的完整环境变量构成的,它们之间可能会共享某一环境对象。Thomas和Jones[1994]描述了一种系统,该系统可以在进行垃圾回收时将闭包的环境变量特化为仅由函数g使用的变量。该策略可以确保某些其他闭包最终不可达并得到回收。</p><p>另一种场景出现在基于类的系统中,例如Java。此类系统中的对象实例通常会引用其所属类型的信息。系统通常会将类型信息及其方法所对应的代码保存在非移动的、不会进行垃圾回收的区域,因此回收器便可忽略掉所有对象中指向类型信息的指针。但是如果要回收类型信息,回收器就必须要对所有对象中指向类型信息的指针进行追踪,在正常情况下这一操作可能会显著增大回收开销。回收器可以仅在特殊模式下才对指向类型信息的指针进行追踪。</p><p><font color="DeepPink"><strong>对于Java而言,运行时类是由其类代码以及类加载器(class loader)同决定的由于系统在加载类时通常会存在一些副作用(例如初始化静态变量),所以类的卸载会变得不透明(即存在副作用—译者注),这是因为该类可能会被同一个类加载器重新加载。唯一可以确保该类不被某个类加载器加载的方法是使类加载器本身也能得到回收。类加载器中包含一个已加载类表(以避免重复加载或者重复初始化等),运行时类也需要引用其类加载器(作为自身标识的一部分)。因此,如果要回收一个类,则必须确保其类加载器、该类加载器所加载的其他类、所有由该类加载器所加载的类的实例都不被现有的线程以及全局变量所引用(此处的全局变量应当是由其他类加载器加载的类的实例)。另外,由于引导类加载器(bootstrap class loader)永远不会被回收,所以其所加载的任何类都无法得到回收。由于Java类卸载是一种特殊的情况,所以某些依赖这一特性的程序或者服务器可能会因此耗尽空间。</strong></font></p><h2 id="读写屏障"><a href="#读写屏障" class="headerlink" title="读写屏障"></a>读写屏障</h2><h3 id="卡表"><a href="#卡表" class="headerlink" title="卡表"></a>卡表</h3><p>卡表(卡标记)策略将堆在逻辑上划分为固定大小的连续区域,每个区域称之为卡。卡通常较小,介于128~512字节之间。卡表最简单的实现方案是使用字节数组,并以卡的编号作为索引。当某个卡内部发生指针写操作时,写屏障将该卡在卡表中对应的字节设置为脏。卡的索引号可以通过对指针域的地址进行移位获得。卡表的设计初衷在于尽量简化写屏障的实现并提高其性能,从而将其内联到赋值器代码中。另外,与哈希表或者顺序存储缓冲区不同,卡表不存在溢出问题。但这些收益总是要付出一定代价的:回收器的工作负荷会加重,因为回收器必须对脏卡中的域进行逐个扫描,并找出其中已被修改的、可能包含回收相关指针的域,此时回收器的工作量将正比于已标记卡的数量(以及卡的大小),而非产生回收相关指针的写操作的发生次数。</p><p>使用卡表的目的在于尽可能减轻赋值器的负担,因而其通常应用在无条件写屏障中,这便意味着卡表必须能够将所有可能被 Write操作修改的地址映射到卡表中的某个槽。如果我们可以确保堆中的某些区域永远不可能写入回收相关指针,同时引入条件检测来过滤掉这些区域的指针写操作,则可以减少卡表的大小。例如,如果将堆中高于某一固定虚拟地址边界的空间用作新生区(回收器在每次回收过程中都处理该区域),则卡表只需要对低于该边界地址的空间创建对应的槽。</p><p><font color="DeepPink"><strong>最紧凑的卡表实现方式应当是位数组,但多种因素决定了位数组并非最佳实现方案。</strong></font>现代处理器的指令集并不会针对单个位的写入设置单独的指令,因而位操作比原始操作需要更多的指令:读取一个字节、通过逻辑运算设置或清除一个位、写回该字节。更糟糕的是,这些操作序列并不是原子化的,多线程同时更新同一个卡表条目可能会导致某些信息丢失,即使它们所修改的是堆中不同的域或者对象。正因如此,卡表才通常使用字节数组。由于处理器清空内存的指令的执行速度更快,所以通常使用0来表示“脏”标记。在使用字节数组的场景下,在卡表中设置脏标记只需要两条SPARC指令(其他架构所需的指令可能会稍多一些)。</p><p><font color="DeepPink"><strong>Detlefs等观察发现,绝大多数卡都是干净的,且单个卡中很少会包含超过16个分代间指针。因此可以使用两级卡表来加速回收器查找脏卡的过程,尽管这一策略会付出额外的空间开销。第二级卡占用的空间更小,其中的每个槽对应2<sup>n</sup>个粒度更细的卡,因而其能够将干净卡的扫描速度提升n倍。</strong></font></p><h1 id="特定语言相关内容"><a href="#特定语言相关内容" class="headerlink" title="特定语言相关内容"></a>特定语言相关内容</h1><h2 id="弱引用"><a href="#弱引用" class="headerlink" title="弱引用"></a>弱引用</h2><h3 id="对不同强度指针的支持"><a href="#对不同强度指针的支持" class="headerlink" title="对不同强度指针的支持"></a>对不同强度指针的支持</h3><p>每种强度的引用通常会与回收器的特定行为相关联。在支持多种不同强度的弱引用的编程语言中,最知名的当属Java,其提供的引用类型从最强到最弱可以分为以下几种:</p><ul><li>强引用(strong reference):普通的引用,具有最高的引用强度。回收器永远不会将强引用置空。</li><li>软引用(soft reference):回收器可以根据当前的空间使用率来判定是否需要将软引用置空。如果Jaa回收器将某个指向对象O的软引用置空,它必须在同一时刻自动将所有导致对象O强可达的软引用置空。这一规则可以确保在回收器将这些引用置空之后,对象将不再软可达。</li><li>弱引用(weak reference):一旦回收器发现某一(软可达的)弱引用的目标对象变为弱可达,则回收器必须将该引用置空(从而确保其目标对象不再软可达)。与软引用类似旦回收器将某个指向对象O的弱引用置空,则必须同时将所有其他导致该对象软可达的软可达弱引用置空。</li><li>终结方法引用(finaliser reference):我们将从终结表到待终结对象的引用称为终结方法引用。终结方法引用只在运行时系统内部出现,它并不会像弱对象一样暴露给开发者。</li><li>虚引用(phantom reference):Java中最弱的一种引用类型。虚引用只有与通知机制联合使用才具有一定意义,这是因为虚引用对象不允许程序经由该引用获取目标对象的引用,因此程序唯一可能的操作是将虚引用置空。程序必须显式地将虚引用置空来确保回收器将其目标对象回收。</li></ul><p>Java语言中不同强度的引用并没有我们此处描述的这么多,但此处的每种语义却与语言规范所定义的每种弱引用相关联。软引用允许系统对可调整的缓存进行收缩;弱引用可以用于规范化表或者其他场景;虚引用允许开发者控制回收的顺序以及时间。</p><p>多强度引用的实现需要在回收过程中增加额外的遍历,但这些操作通常可以很快完成。下面我们以Java的4种强度为例来描述复制式回收器对不同强度引用的处理方式。标记清扫回收器也可以通过类似的方式实现,同时也会更加简单。回收器应当以如下方式执行堆遍历过程：<br>1)从根开始,仅对强可达对象进行追踪并复制,同时找出所有的软对象、弱对象、虚对象(但不对这些对象进行追踪)。<br>2)如果必要,则自动将所有软引用置空。如果无需将软引用置空,则需对其进行追踪和复制,并找出所有的软可达对象。对软可达对象进行追踪时可能会发现新的弱可达或虚可达对象。<br>3)如果弱引用的目标对象已被复制到目标空间,则更新该引用,否则将该引用置空。<br>4)如果尚未复制的对象中存在需要终结的对象,则将其加入终结队列,然后回到第1步,并以终结队列作为新的根进行追踪。需要注意的是,在第二轮执行过程中将不会再有需要终结的对象产生。<br>5)如果虚引用的目标对象并未得到复制,则将其加入ReferenceQueue里。然后回收器将从该对象开始完成虚可达对象的追踪与复制。需要注意的是,回收器不会将任何虚引用置空,这一操作必须由开发者显式操作。</p><h3 id="使用虚对象控制终结顺序"><a href="#使用虚对象控制终结顺序" class="headerlink" title="使用虚对象控制终结顺序"></a>使用虚对象控制终结顺序</h3><p>假设有两个对象,A和B,我们希望它们的终结顺序是先A后B。一种实现策略是创建虚对象A来持有对象A的虚引用。除此之外,A的类型应该是对Java的PhantomReference的扩展,其将持有一个指向对象B的强引用,以避免对象B被提早终结。图12.5演示了这一情况。<br><img src="/images/the-garbage-collection-handbook-the-art-of-automatic-memory-management-note/12.5%E6%8C%89%E5%BA%8F%E7%BB%88%E7%BB%93.png" alt><br>一旦对象A’(即对象A的虚引用来源)加入到用户指定的队列,意味着对象A已经从应用程序不可达,并且A对应的终结方法已经运行过,这是因为终结队列可达要比虚可达的强度更高。然后我们将虚对象A指向A的虚引用图12.5按序终结。我们希望在对象A和B置空,再将其指向B的强引用置空,如此一来,对象B的终结方法将在下一轮回收中得到调用最后我们再把虚对象从全局对象表中删除,则虚对象本身也将得到回收。我们很容易将该策略进行推广,进而实现三个或者更多对象的终结顺序控制,所付出的代价是在两两对象之间通过虚对象来施加终结顺序限制。</p><p>终结顺序的控制只能通过虚对象完成,弱对象无法胜任。对于图12.5所示的状态,如果我们将虚对象替换为弱对象,则当对象A不可达时,A中的弱引用将被置空,且A’将被添加到用户指定的队列中。此时我们可以将A中指向B的强引用置空,但不幸的是,置空A中弱引用的操作将发生在A的终结方法执行之前(因为弱引用的强度高于终结方法引用——译者注),此时我们将很难知道A的终结方法何时执行完毕,因此对象B的终结方法可能会先得到执行。故意将虚引用的强度设计得比终结方法引用更低,目的正在于确保只有当对象的终结方法执行完毕之后,其虚引用来源才会被加入到用户指定的队列。</p><h3 id="弱指针置空时的通知"><a href="#弱指针置空时的通知" class="headerlink" title="弱指针置空时的通知"></a>弱指针置空时的通知</h3><p>在弱引用机制之上,某些应用程序可能需要在特定的弱引用被清空时得到通知(虚引用可以通知应用程序对象已被终结,而弱引用则可以通知应用程序对象可能将要终结),然后再执行某些适当的动作。因此,弱引用机制通常也会支持通知,其实现策略一般是将弱对象添加到开发者指定的队列中。例如,Java的ReferenceQueue内建类便是以此为目的设计的,应用程序既可以对其进行轮询,也可使用阻塞式的操作来获取元素(或者附加额外的超时时间)。应用程序也可以检测某个给定的弱对象是否已经加入到某个队列中(Java只允许弱对象最多被加入到一个队列中)。回收器在对弱指针的多次遍历过程中可以很轻松地实现弱对象的人队。许多语言都增加了类似的通知机制。</p><h1 id="并发算法预备知识"><a href="#并发算法预备知识" class="headerlink" title="并发算法预备知识"></a>并发算法预备知识</h1><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><h3 id="处理器与线程"><a href="#处理器与线程" class="headerlink" title="处理器与线程"></a>处理器与线程</h3><p>处理器(processor)是硬件执行指令的单元。线程(thread)是单一顺序控制流,是软件执行的具体化。线程的状态可以是运行中(running)(也称调度中(scheduled))、可运行(ready to run),或者是为等待某些条件而被阻塞(blocked),例如等待消息的到来、输入/输出的完成,或者到达特定的时间。调度器(scheduler)通常是操作系统组件,其功能是确定在任意时刻哪些线程应当在哪些处理器上执行。如果某个线程被调度器从某个处理器换出(其状态从运行中转变为可运行或者被阻塞),则当其下一次被调度时很可能会在另一个不同的处理器上运行。当然,调度器也允许线程和处理器之间存在一定的亲和性(affinity)。</p><p>某些处理器硬件支持多个逻辑处理器共用一条指令流水线,该技术称为同时多线程(simultaneous multithreading,SMT)或者超线程(hyperthreading)。这一概念会给我们的定义带来一定的麻烦。在我们的术语中,逻辑处理器通常被称为线程,但在此处,同时多线程处理器则可以看作是多(逻辑)处理器,并可以独立进行调度,因而线程这一概念便只能代表软件实体。</p><p>多处理器(multiprocessor)是包含多个处理器的计算机。片上多处理器(chip multiprocessor,CMP)是指在单个集成电路芯片上集成多个处理器的技术,也称多核处理器(multicore processor)甚至众核处理器(many-core processor)。抛开并发多处理器的概念不谈,多线程(multithread)是指使用多个线程的软件,且每个线程可能在多个处理器上并发运行。多程序(multiprogram)是指在单一处理器上执行多个进程或者线程的软件。</p><h3 id="处理器与内存之间的互联"><a href="#处理器与内存之间的互联" class="headerlink" title="处理器与内存之间的互联"></a>处理器与内存之间的互联</h3><p>多处理器与集群计算、云计算或者分布式计算的区别在于,前者存在每个处理器都可以直接访问的共享内存。处理器对共享内存的访问需要以某种互联网络作为媒介。最简单的互联方式是处理器和内存之间使用单个共享总线(bus)来传递信息。我们可以简单地将内存访问操作看作是处理器和内存单元之间的消息通信,每次通信所需的时间可能会达到上百个处理器时钟周期。单个总线的原始速度相当快,但该速度在多处理器同时发起请求时却仍然会成为瓶颈。带宽最高的互联方式可能是在处理器和内存两两之间建立私有通道,但该方案所需的硬件资源却会正比于处理器和内存单元数量的乘积。为获取更高的整体带宽(整个系统中处理器和内存在一秒内可以传输的数据量,将内存分割成多个单元也是一种不错的方案。另外,处理器与内存之间的数据传输通常都是以高速缓存行而非单独的字或者字节为单位的。</p><p>对于更大的片上多处理器,一次内存访问请求在互联网络中的传递可能需要经过多个节点,例如当互联网络以网状或者环状方式组织时。此处的具体细节超出本书的讨论范围,但我们需要了解的是,内存的访问时间可能会随着处理器与内存单元在互联网络中的位置不同而发生变化。另外,相同互联路径上的并发访问也可能引发更大的延迟。</p><p><font color="DeepPink"><strong>在单总线系统中,当处理器的数量达到8~16个之后,总线一般都会成为瓶颈。但相比其他互联方式,总线的实现通常更加简单且更加廉价,且总线允许每个单元侦听(listen)总线中的所有通信(有时也称为窥探(snoopIng),这可以简化系统对高速缓存一致性的支持。</strong></font></p><p><font color="DeepPink"><strong>如果内存单元与处理器之间相互独立,则该系统可以称为对称多处理器(symmetric multiprocessor,SMP)架构,该架构中每个处理器访问任意内存单元的时间都是相同的。我们同样也可以将内存与每个处理器相关联,此时处理器在访问与自身关联的内存时速度更快,而在访问与其他处理器关联的内存时则速度较慢。此类系统被称为非一致内存访问 (non-uniform memory access,NUMA)架构。同一系统可以同时包含全局的SMP内存以及NUMA内存,每个处理器还可以拥有私有内存,但共享内存与垃圾回收技术的关联更大。</strong></font></p><p>对于处理器与内存之间的互联,最值得注意的地方是内存访问需要花费较长的时间,且互联网络可能成为系统的瓶颈,与此同时,不同处理器访问内存的不同部分可能会花费不同的时间。</p><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>尽管内存在物理上可能会跨越多个内存单元或者处理器,但从垃圾回收器的角度来看,共享内存看起来就是一块由字或者字节组成的单个地址空间。由于内存是由多个可以并发访问的单元组成的,所以我们无法对其在任意时刻的状态给出一个全局性的描述,但是内存中的每个单元(也就是每个字)在每个时刻的状态都是确定的。</p><h3 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h3><p>由于内存的访问速度如此之慢,所以现代体系架构通常会在处理器和内存之间增加一到多层高速缓存,其中所记录的是处理器最近访问过的数据,进而降低了程序运行期间处理器需要访问内存的次数。高速缓存与内存的数据交换是以高速缓存行(也称高速缓存块)为单位的,通常为32或者64字节。如果处理器在访问某一地址时发现其所需要的数据已经存在于高速缓存中,这一情况称为高速缓存命中(cache hit,反之则称高速缓存不命中(cache miss),此时处理器便需访问更高一级缓存,如果最高一级缓存依然不命中,则处理器必须访问内存。片上多处理器(CMP)中某些处理器可能会共享最高一级缓存,例如,每个处理器可能都拥有专属的L1高速缓存,但是其会与相邻的一个存储器共享L2高速缓存。各级高速缓存的缓存行大小可以不同。</p><p>当某一级缓存出现不命中,且该级缓存也无法容纳新的缓存行时,处理器就必须依照某种策略从中选择一个缓存行进行置换,被换出的缓存行称作受害者(victim)。当在缓存中写入数据时,某些缓存使用的是写通(write- through)策略,即当某一缓存行中的数据得到更新时,下一级缓存中的对应数据也会尽快得到更新。另一种策略是写回(write-back),即在被修改的行(也称脏行)得到换出之前其中的数据不会写入下一级缓存,除非进行显式刷新fush)(需要使用特殊的指令)或者显式写回(也需要特殊指令支持)。</p><p>缓存置换策略在很大程度上依赖于缓存的内部组织形式。全相联(fully- associative)缓存允许内存中任意地址的数据放置到缓存的任意一行中,其置换策略也可选择任意一行进行淘汰。与之对应的另一个极端是直接映射(direct-maped)缓存,即内存中某一地址的数据只能放置到缓存中特定的行,因而其置换策略只可能淘汰特定的缓存行。k路组相联(k-wayset- associative)缓存是上述两种极端方案的折中,该策略允许内存中特定地址的数据映射到缓存中的k个缓存行,其置换策略也可从这k个缓存行中选择一个进行淘汰。这三种基本的缓存置换策略还存在其他一些变种,例如受害者缓存(victim cache),该缓存包括一个使用直接映射策略的主缓存以及一个额外的容量较小的全相联缓存,从主缓存中淘汰的行将被置于全相联缓存中。该策略的缓存相联性较高,且硬件开销较小。</p><p>高速缓存设计中需要注意的另一方面是各级缓存之间的关系。对于相邻两级缓存,如果较低级别缓存中的数据一定会在高级别缓存中存在,则两级缓存为(严格)包容(inclusive)关系。相反,如果同一数据最多只能出现在两级缓存中的一级,则两级缓存为排他(exclusive)关系。真正的高速缓存设计也可进行折中,即允许同一行存在于两级缓存中,但也并不强制要求高级别缓存一定要包容低级别缓存的数据。</p><h3 id="高速缓存一致性"><a href="#高速缓存一致性" class="headerlink" title="高速缓存一致性"></a>高速缓存一致性</h3><p>高速缓存中所持有的数据在内存中很可能是共享的。由于每个缓存中的数据不可能同时得到更新(特别是对于使用写回策略的缓存),所以内存中同一地址的数据在不同缓存中的副本可能会出现不一致。因此,不同处理器在同一时刻读取同一地址的数据,可能会获得不同的结果,这显然是不应该出现的。为解决这一问题,底层硬件通常会提供一定级别的高速缓存一致性支持。<font color="DeepPink"><strong>一种经典的高速缓存一致性协议(coherence protocol)是MESI,在该协议中,每个缓存行可能有4种状态,这4种状态的首字母构成了该协议的名称。</strong></font></p><ul><li>被修改(modified):该缓存行持有数据的唯一有效副本,其中的数据被修改过,但尚未写回内存。</li><li>独占(exclusive):该缓存行持有数据的唯一有效副本,同时其中的数据与内存保持一致。</li><li>共享(shared):其他缓存行也可能持有数据的有效副本,同时所有副本中的数据均与内存保持一致。</li><li>无效(Invalide):缓存行中不包含任何有效数据。</li></ul><p>只有当缓存行的状态为“被修改”、“独占”、“共享”其中之一时,处理器才可以读取该缓存行;只有当缓存行的状态为“被修改”或“独占”时,处理器才可以将数据写入该缓存行,写入之后其状态将成为“被修改”。如果处理器需要从“无效”缓存行中读取数据,则系统的后续行为取决于该缓存行在其他缓存中的状态:如果为“被修改”,则处理器必须将其写回内存,并将其状态置为“共享”(或者“无效”);如果状态为“独占”,则只需将其降级为“共享”(或“无效”);如果其状态为“共享”或者“无效”,则处理器只需简单地从内存或者其他缓存里状态为“共享”的缓存行中加载数据。如果处理器需要将数据写入“无效”缓存行中,系统的后续行为与读取时的行为类似,唯一的不同之处在于其他缓存行的最终状态都将是“无效”。如果处理器需要将数据写入“共享”缓存行中,其必须先将其他缓存行降级为“无效”。该协议可以进行的改进包括:以写为目的读可以在读取完成之后将其他缓存行的状态降级为“无效”;写回操作可以将缓存行的状态从“被修改”降级为“独占”;令某一缓存行失效的操作可以将状态为“被修改”的缓存行写回内存,然后将其状态置为“无效”。</p><p><font color="DeepPink"><strong>MESI协议的关键之处在于,任意缓存行在同一时刻只能被一个处理器写,且两个缓存针对同一数据的缓存行永远不会产生不一致。MESI协议的实现难点在于,当处理器数量增大时算法的性能会下降,这也是所有由硬件支持的缓存一致性协议的共有问题。因此,更大的片上多处理器逐渐开始放弃内建的缓存一致性协议,转而开始由软件来管理一致性,此时软件便可选择任意类型的缓存一致性协议。即便如此,处理器数量增大时算法依然会存在性能问题,但与将算法固化在硬件中的策略相比,开发者至少可以根据其具体需求选择更好的致性算法。</strong></font></p><p><font color="DeepPink"><strong>缓存一致性要求引发了另一个问题,即伪共享(false sharing):当两个处理器同时访问并更新位于相同缓存行的不同数据时,由于处理器在写操作之前必须将缓存的状态更改为“独占”,所以两个处理器令对方缓存行失效的操作会产生“乒乓”效应,从而引发互联网络中大量的一致性通信,并可能引发额外的内存读取操作。</strong></font></p><h3 id="高速缓存一致性对性能的影响示例-自旋锁"><a href="#高速缓存一致性对性能的影响示例-自旋锁" class="headerlink" title="高速缓存一致性对性能的影响示例:自旋锁"></a>高速缓存一致性对性能的影响示例:自旋锁</h3><p>典型的互斥锁可以通过AtomicExchange原语实现,如算法13.1所示。后续描述中我们均以首字母大写的方式来区分原子指令原语,我们同时也使用首字母小写的1oad和store来表示低级读写操作,并以此避免与应用程序和赋值器之间的读写接口混淆。锁的初始值应该为零,意味着未上锁。如果尝试加锁失败,处理器将在whie循环中自旋,因而称其为自旋锁。每次循环中,原子化的“读一修改-写”操作都会尝试独占其所在的高速缓存行,因而如果多处理器竞争该锁,高速缓存行将会出现“乒乓”效应,即使对于已经持有锁的处理器也不例外。更加糟糕的是,即使持有锁的处理器想要释放锁,其也需要与其他处理器竞争该高速缓存行的独占权。此种自旋锁实现方式被称为“检测并设置”锁(test-and- set lock)尽管它并未依赖我们后文将要介绍的 TestAndset原语。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 算法13.1基于 AtomicExchange原语的自旋锁</span><br><span class="line">exchangeLock(x):</span><br><span class="line">while AtomicExchange(x, 1)=1</span><br><span class="line">/*空*/</span><br><span class="line"></span><br><span class="line">exchangeUnlock(x):</span><br><span class="line">*x &lt;- 0</span><br><span class="line"></span><br><span class="line">AtomicExchange(x, v):</span><br><span class="line">atomic</span><br><span class="line">old ← *X</span><br><span class="line">*x &lt;- v</span><br><span class="line">return old</span><br></pre></td></tr></table></figure><p>算法13.1所描述的自旋锁的实现方式会导致最严重的一种竞争情况出现,因而算法13.2所描述的“检测一检测并设置”锁(test-and-test-and-set lock)作为一种更加巧妙的改进版本,在许多程序中得到应用。其最大的改进之处在于第10行,算法在调用AtomicExchange方法之前先通过一般的读操作判断锁是否已被占用,因而此处的自旋操作只需访问处理器自身的(已经保持一致)的高速缓存,无需进一步访问总线。如果锁位于不可缓存(noncacheable)的内存中,则该线程可以使用空循环来等待,也可在检测之间插入硬件iale指令,如果等待时间稍长,则在两次检测之间的等待时间可以呈指数级别增加或者采用其他类似算法。如果等待时间过长,则线程可以请求操作系统的调度器介入并放弃剩余时间片,或者转而采取等待某一显式信号的方式,此时便要求锁的持有者在释放锁时发送信号。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//算法13.2基于AtomicExchange原语的“检测一检测并设置”自旋锁</span><br><span class="line">testAndTestAndSetExchange Lock(x):</span><br><span class="line">while testAndExchange(x)=1</span><br><span class="line">/*空*/</span><br><span class="line"></span><br><span class="line">testAndTestAndSetExchangeUnlock(x):</span><br><span class="line">*x &lt;- 0</span><br><span class="line"></span><br><span class="line">testAndExchange(x):</span><br><span class="line">while *x=1</span><br><span class="line">/*空*/</span><br><span class="line">return AtomicExchange(x, 1)</span><br></pre></td></tr></table></figure><h2 id="硬件内存一致性"><a href="#硬件内存一致性" class="headerlink" title="硬件内存一致性"></a>硬件内存一致性</h2><p>我们假定共享内存可以提供与高速缓存相同的一致性(coherence)保障,即:不存在未完成的写操作。如果两个处理器读取内存中相同位置的值,所获取的值也是相同的。<font color="DeepPink"><strong>大多数硬件还可以进一步保证:如果两个处理器同时对内存的相同位置发起写操作,则其中的一个将先于另一个发生,同时所有处理器后续读取到的值都将是最后一次写入的值。另外,如果某一处理器已经读取到了最终的值,则在下一次写操作发生之前,其不可能读取到其他值。也就是说,针对内存中任何特定位置的写操作都是经过排序的,且在任意处理器看来,特定位置值的变化顺序都是相同的。</strong></font></p><p>但是,对于程序在多个位置的写入(或者读取)操作,硬件系统却不能保证程序发起操作的顺序与其在高速缓存或者内存中的生效顺序完全一致,更不能保证其他处理器能够以相同的顺序感知到这些地址的数据变更。也就是说,程序顺序(program order)不一定要与内存顺序(memory order)完全一致。读者可能不禁会问:为何如此?其中的含义是什么?前一个问题关乎于硬件和软件,概括来讲,不要求两者完全一致是出于性能考虑—严格一致性(consistency)要么会耗费更多的硬件资源,要么会降低性能,或者两者兼有。对于硬件而言,许多处理器会使用写缓冲区(write buffer/store buffer)来保存未完成的内存写入操作。写缓冲区本质上是一个&lt;地址,数据&gt;对组队列。正常情况下,写操作可能会有序执行,但如果某一后发写操作的目的地址已经存在于写缓冲区中,则硬件可能会将其合并到队列里尚未完成的写操作中,这便意味着写操作可能会出现“后发先至”的情况,即较晚的写操作可能会越过较早的、针对其他地址的写操作而立即在内存中生效。处理器的设计者会小心地确保处理器操作针对其自身的一致性,也就是说,如果处理器在读取某一位置的值时发现该位置存在未完成的写操作,则处理器要么通过直接硬件路径(速度较快但开销较大)来读取该值,要么必须等写缓冲区刷新完毕后再从高速缓存中读取该值。另一个可能导致程序操作被重排序的原因是高速缓存不命中。一旦读取过程中发生高速缓存不命中,许多处理器会将其跳过并继续执行后续指令,进而可能出现后发读/写操作越过先发读/写操作先执行完毕的情况。另外,对于使用写回机制的高速缓存,其中的数据只有在被淘汰或者显式刷新时才会写入内存,因此针对不同缓存行的写操作的执行顺序可能会出现大幅度调整。上述各种硬件方面的原因只是说明性的,但并非面面俱到。</p><p>由软件产生的重排序大多是由编译器造成的。例如,如果编译器已知两个引用指向的是同一地址,且两个引用的读取操作之间并无其他写操作会影响该值,则编译器可能直接使用其第一次读取到的值优化掉第二次读操作。更一般的情况是,如果编译器可以确保各变量之间均不存在别名关系(即不引用相同的内存地址),则其可以对这些变量的读写操作以任意方式重排序,因为不论采用何种顺序,最终的执行结果都是相同的(对于单处理器而言,且假定不存在线程切换)。读取结果复用以及重排序策略可以产生更高效的代码,且在大多数情况下并不影响语义,因而许多编程语言都允许这一策略。</p><p>从开发者的角度来看,程序顺序与内存顺序之间缺乏一致性显然是一个潜在的问题,但是从硬件实现者的角度来看,如此设计可以大幅提升性能并减少开销。</p><p>放宽一致性要求将会产生怎样的后果?第一,这可能导致程序的执行完全背离开发者的意图,也可能导致在完全一致性模型下可正常执行的代码在更加复杂的一致性模型下产生混乱的执行结果。第二,锁相关等技术要求硬件以某种方式确保对不同地址的访问能够有序执行。各种顺序模型必须能够区别出3种主要的访问原语:读(read)、写( write)、原子(atomic)操作。原子操作需要原子化的“读一修改-写”原语,该原语通常是条件性的,例如TestAndset。内存一致性对于依赖加载(dependent load)也十分重要,所谓依赖加载,即程序需要先从地址x加载数据,然后再从地址y加载数据,但第二次加载操作的地址y取决于地址x的加载结果。依赖加载的一个典型案例是沿着指针链进行追踪。在完全一致性之外,还存在着许多较弱的内存访问顺序模型,我们将选择其中较为常见的进行介绍。</p><h3 id="内存屏障与先于关系"><a href="#内存屏障与先于关系" class="headerlink" title="内存屏障与先于关系"></a>内存屏障与先于关系</h3><p><font color="DeepPink"><strong>内存屏障(memory fence)是一种处理器操作,它可以阻止处理器对某些内存访问进行重排序。</strong></font>特别地,它可以避免某些访问指令在屏障之前发送(issue),也可以避免某些访问指令被延迟到屏障之后发送,或者两者皆可。例如,完全读内存屏障可以确保屏障之前的所有读操作都能先于屏障之后的读操作执行。</p><p>先于关系(happens- before)这一概念则更加规范化,它是指内存访问操作在存储中所应遵从的发生顺序。完全读内存屏障相当于是在每两个相邻读操作之间施加了先于关系。<font color="DeepPink"><strong>原子操作通常会为其内部的所有子操作施加完全内存屏障:所有较早的读、写、原子操作都必须先于较晚的读、写、原子操作发生。</strong></font>在先于关系之外还存在其他一些模型,例如获取一释放(acquire-release)语义。在该模型下,获取操作(acquire operation)(可以将其看作是获取锁)能够阻止较晚操作在该操作之前发生,但较早的读写操作则可以在获取操作之后发生;释放操作(release operation)与之完全对称:它能够阻止较早的操作在释放操作之后发生,但是较晩的操作则可以在释放操作之前发生。简而言之,处理器可以将获取一释放操作对之外的操作移动到其内部,但却不能将其内部的操作移动到外部。临界区(critical section)便可使用获取一释放模型来实现。</p><h3 id="内存一致性模型"><a href="#内存一致性模型" class="headerlink" title="内存一致性模型"></a>内存一致性模型</h3><p>最强的内存一致性模型当属严格一致性(strict consitency),即所有的读、写、原子操作在整个系统中的任意位置都以相同的顺序发生(occur)。严格一致性意味着所有操作的发生顺序都满足先于关系,且这一顺序是由某一全局时钟决定的。严格一致性是最容易理解的种模型,这可能也是大多数开发者以为硬件系统所遵从的顺序,但这一模型很难高效地实现。稍弱的一种模型是顺序一致性(sequential consistency)模型,在该模型中,全局先于顺序只需要与每个处理器的程序顺序保持一致即可。相对于其他更加宽松的一致性模型,顺序一致性模型下的编程更加简单,因而规模较小的处理器通常会尝试达到或者接近顺序一致性的要求。弱一致性(weak consitency)会将所有原子操作当作完全屏障。上文所描述的获取释放模型通常被称为释放一致性(release consitency)模型。因果一致性(causal consistency)模型的强度介于顺序一致性和弱一致性之间,该模型要求程序所发起的读操作与其后续的写操作之间必须满足先于关系,其目的在于避免读操作对写操作所写入的值造成影响,即对于先读取某个值然后再将其写入内存的操作,因果一致性会确保它们之间的先于关系。宽松一致性(relaxed consistency)模型泛指所有比顺序一致性模型更弱的模型。</p><p><img src="/images/the-garbage-collection-handbook-the-art-of-automatic-memory-management-note/13.1%E5%86%85%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8F%AF%E8%83%BD%E7%9A%84%E9%87%8D%E6%8E%92%E5%88%97%E6%96%B9%E5%BC%8F.png" alt></p><h2 id="硬件原语"><a href="#硬件原语" class="headerlink" title="硬件原语"></a>硬件原语</h2><h3 id="比较并交换"><a href="#比较并交换" class="headerlink" title="比较并交换"></a>比较并交换</h3><p>即先判断内存地址的当前值,然后再尝试原子性地将其更新,该操作通常被称为“比较一比较并交换”(compare-then- compare-and-swap)。CompareAndSwap原语潜藏着一个微妙的陷阱,即在调用CompareAndSwap时,目标内存地址的值改变了数次,但该地址的当前值却与调用者之前获取到的值相等。某些情况下这可能不会出现问题,但在其他情况下,相同的值并不意味着相同的状态。例如在垃圾回收中,在经历两次半区复制回收之后,某一指针的目标对象很可能与其最初的目标对象完全不同。CompareAndswap原语无法探测到“某个值被修改,然后再被改回原值”的情况,即所谓的ABA问题(ABA problem)。</p><h3 id="加载链接-条件存储"><a href="#加载链接-条件存储" class="headerlink" title="加载链接/条件存储"></a>加载链接/条件存储</h3><p>在LoadLinked和StoreConditionally原语中,处理器会记录LoadLinked原语所访问的地址,并使用处理器的一致性机制来探测所有针对该地址的更新操作,从而解决ABA问题。</p><p>LoadLinked/StoreConditionally原语还有另外一个特征需要注意:即使任何处理器都没有更新过保留地址的值, StoreConditionally原语也有可能出现假性失败。多种低级硬件状况可能导致假性失败,其中值得注意的是中断的出现,包括缺页陷阱、溢出陷阱、时钟中断、IO中断等,这些中断均需要由内核进行处理。这种失败通常不会成为问题,但是如果Loadlinked和StoreConditiona11y之间的某段代码总是引发陷阱,则StoreConditionallsy操作可能始终都会失败。</p><p>由于LoadLinked/StoreConditionally原语可以优雅地解决ABA问题,所以我们更加倾向于用其替代可能产生ABA问题的 CompareAndSwap原语。当然,我们也可为CompareAndswap原语关联一个计数器来解决ABA问题。</p><p>严格意义上讲,如果StoreConditionally原语所操作的并非之前保留的地址,则其最终结果可能是未定义的。但某些处理器在设计上便允许这种使用方式,这相当于提供了一种在某些场景下有用的、针对任意两个内存地址的原子操作。</p><h3 id="原子算术原语"><a href="#原子算术原语" class="headerlink" title="原子算术原语"></a>原子算术原语</h3><p>我们也可使用AtomicAdd或FetchAndAdd原语来实现 AtomicIncrement和AtomicDecrement操作,且其返回值既可以是原始值,也可以是新值。另外,处理器在执行这些原语时通常会设置条件码(condition code),其值可以用于反映目标地址的值是否为零(或者原始值为零),也可反映其他一些信息。在垃圾回收领域, FetchAndAdd原语可以用于实现并发环境下的顺序分配(即阶跃指针分配),但更好的做法通常是为每个线程建立本地分配缓冲区。FetchAndAdd可以简单地用于从队列中添加或者移除元素的操作,但是对于环状缓冲区,还需要小心地处理回绕(wrap-around)问题。</p><p>这些原子算术原语的能力严格弱于CompareAndswap,同时也弱于LoadLinked/StoreConditionally(参见Herlihy and Shavit)。每种原语都存在一个可以用一致数(consensus number)来描述的特征,如果某个原语的一致数为k,意味着它可以解决k个线程之间的一致问题,但无法解决多于k个线程之间的一致问题。所谓一致问题,是指多处理器算法是否能达到如下要求:</p><ol><li>对于某个变量,每个线程均建议一个值;</li><li>所有线程针对某个值达成一致;</li><li>该变量的最终值为某个线程所建议的值;</li><li>所有线程均能够在有限步骤内完成操作,即算法必须满足无等待(wait-free)要求。</li></ol><p>对于所有的无条件设置原语(例如AtomicExchange)或者对相同值产生相同运算结果的更新原语(如AtomicIncrement与FetchAndAdd),其一致数均为2。而CompareAndSwap和LoadLinked/StoreConditionally的一致数则为∞,即它们能够以无等待的方式解决任意多个线程之间的一致问题。</p><p>无条件算术原语的一个潜在优势在于它们通常都会成功,而如果使用CompareAndSwap或者LoadLinked/StoreConditionally来模拟无条件算术原语,线程之间的竞争很可能导致“饥饿”现象的出现。</p><h3 id="更加强大的原语"><a href="#更加强大的原语" class="headerlink" title="更加强大的原语"></a>更加强大的原语</h3><p>在我们描述过的硬件原语中,LoadLinked/StoreConditionally的通用性最强,也是针对单字的最强的原子更新语义。除此之外,允许对多个独立字进行原子更新的硬件原语则更加强大。在单字原语之外,某些处理器还支持双字原语,例如双字比较并交换,我们称之为CompareAndSwapWide/CompareAndSetWide。如果仅从概念上来看,该原语的强大之处没得到充分体现。但是,使用双字CompareAndSwap操作却可以轻松应对单字CompareAndswap无法解决的ABA问题,此时我们只需要将第二个字用作记录第一个字被更新次数的计数器。对于32位的字,计数器的值最多可以达到2<sup>32</sup>,因而基本上可以忽略计数器回绕可能带来的安全问题。支持对相邻两个64位的字进行原子更新的硬件原语则更加强大。因此,尽管CompareAndSwapWide在概念上与常规的CompareAndswap并无较大差别,但其在使用上却更加方便、更加高效。</p><p>尽管更新相邻两个字的原子操作原语十分有用,但如果其能够原子化地更新内存中任意两个(不相邻)字则会显得更加强大。 Motorola880000以及Sun的Rock处理器均提供了“双比较并交换”指令(compare-and-swap-two,也称double-compare-and-swap)。 CompareAndswap2的硬件实现较为复杂,因而目前尚无商业级别的处理器支持这一原语。 CompareAndSwap2可以泛化为通用的n路比较并交换(compare-and-swap-n,也称n-way-compare-and-swap),同理,也可对LoadLinkedStoreConditiona1ly原语进行泛化,由此得到的结果便是事务内存(transactional memory)。</p><h3 id="原子操作原语的开销"><a href="#原子操作原语的开销" class="headerlink" title="原子操作原语的开销"></a>原子操作原语的开销</h3><p>开发者经常会错误地使用原子操作原语,其原因之一是他们知道原子操作的开销较大,因而会刻意避免使用原子操作,而另一种原因则是他们可能错误地使用了原子操作。我们曾经提到,有两个原因导致原子操作的开销较大:一是原子化的“读一修改一写”原语必须以独占方式访问相关的高速缓存行;二是在指令结束之前,处理器必须完成数据读取、计算新值、写入新值这一系列操作。现代处理器可能会使用多指令重叠(overlap)技术,但是如果后续操作强依赖于原子操作的结果,则必然会减少流水线中的指令条数。由于原子操作需要确保一致性,因而其通常会涉及总线甚至内存的访问,这通常会花费较多的指令周期。</p><p>另一个导致原子操作执行速度较慢的原因是,它们要么天然包括内存屏障语义,要么要求开发者在其开始和结束位置手动添加额外的内存屏障。这潜在削减了指令重叠与流水线技术所带来的性能优势,从而导致处理器很难隐藏这些原语访问总线或者内存的开销。</p><h2 id="前进保障"><a href="#前进保障" class="headerlink" title="前进保障"></a>前进保障</h2><p>当多个线程之间竞争相同数据结构时(例如共享堆,或者回收器数据结构),确保整个系统能够正常往下执行尤为重要(特别是在实时环境中),我们将这一要求称为前进保障(progress guarantee)。了解不同硬件原语在前进保障方面的相对强度也十分必要,常见的前进保障级别从强到弱分别是:无等待、无障碍、无锁。对于并发算法而言,如果每个线程始终都可以向前执行(不论其他线程执行何种操作),则称其为无等待(wait-free)算法;如果在并发算法中,对于任意一个线程,只要其拥有足够长的独占式执行时间,便能够在有限步骤内完成操作,则称该算法为无障碍(obstruction-free)算法;如果算法永远可以保证某些线程能在有限步骤内完成操作,则称该算法为无锁(lock-free)算法。在真实系统中,前进保障通常是条件性的,例如,某一算法满足无等待要求的条件可能是存储空间尚未耗尽。Herlihy和Shavit对这些概念及其实现进行了详尽的论述。</p><p>无等待算法通常会引入线程互助的概念,也就是说,如果线程t2即将执行的操作可能会打断线程t1正在执行的、在一定程度上可以确定超前于线程n的操作,则线程t2将协助t1完成其工作,然后再开始执行自身工作。假设线程数量存在固定上界,且线程之间相互协助的工作单元或者对数据结构的操作也存在上界,则任何工作单元或者操作的完成步骤便都存在上界。但是,这一上界通常较大,且与较弱的前进保障相比,线程互助需要引入额外的数据结构与工作量,因而其操作时间通常相当长。对于较为简单的一致性场景,为其设计时间开销较小的无等待算法通常比较容易。从中我们可以看出,该算法满足解决N个线程的一致问题的所有标准,但是其空间开销正比于N。</p><p>与无等待要求相比,无障碍更容易实现,但是其可能需要调度器的协助。如果线程发现当前存在竞争,则它可以使用随机递增的时间退让策略来确保其他线程优先完成工作。也就是说,每当线程探测到竞争时,其首先会计算一个比上次退让时间更长的时间周期T,然后再从0~T之间选择某一随机值作为本次退让的时间。从概率上讲,对于较少出现竞争的场景,每个线程最终都会成功执行。</p><p>无锁要求的实现则更加简单,它只要求在任何情况下至少一个竞争者可以继续往下执行,即使其他线程可能会永久性地等待下去。</p><h2 id="工作共享与结束检测"><a href="#工作共享与结束检测" class="headerlink" title="工作共享与结束检测"></a>工作共享与结束检测</h2><h3 id="汇聚屏障"><a href="#汇聚屏障" class="headerlink" title="汇聚屏障"></a>汇聚屏障</h3><p>并发回收或者并行回收中另一种常见的同步机制是要求所有回收线程到达算法的某点(基本上就是某一回收阶段的结束点),然后再继续往下执行。一般情况下,上述任意种结束检测算法都可以胜任这一场景的要求。另一种常见的场景是:算法在某一阶段的工作并不存在任何形式的工作共享或者负载均衡,但其仍要求所有线程都到达指定点,即汇聚屏障(rendezvous barrier)。</p><h2 id="并发数据结构"><a href="#并发数据结构" class="headerlink" title="并发数据结构"></a>并发数据结构</h2><p>有多种通用实现策略可供开发者在构建并发数据结构时选择,这些策略在并发程度方面从最低到最高(通常也是从最简单到最复杂)分别如下:</p><ul><li>粗粒度锁(coarse-grained locking):使用一个“大”锁来控制整个数据结构的访问。</li><li>细粒度锁(fine-grained locking):该方案为较大数据结构中的每个元素维护独立的锁,例如为链表或树中的每个节点维护一个锁。<font color="DeepPink"><strong>如果各线程对数据结构的访问与更新足够分散,则该策略可以显著提升并发程度。</strong></font>该策略通常需要考虑一个问题,即如果某一操作会对多个元素加锁,则其必须保证没有其他相同操作(或者任何其他操作)会以相反的顺序对相同元素进行加锁,否则将导致死锁的产生。一种通用的解决方案是要求所有操作在访问(单链表或者树中的)元素时遵从相同的方向,即锁联结(lock coupling):某一操作先对节点A加锁,然后再对A所指向的节点B加锁,接着再释放节点A的锁并对节点B所指向的节点C加锁,以此类推。使用这一逐步推进策略来遍历数据结构可以确保后发线程无法超越先发的线程,同时也可以确保在链表/树中插入/删除元素操作的安全性。<font color="DeepPink"><strong>细粒度锁的一个潜在缺陷是,对不同元素多次加解锁可能会给共享总线或者存储带来一定开销,进而掩盖了相对于粗粒度锁的优势。</strong></font></li><li>乐观锁(optimistic locking):该方案对细粒度锁进行了改进,<font color="DeepPink"><strong>即线程在对数据结构进行遍历时先不加锁,直到其找到合适元素时才尝试对其进行加锁。但在从发现合适元素到加锁成功的过程中,该元素可能已被其他并发线程修改,因而线程在加锁完成后需要再次对该元素进行校验。如果校验失败,则其需要释放锁并继续查找。这种尽量将加锁操作延迟、直到迫不得已时才加锁的策略可以减少开销并提升并发能力。乐观锁在大多数场景下都具有较高的性能,但如果频繁发生更新冲突,</strong></font></li><li>懒惰更新(lazy update):即使采用乐观锁,只读操作仍需要对其所读取的元素加锁,这不仅会成为提升并发程度的瓶颈,还可能在只读操作中引入写操作(即加解锁)。为此我们可以设计出一种数据结构,在该结构中只读操作无需加锁,代价是更新操作的复杂度稍有提高。<font color="DeepPink"><strong>一般来讲,懒惰更新策略中的写操作需要先达到其在“逻辑上”的目标(前提是不影响其他线程的并发访问),然后再进一步执行真正的更新操作,并确保数据结构回归正常状态。</strong></font>我们可以通过一个例子来理解懒惰更新的含义:对于以链表方式实现的集合, remove操作首先需要(在逻辑上)将待移除元素打上deleted标记,然后再将其前一个节点的指针重定向从而真正实现节点的移除。为避免并发更新可能带来的问题,所有操作都需要在持有相关元素锁的前提下执行。remove操作必须依照先标记再移除的顺序执行,这样才能确保其他线程能够在不加锁的情况下正确进行读操作。向链表中插入元素的操作只需要更新数据结构中的next指针,因而只需要一次更新操作(即无需事先设置标记),当然,这一操作同样必须在持有相关元素锁的前提下执行。</li><li>非阻塞(non-blocking):在非阻塞策略中,对数据结构的所有操作均无需使用锁,仅依赖原子更新原语便可完成数据结构的状态变更。一般来说,状态变更操作通常都会存在某些特殊的原子更新事件,这些事件的发生点即为该操作的线性化点。与此相比,基于锁的策略则需要引入临界区来标识线性化“点”。非阻塞策略的并发能力可以通过前进保障来衡量,无锁实现可能允许部分线程出现饥饿;无障碍实现中的每个线程可能需要足够长的时间进行独占式操作,才能确保算法整体往下执行;无等待实现可以确保所有线程都能正确往下执行。</li></ul><h2 id="需要考虑的问题-2"><a href="#需要考虑的问题-2" class="headerlink" title="需要考虑的问题"></a>需要考虑的问题</h2><p>平台支持哪些原子更新原语?尽管LoadLinked/StoreConditionally原语便于使用且更加高效,但大多数流行系统仅支持 CompareAndSwap或者等价原语,后者可能会遇到ABA问题,但该问题也可通过某种方式来避免。或许在不久的将来,事务内存将逐渐实用化。</p><p>算法需要达到何种级别的前进保障要求?较弱的前进保障更容易实现,也更易于推导。对于访问量较低的数据结构,直接进行加锁可能会更加合适,因为与具有更强前进保障级别的无锁算法相比,加锁不仅容易实现,而且更容易正确地实现。另外,即使在某些已发布的、绝大多数场景满足无等待要求的系统中,某些极端情况的处理仍会使用更加简单的实现技术,将这些非关键场景无等待化并不具有太大价值。</p><h1 id="并行垃圾回收"><a href="#并行垃圾回收" class="headerlink" title="并行垃圾回收"></a>并行垃圾回收</h1><h2 id="并行垃圾回收分类"><a href="#并行垃圾回收分类" class="headerlink" title="并行垃圾回收分类"></a>并行垃圾回收分类</h2><p>不论是对于哪种情况,我们均需要关注算法如何实现回收工作的获取(acquire)、执行(perform)、生成(generate),这3种操作的设计与实现决定了算法所需同步操作的类型、单个回收线程的负载粒度,以及在多个处理器之间进行负载均衡的策略行垃圾回收算法大致可以划分为两大类,即以处理器为中心(processor-centric)的并行算法和以内存为中心(memory- centrIc)的并行算法。在以处理器为中心的算法中,线程所获取的工作通常大小不等,且线程之间通常会存在工作窃取行为。该策略通常不关注线程所处理对象的位置,但通过前面的章节我们知道,即使是在单处理器环境下,局部性都会对处理性能产生显著影响,而对于非一致内存或者异构系统而言,局部性的作用则更加重要。以内存为中心的算法会更多考虑局部性因素,此类算法通常会针对堆中连续内存块进行操作,并从共享工作缓冲区池中获取工作包(或者将工作包释放到全局工作池中),工作包的大小通常固定。绝大多数并行复制式回收器均使用这一策略。</p><p>最后让我们关注并行回收的结束。回收线程不仅会尝试获取工作,而且还会进一步动态地生成新的工作。因此,简单判定共享工作池是否为空通常不足以断定回收过程是否结束,因为活动线程可能还会向工作池中加入新的任务。</p><blockquote><p>14章及以后，只是泛读了一下</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> GC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> GC </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IDEA 个人常用插件</title>
      <link href="/idea-plugin.html"/>
      <url>/idea-plugin.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>IDEA 个人常用插件整理，持续更新中</p></blockquote><a id="more"></a><h1 id="mybatis-lite"><a href="#mybatis-lite" class="headerlink" title="mybatis-lite"></a>mybatis-lite</h1><p>根据数据库表自动生成代码<br>git地址：<a href="https://github.com/mustfun/mybatis-lite" target="_blank" rel="noopener">https://github.com/mustfun/mybatis-lite</a></p><h1 id="MyBatis-Log-Plugin"><a href="#MyBatis-Log-Plugin" class="headerlink" title="MyBatis Log Plugin"></a>MyBatis Log Plugin</h1><p>把mybatis输出的日志还原成完整的sql语句<br>git地址：<a href="https://github.com/kookob/mybatis-log-plugin" target="_blank" rel="noopener">https://github.com/kookob/mybatis-log-plugin</a></p>]]></content>
      
      
      <categories>
          
          <category> IDE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IDE </tag>
            
            <tag> IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>码出高效：Java 开发手册</title>
      <link href="/alibaba-p3c.html"/>
      <url>/alibaba-p3c.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>开发规范</p></blockquote><a id="more"></a><p>在线PDF版本：<a href="/attachments/阿里巴巴Java开发手册（华山版）.pdf" target="_blank">阿里巴巴Java开发手册（华山版）.pdf</a></p><p><a href="https://github.com/alibaba/p3c" target="_blank" rel="noopener">https://github.com/alibaba/p3c</a></p>]]></content>
      
      
      <categories>
          
          <category> 编码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP/IP详解 卷1：协议 笔记</title>
      <link href="/tcp-ip-illustrated-volume-1-the-protocols-notes.html"/>
      <url>/tcp-ip-illustrated-volume-1-the-protocols-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《TCP/IP详解 卷1:协议》<br>作者：W. Richard Stevens</p><a id="more"></a><p><font color="DeepPink"><strong>一个bit是二进制中的最小单位，代表一个0或1的位置。 bit是位。 Byte是字节。 1Byte=8bit。</strong></font></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h2><p>网络协议通常分不同层次进行开发，每一层分别负责不同的通信功能。一个协议族，比如TCP/IP，是一组不同层次上的多个协议的组合。TCP/IP通常被认为是一个四层协议系统，如图1-1所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/TCPIP%E5%8D%8F%E8%AE%AE%E6%97%8F%E7%9A%84%E5%9B%9B%E4%B8%AA%E5%B1%82%E6%AC%A1.png" alt></p><p>每一层负责不同的功能：<br>1)<font color="DeepPink"><strong>链路层，有时也称作数据链路层或网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。</strong></font><br>2)<font color="DeepPink"><strong>网络层，有时也称作互联网层，处理分组在网络中的活动，例如分组的选路。</strong></font>在TCP/IP协议族中，网络层协议包括IP协议（网际协议），ICMP协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议）。<br>3)<font color="DeepPink"><strong>运输层主要为两台主机上的应用程序提供端到端的通信。</strong></font>在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。而另一方面，UDP则为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。这两种运输层协议分别在不同的应用程序中有不同的用途，这一点将在后面看到。<br>4)应用层负责处理特定的应用程序细节。几乎各种不同的TCP/IP实现都会提供下面这些通用的应用程序：</p><ul><li>Telnet 远程登录。</li><li>FTP 文件传输协议。</li><li>SMTP 简单邮件传送协议。</li><li>SNMP 简单网络管理协议。</li></ul><p>在TCP/IP协议族中，网络层IP提供的是一种不可靠的服务。也就是说，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。而另一方面，TCP在不可靠的IP层上提供了一个可靠的运输层。为了提供这种可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。由此可见，运输层和网络层分别负责不同的功能。</p><p>连接网络的另一个途径是使用网桥。网桥是在链路层上对网络进行互连，而路由器则是在网络层上对网络进行互连。网桥使得多个局域网（LAN）组合在一起，这样对上层来说就好像是一个局域网。</p><h2 id="TCP-IP的分层"><a href="#TCP-IP的分层" class="headerlink" title="TCP/IP的分层"></a>TCP/IP的分层</h2><p>在TCP/IP协议族中，有很多种协议。图1-4给出了本书将要讨论的其他协议。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/TCPIP%E5%8D%8F%E8%AE%AE%E6%97%8F%E4%B8%AD%E4%B8%8D%E5%90%8C%E5%B1%82%E6%AC%A1%E7%9A%84%E5%8D%8F%E8%AE%AE.png" alt></p><p>IP是网络层上的主要协议，同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。</p><p>ICMP是IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。</p><p>IGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。</p><p>ARP（地址解析协议）和RARP（逆地址解析协议）是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。</p><h2 id="互联网地址"><a href="#互联网地址" class="headerlink" title="互联网地址"></a>互联网地址</h2><p>互联网上的每个接口必须有一个唯一的Internet地址（也称作IP地址）。IP地址长32bit。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E4%BA%94%E7%B1%BB%E4%BA%92%E8%81%94%E7%BD%91%E5%9C%B0%E5%9D%80.png" alt></p><p>这些32位的地址通常写成四个十进制的数，其中每个整数对应一个字节。这种表示方法称作“点分十进制表示法（Dotted decimal notation）”。</p><p>区分各类地址的最简单方法是看它的第一个十进制整数。图1-6列出了各类地址的起止范围，其中第一个十进制整数用加黑字体表示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E5%90%84%E7%B1%BBIP%E5%9C%B0%E5%9D%80%E7%9A%84%E8%8C%83%E5%9B%B4.png" alt></p><p>需要再次指出的是，多接口主机具有多个IP地址，其中每个接口都对应一个IP地址。由于互联网上的每个接口必须有一个唯一的IP地址，因此必须要有一个管理机构为接入互联网的网络分配IP地址。这个管理机构就是互联网络信息中心（Internet Network Information Centre），称作InterNIC。InterNIC只分配网络号。主机号的分配由系统管理员来负责。</p><p>有三类IP地址：单播地址（目的为单个主机）、广播地址（目的端为给定网络上的所有主机）以及多播地址（目的端为同一组内的所有主机）。</p><h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><p>当应用程序用TCP传送数据时，数据被送入协议栈中，然后逐个通过每一层直到被当作一串比特流送入网络。其中每一层对收到的数据都要增加一些首部信息（有时还要增加尾部信息），该过程如图1-7所示。TCP传给IP的数据单元称作TCP报文段或简称为TCP段（TCP segment）。IP传给网络接口层的数据单元称作IP数据报(IP datagram)。通过以太网传输的比特流称作帧(Frame)。</p><p>图1-7中帧头和帧尾下面所标注的数字是典型以太网帧首部的字节长度。</p><p>以太网数据帧的物理特性是其长度必须在46～1500字节之间。</p><blockquote><p>更准确地说，图1-7中IP和网络接口层之间传送的数据单元应该是分组（packet）。分组既可以是一个IP数据报，也可以是IP数据报的一个片（fragment）。</p></blockquote><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%85%A5%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%97%B6%E7%9A%84%E5%B0%81%E8%A3%85%E8%BF%87%E7%A8%8B.png" alt></p><p>UDP数据与TCP数据基本一致。唯一的不同是UDP传给IP的信息单元称作UDP数据报（UDP datagram），而且UDP的首部长为8字节。</p><p><font color="DeepPink"><strong>由于TCP、UDP、ICMP和IGMP都要向IP传送数据，因此IP必须在生成的IP首部中加入某种标识，以表明数据属于哪一层。为此，IP在首部中存入一个长度为8 bit的数值，称作协议域。1表示为ICMP协议，2表示为IGMP协议，6表示为TCP协议，17表示为UDP协议。</strong></font></p><p>类似地，许多应用程序都可以使用TCP或UDP来传送数据。运输层协议在生成报文首部时要存入一个应用程序的标识符。TCP和UDP都用一个16 bit的端口号来表示不同的应用程序。TCP和UDP把源端口号和目的端口号分别存入报文首部中。</p><p>网络接口分别要发送和接收IP、ARP和RARP数据，因此也必须在以太网的帧首部中加入某种形式的标识，以指明生成数据的网络层协议。为此，以太网的帧首部也有一个16 bit的帧类型域。</p><h2 id="分用"><a href="#分用" class="headerlink" title="分用"></a>分用</h2><p><font color="DeepPink"><strong>当目的主机收到一个以太网数据帧时，数据就开始从协议栈中由底向上升，同时去掉各层协议加上的报文首部。</strong></font>每层协议盒都要去检查报文首部中的协议标识，以确定接收数据的上层协议。这个过程称作分用（Demultiplexing），图1-8显示了该过程是如何发生的。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E4%BB%A5%E5%A4%AA%E7%BD%91%E6%95%B0%E6%8D%AE%E5%B8%A7%E7%9A%84%E5%88%86%E7%94%A8%E8%BF%87%E7%A8%8B.png" alt></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>TCP/IP协议族分为四层：链路层、网络层、运输层和应用层，每一层各有不同的责任。在TCP/IP中，网络层和运输层之间的区别是最为关键的：<font color="DeepPink"><strong>网络层（IP）提供点到点的服务，而运输层（TCP和UDP）提供端到端的服务。</strong></font></p><h1 id="链路层"><a href="#链路层" class="headerlink" title="链路层"></a>链路层</h1><p>从图1-4中可以看出，在TCP/IP协议族中，链路层主要有三个目的：（1）为IP模块发送和接收IP数据报；（2）为ARP模块发送ARP请求和接收ARP应答；（3）为RARP发送RARP请求和接收RARP应答。</p><h2 id="环回接口"><a href="#环回接口" class="headerlink" title="环回接口"></a>环回接口</h2><p>大多数的产品都支持环回接口（Loopback Interface），以允许运行在同一台主机上的客户程序和服务器程序通过TCP/IP进行通信。A类网络号127就是为环回接口预留的。根据惯例，大多数系统把IP地址127.0.0.1分配给这个接口，并命名为localhost。一个传给环回接口的IP数据报不能在任何网络上出现。</p><h1 id="IP：网际协议"><a href="#IP：网际协议" class="headerlink" title="IP：网际协议"></a>IP：网际协议</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>IP是TCP/IP协议族中最为核心的协议。所有的TCP、UDP、ICMP及IGMP数据都以IP数据报格式传输（见图1-4）。</p><p>不可靠（unreliable）的意思是它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP）。</p><p>无连接（connectionless）这个术语的意思是IP并不维护任何关于后续数据报的状态信息。每个数据报的处理是相互独立的。这也说明，IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达。</p><h2 id="IP首部"><a href="#IP首部" class="headerlink" title="IP首部"></a>IP首部</h2><p>IP数据报的格式如图3-1所示。普通的IP首部长为20个字节，除非含有选项字段。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%A0%BC%E5%BC%8F%E5%8F%8A%E9%A6%96%E9%83%A8%E4%B8%AD%E7%9A%84%E5%90%84%E5%AD%97%E6%AE%B5.png" alt></p><p>分析图3-1中的首部。最高位在左边，记为0 bit；最低位在右边，记为31 bit。</p><p>4个字节的32 bit值以下面的次序传输：首先是0～7 bit，其次8～15 bit，然后16～23 bit，最后是24~31 bit。这种传输次序称作bigendian字节序。由于TCP/IP首部中所有的二进制整数在网络中传输时都要求以这种次序，因此它又称作网络字节序。以其他形式存储二进制整数的机器，如little endian格式，则必须在传输数据之前把首部转换成网络字节序。</p><p>目前的协议版本号是4，因此IP有时也称作IPv4。</p><p>首部长度指的是首部占32 bit字的数目，包括任何选项。由于它是一个4比特字段，因此首部最长为60个字节。普通IP数据报（没有任何选择项）字段的值是5。</p><p>总长度字段是指整个IP数据报的长度，以字节为单位。利用首部长度字段和总长度字段，就可以知道IP数据报中数据内容的起始位置和长度。</p><p>总长度字段是IP首部中必要的内容，因为一些数据链路（如以太网）需要填充一些数据以达到最小长度。尽管以太网的最小帧长为46字节，但是I P数据可能会更短。如果没有总长度字段，那么IP层就不知道46字节中有多少是IP数据报的内容。</p><p>标识字段唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加 1。</p><p>TTL（time-to-live）生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1。当该字段的值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。</p><p>首部检验和字段是根据IP首部计算的检验和码。它不对首部后面的数据进行计算。ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。</p><p>为了计算一份数据报的IP检验和，首先把检验和字段置为 0。然后，对首部中每个16 bit进行二进制反码求和（整个首部看成是由一串 16 bit的字组成），结果存在检验和字段中。当收到一份IP数据报后，同样对首部中每个 16 bit进行二进制反码的求和。由于接收方在计算过程中包含了发送方存在首部中的检验和，因此，如果首部在传输过程中没有发生任何差错，那么接收方计算的结果应该为全 1。如果结果不是全1（即检验和错误），那么IP就丢弃收到的数据报。但是不生成差错报文，由上层去发现丢失的数据报并进行重传。</p><p>选项字段一直都是以 32 bit作为界限，在必要的时候插入值为 0的填充字节。这样就保证IP首部始终是32 bit的整数倍（这是首部长度字段所要求的）。</p><h2 id="IP路由选择"><a href="#IP路由选择" class="headerlink" title="IP路由选择"></a>IP路由选择</h2><p>从概念上说，IP路由选择是简单的，特别对于主机来说。如果目的主机与源主机直接相连（如点对点链路）或都在一个共享网络上（以太网或令牌环网），那么IP数据报就直接送到目的主机上。否则，主机把数据报发往一默认的路由器上，由路由器来转发该数据报。大多数的主机都是采用这种简单机制。</p><p>在一般的体制中，IP可以从TCP、UDP、ICMP和IGMP接收数据报（即在本地生成的数据报）并进行发送，或者从一个网络接口接收数据报（待转发的数据报）并进行发送。IP层在内存中有一个路由表。当收到一份数据报并进行发送时，它都要对该表搜索一次。当数据报来自某个网络接口时，IP首先检查目的IP地址是否为本机的IP地址之一或者IP广播地址。如果确实是这样，数据报就被送到由IP首部协议字段所指定的协议模块进行处理。如果数据报的目的不是这些地址，那么（1）如果IP层被设置为路由器的功能，那么就对数据报进行转发（也就是说，像下面对待发出的数据报一样处理）；否则（2）数据报被丢弃。</p><p>路由表中的每一项都包含下面这些信息：</p><ul><li>目的IP地址。它既可以是一个完整的主机地址，也可以是一个网络地址，由该表目中的标志字段来指定（如下所述）。主机地址有一个非0的主机号（见图1-5），以指定某一特定的主机，而网络地址中的主机号为0，以指定网络中的所有主机（如以太网，令牌环网）。</li><li>下一站（或下一跳）路由器（next-hoprouter）的IP地址，或者有直接连接的网络IP地址。下一站路由器是指一个在直接相连网络上的路由器，通过它可以转发数据报。下一站路由器不是最终的目的，但是它可以把传送给它的数据报转发到最终目的。</li><li>标志。其中一个标志指明目的IP地址是网络地址还是主机地址，另一个标志指明下一站路由器是否为真正的下一站路由器，还是一个直接相连的接口。</li><li>为数据报的传输指定一个网络接口。</li></ul><p>IP路由选择是逐跳地（hop-by-hop）进行的。从这个路由表信息可以看出，IP并不知道到达任何目的的完整路径（当然，除了那些与主机直接相连的目的）。所有的IP路由选择只为数据报传输提供下一站路由器的IP地址。它假定下一站路由器比发送数据报的主机更接近目的，而且下一站路由器与该主机是直接相连的。</p><p>IP路由选择主要完成以下这些功能：</p><ol><li>搜索路由表，寻找能与目的IP地址完全匹配的表目（网络号和主机号都要匹配）。如果找到，则把报文发送给该表目指定的下一站路由器或直接连接的网络接口（取决于标志字段的值）。</li><li>搜索路由表，寻找能与目的网络号相匹配的表目。如果找到，则把报文发送给该表目指定的下一站路由器或直接连接的网络接口（取决于标志字段的值）。目的网络上的所有主机都可以通过这个表目来处置。例如，一个以太网上的所有主机都是通过这种表目进行寻径的。这种搜索网络的匹配方法必须考虑可能的子网掩码。</li><li>搜索路由表，寻找标为“默认（default）”的表目。如果找到，则把报文发送给该表目指定的下一站路由器。</li></ol><p>如果上面这些步骤都没有成功，那么该数据报就不能被传送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或“网络不可达”的错误。完整主机地址匹配在网络号匹配之前执行。只有当它们都失败后才选择默认路由。默认路由，以及下一站路由器发送的ICMP间接报文（如果我们为数据报选择了错误的默认路由），是IP路由选择机制中功能强大的特性。</p><p>为一个网络指定一个路由器，而不必为每个主机指定一个路由器，这是IP路由选择机制的另一个基本特性。这样做可以极大地缩小路由表的规模，比如Internet上的路由器有只有几千个表目，而不会是超过100万个表目。</p><h2 id="子网寻址"><a href="#子网寻址" class="headerlink" title="子网寻址"></a>子网寻址</h2><p>现在所有的主机都要求支持子网编址（RFC 950 [Mogul and Postel 1985]）。不是把IP地址看成由单纯的一个网络号和一个主机号组成，而是把主机号再分成一个子网号和一个主机号。</p><p>这样做的原因是因为A类和B类地址为主机号分配了太多的空间，可分别容纳的主机数为2^24 -2和2^16 -2。事实上，在一个网络中人们并不安排这么多的主机（各类IP地址的格式如图1-5所示）。由于全0或全1的主机号都是无效的，因此我们把总数减去 2。</p><h2 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h2><p>任何主机在引导时进行的部分配置是指定主机IP地址。大多数系统把IP地址存在一个磁盘文件里供引导时读用。</p><p>除了IP地址以外，主机还需要知道有多少比特用于子网号及多少比特用于主机号。这是在引导过程中通过子网掩码来确定的。这个掩码是一个32 bit的值，其中值为1的比特留给网络号和子网号，为0的比特留给主机号。图3-7是一个B类地址的两种不同的子网掩码格式。第一个例子是noao.edu网络采用的子网划分方法，子网号和主机号都是8 bit宽。第二个例子是一个B类地址划分成10 bit的子网号和6 bit的主机号。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84B%E7%B1%BB%E5%9C%B0%E5%9D%80%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt></p><p>给定IP地址和子网掩码以后，主机就可以确定IP数据报的目的是：(1)本子网上的主机；(2)本网络中其他子网中的主机；(3)其他网络上的主机。如果知道本机的IP地址，那么就知道它是否为A类、B类或C类地址(从IP地址的高位可以得知)，也就知道网络号和子网号之间的分界线。而根据子网掩码就可知道子网号与主机号之间的分界线。</p><p>将来或许会有更多的主机和网络，但是为了不让主机跨越不同的网络就得使用不同的子网号。我们的解决方法是把子网号从8 bit扩充到11 bit，把主机号从8 bit减为5 bit。这就叫作变长子网，因为140.252网络中的大多数子网都采用8 bit子网掩码，而我们的子网却采用11 bit的子网掩码。</p><p>作者子网中的IP地址结构如图3-11所示，11位子网号中的前8bit始终是13。在剩下的3 bit中，我们用二进制001表示以太网，010表示点对点SLIP链路。这个变长子网掩码在140.252网络中不会给其他主机和路由器带来问题—只要目的是子网140.252.13的所有数据报都传给路由器sun（IP地址是140.252.1.29），如图3-11所示。如果sun知道子网13中的主机有11bit子网号，那么一切都好办了。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91.png" alt></p><p>140.252.13子网中的所有接口的子网掩码是255.255.255.224，或0xffffffe0。这表明最右边的5bit留给主机号，左边的27bit留给网络号和子网号。</p><h2 id="ifconfig命令"><a href="#ifconfig命令" class="headerlink" title="ifconfig命令"></a>ifconfig命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ifconfig -a</span><br><span class="line">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class="line">        ether 02:42:a5:fc:a8:b0  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 1803610  bytes 751152220 (716.3 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1715508  bytes 1981302829 (1.8 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.21.0.3  netmask 255.255.240.0  broadcast 172.21.15.255</span><br><span class="line">        ether 52:54:00:9f:9a:52  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 25626090  bytes 6434619435 (5.9 GiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 27765770  bytes 6026731597 (5.6 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 2  bytes 272 (272.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 2  bytes 272 (272.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">veth7423cb0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        ether 0a:19:63:74:aa:32  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 1939  bytes 158399 (154.6 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1810  bytes 2114402 (2.0 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>环回接口被认为是一个网络接口。它是一个 A类地址，没有进行子网划分。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>在进行路由选择决策时，主机和路由器都使用路由表。在表中有三种类型的路由：特定主机型、特定网络型和默认路由型。路由表中的表目具有一定的优先级。在选择路由时，主机路由优先于网络路由，最后在没有其他可选路由存在时才选择默认路由。</p><p>IP路由选择是通过逐跳来实现的。数据报在各站的传输过程中目的 IP地址始终不变，但是封装和目的链路层地址在每一站都可以改变。大多数的主机和许多路由器对于非本地网络的数据报都使用默认的下一站路由器。</p><h1 id="ARP：地址解析协议"><a href="#ARP：地址解析协议" class="headerlink" title="ARP：地址解析协议"></a>ARP：地址解析协议</h1><h2 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h2><p>当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据 48 bit的以太网地址来确定目的接口的。设备驱动程序从不检查 IP数据报中的目的IP地址。</p><p>地址解析为这两种不同的地址形式提供映射： 32 bit的IP地址和数据链路层使用的任何类型的地址。</p><p>ARP为IP地址到对应的硬件地址之间提供动态映射。我们之所以用动态这个词是因为这个过程是自动完成的，一般应用程序用户或系统管理员不必关心。</p><p>RARP是被那些没有磁盘驱动器的系统使用（一般是无盘工作站或X终端），它需要系统管理员进行手工设置。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AEARP%E5%92%8CRARP.png" alt></p><h2 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h2><p>任何时候我们敲入下面这个形式的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%ftp bsdi</span><br></pre></td></tr></table></figure><p>都会进行以下这些步骤。这些步骤的序号如图4-2所示。</p><ol><li>应用程序FTP客户端调用函数gethostbyname(3)把主机名（bsdi）转换成32bit的IP地址。这个函数在DNS（域名系统）中称作解析器，我们将在第14章对它进行介绍。这个转换过程或者使用DNS，或者在较小网络中使用一个静态的主机文件（/etc/hosts）。</li><li>FTP客户端请求TCP用得到的IP地址建立连接。</li><li>TCP发送一个连接请求分段到远端的主机，即用上述IP地址发送一份IP数据报。</li><li>如果目的主机在本地网络上（如以太网、令牌环网或点对点链接的另一端），那么IP数据报可以直接送到目的主机上。如果目的主机在一个远程网络上，那么就通过IP选路函数来确定位于本地网络上的下一站路由器地址，并让它转发IP数据报。在这两种情况下，IP数据报都是被送到位于本地网络上的一台主机或路由器。</li><li>假定是一个以太网，那么发送端主机必须把32bit的IP地址变换成48bit的以太网地址。从逻辑Internet地址到对应的物理硬件地址需要进行翻译。这就是ARP的功能。ARP本来是用于广播网络的，有许多主机或路由器连在同一个网络上。</li><li>ARP发送一份称作ARP请求的以太网数据帧给以太网上的每个主机。这个过程称作广播，如图4-2中的虚线所示。ARP请求数据帧中包含目的主机的IP地址（主机名为bsdi），其意思是“如果你是这个IP地址的拥有者，请回答你的硬件地址。”</li></ol><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E5%BD%93%E7%94%A8%E6%88%B7%E8%BE%93%E5%85%A5%E5%91%BD%E4%BB%A4ftp%E4%B8%BB%E6%9C%BA%E5%90%8D%E6%97%B6ARP%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt></p><ol start="7"><li>目的主机的ARP层收到这份广播报文后，识别出这是发送端在寻问它的IP地址，于是发送一个ARP应答。这个ARP应答包含IP地址及对应的硬件地址。</li><li>收到ARP应答后，使ARP进行请求—应答交换的IP数据报现在就可以传送了。</li><li>发送IP数据报到目的主机。</li></ol><p><font color="DeepPink"><strong>在ARP背后有一个基本概念，那就是网络接口有一个硬件地址（一个48bit的值，标识不同的以太网或令牌环网络接口）。在硬件层次上进行的数据帧交换必须有正确的接口地址。但是，TCP/IP有自己的地址：32bit的IP地址。知道主机的IP地址并不能让内核发送一帧数据给主机。内核（如以太网驱动程序）必须知道目的端的硬件地址才能发送数据。ARP的功能是在32bit的IP地址和采用不同网络技术的硬件地址之间提供动态映射。</strong></font></p><h2 id="ARP高速缓存"><a href="#ARP高速缓存" class="headerlink" title="ARP高速缓存"></a>ARP高速缓存</h2><p>ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存。这个高速缓存存放了最近Internet地址到硬件地址之间的映射记录。高速缓存中每一项的生存时间一般为20分钟，起始时间从被创建时开始算起。</p><p>我们可以用arp命令来检查ARP高速缓存。参数-a的意思是显示高速缓存中所有的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# arp -a</span><br><span class="line">? (169.254.0.15) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.0.3) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (172.17.0.4) at 02:42:ac:11:00:04 [ether] on docker0</span><br><span class="line">? (169.254.0.2) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.0.4) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (172.17.0.3) at 02:42:ac:11:00:03 [ether] on docker0</span><br><span class="line">? (172.17.0.2) at 02:42:ac:11:00:02 [ether] on docker0</span><br><span class="line">? (169.254.0.23) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.128.3) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.128.5) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">gateway (172.21.0.1) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>48 bit的以太网地址用6个十六进制的数来表示，中间以冒号隔开。</p><h2 id="ARP的分组格式"><a href="#ARP的分组格式" class="headerlink" title="ARP的分组格式"></a>ARP的分组格式</h2><p>在以太网上解析IP地址时，ARP请求和应答分组的格式如图4-3所示（ARP可以用于其他类型的网络，可以解析IP地址以外的地址。紧跟着帧类型字段的前四个字段指定了最后四个字段的类型和长度）。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E7%94%A8%E4%BA%8E%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84ARP%E8%AF%B7%E6%B1%82%E6%88%96%E5%BA%94%E7%AD%94%E5%88%86%E7%BB%84%E6%A0%BC%E5%BC%8F.png" alt></p><p>以太网报头中的前两个字段是以太网的源地址和目的地址。目的地址为全 1的特殊地址是广播地址。电缆上的所有以太网接口都要接收广播的数据帧。</p><p>两个字节长的以太网帧类型表示后面数据的类型。对于ARP请求或应答来说，该字段的值为0x0806。</p><p>形容词hardware(硬件)和protocol(协议)用来描述ARP分组中的各个字段。例如，一个ARP请求分组询问协议地址（这里是IP地址）对应的硬件地址（这里是以太网地址）。</p><p>硬件类型字段表示硬件地址的类型。它的值为1即表示以太网地址。协议类型字段表示要映射的协议地址类型。它的值为0x0800即表示IP地址。它的值与包含IP数据报的以太网数据帧中的类型字段的值相同，这是有意设计的。</p><p>接下来的两个1字节的字段，硬件地址长度和协议地址长度分别指出硬件地址和协议地址的长度，以字节为单位。对于以太网上IP地址的ARP请求或应答来说，它们的值分别为6和4。</p><p>操作字段指出四种操作类型，它们是ARP请求（值为1）、ARP应答（值为2）、RARP请求（值为3）和RARP应答（值为4）（我们在第5章讨论RARP）。这个字段必需的，因为ARP请求和ARP应答的帧类型字段值是相同的。</p><p>接下来的四个字段是发送端的硬件地址（在本例中是以太网地址）、发送端的协议地址（IP地址）、目的端的硬件地址和目的端的协议地址。注意，这里有一些重复信息：在以太网的数据帧报头中和ARP请求数据帧中都有发送端的硬件地址。</p><p>对于一个ARP请求来说，除目的端硬件地址外的所有其他的字段都有填充值。当系统收到一份目的端为本机的ARP请求报文后，它就把硬件地址填进去，然后用两个目的端地址分别替换两个发送端地址，并把操作字段置为2，最后把它发送回去。</p><h2 id="ARP代理"><a href="#ARP代理" class="headerlink" title="ARP代理"></a>ARP代理</h2><p>如果ARP请求是从一个网络的主机发往另一个网络上的主机，那么连接这两个网络的路由器就可以回答该请求，这个过程称作委托ARP或ARP代理(Proxy ARP)。这样可以欺骗发起ARP请求的发送端，使它误以为路由器就是目的主机，而事实上目的主机是在路由器的“另一边”。路由器的功能相当于目的主机的代理，把分组从其他主机转发给它。</p><p>ARP代理也称作混合ARP（promiscuousARP）或ARP出租(ARPhack)。这些名字来自于ARP代理的其他用途：通过两个物理网络之间的路由器可以互相隐藏物理网络。在这种情况下，两个物理网络可以使用相同的网络号，只要把中间的路由器设置成一个ARP代理，以响应一个网络到另一个网络主机的ARP请求。这种技术在过去用来隐藏一组在不同物理电缆上运行旧版TCP/IP的主机。分开这些旧主机有两个共同的理由，其一是它们不能处理子网划分，其二是它们使用旧的广播地址（所有比特值为0的主机号，而不是目前使用的所有比特值为1的主机号）。</p><h2 id="免费ARP"><a href="#免费ARP" class="headerlink" title="免费ARP"></a>免费ARP</h2><p>我们可以看到的另一个ARP特性称作免费ARP(gratuitous ARP)。它是指主机发送ARP查找自己的IP地址。通常，它发生在系统引导期间进行接口配置的时候。</p><p>免费ARP可以有两个方面的作用：</p><ol><li>一个主机可以通过它来确定另一个主机是否设置了相同的IP地址。主机bsdi并不希望对此请求有一个回答。但是，如果收到一个回答，那么就会在终端日志上产生一个错误消息“以太网地址：a:b:c:d:e:f发送来重复的IP地址”。这样就可以警告系统管理员，某个系统有不正确的设置。</li><li>如果发送免费ARP的主机正好改变了硬件地址（很可能是主机关机了，并换了一块接口卡，然后重新启动），那么这个分组就可以使其他主机高速缓存中旧的硬件地址进行相应的更新。一个比较著名的ARP协议事实[Plummer1982]是，如果主机收到某个IP地址的ARP请求，而且它已经在接收者的高速缓存中，那么就要用ARP请求中的发送端硬件地址（如以太网地址）对高速缓存中相应的内容进行更新。主机接收到任何ARP请求都要完成这个操作（ARP请求是在网上广播的，因此每次发送ARP请求时网络上的所有主机都要这样做）。</li></ol><h2 id="arp命令"><a href="#arp命令" class="headerlink" title="arp命令"></a>arp命令</h2><ul><li>参数-a来显示ARP高速缓存中的所有内容</li><li>超级用户可以用选项-d来删除ARP高速缓存中的某一项内容</li><li>可以通过选项-s来增加高速缓存中的内容。这个参数需要主机名和以太网地址：对应于主机名的IP地址和以太网地址被增加到高速缓存中。新增加的内容是永久性的（比如，它没有超时值），除非在命令行的末尾附上关键字temp。</li><li>位于命令行末尾的关键字pub和-s选项一起，可以使系统起着主机ARP代理的作用。系统将回答与主机名对应的IP地址的ARP请求，并以指定的以太网地址作为应答。如果广播的地址是系统本身，那么系统就为指定的主机名起着委托ARP代理的作用。</li></ul><h1 id="RARP：逆地址解析协议"><a href="#RARP：逆地址解析协议" class="headerlink" title="RARP：逆地址解析协议"></a>RARP：逆地址解析协议</h1><h2 id="引言-2"><a href="#引言-2" class="headerlink" title="引言"></a>引言</h2><p>具有本地磁盘的系统引导时，一般是从磁盘上的配置文件中读取IP地址。但是无盘机，如X终端或无盘工作站，则需要采用其他方法来获得IP地址。</p><p>网络上的每个系统都具有唯一的硬件地址，它是由网络接口生产厂家配置的。无盘系统的RARP实现过程是从接口卡上读取唯一的硬件地址，然后发送一份RARP请求（一帧在网络上广播的数据），请求某个主机响应该无盘系统的IP地址（在RARP应答中）。</p><h2 id="RARP的分组格式"><a href="#RARP的分组格式" class="headerlink" title="RARP的分组格式"></a>RARP的分组格式</h2><p>RARP分组的格式与ARP分组基本一致（见图4-3）。它们之间主要的差别是RARP请求或应答的帧类型代码为0x8035，而且RARP请求的操作代码为3，应答操作代码为4。</p><p>对应于ARP，RARP请求以广播方式传送，而RARP应答一般是单播(unicast)传送的。</p><h2 id="RARP服务器的设计"><a href="#RARP服务器的设计" class="headerlink" title="RARP服务器的设计"></a>RARP服务器的设计</h2><p>虽然RARP在概念上很简单，但是一个RARP服务器的设计与系统相关而且比较复杂。相反，提供一个ARP服务器很简单，通常是TCP/IP在内核中实现的一部分。由于内核知道IP地址和硬件地址，因此当它收到一个询问IP地址的ARP请求时，只需用相应的硬件地址来提供应答就可以了。</p><h3 id="作为用户进程的RARP服务器"><a href="#作为用户进程的RARP服务器" class="headerlink" title="作为用户进程的RARP服务器"></a>作为用户进程的RARP服务器</h3><p>RARP服务器的复杂性在于，服务器一般要为多个主机（网络上所有的无盘系统）提供硬件地址到IP地址的映射。该映射包含在一个磁盘文件中（在Unix系统中一般位于/etc/ethers目录中）。由于内核一般不读取和分析磁盘文件，因此RARP服务器的功能就由用户进程来提供，而不是作为内核的TCP/IP实现的一部分。</p><p>更为复杂的是，RARP请求是作为一个特殊类型的以太网数据帧来传送的（帧类型字段值为0x8035）。这说明RARP服务器必须能够发送和接收这种类型的以太网数据帧。在附录A中，我们描述了BSD分组过滤器、Sun的网络接口栓以及SVR4数据链路提供者接口都可用来接收这些数据帧。由于发送和接收这些数据帧与系统有关，因此RARP服务器的实现是与系统捆绑在一起的。</p><h3 id="每个网络有多个RARP服务器"><a href="#每个网络有多个RARP服务器" class="headerlink" title="每个网络有多个RARP服务器"></a>每个网络有多个RARP服务器</h3><p>RARP服务器实现的一个复杂因素是RARP请求是在硬件层上进行广播的。这意味着它们不经过路由器进行转发。为了让无盘系统在RARP服务器关机的状态下也能引导，<br>通常在一个网络上（例如一根电缆）要提供多个RARP服务器。</p><p>当服务器的数目增加时（以提供冗余备份），网络流量也随之增加，因为每个服务器对每个RARP请求都要发送RARP应答。发送RARP请求的无盘系统一般采用最先收到的RARP应答（对于ARP，我们从来没有遇到这种情况，因为只有一台主机发送ARP应答）。另外，还有一种可能发生的情况是每个RARP服务器同时应答，这样会增加以太网发生冲突的概率。</p><h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><p>RARP协议是许多无盘系统在引导时用来获取IP地址的。RARP分组格式基本上与ARP分组一致。一个RARP请求在网络上进行广播，它在分组中标明发送端的硬件地址，以请求相应IP地址的响应。应答通常是单播传送的。</p><p>RARP带来的问题包括使用链路层广播，这样就阻止大多数路由器转发RARP请求，只返回很少信息：只是系统的IP地址。</p><p>虽然RARP在概念上很简单，但是RARP服务器的实现却与系统相关。因此，并不是所有的TCP/IP实现都提供RARP服务器。</p><h1 id="ICMP：Internet控制报文协议"><a href="#ICMP：Internet控制报文协议" class="headerlink" title="ICMP：Internet控制报文协议"></a>ICMP：Internet控制报文协议</h1><h2 id="引言-3"><a href="#引言-3" class="headerlink" title="引言"></a>引言</h2><blockquote><p>ICMP（Internet Control Message Protocol）</p></blockquote><p>ICMP经常被认为是IP层的一个组成部分。它传递差错报文以及其他需要注意的信息。ICMP报文通常被IP层或更高层协议（TCP或UDP）使用。一些ICMP报文把差错报文返回给用户进程。</p><p>ICMP报文是在IP数据报内部被传输的，如图6-1所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E5%B0%81%E8%A3%85%E5%9C%A8IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%86%85%E9%83%A8.png" alt></p><p>ICMP报文的格式如图6-2所示。所有报文的前4个字节都是一样的，但是剩下的其他字节则互不相同。下面我们将逐个介绍各种报文格式。</p><p>类型字段可以有15个不同的值，以描述特定类型的ICMP报文。某些ICMP报文还使用代码字段的值来进一步描述不同的条件。</p><p>检验和字段覆盖整个ICMP报文。ICMP的检验和是必需的。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E6%8A%A5%E6%96%87.png" alt></p><h2 id="ICMP报文的类型"><a href="#ICMP报文的类型" class="headerlink" title="ICMP报文的类型"></a>ICMP报文的类型</h2><p>各种类型的ICMP报文如图6-3所示，不同类型由报文中的类型字段和代码字段来共同决定。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B.png" alt></p><p>图中的最后两列表明ICMP报文是一份查询报文还是一份差错报文。因为对ICMP差错报文有时需要作特殊处理，因此我们需要对它们进行区分。例如，在对ICMP差错报文进行响应时，永远不会生成另一份ICMP差错报文（如果没有这个限制规则，可能会遇到一个差错产生另一个差错的情况，而差错再产生差错，这样会无休止地循环下去）。</p><p>当发送一份ICMP差错报文时，报文始终包含IP的首部和产生ICMP差错报文的IP数据报的前8个字节。这样，接收ICMP差错报文的模块就会把它与某个特定的协议（根据IP数据报首部中的协议字段来判断）和用户进程（根据包含在IP数据报前8个字节中的TCP或UDP报文首部中的TCP或UDP端口号来判断）联系起来。</p><p>下面各种情况都不会导致产生ICMP差错报文：</p><ol><li>ICMP差错报文（但是，ICMP查询报文可能会产生ICMP差错报文）。</li><li>目的地址是广播地址或多播地址（D类地址）的IP数据报。</li><li>作为链路层广播的数据报。</li><li>不是IP分片的第一片。</li><li>源地址不是单个主机的数据报。这就是说，源地址不能为零地址、环回地址、广播地址或多播地址。</li></ol><p>这些规则是为了防止过去允许ICMP差错报文对广播分组响应所带来的广播风暴。</p><h2 id="ICMP地址掩码请求与应答"><a href="#ICMP地址掩码请求与应答" class="headerlink" title="ICMP地址掩码请求与应答"></a>ICMP地址掩码请求与应答</h2><p>ICMP地址掩码请求用于无盘系统在引导过程中获取自己的子网掩码。系统广播它的ICMP请求报文（这一过程与无盘系统在引导过程中用RARP获取IP地址是类似的）。无盘系统获取子网掩码的另一个方法是BOOTP协议。</p><p>ICMP地址掩码请求和应答报文的格式如图6-4所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E5%9C%B0%E5%9D%80%E6%8E%A9%E7%A0%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%BA%94%E7%AD%94%E6%8A%A5%E6%96%87.png" alt></p><p>ICMP报文中的标识符和序列号字段由发送端任意选择设定，这些值在应答中将被返回。这样，发送端就可以把应答与请求进行匹配。</p><h1 id="Ping程序"><a href="#Ping程序" class="headerlink" title="Ping程序"></a>Ping程序</h1><p><strong>ping</strong><br>测试主机之间网络的连通性</p><p><strong>补充说明</strong><br>ping命令 用来测试主机之间网络的连通性。执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping(选项)(参数)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-d：使用Socket的SO_DEBUG功能；</span><br><span class="line">-c&lt;完成次数&gt;：设置完成要求回应的次数；</span><br><span class="line">-f：极限检测；</span><br><span class="line">-i&lt;间隔秒数&gt;：指定收发信息的间隔时间；</span><br><span class="line">-I&lt;网络界面&gt;：使用指定的网络界面送出数据包；</span><br><span class="line">-l&lt;前置载入&gt;：设置在送出要求信息之前，先行发出的数据包；</span><br><span class="line">-n：只输出数值；</span><br><span class="line">-p&lt;范本样式&gt;：设置填满数据包的范本样式；</span><br><span class="line">-q：不显示指令执行过程，开头和结尾的相关信息除外；</span><br><span class="line">-r：忽略普通的Routing Table，直接将数据包送到远端主机上；</span><br><span class="line">-R：记录路由过程；</span><br><span class="line">-s&lt;数据包大小&gt;：设置数据包的大小；</span><br><span class="line">-t&lt;存活数值&gt;：设置存活数值TTL的大小；</span><br><span class="line">-v：详细显示指令的执行过程。</span><br></pre></td></tr></table></figure><p><strong>参数</strong><br>目的主机：指定发送ICMP报文的目的主机。</p><h2 id="引言-4"><a href="#引言-4" class="headerlink" title="引言"></a>引言</h2><p>“ping”这个名字源于声纳定位操作。Ping程序由MikeMuuss编写，目的是为了测试另一台主机是否可达。该程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答（图6-3列出了所有的ICMP报文类型）。</p><p>一般来说，如果不能Ping到某台主机，那么就不能Telnet或者FTP到那台主机。反过来，如果不能Telnet到某台主机，那么通常可以用Ping程序来确定问题出在哪里。Ping程序还能测出到这台主机的往返时间，以表明该主机离我们有“多远”。</p><h2 id="Ping程序-1"><a href="#Ping程序-1" class="headerlink" title="Ping程序"></a>Ping程序</h2><p>我们称发送回显请求的ping程序为客户，而称被ping的主机为服务器。大多数的TCP/IP实现都在内核中直接支持Ping服务器—这种服务器不是一个用户进程。</p><p>ICMP回显请求和回显应答报文如图7-1所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E5%9B%9E%E6%98%BE%E8%AF%B7%E6%B1%82%E5%92%8C%E5%9B%9E%E6%98%BE%E5%BA%94%E7%AD%94%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt></p><p>对于其他类型的ICMP查询报文，服务器必须响应标识符和序列号字段。另外，客户发送的选项数据必须回显，假设客户对这些信息都会感兴趣。</p><p>Unix系统在实现ping程序时是把ICMP报文中的标识符字段置成发送进程的ID号。这样即使在同一台主机上同时运行了多个ping程序实例，ping程序也可以识别出返回的信息。</p><p>序列号从0开始，每发送一次新的回显请求就加1。ping程序打印出返回的每个分组的序列号，允许我们查看是否有分组丢失、失序或重复。IP是一种最好的数据报传递服务，因此这三个条件都有可能发生。</p><p>旧版本的ping程序曾经以这种模式运行，即每秒发送一个回显请求，并打印出返回的每个回显应答。但是，新版本的实现需要加上-s选项才能以这种模式运行。默认情况下，新版本的ping程序只发送一个回显请求。如果收到回显应答，则输出“host is alive”；否则，在20秒内没有收到应答就输出“no answer（没有回答）”。</p><h3 id="LAN-WAN-输出"><a href="#LAN-WAN-输出" class="headerlink" title="LAN/WAN 输出"></a>LAN/WAN 输出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ping www.jiankunking.com</span><br><span class="line">PING www.jiankunking.com (139.199.31.69) 56(84) bytes of data.</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=1 ttl=63 time=0.336 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=2 ttl=63 time=0.288 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=3 ttl=63 time=0.295 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=4 ttl=63 time=0.295 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=5 ttl=63 time=0.323 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=6 ttl=63 time=0.324 ms</span><br><span class="line">^C 键入中断来停止显示</span><br><span class="line">--- www.jiankunking.com ping statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 6510ms</span><br><span class="line">rtt min/avg/max/mdev = 0.288/0.310/0.336/0.020 ms</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><blockquote><p>默认情况下发送的ICMP报文有56个字节。再加上20个字节的IP首部和8个字节的ICMP首部，IP数据报的总长度为84字节。</p></blockquote><p>当返回ICMP回显应答时，要打印出序列号和TTL，并计算往返时间（TTL位于IP首部中的生存时间字段。当前的BSD系统中的ping程序每次收到回显应答时都打印出收到的TTL—有些系统并不这样做。）。</p><p>从上面的输出中可以看出，回显应答是以发送的次序返回的（0，1，2等）。</p><p>ping程序通过在ICMP报文数据中存放发送请求的时间值来计算往返时间。当应答返回时，用当前时间减去存放在ICMP报文中的时间值，即是往返时间。</p><p>通过广域网还有可能看到重复的分组（即相同序列号的分组被打印两次或更多次），失序的分组（序列号为N + 1的分组在序列号为N的分组之前被打印）。</p><h2 id="IP记录路由选项"><a href="#IP记录路由选项" class="headerlink" title="IP记录路由选项"></a>IP记录路由选项</h2><p>ping程序为我们提供了查看IP记录路由（RR）选项的机会。大多数不同版本的ping程序都提供-R选项，以提供记录路由的功能。它使得ping程序在发送出去的IP数据报中设置IP RR选项（该IP数据报包含ICMP回显请求报文）。这样，每个处理该数据报的路由器都把它的IP地址放入选项字段中。当数据报到达目的端时，IP地址清单应该复制到ICMP回显应答中，这样返回途中所经过的路由器地址也被加入清单中。当ping程序收到回显应答时，它就打印出这份IP地址清单。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ping -R www.jiankunking.com</span><br><span class="line">PING www.jiankunking.com (139.199.31.69) 56(124) bytes of data.</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=1 ttl=63 time=13.3 ms</span><br><span class="line">RR: VM_0_3_centos (172.21.0.3)</span><br><span class="line">10.53.209.129 (10.53.209.129)</span><br><span class="line">VM_0_3_centos (172.21.0.3)</span><br><span class="line">VM_0_3_centos (172.21.0.3)</span><br><span class="line">10.53.209.130 (10.53.209.130)</span><br><span class="line">VM_0_3_centos (172.21.0.3)</span><br><span class="line"></span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=2 ttl=63 time=4.91 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=3 ttl=63 time=6.81 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=4 ttl=63 time=5.03 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=5 ttl=63 time=4.59 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=6 ttl=63 time=4.77 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=7 ttl=63 time=5.18 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=8 ttl=63 time=3.69 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=9 ttl=63 time=4.24 ms(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=10 ttl=63 time=5.43 ms(same route)</span><br><span class="line">^C</span><br><span class="line">--- www.jiankunking.com ping statistics ---</span><br><span class="line">11 packets transmitted, 11 received, 0% packet loss, time 10015ms</span><br><span class="line">rtt min/avg/max/mdev = 3.697/5.696/13.385/2.545 ms</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>但是，最大的问题是IP首部中只有有限的空间来存放IP地址。我们从图3-1可以看到，IP首部中的首部长度字段只有4bit，因此整个IP首部最长只能包括15个32bit长的字（即60个字节）。由于IP首部固定长度为20字节，RR选项用去3个字节（下面我们再讨论），这样只剩下37个字节（60-20-3）来存放IP地址清单，也就是说只能存放9个IP地址。对于早期的ARPANET来说，9个IP地址似乎是很多了，但是现在看来是非常有限的。除了这些缺点，记录路由选项工作得很好，为详细查看如何处理IP选项提供了一个机会。</p><p>IP数据报中的RR选项的一般格式如图7-3所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/IP%E9%A6%96%E9%83%A8%E4%B8%AD%E7%9A%84%E8%AE%B0%E5%BD%95%E8%B7%AF%E7%94%B1%E9%80%89%E9%A1%B9%E7%9A%84%E4%B8%80%E8%88%AC%E6%A0%BC%E5%BC%8F.png" alt></p><p>code是一个字节，指明IP选项的类型。对于RR选项来说，它的值为7。len是RR选项总字节长度，在这种情况下为39（尽管可以为RR选项设置比最大长度小的长度，但是ping程序是提供39字节的选项字段，最多可以记录9个IP地址。由于IP首部中留给选项的空间有限，它一般情况都设置成最大长度）。</p><p>ptr称作指针字段。它是一个基于1的指针，指向存放下一个IP地址的位置。它的最小值为4，指向存放第一个IP地址的位置。随着每个IP地址存入清单，ptr的值分别为8，12，16，最大到36。当记录下9个IP地址后，ptr的值为40，表示清单已满。</p><p>当路由器（根据定义应该是多穴的）在清单中记录IP地址时，它应该记录哪个地址呢？是入口地址还是出口地址？为此，RFC791[Postel1981a]指定路由器记录出口IP地址。我们在后面将看到，当原始主机（运行ping程序的主机）收到带有RR选项的ICMP回显应答时，它也要把它的入口IP地址放入清单中。</p><h2 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h2><p>ping程序是对两个TCP/IP系统连通性进行测试的基本工具。它只利用ICMP回显请求和回显应答报文，而不用经过传输层（TCP/UDP）。Ping服务器一般在内核中实现ICMP的功能。</p><h1 id="Traceroute程序"><a href="#Traceroute程序" class="headerlink" title="Traceroute程序"></a>Traceroute程序</h1><p><strong>traceroute</strong><br>显示数据包到主机间的路径</p><p><strong>补充说明</strong><br>traceroute命令 用于追踪数据包在网络上的传输时的全部路径，它默认发送的数据包大小是40字节。</p><p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。</p><p>traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其ip地址。<br><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">traceroute(选项)(参数)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-d：使用Socket层级的排错功能；</span><br><span class="line">-f&lt;存活数值&gt;：设置第一个检测数据包的存活数值TTL的大小；</span><br><span class="line">-F：设置勿离断位；</span><br><span class="line">-g&lt;网关&gt;：设置来源路由网关，最多可设置8个；</span><br><span class="line">-i&lt;网络界面&gt;：使用指定的网络界面送出数据包；</span><br><span class="line">-I：使用ICMP回应取代UDP资料信息；</span><br><span class="line">-m&lt;存活数值&gt;：设置检测数据包的最大存活数值TTL的大小；</span><br><span class="line">-n：直接使用IP地址而非主机名称；</span><br><span class="line">-p&lt;通信端口&gt;：设置UDP传输协议的通信端口；</span><br><span class="line">-r：忽略普通的Routing Table，直接将数据包送到远端主机上。</span><br><span class="line">-s&lt;来源地址&gt;：设置本地主机送出数据包的IP地址；</span><br><span class="line">-t&lt;服务类型&gt;：设置检测数据包的TOS数值；</span><br><span class="line">-v：详细显示指令的执行过程；</span><br><span class="line">-w&lt;超时秒数&gt;：设置等待远端主机回报的时间；</span><br><span class="line">-x：开启或关闭数据包的正确性检验。</span><br></pre></td></tr></table></figure><p><strong>参数</strong><br>主机：指定目的主机IP地址或主机名。</p><h2 id="引言-5"><a href="#引言-5" class="headerlink" title="引言"></a>引言</h2><p>Traceroute程序可以让我们看到IP数据报从一台主机传到另一台主机所经过的路由。</p><h2 id="Traceroute程序的操作"><a href="#Traceroute程序的操作" class="headerlink" title="Traceroute程序的操作"></a>Traceroute程序的操作</h2><p>在上节中，我们描述了IP记录路由选项（RR）。为什么不使用这个选项而另外开发一个新的应用程序？有三个方面的原因。首先，原先并不是所有的路由器都支持记录路由选项，因此该选项在某些路径上不能使用（Traceroute程序不需要中间路由器具备任何特殊的或可选的功能）。</p><p>其次，记录路由一般是单向的选项。发送端设置了该选项，那么接收端不得不从收到的IP首部中提取出所有的信息，然后全部返回给发送端。在上节中，我们看到大多数Ping服务器的实现（内核中的ICMP回显应答功能）把接收到的RR清单返回，但是这样使得记录下来的IP地址翻了一番（一来一回）。这样做会受到一些限制，这一点我们在下一段讨论（Traceroute程序只需要目的端运行一个UDP模块—其他不需要任何特殊的服务器应用程序）。</p><p>最后一个原因也是最主要的原因是，IP首部中留给选项的空间有限，不能存放当前大多数的路径。在IP首部选项字段中最多只能存放9个IP地址。在原先的ARPANET中这是足够的，但是对现在来说是远远不够的。</p><p>Traceroute程序使用ICMP报文和IP首部中的TTL字段（生存周期）。TTL字段是由发送端初始设置一个8bit字段。推荐的初始值由分配数字RFC指定，当前值为64。较老版本的系统经常初始化为15或32。我们从第7章中的一些ping程序例子中可以看出，发送ICMP回显应答时经常把TTL设为最大值255。</p><p>每个处理数据报的路由器都需要把TTL的值减1或减去数据报在路由器中停留的秒数。由于大多数的路由器转发数据报的时延都小于1秒钟，因此TTL最终成为一个跳站的计数器，所经过的每个路由器都将其值减1。</p><blockquote><p>RFC 1009 [Braden and Postel 1987]指出，如果路由器转发数据报的时延超过1秒，那么它将把TTL值减去所消耗的时间（秒数）。但很少有路由器这么实现。新的路由器需求文档RFC [Almquist 1993]为此指定它为可选择功能，允许把TTL看成一个跳站计数器。</p></blockquote><p><font color="DeepPink"><strong>TTL字段的目的是防止数据报在选路时无休止地在网络中流动。</strong></font>例如，当路由器瘫痪或者两个路由器之间的连接丢失时，选路协议有时会去检测丢失的路由并一直进行下去。在这段时间内，数据报可能在循环回路被终止。TTL字段就是在这些循环传递的数据报上加上一个生存上限。</p><p>当路由器收到一份IP数据报，如果其TTL字段是0或1，则路由器不转发该数据报（接收到这种数据报的目的主机可以将它交给应用程序，这是因为不需要转发该数据报。但是在通常情况下，系统不应该接收TTL字段为0的数据报）。相反，路由器将该数据报丢弃，并给信源机发一份ICMP“超时”信息。Traceroute程序的关键在于包含这份ICMP信息的IP报文的信源地址是该路由器的IP地址。</p><p><font color="DeepPink"><strong>我们现在可以猜想一下Traceroute程序的操作过程。它发送一份TTL字段为1的IP数据报给目的主机。处理这份数据报的第一个路由器将TTL值减1，丢弃该数据报，并发回一份超时ICMP报文。这样就得到了该路径中的第一个路由器的地址。然后Traceroute程序发送一份TTL值为2的数据报，这样我们就可以得到第二个路由器的地址。继续这个过程直至该数据报到达目的主机。但是目的主机哪怕接收到TTL值为1的IP数据报，也不会丢弃该数据报并产生一份超时ICMP报文，这是因为数据报已经到达其最终目的地。那么我们该如何判断是否已经到达目的主机了呢？</strong></font></p><p><font color="DeepPink"><strong>Traceroute程序发送一份UDP数据报给目的主机，但它选择一个不可能的值作为UDP端口号（大于30000），使目的主机的任何一个应用程序都不可能使用该端口。因为，当该数据报到达时，将使目的主机的UDP模块产生一份“端口不可达”错误的ICMP报文。这样，Traceroute程序所要做的就是区分接收到的ICMP报文是超时还是端口不可达，以判断什么时候结束。</strong></font></p><blockquote><p>Traceroute程序必须可以为发送的数据报设置TTL字段。并非所有与TCP/IP接口的程序都支持这项功能，同时并非所有的实现都支持这项能力，但目前大部分系统都支持这项功能，并可以运行Traceroute程序。这个程序界面通常要求用户具有超级用户权限，这意味着它可能需要特殊的权限以在你的主机上运行该程序。</p></blockquote><h2 id="IP源站选路选项"><a href="#IP源站选路选项" class="headerlink" title="IP源站选路选项"></a>IP源站选路选项</h2><p>通常IP路由是动态的，即每个路由器都要判断数据报下面该转发到哪个路由器。应用程序对此不进行控制，而且通常也并不关心路由。它采用类似Traceroute程序的工具来发现实际的路由。</p><p>源站选路(source routing)的思想是由发送者指定路由。它可以采用以下两种形式：</p><ul><li>严格的源路由选择。发送端指明IP数据报所必须采用的确切路由。如果一个路由器发现源路由所指定的下一个路由器不在其直接连接的网络上，那么它就返回一个“源站路由失败”的ICMP差错报文。</li><li>宽松的源站选路。发送端指明了一个数据报经过的IP地址清单，但是数据报在清单上指明的任意两个地址之间可以通过其他路由器。</li></ul><h1 id="IP选路"><a href="#IP选路" class="headerlink" title="IP选路"></a>IP选路</h1><h2 id="引言-6"><a href="#引言-6" class="headerlink" title="引言"></a>引言</h2><p>选路是IP最重要的功能之一。需要进行选路的数据报可以由本地主机产生，也可以由其他主机产生。在后一种情况下，主机必须配置成一个路由器，否则通过网络接口接收到的数据报，如果目的地址不是本机就要被丢弃（例如，悄无声息地被丢弃）。</p><p><strong>netstat</strong><br>查看Linux中网络系统状态信息。</p><p><strong>补充说明</strong><br>netstat命令 用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat(选项)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">-a或--all：显示所有连线中的Socket；</span><br><span class="line">-A&lt;网络类型&gt;或--&lt;网络类型&gt;：列出该网络类型连线中的相关地址；</span><br><span class="line">-c或--continuous：持续列出网络状态；</span><br><span class="line">-C或--cache：显示路由器配置的快取信息；</span><br><span class="line">-e或--extend：显示网络其他相关信息；</span><br><span class="line">-F或--fib：显示FIB；</span><br><span class="line">-g或--groups：显示多重广播功能群组组员名单；</span><br><span class="line">-h或--help：在线帮助；</span><br><span class="line">-i或--interfaces：显示网络界面信息表单；</span><br><span class="line">-l或--listening：显示监控中的服务器的Socket；</span><br><span class="line">-M或--masquerade：显示伪装的网络连线；</span><br><span class="line">-n或--numeric：直接使用ip地址，而不通过域名服务器；</span><br><span class="line">-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称；</span><br><span class="line">-o或--timers：显示计时器；</span><br><span class="line">-p或--programs：显示正在使用Socket的程序识别码和程序名称；</span><br><span class="line">-r或--route：显示Routing Table；</span><br><span class="line">-s或--statistice：显示网络工作信息统计表；</span><br><span class="line">-t或--tcp：显示TCP传输协议的连线状况；</span><br><span class="line">-u或--udp：显示UDP传输协议的连线状况；</span><br><span class="line">-v或--verbose：显示指令执行过程；</span><br><span class="line">-V或--version：显示版本信息；</span><br><span class="line">-w或--raw：显示RAW传输协议的连线状况；</span><br><span class="line">-x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同；</span><br><span class="line">--ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同。</span><br></pre></td></tr></table></figure><h2 id="选路的原理"><a href="#选路的原理" class="headerlink" title="选路的原理"></a>选路的原理</h2><p>开始讨论IP选路之前，首先要理解内核是如何维护路由表的。路由表中包含的信息决定了IP层所做的所有决策。</p><p>IP搜索路由表的几个步骤：</p><ol><li>搜索匹配的主机地址；</li><li>搜索匹配的网络地址；</li><li>搜索默认表项（默认表项一般在路由表中被指定为一个网络表项，其网络号为0）。</li></ol><p>匹配主机地址步骤始终发生在匹配网络地址步骤之前。</p><p>IP层进行的选路实际上是一种选路机制，它搜索路由表并决定向哪个网络接口发送分组。这区别于选路策略，它只是一组决定把哪些路由放入路由表的规则。IP执行选路机制，而路由守护程序则一般提供选路策略。</p><h3 id="简单路由表"><a href="#简单路由表" class="headerlink" title="简单路由表"></a>简单路由表</h3><p>首先来看一看一些典型的主机路由表。在主机上，我们先执行带-r选项的netstat命令列出路由表，然后以-n选项再次执行该命令，以数字格式打印出IP地址。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# netstat -rn</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface</span><br><span class="line">0.0.0.0         172.21.0.1      0.0.0.0         UG        0 0          0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U         0 0          0 docker0</span><br><span class="line">172.21.0.0      0.0.0.0         255.255.240.0   U         0 0          0 eth0</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>对于一个给定的路由器，可以打印出五种不同的标志（flag）：</p><table><thead><tr><th>标志</th><th>解释</th></tr></thead><tbody><tr><td>U</td><td>该路由可以使用。</td></tr><tr><td>G</td><td>该路由是到一个网关（路由器）。如果没有设置该标志，说明目的地是直接相连的。</td></tr><tr><td>H</td><td>该路由是到一个主机，也就是说，目的地址是一个完整的主机地址。如果没有设置该标志，说明该路由是到一个网络，而目的地址是一个网络地址：一个网络号，或者网络号与子网号的组合。</td></tr><tr><td>D</td><td>该路由是由重定向报文创建的。</td></tr><tr><td>M</td><td>该路由已被重定向报文修改。</td></tr></tbody></table><p>标志G是非常重要的，因为由它区分了间接路由和直接路由（对于直接路由来说是不设置标志G的）。其区别在于，发往直接路由的分组中不但具有指明目的端的IP地址，还具有其链路层地址。当分组被发往一个间接路由时，IP地址指明的是最终的目的地，但是链路层地址指明的是网关（即下一站路由器）。</p><p>理解G和H标志之间的区别是很重要的。G标志区分了直接路由和间接路由，如上所述。但是H标志表明，目的地址（netstat命令输出第一行）是一个完整的主机地址。没有设置H标志说明目的地址是一个网络地址（主机号部分为0）。当为某个目的IP地址搜索路由表时，主机地址项必须与目的地址完全匹配，而网络地址项只需要匹配目的地址的网络号和子网号就可以了。另外，大多数版本的netstat命令首先打印出所有的主机路由表项，然后才是网络路由表项。</p><h2 id="ICMP主机与网络不可达差错"><a href="#ICMP主机与网络不可达差错" class="headerlink" title="ICMP主机与网络不可达差错"></a>ICMP主机与网络不可达差错</h2><p>当路由器收到一份IP数据报但又不能转发时，就要发送一份ICMP“主机不可达”差错报文。</p><h2 id="ICMP重定向差错"><a href="#ICMP重定向差错" class="headerlink" title="ICMP重定向差错"></a>ICMP重定向差错</h2><p>当IP数据报应该被发送到另一个路由器时，收到数据报的路由器就要发送ICMP重定向差错报文给IP数据报的发送端。这在概念上是很简单的，正如图9-3所示的那样。只有当主机可以选择路由器发送分组的情况下，我们才可能看到ICMP重定向报文。</p><ol><li>我们假定主机发送一份IP数据报给R1。这种选路决策经常发生，因为R1是该主机的默认路由。</li><li>R1收到数据报并且检查它的路由表，发现R2是发送该数据报的下一站。当它把数据报发送给R2时，R1检测到它正在发送的接口与数据报到达接口是相同的（即主机和两个路由器所在的LAN）。这样就给路由器发送重定向报文给原始发送端提供了线索。</li><li>R1发送一份ICMP重定向报文给主机，告诉它以后把数据报发送给R2而不是R1。</li></ol><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/ICMP%E9%87%8D%E5%AE%9A%E5%90%91%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt></p><p>重定向一般用来让具有很少选路信息的主机逐渐建立更完善的路由表。主机启动时路由表中可以只有一个默认表项（在图9-3所示的例子中，为R1或R2）。一旦默认路由发生差错，默认路由器将通知它进行重定向，并允许主机对路由表作相应的改动。ICMP重定向允许TCP/IP主机在进行选路时不需要具备智能特性，而把所有的智能特性放在路由器端。</p><h2 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h2><p>系统产生的或转发的每份IP数据报都要搜索路由表，它可以被路由守护程序或ICMP重定向报文修改。系统在默认情况下不转发数据报，除非进行特殊的配置。用route命令可以进入静态路由，可以利用新ICMP路由器发现报文来初始化默认表项，并进行动态修改。主机在启动时只有一个简单的路由表，它可以被来自默认路由器的ICMP重定向报文动态修改。</p><h1 id="动态选路协议"><a href="#动态选路协议" class="headerlink" title="动态选路协议"></a>动态选路协议</h1><p>在前面各章中，我们讨论了静态选路。在配置接口时，以默认方式生成路由表项（对于直接连接的接口），并通过route命令增加表项（通常从系统自引导程序文件），或是通过ICMP重定向生成表项（通常是在默认方式出错的情况下）。</p><p>在网络很小，且与其他网络只有单个连接点且没有多余路由时（若主路由失败，可以使用备用路由），采用这种方法是可行的。如果上述三种情况不能全部满足，通常使用动态选路。</p><h2 id="动态选路"><a href="#动态选路" class="headerlink" title="动态选路"></a>动态选路</h2><p>当相邻路由器之间进行通信，以告知对方每个路由器当前所连接的网络，这时就出现了动态选路。路由器之间必须采用选路协议进行通信，这样的选路协议有很多种。路由器上有一个进程称为路由守护程序（ routing daemon），它运行选路协议，并与其相邻的一些路由器进行通信。</p><p>路由守护程序将选路策略（routing policy）加入到系统中，选择路由并加入到内核的路由表中。如果守护程序发现前往同一信宿存在多条路由，那么它（以某种方法）将选择最佳路由并加入内核路由表中。如果路由守护程序发现一条链路已经断开（可能是路由器崩溃或电话线路不好），它可以删除受影响的路由或增加另一条路由以绕过该问题。</p><p>在像Internet这样的系统中，目前采用了许多不同的选路协议。Internet是以一组自治系统(AS，Autonomous System)的方式组织的，每个自治系统通常由单个实体管理。常常将一个公司或大学校园定义为一个自治系统。NSFNET的Internet骨干网形成一个自治系统，这是因为骨干网中的所有路由器都在单个的管理控制之下。</p><p>每个自治系统可以选择该自治系统中各个路由器之间的选路协议。这种协议我们称之为内部网关协议IGP（Interior Gateway Protocol）或域内选路协议（intradomain routing protocol）。最常用的IGP是选路信息协议RIP。一种新的IGP是开放最短路径优先OSPF（Open Shortest PathFirst）协议。它意在取代RIP。</p><blockquote><p>新的RFC[Almquist 1993]规定，实现任何动态选路协议的路由器必须同时支持OSPF和RIP，还可以支持其他IGP协议。</p></blockquote><h2 id="RIP：选路信息协议"><a href="#RIP：选路信息协议" class="headerlink" title="RIP：选路信息协议"></a>RIP：选路信息协议</h2><h3 id="正常运行"><a href="#正常运行" class="headerlink" title="正常运行"></a>正常运行</h3><p>让我们来看一下采用RIP协议的routed程序正常运行的结果。RIP常用的UDP端口号是520。</p><ul><li>初始化：在启动一个路由守护程序时，它先判断启动了哪些接口，并在每个接口上发送一个请求报文，要求其他路由器发送完整路由表。在点对点链路中，该请求是发送给其他终点的。如果网络支持广播的话，这种请求是以广播形式发送的。目的UDP端口号是520（这是其他路由器的路由守护程序端口号）。这种请求报文的命令字段为1，但地址系列字段设置为0，而度量字段设置为16。这是一种要求另一端完整路由表的特殊请求报文。</li><li>接收到请求。如果这个请求是刚才提到的特殊请求，那么路由器就将完整的路由表发送给请求者。否则，就处理请求中的每一个表项：如果有连接到指明地址的路由，则将度量设置成我们的值，否则将度量置为16（度量为16是一种称为“无穷大”的特殊值，它意味着没有到达目的的路由）。然后发回响应。</li><li>接收到响应。使响应生效，可能会更新路由表。可能会增加新表项，对已有的表项进行修改，或是将已有表项删除。</li><li>定期选路更新。每过30秒，所有或部分路由器会将其完整路由表发送给相邻路由器。发送路由表可以是广播形式的（如在以太网上），或是发送给点对点链路的其他终点的。</li><li>触发更新。每当一条路由的度量发生变化时，就对它进行更新。不需要发送完整路由表，而只需要发送那些发生变化的表项。</li></ul><p><font color="DeepPink"><strong>每条路由都有与之相关的定时器。如果运行RIP的系统发现一条路由在3分钟内未更新，就将该路由的度量设置成无穷大（16），并标注为删除。这意味着已经在6个30秒更新时间里没收到通告该路由的路由器的更新了。再过60秒，将从本地路由表中删除该路由，以保证该路由的失效已被传播开。</strong></font></p><h3 id="度量"><a href="#度量" class="headerlink" title="度量"></a>度量</h3><p>RIP所使用的度量是以跳(hop)计算的。所有直接连接接口的跳数为1。考虑图10-4所示的路由器和网络。画出的4条虚线是广播RIP报文。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E8%B7%AF%E7%94%B1%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B.png" alt></p><p>路由器R1通过发送广播到N1通告它与N2之间的跳数是1（发送给N1的广播中通告它与N1之间的路由是无用的）。同时也通过发送广播给N2通告它与N1之间的跳数为1。同样，R2通告它与N2的度量为1，与N3的度量为1。</p><p>如果相邻路由器通告它与其他网络路由的跳数为1，那么我们与那个网络的度量就是2，这是因为为了发送报文到该网络，我们必须经过那个路由器。在我们的例子中，R2到N1的度量是2，与R1到N3的度量一样。</p><p>由于每个路由器都发送其路由表给邻站，因此，可以判断在同一个自治系统AS内到每个网络的路由。如果在该AS内从一个路由器到一个网络有多条路由，那么路由器将选择跳数最小的路由，而忽略其他路由。</p><p>跳数的最大值是15，这意味着RIP只能用在主机间最大跳数值为15的AS内。度量为16表示到无路由到达该IP地址。</p><h2 id="OSPF：开放最短路径优先"><a href="#OSPF：开放最短路径优先" class="headerlink" title="OSPF：开放最短路径优先"></a>OSPF：开放最短路径优先</h2><p>OSPF是除RIP外的另一个内部网关协议。它克服了RIP的所有限制。RFC1247[Moy 1991]中对第2版OSPF进行了描述。</p><p>与采用距离向量的RIP协议不同的是，OSPF是一个链路状态协议。距离向量的意思是，RIP发送的报文包含一个距离向量（跳数）。每个路由器都根据它所接收到邻站的这些距离向量来更新自己的路由表。</p><p>在一个链路状态协议中，路由器并不与其邻站交换距离信息。它采用的是每个路由器主动地测试与其邻站相连链路的状态，将这些信息发送给它的其他邻站，而邻站将这些信息在自治系统中传播出去。每个路由器接收这些链路状态信息，并建立起完整的路由表。</p><p>从实际角度来看，二者的不同点是链路状态协议总是比距离向量协议收敛更快。收敛的意思是在路由发生变化后，例如在路由器关闭或链路出故障后，可以稳定下来。</p><p>OSPF与RIP（以及其他选路协议）的不同点在于，OSPF直接使用IP。也就是说，它并不使用UDP或TCP。对于IP首部的protocol字段，OSPF有其自己的值。</p><p>另外，作为一种链路状态协议而不是距离向量协议，OSPF还有着一些优于RIP的特点。</p><ol><li>OSPF可以对每个IP服务类型计算各自的路由集。这意味着对于任何目的，可以有多个路由表表项，每个表项对应着一个IP服务类型。</li><li>给每个接口指派一个无维数的费用。可以通过吞吐率、往返时间、可靠性或其他性能来进行指派。可以给每个IP服务类型指派一个单独的费用。</li><li>当对同一个目的地址存在着多个相同费用的路由时，OSPF在这些路由上平均分配流量。我们称之为流量平衡。</li><li>OSPF支持子网：子网掩码与每个通告路由相连。这样就允许将一个任何类型的IP地址分割成多个不同大小的子网。到一个主机的路由是通过全1子网掩码进行通告的。默认路由是以IP地址为0.0.0.0、网络掩码为全0进行通告的。</li><li>路由器之间的点对点链路不需要每端都有一个IP地址，我们称之为无编号网络。这样可以节省IP地址—现在非常紧缺的一种资源。</li><li>采用了一种简单鉴别机制。可以采用类似于RIP-2机制的方法指定一个明文口令。</li><li>OSPF采用多播，而不是广播形式，以减少不参与OSPF的系统负载。</li></ol><p>随着大部分厂商支持OSPF，在很多网络中OSPF将逐步取代RIP。</p><h2 id="BGP：边界网关协议"><a href="#BGP：边界网关协议" class="headerlink" title="BGP：边界网关协议"></a>BGP：边界网关协议</h2><p>BGP系统与其他BGP系统之间交换网络可到达信息。这些信息包括数据到达这些网络所必须经过的自治系统AS中的所有路径。这些信息足以构造一幅自治系统连接图。然后，可以根据连接图删除选路环，制订选路策略。</p><p>首先，我们将一个自治系统中的IP数据报分成本地流量和通过流量。在自治系统中，本地流量是起始或终止于该自治系统的流量。也就是说，其信源IP地址或信宿IP地址所指定的主机位于该自治系统中。其他的流量则称为通过流量。在Internet中使用BGP的一个目的就是减少通过流量。</p><p>可以将自治系统分为以下几种类型：<br>1) 残桩自治系统(stub AS)，它与其他自治系统只有单个连接。 stub AS只有本地流量。<br>2) 多接口自治系统(multihomed AS)，它与其他自治系统有多个连接，但拒绝传送通过流量。<br>3) 转送自治系统(transit AS)，它与其他自治系统有多个连接，在一些策略准则之下，它可以传送本地流量和通过流量。</p><p>这样，可以将Internet的总拓扑结构看成是由一些残桩自治系统、多接口自治系统以及转送自治系统的任意互连。残桩自治系统和多接口自治系统不需要使用BGP——它们通过运行EGP在自治系统之间交换可到达信息。</p><p>BGP允许使用基于策略的选路。由自治系统管理员制订策略，并通过配置文件将策略指定给BGP。制订策略并不是协议的一部分，但指定策略允许BGP实现在存在多个可选路径时选择路径，并控制信息的重发送。选路策略与政治、安全或经济因素有关。</p><p>BGP与RIP和OSPF的不同之处在于BGP使用TCP作为其传输层协议。两个运行BGP的系统之间建立一条TCP连接，然后交换整个BGP路由表。从这个时候开始，在路由表发生变化时，再发送更新信号。</p><p>BGP是一个距离向量协议，但是与（通告到目的地址跳数的）RIP不同的是，BGP列举了到每个目的地址的路由（自治系统到达目的地址的序列号）。这样就排除了一些距离向量协议的问题。采用16bit数字表示自治系统标识。</p><p>BGP通过定期发送keepalive报文给其邻站来检测TCP连接对端的链路或主机失败。两个报文之间的时间间隔建议值为30秒。应用层的keepalive报文与TCP的keepalive选项是独立的。</p><h2 id="CIDR：无类型域间选路"><a href="#CIDR：无类型域间选路" class="headerlink" title="CIDR：无类型域间选路"></a>CIDR：无类型域间选路</h2><p>CIDR的基本观点是采用一种分配多个IP地址的方式，使其能够将路由表中的许多表项总和(summarization)成更少的数目。例如，如果给单个站点分配16个C类地址，以一种可以用总和的方式来分配这16个地址，这样，所有这16个地址可以参照Internet上的单个路由表表项。同时，如果有8个不同的站点是通过同一个Internet服务提供商的同一个连接点接入Internet的，且这8个站点分配的8个不同IP地址可以进行总和，那么，对于这8个站点，在Internet上，只需要单个路由表表项。</p><p>要使用这种总和，必须满足以下三种特性：<br>1) 为进行选路要对多个IP地址进行总和时，这些IP地址必须具有相同的高位地址比特。<br>2) 路由表和选路算法必须扩展成根据 32 bit IP地址和32 bit掩码做出选路决策。<br>3) 必须扩展选路协议使其除了32 bit地址外，还要有32 bit掩码。OSPF和RIP-2都能够携带第4版BGP所提出的32 bit掩码。</p><p>CIDR同时还使用一种技术，使最佳匹配总是最长的匹配：即在32bit掩码中，它具有最大值。</p><h1 id="UDP：用户数据报协议"><a href="#UDP：用户数据报协议" class="headerlink" title="UDP：用户数据报协议"></a>UDP：用户数据报协议</h1><h2 id="引言-7"><a href="#引言-7" class="headerlink" title="引言"></a>引言</h2><p>UDP是一个简单的面向数据报的运输层协议：进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。这与面向流字符的协议不同，如TCP，应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。</p><p>UDP数据报封装成一份IP数据报的格式如图11-1所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/UDP%E5%B0%81%E8%A3%85.png" alt></p><p>应用程序必须关心IP数据报的长度。如果它超过网络的MTU，那么就要对IP数据报进行分片。如果需要，源端到目的端之间的每个网络都要进行分片，并不只是发送端主机连接第一个网络才这样做。</p><h2 id="UDP首部"><a href="#UDP首部" class="headerlink" title="UDP首部"></a>UDP首部</h2><p>UDP首部的各字段如图11-2所示。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/UDP%E9%A6%96%E9%83%A8.png" alt></p><p>UDP长度字段指的是UDP首部和UDP数据的字节长度。该字段的最小值为8字节（发送一份0字节的UDP数据报是OK）。这个UDP长度是有冗余的。IP数据报长度指的是数据报全长，因此UDP数据报长度是全长减去IP首部的长度。</p><h2 id="UDP检验和"><a href="#UDP检验和" class="headerlink" title="UDP检验和"></a>UDP检验和</h2><p>UDP和TCP在首部中都有覆盖它们首部和数据的检验和。UDP的检验和是可选的，而TCP的检验和是必需的。</p><p>如果发送端没有计算检验和而接收端检测到检验和有差错，那么UDP数据报就要被悄悄地丢弃。不产生任何差错报文（当IP层检测到IP首部检验和有差错时也这样做）。UDP检验和是一个端到端的检验和。它由发送端计算，然后由接收端验证。其目的是为了发现UDP首部和数据在发送端到接收端之间发生的任何改动。</p><blockquote><p>注意，TCP发生检验和差错的比例与UDP相比要高得多。这很可能是因为在该系统中的TCP连接经常是“远程”连接（经过许多路由器和网桥等中间设备），而UDP一般为本地通信。</p></blockquote><h2 id="IP分片"><a href="#IP分片" class="headerlink" title="IP分片"></a>IP分片</h2><p>物理网络层一般要限制每次发送数据帧的最大长度。任何时候IP层接收到一份要发送的IP数据报时，它要判断向本地哪个接口发送数据（选路），并查询该接口获得其MTU。IP把MTU与数据报长度进行比较，如果需要则进行分片。分片可以发生在原始发送端主机上，也可以发生在中间路由器上。</p><p>把一份IP数据报分片以后，只有到达目的地才进行重新组装（这里的重新组装与其他网络协议不同，它们要求在下一站就进行进行重新组装，而不是在最终的目的地）。重新组装由目的端的IP层来完成，其目的是使分片和重新组装过程对运输层（TCP和UDP）是透明的，除了某些可能的越级操作外。已经分片过的数据报有可能会再次进行分片（可能不止一次）。IP首部中包含的数据为分片和重新组装提供了足够的信息。</p><p>回忆IP首部（图3-1），下面这些字段用于分片过程。对于发送端发送的每份IP数据报来说，其标识字段都包含一个唯一值。该值在数据报分片时被复制到每个片中（我们现在已经看到这个字段的用途）。标志字段用其中一个比特来表示“更多的片”。除了最后一片外，其他每个组成数据报的片都要把该比特置1。片偏移字段指的是该片偏移原始数据报开始处的位置。另外，当数据报被分片后，每个片的总长度值要改为该片的长度值。</p><p>最后，标志字段中有一个比特称作“不分片”位。如果将这一比特置1，IP将不对数据报进行分片。相反把数据报丢弃并发送一个ICMP差错报文（“需要进行分片但设置了不分片比特”，见图6-3）给起始端。在下一节我们将看到出现这个差错的例子。</p><p>当IP数据报被分片后，每一片都成为一个分组，具有自己的IP首部，并在选择路由时与其他分组独立。这样，当数据报的这些片到达目的端时有可能会失序，但是在IP首部中有足够的信息让接收端能正确组装这些数据报片。</p><p>尽管IP分片过程看起来是透明的，但有一点让人不想使用它：即使只丢失一片数据也要重传整个数据报。为什么会发生这种情况呢？因为IP层本身没有超时重传的机制——由更高层来负责超时和重传（TCP有超时和重传机制，但UDP没有。一些UDP应用程序本身也执行超时和重传）。当来自TCP报文段的某一片丢失后，TCP在超时后会重发整个TCP报文段，该报文段对应于一份IP数据报。没有办法只重传数据报中的一个数据报片。事实上，如果对数据报分片的是中间路由器，而不是起始端系统，那么起始端系统就无法知道数据报是如何被分片的。就这个原因，经常要避免分片。文献[KentandMogul1987]对避免分片进行了论述。</p><blockquote><p>在一个以太网上，数据帧的最大长度是1500字节，其中1472字节留给数据，假定IP首部为20字节，UDP首部为8字节。</p></blockquote><p>IP数据报是指IP层端到端的传输单元（在分片之前和重新组装之后），分组是指在IP层和链路层之间传送的数据单元。一个分组可以是一个完整的IP数据报，也可以是IP数据报的一个分片。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/UDP%E5%88%86%E7%89%87%E4%B8%BE%E4%BE%8B.png" alt></p><h1 id="广播和多播"><a href="#广播和多播" class="headerlink" title="广播和多播"></a>广播和多播</h1><h2 id="引言-8"><a href="#引言-8" class="headerlink" title="引言"></a>引言</h2><p>为了弄清广播和多播，需要了解主机对由信道传送过来帧的过滤过程。图12-1说明了这一过程。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%90%84%E5%B1%82%E5%AF%B9%E6%94%B6%E5%88%B0%E5%B8%A7%E7%9A%84%E8%BF%87%E6%BB%A4%E8%BF%87%E7%A8%8B.png" alt></p><p>首先，网卡查看由信道传送过来的帧，确定是否接收该帧，若接收后就将它传往设备驱动程序。通常网卡仅接收那些目的地址为网卡物理地址或广播地址的帧。另外，多数接口均被设置为混合模式，这种模式能接收每个帧的一个复制。作为一个例子，tcpdump使用这种模式。</p><p>目前，大多数的网卡经过配置都能接收目的地址为多播地址或某些子网多播地址的帧。对于以太网，当地址中最高字节的最低位设置为1时表示该地址是一个多播地址，用十六进制可表示为01:00:00:00:00:00（以太网广播地址ff:ff:ff:ff:ff:ff可看作是以太网多播地址的特例）。</p><p>如果网卡收到一个帧，这个帧将被传送给设备驱动程序（如果帧检验和错，网卡将丢弃该帧）。设备驱动程序将进行另外的帧过滤。首先，帧类型中必须指定要使用的协议（IP、ARP等等）。其次，进行多播过滤来检测该主机是否属于多播地址说明的多播组。设备驱动程序随后将数据帧传送给下一层，比如，当帧类型指定为IP数据报时，就传往IP层。IP根据IP地址中的源地址和目的地址进行更多的过滤检测。如果正常，就将数据报传送给下一层（如TCP或UDP）。</p><p>每次UDP收到由IP传送来的数据报，就根据目的端口号，有时还有源端口号进行数据报过滤。如果当前没有进程使用该目的端口号，就丢弃该数据报并产生一个ICMP不可达报文（TCP根据它的端口号作相似的过滤）。如果UDP数据报存在检验和错，将被丢弃。</p><p>使用广播的问题在于它增加了对广播数据不感兴趣主机的处理负荷。拿一个使用UDP广播应用作为例子。如果网内有50个主机，但仅有20个参与该应用，每次这20个主机中的一个发送UDP广播数据时，其余30个主机不得不处理这些广播数据报。一直到UDP层，收到的UDP广播数据报才会被丢弃。这30个主机丢弃UDP广播数据报是因为这些主机没有使用这个目的端口。</p><p>多播的出现减少了对应用不感兴趣主机的处理负荷。使用多播，主机可加入一个或多个多播组。这样，网卡将获悉该主机属于哪个多播组，然后仅接收主机所在多播组的那些多播帧。</p><h2 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h2><h3 id="受限的广播"><a href="#受限的广播" class="headerlink" title="受限的广播"></a>受限的广播</h3><p>受限的广播地址是255.255.255.255。该地址用于主机配置过程中IP数据报的目的地址，此时，主机可能还不知道它所在网络的网络掩码，甚至连它的IP地址也不知道。</p><p>在任何情况下，路由器都不转发目的地址为受限的广播地址的数据报，这样的数据报仅出现在本地网络中。</p><h3 id="指向网络的广播"><a href="#指向网络的广播" class="headerlink" title="指向网络的广播"></a>指向网络的广播</h3><p>指向网络的广播地址是主机号为全1的地址。A类网络广播地址为netid.255.255.255，其中netid为A类网络的网络号。</p><p>一个路由器必须转发指向网络的广播，但它也必须有一个不进行转发的选择。</p><h3 id="指向子网的广播"><a href="#指向子网的广播" class="headerlink" title="指向子网的广播"></a>指向子网的广播</h3><p>指向子网的广播地址为主机号为全1且有特定子网号的地址。作为子网直接广播地址的IP地址需要了解子网的掩码。例如，如果路由器收到发往128.1.2.255的数据报，当B类网络128.1的子网掩码为255.255.255.0时，该地址就是指向子网的广播地址；但如果该子网的掩码为255.255.254.0，该地址就不是指向子网的广播地址。</p><h3 id="指向所有子网的广播"><a href="#指向所有子网的广播" class="headerlink" title="指向所有子网的广播"></a>指向所有子网的广播</h3><p>指向所有子网的广播也需要了解目的网络的子网掩码，以便与指向网络的广播地址区分开。指向所有子网的广播地址的子网号及主机号为全1。例如，如果目的子网掩码为255.255.255.0，那么IP地址128.1.255.255是一个指向所有子网的广播地址。然而，如果网络没有划分子网，这就是一个指向网络的广播。</p><h2 id="多播"><a href="#多播" class="headerlink" title="多播"></a>多播</h2><p>IP多播提供两类服务：</p><ol><li>向多个目的地址传送数据。</li><li>客户对服务器的请求。例如，无盘工作站需要确定启动引导服务器。目前，这项服务是通过广播来提供的，但是使用多播可降低不提供这项服务主机的负担。</li></ol><h3 id="多播组地址"><a href="#多播组地址" class="headerlink" title="多播组地址"></a>多播组地址</h3><p>图12-2显示了D类IP地址的格式。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/D%E7%B1%BBIP%E5%9C%B0%E5%9D%80%E6%A0%BC%E5%BC%8F.png" alt></p><p>多播组地址包括为1110的最高4bit和多播组号。它们通常可表示为点分十进制数，范围从224.0.0.0到239.255.255.255。</p><p>能够接收发往一个特定多播组地址数据的主机集合称为主机组(hostgroup)。一个主机组可跨越多个网络。主机组中成员可随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。</p><h2 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h2><p>广播是将数据报发送到网络中的所有主机（通常是本地相连的网络），而多播是将数据报发送到网络的一个主机组。这两个概念的基本点在于当收到送往上一个协议栈的数据帧时采用不同类型的过滤。每个协议层均可以因为不同的理由丢弃数据报。</p><p>目前有四种类型的广播地址：受限的广播、指向网络的广播、指向子网的广播和指向所有子网的广播。最常用的是指向子网的广播。受限的广播通常只在系统初始启动时才会用到。</p><p>试图通过路由器进行广播而发生的问题，常常是因为路由器不了解目的网络的子网掩码。结果与多种因素有关：广播地址类型、配置参数等等。</p><p>D类IP地址被称为多播组地址。通过将其低位23bit映射到相应以太网地址中便可实现多播组地址到以太网地址的转换。由于地址映射是不唯一的，因此需要其他的协议实现额外的数据报过滤。</p><h1 id="IGMP：Internet组管理协议"><a href="#IGMP：Internet组管理协议" class="headerlink" title="IGMP：Internet组管理协议"></a>IGMP：Internet组管理协议</h1><h2 id="引言-9"><a href="#引言-9" class="headerlink" title="引言"></a>引言</h2><p><font color="DeepPink"><strong>本章将介绍用于支持主机和路由器进行多播的Internet组管理协议（IGMP）。它让一个物理网络上的所有系统知道主机当前所在的多播组。</strong></font>多播路由器需要这些信息以便知道多播数据报应该向哪些接口转发。</p><p>正如ICMP一样，IGMP也被当作IP层的一部分。IGMP报文通过IP数据报进行传输。不像我们已经见到的其他协议，IGMP有固定的报文长度，没有可选数据。图13-1显示了IGMP报文如何封装在IP数据报中。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/IGMP%E6%8A%A5%E6%96%87%E5%B0%81%E8%A3%85%E5%9C%A8IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E4%B8%AD.png" alt></p><p>IGMP报文通过IP首部中协议字段值为2来指明。</p><h2 id="IGMP报文"><a href="#IGMP报文" class="headerlink" title="IGMP报文"></a>IGMP报文</h2><p>图13-2显示了长度为8字节的IGMP报文格式。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/IGMP%E6%8A%A5%E6%96%87%E7%9A%84%E5%AD%97%E6%AE%B5%E6%A0%BC%E5%BC%8F.png" alt></p><p>这是版本为1的IGMP。IGMP类型为1说明是由多播路由器发出的查询报文，为2说明是主机发出的报告报文。检验和的计算和ICMP协议相同。<br>组地址为D类IP地址。在查询报文中组地址设置为0，在报告报文中组地址为要参加的组地址。</p><h1 id="DNS：域名系统"><a href="#DNS：域名系统" class="headerlink" title="DNS：域名系统"></a>DNS：域名系统</h1><h2 id="引言-10"><a href="#引言-10" class="headerlink" title="引言"></a>引言</h2><p>域名系统（DNS）是一种用于TCP/IP应用程序的分布式数据库，它提供主机名字和IP地址之间的转换及有关电子邮件的选路信息。这里提到的分布式是指在Internet上的单个站点不能拥有所有的信息。</p><h2 id="DNS-基础"><a href="#DNS-基础" class="headerlink" title="DNS 基础"></a>DNS 基础</h2><p>DNS的层次组织:</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/DNS%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%84%E7%BB%87.png" alt></p><p>每个问题有一个查询类型，而每个响应（也称一个资源记录，我们下面将谈到）也有一个类型。大约有20个不同的类型值，其中的一些目前已经过时。图14-7显示了其中的一些值。查询类型是类型的一个超集(superset)：图中显示的类型值中只有两个能用于查询类型。</p><p><img src="/images/tcp-ip-illustrated-volume-1-the-protocols-note/DNS%E9%97%AE%E9%A2%98%E5%92%8C%E5%93%8D%E5%BA%94%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%80%BC%E5%92%8C%E6%9F%A5%E8%AF%A2%E7%B1%BB%E5%9E%8B%E5%80%BC.png" alt></p><p>最常用的查询类型是A类型，表示期望获得查询名的IP地址。一个PTR查询则请求获得一个IP地址对应的域名。</p><p>查询类通常是1，指互联网地址（某些站点也支持其他非IP地址）。</p><h2 id="指针查询"><a href="#指针查询" class="headerlink" title="指针查询"></a>指针查询</h2><p>DNS中一直难于理解的部分就是指针查询方式，即给定一个IP地址，返回与该地址对应的域名。</p><h2 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h2><p>应用程序通过名字解析器将一个主机名转换为一个IP地址，也可将一个IP地址转换为与之对应的主机名。名字解析器将向一个本地名字服务器发出查询请求，这个名字服务器可能通过某个根名字服务器或其他名字服务器来完成这个查询。</p><h1 id="TCP：传输控制协议"><a href="#TCP：传输控制协议" class="headerlink" title="TCP：传输控制协议"></a>TCP：传输控制协议</h1><h2 id="TCP的服务"><a href="#TCP的服务" class="headerlink" title="TCP的服务"></a>TCP的服务</h2><p>TCP通过下列方式来提供可靠性：</p><ul><li>应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的数据报长度将保持不变。由TCP传递给IP的信息单位称为报文段或段（segment）。</li><li>当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。</li><li>当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。</li><li>TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）。</li><li>既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。</li><li>既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据。</li><li>TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。</li></ul><p>TCP对字节流的内容不作任何解释。TCP不知道传输的数据字节流是二进制数据，还是ASCII字符、EBCDIC字符或者其他类型数据。对字节流的解释由TCP连接双方的应用层解释。</p><blockquote><p>这种对字节流的处理方式与Unix操作系统对文件的处理方式很相似。Unix的内核对一个应用读或写的内容不作任何解释，而是交给应用程序处理。对Unix的内核来说，它无法区分一个二进制文件与一个文本文件。</p></blockquote><h1 id="未读章节"><a href="#未读章节" class="headerlink" title="未读章节"></a>未读章节</h1><p><font color="DeepPink"><strong>17章之后未读</strong></font></p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Network </tag>
            
            <tag> TCP </tag>
            
            <tag> IP </tag>
            
            <tag> Protocol </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go 设计模式</title>
      <link href="/go-solid-design.html"/>
      <url>/go-solid-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golang 代码设计及规范</p></blockquote><a id="more"></a><h1 id="代码评审"><a href="#代码评审" class="headerlink" title="代码评审"></a>代码评审</h1><p>为什么要代码评审？ 如果代码评审是要捕捉糟糕的代码，那么你如何知道你审查的代码是好的还是糟糕的？</p><p>我在找一些客观的方式来谈论代码的好坏属性。</p><h1 id="糟糕的代码"><a href="#糟糕的代码" class="headerlink" title="糟糕的代码"></a>糟糕的代码</h1><p>你可能会在代码审查中遇到以下这些糟糕的代码：</p><ul><li>Rigid - 代码是否死板？它是否有强类型或参数以至于修改起来很困难？</li><li>Fragile - 代码是否脆弱？对代码做轻微的改变是否就会引起程序极大的破坏？</li><li>Immobile - 代码是否很难重构？</li><li>Complex - 代码是否过于复杂，是否过度设计？</li><li>Verbose - 代码是否过于冗长而使用起来很费劲？当查阅代码是否很难看出来代码在做什么？</li></ul><p>当你做代码审查的时候是否会很高兴看到这些词语？</p><p>当然不会。</p><h1 id="好的设计"><a href="#好的设计" class="headerlink" title="好的设计"></a>好的设计</h1><p>如果有一些描述优秀的设计属性的方式就更好了，不仅仅是糟糕的设计，是否能在客观条件下做？</p><h2 id="SOLID"><a href="#SOLID" class="headerlink" title="SOLID"></a>SOLID</h2><p>在2002年，Robert Martin的《Agile Software Development, Principles, Patterns, and Practices》书中提到了五个可重用软件设计的原则 - “SOLID”（英文首字母缩略字）:</p><ul><li>Single Responsibility Principle - 单一功能原则</li><li>Open/Closed Principle - 开闭原则</li><li>Liskov Substitution Principle - 里氏替换原则</li><li>Interface Segregation Principle - 接口隔离原则</li><li>Dependency Inversion Principle - 依赖反转原则</li></ul><p>这本书有点点过时，使用的语言也是十多年前的。但是，或许SOLID原则的某些方面可以给我们一个有关如何谈论一个精心设计的Go语言程序的线索。</p><h3 id="Single-Responsibility-Principle"><a href="#Single-Responsibility-Principle" class="headerlink" title="Single Responsibility Principle"></a>Single Responsibility Principle</h3><blockquote><p>A class should have one, and only one, reason to change. –Robert C Martin</p></blockquote><p>现在Go语言显然没有classses - 相反，我们有更为强大的组合的概念 - 但是如果你可以看到过去class的使用，我认为这里有其价值。</p><p>为什么一段代码应该只有一个原因改变如此重要？当然，和你自己的代码要修改比较起来，发现自己代码所依赖的代码要修改会更令人头疼。而且，当你的代码不得不要修改的时候，它应该对直接的刺激有反应，而不应该是一个间接伤害的受害者。</p><p>所以，代码有单一功能原则从而有最少的原因来改变。</p><h4 id="Coupling-amp-Cohesion-耦合与内聚"><a href="#Coupling-amp-Cohesion-耦合与内聚" class="headerlink" title="Coupling&amp;Cohesion - 耦合与内聚"></a>Coupling&amp;Cohesion - 耦合与内聚</h4><p>这两个词语描绘了修改一段软件代码是何等的简单或困难。</p><p>Coupling - 耦合是两个东西一起改变 - 一个移动会引发另一个移动。<br>Cohesion - 内聚是相关联但又隔离，一种相互吸引的力量。</p><p>在软件方面，内聚是形容代码段自然吸引到另一个的属性。</p><p>要描述Go语言的耦合与内聚，我们可以要谈论一下functions和methods，当讨论单一功能原则时它们很常见，但是我相信它始于Go语言的package模型。</p><h4 id="Pakcage命名"><a href="#Pakcage命名" class="headerlink" title="Pakcage命名"></a>Pakcage命名</h4><p>在Go语言中，所有的代码都在某个package中。好的package设计始于他的命名。package名字不仅描述了它的目的而且还是一个命名空间的前缀。Go语言标准库里有一些好的例子： </p><ul><li>net/http - 提供了http客户端和服务 </li><li>os/exec - 执行外部的命令 </li><li>encoding/json - 实现了JSON的编码与解码</li></ul><p>在你自己的项目中使用其他pakcage时要用import声明，它会在两个package之间建立一个源码级的耦合。</p><h4 id="糟糕的pakcage命名"><a href="#糟糕的pakcage命名" class="headerlink" title="糟糕的pakcage命名"></a>糟糕的pakcage命名</h4><p>关注于命名并不是在卖弄。糟糕的命名会失去罗列其目的的机会。</p><p>比如说server、private、common、utils 这些糟糕的命名都很常见。这些package就像是一个混杂的场所，因为他们好多都是没有原因地经常改变。</p><h4 id="Go语言的UNIX哲学"><a href="#Go语言的UNIX哲学" class="headerlink" title="Go语言的UNIX哲学"></a>Go语言的UNIX哲学</h4><p>以我的观点，涉及到解耦设计必须要提及Doug Mcllroy的Unix哲学：小巧而锋利的工具的结合解决更大的任务或者通常原创作者并没有预想到的任务。</p><p>我认为Go语言的Package体现了UNIX哲学精神。实际上每个package自身就是一个具有单一原则的变化单元的小型Go语言项目。</p><h3 id="Open-Closed-Principle"><a href="#Open-Closed-Principle" class="headerlink" title="Open/Closed Principle"></a>Open/Closed Principle</h3><p>Bertrand Meyer曾经写道： </p><blockquote><p>Software entities should be open for extension, but closed for modification. –Bertrand Meyer, Object-Oriented Software Construction</p></blockquote><p>该建议如何应用到现在的编程语言上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">type A struct &#123;</span><br><span class="line">        year int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (a A) Greet() &#123; fmt.Println(&quot;Hello GolangUK&quot;, a.year) &#125;</span><br><span class="line"></span><br><span class="line">type B struct &#123;</span><br><span class="line">        A</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (b B) Greet() &#123; fmt.Println(&quot;Welcome to GolangUK&quot;, b.year) &#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">        var a A</span><br><span class="line">        a.year = 2016</span><br><span class="line">        var b B</span><br><span class="line">        b.year = 2016</span><br><span class="line">        a.Greet() // Hello GolangUK 2016</span><br><span class="line">        b.Greet() // Welcome to GolangUK 2016</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>typeA有一个year字段以及Greet方法。 typeB嵌入了A做为字段，从而，使B提供的Greet方法遮蔽了A的，调用时可以看到B的方法覆盖了A。</p><p>但是嵌入不仅仅是对于方法，它还能提供嵌入type的字段访问。如你所见，由于A和B都在同一个package内，B可以访问A的私有year字段就像B已经声明过。</p><p>因此嵌入是一个强大的工具，它允许Go语言type对扩展是开放的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">type Cat struct &#123;</span><br><span class="line">        Name string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c Cat) Legs() int &#123; return 4 &#125;</span><br><span class="line"></span><br><span class="line">func (c Cat) PrintLegs() &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type OctoCat struct &#123;</span><br><span class="line">        Cat</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (o OctoCat) Legs() int &#123; return 5 &#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">        var octo OctoCat</span><br><span class="line">        fmt.Println(octo.Legs()) // 5</span><br><span class="line">        octo.PrintLegs()         // I have 4 legs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上边这个例子中，typeCat有Legs方法来计算它有几条腿。我们嵌入Cat到一个新的typeOctoCat中，并声明Octocats有五条腿。然而，尽管OctoCat定义了自己有五条腿，但是PrintLegs方法被调用时会返回4。</p><p>这是因为PrintLegs在typeCat中定义。它会将Cat做为它的接收者，因此它会使用Cat的Legs方法。Cat并不了解已嵌入的type，因此它的嵌入方法不能被修改。</p><p>由此，我们可以说<font color="DeepPink"><strong>Go语言的types对扩展开放，但是对修改是关闭的。</strong></font></p><p>事实上，Go语言接收者的方法仅仅是带有预先声明形式的参数的function的语法糖而已：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func (c Cat) PrintLegs() &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func PrintLegs(c Cat) &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个function的接收者就是你传进去的参数，而且由于Go语言不知道重载，所以说OctoCats并不能替换普通的Cats，这就引出了接下来一个原则：</p><h3 id="Liskov-Substitution-Principle"><a href="#Liskov-Substitution-Principle" class="headerlink" title="Liskov Substitution Principle"></a>Liskov Substitution Principle</h3><p>该原则由Barbara Liskov提出，大致上,它规定了两种类型如果调用者不能区分出他们行为的不同，那么他们是可替代的。</p><p>基于class的编程语言，里氏替换原则通常被解释为一个抽象基类的各种具体子类的规范。但是Go语言没有class或者inheritance（继承），因此就不能以抽象类的层次结构实现替换。</p><h4 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h4><p>相反，Go语言的interface才有权替换。在Go语言中，type不需要声明他们具体要实现的某个interface，相反的，任何想要实现interface的type仅需提供与interface声明所匹配的方法。</p><p>就Go语言而言，隐式的interface要比显式的更令人满意，这也深刻地影响着他们使用的方式。</p><p><font color="DeepPink"><strong>精心设计的interface更可能是小巧的，流行的做法是一个interface只包含一个方法。逻辑上来讲小巧的interface使实现变得简单，反之就很难做到。</strong></font>这就导致了由常见行为连接的简单实现而组成的package。</p><h4 id="io-Reader"><a href="#io-Reader" class="headerlink" title="io.Reader"></a>io.Reader</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type Reader interface &#123;</span><br><span class="line">        // Read reads up to len(buf) bytes into buf.</span><br><span class="line">        Read(buf []byte) (n int, err error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我最喜爱的Go语言interface - io.Reader</p><p>interface io.Reader非常简单，Read读取数据到提供的buffer，并返回调用者读取数据的bytes的数量以及读取期间的任何错误。它看起来简单但是很强大。</p><p>因为io.Reader可以处理任何能转换为bytes流的数据，我们可以在任何事情上构建readers：string常量、byte数组、标准输入、网络数据流、gzip后的tar文件以及通过ssh远程执行的命令的标准输出。</p><p>所有这些实现对于另外一个都是可替换的，因为他们都履行了相同的简单合同。</p><p>因此，里氏替换原则在Go语言的应用，可以用 Jim Weirich 的格言来总结：</p><blockquote><p>Require no more, promise no less. –Jim Weirich</p></blockquote><p>接下来就到了”SOLID”第四个原则。</p><h3 id="Interface-Segregation-Principle"><a href="#Interface-Segregation-Principle" class="headerlink" title="Interface Segregation Principle"></a>Interface Segregation Principle</h3><blockquote><p>Clients should not be forced to depend on methods they do not use. –Robert C. Martin</p></blockquote><p>在Go语言中，接口隔离原则的应用是指一个方法来完成其工作的孤立行为的过程。举个“栗子”，编写方法来保存一个文档结构到磁盘的任务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Save writes the contents of doc to the file f.</span><br><span class="line">func Save(f *os.File, doc *Document) error</span><br></pre></td></tr></table></figure><p>我可以这样定义这个Save方法，使用*os.File做为保存Document的文件。但是这样做会有一些问题。</p><p>Save方法排除了保存数据到网络位置的选项。假如过后要加入网络储存的需求，那么该方法就需要修改也就意味着要影响到所有使用该方法的调用者。</p><p>因为Save直接地操作磁盘上的文件，测试起来很不方便。要验证其操作，测试不得不在文件被写入后读取其内容。另外测试必须确保f被写入一个临时的位置而且过后还要删除。</p><p>*os.File还包含了许多跟Save无关的方法，像读取路径以及检查路径是否是软连接。如果Save方法只使用*os.File相关的部分将会非常有用。</p><p>我们如何做呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied ReadWriterCloser.</span><br><span class="line">func Save(rwc io.ReadWriteCloser, doc *Document) error</span><br></pre></td></tr></table></figure><p>使用io.ReadWriteCloser来应用接口隔离原则，这样就重新定义了Save方法使用一个interface来描述更为通用的类型。</p><p>随着修改，任何实现了io.ReadWriteCloser接口的type都可以代替之前的*os.File。这使得Save不仅扩展了它的应用范围同时也给Save的调用者说明了type *os.File哪些方法是操作相关的。</p><p>做为Save的作者，我没有了在*os.File上调用无关的方法选项了，因为他们都被隐藏于io.ReadWriteCloser接口。我们可以进一步地应用接口隔离原则。</p><p>首先，Save方法不太可能会保持单一功能原则，因为它要读取的文件内容应该是另外一段代码的责任。因此我们可以缩小接口范围，只传入writing和closing。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied WriteCloser.</span><br><span class="line">func Save(wc io.WriteCloser, doc *Document) error</span><br></pre></td></tr></table></figure><p>其次，通过向Save提供一种机制来关闭它的数据流，会导致另外一个问题：wc会在什么情况下关闭。Save可能会无条件的调用Close或在成功的情况下调用Close。</p><p>如果它想要在写入document之后再写入额外的数据时会引起Save的调用者一个问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">type NopCloser struct &#123;</span><br><span class="line">        io.Writer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Close has no effect on the underlying writer.</span><br><span class="line">func (c *NopCloser) Close() error &#123; return nil &#125;</span><br></pre></td></tr></table></figure><p>一个原始解决方案回事定义一个新的type，在其内嵌入io.Writer以及重写Close方法来阻止Save方法关闭底层数据流。</p><p>但是这样可能会违反里氏替换原则，如果NopCloser并没有关闭任何东西。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied Writer.</span><br><span class="line">func Save(w io.Writer, doc *Document) error</span><br></pre></td></tr></table></figure><p>一个更好的解决办法是重新定义Save只传入io.Writer，剥离它的所有责任除了写入数据到数据流。</p><p>通过对Save方法应用接口隔离原则，同时得到了最具体以及最通用的需求函数。我们现在可以使用Save方法来保存数据到任何实现了io.Writer的地方。</p><blockquote><p><font color="DeepPink"><strong>A great rule of thumb for Go is accept interfaces, return structs.</strong></font> –Jack Lindamood</p></blockquote><h3 id="Dependency-Inversion-Principle"><a href="#Dependency-Inversion-Principle" class="headerlink" title="Dependency Inversion Principle"></a>Dependency Inversion Principle</h3><blockquote><p>High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions. –Robert C. Martin</p></blockquote><p>对于Go语言来讲，依赖反转意味着什么呢?</p><p>如果你应用以上所有的原则，代码已经被分解成离散的有明确责任和目的的package，你的代码应该描述了它的依赖interface以及这些interface应该只描述他们需要的功能行为。换句话说就是他们不会再过多的改变。</p><p>因此，我认为Martin所讲的在Go语言的应用是context，即你import graph（译注：后文用“导入图”代替）的结构。</p><p>在Go语言中，你的导入图必须是非循环。不遵守此非循环的需求会导致编译错误，但是更为严重的是它代表了一系列的设计错误。</p><p>所有条件都相同的情况下精心设计的导入图应该是广泛的以及相对平坦的，而不是又高又窄。如果你有一个package的函数在没有其他package的情况下就无法操作，也许这就表明了代码没有考虑pakcage的边界。</p><p>依赖反转原则鼓励你尽可能地像导入图一样在main package或者最高层级的处理程序内对具体细节负责，让低层级代码来处理抽象的接口。</p><h2 id="“SOLID”-Go语言设计"><a href="#“SOLID”-Go语言设计" class="headerlink" title="“SOLID” Go语言设计"></a>“SOLID” Go语言设计</h2><p>回顾一下，当应用到Go语言设计中，每个“SOLID”原则都是强有力的声明，但是加在一起他们有一个中心主题。</p><ul><li>单一功能原则鼓励你在package中构建functions、types以及方法表现出自然的凝聚力。types属于彼此，functions为单一目的服务。</li><li>开闭原则鼓励你使用嵌入将简单的type组合成更为复杂的。</li><li><font color="DeepPink"><strong>里氏替换原则鼓励你在package之间表达依赖关系时用interface，而非具体类型。</strong></font>通过定义小巧的interface，我们可以更有信心地切实满足其合约。</li><li>接口隔离原则鼓励你仅取决于所需行为来定义函数和方法。<font color="DeepPink"><strong>如果你的函数仅仅需要有一个方法的interface做为参数，那么它很有可能只有一个责任。</strong></font></li><li>依赖反转原则鼓励你在编译时将package所依赖的东西移除 - 在Go语言中我们可以看到这样做使得运行时用到的某个特定的package的import声明的数量减少。</li></ul><p>如果总结这个演讲（译注：该篇文章取自Dave大神在Golang UK Conference 2016的演讲文字内容，文章结尾处有YouTube链接）它可能会是： &gt; interfaces let you apply the SOLID principles to Go programs</p><p>因为interface描绘了他们的pakcage的规定，而不是如何规定的。换个说法就是“解耦”，这确实是我们的目标，因为解耦的软件修改起来更容易。</p><p>就像Sandi Metz提到的：</p><blockquote><p>Design is the art of arranging code that needs to work today, and to be easy to change forever. –Sandi Metz</p></blockquote><p>因为如果Go语言想要成为公司长期投资的编程语言，Go程序的维护，更容易的变更将是他们决定的关键因素。</p><h1 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h1><p>Go语言程序员应当讨论更多的是设计而非框架。我们应当不惜一切代价地关注重用而非性能。</p><p>我想要看到是今天的人们谈论关于如何使用编程语言，无论是设计解决方案还是解决实际问题的选择和局限性。</p><p>我想要听到的是人们谈论如何通过精心设计、解耦、重用以及适应变化的方式来设计Go语言程序。</p><h1 id="…还有一点"><a href="#…还有一点" class="headerlink" title="…还有一点"></a>…还有一点</h1><p>我们需要告诉世界优秀的软件该如何编写。告诉他们使用Go语言如何编写优秀的、可组合的及易于变化的软件。</p><p>原文链接：<a href="http://dave.cheney.net/2016/08/20/solid-go-design" target="_blank" rel="noopener">http://dave.cheney.net/2016/08/20/solid-go-design</a></p><blockquote><p>本文转载自：<br><a href="https://blog.gokit.info/post/go-solid-design/" target="_blank" rel="noopener">https://blog.gokit.info/post/go-solid-design/</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design </tag>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 初始化顺序</title>
      <link href="/golang-package-init-order.html"/>
      <url>/golang-package-init-order.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>golang package init order</p></blockquote><a id="more"></a><p>Go程序的初始化和执行总是从 main.main  函数开始的。但是如果 main  包里导入了其它的包，则会按照顺序将它们包含进 main  包里（这里的导入顺序依赖具体实现，一般可能是以文件名或包路径名的字符串顺序导入）。如果某个包被多次导入的话，在执行的时候只会导入一次。当一个包被导入时，如果它还导入了其它的包，则先将其它的包包含进来，然后创建和初始化这个包的常量和变量。然后就是调用包里的 init  函数，如果一个包有多个 init  函数的话，实现可能是以文件名的顺序调用，同一个文件内的多个 init  则是以出现的顺序依次调用（ init  不是普通函数，可以定义有多个，所以不能被其它函数调用）。最终，在 main  包的所有包常量、包变量被创建和初始化，并且 init  函数被执行后，才会进入 main.main  函数，程序开始正常执行。下图是Go程序函数启动顺序的示意图：</p><p><img src="/images/golang-package-init-order/init.png" alt></p><p>要注意的是，在 main.main  函数执行之前所有代码都运行在同一个Goroutine中，也是运行在程序的主系统线程中。如果某个 init  函数内部用go关键字启动了新的Goroutine的话，新的Goroutine和 main.main  函数是并发执行的。<br>因为所有的 init  函数和 main  函数都是在主线程完成，它们也是满足顺序一致性模型的。</p><blockquote><p>整理自：Go语言高级编程 作者：柴树杉、曹春晖<br>图片来自：beego官网router部分</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Init </tag>
            
            <tag> Order </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Goroutine和系统线程</title>
      <link href="/goroutine-and-system-threads.html"/>
      <url>/goroutine-and-system-threads.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>goroutine and system threads</p></blockquote><a id="more"></a><p>Goroutine是Go语言特有的并发体，是一种轻量级的线程，由go关键字启动。在真实的Go语言的实现中，goroutine和系统线程也不是等价的。尽管两者的区别实际上只是一个量的区别，但正是这个量变引发了Go语言并发编程质的飞跃。</p><p>首先，每个系统级线程都会有一个固定大小的栈（一般默认可能是2MB），这个栈主要用来保存函数递归调用时参数和局部变量。固定了栈的大小导致了两个问题：一是对于很多只需要很小的栈空间的线程来说是一个巨大的浪费，二是对于少数需要巨大栈空间的线程来说又面临栈溢出的风险。针对这两个问题的解决方案是：要么降低固定的栈大小，提升空间的利用率；要么增大栈的大小以允许更深的函数递归调用，但这两者是没法同时兼得的。相反，<font color="DeepPink"><strong>一个Goroutine会以一个很小的栈启动（可能是2KB或4KB），当遇到深度递归导致当前栈空间不足时，Goroutine会根据需要动态地伸缩栈的大小（主流实现中栈的最大值可达到1GB）。</strong></font>因为启动的代价很小，所以我们可以轻易地启动成千上万个Goroutine。</p><p>Go的运行时还包含了其自己的调度器，这个调度器使用了一些技术手段，可以在n个操作系统线程上多工调度m个Goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的Goroutine。Goroutine采用的是半抢占式的协作调度，只有在当前Goroutine发生阻塞时才会导致调度；同时发生在用户态，调度器会根据具体函数只保存必要的寄存器，切换的代价要比系统线程低得多。运行时有一个 runtime.GOMAXPROCS 变量，用于控制当前运行正常非阻塞Goroutine的系统线程数目。</p><p>在Go语言中启动一个Goroutine不仅和调用函数一样简单，而且Goroutine之间调度代价也很低，这些因素极大地促进了并发编程的流行和发展。</p><blockquote><p>整理自：Go语言高级编程 作者：柴树杉、曹春晖</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Goroutine </tag>
            
            <tag> Thread </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go 密码学应用</title>
      <link href="/golang-for-crypto-developers.html"/>
      <url>/golang-for-crypto-developers.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Go Crypto</p></blockquote><a id="more"></a><h1 id="视频信息"><a href="#视频信息" class="headerlink" title="视频信息"></a>视频信息</h1><p>Go for Crypto Developers<br>by George Tankersley<br>at GopherCon 2016</p><p><a href="https://www.youtube.com/watch?v=2r_KMzXB74w" target="_blank" rel="noopener">https://www.youtube.com/watch?v=2r_KMzXB74w</a></p><p>幻灯地址：<a href="https://speakerdeck.com/gtank/crypto-for-go-developers" target="_blank" rel="noopener">https://speakerdeck.com/gtank/crypto-for-go-developers</a><br>代码：<a href="https://github.com/gtank/cryptopasta" target="_blank" rel="noopener">https://github.com/gtank/cryptopasta</a></p><h1 id="Don’t-write-your-own-crypto"><a href="#Don’t-write-your-own-crypto" class="headerlink" title="Don’t write your own crypto"></a>Don’t write your own crypto</h1><p>很多人把这句话<font color="DeepPink"><strong>误解为</strong></font>不要使用加密、不要使用任何密码学的技术，因为你不够聪明。<font color="DeepPink"><strong>No。完全不是这个意思</strong></font>。</p><p>这句话是说<font color="DeepPink"><strong>不要试图去发明创造那些加密类的算法</strong></font>。因为你不大可能会创造一个超过 AES 的加密算法、也不大可能会创造一个比 SHA 更好的 hash 算法。所以自己闭门造的算法一般意味着安全性的大大降低。</p><p>全世界能干这件事情的人不超过5个，而且他们今天都不在这里。另外一半都是 <font color="DeepPink"><strong>Daniel J. Bernstein</strong></font> 干的（开个玩笑，不过这人很牛，今天我们在用的很多加密的东西都是他设计、实现的）。</p><p>表面上好像这是个限制，其实这是个优势。因为我们<font color="DeepPink"><strong>不需要</strong></font>编写自己的加密算法，一切痛苦的工作都已经由别人做好了。我们只需要和搭积木一样去使用这些密码学工具就好了。</p><h1 id="经常听到这样的建议"><a href="#经常听到这样的建议" class="headerlink" title="经常听到这样的建议"></a>经常听到这样的建议</h1><ul><li>对传输中的数据用 TLS</li><li>对静止的数据用 GPG</li></ul><h2 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h2><p>Go 可以很容易使用 TLS，因为必须的东西都内置了，从客户端到服务端。</p><p>客户端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">var minimalTLSConfig = &amp;tls.Config&#123;</span><br><span class="line">MinVersion: tls.VersionTLS12,</span><br><span class="line">&#125;</span><br><span class="line">var tlsTransport = &amp;http.Transport&#123;</span><br><span class="line">TLSClientConfig: minimalTLSConfig,</span><br><span class="line">&#125;</span><br><span class="line">var httpClient = &amp;http.Client&#123;</span><br><span class="line">Transport: tlsTransport,</span><br><span class="line">Timeout:   10 * time.Second,</span><br><span class="line">&#125;</span><br><span class="line">func MakeRequest() error &#123;</span><br><span class="line">resp, err := httpClient.Get(&quot;https://www.google.com&quot;)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return err</span><br><span class="line">&#125;</span><br><span class="line">// have fun</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里最重要的是 tls.VersionTLS12，因为低于 1.2 的话，会导致 Go 使用一些不安全的低版本的实现，所以这里限定 1.2 比较安全。而且大部分网站也都支持。</p><p>服务端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">var minimalTLSConfig = &amp;tls.Config&#123;</span><br><span class="line">MinVersion:               tls.VersionTLS12,</span><br><span class="line">PreferServerCipherSuites: true,</span><br><span class="line">&#125;</span><br><span class="line">var srv = &amp;http.Server&#123;</span><br><span class="line">Addr:      &quot;localhost:8080&quot;,</span><br><span class="line">TLSConfig: minimalTLSConfig,</span><br><span class="line">&#125;</span><br><span class="line">func handleReq(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">fmt.Fprintf(w, &quot;Hello, world&quot;)</span><br><span class="line">&#125;</span><br><span class="line">func main() &#123;</span><br><span class="line">http.HandleFunc(&quot;/&quot;, handleReq)</span><br><span class="line">err := srv.ListenAndServeTLS(&quot;cert.pem&quot;, &quot;key.pem&quot;)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里和客户端一样，限定最小版本是 1.2，并且多了一个额外的参数，要求以服务器的 Cipher 优先，因此不按照客户端给的选择，而是按照Go服务端给的选择。因为 Go 的 TLS 包中有大量针对各种安全问题的调整，因此选择加密包的话，遵循 Go 内部的决定是最好的。</p><h2 id="GPG"><a href="#GPG" class="headerlink" title="GPG"></a>GPG</h2><p>GPG 是为了人和人之间的交流信息，而不是机器和机器之间交流信息的。</p><p>那么如何安全的使用 GPG 呢？答案就是<font color="DeepPink"><strong>不用GPG</strong></font>。因为作者觉得 GPG 太过阴谋论了，陷入了很多本不需要过多注意的区域，即使那么做了，也不见得更安全。</p><h1 id="这个-Talk-不讲-TLS-和-GPG"><a href="#这个-Talk-不讲-TLS-和-GPG" class="headerlink" title="这个 Talk 不讲 TLS 和 GPG"></a>这个 Talk 不讲 TLS 和 GPG</h1><p>因为当你实现安全的信息系统的时候，通常不会用到这两个东西。TLS 和 GPG 有他们应用的场合，但是对于每天的密码学工作来说，基本都不用这两个工具：</p><ul><li>对文件计算散列</li><li>生成随机 ID</li><li>API 验证</li><li>网站密码存储</li><li>签名、加密 cookies</li><li>JWT</li><li>签名更新</li></ul><h1 id="在-Go-的-crypto-包里的算法可不都是好的算法"><a href="#在-Go-的-crypto-包里的算法可不都是好的算法" class="headerlink" title="在 Go 的 crypto 包里的算法可不都是好的算法"></a>在 Go 的 crypto 包里的算法可不都是好的算法</h1><h2 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h2><p>下列划掉的算法都不应该再使用了：</p><ul><li><del>DES</del></li><li><del>3DES</del></li><li><del>RC4</del></li><li><del>TEA</del></li><li><del>XTEA</del></li><li><del>Blowfish</del></li><li>✔️ Twofish</li><li><del>CAST5</del></li><li>✔️ Salsa20</li><li>✔️ AES</li></ul><p>只有 Twofish、Salsa20 和 AES 还算是安全的加密算法，但是 AES 在大部分的计算机上都有硬件加速。因此只剩下一个 AES 是最佳加密算法。</p><h3 id="怎么使用-AES"><a href="#怎么使用-AES" class="headerlink" title="怎么使用 AES"></a>怎么使用 AES</h3><p>要注意，aesCipher.Encrypt() <font color="DeepPink"><strong>只会加密前16个字节</strong></font>。不少人掉到这个坑里了，结果不知道为啥就前几个字符是密文，后面全都是明文。解决办法就是<font color="DeepPink"><strong>不直接用AES</strong></font>，通过 Mode 来使用。</p><p>Block cipher mode 一样有很多种选择：</p><ul><li><del>CBC</del></li><li><del>CFB</del></li><li><del>CTR</del></li><li><del>OFB</del></li><li>✔️ GCM</li></ul><p>这里只有 GCM 是<font color="DeepPink"><strong>验证的</strong></font>加密算法，因此别的都可以不选。</p><h4 id="加密-1"><a href="#加密-1" class="headerlink" title="加密"></a>加密</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;crypto/aes&quot;</span><br><span class="line">&quot;crypto/cipher&quot;</span><br><span class="line">&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func Encrypt(data []byte, key [32]byte) ([]byte, error) &#123;</span><br><span class="line">//初始化 block cipher</span><br><span class="line">block, err := aes.NewCipher(key[:])</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//设置 block cipher mode</span><br><span class="line">gcm, err := cipher.NewGCM(block)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//生成随机 nonce</span><br><span class="line">nonce := make([]byte, gcm.NonceSize())</span><br><span class="line">_, err = rand.Read(nonce)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//封装、返回</span><br><span class="line">return gcm.Seal(nonce, nonce, data, nil), nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解密"><a href="#解密" class="headerlink" title="解密"></a>解密</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;crypto/aes&quot;</span><br><span class="line">&quot;crypto/cipher&quot;</span><br><span class="line">&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func Decrypt(ciphertext []byte, key [32]byte) (plaintext []byte, err error) &#123;</span><br><span class="line">//初始化 block cipher</span><br><span class="line">block, err := aes.NewCipher(key[:])</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//设置 block cipher mode</span><br><span class="line">gcm, err := cipher.NewGCM(block)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//返回解开的包，注意这里的 nonce 是直接取的。</span><br><span class="line">return gcm.Open(nil,</span><br><span class="line">ciphertext[:gcm.NonceSize()],</span><br><span class="line">ciphertext[gcm.NonceSize():],</span><br><span class="line">nil,</span><br><span class="line">)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="哈希散列"><a href="#哈希散列" class="headerlink" title="哈希散列"></a>哈希散列</h2><p>将一大段数据使用 Hash 算法，希望得到一串数值，这串数值可以反映你的这段数据，任何数据变化，这串数值都不同。而且希望无法从这串数值反推数据。这就是密码学 Hash 函数要保证的。（<font color="DeepPink"><strong>注意：哈希不等于加密，很多人这点容易搞混</strong></font>）</p><p>同样 Hash 函数一样有很多选择，一样是大部分都不用：</p><ul><li><del>MD4</del></li><li><del>MD5</del></li><li><del>RIPEMD160</del></li><li><del>SHA1</del></li><li>✔️ SHA2</li><li>✔️ SHA3<br>选择 SHA3 并不是因为它比 SHA2 更新更好，而是因为它不同于 SHA1 和 SHA2。几年前密码学家已经开始担心，因为MD<font color="DeepPink"><strong>以及SHA</strong></font>的哈希算法本质太相似了，那么一旦这个依赖出现问题，就意味着这个体系的不再安全。因此开始寻找一种不同的算法。经过竞赛、挑选，最终 SHA3 脱颖而出。他本身是个很出色的 Hash 算法，同时其设计和之前的这几个算法完全不一样。</li></ul><p>但是由于 SHA3 并不被广泛支持，所以如果你明确知道你可以用 SHA3，那么就用 SHA3。其它情况用 SHA2。</p><p>但是和加密一样，我们<font color="DeepPink"><strong>不应该直接使用 Hash 算法</strong></font>。因为可能会面临一系列的攻击：</p><ul><li>Length extension</li><li>Rainbow tables</li><li>Small number of possibilities (phone numbers)</li><li>Salt? Peper?</li></ul><blockquote><p>我们应该使用 HMAC，而不要直接用 Hash</p></blockquote><h2 id="实现-Hash"><a href="#实现-Hash" class="headerlink" title="实现 Hash"></a>实现 Hash</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;crypto/hmac&quot;</span><br><span class="line">&quot;crypto/sha512&quot;</span><br><span class="line">)</span><br><span class="line">func Hash(tag string, data []byte) []byte &#123;</span><br><span class="line">h := hmac.New(sha512.New512_256, []byte(tag))</span><br><span class="line">h.Write(data)</span><br><span class="line">return h.Sum(nil)</span><br><span class="line">&#125;</span><br><span class="line">func ExampleHash() error &#123;</span><br><span class="line">tag := &quot;hashing file for storage key&quot;</span><br><span class="line">contents, err := ioutil.ReadFile(&quot;testfile&quot;)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return error</span><br><span class="line">&#125;</span><br><span class="line">digest := Hash(tag, contents)</span><br><span class="line">fmt.Println(hex.EncodeToString(digest))</span><br><span class="line">&#125;</span><br><span class="line">//Output:</span><br><span class="line">//9f4c795d8ae5e207f19184ccebee6a606c1fdfe509c793614006d613580f03e1</span><br></pre></td></tr></table></figure><h2 id="Hash-密码"><a href="#Hash-密码" class="headerlink" title="Hash 密码"></a>Hash 密码</h2><p>一般东西的 Hash 用刚才的就行了，但是<font color="DeepPink"><strong>除了密码Hash</strong></font>。密码 Hash 和数据 Hash 的特征完全不同。</p><ul><li><font color="DeepPink"><strong>数据</strong></font> Hash 希望的是 Hash 算法<font color="DeepPink"><strong>越快越好</strong></font></li><li>而<font color="DeepPink"><strong>密码</strong></font> Hash 则希望 Hash 算法<font color="DeepPink"><strong>越慢越好</strong></font></li></ul><blockquote><p>过快的密码哈希会导致暴力破解的成本降低。因此密码哈希需要特殊算法。</p></blockquote><h3 id="使用-bcrypt"><a href="#使用-bcrypt" class="headerlink" title="使用 bcrypt"></a>使用 bcrypt</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;golang.org/x/crypto/bcrypt&quot;</span><br><span class="line">)</span><br><span class="line">func HashPassword(password []byte) ([]byte, error) &#123;</span><br><span class="line">return bcrypt.GenerateFromPassword(password, 14)</span><br><span class="line">&#125;</span><br><span class="line">func CheckPasswordHash(hash, password []byte) error &#123;</span><br><span class="line">return bcrypt.CompareHashAndPassword(hash, password)</span><br><span class="line">&#125;</span><br><span class="line">func Example() &#123;</span><br><span class="line">myPassword := []byte(&quot;password&quot;)</span><br><span class="line">hashed, err := HashPassword(myPassword)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(string(hashed))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>14 是计算量的复杂度，14 是个比较好的值，如果觉得性能无法接受，可以降到 12，但是不要再低了。</p><h2 id="签名"><a href="#签名" class="headerlink" title="签名"></a>签名</h2><p>首先是有一对密钥，一个是公钥、一个是私钥。任何拥有私钥的人可以对一段信息签名，而所有拥有公钥的人都可以来验证这个消息确实是由那个人签名的。</p><p>通过签名可以确保两件事情：</p><ul><li>消息未曾被篡改</li><li>是谁发出的这个消息</li></ul><p>和前面一样，Go 有很多签名算法可以选择：</p><ul><li>RSA<ul><li><del>PKCS1v15</del></li><li>PSS</li></ul></li><li>ECDSA<ul><li>✔️ P256</li><li><del>P385</del></li><li><del>P521</del></li></ul></li><li>Ed25519</li></ul><p>这次和前面不同，签名算法的安全更多的<font color="DeepPink"><strong>不是取决于算法选择，而是取决于你是怎么使用的</strong></font>。</p><p>比如这里比较推荐使用 ECDSA/P256，但是要注意，当初 PS3 被黑，被解出私钥就是用的这个算法，当时是由于那个算法实现是非常烂的。幸运的是 Go 没这个问题。所以相对于其他语言，Go 可以使用这个比较安全的签名算法。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>生成密钥</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;crypto/ecdsa&quot;</span><br><span class="line">&quot;crypto/elliptic&quot;</span><br><span class="line">&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func NewSigningKey() (*ecdsa.PrivateKey, error) &#123;</span><br><span class="line">return ecdsa.GenerateKey(elliptic.P256(), rand.Reader)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>签名数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">func Sign(data []byte, priv *ecdsa.PrivateKey) ([]byte, error) &#123;</span><br><span class="line">digest := sha256.Sum256(data)</span><br><span class="line">r, s, err := ecdsa.Sign(rand.Reader, priv, digest[:])</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">//encode the signature &#123;R, S&#125;</span><br><span class="line">params := priv.Curve.Params()</span><br><span class="line">curveByteSize := params.P.BitLen() / 8</span><br><span class="line">rBytes, sBytes := r.Bytes(), s.Bytes()</span><br><span class="line">signature := make([]byte, curveByteSize * 2)</span><br><span class="line">copy(signature[curveByteSize - len(rBytes):], rBytes)</span><br><span class="line">copy(signature[curveByteSize*2 - len(sBytes):], sBytes)</span><br><span class="line">return signature, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>验证签名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;crypto/ecdsa&quot;</span><br><span class="line">&quot;crypto/sha256&quot;</span><br><span class="line">&quot;math/big&quot;</span><br><span class="line">)</span><br><span class="line">//验证成功返回 true，否则 false</span><br><span class="line">func Verify(data, sig []byte, pub *ecdsa.PublicKey) bool &#123;</span><br><span class="line">digest := sha256.Sum256(data)</span><br><span class="line">curveByteSize := pub.Curve.Params().P.BitLen() / 8</span><br><span class="line">r, s := new(big.Int), new(big.Int)</span><br><span class="line">r.SetBytes(signature[:curveByteSize])</span><br><span class="line">s.SetBytes(signature[curveByteSize:])</span><br><span class="line">return ecdsa.Verify(pub, digest[:], r, s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Crypto </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gRPC 从学习到生产</title>
      <link href="/golang-grpc-from-tutorial-to-production.html"/>
      <url>/golang-grpc-from-tutorial-to-production.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>gRPC Practice<br>了解gRPC，更知REST</p></blockquote><a id="more"></a><h1 id="视频信息"><a href="#视频信息" class="headerlink" title="视频信息"></a>视频信息</h1><p>grpc: From Tutorial to Production<br>by Alan Shreve<br>at GopherCon 2017</p><p><a href="https://www.youtube.com/watch?v=7FZ6ZyzGex0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=7FZ6ZyzGex0</a></p><p>博文：<a href="https://about.sourcegraph.com/go/grpc-in-production-alan-shreve/" target="_blank" rel="noopener">https://about.sourcegraph.com/go/grpc-in-production-alan-shreve/</a></p><h1 id="微服务之间应该如何通讯？"><a href="#微服务之间应该如何通讯？" class="headerlink" title="微服务之间应该如何通讯？"></a>微服务之间应该如何通讯？</h1><p>答案就是：<font color="DeepPink"><strong>SOAP</strong></font>……好吧，开个玩笑，当然不可能是 SOAP 了。</p><p>现在流行的做法是 <font color="DeepPink"><strong>HTTP + JSON (REST API)</strong></font></p><p>Alan 说“如果这辈子再也不写另一个 REST 客户端库的话，那就可以很幸福的死去了……😂”，因为这是最无聊的事情，一遍一遍的在做同样的事情。</p><h1 id="为什么-REST-API-不好用？"><a href="#为什么-REST-API-不好用？" class="headerlink" title="为什么 REST API 不好用？"></a>为什么 REST API 不好用？</h1><ul><li>实现 Stream 太难了</li><li>而双向的流就根本不可能</li><li>很难对操作建立模型</li><li>效率很差，文本表示对于网络来说并不是最好的选择</li><li>而且，其实服务内部根本不是 RESTful 的方式，这只是 HTTP endpoint</li><li>很难在一个请求中取得多个资源数据 （反例看 GraphQL）</li><li>没有正式的（机器可读的）API约束<ul><li>因此写客户端需要人类<ul><li>而且因为👷很贵，而且不喜欢写客户端</li></ul></li></ul></li></ul><h1 id="什么是-gRPC"><a href="#什么是-gRPC" class="headerlink" title="什么是 gRPC"></a>什么是 gRPC</h1><blockquote><p>gPRC 是高性能、开源、通用的 RPC 框架。</p></blockquote><p>与其讲解定义，不如来实际做个东西更清楚。</p><h1 id="建一个缓存服务"><a href="#建一个缓存服务" class="headerlink" title="建一个缓存服务"></a>建一个缓存服务</h1><p>使用 gRPC 这类东西，我们并非开始于写 Go 代码，我们是从撰写 gRPC 的 <a href="https://developers.google.com/protocol-buffers/docs/overview" target="_blank" rel="noopener">IDL</a> 开始的。</p><h2 id="app-proto"><a href="#app-proto" class="headerlink" title="app.proto"></a>app.proto</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">syntax = &quot;proto3&quot;</span><br><span class="line">package rpc;</span><br><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message StoreReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br><span class="line">message StoreResp &#123;</span><br><span class="line">&#125;</span><br><span class="line">message GetReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">&#125;</span><br><span class="line">message GetResp &#123;</span><br><span class="line">  bytes val = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当写了这个文件后，我们立刻拥有了 <font color="DeepPink"><strong>9</strong></font> 种语言的客户端的库。</p><ul><li>C++</li><li>Java(and Android)</li><li>Python</li><li>Go</li><li>Ruby</li><li>C#</li><li>Javascript(node.js)</li><li>Objective-C (iOS!)</li><li>PHP</li></ul><p>同时，我们也拥有了 <font color="DeepPink"><strong>7</strong></font> 种语言的服务端的 API Stub：</p><ul><li>C++</li><li>Java</li><li>Python</li><li>Go</li><li>Ruby</li><li>C#</li><li>Javascript(node.js)</li></ul><h2 id="server-go"><a href="#server-go" class="headerlink" title="server.go"></a>server.go</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">func serverMain() &#123;</span><br><span class="line">  if err := runServer(); err != nil &#123;</span><br><span class="line">    fmt.Fprintf(os.Stderr, &quot;Failed to run cache server: %s\n&quot;, err)</span><br><span class="line">    os.Exit(1)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">func runServer() error &#123;</span><br><span class="line">  srv := grpc.NewServer()</span><br><span class="line">  rpc.RegisterCacheServer(srv, &amp;CacheService&#123;&#125;)</span><br><span class="line">  l, err := net.Listen(&quot;tcp&quot;, &quot;localhost:5051&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  //  block</span><br><span class="line">  return srv.Serve(l)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>暂时先不实现 CacheService，先放个空的，稍后再实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  return nil, fmt.Errorf(&quot;unimplemented&quot;)</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  return nil, fmt.Errorf(&quot;unimplemented&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="client-go"><a href="#client-go" class="headerlink" title="client.go"></a>client.go</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">func clientMain() &#123;</span><br><span class="line">  if err != runClient(); err != nil &#123;</span><br><span class="line">    fmt.Fprintf(os.Stderr, &quot;failed: %v\n&quot;, err)</span><br><span class="line">    os.Exit(1)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">func runClient() error &#123;</span><br><span class="line">  //  建立连接</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5053&quot;, grpc.WithInsecure())</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to dial server: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  cache := rpc.NewCacheClient(conn)</span><br><span class="line">  //  调用 grpc 的 store() 方法存储键值对 &#123; &quot;gopher&quot;: &quot;con&quot; &#125;</span><br><span class="line">  _, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  //  调用 grpc 的 get() 方法取回键为 `gopher` 的值</span><br><span class="line">  resp, err := cache.Get(context.Background(), &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to get: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  //  输出</span><br><span class="line">  fmt.Printf(&quot;Got cached value %s\n&quot;, resp.Val)</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="这不就是-WSDL-么？"><a href="#这不就是-WSDL-么？" class="headerlink" title="这不就是 WSDL 么？"></a>这不就是 WSDL 么？</h2><p>或许有些人会认为这和 <font color="DeepPink"><strong>WSDL</strong></font> 也太像了，这么想没有错，因为 gRPC 在借鉴之前的 SOAP/WSDL 的错误基础上，也吸取了他们优秀的地方。</p><ul><li>和 XML 关系没那么紧(grpc 是可插拔式的，可以换成各种底层表述)</li><li>写过 XML/XSD 的人都知道这些服务定义太繁重了，gRPC 没有这个问题</li><li>WSDL这类有完全不必要的复杂度、和基本不需要的功能（两步 commit）</li><li>WSDL 不灵活、而且无法前向兼容（不像 <a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener">protobuf</a>）</li><li>SOAP/WSDL 性能太差，以及无法使用流</li><li>但是WSDL中的机器可以理解的API定义确实是个好东西</li></ul><h2 id="实现具体的-CacheService"><a href="#实现具体的-CacheService" class="headerlink" title="实现具体的 CacheService"></a>实现具体的 CacheService</h2><p>server.go</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">  store map[string][]byte</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  val := s.store[req.Key]</span><br><span class="line">  return &amp;rpc.GetResp&#123;Val: val&#125;, nil</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  s.store[req.Key] = req.Val</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里没有锁，你可以想想他们中有，因为将来他们会被并发的调用的。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>当然，gRPC 支持错误处理。假设改写上面的 Get()，对不存在的键进行报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  val, ok := s.store[req.Key]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return nil, status.Errorf(code.NotFound, &quot;Key not found %s&quot;, req.Key)</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rpc.GetResp&#123;Val: val&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="加密传输"><a href="#加密传输" class="headerlink" title="加密传输"></a>加密传输</h2><p>如果这样的代码打算去部署的话，一定会被 <a href="https://en.wikipedia.org/wiki/Site_reliability_engineering" target="_blank" rel="noopener">SRE</a> 拦截下来，因为所有通讯必须加密传输。</p><p>在 gRPC 中添加 TLS 加密传输很容易。比如我们修改 runServer() 添加 TLS 加密传输。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  tlsCreds, err := credentials.NewServerTLSFromFile(&quot;tls.crt&quot;, &quot;tls.key&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，我们也需要修改一下 runClient()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  tlsCreds := credentials.NewTLS(&amp;tls.Config(InsecureSkipVerify: true))</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5051&quot;, grpc.WithTransportCredentials(tlsCreds))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="生产环境如何使用-gRPC"><a href="#生产环境如何使用-gRPC" class="headerlink" title="生产环境如何使用 gRPC"></a>生产环境如何使用 gRPC</h1><ul><li>HTTP/2</li><li>protobuf serialization (pluggable)</li><li>客户端会和 grpc 服务器打开一个长连接<ul><li>对于每一个 RPC 调用都将是一个新的 HTTP/2 stream</li><li>允许模拟飞行模式的 RPC 调用</li></ul></li><li>允许客户端 <font color="DeepPink"><strong>和</strong></font> 服务端 Streaming</li></ul><h2 id="gRPC-的实现"><a href="#gRPC-的实现" class="headerlink" title="gRPC 的实现"></a>gRPC 的实现</h2><p>现在有3个高性能的、事件驱动的实现</p><ul><li>C<ul><li>Ruby, Python, Node.js, PHP, C#, Objective-C, C++ 都是对这个 C core 实现的绑定</li><li>PHP 则是通过 PECL 和这个实现的绑定</li></ul></li><li>Java<ul><li>Netty + BoringSSL 通过 JNI</li></ul></li><li>Go<ul><li>纯 Go 实现，使用了 Go 标准库的 crypto/tls</li></ul></li></ul><h2 id="gRPC-从哪来的"><a href="#gRPC-从哪来的" class="headerlink" title="gRPC 从哪来的"></a>gRPC 从哪来的</h2><ul><li>最初是 Google 的一个团队创建的</li><li>更早期的是 Google 一个内部项目叫做 stubby</li><li>这个 gRPC 是其下一代开源项目，并且现在不仅仅是 Google 在使用，很多公司都在贡献代码<ul><li>当然，Google 还是主要代码贡献者</li></ul></li></ul><h2 id="生产环境案例：多租户"><a href="#生产环境案例：多租户" class="headerlink" title="生产环境案例：多租户"></a>生产环境案例：多租户</h2><p>上线生产后，发现有一部分客户产生了大量的键值，询问得知，有的客户希望对所有东西都缓存，这显然不是对我们这个缓存服务很好的事情。</p><p>我们希望限制这种行为，但对于当前系统而言，无法满足这种需求，因此我们需要修改实现，对每个客户发放客户 token，那么我们就可以约束特定客户最多可以建立多少键值，避免系统滥用。这就成为了多租户的缓存服务。</p><p>和之前一样，我们还是从 IDL 开始，我们需要修改接口，增加 account_token 项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">message StoreReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">  string account_token = 3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，我们需要有独立的服务针对账户服务，来获取账户所允许的缓存键数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">service Accounts &#123;</span><br><span class="line">  rpc GetByToken(GetByTokenReq) return (GetByTokenResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message GetByTokenReq &#123;</span><br><span class="line">  string token = 1;</span><br><span class="line">&#125;</span><br><span class="line">message GetByTokenResp &#123;</span><br><span class="line">  Account account = 1;</span><br><span class="line">&#125;</span><br><span class="line">message Account &#123;</span><br><span class="line">  int64 max_cache_keys = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里建立了一个新的 Accounts 服务，并且有一个 GetByToken() 方法，给入 token，返回一个 Account 类型的结果，而 Account 内有 max_cache_keys 键对应最大可缓存的键值数。</p><p>现在我们进一步修改 <font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  cache := rpc.NewCacheClient(conn)</span><br><span class="line">  _, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;</span><br><span class="line">    AccountToken: &quot;inconshreveable&quot;,</span><br><span class="line">    Key:          &quot;gopher&quot;,</span><br><span class="line">    Val:          []byte(&quot;con&quot;),</span><br><span class="line">  &#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务端的改变要稍微大一些，但不过分。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">  accounts      rpc.AccountsClient</span><br><span class="line">  store         map[string][]byte</span><br><span class="line">  keysByAccount map[string]int64</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里的 accounts 是一个 grpc 的客户端，因为我们这个服务，同时也是另一个 grpc 服务的客户端。所以在接下来的 Store() 实现中，我们需要先通过 accounts 调用另一个服务取得账户信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  //  调用另一个服务取得账户信息，包含其键值限制</span><br><span class="line">  resp, err := s.accounts.GetByToken(context.Background(), &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return nil, err</span><br><span class="line">  &#125;</span><br><span class="line">  //  检查是否超量使用</span><br><span class="line">  if s.keysByAccount[req.AccountToken] &gt;= resp.Account.MaxCacheKeys &#123;</span><br><span class="line">    return nil, status.Errorf(codes.FailedPrecondition, &quot;Account %s exceeds max key limit %d&quot;, req.AccountToken, resp.Account.MaxCacheKeys)</span><br><span class="line">  &#125;</span><br><span class="line">  //  如果键不存在，需要新加键值，那么我们就对计数器加一</span><br><span class="line">  if _, ok := s.store[req.Key]; !ok &#123;</span><br><span class="line">    s.keysByAccount[req.AccountToken] += 1</span><br><span class="line">  &#125;</span><br><span class="line">  //  保存键值</span><br><span class="line">  s.store[req.Key] = req.Val</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：性能"><a href="#生产环境案例：性能" class="headerlink" title="生产环境案例：性能"></a>生产环境案例：性能</h2><p>上面的问题解决了，我们服务又恢复了正常，不会有用户建立过多的键值了。但是很快，我们就又收到了其他用户发来的新的 issue，很多人反应说新系统变慢了，没有达到 <a href="https://en.wikipedia.org/wiki/Service-level_agreement" target="_blank" rel="noopener">SLA</a> 的要求。</p><p>可是我们根本不知道到底发生了什么，于是意识到了，我们的程序没有任何可观察性（Observability），换句话说，我们的程序没有任何计量系统来统计性能相关的数据。</p><p>我们先从最简单的做起，添加日志。</p><p>我们先从 <font color="DeepPink"><strong>client.go</strong></font> 开始，增加一些测量和计数以及日志输出。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">//  开始计时</span><br><span class="line">start := time.Now()</span><br><span class="line">_, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;</span><br><span class="line">  AccountToken: &quot;inconshreveable&quot;,</span><br><span class="line">  Key:          &quot;gopher&quot;,</span><br><span class="line">  Val:          []byte(&quot;con&quot;),</span><br><span class="line">&#125;)</span><br><span class="line">//  计算 cache.Store() 调用时间</span><br><span class="line">log.Printf(&quot;cache.Store duration %s&quot;, time.Since(start))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">  return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line">//  再次开始计时</span><br><span class="line">start = time.Now()</span><br><span class="line">//  调用 grpc 的 get() 方法取回键为 `gopher` 的值</span><br><span class="line">resp, err := cache.Get(context.Background(), &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">//  计算 cache.Get() 调用时间</span><br><span class="line">log.Printf(&quot;cache.Get duration %s&quot;, time.Since(start))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">  return fmt.Errorf(&quot;failed to get: %v&quot;, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，在服务端也这么处理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  //  开始计时</span><br><span class="line">  start := time.Now()</span><br><span class="line">  //  调用另一个服务取得账户信息，包含其键值限制</span><br><span class="line">  resp, err := s.accounts.GetByToken(context.Background(), &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  //  输出 account.GetByToken() 的调用时间</span><br><span class="line">  log.Printf(&quot;accounts.GetByToken duration %s&quot;, time.Since(start))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过这些修改后，我们发现一样的事情在反反复复的做，那么有什么办法可以改变这种无聊的做法么？查阅 grpc 文档后，看到有一个叫做 <font color="DeepPink"><strong>Client Interceptor</strong></font> 的东西。</p><p>这相当于是一个中间件，但是是在客户端。当客户端进行 rpc 调用的时候，这个中间件先会被调用，因此这个中间件可以对调用进行一层包装，然后再进行调用。</p><p>为了实现这个功能，我们创建一个新的文件，叫做 interceptor.go：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">func WithClientInterceptor() grpc.DialOption &#123;</span><br><span class="line">  return grpc.WithUnaryInterceptor(clientInterceptor)</span><br><span class="line">&#125;</span><br><span class="line">func clientInterceptor(</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  method string,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  reply interface&#123;&#125;,</span><br><span class="line">  cc *grpc.ClientConn,</span><br><span class="line">  invoker grpc.UnaryInvoker,</span><br><span class="line">  opts ...grpc.CallOption,</span><br><span class="line">) error &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  err := invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">  log.Printf(&quot;invoke remote method=%s duration=%s error=%v&quot;, method, time.Since(start), err)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们有了这个 WithClientInterceptor() 之后，可以在 grpc.Dial() 的时候注册进去。<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5051&quot;,</span><br><span class="line">    grpc.WithTransportCredentials(tlsCreds),</span><br><span class="line">    WithClientInterceptor())</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注册之后，所有的 grpc 调用都会经过我们注册的 clientInterceptor()，因此所有的时间就都有统计了，而不用每个函数内部反反复复的添加时间、计量、输出。</p><p>添加了客户端的这个计量后，自然而然就联想到服务端是不是也可以做同样的事情？经过查看文档，可以，有个叫做 <font color="DeepPink"><strong>Server Interceptor</strong></font> 的东西。</p><p>同样的做法，我们在服务端添加 interceptor.go，并且添加 ServerInterceptor() 函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">func ServerInterceptor() grpc.ServerOption &#123;</span><br><span class="line">  return grpc.UnaryInterceptor(serverInterceptor)</span><br><span class="line">&#125;</span><br><span class="line">func serverInterceptor(</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  info *grpc.UnaryServerInfo,</span><br><span class="line">  handler grpc.UnaryHandler,</span><br><span class="line">) (interface&#123;&#125;, error) &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  resp, err := handler(ctx, req)</span><br><span class="line">  log.Printf(&quot;invoke server method=%s duration=%s error=%v&quot;,</span><br><span class="line">    info.FullMethod,</span><br><span class="line">    time.Since(start),</span><br><span class="line">    err)</span><br><span class="line">  return resp, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和客户端一样，需要在 runServer() 的时候注册我们定义的这个中间件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds), ServerInterceptor())</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：超时"><a href="#生产环境案例：超时" class="headerlink" title="生产环境案例：超时"></a>生产环境案例：超时</h2><p>添加了日志后，我们终于在日志中发现，/rpc.Accounts/GetByToken/ 花了好长的时间。我们需要对这个操作设置超时。<br><font color="DeepPink"><strong>server.go</strong></font> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  accountsCtx, _ := context.WithTimeout(context.Background(), 2 * time.Second)</span><br><span class="line">  resp, err := s.accounts.GetByToken(accountsCtx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里操作很简单，直接使用标准库中 context.WithTimeout() 就可以了。</p><h2 id="生产环境案例：上下文传递"><a href="#生产环境案例：上下文传递" class="headerlink" title="生产环境案例：上下文传递"></a>生产环境案例：上下文传递</h2><p>经过上面修改后，客户依旧抱怨说没有满足 SLA，仔细一想也对。就算这里约束了 2 秒钟，客户端调用还需要时间，别的代码在中间也有时间开销。而且有的客户说，我们这里需要1秒钟，而不是2秒钟。</p><p>好吧，让我们把这个时间设定推向调用方。</p><p>首先我们要求在客户端进行调用时间约束的设定：<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ := context.WithTimeout(context.Background(), time.Second)</span><br><span class="line">  _, err = cache.Store(ctx, &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ = context.WithTimeout(context.Background(), 50*time.Millisecond)</span><br><span class="line">  resp, err := cache.Get(ctx, &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在服务端，我们将上下文传递。直接取调用方的 ctx。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  resp, err := s.accounts.GetByToken(ctx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：GRPC-Metadata"><a href="#生产环境案例：GRPC-Metadata" class="headerlink" title="生产环境案例：GRPC Metadata"></a>生产环境案例：GRPC Metadata</h2><p>上面的问题都解决了，终于可以松一口气了。可是客户又提新的需求了……😅，说我们能不能增加一个 Dry Run 的标志，就是说我希望你做所有需要做的事情，除了真的修改键值库。</p><p>GRPC metadata，也称为 GRPC 的 Header。就像 HTTP 头一样，可以有一些 Metadata 信息传递过来。使用 metadata，可以让我们的 Dry Run 的实现变得更简洁，不必每个 RPC 方法内都实现一遍检查 Dry Run 标志的逻辑，我们可以独立出来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  resp, err := s.accounts.GetByToken(ctx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  if !dryRun(ctx) &#123;</span><br><span class="line">    if _, ok := s.store[req.Key]; !ok &#123;</span><br><span class="line">      s.keysByAccount[req.AccountToke] += 1</span><br><span class="line">    &#125;</span><br><span class="line">    s.store[req.Key] = req.Val</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br><span class="line">func dryRun(ctx context.Context) bool &#123;</span><br><span class="line">  md, ok := metadata.FromContext(ctx)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  val, ok := md[&quot;dry-run&quot;]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  if len(val) &lt; 1 &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  return val[0] == &quot;1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，这么做是有妥协的，因为通用化后就失去了类型检查的能力。</p><p>在客户端调用的时候，则需要根据情况添加 dry-run 参数给 metadata。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ := context.WithTimeout(context.Background(), time.Second)</span><br><span class="line">  ctx = metadata.NewContext(ctx, metadata.Pairs(&quot;dry-run&quot;, &quot;1&quot;))</span><br><span class="line">  _, err = cache.Store(ctx, &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：Retry"><a href="#生产环境案例：Retry" class="headerlink" title="生产环境案例：Retry"></a>生产环境案例：Retry</h2><p>实现了 Dry Run 以为可以休息了，之前抱怨慢的客户又来抱怨了，虽然有超时控制，满足 SLA，但是服务那边还是慢，总超时不成功。检查了一下，发现是网络上的事情，我们没有太多可以做的事情。为了解决客户的问题，我们来添加一个重试的机制。</p><p>我们可以对每一个 gRPC 调用添加一个 Retry 机制，我们也可以像之前计时统计那样，使用 Interceptor 吧？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">func clientInterceptor(...) error &#123;</span><br><span class="line">  var (</span><br><span class="line">    start     = time.Now()</span><br><span class="line">    attempts  = 0</span><br><span class="line">    err       error</span><br><span class="line">    backoff   retryBackOff</span><br><span class="line">  )</span><br><span class="line">  for &#123;</span><br><span class="line">    attempts += 1</span><br><span class="line">    select &#123;</span><br><span class="line">    case &lt;-ctx.Done():</span><br><span class="line">      err = status.Errorf(codes.DeadlineExceeded, &quot;timeout reached before next retry attempt&quot;)</span><br><span class="line">    case &lt;-backoff.Next():</span><br><span class="line">      startAttempt := time.Now()</span><br><span class="line">      err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">      if err != nil &#123;</span><br><span class="line">        log.Printf(...)</span><br><span class="line">        continue</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    break</span><br><span class="line">  &#125;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来还不错，然后就打算发布这个代码了。结果提交审核的时候被打回来了，说这个代码不合理，因为如果是<font color="DeepPink"><strong>非幂等（non-idempotent）</strong></font> 的操作，这样就会导致多次执行，改变期望结果了。</p><p>看来我们得针对幂等和非幂等操作区别对待了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">silo.FireZeMissiles(NotIdempotent(ctx), req)</span><br></pre></td></tr></table></figure><p>嗯，当然，没这个东西。所以我们需要自己来创造一个标记，通过 context，来标明操作是否幂等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func NotIdempotent(ctx context.Context) context.Context &#123;</span><br><span class="line">  return context.WithValue(ctx, &quot;idempotent&quot;, false)</span><br><span class="line">&#125;</span><br><span class="line">func isIdempotent(ctx context.Context) bool &#123;</span><br><span class="line">  val, ok := ctx.Value(&quot;idempotent&quot;).(bool)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return true</span><br><span class="line">  &#125;</span><br><span class="line">  return val</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在我们的 clientInterceptor() 实现中加入 isIdempotent() 判断：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">func clientInterceptor(...) error &#123;</span><br><span class="line">  var (</span><br><span class="line">    start     = time.Now()</span><br><span class="line">    attempts  = 0</span><br><span class="line">    err       error</span><br><span class="line">    backoff   retryBackOff</span><br><span class="line">  )</span><br><span class="line">  for &#123;</span><br><span class="line">    attempts += 1</span><br><span class="line">    select &#123;</span><br><span class="line">    case &lt;-ctx.Done():</span><br><span class="line">      err = status.Errorf(codes.DeadlineExceeded, &quot;timeout reached before next retry attempt&quot;)</span><br><span class="line">    case &lt;-backoff.Next():</span><br><span class="line">      startAttempt := time.Now()</span><br><span class="line">      err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">      if err != nil &amp;&amp; isIdempotent(ctx) &#123;</span><br><span class="line">        log.Printf(...)</span><br><span class="line">        continue</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    break</span><br><span class="line">  &#125;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样当调用失败后，客户端检查发现是幂等的情况，才重试，否则不重试。避免了非幂等操作的反复操作。</p><h2 id="生产环境案例：结构化错误"><a href="#生产环境案例：结构化错误" class="headerlink" title="生产环境案例：结构化错误"></a>生产环境案例：结构化错误</h2><p>感觉没啥问题了，于是部署上线了。可是运行一段时间后，发现有些不对劲。所有成功的RPC调用，也就是说这个操作本身是正确的，都没有问题，超时重试也正常。但是所有失败的 RPC 调用都不对了，所有失败的 RPC 调用，都返回超时，而不是错误本身。这里说的失败，不是说网络问题导致超时啥的，而是说请求本身的失败，比如之前提到的，Get() 不存在的键，应该返回错误；或者 Store() 超过了配额，应该返回错误，这类错误在日志中都没看到，反而都对应了超时。</p><p>经过分析发现，服务端该报错都报错，没啥问题，但是客户端不对，本应该返回错误给调用方的地方，客户端代码反而又开始重试这个操作了。看来之前重试的代码还有问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">if err != nil &amp;&amp; isIdempotent(ctx) &#123;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  continue</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果仔细观察这部分代码，会发现，无论 err 是什么，只要非 nil，我们就重试。其实这是不对的，我们只有针对某些错误重试，比如网络问题之类的，而不应该对我们希望返回给调用方的错误重试，那没有意义。</p><p>那么问题就变成了，我们到底应该怎么对 err 判断来决定是否重试？</p><ul><li>可以使用不同的 Error Code，特定的 Code 需要 Retry，其它的不需要，那就需要自定义 gRPC 错误码；</li><li>我们也可以定义一个 Error 类型的数据，里面包含了某种标志位，来告知是否值得 retry</li><li>或者干脆把错误码放到 Response 的消息里，确保每个消息都有一个我们定义的错误码，来标明是否需要 retry。</li></ul><p>所以，我们需要的是一个完整的结构化的错误信息，而不是简单的一个 Error Code 和字符串。当然这条路不好走，但是我们已经做了这么多了，坚持一下还是可以克服的。</p><p>这里我们还是从 IDL 开始：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">message Error &#123;</span><br><span class="line">  int64 code = 1;</span><br><span class="line">  string messsage = 2;</span><br><span class="line">  bool temporary = 3;</span><br><span class="line">  int64 userErrorCode = 4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们实现这个 Error 类型。<br><font color="DeepPink"><strong>rpc/error.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func (e *Error) Error() string &#123;</span><br><span class="line">  return e.Message</span><br><span class="line">&#125;</span><br><span class="line">func Errorf(code codes.Code, temporary bool, msg string, args ..interface&#123;&#125;) error &#123;</span><br><span class="line">  return &amp;Error&#123;</span><br><span class="line">    Code:      int64(code),</span><br><span class="line">    Message:   fmt.Sprintf(msg, args...),</span><br><span class="line">    Temporary: temporary,</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有这两个函数，我们可以显示和构造这个 Error 类型的变量了，但是我们该怎么把错误消息传回客户端呢？然后问题就开始变的繁琐起来了：<br><font color="DeepPink"><strong>rpc/error.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">func MarshalError (err error, ctx context.Context) error &#123;</span><br><span class="line">  rerr, ok := err.(*Error)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  pberr, marshalerr := pb.Marshal(rerr)</span><br><span class="line">  if marshalerr == nil &#123;</span><br><span class="line">    md := metadata.Pairs(&quot;rpc-error&quot;, base64.StdEncoding.EncodeToString(pberr))</span><br><span class="line">    _ = grpc.SetTrailer(ctx, md)</span><br><span class="line">  &#125;</span><br><span class="line">  return status.Errorf(codes.Code(rerr.Code), rerr.Message)</span><br><span class="line">&#125;</span><br><span class="line">func UnmarshalError(err error, md metadata.MD) *Error &#123;</span><br><span class="line">  vals, ok := md[&quot;rpc-error&quot;]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  buf, err := base64.StdEncoding.DecodeString(vals[0])</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  var rerr Error</span><br><span class="line">  if err := pb.Unmarshal(buf, &amp;rerr); err != nil &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rerr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>interceptor.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">func serverInterceptor (</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  info *grpc.UnaryServerInfo,</span><br><span class="line">  handler grpc.UnaryHandler,</span><br><span class="line">) (interface&#123;&#125;, error) &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  resp, err := handler(ctx, req)</span><br><span class="line">  err = rpc.MarshalError(err, ctx)</span><br><span class="line">  log.Print(...)</span><br><span class="line">  return resp, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>it’s ugly，but works.</p><p>这是在 gRPC 不支持高级 Error 的情况下，怎么去 work around 这个问题，并且凑合用起来。现在这么做，错误就可以跨主机边界传递了。</p><h2 id="生产环境案例：Dump"><a href="#生产环境案例：Dump" class="headerlink" title="生产环境案例：Dump"></a>生产环境案例：Dump</h2><p>又有客户前来提需求了，有的客户说我们可以存、也可以取，但是如何才能把里面所有的数据都获取下来？于是有了需求，希望实现 Dump() 操作，可以取回所有数据。</p><p>现在已经轻车熟路了，我们先改 IDL，添加一个 Dump() 函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">  rpc Dump(DumpReq) returns (DumpResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message DumpReq&#123;</span><br><span class="line">&#125;</span><br><span class="line">message DumpResp &#123;</span><br><span class="line">  repeated DumpItem items = 1;</span><br><span class="line">&#125;</span><br><span class="line">message DumpItem &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 DumpResp 里面用的是 repeated，因为 protobuf 里面不知道为啥不叫 array。</p><h2 id="生产环境案例：流量控制"><a href="#生产环境案例：流量控制" class="headerlink" title="生产环境案例：流量控制"></a>生产环境案例：流量控制</h2><p>新功能 Dump 上线了，结果发现大家都很喜欢 Dump，有很多人在 Dump，结果服务器的内存开始不够了。于是我们需要一些限制手段，可以控制流量。</p><p>查阅了文档后，发现我们可以控制同时最大有多少并发可以访问，以及可以多频繁的来访问服务。<br><font color="DeepPink"><strong>server.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds),</span><br><span class="line">    ServerInterceptor(),</span><br><span class="line">    grpc.MaxConcurrentStreams(64),</span><br><span class="line">    grpc.InTapHandle(NewTap().Handler))</span><br><span class="line">  rpc.RegisterCacheServer(srv, NewCacheService(accounts))</span><br><span class="line">  l, err := net.Listen(&quot;tcp&quot;, &quot;localhost:5051&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  l = netutil.LimitListener(l, 1024)</span><br><span class="line">  return srv.Serve(l)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了 netutil.LimitListener(l, 1024) 控制了总共可以有多少个连接，然后用 grpc.MaxConcurrentStreams(64) 指定了每个 grpc 的连接可以有多少个并发流(stream)。这两个结合起来基本控制了并发的总数。</p><p>但是 gRPC 里没有地方限定可以多频繁的访问。因此这里用了 grpc.InTapHandle(NewTap().Handler)) 来进行定制，这是在更靠前的位置执行的。</p><p><font color="DeepPink"><strong>tap.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">type Tap struct &#123;</span><br><span class="line">  lim *rate.Limiter</span><br><span class="line">&#125;</span><br><span class="line">func NewTap() *Tap &#123;</span><br><span class="line">  return &amp;Tap(rate.NewLimiter(150, 5))</span><br><span class="line">&#125;</span><br><span class="line">func (t *Tap) Handler(ctx context.Context, info *tap.Info) (context.Context, error) &#123;</span><br><span class="line">  if !t.lim.Allow() &#123;</span><br><span class="line">    return nil, status.Errorf(codes.ResourceExhausted, &quot;service is over rate limit&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  return ctx, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：Streaming"><a href="#生产环境案例：Streaming" class="headerlink" title="生产环境案例：Streaming"></a>生产环境案例：Streaming</h2><p>之前的方案部署后，内存终于降下来了，但是还没休息，就发现大家越来越喜欢用这个缓存服务，内存又不够用了。这个时候我们就开始思考，是不是可以调整一下设计，不是每次 Dump 就立即在内存生成完整的返回数组，而是以流的形式，按需发回。<br><font color="DeepPink"><strong>app.proto</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">syntax = &quot;proto3&quot;;</span><br><span class="line">package rpc;</span><br><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">  rpc Dump(DumpReq) returns (stream DumpItem) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message DumpReq&#123;</span><br><span class="line">&#125;</span><br><span class="line">message DumpItem &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里不再使用数组性质的 repeated，而是用 stream，客户端请求 Dump() 后，将结果以流的形式发回去。<br><font color="DeepPink"><strong>server.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func (s *CacheService) Dump(req *rpc.DumpReq, stream rpc.Cache_DumpServer) error &#123;</span><br><span class="line">  for k, v := range s.store &#123;</span><br><span class="line">    stream.Send(&amp;rpc.DumpItem&#123;</span><br><span class="line">      Key: k,</span><br><span class="line">      Val: v,</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们修改 Dump() 的实现，对于每个记录，利用 stream.Send() 发送到流。</p><p>注意这里我们没有 context，只有个 stream。<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  stream, err := cache.Dump(context.Background(), &amp;rpc.DumpReq&#123;&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to dump: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  for &#123;</span><br><span class="line">    item, err := stream.Recv()</span><br><span class="line">    if err == io.EOF &#123;</span><br><span class="line">      break</span><br><span class="line">    &#125;</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">      return fmt.Errorf(&quot;failed to stream item: %v&quot;, err)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：横向扩展、负载均衡"><a href="#生产环境案例：横向扩展、负载均衡" class="headerlink" title="生产环境案例：横向扩展、负载均衡"></a>生产环境案例：横向扩展、负载均衡</h2><p>使用流后，服务器性能提高了很多，但是，我们的服务太吸引人了，用户越来越多，结果又内存不够了。这时候我们审查代码，感觉能做的事情都做了，或许是时候从单一服务器，扩展为多个服务器，然后之间使用负载均衡。</p><p>gRPC 是长连接性质的通讯，因此如果一个客户端连接了一个 gRPC Endpoint，那么他就会一直连接到一个固定的服务器，因此多服务器的负载均衡对同一个客户端来说是没有意义的，不会因为这个客户端有大量的请求而导致分散请求到不同的服务器上去。</p><p>如果我们希望客户端可以利用多服务器的机制，我们就需要更智能的客户端，让客户端意识到服务器存在多个副本，因此客户端建立多条连接到不同的服务器，这样就可以让单一客户端利用负载均衡的横向扩展能力。</p><h2 id="生产环境案例：多语言协作"><a href="#生产环境案例：多语言协作" class="headerlink" title="生产环境案例：多语言协作"></a>生产环境案例：多语言协作</h2><p>在复杂的环境中，我们 gRPC 的客户端（甚至服务端）可能是不同语言平台的。这其实是 gRPC 的优势，可以比较容易的实现跨语言平台的通讯。</p><p>比如我们可以做一个 Python 客户端：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import grpc</span><br><span class="line">import rpc_pb2 as rpc</span><br><span class="line">channel = grpc.insecure_channel(&apos;localhost:5051&apos;)</span><br><span class="line">cache_svc = rpc.CacheStub(channel)</span><br><span class="line">resp = cache_svc.Get(rpc.GetReq(</span><br><span class="line">  key=&quot;gopher&quot;,</span><br><span class="line">))</span><br><span class="line">print resp.val</span><br></pre></td></tr></table></figure><p>一个不是很爽的地方是虽然 gRPC 的跨语言通讯很方便，但是各个语言的实现都比较随意，比如 Go 中叫做 CacheClient()，而 Python 中则叫做 CacheStub()。这里没有什么特别的原因非不一样的名字，就是由于不同的作者实现的时候按照自己的想法命名的。</p><h1 id="gRPC-尚不完美的地方"><a href="#gRPC-尚不完美的地方" class="headerlink" title="gRPC 尚不完美的地方"></a>gRPC 尚不完美的地方</h1><ul><li>负载均衡</li><li>结构化的错误信息</li><li>还不支持浏览器的 JS （某种角度上讲，这是最常用的客户端）</li><li>还经常发生 API 改变（即使都1.0了）</li><li>某些语言实现的文档非常差</li><li>没有跨语言的标准化的做法</li></ul><h1 id="gRPC-在生产环境中的用例"><a href="#gRPC-在生产环境中的用例" class="headerlink" title="gRPC 在生产环境中的用例"></a>gRPC 在生产环境中的用例</h1><ul><li>ngrok，所有内部20多个通讯都走的是 gRPC</li><li>Square，将内部的通讯都换成了 gRPC，是最早使用 gRPC 的用户和贡献者</li><li>CoreOS，etcd v3 完全走的是 gRPC</li><li>Google，Google Cloud Service（PubSub, Speech Rec）走的是 gRPC</li><li>Netflix, Yik Yak, VSCO, Cockroach, …</li></ul><h1 id="gRPC-未来的变化"><a href="#gRPC-未来的变化" class="headerlink" title="gRPC 未来的变化"></a>gRPC 未来的变化</h1><ul><li>想了解未来的变化可以查看：<ul><li><a href="https://github.com/grpc/proposal" target="_blank" rel="noopener">grpc/proposal</a></li><li><a href="https://groups.google.com/forum/#!forum/grpc-io" target="_blank" rel="noopener">grpc-io 邮件列表</a></li></ul></li><li>新的语言支持（<a href="https://github.com/grpc/grpc-swift" target="_blank" rel="noopener">Swift</a> 和 <a href="https://github.com/grpc/grpc-haskell" target="_blank" rel="noopener">Haskell</a>正在试验阶段）</li><li>稳定性、可靠性、性能的提高</li><li>增加更多细化的 API 来支持自定义的行为（连接管理、频道跟踪）</li><li>浏览器的 JS</li></ul><blockquote><p>本文转载自：<br><a href="https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> gRPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>给 Go 库作者的建议</title>
      <link href="/golang-practice-advice-for-go-library-authors.html"/>
      <url>/golang-practice-advice-for-go-library-authors.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golang Practice Advice</p></blockquote><a id="more"></a><h1 id="视频信息"><a href="#视频信息" class="headerlink" title="视频信息"></a>视频信息</h1><p>Practical Advice for Go Library Authors<br>by Jack Lindamood<br>at GopherCon 2016</p><p><a href="https://www.youtube.com/watch?v=5v2fqm_8jYI" target="_blank" rel="noopener">https://www.youtube.com/watch?v=5v2fqm_8jYI</a></p><p>幻灯地址：<br><a href="http://go-talks.appspot.com/github.com/cep21/go-talks/practical-advice-for-go-library-authors.slide#1" target="_blank" rel="noopener">http://go-talks.appspot.com/github.com/cep21/go-talks/practical-advice-for-go-library-authors.slide#1</a></p><h1 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h1><p>包名是将来使用过程中的一部分，所以避免重复包名和结构与函数。比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var h client.Client → var h http.Client</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.NewContext() =&gt; context.Background()</span><br></pre></td></tr></table></figure><h1 id="Object-Creation"><a href="#Object-Creation" class="headerlink" title="Object Creation"></a>Object Creation</h1><p>golang 没有构造函数，因此创建对象一般有两种办法:</p><ul><li>默认的0值</li><li>单独的构造函数，NewSomething()</li></ul><p>推荐使用默认 0 值的构造方法</p><p>在默认0值的情况下，各个方法要处理好0值，比如有些东西发现是0值后，给入一个默认值。</p><p>New() 构造函数很灵活，可以做任何事情，因此对于代码阅读上不利，意味着隐藏了很多东西。</p><p>有些库使用私有 struct，公开接口的方法，authImpl struct and Auth interface，这是反模式，不推荐使用。</p><p>不推荐使用 <font color="DeepPink"><strong>Singleton</strong></font>，虽然标准库中大量使用了 <font color="DeepPink"><strong>Singleton</strong></font> 模式，但是 Jack 个人不喜欢这种模式。</p><p>使用高阶函数作为选项这种形式不推荐：NewSomething(WithThingA(), WithThingB())</p><h1 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h1><p>一些日志是直接打印到标准输出去，这是非常不好的设计，因为用户如果想关根本关不了。</p><p>建议</p><ul><li>确定一下作为<font color="DeepPink"><strong>库</strong></font>是不是真的需要打印日志，是不是应该把输出日志的工作交给调用方决定？</li><li>如果一定需要日志，那么使用回调函数方式</li><li>输出日志到一个 interface</li><li>不要假定传进来的就是标准库的 log ，有很多选择。</li><li>尊重 stdout 和 stderr</li><li>不要使用 singleton</li></ul><h1 id="interface-vs-struct"><a href="#interface-vs-struct" class="headerlink" title="interface vs struct"></a>interface vs struct</h1><p>接受 interface ，但返回的是 struct</p><p>这点和 Java 不同，Java 更倾向于所有东西都是通过 interface 操作。而 golang 不需要，golang 使用的是隐性interface。</p><h1 id="什么时候-panic"><a href="#什么时候-panic" class="headerlink" title="什么时候 panic"></a>什么时候 panic</h1><p>最好都不 panic。如果非要 panic，可能最合适的地方是 init 的时候，因为刚一运行就能看到挂了，比较容易处理。但即使如此，也尽量不要 panic。</p><h1 id="检查-error"><a href="#检查-error" class="headerlink" title="检查 error"></a>检查 error</h1><p>问：我们是需要检查所有的 error 么？比如有些似乎不大容易出错。<br>答：需要，<font color="DeepPink"><strong>特别是你说的这些不大容易出错的</strong></font>！！</p><p>我们用 error 代替了 exception，所以不要忽略这个东西。</p><p>处理的办法</p><ul><li>最好的办法是 Bubble up，也就是传回调用方</li><li>但有的时候（比如 <font color="DeepPink"><strong>goroutine</strong></font>) 不适合，那就：<ul><li>做日志</li><li>或者增加某个计数器</li></ul></li></ul><p>什么时候应该返回错误比较合适？</p><ul><li>当不满足约定</li><li>当需要的答案无法得到</li></ul><h1 id="允许启用库的调试能力"><a href="#允许启用库的调试能力" class="headerlink" title="允许启用库的调试能力"></a>允许启用库的调试能力</h1><h1 id="为测试而设计"><a href="#为测试而设计" class="headerlink" title="为测试而设计"></a>为测试而设计</h1><ul><li>为了方便自己测试</li><li>为了方便库用户测试</li></ul><h1 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h1><h2 id="channels"><a href="#channels" class="headerlink" title="channels"></a>channels</h2><p>虽然 <font color="DeepPink"><strong>channel</strong></font> 是 golang 一个处理并发很好地东西，但是并非所有场合都需要。比如标准库中就很少有在 API 中使用 channel 的。</p><ul><li>将使用 channel 的位置向上层移动。</li><li>可以使用回调函数。</li><li>不要混合使用 mutex 和 channel</li></ul><h2 id="什么时候发起-goroutine"><a href="#什么时候发起-goroutine" class="headerlink" title="什么时候发起 goroutine"></a>什么时候发起 goroutine</h2><ul><li>有一些库的 New() 会发起他们的 goroutine，这是不好的。</li><li>标准库使用的是 Serve() 函数。以及对应的 Close() 函数</li><li>将 goroutine 向上层推</li></ul><h1 id="什么时候使用-context-Context"><a href="#什么时候使用-context-Context" class="headerlink" title="什么时候使用 context.Context"></a>什么时候使用 context.Context</h1><ul><li>所有的阻塞、长时间的操作，都应该可以被 cancel</li><li>由于 context.Context 很容易存储东西，所以很容易被滥用。要尽力去避免使用 Context</li><li>Singleton 和 context.Value() 是同样性质的东西，像全局变量一样，对于程序状态来说是个黑箱。</li></ul><h1 id="其它注意事项"><a href="#其它注意事项" class="headerlink" title="其它注意事项"></a>其它注意事项</h1><ul><li>如果什么东西很难做，嗯，那就让别人去做吧</li><li>为了效率而升级<ul><li>但是，正确性要比效率重要，在正确性的前提下，注意效率</li></ul></li><li>不要在库中使用 /vendor （在 main 包中可以）</li><li>注意 build tag</li><li>保持干净<ul><li>尽量使用所有的静态分析工具来检查代码。</li></ul></li></ul><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p><a href="https://blog.lab99.org/post/golang-2017-09-21-video-practice-advice-for-go-library-authors.html" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-09-21-video-practice-advice-for-go-library-authors.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Practice </tag>
            
            <tag> Advice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 如何正确使用 Context</title>
      <link href="/how-to-correctly-use-package-context.html"/>
      <url>/how-to-correctly-use-package-context.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golang Context</p></blockquote><a id="more"></a><h1 id="视频信息"><a href="#视频信息" class="headerlink" title="视频信息"></a>视频信息</h1><p>How to correctly use package context<br>by Jack Lindamood<br>at Golang UK Conf. 2017</p><p>视频：<a href="https://www.youtube.com/watch?v=-_B5uQ4UGi0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=-_B5uQ4UGi0</a><br>博文：<a href="https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39" target="_blank" rel="noopener">https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39</a></p><h1 id="为什么需要-Context"><a href="#为什么需要-Context" class="headerlink" title="为什么需要 Context"></a>为什么需要 Context</h1><ul><li>每一个<font color="DeepPink"><strong>长请求</strong></font>都应该有个<font color="DeepPink"><strong>超时限制</strong></font></li><li>需要在调用中传递这个超时<ul><li>比如开始处理请求的时候我们说是 3 秒钟超时</li><li>那么在函数调用中间，这个超时还剩多少时间了？</li><li>需要在什么地方存储这个信息，这样请求处理中间可以停止</li></ul></li></ul><p>如果进一步考虑。<br><img src="/images/how-to-correctly-use-package-context/rpc-fails-1.svg" alt><br>如上图这样的 RPC 调用，开始调用 RPC 1 后，里面分别调用了 RPC 2, RPC 3, RPC 4，等所有 RPC 用成功后，返回结果。</p><p>这是正常的方式，但是如果 RPC 2 调用失败了会发生什么？<br><img src="/images/how-to-correctly-use-package-context/rpc-fails-2.svg" alt></p><p>RPC 2 失败后，如果没有 Context 的存在，那么我们可能依旧会等所有的 RPC 执行完毕，但是由于 RPC 2 败了，所以其实其它的 RPC 结果意义不大了，我们依旧需要给用户返回错误。因此我们白白的浪费了 10ms，完全没必要去等待其它 RPC 执行完毕。</p><p>那如果我们在 RPC 2 失败后，就直接给用户返回失败呢？<br><img src="/images/how-to-correctly-use-package-context/rpc-fails-3.svg" alt><br>用户是在 30ms 的位置收到了错误消息，可是 RPC 3 和 RPC 4 依然在没意义的运行，还在浪费计算和IO资源。<br><img src="/images/how-to-correctly-use-package-context/rpc-fails-4.svg" alt></p><p>所以理想状态应该是如上图，当 RPC 2 出错后，除了返回用户错误信息外，我们也应该有某种方式可以通知 RPC 3 和 RPC 4，让他们也停止运行，不再浪费资源。</p><p>所以解决方案就是：</p><ul><li>用信号的方式来通知请求该停了</li><li>包含一些关于什么时间请求可能会结束的提示（超时）</li><li>用 channel 来通知请求结束了</li></ul><p>那干脆让我们把变量也扔那吧。😈</p><ul><li>在 Go 中没有线程/go routine 变量<ul><li>其实挺合理的，因为这样就会让 goroutine 互相产生依赖</li></ul></li><li><font color="DeepPink"><strong>非常容易被滥用</strong></font></li></ul><h1 id="Context-实现细节"><a href="#Context-实现细节" class="headerlink" title="Context 实现细节"></a>Context 实现细节</h1><p>context.Context：</p><ul><li>是不可变的(immutable)树节点</li><li>Cancel 一个节点，会连带 Cancel 其所有子节点 （<font color="DeepPink"><strong>从上到下</strong></font>）</li><li>Context values 是一个节点</li><li>Value 查找是回溯树的方式 （<font color="DeepPink"><strong>从下到上</strong></font>）</li></ul><h2 id="示例-Context-链"><a href="#示例-Context-链" class="headerlink" title="示例 Context 链"></a>示例 Context 链</h2><p>完整代码：<a href="https://play.golang.org/p/ddpofBV1QS" target="_blank" rel="noopener">https://play.golang.org/p/ddpofBV1QS</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">func tree() &#123;</span><br><span class="line">  ctx1 := context.Background()</span><br><span class="line">  ctx2, _ := context.WithCancel(ctx1)</span><br><span class="line">  ctx3, _ := context.WithTimeout(ctx2, time.Second * 5)</span><br><span class="line">  ctx4, _ := context.WithTimeout(ctx3, time.Second * 3)</span><br><span class="line">  ctx5, _ := context.WithTimeout(ctx3, time.Second * 6)</span><br><span class="line">  ctx6 := context.WithValue(ctx5, &quot;userID&quot;, 12)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果这样构成的 Context 链，其形如下图：<br><img src="/images/how-to-correctly-use-package-context/context-chain-1.svg" alt><br>那么当 3 秒超时到了时候：<br><img src="/images/how-to-correctly-use-package-context/context-chain-2.svg" alt><br>可以看到 ctx4 超时退出了。</p><p>当 5秒钟 超时到达时：<br><img src="/images/how-to-correctly-use-package-context/context-chain-3.svg" alt><br>可以看到，不仅仅 ctx3 退出了，其所有子节点，比如 ctx5 和 ctx6 也都退出了。</p><h2 id="context-Context-API"><a href="#context-Context-API" class="headerlink" title="context.Context API"></a>context.Context API</h2><p>基本上是两类操作：</p><ul><li>3个函数用于<font color="DeepPink"><strong>限定什么时候你的子节点退出</strong></font>；</li><li>1个函数用于<font color="DeepPink"><strong>设置请求范畴的变量</strong></font><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">type Context interface &#123;</span><br><span class="line">  //  啥时候退出</span><br><span class="line">  Deadline() (deadline time.Time, ok bool)</span><br><span class="line">  Done() &lt;-chan struct&#123;&#125;</span><br><span class="line">  Err() error</span><br><span class="line">  //  设置变量</span><br><span class="line">  Value(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="什么时候应该使用-Context？"><a href="#什么时候应该使用-Context？" class="headerlink" title="什么时候应该使用 Context？"></a>什么时候应该使用 Context？</h2><ul><li>每一个 RPC 调用都应该有<font color="DeepPink"><strong>超时退出</strong></font>的能力，这是比较合理的 API 设计</li><li><font color="DeepPink"><strong>不仅仅</strong></font> 是超时，你还需要有能力去结束那些不再需要操作的行为</li><li>context.Context 是 Go 标准的解决方案</li><li>任何函数可能被阻塞，或者需要很长时间来完成的，都应该有个 context.Context</li></ul><h2 id="如何创建-Context？"><a href="#如何创建-Context？" class="headerlink" title="如何创建 Context？"></a>如何创建 Context？</h2><ul><li>在 RPC 开始的时候，使用 context.Background()<ul><li>有些人把在 main() 里记录一个 context.Background()，然后把这个放到服务器的某个变量里，然后请求来了后从这个变量里继承 context。这么做是<font color="DeepPink"><strong>不对的</strong></font>。直接每个请求，源自自己的 context.Background() 即可。</li></ul></li><li>如果你没有 context，却需要调用一个 context 的函数的话，用 context.TODO()</li><li>如果某步操作需要自己的超时设置的话，给它一个独立的 sub-context（如前面的例子）</li></ul><h2 id="如何集成到-API-里？"><a href="#如何集成到-API-里？" class="headerlink" title="如何集成到 API 里？"></a>如何集成到 API 里？</h2><ul><li>如果有 Context，<font color="DeepPink"><strong>将其作为第一个变量</strong></font>。<ul><li>如 func (d* Dialer) DialContext(ctx context.Context, network, address string) (Conn, error)</li><li>有些人把 context 放到中间的某个变量里去，这很不合习惯，不要那么做，放到第一个去。</li></ul></li><li>将其作为<font color="DeepPink"><strong>可选的</strong></font>方式，用 request 结构体方式。<ul><li>如：func (r *Request) WithContext(ctx context.Context) *Request</li></ul></li><li>Context 的变量名请用 ctx（不要起一些诡异的名字😓）</li></ul><h2 id="Context-放哪？"><a href="#Context-放哪？" class="headerlink" title="Context 放哪？"></a>Context 放哪？</h2><ul><li>把 Context 想象为一条河流流过你的程序（另一个意思就是说不要喝河里的水……🙊）</li><li>理想情况下，Context 存在于调用栈（Call Stack） 中</li><li>不要把 Context 存储到一个 struct 里<ul><li>除非你使用的是像 http.Request 中的 request 结构体的方式</li></ul></li><li>request 结构体应该以 Request 结束为生命终止</li><li>当 RPC 请求处理结束后，应该去掉对 Context 变量的引用（Unreference）</li><li>Request 结束，Context 就应该结束。（这俩是一对儿，不求同年同月同日生，但求同年同月同日死……💕）</li></ul><h2 id="Context-包的注意事项"><a href="#Context-包的注意事项" class="headerlink" title="Context 包的注意事项"></a>Context 包的注意事项</h2><ul><li><p>要养成关闭 Context 的习惯</p><ul><li><font color="DeepPink"><strong>特别是</strong></font> 超时的 Contexts</li></ul></li><li><p>如果一个 context 被 GC 而不是 cancel 了，那一般是你做错了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ctx, cancel := context.WithTimeout(parentCtx, time.Second * 2)</span><br><span class="line">defer cancel()</span><br></pre></td></tr></table></figure></li><li><p>使用 Timeout 会导致内部使用 time.AfterFunc，从而会导致 context 在计时器到时之前都不会被垃圾回收。</p></li><li><p>在建立之后，立即 defer cancel() 是一个好习惯。</p></li></ul><h2 id="终止请求-Request-Cancellation"><a href="#终止请求-Request-Cancellation" class="headerlink" title="终止请求 (Request Cancellation)"></a>终止请求 (Request Cancellation)</h2><p>当你不再关心接下来获取的结果的时候，有可能会 Cancel 一个 Context？</p><p>以 golang.org/x/sync/errgroup 为例，errgroup 使用 Context 来提供 RPC 的终止行为。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">type Group struct &#123;</span><br><span class="line">cancel  func()</span><br><span class="line">wg      sync.WaitGroup</span><br><span class="line">errOnce sync.Once</span><br><span class="line">err     error</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个 group 和 context：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">func WithContext(ctx context.Context) (*Group, context.Context) &#123;</span><br><span class="line">  ctx, cancel := context.WithCancel(ctx)</span><br><span class="line">  return &amp;Group&#123;cancel: cancel&#125;, ctx</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就返回了一个可以被提前 cancel 的 group。</p><p>而调用的时候，并不是直接调用 go func()，而是调用 Go()，将函数作为参数传进去，用高阶函数的形式来调用，其内部才是 go func() 开启 goroutine。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func (g *Group) Go(f func() error) &#123;</span><br><span class="line">  g.wg.Add(1)</span><br><span class="line">  go func() &#123;</span><br><span class="line">    defer g.wg.Done()</span><br><span class="line">    if err := f(); err != nil &#123;</span><br><span class="line">      g.errOnce.Do(func() &#123;</span><br><span class="line">        g.err = err</span><br><span class="line">        if g.cancel != nil &#123;</span><br><span class="line">          g.cancel()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当给入函数 f 返回错误，则使用 sync.Once 来 cancel context，而错误被保存于 g.err 之中，在随后的 Wait() 函数中返回。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func (g *Group) Wait() error &#123;</span><br><span class="line">  g.wg.Wait()</span><br><span class="line">  if g.cancel != nil &#123;</span><br><span class="line">    g.cancel()</span><br><span class="line">  &#125;</span><br><span class="line">  return g.err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里在 Wait() 结束后，调用了一次 cancel()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">func DoTwoRequestsAtOnce(ctx context.Context) error &#123;</span><br><span class="line">  eg, egCtx := errgroup.WithContext(ctx)</span><br><span class="line">  var resp1, resp2 *http.Response</span><br><span class="line">  f := func(loc string, respIn **http.Response) func() error &#123;</span><br><span class="line">    return func() error &#123;</span><br><span class="line">      reqCtx, cancel := context.WithTimeout(egCtx, time.Second)</span><br><span class="line">      defer cancel()</span><br><span class="line">      req, _ := http.NewRequest(&quot;GET&quot;, loc, nil)</span><br><span class="line">      var err error</span><br><span class="line">      *respIn, err = http.DefaultClient.Do(req.WithContext(reqCtx))</span><br><span class="line">      if err == nil &amp;&amp; (*respIn).StatusCode &gt;= 500 &#123;</span><br><span class="line">        return errors.New(&quot;unexpected!&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">      return err</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  eg.Go(f(&quot;http://localhost:8080/fast_request&quot;, &amp;resp1))</span><br><span class="line">  eg.Go(f(&quot;http://localhost:8080/slow_request&quot;, &amp;resp2))</span><br><span class="line">  return eg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，同时发起了两个 RPC 调用，当任何一个调用超时或者出错后，会终止另一个 RPC 调用。这里就是利用前面讲到的 errgroup 来实现的，应对有很多并非请求，并需要集中处理超时、出错终止其它并发任务的时候，这个 pattern 使用起来很方便。</p><h2 id="Context-Value-Request-范畴的值"><a href="#Context-Value-Request-范畴的值" class="headerlink" title="Context.Value - Request 范畴的值"></a>Context.Value - Request 范畴的值</h2><h3 id="context-Value-API-的万金油（duct-tape"><a href="#context-Value-API-的万金油（duct-tape" class="headerlink" title="context.Value API 的万金油（duct tape)"></a>context.Value API 的万金油（duct tape)</h3><p>胶带（duct tape) 几乎可以修任何东西，从破箱子，到人的伤口，到汽车引擎，甚至到NASA登月任务中的阿波罗13号飞船（Yeah! True Story)。所以在西方文化里，胶带是个“万能”的东西。在中文里，恐怕万金油是更合适的对应词汇，从头疼、脑热，感冒发烧，到跌打损伤几乎无所不治。</p><p>当然，<font color="DeepPink"><strong>治标不治本</strong></font>，这点东西方文化中的潜台词都是一样的。这里提及的 context.Value 对于 API 而言，就是这类性质的东西，啥都可以干，但是治标不治本。</p><ul><li>value 节点是 Context 链中的一个节点<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">package context</span><br><span class="line">type valueCtx struct &#123;</span><br><span class="line">  Context</span><br><span class="line">  key, val interface&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123;</span><br><span class="line">  //  ...</span><br><span class="line">  return &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class="line">&#125;</span><br><span class="line">func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;</span><br><span class="line">  if c.key == key &#123;</span><br><span class="line">    return c.val</span><br><span class="line">  &#125;</span><br><span class="line">  return c.Context.Value(key)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>可以看到，WithValue() 实际上就是在 Context 树形结构中，增加一个节点罢了。</p><p>Context 是 immutable 的。</p><h3 id="约束-key-的空间"><a href="#约束-key-的空间" class="headerlink" title="约束 key 的空间"></a>约束 key 的空间</h3><p>为了防止树形结构中出现重复的键，建议约束键的空间。比如使用私有类型，然后用 GetXxx() 和 WithXxxx() 来操作私有实体。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type privateCtxType string</span><br><span class="line">var (</span><br><span class="line">  reqID = privateCtxType(&quot;req-id&quot;)</span><br><span class="line">)</span><br><span class="line">func GetRequestID(ctx context.Context) (int, bool) &#123;</span><br><span class="line">  id, exists := ctx.Value(reqID).(int)</span><br><span class="line">  return id, exists</span><br><span class="line">&#125;</span><br><span class="line">func WithRequestID(ctx context.Context, reqid int) context.Context &#123;</span><br><span class="line">  return context.WithValue(ctx, reqID, reqid)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用 WithXxx 而不是 SetXxx 也是因为 Context 实际上是 immutable 的，所以不是修改 Context 里某个值，而是产生新的 Context <font color="DeepPink"><strong>带某个值</strong></font>。</p><h3 id="Context-Value-是-immutable-的"><a href="#Context-Value-是-immutable-的" class="headerlink" title="Context.Value 是 immutable 的"></a>Context.Value 是 immutable 的</h3><p>再多次的强调 Context.Value 是 <font color="DeepPink"><strong>immutable</strong></font> 的也不过分。</p><ul><li>context.Context 从设计上就是按照 immutable （不可变的）模式设计的</li><li>同样，Context.Value 也是 immutable 的</li><li>不要试图在 Context.Value 里存某个可变更的值，然后改变，期望别的 Context 可以看到这个改变<ul><li>更别指望着在 Context.Value 里存可变的值，最后多个 goroutine 并发访问没竞争冒险啥的，因为自始至终，就是按照不可变来设计的</li><li>比如设置了超时，就别以为可以改变这个设置的超时值</li></ul></li><li>在使用 Context.Value 的时候，一定要记住这一点</li></ul><h3 id="应该把什么放到-Context-Value-里？"><a href="#应该把什么放到-Context-Value-里？" class="headerlink" title="应该把什么放到 Context.Value 里？"></a>应该把什么放到 Context.Value 里？</h3><ul><li>应该保存 Request 范畴的值<ul><li>任何关于 Context 自身的都是 Request 范畴的（这俩同生共死）</li><li>从 Request 数据衍生出来，并且随着 Request 的结束而终结</li></ul></li></ul><h3 id="什么东西不属于-Request-范畴？"><a href="#什么东西不属于-Request-范畴？" class="headerlink" title="什么东西不属于 Request 范畴？"></a>什么东西不属于 Request 范畴？</h3><ul><li>在 Request 以外建立的，并且不随着 Request 改变而变化<ul><li>比如你 func main() 里建立的东西显然不属于 Request 范畴</li></ul></li><li>数据库连接<ul><li>如果 User ID 在连接里呢？(稍后会提及)</li></ul></li><li>全局 logger<ul><li>如果 logger 里需要有 User ID 呢？（稍后会提及）</li></ul></li></ul><h3 id="那么用-Context-Value-有什么问题？"><a href="#那么用-Context-Value-有什么问题？" class="headerlink" title="那么用 Context.Value 有什么问题？"></a>那么用 Context.Value 有什么问题？</h3><ul><li>不幸的是，好像所有东西都是由请求衍生出来的</li><li>那么我们为什么还需要函数参数？然后干脆只来一个 Context 就完了？<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">func Add(ctx context.Context) int &#123;</span><br><span class="line">  return ctx.Value(&quot;first&quot;).(int) + ctx.Value(&quot;second&quot;).(int)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>曾经看到过一个 API，就是这种形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">func IsAdminUser(ctx context.Context) bool &#123;</span><br><span class="line">  userID := GetUser(ctx)</span><br><span class="line">  return authSingleton.IsAdmin(userID)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里API实现内部从 context 中取得 UserID，然后再进行权限判断。但是从函数签名看，则完全无法理解这个函数具体需要什么、以及做什么。</p><blockquote><p>代码要以可读性为优先设计考虑。</p></blockquote><p>别人拿到一个代码，一般不是掉进函数实现细节里去一行行的读代码，而是会先浏览一下函数接口。所以清晰的函数接口设计，会更加利于别人（<font color="DeepPink"><strong>或者是几个月后的你自己</strong></font>）理解这段代码。</p><p>一个良好的 API 设计，应该从函数签名就清晰的理解函数的逻辑。如果我们将上面的接口改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func IsAdminUser(ctx context.Context, userID string, authenticator auth.Service) bool</span><br></pre></td></tr></table></figure><p>我们从这个函数签名就可以清楚的知道：</p><ul><li>这个函数很可能可以提前被 cancel</li><li>这个函数需要 User ID</li><li>这个函数需要一个authenticator来</li><li>而且由于 authenticator 是传入参数，而不是依赖于隐式的某个东西，我们知道，测试的时候就很容易传入一个模拟认证函数来做测试</li><li>userID 是传入值，因此我们可以修改它，不用担心影响别的东西</li></ul><p>所有这些信息，都是从函数签名得到的，而无需打开函数实现一行行去看。</p><h3 id="那什么可以放到-Context-Value-里去？"><a href="#那什么可以放到-Context-Value-里去？" class="headerlink" title="那什么可以放到 Context.Value 里去？"></a>那什么可以放到 Context.Value 里去？</h3><p>现在知道 Context.Value 会让接口定义更加模糊，似乎不应该使用。那么又回到了原来的问题，到底什么可以放到 Context.Value 里去？换个角度去想，什么不是衍生于 Request？</p><ul><li>Context.Value 应该是告知性质的东西，而不是控制性质的东西</li><li>应该永远都不需要写进文档作为必须存在的输入数据</li><li>如果你发现你的函数在某些 Context.Value 下无法正确工作，那就说明这个 Context.Value 里的信息不应该放在里面，而应该放在接口上。因为已经让接口太模糊了。</li></ul><h4 id="什么东西不是控制性质的东西？"><a href="#什么东西不是控制性质的东西？" class="headerlink" title="什么东西不是控制性质的东西？"></a>什么东西不是控制性质的东西？</h4><ul><li>Request ID<ul><li>只是给每个 RPC 调用一个 ID，而没有实际意义</li><li>这就是个数字/字符串，反正你也不会用其作为逻辑判断</li><li>一般也就是日志的时候需要记录一下<ul><li>而 logger 本身不是 Request 范畴，所以 logger 不应该在 Context 里</li><li>非 Request 范畴的 logger 应该只是利用 Context 信息来修饰日志</li></ul></li></ul></li><li>User ID （如果仅仅是作为日志用）</li><li>Incoming Request ID</li></ul><h4 id="什么显然是控制性质的东西？"><a href="#什么显然是控制性质的东西？" class="headerlink" title="什么显然是控制性质的东西？"></a>什么显然是控制性质的东西？</h4><ul><li>数据库连接<ul><li>显然会非常严重的影响逻辑</li><li>因此这应该在函数参数里，明确表示出来</li></ul></li><li>认证服务(Authentication)<ul><li>显然不同的认证服务导致的逻辑不同</li><li>也应该放到函数参数里，明确表示出来</li></ul></li></ul><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><h4 id="调试性质的-Context-Value-net-http-httptrace"><a href="#调试性质的-Context-Value-net-http-httptrace" class="headerlink" title="调试性质的 Context.Value - net/http/httptrace"></a>调试性质的 Context.Value - net/http/httptrace</h4><p><a href="https://medium.com/@cep21/go-1-7-httptrace-and-context-debug-patterns-608ae887224a" target="_blank" rel="noopener">https://medium.com/@cep21/go-1-7-httptrace-and-context-debug-patterns-608ae887224a</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">func trace(req *http.Request, c *http.Client) &#123;</span><br><span class="line">  trace := &amp;httptrace.ClientTrace&#123;</span><br><span class="line">    GotConn: func(connInfo httptrace.GotConnInfo) &#123;</span><br><span class="line">      fmt.Println(&quot;Got Conn&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">    ConnectStart: func(network, addr string) &#123;</span><br><span class="line">      fmt.Println(&quot;Dial Start&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">    ConnectDone: func(network, addr string, err error) &#123;</span><br><span class="line">      fmt.Println(&quot;Dial done&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;</span><br><span class="line">  req = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))</span><br><span class="line">  c.Do(req)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="net-http-是怎么使用-httptrace-的？"><a href="#net-http-是怎么使用-httptrace-的？" class="headerlink" title="net/http 是怎么使用 httptrace 的？"></a>net/http 是怎么使用 httptrace 的？</h4><ul><li>如果有 trace 存在的话，就执行 trace 回调函数</li><li>这只是告知性质，而不是控制性质<ul><li>http 不会因为存在 trace 与否就有不同的执行逻辑</li><li>这里只是告知 API 的用户，帮助用户记录日志或者调试</li><li>因此这里的 trace 是存在于 Context 里的<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">package http</span><br><span class="line">func (req *Request) write(w io.Writer, usingProxy bool, extraHeaders Header, waitForContinue func() bool) (err error) &#123;</span><br><span class="line">  //  ...</span><br><span class="line">  trace := httptrace.ContextClientTrace(req.Context())</span><br><span class="line">  //  ...</span><br><span class="line">  if trace != nil &amp;&amp; trace.WroteHeaders != nil &#123;</span><br><span class="line">    trace.WroteHeaders()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="回避依赖注入-github-com-golang-oauth2"><a href="#回避依赖注入-github-com-golang-oauth2" class="headerlink" title="回避依赖注入 - github.com/golang/oauth2"></a>回避依赖注入 - github.com/golang/oauth2</h4><ul><li>这里比较诡异，使用 ctx.Value 来定位依赖</li><li><font color="DeepPink"><strong>不推荐这样做</strong></font><ul><li>这里这样做基本上只是为了满足测试需求<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import &quot;github.com/golang/oauth2&quot;</span><br><span class="line">func oauth() &#123;</span><br><span class="line">  c := &amp;http.Client&#123;Transport: &amp;mockTransport&#123;&#125;&#125;</span><br><span class="line">  ctx := context.WithValue(context.Background(), oauth2.HTTPClient, c)</span><br><span class="line">  conf := &amp;oauth2.Config&#123; /* ... */ &#125;</span><br><span class="line">  conf.Exchange(ctx, &quot;code&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="人们滥用-Context-Value-的原因"><a href="#人们滥用-Context-Value-的原因" class="headerlink" title="人们滥用 Context.Value 的原因"></a>人们滥用 Context.Value 的原因</h3><ul><li>中间件的抽象</li><li>很深的函数调用栈</li><li>混乱的设计</li></ul><blockquote><p>context.Value 并没有让你的 API 更简洁，那是假象，相反，它让你的 API 定义更加模糊。</p></blockquote><h2 id="总结-Context-Value"><a href="#总结-Context-Value" class="headerlink" title="总结 Context.Value"></a>总结 Context.Value</h2><ul><li>对于调试非常方便</li><li>将必须的信息放入 Context.Value 中，会让接口定义更加不透明</li><li>如果可以尽量明确定义在接口</li><li>尽量不要用 Context.Value</li></ul><h1 id="总结-Context"><a href="#总结-Context" class="headerlink" title="总结 Context"></a>总结 Context</h1><ul><li>所有的长的、阻塞的操作都需要 Context</li><li>errgroup 是构架于 Context 之上很好的抽象</li><li>当 Request 的结束的时候，Cancel Context</li><li>Context.Value 应该被用于<font color="DeepPink"><strong>告知性质</strong></font>的事物，而不是<font color="DeepPink"><strong>控制性质</strong></font>的事物</li><li>约束 Context.Value 的键空间</li><li>Context 以及 Context.Value 应该是不可变的（immutable），并且应该是线程安全</li><li>Context 应该随 Request 消亡而消亡</li></ul><h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><h2 id="数据库的访问也用-Context-么？"><a href="#数据库的访问也用-Context-么？" class="headerlink" title="数据库的访问也用 Context 么？"></a>数据库的访问也用 Context 么？</h2><p>之前说过长时间、可阻塞的操作都用 Context，数据库操作也是如此。不过对于超时 Cancel 操作来说，一般不会对写操作进行 cancel；但是对于读操作，一般会有 Cancel 操作。</p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p><a href="https://blog.lab99.org/post/golang-2017-10-27-video-how-to-correctly-use-package-context.html" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-27-video-how-to-correctly-use-package-context.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Context </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>encrypted communication elasticsearch java rest client</title>
      <link href="/encrypted-communication-elasticsearch-java-rest-client.html"/>
      <url>/encrypted-communication-elasticsearch-java-rest-client.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>ElasticSearch 7.3.1<br>Java Rest Client HTTPS连接操作</p></blockquote><a id="more"></a><p>ElasticSearch版本7.3.1，elasticsearch.yml配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">xpack.security.transport.ssl.verification_mode: certificate</span><br><span class="line">xpack.security.transport.ssl.key: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.key</span><br><span class="line">xpack.security.transport.ssl.certificate: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.cer</span><br><span class="line">xpack.security.transport.ssl.certificate_authorities: [ &quot;/home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com_ca.crt&quot; ]</span><br><span class="line">xpack.security.http.ssl.enabled: true</span><br><span class="line">xpack.security.http.ssl.key:  /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.key</span><br><span class="line">xpack.security.http.ssl.certificate: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.cer</span><br><span class="line">xpack.security.http.ssl.certificate_authorities: [ &quot;/home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com_ca.crt&quot; ]</span><br></pre></td></tr></table></figure><p>由于ElasticSearch Java client中的<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#KeyStore" target="_blank" rel="noopener">KeyStore Types</a>只支持以下几种：</p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>jceks</td><td>The proprietary keystore implementation provided by the SunJCE provider.</td></tr><tr><td>jks</td><td>The proprietary keystore implementation provided by the SUN provider.</td></tr><tr><td>dks</td><td>A domain keystore is a collection of keystores presented as a single logical keystore. It is specified by configuration data whose syntax is described in DomainLoadStoreParameter.</td></tr><tr><td>pkcs11</td><td>A keystore backed by a PKCS #11 token.</td></tr><tr><td>pkcs12</td><td>The transfer syntax for personal identity information as defined in PKCS #12.</td></tr></tbody></table><p>而我这边证书格式为cer，所以通过keytool进行转换：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -import -v -trustcacerts -file _.jiankunking.com.cer  -keystore my_keystore.jks -keypass password -storepass password</span><br></pre></td></tr></table></figure><p>证书转换完成后，操作代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">package ssl;</span><br><span class="line"></span><br><span class="line">import org.apache.http.HttpHost;</span><br><span class="line">import org.apache.http.auth.AuthScope;</span><br><span class="line">import org.apache.http.auth.UsernamePasswordCredentials;</span><br><span class="line">import org.apache.http.client.CredentialsProvider;</span><br><span class="line">import org.apache.http.impl.client.BasicCredentialsProvider;</span><br><span class="line">import org.apache.http.ssl.SSLContexts;</span><br><span class="line">import org.elasticsearch.client.RequestOptions;</span><br><span class="line">import org.elasticsearch.client.RestClient;</span><br><span class="line">import org.elasticsearch.client.RestClientBuilder;</span><br><span class="line">import org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line">import org.elasticsearch.client.indices.CreateIndexRequest;</span><br><span class="line">import org.elasticsearch.client.indices.CreateIndexResponse;</span><br><span class="line">import org.elasticsearch.common.settings.Settings;</span><br><span class="line">import org.elasticsearch.common.xcontent.XContentType;</span><br><span class="line"></span><br><span class="line">import javax.net.ssl.SSLContext;</span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.security.KeyManagementException;</span><br><span class="line">import java.security.KeyStoreException;</span><br><span class="line">import java.security.NoSuchAlgorithmException;</span><br><span class="line">import java.security.cert.CertificateException;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @Author: jiankunking</span><br><span class="line"> * @Date: 2019/8/27 15:32</span><br><span class="line"> * @Description:</span><br><span class="line"> */</span><br><span class="line">public class es &#123;</span><br><span class="line">    public static void main(String[] args) throws KeyStoreException, IOException, NoSuchAlgorithmException, KeyManagementException, CertificateException &#123;</span><br><span class="line">        </span><br><span class="line">        CredentialsProvider credentialsProvider = new BasicCredentialsProvider();</span><br><span class="line">        credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(&quot;elastic&quot;, &quot;jiankunking&quot;));</span><br><span class="line"></span><br><span class="line">        SSLContext sslContext = SSLContexts.custom()</span><br><span class="line">                .loadTrustMaterial(new File(&quot;I:\\certs\\my_keystore.jks&quot;))</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        String host = &quot;es.jiankunking.com&quot;;</span><br><span class="line">        int port = 9200;</span><br><span class="line">        String scheme = &quot;https&quot;;</span><br><span class="line">        String indexName = &quot;twitter2&quot;;</span><br><span class="line"></span><br><span class="line">        RestClientBuilder restClientBuilder = RestClient.builder(new HttpHost(host, port, scheme)).setHttpClientConfigCallback(httpClientBuilder -&gt; httpClientBuilder</span><br><span class="line">                .setDefaultCredentialsProvider(credentialsProvider)</span><br><span class="line">                .setSSLContext(sslContext)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">// 到这里RestHighLevelClient已经初始化完成，下面的创建索引是测试</span><br><span class="line">        RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder);</span><br><span class="line"></span><br><span class="line">        // 创建索引请求</span><br><span class="line">        CreateIndexRequest request = new CreateIndexRequest(indexName);</span><br><span class="line">        request.settings(Settings.builder()</span><br><span class="line">                .put(&quot;index.number_of_shards&quot;, 3)</span><br><span class="line">                .put(&quot;index.number_of_replicas&quot;, 2)</span><br><span class="line">        );</span><br><span class="line">        request.mapping(</span><br><span class="line">                &quot;&#123;\n&quot; +</span><br><span class="line">                        &quot;  \&quot;properties\&quot;: &#123;\n&quot; +</span><br><span class="line">                        &quot;    \&quot;message\&quot;: &#123;\n&quot; +</span><br><span class="line">                        &quot;      \&quot;type\&quot;: \&quot;text\&quot;\n&quot; +</span><br><span class="line">                        &quot;    &#125;\n&quot; +</span><br><span class="line">                        &quot;  &#125;\n&quot; +</span><br><span class="line">                        &quot;&#125;&quot;,</span><br><span class="line">                XContentType.JSON);</span><br><span class="line">        Map&lt;String, Object&gt; message = new HashMap&lt;&gt;();</span><br><span class="line">        message.put(&quot;type&quot;, &quot;text&quot;);</span><br><span class="line">        Map&lt;String, Object&gt; properties = new HashMap&lt;&gt;();</span><br><span class="line">        properties.put(&quot;message&quot;, message);</span><br><span class="line">        Map&lt;String, Object&gt; mapping = new HashMap&lt;&gt;();</span><br><span class="line">        mapping.put(&quot;properties&quot;, properties);</span><br><span class="line">        request.mapping(mapping);</span><br><span class="line">        CreateIndexResponse createIndexResponse;</span><br><span class="line">        try &#123;</span><br><span class="line">            createIndexResponse = restHighLevelClient.indices().create(request, RequestOptions.DEFAULT);</span><br><span class="line">            System.out.println(createIndexResponse);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ElasticSearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> ElasticSearch </tag>
            
            <tag> Java </tag>
            
            <tag> Rest </tag>
            
            <tag> Client </tag>
            
            <tag> Encrypted </tag>
            
            <tag> Communication </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web性能权威指南 笔记</title>
      <link href="/high-performance-browser-networking-notes.html"/>
      <url>/high-performance-browser-networking-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《Web性能权威指南》 作者：Ilya Grigorik</p><p>出版时间：2014-04</p><a id="more"></a><h1 id="网络技术概览"><a href="#网络技术概览" class="headerlink" title="网络技术概览"></a>网络技术概览</h1><h2 id="带宽与延迟"><a href="#带宽与延迟" class="headerlink" title="带宽与延迟"></a>带宽与延迟</h2><h3 id="延迟的最后一公里"><a href="#延迟的最后一公里" class="headerlink" title="延迟的最后一公里"></a>延迟的最后一公里</h3><p>traceroute (Windows 系统下是tracert) 命令利用ICMP协议定位您的计算机和目标计算机之间的所有路由器。</p><h2 id="TCP的构成"><a href="#TCP的构成" class="headerlink" title="TCP的构成"></a>TCP的构成</h2><p>因特网有两个核心协议：IP和TCP。IP，即 Internet Protocol（因特网协议），负责联网主机之间的路由选择和寻址；TCP，即 Transmission Control Protocol（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。</p><h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p>所有TCP连接一开始都要经过三次握手（见图 2-1）。客户端与服务器在交换应用数据之前，必须就起始分组序列号，以及其他一些连接相关的细节达成一致。出于安全考虑，序列号由两端随机生成。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE21%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><ul><li>SYN<br>客户端选择一个随机序列号x，并发送一个SYN分组，其中可能还包括其他TCP标志和选项。</li><li>SYN ACK<br>服务器给x加1，并选择自己的一个随机序列号y，追加自己的标志和选项，然后返回响应。</li><li>ACK<br>客户端给x和y加1并发送握手期间的最后一个ACK分组。</li></ul><blockquote><p>SYN：同步序列编号（Synchronize Sequence Numbers）<br>ACK (Acknowledge character）即是确认字符</p></blockquote><p>三次握手完成后，客户端与服务器之间就可以通信了。<font color="DeepPink"><strong>客户端可以在发送ACK分组之后立即发送数据，而服务器必须等接收到ACK分组之后才能发送数据。</strong></font>这个启动通信的过程适用于所有TCP连接，因此对所有使用TCP的应用具有非常大的性能影响，因为每次传输应用数据之前，都必须经历一次完整的往返。</p><h3 id="队首阻塞"><a href="#队首阻塞" class="headerlink" title="队首阻塞"></a>队首阻塞</h3><blockquote><p>丢包就丢包<br>事实上，丢包是让TCP达到最佳性能的关键。被删除的包恰恰是一种反馈机制，能够让接收端和发送端各自调整速度，以避免网络拥堵，同时保持延迟最短。另外，有些应用程序可以容忍丢失一定数量的包，比如语音和游戏状态通信，就不需要可靠传输或按序交付。<br>就算有个包丢了，音频编解码器只要在音频中插入一个小小的间歇，就可以继续处理后来的包。只要间歇够小，用户就注意不到，而等待丢失的包则可能导致音频输出产生无法预料的暂停。相对来说，后者的用户体验更糟糕。<br>类似地，更新3D游戏中角色的状态也一样：收到T时刻的包而等待T-1时刻的包通常毫无必要。理想情况下，应该可以接收所有状态更新，但为避免游戏延迟，间歇性的丢包也是可以接受的。</p></blockquote><h2 id="针对TCP的优化建议"><a href="#针对TCP的优化建议" class="headerlink" title="针对TCP的优化建议"></a>针对TCP的优化建议</h2><p>TCP是一个自适应的、对所有网络节点一视同仁的、最大限制利用底层网络的协议。因此，优化TCP的最佳途径就是调整它感知当前网络状况的方式，根据它之上或之下的抽象层的类型和需求来改变它的行为。</p><h3 id="服务器配置调优"><a href="#服务器配置调优" class="headerlink" title="服务器配置调优"></a>服务器配置调优</h3><p>在着手调整TCP的缓冲区、超时等数十个变量之前，最好先把主机操作系统升级到最新版本。TCP 的最佳实践以及影响其性能的底层算法一直在与时俱进，而且大多数变化都只在最新内核中才有实现。一句话，让你的服务器跟上时代是优化发送端和接收端TCP栈的首要措施。</p><p>有了最新的内核，我们推荐你遵循如下最佳实践来配置自己的服务器。</p><ul><li>增大TCP的初始拥塞窗口<br>加大起始拥塞窗口可以让TCP在第一次往返就传输较多数据，而随后的速度提升也会很明显。对于突发性的短暂连接，这也是特别关键的一个优化。</li><li>慢启动重启<br>在连接空闲时禁用慢启动可以改善瞬时发送数据的长TCP连接的性能。</li><li>窗口缩放<br>启用窗口缩放可以增大最大接收窗口大小，可以让高延迟的连接达到更好吞吐量。</li><li>TCP快速打开<br>在某些条件下，允许在第一个SYN分组中发送应用程序数据。TFO（TCP Fast Open，TCP 快速打开）是一种新的优化选项，需要客户端和服务器共同支持。为此，首先要搞清楚你的应用程序是否可以利用这个特性。</li></ul><blockquote><p>Linux用户可以使用ss来查看当前打开的套接字的各种统计信息。在命令行里运行ss –options –extended –memory –processes –info ，可以看到当前通信节点以及它们相应的连接设置。</p></blockquote><h2 id="UDP的构成"><a href="#UDP的构成" class="headerlink" title="UDP的构成"></a>UDP的构成</h2><p>关于UDP的应用，最广为人知同时也是所有浏览器和因特网应用都赖以运作的，就是DNS（Domain Name System，域名系统）。</p><p>IETF和W3C工作组共同制定了一套新API WebRTC（Web Real-Time Communication，Web 实时通信）。WebRTC着眼于在浏览器中通过UDP实现原生的语音和视频实时通信，以及其他形式的 P2P（Peer-to-Peer，端到端）通信。</p><h3 id="无协议服务"><a href="#无协议服务" class="headerlink" title="无协议服务"></a>无协议服务</h3><p>要理解为什么UDP被人称作“无协议”，必须从作为TCP和UDP下一层的IP协议说起。<font color="DeepPink"><strong>IP层的主要任务就是按照地址从源主机向目标主机发送数据报</strong></font>。为此，消息会被封装在一个IP分组内（图3-1），其中载明了源地址和目标地址，以及其他一些路由参数。注意，数据报这个词暗示了一个重要的信息：<font color="DeepPink"><strong>IP层不保证消息可靠的交付，也不发送失败通知，实际上是把底层网络的不可靠性直接暴露给了上一层</strong></font>。如果某个路由节点因为网络拥塞、负载过高或其他原因而删除了IP分组，那么在必要的情况下，IP 的上一层协议要负责检测、恢复和重发数据。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE31IPv4%E9%A6%96%E9%83%A8.png" alt></p><p>UDP协议会用自己的分组结构（图3-2）封装用户消息，它只增加 4个字段：<font color="DeepPink"><strong>源端口、目标端口、分组长度和校验和</strong></font>。这样，当IP把分组送达目标主机时，该主机能够拆开UDP分组，根据目标端口找到目标应用程序，然后再把消息发送过去。仅此而已。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE32UDP%E9%A6%96%E9%83%A8.png" alt></p><p>事实上，UDP数据报中的源端口和校验和字段都是可选的。IP分组的首部也有校验和，应用程序可以忽略UDP校验和。也就是说，所有错误检测和错误纠正工作都可以委托给上层的应用程序。说到底，<font color="DeepPink"><strong>UDP仅仅是在IP层之上通过嵌入应用程序的源端口和目标端口</strong></font>，提供了一个“应用程序多路复用”机制。明白了这一点，就可以总结一下UDP的无服务是怎么回事了。</p><ul><li>不保证消息交付<br>不确认，不重传，无超时。</li><li>不保证交付顺序<br>不设置包序号，不重排，不会发生队首阻塞。</li><li>不跟踪连接状态<br>不必建立连接或重启状态机。</li><li>不需要拥塞控制<br>不内置客户端或网络反馈机制。</li></ul><p>TCP是一个面向字节流的协议，能够以多个分组形式发送应用程序消息，且对分组中的消息范围没有任何明确限制。因此，连接的两端存在一个连接状态，每个分组都有序号，丢失还要重发，并且要按顺序交付。相对来说，<font color="DeepPink"><strong>UDP数据报有明确的限制：数据报必须封装在IP分组中，应用程序必须读取完整的消息。换句话说，数据报不能分片。</strong></font></p><h3 id="UDP与网络地址转换器"><a href="#UDP与网络地址转换器" class="headerlink" title="UDP与网络地址转换器"></a>UDP与网络地址转换器</h3><p>作为监管全球IP地址分配的机构，IANA（Internet Assigned Numbers Authority，因特网号码分配机构）为私有网络保留了三段IP地址，这些IP地址经常可以在NAT设备后面的内网中看到。</p><p>保留的IP地址范围：</p><table><thead><tr><th>IP地址范围</th><th>地址数量</th></tr></thead><tbody><tr><td>10.0.0.0~10.255.255.255</td><td>16 777 216</td></tr><tr><td>172.16.0.0~172.31.255.255</td><td>1 048 576</td></tr><tr><td>192.168.0.0~192.168.255.255</td><td>65 536</td></tr></tbody></table><blockquote><p>为防止路由错误和引起不必要的麻烦，不允许给外网计算机分配这些保留的私有IP地址。</p></blockquote><h2 id="传输层安全（TLS）"><a href="#传输层安全（TLS）" class="headerlink" title="传输层安全（TLS）"></a>传输层安全（TLS）</h2><p>SSL（Secure Sockets Layer，安全套接字层）协议最初是网景公司为了保障网上交易安全而开发的，该协议通过加密来保护客户个人资料，通过认证和完整性检查来确保交易安全。为达到这个目标，SSL协议在直接位于TCP上一层的应用层被实现（图 4-1）。SSL不会影响上层协议（如HTTP、电子邮件、即时通讯），但能够保证上层协议的网络通信安全。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE41%E4%BC%A0%E8%BE%93%E5%B1%82%E5%AE%89%E5%85%A8.png" alt></p><p>在正确使用SSL的情况下，第三方监听者只能推断出连接的端点、加密类型，以及发送数据的频率和大致数量，不能实际读取或修改任何数据。</p><h3 id="加密、身份验证与完整性"><a href="#加密、身份验证与完整性" class="headerlink" title="加密、身份验证与完整性"></a>加密、身份验证与完整性</h3><blockquote><p><font color="DeepPink"><strong>Web 代理、中间设备、TLS 与新协议</strong></font><br><strong>HTTP 良好的扩展能力和获得的巨大成功，使得 Web 上出现了大量代理和中间设备：缓存服务器、安全网关、Web 加速器、内容过滤器，等等。有时候，我们知道这些设备的存在（显式代理），而有时候，这些设备对终端用户则完全不可见。</strong></p></blockquote><blockquote><p><strong>然而，这些服务器的存在及成功也给那些试图脱离 HTTP 协议的人带了一些不便。比如，有的代理服务器只会简单地转发自己无法解释的 HTTP 扩展或其他在线格式（wire format），而有的则不管是否必要都会对所有数据执行自己设定的逻辑，还有一些安全设备可能会把本来正常的数据误判成恶意通信。</strong></p></blockquote><blockquote><p><strong>换句话说，现实当中如果想脱离 HTTP 和 80 端口的语义行事，经常会遭遇各种部署上的麻烦。比如，某些客户端表现正常，另一些可能就会异常，甚至在某个网段表现正常的客户端到了另一个网段又会变得异常。</strong></p></blockquote><blockquote><p><strong>为解决这些问题，出现了一些新协议和对 HTTP 的扩展，比如 WebSocket、SPDY等。这些新协议一般要依赖于建立 HTTPS 信道，以绕过中间代理，从而实现可靠的部署，因为加密的传输信道会对所有中间设备都混淆数据。这样虽然解决了中间设备的问题，但却导致通信两端不能再利用这些中间设备，从而与这些设备提供的身份验证、缓存、安全扫描等功能失之交臂。</strong></p></blockquote><h3 id="信任链与证书颁发机构"><a href="#信任链与证书颁发机构" class="headerlink" title="信任链与证书颁发机构"></a>信任链与证书颁发机构</h3><p>Web以及浏览器中的身份验证需要回答以下几个问题：我的浏览器信任谁？我在使用浏览器的时候信任谁？这个问题至少有三个答案。</p><ul><li>手工指定证书<br>所有浏览器和操作系统都提供了一种手工导入信任证书的机制。至于如何获得证书和验证完整性则完全由你自己来定。</li><li>证书颁发机构<br>CA（Certificate Authority，证书颁发机构）是被证书接受者（拥有者）和依赖证书的一方共同信任的第三方。</li><li>浏览器和操作系统<br>每个操作系统和大多数浏览器都会内置一个知名证书颁发机构的名单。因此，你也会信任操作系统及浏览器提供商提供和维护的可信任机构。</li></ul><p>实践中，保存并手工验证每个网站的密钥是不可行的（当然，如果你愿意，也可以）。现实中最常见的方案就是让证书颁发机构替我们做这件事（图 4-5）：浏览器指定可信任的证书颁发机构（根CA），然后验证他们签署的每个站点的责任就转移到了他们头上，他们会审计和验证这些站点的证书没有被滥用或冒充。持有CA证书的站点的安全性如果遭到破坏，那撤销该证书也是证书颁发机构的责任。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE45%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84%E7%AD%BE%E7%BD%B2%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6.png" alt></p><p>所有浏览器都允许用户检视自己安全连接的信任链，常见的访问入口就是地址栏头儿上的锁图标，点击即可查看。</p><h3 id="证书撤销"><a href="#证书撤销" class="headerlink" title="证书撤销"></a>证书撤销</h3><h4 id="证书撤销名单（CRL）"><a href="#证书撤销名单（CRL）" class="headerlink" title="证书撤销名单（CRL）"></a>证书撤销名单（CRL）</h4><p>CRL（Certificate Revocation List，证书撤销名单）是RFC 5280规定的一种检查所有证书状态的简单机制：每个证书颁发机构维护并定期发布已撤销证书的序列号名<br>单。这样，任何想验证证书的人都可以下载撤销名单，检查相应证书是否榜上有名。如果有，说明证书已经被撤销了。</p><p>CRL文件本身可以定期发布、每次更新时发布，或通过HTTP或其他文件传输协议来提供访问。这个名单同样由证书颁发机构签名，通常允许被缓存一定时间。实践中，这种机制效果很好，但也存在一些问题：</p><ul><li>CRL名单会随着要撤销的证书增多而变长，每个客户端都必须取得包含所有序列号的完整名单；</li><li>没有办法立即更新刚刚被撤销的证书序列号，比如客户端先缓存了CRL，之后某证书被撤销，那到缓存过期之前，该证书将一直被视为有效。</li></ul><h4 id="在线证书状态协议（OCSP）"><a href="#在线证书状态协议（OCSP）" class="headerlink" title="在线证书状态协议（OCSP）"></a>在线证书状态协议（OCSP）</h4><p>为解决CRL机制的上述问题，RFC 2560定义了OCSP（Online Certificate Status Protocol，在线证书状态协议），提供了一种实时检查证书状态的机制。与CRL包含被撤销证书的序列号不同，OCSP 支持验证端直接查询证书数据库中的序列号，从而验证证书链是否有效。总之，OCSP 占用带宽更少，支持实时验证。</p><p>然而，没有什么机制是完美无缺的！实时OCSP查询也带了一些问题：</p><ul><li>证书颁发机构必须处理实时查询；</li><li>证书颁发机构必须确保随时随地可以访问；</li><li>客户端在进一步协商之前阻塞OCSP请求；</li><li>由于证书颁发机构知道客户端要访问哪个站点，因此实时OCSP请求可能会泄露客户端的隐私。</li></ul><blockquote><p>实践中，CRL和OCSP机制是互补存在的，大多数证书既提供指令也支持查询。<br>更重要的倒是客户端的支持和行为。有的浏览器会分发自己的CRL名单，有的浏览器从证书颁发机构取得并缓存CRL文件。类似地，有的浏览器会进行实时OCSP检查，但在OCSP请求失败的情况下行为又会有所不同。要了解具体的情况，可以检查浏览器和操作系统的证书撤销网络设置。</p></blockquote><h3 id="针对TLS的优化建议"><a href="#针对TLS的优化建议" class="headerlink" title="针对TLS的优化建议"></a>针对TLS的优化建议</h3><h4 id="TLS记录大小"><a href="#TLS记录大小" class="headerlink" title="TLS记录大小"></a>TLS记录大小</h4><p>不过对于在浏览器中运行的Web应用来说，倒是有一个值得推荐的做法：每个TCP分组恰好封装一个TLS记录，而TLS记录大小恰好占满TCP分配的MSS（Maximum Segment Size，最大段大小）。换句话说，一方面不要让TLS记录分成多个TCP分组，另一方面又要尽量在一条记录中多发送数据。以下数据可作为确定最优TLS记录大小的参考：</p><ul><li>IPv4 帧需要 20 字节，IPv6 需要 40 字节；</li><li>TCP 帧需要 20 字节；</li><li>TCP 选项需要 40 字节（时间戳、SACK 等）。</li></ul><p>假设常见的MTU为1500字节，则TLS记录大小在IPv4下是1420字节，在IPv6下是1400字节。为确保向前兼容，建议使用IPv6下的大小：1400字节。当然，如果MTU更小，这个值也要相应调小。</p><p>可惜的是，我们不能在应用层控制TLS记录大小。TLS记录大小通常是一个设置，甚至是TLS服务器上的编译时常量或标志。要了解具体如何设置这个值，请参考服务器文档。</p><blockquote><p>如果服务器要处理大量TLS连接，那么关键的优化是把每个连接占用的内存量控制在最小。默认情况下，OpenSSL等常用的库会给每个连接分配50KB空间，但正像设置记录大小一样，有必要查一查文档或者源代码，然后再决定如何调整这个值。谷歌的服务器把OpenSSL缓冲区的大小减少到了大约5KB。</p></blockquote><h4 id="TLS压缩"><a href="#TLS压缩" class="headerlink" title="TLS压缩"></a>TLS压缩</h4><p>TLS还有一个内置的小功能，就是支持对记录协议传输的数据进行无损压缩。压缩算法在TLS握手期间商定，压缩操作在对记录加密之前执行。然而，出于如下原因，实践中往往需要禁用服务器上的TLS压缩功能：</p><ul><li>2012 年公布的“CRIME”攻击会利用TLS压缩恢复加密认证cookie，让攻击者实施会话劫持；</li><li>传输级的TLS压缩不关心内容，可能会再次压缩已经压缩过的数据（图像、视频等等）。</li></ul><p>双重压缩会浪费服务器和客户端的CPU时间，而且暴露的安全漏洞也很严重，因此请禁用TLS压缩。实践中，大多数浏览器会禁用TLS压缩，但即便如此你也应该在服务器的配置中明确禁用它，以保护用户的利益。</p><blockquote><p>虽然不能使用TLS压缩，但应该使用服务器的Gzip设置压缩所有文本资源，同时对图像、视频、音频等媒体采用最合适的压缩格式。</p></blockquote><h1 id="无线网络性能"><a href="#无线网络性能" class="headerlink" title="无线网络性能"></a>无线网络性能</h1><h2 id="移动网络的优化建议"><a href="#移动网络的优化建议" class="headerlink" title="移动网络的优化建议"></a>移动网络的优化建议</h2><h3 id="消除周期性及无效的数据传输"><a href="#消除周期性及无效的数据传输" class="headerlink" title="消除周期性及无效的数据传输"></a>消除周期性及无效的数据传输</h3><p>对推送而言，原生应用可以访问平台专有的推送服务，因此应该尽可能使用。对 Web 应用来说，可以使用SSE（Server Sent Events，服务器发送事件）和WebSocket以降低延迟时间和协议消耗，尽可能不使用轮询和更耗资源的XHR技术。</p><h3 id="消除不必要的长连接"><a href="#消除不必要的长连接" class="headerlink" title="消除不必要的长连接"></a>消除不必要的长连接</h3><p>TCP或UDP连接的连接状态及生命期与设备的无线状态是相互独立的。换句话说，即便与运营商网络仍维持着（两端间）连接不中断，无线模块也可以处于低耗电状态。外部网络的分组到来时，运营商无线网络会通知设备，使其无线模块切换到连接状态，从而恢复数据传输。</p><p>明白了吗，应用不必让无线模块“活动”也可以保持连接不被断开。但不必要的长连接也有可能极大地消耗电量，而且由于人们对移动网络无线通信的误解，这种情况经常发生。</p><h3 id="预测网络延迟上限"><a href="#预测网络延迟上限" class="headerlink" title="预测网络延迟上限"></a>预测网络延迟上限</h3><p>在移动网络中，一个HTTP请求很可能会导致一连串长达几百甚至上几千ms的网络延迟。这一方面是因为有往返延迟，另一方面也不能忘记DNS、TCP、TLS及控制面的延迟（图8-2）。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE82%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E7%9A%84%E6%9E%84%E6%88%90.png" alt></p><h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="HTTP-简史"><a href="#HTTP-简史" class="headerlink" title="HTTP 简史"></a>HTTP 简史</h2><h3 id="HTTP-1-0：迅速发展及参考性RFC"><a href="#HTTP-1-0：迅速发展及参考性RFC" class="headerlink" title="HTTP 1.0：迅速发展及参考性RFC"></a>HTTP 1.0：迅速发展及参考性RFC</h3><p>今天，几乎所有Web服务器都支持，而且以后还会继续支持HTTP 1.0。除此之外，剩下的你都知道了。但HTTP 1.0对每个请求都打开一个新TCP连接严重影响性能。</p><h3 id="HTTP-1-1：互联网标准"><a href="#HTTP-1-1：互联网标准" class="headerlink" title="HTTP 1.1：互联网标准"></a>HTTP 1.1：互联网标准</h3><p>HTTP 1.1 标准厘清了之前版本中很多有歧义的地方，而且还加入了很多重要的性能优化：<font color="DeepPink"><strong>持久连接、分块编码传输、字节范围请求、增强的缓存机制、传输编码及请求管道</strong></font>。</p><p>HTTP 1.1 改变了HTTP协议的语义，默认使用持久连接。换句话说，除非明确告知（通过Connection: close 首部），否则服务器默认会保持连接打开。</p><p>不过，这个功能也反向移植到了HTTP 1.0，可以通过Connection: Keep-Alive 首部来启用。实际上，如果你使用的是HTTP 1.1，从技术上说不需要Connection: Keep-Alive首部，但很多客户端还是选择加上它。</p><p>此外，HTTP 1.1 协议添加了内容、编码、字符集，甚至语言的协商机制，还添加了传输编码、缓存指令、客户端cookie 等十几个可以每次请求都协商的字段。</p><h3 id="HTTP-2-0：改进传输性能"><a href="#HTTP-2-0：改进传输性能" class="headerlink" title="HTTP 2.0：改进传输性能"></a>HTTP 2.0：改进传输性能</h3><blockquote><p>HTTP（Hypertext Transfer Protocol）是一个应用层协议，可用于分布协作式的超媒体系统。它是一个通用、无状态的协议。除了超文本，通过扩展它的请求方式、错误编码及首部，还可以将它用于很多其他领域，比如域名服务器和分布式对象管理系统。HTTP的一个功能就是允许数据的类型变化和协商，从而允许系统独立于被传输的数据构建。——RFC 2616：HTTP/1.1（1999 年 6 月）</p></blockquote><blockquote><p>当前，出现了一种保持HTTP语义，但脱离HTTP/1.x消息分帧及语法的协议用法。这种用法被证明有碍于性能，并且是在鼓励滥用底层传输协议。本工作组将制定一个新规范，从有序、半双工流的角度重新表达当前HTTP的语义。与HTTP/1.x一样，主要将使用TCP作为传输层，不过也应该支持其他传输协议。——HTTP 2.0 纲领 （2012 年 1 月）</p></blockquote><p>HTTP 2.0 的主要目标是改进传输性能，实现低延迟和高吞吐量。主版本号的增加听起来像是要做大的改进，从性能角度说的确如此。但从另一方面看，HTTP的高层协议语义并不会因为这次版本升级而受影响。所有 HTTP 首部、值，以及它们的使用场景都不会变。</p><h2 id="Web性能要点"><a href="#Web性能要点" class="headerlink" title="Web性能要点"></a>Web性能要点</h2><h3 id="剖析现代Web应用"><a href="#剖析现代Web应用" class="headerlink" title="剖析现代Web应用"></a>剖析现代Web应用</h3><h4 id="速度、性能与用户期望"><a href="#速度、性能与用户期望" class="headerlink" title="速度、性能与用户期望"></a>速度、性能与用户期望</h4><p>时间和用户感觉</p><table><thead><tr><th>时间</th><th>感觉</th></tr></thead><tbody><tr><td>0 ~100 ms</td><td>很快</td></tr><tr><td>100~300 ms</td><td>有一点点慢</td></tr><tr><td>300~1000 ms</td><td>机器在工作呢</td></tr><tr><td>&gt; 1000 ms</td><td>先干点别的吧</td></tr><tr><td>&gt; 10000 ms</td><td>不能用了</td></tr></tbody></table><blockquote><p>这个表格解释了Web性能社区总结的经验法则：必须250 ms内渲染页面，或者至少提供视觉反馈，才能保证用户不走开！</p></blockquote><h2 id="HTTP-1-x"><a href="#HTTP-1-x" class="headerlink" title="HTTP 1.x"></a>HTTP 1.x</h2><p>HTTP 1.0的优化策略非常简单，就一句话：升级到HTTP 1.1。完了！</p><p>改进 HTTP 的性能是 HTTP 1.1 工作组的一个重要目标，后来这个版本也引入了大量增强性能的重要特性，其中一些大家比较熟知的有：</p><ul><li>持久化连接以支持连接重用； </li><li>分块传输编码以支持流式响应； </li><li>请求管道以支持并行请求处理； </li><li>字节服务以支持基于范围的资源请求；　 </li><li>改进的更好的缓存机制。 </li></ul><h3 id="HTTP管道"><a href="#HTTP管道" class="headerlink" title="HTTP管道"></a>HTTP管道</h3><p>HTTP 1.x 只能严格串行地返回响应。特别是，HTTP 1.x 不允许一个连接上的多个响应数据交错到达（多路复用），因而一个响应必须完全返回后，下一个响应才会开始传输。为说明这一点，我们可以看看服务器并行处理请求的情况（图 11-4）。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE114%E4%BD%BF%E7%94%A8HTTP%E7%AE%A1%E9%81%93%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E4%B8%94%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.png" alt></p><p>图 11-4 演示了如下几个方面：</p><ul><li>HTML 和 CSS 请求同时到达，但先处理的是 HTML 请求；</li><li>服务器并行处理两个请求，其中处理 HTML 用时 40 ms，处理 CSS 用时 20 ms；</li><li>CSS 请求先处理完成，但被缓冲起来以等候发送 HTML 响应；</li><li>发送完 HTML 响应后，再发送服务器缓冲中的 CSS 响应。</li></ul><p>HTTP 管道会导致 HTTP 服务器、代理和客户端出现很多微妙的，不见文档记载的问题：</p><ul><li>一个慢响应就会阻塞所有后续请求；</li><li>并行处理请求时，服务器必须缓冲管道中的响应，从而占用服务器资源，如果有个响应非常大，则很容易形成服务器的受攻击面；</li><li>响应失败可能终止 TCP 连接，从页强迫客户端重新发送对所有后续资源的请求，导致重复处理；</li><li>由于可能存在中间代理，因此检测管道兼容性，确保可靠性很重要；</li><li>如果中间代理不支持管道，那它可能会中断连接，也可能会把所有请求串联起来。</li></ul><p>今天，一些支持管道的浏览器，通常都将其作为一个高级配置选项，但大多数浏览器都会禁用它。换句话说，如果浏览器是 Web 应用的主要交付工具，那还是很难指望通过 HTTP 管道来提升性能。</p><p>要在你自己的应用中启用管道，要注意如下事项：</p><ul><li>确保 HTTP 客户端支持管道；</li><li>确保 HTTP 服务器支持管道；</li><li>应用必须处理中断的连接并恢复；</li><li>应用必须处理中断请求的幂等问题；</li><li>应用必须保护自身不受出问题的代理的影响。</li></ul><p>实践中部署 HTTP 管道的最佳途径，就是在客户端和服务器间使用安全通道（HTTPS）。这样，就能可靠地避免那些不理解或不支持管道的中间代理的干扰。</p><h3 id="使用多个TCP连接"><a href="#使用多个TCP连接" class="headerlink" title="使用多个TCP连接"></a>使用多个TCP连接</h3><p>由于 HTTP 1.x 不支持多路复用，浏览器可以不假思索地在客户端排队所有 HTTP请求，然后通过一个持久连接，一个接一个地发送这些请求。然而，这种方式在实践中太慢。实际上，浏览器开发商没有别的办法，只能允许我们并行打开多个 TCP会话。多少个？现实中，大多数现代浏览器，包括桌面和移动浏览器，都支持每个主机打开 6 个连接。</p><blockquote><p>消耗客户端和服务器资源<br>限制每个主机最多 6 个连接，可以让浏览器检测出无意（或有意）的 DoS（Denial of Service）攻击。如果没有这个限制，客户端有可能消耗掉服务器的所有资源。讽刺的是，同样的安全检测在某些浏览器上却会招致反向攻击：如果客户端超过<br>了最大连接数，那么所有后来的客户端请求都将被阻塞。大家可以做个试验，在一个主机上同时打开 6 个并行下载，然后再打开第 7 个下载请求，这个请求会挂起，直到前面的请求完成才会执行。</p></blockquote><p>用足客户端连接的限制似乎是一个可以接受的安全问题，但<font color="DeepPink"><strong>对于需要实时交付数据的应用而言，这样做越来越容易造成部署上的问题。比如 WebSocket、ServerSent Event 和挂起 XHR，这些会话都会占用整整一个 TCP 流，而不管有无数据传输——记住，没有多路复用一说！</strong></font>实际上，如果你不注意，那很可能自己对自己的应用施加 DoS 攻击。</p><h3 id="域名分区"><a href="#域名分区" class="headerlink" title="域名分区"></a>域名分区</h3><p>根据 HTTP Archive 的统计，目前平均每个页面都包含 90 多个独立的资源，如果这些资源都来自同一个主机，那么仍然会导致明显的排队等待。实际上，何必把自己只限制在一个主机上呢？我们不必只通过一个主机（例如 www.example.com）提供所有资源，而是可以手工将所有资源分散到多个子域名：{shard1,shardn}.example.com。由于主机名称不一样了，就可以突破浏览器的连接限制，实现更高的并行能力。域名分区使用得越多，并行能力就越强！</p><p>当然，天下没有免费的午餐，域名分区也不例外：每个新主机名都要求有一次额外的 DNS 查询，每多一个套接字都会多消耗两端的一些资源，而更糟糕的是，站点作者必须手工分离这些资源，并分别把它们托管到多个主机上。</p><blockquote><p>实践中，把多个域名（如 shard1.example.com、shard2.example.com）解析到同一个 IP 地址是很常见的做法。所有分区都通过 CNAME DNS 记录指向同一个服务器，而浏览器连接限制针对的是主机名，不是 IP 地址。另外，每个分区也可以指向一个 CDN 或其他可以访问到的服务器。</p></blockquote><blockquote><p>DNS 查询和 TCP 慢启动导致的额外消耗对高延迟客户端的影响最大。换句话说，移动（3G、4G）客户端经常是受过度域名分区影响最大的！</p></blockquote><blockquote><p><font color="DeepPink"><strong>Cookie 在很多应用中都是常见的性能瓶颈，很多开发者都会忽略它给每次请求增加的额外负担。</strong></font></p></blockquote><blockquote><p>计算图片对内存的需求<br>所有编码的图片经浏览器解析后都会以 RGBA 位图的形式保存于内存当中。每个RGBA 图片的像素需要占用 4 字节：红、绿、蓝通道各占 1 字节，Alpha（透明）通道占 1 字节。这样算下来，一张图片占用的内存量就是图片像素宽度 × 像素高度 ×4 字节。<br>举个例子，800×600 像素的位图会占多大内存呢？<br>800 × 600 × 4 B = 1 920 000 B ≈ 1.83 MB<br>在资源受限的设备，比如手机上，内存占用很快就会成为瓶颈。对于游戏等严重依赖图片的应用来说，这个问题就会更明显。</p></blockquote><blockquote><p>打包文件到底多大合适呢？可惜的是，没有理想的大小。然而，谷歌 PageSpeed团队的测试表明，30~50 KB（压缩后）是每个 JavaScript 文件大小的合适范围：既大到了能够减少小文件带来的网络延迟，还能确保递增及分层式的执行。具体的结果可能会由于应用类型和脚本数量而有所不同。</p></blockquote><h3 id="嵌入资源"><a href="#嵌入资源" class="headerlink" title="嵌入资源"></a>嵌入资源</h3><p>嵌入资源是另一种非常流行的优化方法，把资源嵌入文档可以减少请求的次数。比如，JavaScript 和 CSS 代码，通过适当的 script 和 style 块可以直接放在页面中，而图片甚至音频或 PDF 文件，都可以通过数据 URI（data:[mediatype][;base64],data ）的方式嵌入到页面中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAA</span><br><span class="line">AAAAAACH5BAAAAAAALAAAAAABAAEAAAICTAEAOw==&quot;</span><br><span class="line">alt=&quot;1x1 transparent (GIF) pixel&quot; /&gt;</span><br></pre></td></tr></table></figure><blockquote><p>前面的例子是在文档中嵌入了一个 1×1 的透明 GIF 像素。而任何 MIME类型，只要浏览器能理解，都可以通过类似方式嵌入到页面中，包括PDF、音频、视频。不过，有些浏览器会限制数据 URI 的大小，比如 IE8最大只允许 32 KB。</p></blockquote><p>数据 URI 适合特别小的，理想情况下，最好是只用一次的资源。以嵌入方式放到页面中的资源，应该算是页面的一部分，不能被浏览器、CDN 或其他缓存代理作为单独的资源缓存。换句话说，如果在多个页面中都嵌入同样的资源，那么这个资源将<br>会随着每个页面的加载而被加载，从而增大每个页面的总体大小。另外，如果嵌入资源被更新，那么所有以前出现过它的页面都将被宣告无效，而由客户端重新从服务器获取。</p><p>最后，虽然 CSS 和 JavaScript 等基于文本的资源很容易直接嵌入页面，也不会带来多余的开销，但非文本性资源则必须通过 base64 编码，而这会导致开销明显增大：编码后的资源大小比原大小增大 33% ！</p><blockquote><p><font color="DeepPink"><strong>base64 编码使用 64 个 ASCII 符号和空白符将任意字节流编码为 ASCII字符串。编码过程中，base64 会导致被编码的流变成原来的 4/3，即增大33% 的字节开销。</strong></font></p></blockquote><p>实践中，常见的一个经验规则是只考虑嵌入 1~2 KB 以下的资源，因为小于这个标准的资源经常会导致比它自身更高的 HTTP 开销。然而，如果嵌入的资源频繁变更，又会导致宿主文档的无效缓存率升高。嵌入资源也不是完美的方法。如果你的应用要使用很小的、个别的文件，在考虑是否嵌入时，可以参照如下建议：</p><ul><li>如果文件很小，而且只有个别页面使用，可以考虑嵌入；</li><li>如果文件很小，但需要在多个页面中重用，应该考虑集中打包；</li><li>如果小文件经常需要更新，就不要嵌入了；</li><li>通过减少 HTTP cookie 的大小将协议开销最小化。</li></ul><h2 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h2><p><font color="DeepPink"><strong>HTTP 2.0 的目的就是通过支持请求与响应的多路复用来减少延迟，通过压缩 HTTP首部字段将协议开销降至最低，同时增加对请求优先级和服务器端推送的支持。</strong></font></p><p>HTTP 2.0 不会改动 HTTP 的语义。HTTP 方法、状态码、URI 及首部字段，等等这些核心概念一如往常。但是，HTTP 2.0 修改了格式化数据（分帧）的方式，以及客户端与服务器间传输这些数据的方式。这两点统帅全局，通过新的组帧机制向我们的应用隐藏了所有复杂性。换句话说，所有原来的应用都可以不必修改而在新协议运行。这当然是好事。</p><h3 id="走向HTTP-2-0"><a href="#走向HTTP-2-0" class="headerlink" title="走向HTTP 2.0"></a>走向HTTP 2.0</h3><p>在此，有必要回顾一下 HTTP 2.0 宣言草稿，因为这份宣言明确了该协议的范围和关键设计要求：</p><p>HTTP/2.0 应该满足如下条件：</p><ul><li>相对于使用 TCP 的 HTTP 1.1，用户在大多数情况下的感知延迟要有实质上、可度量的改进；</li><li>解决 HTTP 中的“队首阻塞”问题；</li><li>并行操作无需与服务器建立多个连接，从而改进 TCP 的利用率，特别是拥塞控制方面；</li><li>保持 HTTP 1.1 的语义，利用现有文档，包括（但不限于）HTTP 方法、状态码、URI，以及首部字段；</li><li>明确规定 HTTP 2.0 如何与 HTTP 1.x 互操作，特别是在中间介质上；</li><li>明确指出所有新的可扩展机制以及适当的扩展策略。</li></ul><p>之所以要递增一个大版本到 2.0，主要是因为它改变了客户端与服务器之间交换数据的方式。为实现宏伟的性能改进目标，HTTP 2.0增加了新的二进制分帧数据层，而这一层并不兼容之前的 HTTP 1.x 服务器及客户端——是谓 2.0。</p><blockquote><p>除非你在实现 Web 服务器或者定制客户端，需要使用原始的 TCP 套接字，否则你很可能注意不到 HTTP 2.0 技术面的实际变化：所有新的、低级分帧机制都是浏览器和服务器为你处理的。或许唯一的区别就是可选的 API多了一些，比如服务器推送！</p></blockquote><h3 id="设计和技术目标"><a href="#设计和技术目标" class="headerlink" title="设计和技术目标"></a>设计和技术目标</h3><blockquote><p>HTTP/2.0 通过支持首部字段压缩和在同一连接上发送多个并发消息，让应用更有效地利用网络资源，减少感知的延迟时间。而且，它还支持服务器到客户端的主动推送机制。——HTTP/2.0，Draft 4</p></blockquote><h4 id="二进制分帧层"><a href="#二进制分帧层" class="headerlink" title="二进制分帧层"></a>二进制分帧层</h4><p>HTTP 2.0 性能增强的核心，全在于新增的二进制分帧层（图 12-1），它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE121HTTP2.0%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%88%86%E5%B8%A7%E5%B1%82.png" alt></p><p>这里所谓的“层”，指的是位于套接字接口与应用可见的高层 HTTP API 之间的一个新机制：HTTP 的语义，包括各种动词、方法、首部，都不受影响，不同的是传输期间对它们的编码方式变了。<font color="DeepPink"><strong>HTTP 1.x 以换行符作为纯文本的分隔符，而 HTTP2.0 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。</strong></font></p><h4 id="流、消息和帧"><a href="#流、消息和帧" class="headerlink" title="流、消息和帧"></a>流、消息和帧</h4><ul><li>流<br>已建立的连接上的双向字节流。</li><li>消息<br>与逻辑消息对应的完整的一系列数据帧。</li><li>帧<br>HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流。</li></ul><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE122HTTP2.0%E6%B5%81%E6%B6%88%E6%81%AF%E5%92%8C%E5%B8%A7.png" alt></p><p><font color="DeepPink"><strong>所有 HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。</strong></font></p><blockquote><p>HTTP 2.0 的所有帧都采用二进制编码，所有首部数据都会被压缩。因此，图 12-2 只是说明了数据流、消息和帧之间的关系，而非它们实际传输时的编码结果。</p></blockquote><p>要理解 HTTP 2.0，就必须理解流、消息和帧这几个基本概念。</p><ul><li>所有通信都在一个 TCP 连接上完成。</li><li>流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）。</li><li>消息是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。</li><li>帧是最小的通信单位，承载着特定类型的数据，如 HTTP 首部、负荷，等等。</li></ul><p>简言之，HTTP 2.0 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。相应地，很多流可以并行地在同一个 TCP 连接上交换消息。</p><h4 id="多向请求与响应"><a href="#多向请求与响应" class="headerlink" title="多向请求与响应"></a>多向请求与响应</h4><p>在 HTTP 1.x 中，如果客户端想发送多个并行的请求以及改进性能，那么必须使用多个 TCP 连接。这是 HTTP 1.x 交付模型的直接结果，该模型会保证每个连接每次只交付一个响应（多个响应必须排队）。更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。</p><p>HTTP 2.0 中新的二进制分帧层突破了这些限制，实现了多向请求和响应：客户端和服务器可以把 HTTP 消息分解为互不依赖的帧（图 12-3），然后乱序发送，最后再在另一端把它们重新组合起来。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE123HTTP2.0%E5%9C%A8%E5%85%B1%E4%BA%AB%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%B8%8A%E5%90%8C%E6%97%B6%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.png" alt></p><p>图 12-3 中包含了同一个连接上多个传输中的数据流：客户端正在向服务器传输一个DATA 帧（stream 5），与此同时，服务器正向客户端乱序发送 stream 1 和 stream 3的一系列帧。此时，一个连接上有 3 个请求/响应并行交换！</p><p>总之，<font color="DeepPink"><strong>HTTP 2.0 的二进制分帧机制解决了 HTTP 1.x 中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。</strong></font></p><blockquote><p>支持多向请求与响应，可以省掉针对 HTTP 1.x 限制所费的那些脑筋和工作，比如拼接文件、图片精灵、域名分区。类似地，通过减少 TCP 连接的数量，HTTP 2.0 也会减少客户端和服务器的 CPU 及内存占用。</p></blockquote><h4 id="请求优先级"><a href="#请求优先级" class="headerlink" title="请求优先级"></a>请求优先级</h4><p>把 HTTP 消息分解为很多独立的帧之后，就可以通过优化这些帧的交错和传输顺序，进一步提升性能。为了做到这一点，每个流都可以带有一个 31 比特的优先值：</p><ul><li>0 表示最高优先级；</li><li>2^31 -1 表示最低优先级。</li></ul><p>有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。具体来讲，服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。</p><blockquote><p>浏览器请求优先级与 HTTP 2.0<br>浏览器在渲染页面时，并非所有资源都具有相同的优先级：HTML 文档本身对构建 DOM 不可或缺，CSS 对构建 CSSOM 不可或缺，而 DOM 和 CSSOM 的构建都可能受到 JavaScript 资源的阻塞，其他资源（如图片）的优先级都可以降低。<br>为加快页面加载速度，所有现代浏览器都会基于资源的类型以及它在页面中的位置排定请求的优先次序，甚至通过之前的访问来学习优先级模式——比如，之前的渲染如果被某些资源阻塞了，那么同样的资源在下一次访问时可能就会被赋予更高的优先级。<br>在 HTTP 1.x 中，浏览器极少能利用上述优先级信息，因为协议本身并不支持多路复用，也没有办法向服务器通告请求的优先级。此时，浏览器只能依赖并行连接，且最多只能同时向一个域名发送 6 个请求。于是，在等连接可用期间，请求只能<br>在客户端排队，从而增加了不必要的网络延迟。理论上，HTTP 管道可以解决这个问题，只是由于缺乏支持而无法付诸实践。<br>HTTP 2.0 一举解决了所有这些低效的问题：浏览器可以在发现资源时立即分派请求，指定每个流的优先级，让服务器决定最优的响应次序。这样请求就不必排队了，既节省了时间，也最大限度地利用了每个连接。</p></blockquote><p>HTTP 2.0 没有规定处理优先级的具体算法，只是提供了一种赋予数据优先级的机制，而且要求客户端与服务器必须能够交换这些数据。这样一来，<font color="DeepPink"><strong>优先值作为提示信息，对应的次序排定策略可能因客户端或服务器的实现而不同：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据。</strong></font></p><p>在这个规定之下，尽管你可能无法控制客户端发送的优先值，但或许你可以控制服务器。因此，在选择 HTTP 2.0 服务器时，可以多留点心！为说明这一点，考虑下面几个问题。</p><ul><li>如果服务器对所有优先值视而不见怎么办？</li><li>高优先值的流一定优先处理吗？</li><li>是否存在不同优先级的流应该交错的情况？<br>如果服务器不理睬所有优先值，那么可能会导致应用响应变慢：浏览器明明在等关键的 CSS 和 JavaScript，服务器却在发送图片，从而造成渲染阻塞。不过，规定严格的优先级次序也可能带来次优的结果，因为这可能又会引入队首阻塞问题，即某<br>个高优先级的慢请求会不必要地阻塞其他资源的交付。</li></ul><p>服务器可以而且应该交错发送不同优先级别的帧。只要可能，高优先级流都应该优先，包括分配处理资源和客户端与服务器间的带宽。不过，为了最高效地利用底层连接，不同优先级的混合也是必需的。</p><h4 id="每个来源一个连接"><a href="#每个来源一个连接" class="headerlink" title="每个来源一个连接"></a>每个来源一个连接</h4><p>有了新的分帧机制后，HTTP 2.0 不再依赖多个 TCP 连接去实现多流并行了。现在，每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别优先级。于是，<font color="DeepPink"><strong>所有HTTP 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接即可。</strong></font></p><blockquote><p>实验表明，客户端使用更少的连接肯定可以降低延迟时间。HTTP 2.0 发送的总分组数量比 HTTP 差不多要少 40%。而服务器处理大量并发连接的情况也变成了可伸缩性问题，因为 HTTP 2.0 减轻了这个负担。<br>——HTTP/2.0 Draft 2</p></blockquote><p>每个来源一个连接显著减少了相关的资源占用：连接路径上的套接字管理工作量少了，内存占用少了，连接吞吐量大了。此外，从上到下所有层面上也都获得了相应的好处：</p><ul><li>所有数据流的优先次序始终如一；</li><li>压缩上下文单一使得压缩效果更好；</li><li>由于 TCP 连接减少而使网络拥塞状况得以改观；</li><li>慢启动时间减少，拥塞和丢包恢复速度更快。</li></ul><blockquote><p><font color="DeepPink"><strong>大多数 HTTP 连接的时间都很短，而且是突发性的，但 TCP 只在长时间连接传输大块数据时效率才最高。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接。</strong></font></p></blockquote><blockquote><p>丢包、高 RTT 连接和 HTTP 2.0 性能<br>等一等，我听你说了一大堆每个来源一个 TCP 连接的好处，难道它就一点坏处都<br>没有吗？有，当然有。；</p><ul><li>虽然消除了 HTTP 队首阻塞现象，但 TCP 层次上仍然存在队首阻塞;</li><li>如果 TCP 窗口缩放被禁用，那带宽延迟积效应可能会限制连接的吞吐量；</li><li>丢包时，TCP 拥塞窗口会缩小。</li></ul></blockquote><blockquote><p>上述每一点都可能对 HTTP 2.0 连接的吞吐量和延迟性能造成不利影响。然而，除了这些局限性之外，实验表明一个 TCP 连接仍然是 HTTP 2.0 基础上的最佳部署策略。</p></blockquote><p><font color="DeepPink"><strong>总之，一定要知道 HTTP 2.0 与之前的版本一样，并不强制使用 TCP。UDP 等其他传输协议也并非不可以。</strong></font></p><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>在同一个 TCP 连接上传输多个数据流，就意味着要共享带宽。标定数据流的优先级有助于按序交付，但只有优先级还不足以确定多个数据流或多个连接间的资源分配。为解决这个问题，HTTP 2.0 为数据流和连接的流量控制提供了一个简单的机制：</p><ul><li>流量控制基于每一跳进行，而非端到端的控制；</li><li>流量控制基于窗口更新帧进行，即接收方广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节；</li><li>流量控制窗口大小通过WINDOW_UPDATE 帧更新，这个字段指定了流 ID 和窗口大小递增值；</li><li>流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口大小；</li><li>流量控制可以由接收方禁用，包括针对个别的流和针对整个连接。</li></ul><blockquote><p>HTTP 2.0 连接建立之后，客户端与服务器交换 SETTINGS 帧，目的是设置双向的流量控制窗口大小。除此之外，任何一端都可以选择禁用个别流或整个连接的流量控制。</p></blockquote><blockquote><p>优先级可以决定交付次序，而流量控制则可以控制 HTTP 2.0 连接中每个流占用的资源：接收方可以针对特定的流广播较低的窗口大小，以限制它的传输速度。</p></blockquote><h4 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h4><p>HTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确地请求。</p><blockquote><p>建立 HTTP 2.0 连接后，客户端与服务器交换 SETTINGS 帧，借此可以限定双向并发的流的最大数量。因此，客户端可以限定推送流的数量，或者通过把这个值设置为 0 而完全禁用服务器推送。</p></blockquote><p>为什么需要这样一个机制呢？通常的 Web 应用都由几十个资源组成，客户端需要分析服务器提供的文档才能逐个找到它们。那为什么不让服务器提前就把这些资源推送给客户端，从而减少额外的时间延迟呢？服务器已经知道客户端下一步要请求什么资源了，这时候服务器推送即可派上用场。事实上，如果你在网页里嵌入过 CSS、JavaScript，或者通过数据 URI 嵌入过其他资源，那你就已经亲身体验过服务器推送了。</p><blockquote><p>所有推送的资源都遵守同源策略。换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。</p></blockquote><h4 id="首部压缩"><a href="#首部压缩" class="headerlink" title="首部压缩"></a>首部压缩</h4><p>HTTP 的每一次通信都会携带一组首部，用于描述传输的资源及其属性。在 HTTP 1.x 中，这些元数据都是以纯文本形式发送的，通常会给每个请求增加 500~800 字节的负荷。如果算上 HTTP cookie，增加的负荷通常会达到上千字节。为减少这些开销并提升性能，HTTP 2.0 会压缩首部元数据：</p><ul><li><font color="DeepPink"><strong>HTTP 2.0 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</strong></font></li><li><font color="DeepPink"><strong>首部表在HTTP 2.0的连接存续期内始终存在，由客户端和服务器共同渐进地更新</strong></font>; </li><li><font color="DeepPink"><strong>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值</strong></font>。 </li></ul><p>于是，HTTP 2.0 连接的两端都知道已经发送了哪些首部，这些首部的值是什么，从而可以针对之前的数据只编码发送差异数据（图 12-5）。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE125HTTP2.0%E9%A6%96%E9%83%A8%E7%9A%84%E5%B7%AE%E5%BC%82%E5%8C%96%E7%BC%96%E7%A0%81.png" alt></p><blockquote><p>请求与响应首部的定义在 HTTP 2.0 中基本没有改变，只是所有首部键必须全部小写，而且请求行要独立为 :method 、 :scheme 、 :host 和 :path 这些键－值对。</p></blockquote><p>在前面的例子中，第二个请求只需要发送变化了的路径首部（:path），其他首部没有变化，不用再发送了。这样就可以避免传输冗余的首部，从而显著减少每个请求的开销。通信期间几乎不会改变的通用键－值对（用户代理、可接受的媒体类型，等等）只需发送一次。事实上，如果请求中不包含首部（例如对同一资源的轮询请求），那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部！</p><h4 id="有效的HTTP-2-0升级与发现"><a href="#有效的HTTP-2-0升级与发现" class="headerlink" title="有效的HTTP 2.0升级与发现"></a>有效的HTTP 2.0升级与发现</h4><p>通过常规非加密信道建立 HTTP 2.0 连接需要多做一点工作。因为 HTTP 1.0 和HTTP 2.0 都使用同一个端口（80），又没有服务器是否支持 HTTP 2.0 的其他任何信息，此时客户端只能使用 <font color="DeepPink"><strong>HTTP  Upgrade 机制</strong></font>通过协调确定适当的协议：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET /page HTTP/1.1</span><br><span class="line">Host: server.example.com</span><br><span class="line">Connection: Upgrade, HTTP2-Settings</span><br><span class="line">Upgrade: HTTP/2.0 ➊</span><br><span class="line">HTTP2-Settings: (SETTINGS payload) ➋</span><br><span class="line">HTTP/1.1 200 OK ➌</span><br><span class="line">Content-length: 243</span><br><span class="line">Content-type: text/html</span><br><span class="line">(... HTTP 1.1 response ...)</span><br><span class="line">(or)</span><br><span class="line">HTTP/1.1 101 Switching Protocols ➍</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: HTTP/2.0</span><br><span class="line">(... HTTP 2.0 response ...)</span><br></pre></td></tr></table></figure><p>➊ 发起带有 HTTP 2.0 Upgrade 首部的 HTTP 1.1 请求<br>➋ HTTP/2.0  SETTINGS 净荷的 Base64 URL 编码<br>➌ 服务器拒绝升级，通过 HTTP 1.1 返回响应<br>➍ 服务器接受 HTTP 2.0 升级，切换到新分帧</p><p>使用这种 Upgrade 流，如果服务器不支持 HTTP 2.0，就立即返回 HTTP 1.1 响应。否则，服务器就会以 HTTP 1.1 格式返回 101 Switching Protocols 响应，然后立即切换到 HTTP 2.0 并使用新的二进制分帧协议返回响应。无论哪种情况，都不需要额外往返。</p><blockquote><p>为确定服务器和客户端都有意使用 HTTP 2.0 对话，双方还必须发送“连接首部”，也就是一串标准的字节。这种信息交换本质上是一种“尽早失败”（fail-fast）的机制，可以避免客户端、服务器，以及中间设备偶尔接受请<br>求的升级却不理解新协议。而且，这种信息交换也不会带来额外的往返，只是在连接开始时要多传一些字节。</p></blockquote><p>最后，如果客户端因为自己保存有或通过其他手段（如 DNS 记录、手工配置等）获得了关于 HTTP 2.0 的支持信息，它也可以直接发送 HTTP 2.0 分帧，而不必依赖Upgrade 机制。有了这些信息，客户端可以一上来就通过非加密信道发送 HTTP 2.0 分帧，其他就不管了。最坏的情况，就是无法建立连接，客户端再回退一步，重新使用 Upgrade 首部，或者切换到带 ALPN 协商的 TLS 信道。</p><p><font color="DeepPink"><strong>服务器之前的 HTTP 2.0 支持信息并不能保证下一次就能可靠地建立连接。以这种方式通信的前提，就是各端都必须支持 HTTP 2.0。如果任何中间设备不支持，连接都不会成功。</strong></font></p><h3 id="二进制分帧简介"><a href="#二进制分帧简介" class="headerlink" title="二进制分帧简介"></a>二进制分帧简介</h3><p>HTTP 2.0 的根本改进还是新增的长度前置的二进制分帧层。</p><p>建立了 HTTP 2.0 连接后，客户端与服务器会通过交换帧来通信，帧是基于这个新协议通信的最小单位。所有帧都共享一个 8 字节的首部（图 12-6），其中包含帧的长度、类型、标志，还有一个保留位和一个 31 位的流标识符。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE126%E5%85%B1%E6%9C%89%E7%9A%848%E5%AD%97%E8%8A%82%E5%B8%A7%E9%A6%96%E9%83%A8.png" alt></p><ul><li>16 位的长度前缀意味着一帧大约可以携带 64 KB 数据，不包括 8 字节首部。</li><li>8 位的类型字段决定如何解释帧其余部分的内容。</li><li>8 位的标志字段允许不同的帧类型定义特定于帧的消息标志。</li><li>1 位的保留字段始终置为 0。</li><li>31 位的流标识符唯一标识 HTTP 2.0 的流。</li></ul><blockquote><p>在调试 HTTP 2.0 通信时，有人会使用自己喜欢的十六进制查看器。其实，Wireshark 及其他类似的工具也有相应的插件，使用很简单，也很人性化。比如，谷歌 Chrome 就支持 chrome://internals#spdy ，通过它可以查看通信细节。</p></blockquote><p>知道了 HTTP 2.0 规定的这个共享的帧首部，就可以自己编写一个简单的解析器，通过分析 HTTP 2.0 字节流，根据每个帧的前 8 字节找到帧的类型、标志和长度。而且，由于每个帧的长度都是预先定义好的，解析器可以迅速而准确地跳到下一帧的开始，这也是相对于 HTTP 1.x 的一个很大的性能提升。</p><p>知道了帧类型，解析器就知道该如何解释帧的其余内容了。HTTP 2.0 规定了如下帧类型。</p><ul><li>DATA：用于传输 HTTP 消息体。</li><li>HEADERS：用于传输关于流的额外的首部字段。</li><li>PRIORITY：用于指定或重新指定引用资源的优先级。</li><li>RST_STREAM：用于通知流的非正常终止。</li><li>SETTINGS：用于通知两端通信方式的配置数据。</li><li>PUSH_PROMISE：用于发出创建流和服务器引用资源的要约。</li><li>PING：用于计算往返时间，执行“活性”检查。</li><li>GOAWAY：用于通知对端停止在当前连接中创建流。</li><li>WINDOW_UPDATE：用于针对个别流或个别连接实现流量控制。</li><li>CONTINUATION：用于继续一系列首部块片段。</li></ul><blockquote><p>服务器可以利用 GOAWAY 类型的帧告诉客户端要处理的最后一个流的 ID，从而消除一些请求竞争，而且浏览器也可以据此智能地重试或取消“悬着的”请求。这也是保证复用连接安全的一个重要和必要的功能！</p></blockquote><p>既然有了这个分帧层，即使它对我们的应用不可见，我们也应该更进一步，分析一下两种最常见的工作流：发起新流和交换应用数据。只有明白了一个请求或响应如何转换成一个一个的帧，才能理解 HTTP 2.0 对性能的提升来自哪里。</p><blockquote><p>固定长度与可变长度字段<br>HTTP 2.0 只使用固定长度字段，HTTP 2.0 帧占用带宽很少（帧首部是 8 字节）。采用可变长度编码的确可以节省一点带宽和时延，但却无法抵偿由此带来的分析复杂性。<br>即使可变长度编码能减少 50% 的带宽占用，那么在 1 Mbit/s 的连接上传输 1400 字节的分组，也只能节省 4 字节（0.3%）和每帧不到 100 纳秒的延迟时间。</p></blockquote><h4 id="发起新流"><a href="#发起新流" class="headerlink" title="发起新流"></a>发起新流</h4><p>在发送应用数据之前，必须创建一个新流并随之发送相应的元数据，比如流优先级、HTTP 首部等。HTTP 2.0 协议规定客户端和服务器都可以发起新流，因此有两种可能：</p><ul><li>客户端通过发送HEADERS 帧来发起新流（图 12-7），这个帧里包含带有新流 ID 的公用首部、可选的 31 位优先值，以及一组 HTTP 键－值对首部；</li><li>服务器通过发送PUSH_PROMISE 帧来发起推送流，这个帧与 HEADERS 帧等效，但它包含“要约流 ID”，没有优先值。</li></ul><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE127%E5%B8%A6%E4%BC%98%E5%85%88%E5%80%BC%E7%9A%84HEADERS%E5%B8%A7.png" alt></p><p>这两种帧的类型字段都只用于沟通新流的元数据，净荷会在 DATA 帧中单独发送。同样，由于两端都可以发起新流，流计数器偏置：客户端发起的流具有偶数 ID，服务器发起的流具有奇数 ID。这样，两端的流 ID 不会冲突，而且各自持有一个简单的计数器，每次发起新流时递增 ID 即可。</p><blockquote><p>由于流的元数据与应用数据是单独发送的，因此客户端和服务器可以分别给它们设定不同的优先级。比如，“控制流量”的流优先级可以高一些，但只将其应用给 DATA 帧。</p></blockquote><h4 id="发送应用数据"><a href="#发送应用数据" class="headerlink" title="发送应用数据"></a>发送应用数据</h4><p>创建新流并发送 HTTP 首部之后，接下来就是利用 DATA 帧（图 12-8）发送应用数据。应用数据可以分为多个 DATA 帧，最后一帧要翻转帧首部的 END_STREAM 字段。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE128DATA%E5%B8%A7.png" alt></p><p>数据净荷不会被另行编码或压缩。编码方式取决于应用或服务器，纯文本、gzip 压缩、图片或视频压缩格式都可以。既然如此，关于 DATA 帧再也没有什么新东西好说了！整个帧由公用的 8 字节首部，后跟 HTTP 净荷组成。</p><blockquote><p>从技术上说， DATA 帧的长度字段决定了每帧的数据净荷最多可达 2^16-1（65 535）字节。可是，为减少队首阻塞，HTTP 2.0 标准要求 DATA 帧不能超过 2^14 -1（16383）字节。长度超过这个阀值的数据，就得分帧发送。</p></blockquote><h4 id="HTTP-2-0帧数据流分析"><a href="#HTTP-2-0帧数据流分析" class="headerlink" title="HTTP 2.0帧数据流分析"></a>HTTP 2.0帧数据流分析</h4><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE123HTTP2.0%E5%9C%A8%E5%85%B1%E4%BA%AB%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%B8%8A%E5%90%8C%E6%97%B6%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.png" alt></p><ul><li>有 3 个活动的流：stream 1、stream 3 和 stream 5。</li><li>3 个流的 ID 都是奇数，说明都是客户端发起的。</li><li>这里没有服务器发起的流。</li><li>服务器发送的 stream 1 包含多个DATA 帧，这是对客户端之前请求的响应数据。</li><li>这也说明在此之前已经发送过 HEADERS 帧了。</li><li>服务器在交错发送 stream 1 的DATA 帧和 stream 3 的 HEADERS 帧，这就是响应的多路复用！</li><li>客户端正在发送 stream 5 的DATA 帧，表明 HEADERS 帧之前已经发送过了。</li></ul><p>简言之，图 12-3 中连接正在并行传送 3 个数据流，每个流都处于各自处理周期的不同阶段。服务器决定帧的顺序，而我们不用关心每个流的类型或内容。stream 1 携带的数据量可能比较大，也许是视频，但它不会阻塞共享连接中的其他流！</p><h2 id="优化应用的交付"><a href="#优化应用的交付" class="headerlink" title="优化应用的交付"></a>优化应用的交付</h2><p><font color="DeepPink"><strong>事实上，影响绝大多数 Web 应用性能的并非带宽，而是延迟。</strong></font>网速虽然越来越快，但不幸的是，延迟似乎并没有缩短。</p><blockquote><p>说到底，成功的、可持续的 Web 性能优化策略其实很简单：先度量，然后拿业务目标与性能指标进行比较，采取优化措施，紧了松点，松了紧点，如此反复。开发和购买合用的度量工具及选择恰当的度量手段具有最高优先级；</p></blockquote><h3 id="经典的性能优化最佳实践"><a href="#经典的性能优化最佳实践" class="headerlink" title="经典的性能优化最佳实践"></a>经典的性能优化最佳实践</h3><p>无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优化最佳实践，是其他数十条性能准则的出发点。</p><ul><li>减少DNS查找<br>每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻塞后续请求。</li><li>重用TCP连接<br>尽可能使用持久连接，以消除 TCP 握手和慢启动延迟。</li><li>减少HTTP重定向<br>HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时；这里面既有额外的 DNS 查询、TCP 握手，还有其他延迟。最佳的重定向次数为零。</li><li>使用CDN（内容分发网络）<br>把数据放到离用户地理位置更近的地方，可以显著减少每次 TCP 连接的网络延迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容(比如：不缓存的原始获取)。</li><li>去掉不必要的资源<br>任何请求都不如没有请求快。</li></ul><blockquote><p>不缓存的原始获取<br>使用 CDN 或代理服务器取得资源的技术，如果要根据用户定制或者涉及隐私数据，则不能做到全球缓存，这种情况被称为“不缓存的原始获取”（uncached origin fetch）。<br>虽然只有把数据缓存到全球各地的服务器上 CDN 才能发挥最大的效用，但“不缓存的原始获取”仍然具有性能优势：客户端连接终止于附近的服务器，从而显著减少握手延迟。相应地，CDN 或你的代理服务器可以维护一个“热连接池”（warm connection pool），通过它将数据转发给原始服务器，同时做到对客户端快速响应。<br>事实上，作为附加的一个优化层，CDN 提供商在连接两端都会使用邻近服务器！客户端连接终止于邻近 CDN 节点，该节点将请求转发到与对端服务器邻近的 CDN节点，之后请求才会被路由到原始服务器。CDN 网络中多出来这一跳，可以让数据在优化的 CDN 骨干网中寻路，从而进一步减少客户端与服务器之间的延迟。</p></blockquote><ul><li>在客户端缓存资源<br>应该缓存应用资源，从而避免每次请求都发送相同的内容。</li><li>传输压缩过的内容<br>传输前应该压缩应用资源，把要传输的字节减至最少：确保对每种要传输的资源采用最好的压缩手段。</li><li>消除不必要的请求开销<br>减少请求的 HTTP 首部数据（比如 HTTP cookie），节省的时间相当于几次往返的延迟时间。</li><li>并行处理请求和响应<br>请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽视，但却会无谓地导致很长延迟。</li><li>针对协议版本采取优化措施<br>HTTP 1.x 支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而言，HTTP 2.0 只要建立一个连接就能实现最优性能，同时无需针对 HTTP 1.x 的那些优化方法。</li></ul><h4 id="在客户端缓存资源"><a href="#在客户端缓存资源" class="headerlink" title="在客户端缓存资源"></a>在客户端缓存资源</h4><p>要说最快的网络请求，那就是不用发送请求就能获取资源。将之前下载过的数据缓存并维护好，就可以做到这一点。对于通过 HTTP 传输的资源，要保证首部包含适当的缓存字段：</p><ul><li>Cache-Control 首部用于指定缓存时间；</li><li>Last-Modified 和 ETag 首部提供验证机制。</li></ul><p>只要可能，就给每种资源都指定一个明确的缓存时间。这样客户端就可以直接使用本地副本，而不必每次都请求相同的内容。类似地，指定验证机制可以让客户端检查过期的资源是否有更新。没有更新，就没必要重新发送。</p><p>最后，还要注意应同时指定缓存时间和验证方法！只指定其中之一是最常见的错误，于是要么导致每次都在没有更新的情况下重发相同内容（这是没有指定验证），要么导致每次使用资源时都多余地执行验证检查（这是没有指定缓存时间）。</p><h4 id="压缩传输的数据"><a href="#压缩传输的数据" class="headerlink" title="压缩传输的数据"></a>压缩传输的数据</h4><p>利用本地缓存可以让客户端避免每次请求都重复取得数据。不过，还是有一些资源是必须取得的，比如原来的资源过期了，或者有新资源，再或者资源不能缓存。对于这些资源，应该保证传输的字节数最少。因此要保证对它们进行最有效的压缩。</p><p>HTML、CSS 和 JavaScript 等文本资源的大小经过 gzip 压缩平均可以减少 60%~80%。而图片则需要仔细考量：</p><ul><li>图片一般会占到一个网页需要传输的总字节数的一半；</li><li>通过去掉不必要的元数据可以把图片文件变小；</li><li>要调整大小就在服务器上调整，避免传输不必要的字节；</li><li>应该根据图像选择最优的图片格式；</li><li>尽可能使用有损压缩。</li></ul><p>不同图片格式的压缩率迥然不同，因为不同的格式是分别为不同使用场景设计的。事实上，如果选错了图片格式（比如，使用了 PNG 而非 JPG 或 WebP），多产生几百甚至上千 KB 数据是轻而易举的事。建议大家多找一些工具和自动化手段，以确定最佳图片格式。</p><p>选定图片格式后，其次就是不要让图片超过它需要的大小。如果在客户端对超出需要大小的图片做调整，那么除了额外传输不必要的字节之外，还会浪费 CPU、GPU和内存资源。</p><p>最后，选择了正确的格式，确定了必需的大小，接下来就要研究使用哪一种有损图片格式，比如 JPEG 还是 WebP，以及压缩到哪个级别：较高压缩率可以明显减少字节数，同时图片品质不会有太大或太明显的损失，尤其是在较小（手机）的屏幕上看，不容易发现。</p><blockquote><p>WebP：Web 上的新图片格式<br>WebP 是谷歌开发的一种新图片格式，得到了 Chrome 和 Opera 浏览器支持。这种格式的无损压缩和有损压缩效能都有所提升：</p><ul><li>WebP 的无损压缩图片比 PNG 的小 26%；</li><li>WebP 的有损压缩图片比 JPG 的小 25%~34%；</li><li>WebP 支持无损透明压缩，但因此仅增加 22% 的字节。</li></ul></blockquote><blockquote><p>在现有网页平均 1 MB 大小，其中图片占一半的情况下，WebP 节省的 20%~30%，对每个页面而言就是几百 KB。这种格式需要客户端 CPU 多花点时间解码（大约相当于处理 JPG 的 1.4 倍），但字节的节省完全可以补偿处理时间的增长。此外，由于数据流量的限制和高速网络的存在，对很多用户而言，节省字节才是当务之急。<br>事实上，Chrome Data Compression Proxy 和 Opera Turbo 等工具为用户降低带宽占用的主要手段，就是重新把每张图片编码为 WebP 格式。正常情况下，Chrome Data Compression Proxy 的数据压缩率可以达到 50%，这说明我们自己的应用也有很多可以通过压缩提升性能的空间。</p></blockquote><h4 id="消除不必要的请求字节"><a href="#消除不必要的请求字节" class="headerlink" title="消除不必要的请求字节"></a>消除不必要的请求字节</h4><p>HTTP 是一种无状态协议，也就是说服务器不必保存每次请求的客户端的信息。然而，很多应用又依赖于状态信息以实现会话管理、个性化、分析等功能。为了实现这些功能，HTTP State Management Mechanism（RFC 2965）作为扩展，允许任何网站针对自身来源关联和更新 cookie 元数据：浏览器保存数据，而在随后发送给来源的每一个请求的 Cookie 首部中自动附加这些信息。</p><p>上述标准并未规定 cookie 最大不能超过多大，但实践中大多数浏览器都将其限制为4 KB。与此同时，该标准还规定每个站点针对其来源可以有多个关联的 cookie。于是，一个来源的 cookie 就有可能多达几十 KB ！不用说，这么多元数据随请求传递，必然会给应用带来明显的性能损失：</p><ul><li>浏览器会在每个请求中自动附加关联的 cookie 数据；</li><li>在 HTTP 1.x 中，包括 cookie 在内的所有 HTTP 首部都会在不压缩的状态下传输；</li><li>在 HTTP 2.0 中，这些元数据经过压缩了，但开销依然不小； </li><li>最坏的情况下，过大的 HTTP cookie 会超过初始的 TCP 拥塞窗口，从而导致多余的网络往返。</li></ul><p>应该认真对待和监控 cookie 的大小，确保只传输最低数量的元数据，比如安全会话令牌。同时，还应该利用服务器上共享的会话缓存，从中查询缓存的元数据。更好的结果，则是完全不用cookie。比如，在请求图片、脚本和样式表等静态资源时，<br>浏览器绝大多数情况下不必传输特定于客户端的元数据。</p><blockquote><p>在使用 HTTP 1.x 的情况下，可以指定一个专门的“无需 cookie”的来源服务器。这个服务器可以用于交付那些不区分客户端的共用资源。</p></blockquote><h3 id="针对HTTP-1-x的优化建议"><a href="#针对HTTP-1-x的优化建议" class="headerlink" title="针对HTTP 1.x的优化建议"></a>针对HTTP 1.x的优化建议</h3><p>针对 HTTP 1.x 的优化次序很重要：首先要配置服务器以最大限度地保证 TCP 和TLS 的性能最优，然后再谨慎地选择和采用移动及经典的应用最佳实践，之后再度量，迭代。</p><p>采用了经典的应用优化措施和适当的性能度量手段，还要进一步评估是否有必要为应用采取特定于 HTTP 1.x 的优化措施（其实是权宜之计）。</p><ul><li>利用HTTP管道<br>如果你的应用可以控制客户端和服务器这两端，那么使用管道可以显著减少网络延迟。</li><li>采用域名分区<br>如果你的应用性能受限于默认的每来源 6 个连接，可以考虑将资源分散到多个来源。</li><li>打包资源以减少HTTP请求<br>拼接和精灵图等技巧有助于降低协议开销，又能达成类似管道的性能提升。</li><li>嵌入小资源<br>考虑直接在父文档中嵌入小资源，从而减少请求数量。</li></ul><p>管道缺乏支持，而其他优化手段又各有各的利弊。事实上，这些优化措施如果过于激进或使用不当，反倒会伤害性能。总之，要有务实的态度，通过度量来评估各种措施对性能的影响，在此基础上再迭代改进。天底下就没有包治百病的灵丹妙药。</p><blockquote><p>对了，还有最后一招儿 —— 升级到 HTTP 2.0。仅此一招儿抵得上前面提到的大多数针对 HTTP 1.x 的优化手段！ HTTP 2.0 不光能让应用加载更快，还能让开发更简单。</p></blockquote><h3 id="针对HTTP-2-0的优化建议"><a href="#针对HTTP-2-0的优化建议" class="headerlink" title="针对HTTP 2.0的优化建议"></a>针对HTTP 2.0的优化建议</h3><p>HTTP 2.0 的主要目标就是提升传输性能，实现客户端与服务器间较低的延迟和较高的吞吐量。显然，在 TCP 和 TLS 之上实现最佳性能，同时消除不必要的网络延迟，从来没有如此重要过。最低限度：</p><ul><li>服务器的初始cwnd 应该是 10 个分组；</li><li>服务器应该通过 ALPN（针对 SPDY 则为 NPN）协商支持 TLS；</li><li>服务器应该支持 TLS 恢复以最小化握手延迟。 </li></ul><p>接下来，或许有点意外，那就是采用移动及其他经典的最佳做法：少发数据、削减请求，根据无线网络情况调整资源供给。不管使用什么版本的协议，减少传输的数据量和消除不必要的网络延迟，对任何应用都是最有效的优化手段。</p><p>最后，杜绝和忘记域名分区、文件拼接、图片精灵等不良的习惯，这些做法在HTTP 2.0 之上完全没有必要。事实上，继续使用这些手段反而有害！可以利用HTTP 2.0 内置的多路分发以及服务器推送等新功能。</p><h4 id="去掉对1-x的优化"><a href="#去掉对1-x的优化" class="headerlink" title="去掉对1.x的优化"></a>去掉对1.x的优化</h4><p>针对 HTTP 2.0 和 HTTP 1.x 的优化策略没有什么重叠。因此，不仅不必担心 HTTP 1.x 协议的种种限制，而且要撤销原先那些必要的做法。</p><ul><li>每个来源使用一个连接<br>HTTP 2.0 通过将一个 TCP 连接的吞吐量最大化来提升性能。事实上，在 HTTP 2.0 之下再使用多个连接（比如域名分区）反倒成了一种反模式，因为多个连接会抵消新协议中首部压缩和请求优先级的效用。</li><li>去掉不必要的文件合并和图片拼接<br>打包资源的缺点很多，比如缓存失效、占用内存、延缓执行，以及增加应用复杂性。有了 HTTP 2.0，很多小资源都可以并行发送，导致打包资源的效率反而更低。</li><li>利用服务器推送<br>之前针对 HTTP 1.x 而嵌入的大多数资源，都可以而且应该通过服务器推送来交付。这样一来，客户端就可以分别缓存每个资源，并在页面间实现重用，而不必把它们放到每个页面里了。</li></ul><p>要获得最佳性能，应该尽可能把所有资源都集中在一个域名之下。域名分区在 HTTP 2.0 之下属于反模式，对发挥协议的性能有害：分区是开始，之后影响会逐渐扩散。打包资源不会影响 HTTP 2.0 协议本身，但对缓存性能和执行速度有负面影响。</p><p>类似地，把嵌入资源改为服务器推送能提升客户端的缓存性能，又不会导致额外网络延迟。事实上，由于 3G 和 4G 网络的往返时间更长，因而服务器推送对移动应用来说效果更明显。</p><blockquote><p>HTTP 2.0 中的打包与协议开销<br>由于 HTTP 1.x 做不到多路复用，而且每次请求的协议开销很高，这才有了连接和拼合等打包技术。在 HTTP 2.0 之下，多路复用已经不成问题，首部压缩也可以降低每次 HTTP 请求要传输的元数据量，打包技术在多数情况下都不再需要了。<br>不过，请求开销只是减少了，并没有等于零。少数情况下，某些资源必须一块使用，而且更新也不频繁，此时使用打包技术仍然可以提升性能。但这些情况很少见，可以算作例外。具体措施可以通过性能度量确定。</p></blockquote><h4 id="双协议应用策略"><a href="#双协议应用策略" class="headerlink" title="双协议应用策略"></a>双协议应用策略</h4><p>遗憾的是，升级到 HTTP 2.0 不会在一夜之间完成。因此，很多应用都需要认真考虑双协议并存的部署策略，即同一个应用既能通过 HTTP 1.x 交付，也能通过 HTTP2.0 交付，无需任何改动。然而，过于激进的 HTTP 1.x 优化可能伤害 HTTP 2.0 性能，反之亦然。</p><p>如果应用可以同时控制服务器和客户端，那倒简单了，因为它可以决定使用什么协议。但大多数应用不能也无法控制客户端，只有采用一种混合或自动策略，以适应两种协议并存的现实。下面我们就分析几种可能的情况。</p><ul><li>相同的应用代码，双协议部署<br>相同的应用代码可能通过 HTTP 1.x 也可能通过 HTTP 2.0 交付。可能任何一种协议之下都达不到最佳性能，但可以追求性能足够好。所谓足够好，需要通过针对每一种应用单独度量来保证。这种情况下，第一步可以先撤销域名分区以实现HTTP 2.0 交付。然后，随着更多用户迁移到 HTTP 2.0，可以继续撤销资源打包并尽可能利用服务器推送。</li><li>分离应用代码，双协议部署<br>根据协议不同分别交付不同版本的应用。这样会增加运维的复杂性，但实践中对很多应用倒是十分可行。比如，一台负责完成连接的边界服务器可以根据协商后的协议版本，把客户端请求引导至适当的服务器。</li><li>动态HTTP 1.x和HTTP 2.0优化<br>某些自动化的 Web 优化框架，以及开源及商业产品，都可以在响应请求时动态重写交付的应用代码（包括连接、拼合、分区，等等）。此时，服务器也可以考虑协商的协议版本，并动态采用适当的优化策略。</li><li>HTTP 2.0，单协议部署<br>如果应用可以控制服务器和客户端，那没理由不只使用 HTTP 2.0。事实上，如果真有这种可能，那就应该专一使用 HTTP 2.0。</li></ul><p>选择路线时，要看当前的基础设施、应用的复杂程度，以及用户的构成。让人哭笑不得的是，那些在 HTTP 1.x 优化上投资很大的应用，反倒在这种情况下最难办。如果你能控制客户端，有自动的应用优化策略，或者没有使用任何特定于 1.x 的优化，那么就可以专注于 HTTP 2.0，而没有后顾之忧了。</p><blockquote><p>使用 PageSpeed 实现动态优化<br>谷歌的 PageSpeed Optimization Libraries（PSOL）提供了 40 多种“Web 优化过滤器”的开源实现，可以集成到任何服务器运行时，动态应用各种优化策略。</p></blockquote><blockquote><p>在使用 PSOL 库的情况下， mod_pagespeed （Apache）和 ngx_pagespeed （Nginx）模块都可以基于指定的优化过滤器（如嵌入、压缩、拼接、分片等）实现动态重写，并优化资源交付方式。每次优化都在请求时动态应用（并被缓存），整个优化过程完全自动化了。<br>在动态优化下，服务器还可以根据所用协议，甚至用户代理的类型和版本调整优化策略。比如，可以配置 mod_pagespeed 模块，在客户端使用 HTTP 2.0 时跳过某些优化：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#  对 SPDY/HTTP 2.0 客户端禁用拼接</span><br><span class="line">&lt;ModPagespeedIf spdy&gt;</span><br><span class="line">ModPagespeedDisableFilters combine_css,combine_javascript</span><br><span class="line">&lt;/ModPagespeedIf&gt;</span><br><span class="line">#  只对 HTTP 1.x 客户端使用域名分区</span><br><span class="line">&lt;ModPagespeedIf !spdy&gt;</span><br><span class="line">ModPagespeedShardDomain www.site.com s1.site.com,s2.site.com</span><br><span class="line">&lt;/ModPagespeedIf&gt;</span><br></pre></td></tr></table></figure><blockquote><p>使用 PageSpeed 这样的自动 Web 优化库，可以让我们省去不少麻烦，值得考虑。</p></blockquote><h4 id="1-x与2-0的相互转换"><a href="#1-x与2-0的相互转换" class="headerlink" title="1.x与2.0的相互转换"></a>1.x与2.0的相互转换</h4><p>除了双协议优化策略，很多已部署的应用都需要在自己的应用服务器上采取一种折中方案：两端都是 HTTP 2.0 是追求最佳性能的目标，但（新增）一个转换层（图13-2）也可以让 1.x 服务器利用 HTTP 2.0。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE132HTTP20%E5%88%B01x%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%8D%B3%E5%B0%86%E6%B5%81%E8%BD%AC%E6%8D%A2%E4%B8%BA1x%E8%AF%B7%E6%B1%82.png" alt></p><p>一台居间服务器可以接受 HTTP 2.0 会话，处理之后再向既有基础设施分派 1.x 格式的请求。接到响应后，再将其转换成 HTTP 2.0 的流并返回客户端。通常，这是应用 HTTP 2.0 更新的最简单方式，因为这样可以重用已有的 1.x 基础设施，而且基本不用修改。</p><blockquote><p>大多数支持 HTTP 2.0 的 Web 服务器默认都提供 2.0 到 1.x 的转换机制：2.0 会话终止于服务器（Apache 或 Nginx），如果服务器被配置为反向代理，那么分派给具体应用服务器的就是 1.x 请求。</p></blockquote><p>然而，2.0 到 1.x 的这种简单策略并非长久之计。从很多方面来说，这种工作流实际是一种倒退。真正正确的做法，不是把优化的、可复用的会话转换成一系列 1.x请求，因基础设施而废优化，而是相反：把接收到的 1.x 客户端请求转换成 2.0 流，并把我们的基础设施标准化，使其在任何时候都处理 2.0 会话。</p><p>为获得最佳性能，同时实现低延迟和实时的 Web 应用，应该要求我们的内部基础设施达到如下标准：</p><ul><li><font color="DeepPink"><strong>负载均衡器和代理与应用的连接应该持久化</strong></font>；</li><li><font color="DeepPink"><strong>请求和响应流及多路复用应该是默认配置</strong></font>；</li><li><font color="DeepPink"><strong>与应用服务器的通信应该基于消息</strong></font>；</li><li><font color="DeepPink"><strong>客户端与应用服务器的通信应该是双向的</strong></font>。 </li></ul><p><font color="DeepPink"><strong>端到端的 HTTP 2.0 会话符合上述所有条件，能实现对客户端以及数据中心内部的低延迟交付：无需定制的 RPC 层及相应机制，就能实现内部服务之间的通信，并获得理想的性能。</strong></font>简言之，不要把 2.0 降级到 1.x，这不是长久之计。长久之计是把1.x 升级到 2.0，这样才能求得最佳性能。</p><h4 id="评估服务器质量与性能"><a href="#评估服务器质量与性能" class="headerlink" title="评估服务器质量与性能"></a>评估服务器质量与性能</h4><p>HTTP 2.0 服务器实现的质量对客户端性能影响很大。HTTP 服务器的配置当然是一个重要因素，但服务器实现逻辑的质量同样与优先级、服务器推送、多路复用等性能机制的发挥紧密相关。</p><ul><li>HTTP 2.0 服务器必须理解流优先级；</li><li>HTTP 2.0 服务器必须根据优先级处理响应和交付资源；</li><li>HTTP 2.0 服务器必须支持服务器推送；</li><li>HTTP 2.0 服务器应该提供不同推送策略的实现。</li></ul><p>HTTP 2.0 服务器的初级实现也能支持某些功能，但不能明确支持请求的优先级和服务器推送，可能导致次优性能。比如，发送大型、静态图片导致带宽饱和，而客户端又因为其他重要资源（如 CSS 或 JavaScript）被阻塞。</p><blockquote><p>为尽可能获得最佳性能，HTTP 2.0 客户端必须是个“乐观主义者”：尽可能早地发送所有请求，然后完全听凭服务器的优化。事实上，HTTP 2.0 客户端对服务器的依赖程度较之以前更甚。</p></blockquote><h4 id="2-0与TLS"><a href="#2-0与TLS" class="headerlink" title="2.0与TLS"></a>2.0与TLS</h4><p>实践中，由于存在很多不兼容的中间代理，早期的 HTTP 2.0 部署必然依赖加密信道。这样一来，我们就面临两种可能出现 ALPN 协商和 TLS 终止的情况：</p><ul><li>TLS 连接可能会在 HTTP 2.0 服务器上终止；</li><li>TLS 连接可能会在上游（如负载均衡器）上终止。</li></ul><p>第一种情况要求 HTTP 2.0 服务器能够处理 TLS，除此之外就没有什么了。第二种情况复杂一些：TLS+ALPN 握手可能会在上游代理处终止（图 13-3），然后再从那里建立一条加密信道，或者直接将非加密的 HTTP 2.0 流发送到服务器。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE133%E6%94%AF%E6%8C%81TLSALPN%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8.png" alt></p><p>代理和应用服务器之间使用安全信道还是非加密信道，取决于应用：只要能控制中间设备，就可以保证未加密的帧不会被修改或丢弃。那么，虽然大多数 HTTP 2.0 服务器都应该支持 TLS+ALPN 协商，但它们同时也应该在不加密的情况下实现HTTP 2.0 通信。</p><p>另外，智能负载均衡器也可以使用 TLS+ALPN 协商机制，根据协商后的协议，选择性地将不同的客户端路由到不同的服务器。</p><h4 id="负载均衡器、代理及应用服务器"><a href="#负载均衡器、代理及应用服务器" class="headerlink" title="负载均衡器、代理及应用服务器"></a>负载均衡器、代理及应用服务器</h4><p>根据现有基础设施以及应用的复杂程度和规模，你的基础设施中可能需要一台或多台负载均衡器（图 13-4）或者 HTTP 2.0 代理。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE134%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8%E4%B8%8ETLS%E7%BB%88%E6%AD%A2%E7%AD%96%E7%95%A5.png" alt></p><p>最简单的情况下，HTTP 2.0 服务器与客户端直接对话，并负责完成 TLS 连接，进行 ALPN 协商，以及处理所有请求。</p><p>然而，一台服务器对于大型应用是不够的。大型应用必须要添加一台负载均衡器，以分流大量请求。此时，负载均衡器可以终止 TLS 连接（参见 上节 “2.0 与TLS”），也可以经过配置作为 TCP 代理并直接将加密数据发送给应用服务器。</p><blockquote><p>很多云提供商也会提供负载均衡器服务。然而，这些负载均衡器大多支持TLS 终止，却不支持 ALPN 协商，而这对于通过 TLS 实现 HTTP 2.0 通信是必需的。在这种情况下，应该将负载均衡器配置为 TCP 代理，即通过它们将加密数据发送给应用服务器，让应用服务器完成 TLS+ALPN 协商。</p></blockquote><p>实践中，要回答的最重要的一个问题，就是你的基础设施中的哪个组件负责终止TLS 连接，以及它是否能够执行必要的 ALPN 协商？</p><ul><li>要在 TLS 之上实现 HTTP 2.0 通信，终端服务器必须支持 ALPN；</li><li>尽可能在接近用户的地方终止 TLS；</li><li>如果无法支持 ALPN，那么选择 TCP 负载均衡模式；</li><li>如果无法支持 ALPN 且 TCP 负载均衡也做不到，那么就退而求其次，在非加密</li><li>信道上使用 HTTP 的 Upgrade 流</li></ul><h1 id="浏览器API与协议"><a href="#浏览器API与协议" class="headerlink" title="浏览器API与协议"></a>浏览器API与协议</h1><h2 id="浏览器网络概述"><a href="#浏览器网络概述" class="headerlink" title="浏览器网络概述"></a>浏览器网络概述</h2><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE141%E9%AB%98%E5%B1%82%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BD%91%E7%BB%9CAPI%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%9C%8D%E5%8A%A1.png" alt></p><h3 id="连接管理与优化"><a href="#连接管理与优化" class="headerlink" title="连接管理与优化"></a>连接管理与优化</h3><p>运行在浏览器中的 Web 应用并不负责管理个别网络套接字的生命周期，这是好事。通过把这个任务委托给浏览器，可以自动化很多重要的性能优化任务，包括套接字重用、请求优先级排定、晚绑定、协议协商、施加连接数限制，等等。<font color="DeepPink"><strong>事实上，浏览器是有意把请求管理生命周期与套接字管理分开的。</strong></font>这一点很微妙，但却至关重要。</p><p>套接字是以池的形式进行管理的（图 14-2），即按照来源，每个池都有自己的连接限制和安全约束。挂起的请求是排好队的、有优先次序的，然后再适时把它们绑定到池中个别的套接字上。除非服务器有意关闭连接，否则同一个套接字可以自动用于多个请求！</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE142%E8%87%AA%E5%8A%A8%E7%AE%A1%E7%90%86%E7%9A%84%E5%A5%97%E6%8E%A5%E5%AD%97%E6%B1%A0%E5%9C%A8%E6%89%80%E6%9C%89%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BF%9B%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB.png" alt></p><ul><li>来源<br>由应用协议、域名和端口三个要件构成，比如 (http, <a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a>, 80) 与(https, <a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a>, 443) 就是两个不同的来源。</li><li>套接字池<br>属于同一个来源的一组套接字。实践中，所有主流浏览器的最大池规模都是 6 个套接字。</li></ul><p>自动化的套接字池管理会自动重用 TCP 连接，从而有效保障性能。除此之外，这种架构设计还提供了其他优化的机会：</p><ul><li>浏览器可以按照优先次序发送排队的请求；</li><li>浏览器可以重用套接字以最小化延迟并提升吞吐量；</li><li>浏览器可以预测请求提前打开套接字；</li><li>浏览器可以优化何时关闭空闲套接字；</li><li>浏览器可以优化分配给所有套接字的带宽。</li></ul><blockquote><p>谷歌 Chrome 的推测性网络优化<br>我们已经知道了，现代浏览器的网络组件并非一个套接字管理器那么简单。但是，即使如此有时候也足以客观地评价现代浏览器中的某些优化技术。<br>比如，你使用谷歌 Chrome 浏览器的次数越多，它的速度就会越快。Chrome 会学习访问过的站点的拓扑，以及常见的浏览模式，然后利用这些信息进行各种“推测性优化”，以预测用户下一步的操作，从而消除不必要的网络延迟：DNS 预解析、TCP 预连接、页面预渲染，等等。像鼠标悬停在链接上这么个简单的动作，就可以触发浏览器向其网络组件的“预测器”发送信号，后者则会依据过往的性能数据选择最佳的优化措施。<br>如果你对Chrome 浏览器的网络优化技术感兴趣，可以看看这篇文章“High Performance Networking in Google Chrome”：<a href="http://hpbn.co/chrome-networking" target="_blank" rel="noopener">http://hpbn.co/chrome-networking</a>。</p></blockquote><h3 id="网络安全与沙箱"><a href="#网络安全与沙箱" class="headerlink" title="网络安全与沙箱"></a>网络安全与沙箱</h3><p><font color="DeepPink"><strong>将个别套接字的管理任务委托给浏览器还有另一个重要的用意：可以让浏览器运用沙箱机制，对不受信任的应用代码采取一致的安全与策略限制。</strong></font>比如，浏览器不允许直接访问原始网络套接字 API，因为这样给恶意应用向任意主机发起任意请求（端口扫描、连接邮件服务器或发送未知消息）提供可乘之机。</p><ul><li>连接限制<br>浏览器管理所有打开的套接字池并强制施加连接数限制，保护客户端和服务器的资源不会被耗尽。</li><li>请求格式化与响应处理<br>浏览器格式化所有外发请求以保证格式一致和符合协议的语义，从而保护服务器。类似地，响应解码也会自动完成，以保护用户。</li><li>TLS 协商<br>浏览器执行 TLS 握手和必要的证书检查。任何证书有问题（比如服务器正在使用自已签发的证书），用户都会收到通知。</li><li>同源策略<br>浏览器会限制应用只能向哪个来源发送请求。</li></ul><p>以上列出的安全限制机制只是一部分，但已经可以体现“最低特权”（least privilege）原则了。浏览器只向应用代码公开那些必要的 API 和资源：应用提供数据和 URL，浏览器执行请求并负责管理每个连接的整个生命周期。</p><blockquote><p>有必要提一句，并没有单独一条原则叫“同源策略”。实际上，这是一组相关的机制，涉及对 DOM 访问、cookie 和会话状态管理、网络及其他浏览器组件的限制。</p></blockquote><h3 id="资源与客户端状态缓存"><a href="#资源与客户端状态缓存" class="headerlink" title="资源与客户端状态缓存"></a>资源与客户端状态缓存</h3><p>最好最快的请求是没有请求。在分派请求之前，浏览器会自动检查其资源缓存，执行必要的验证，然后在满足限制条件的情况下返回资源的本地副本。类似地，如果某本地资源不在缓存中，那么浏览器就会发送网络请求，将响应自动填充到缓存中，<br>以备后续访问使用。</p><ul><li>浏览器针对每个资源自动执行缓存指令。</li><li>浏览器会尽可能恢复失效资源的有效性。</li><li>浏览器会自动管理缓存大小及资源回收。</li></ul><p><font color="DeepPink"><strong>浏览器还有一个经常被人忽视的重要功能，那就是提供会话认证和 cookie 管理。浏览器为每个来源维护着独立的 cookie 容器，为读写新 cookie、会话和认证数据提供必要的应用及服务器 API，还会为我们自动追加和处理 HTTP 首部，让一切都自动化。</strong></font></p><blockquote><p>举一个简单但直观的例子，它能说明把会话状态管理委托给浏览器的好处：认证的会话可以在多个标签页或浏览器口间共享，反之亦然；如果用户在某个标签页中退出，那么其他所有打开窗口中的会话都将失效。</p></blockquote><h3 id="应用API与协议"><a href="#应用API与协议" class="headerlink" title="应用API与协议"></a>应用API与协议</h3><p><img src="/images/high-performance-browser-networking-note/%E8%A1%A8141XHRSSE%E5%92%8CWebSocket%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7.png" alt></p><blockquote><p>我们在这个表中有意忽略了 WebRTC，因为那是一种端到端的交付模型，与 XHR、SSE 和 WebSocket 协议有着根本的不同。</p></blockquote><h2 id="XMLHttpRequest"><a href="#XMLHttpRequest" class="headerlink" title="XMLHttpRequest"></a>XMLHttpRequest</h2><h3 id="XHR简史"><a href="#XHR简史" class="headerlink" title="XHR简史"></a>XHR简史</h3><p>尽管名字里有 XML 的 X，XHR 也不是专门针对 XML 开发的。这只是因为 Internet Explorer 5 当初发布它的时候，把它放到 MSXML 库里，这才“继承”了这个 X。</p><h3 id="跨源资源共享（CORS）"><a href="#跨源资源共享（CORS）" class="headerlink" title="跨源资源共享（CORS）"></a>跨源资源共享（CORS）</h3><p>XHR 是一个浏览器层面的 API，向我们隐藏了大量底层处理，包括缓存、重定向、内容协商、认证，等等。这样做有两个目的。第一，XHR 的 API 因此非常简单，开发人员可以专注业务逻辑。其次，浏览器可以采用沙箱机制，对应用代码强制施加一套安全限制。</p><p>XHR 接口强制要求每个请求都严格具备 HTTP 语义：应用提供数据和 URL，浏览器格式化请求并管理每个连接的完整生命周期。类似地，虽然 XHR API 允许应用添加自定义的 HTTP 首部（通过 setRequestHeader() 方法），同时也有一些首部是应用代码不能设定的：</p><ul><li>Accept-Charset、Accept-Encoding、Access-Control-*</li><li>Host、Upgrade、Connection、Referer、Origin</li><li>Cookie、Sec-*、Proxy-* 以及很多其他首部</li></ul><p><font color="DeepPink"><strong>浏览器会拒绝对不安全首部的重写，以此保证应用不能假扮用户代理、用户或请求来源。事实上，保护来源（Origin）首部特别重要，因为这是对所有 XHR 请求应用“同源策略”的关键。</strong></font></p><blockquote><p>一个“源”由应用协议、域名和端口这三个要件共同定义。比如，(http,example.com, 80) 和 (https, example.com, 443) 就是不同的源。</p></blockquote><p>同源策略的出发点很简单：浏览器存储着用户数据，比如认证令牌、cookie 及其他私有元数据，这些数据不能泄露给其他应用。如果没有同源沙箱，那么 example.com 中的脚本就可以访问并操纵 thirdparty.com 的用户数据！</p><p>为解决这个问题，XHR 的早期版本都限制应用只能执行同源请求，即新请求的来源必须与旧请求的来源一致：来自 example.com 的 XHR 请求，只能从 example.com 请求其他资源。如果后续请求不同源，浏览器就拒绝该 XHR 请求并报错。</p><p>可是，在某些必要的情况下，同源策略也会给更好地利用 XHR 带来麻烦：如果服务器想要给另一个网站中的脚本提供资源怎么办？这就是 Cross-Origin Resource Sharing（跨源资源共享，CORS）的来由！ CORS 针对客户端的跨源请求提供了安全的选择同意机制：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//  脚本来源： (http, example.com, 80)</span><br><span class="line">var xhr = new XMLHttpRequest();</span><br><span class="line">xhr.open(&apos;GET&apos;, &apos;/resource.js&apos;); ➊</span><br><span class="line">xhr.onload = function() &#123; ... &#125;;</span><br><span class="line">xhr.send();</span><br><span class="line">var cors_xhr = new XMLHttpRequest();</span><br><span class="line">cors_xhr.open(&apos;GET&apos;, &apos;http://thirdparty.com/resource.js&apos;); ➋</span><br><span class="line">cors_xhr.onload = function() &#123; ... &#125;;</span><br><span class="line">cors_xhr.send();</span><br></pre></td></tr></table></figure><p>➊ 同源 XHR 请求<br>➋ 跨源 XHR 请求</p><p>CORS 请求也使用相同的 XHR API，区别仅在于请求资源用的 URL 与当前脚本并不同源。在前面的例子中，当前执行的脚本来自 (http, example.com, 80)，而第二个XHR 请求访问的 resource.js 则来自 (http, thirdparty.com, 80)。</p><p>针对 CORS 请求的选择同意认证机制由底层处理：请求发出后，浏览器自动追加受保护的 Origin HTTP 首部，包含着发出请求的来源。相应地，远程服务器可以检查 Origin 首部，决定是否接受该请求，如果接受就返回 Access-Control-Allow-Origin 响应首部：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">=&gt;  请求</span><br><span class="line">GET /resource.js HTTP/1.1</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com ➊</span><br><span class="line">...</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: http://example.com ➋</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>➊ Origin 首部由浏览器自动设置<br>➋ 选择同意首部由服务器设置</p><p>在前面的例子中，thirdparty.com 决定同意与 example.com 跨源共享资源，因此就在响应中返回了适当的访问控制首部。假如它选择不同意接受这个请求，那么只要不在响应中包含 Access-Control-Allow-Origin 首部即可。这样，客户端的浏览器就会自动将发出的请求作废。</p><blockquote><p>如果第三方服务器不支持 CORS，那么客户端请求同样会作废，因为客户端会验证响应中是否包含选择同意的首部。作为一个特例，CORS 还允许服务器返回一个通配值 ( Access-Control-Allow-Origin: * )，表示它允许来自任何源的请求。不过，在启用这个选项前，请大家务必三思！</p></blockquote><p>这就是全部了吧？准确地讲，不是。因为 CORS 还会提前采取一系列安全措施，以确保服务器支持 CORS：</p><ul><li>CORS 请求会省略 cookie 和 HTTP 认证等用户凭据；</li><li>客户端被限制只能发送“简单的跨源请求”，包括只能使用特定的方法（GET、POST 和 HEAD），以及只能访问可以通过 XHR 发送并读取的 HTTP 首部。</li></ul><p>要启用 cookie 和 HTTP 认证，客户端必须在发送请求时通过 XHR 对象发送额外的属性（ withCredentials ），而服务器也必须以适当的首部（Access-Control-Allow-Credentials）响应，表示它允许应用发送用户的隐私数据。类似地，如果客户端需要写或者读自定义的 HTTP 首部，或者想要使用“不简单的方法”发送请求，那么它必须首先要获得第三方服务器的许可，即向第三方服务器发送一个预备（preflight）请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">=&gt;  预备请求</span><br><span class="line">OPTIONS /resource.js HTTP/1.1 ➊</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com</span><br><span class="line">Access-Control-Request-Method: POST</span><br><span class="line">Access-Control-Request-Headers: My-Custom-Header</span><br><span class="line">...</span><br><span class="line">&lt;= 预备响应</span><br><span class="line">HTTP/1.1 200 OK ➋</span><br><span class="line">Access-Control-Allow-Origin: http://example.com</span><br><span class="line">Access-Control-Allow-Methods: GET, POST, PUT</span><br><span class="line">Access-Control-Allow-Headers: My-Custom-Header</span><br><span class="line">...</span><br><span class="line">（正式的 HTTP 请求） ➌</span><br></pre></td></tr></table></figure><p>➊ 验证许可的预备 OPTIONS 请求<br>➋ 第三方源的成功预备响应<br>➌ 实际的 CORS 请求</p><p>W3C 官方的 CORS 规范规定了何时何地必须使用预备请求：“简单的”请求可以跳过它，但很多条件下这个请求都是必需的，因此也会为验证许可而增加仅有一次往返的网络延迟。好在，只要完成预备请求，客户端就会将结果缓存起来，后续请求就不必重复验证了。</p><blockquote><p>CORS 得到了所有现代浏览器支持，参见：caniuse.com/cors。要全面了解CORS 的各种策略及实现，请参考 W3C 官方标准（<a href="http://www.w3.org/TR/cors/" target="_blank" rel="noopener">http://www.w3.org/TR/cors/</a>）。</p></blockquote><h3 id="通过XHR下载数据"><a href="#通过XHR下载数据" class="headerlink" title="通过XHR下载数据"></a>通过XHR下载数据</h3><p>浏览器可以自动解码的数据类型如下:</p><ul><li>ArrayBuffer<br>固定长度的二进制数据缓冲区。</li><li>Blob<br>二进制大对象或不可变数据。</li><li>Document<br>解析后得到的 HTML 或 XML 文档。</li><li>JSON<br>表示简单数据结构的 JavaScript 对象。</li><li>Text<br>简单的文本字符串。</li></ul><p>浏览器可以依靠 HTTP 的 content-type 首部来推断适当的数据类型（比如把application/json 响应解析为 JSON 对象），应用也可以在发起 XHR 请求时显式重写数据类型。</p><blockquote><p>这里的二进制大对象接口（ Blob ）属于 HTML5 的 File API，就像一个不透明的引用，可以指向任何数据块（二进制或文本）。这个对象本身没有太多功能，只能查询其大小、MIME 类型，或将它切分成更小的块。这个对象存在的真正目的，是作为各种 JavaScript API 之间的一种高效的互操作机制。</p></blockquote><blockquote><p>要估算传输完成的数据量，服务器必须在其响应中提供内容长度（Content-Length）首部。而对于分块数据，由于响应的总长度未知，因此就无法估计进度了。另外，XHR 请求默认没有超时限制，这意味着一个请求的“进度”可以无限长。作为最佳实践，一定要为应用设置合理的超时时间，并适当处理错误。</p></blockquote><h2 id="服务器发送事件"><a href="#服务器发送事件" class="headerlink" title="服务器发送事件"></a>服务器发送事件</h2><p>Server-Sent Events（SSE）让服务器可以向客户端流式发送文本消息，比如服务器上生成的实时通知或更新。为达到这个目标，SSE 设计了两个组件：浏览器中的EventSource 和新的“事件流”数据格式。其中， EventSource 可以让客户端以 DOM 事件的形式接收到服务器推送的通知，而新数据格式则用于交付每一次更新。</p><p>EventSource API 和定义完善的事件流数据格式，使得 SSE 成为了在浏览器中处理实时数据的高效而不可或缺的工具：</p><ul><li>通过一个长连接低延迟交付；</li><li>高效的浏览器消息解析，不会出现无限缓冲；</li><li>自动跟踪最后看到的消息及自动重新连接；</li><li>消息通知在客户端以 DOM 事件形式呈现。</li></ul><p>实际上，SSE 提供的是一个高效、跨浏览器的 XHR 流实现，消息交付只使用一个长 HTTP 连接。然而，与我们自己实现 XHR 流不同，浏览器会帮我们管理连接、解析消息，从而让我们只关注业务逻辑。</p><h3 id="EventSource-API"><a href="#EventSource-API" class="headerlink" title="EventSource API"></a>EventSource API</h3><p>EventSource 接口通过一个简单的浏览器 API 隐藏了所有的底层细节，包括建立连接和解析消息。</p><blockquote><p>SSE 实现了节省内存的 XHR 流。与原始的 XHR 流在连接关闭前会缓冲接收到的所有响应不同，SSE 连接会丢弃已经处理过的消息，而不会在内存中累积。</p></blockquote><p><font color="DeepPink"><strong>值得一提的是， EventSource 接口还能自动重新连接并跟踪最近接收的消息：如果连接断开了， EventSource 会自动重新连接到服务器，还可以向服务器发送上一次接收到的消息 ID，以便服务器重传丢失的消息并恢复流。</strong></font></p><h3 id="Event-Stream协议"><a href="#Event-Stream协议" class="headerlink" title="Event Stream协议"></a>Event Stream协议</h3><p>SSE 事件流是以流式 HTTP 响应形式交付的：客户端发起常规 HTTP 请求，服务器以自定义的“text/event-stream”内容类型响应，然后交付 UTF-8 编码的事件数据。这么简单几句话似乎都有点说复杂了，看一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">=&gt;  请求</span><br><span class="line">GET /stream HTTP/1.1 ➊</span><br><span class="line">Host: example.com</span><br><span class="line">Accept: text/event-stream</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK ➋</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Type: text/event-stream</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">retry: 15000 ➌</span><br><span class="line">data: First message is a simple string. ➍</span><br><span class="line">data: &#123;&quot;message&quot;: &quot;JSON payload&quot;&#125; ➎</span><br><span class="line">event: foo ➏</span><br><span class="line">data: Message of type &quot;foo&quot;</span><br><span class="line">id: 42 ➐</span><br><span class="line">event: bar</span><br><span class="line">data: Multi-line message of</span><br><span class="line">data: type &quot;bar&quot; and id &quot;42&quot;</span><br><span class="line">id: 43 ➑</span><br><span class="line">data: Last message, id &quot;43&quot;</span><br></pre></td></tr></table></figure><p>➊ 客户端通过 EventSource 接口发起连接<br>➋ 服务器以 “text/event-stream” 内容类型响应<br>➌ 服务器设置连接中断后重新连接的间隔时间（15 s）<br>➍ 不带消息类型的简单文本事件<br>➎ 不带消息类型的 JSON 数据载荷<br>➏ 类型为 “foo” 的简单文本事件<br>➐ 带消息 ID 和类型的多行事件<br>➑ 带可选 ID 的简单文本事件</p><p>在接收端， EventSource 接口通过检查换行分隔符来解析到来的数据流。</p><blockquote><p><font color="DeepPink"><strong>SSE 中的 UTF-8 编码与二进制传输 EventSource 不会对实际载荷进行任何额外处理：从一或多个 data 字段中提取出来的消息，会被拼接起来直接交给应用。因此，服务器可以推送任何文本格式（例如，简单字符串、JSON，等等），应用必须自己解码。</strong></font></p></blockquote><blockquote><p>话虽如此，但所有事件源数据都是 UTF-8 编码的：SSE 不是为传输二进制载荷而设计的！如果有必要，可以把二进制对象编码为 base64 形式，然后再使用 SSE。但这样会导致很高（33%）的字节开销。</p></blockquote><blockquote><p>担心 UTF-8 编码也会造成高开销？ SSE 连接本质上是 HTTP 流式响应，因此响应是可以压缩的（如 gzip 压缩），就跟压缩其他 HTTP 响应一样，而且是动态压缩！虽然 SSE 不是为传输二进制数据而设计的，但它却是一个高效的机制——只要让你的服务器对 SSE 流应用 gzip 压缩。</p></blockquote><blockquote><p><font color="DeepPink"><strong>不支持二进制传输是有意为之的。SSE 的设计目标是简单、高效，作为一种服务器向客户端传送文本数据的机制。如果你想传输二进制数据，WebSocket 才是更合适的选择。</strong></font></p></blockquote><p>最后，除了自动解析事件数据，SSE 还内置支持断线重连，以及恢复客户端因断线而丢失的消息。默认情况下，如果连接中断，浏览器会自动重新连接。SSE 规范建议的间隔时间是 2~3 s，这也是大多数浏览器采用的默认值。不过，服务器也可以设置一个自定义的间隔时间，只要在推送任何消息时向客户端发送一个 retry 命令即可。</p><p>类似地，服务器还可以给每条消息关联任意 ID 字符串。浏览器会自动记录最后一次收到的消息 ID，并在发送重连请求时自动在 HTTP 首部追加“Last-Event-ID”值。下面看一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">（既有 SSE 连接）</span><br><span class="line">retry: 4500 ➊</span><br><span class="line">id: 43 ➋</span><br><span class="line">data: Lorem ipsum</span><br><span class="line">（连接断开）</span><br><span class="line">（4500 ms 后）</span><br><span class="line">=&gt;  请求</span><br><span class="line">GET /stream HTTP/1.1 ➌</span><br><span class="line">Host: example.com</span><br><span class="line">Accept: text/event-stream</span><br><span class="line">Last-Event-ID: 43</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK ➍</span><br><span class="line">Content-Type: text/event-stream</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">id: 44 ➎</span><br><span class="line">data: dolor sit amet</span><br></pre></td></tr></table></figure><p>➊ 服务器将客户端的重连间隔设置为 4.5 s<br>➋ 简单文本事件，ID:43<br>➌ 带最后一次事件 ID 的客户端重连请求<br>➍ 服务器以 ‘text/event-stream’ 内容类型响应<br>➎ 简单文本事件，ID:44</p><p>客户端应用不必为重新连接和记录上一次事件 ID 编写任何代码。这些都由浏览器自动完成，然后就是服务器负责恢复了。值得注意的是，根据应用的要求和数据流，服务器可以采取不同的实现策略。</p><ul><li><p>如果丢失消息可以接受，就不需要事件 ID 或特殊逻辑，只要让客户端重连并恢复数据流即可。</p></li><li><p><font color="DeepPink"><strong>如果必须恢复消息，那服务器就需要指定相关事件的 ID，以便客户端在重连时报告最后接收到的 ID。</strong></font>同样，服务器也需要实现某种形式的本地缓存，以便恢复并向客户端重传错过的消息。</p></li></ul><h3 id="SSE使用场景及性能"><a href="#SSE使用场景及性能" class="headerlink" title="SSE使用场景及性能"></a>SSE使用场景及性能</h3><blockquote><p>通过 TLS 实现 SSE 流<br>SSE 通过常规 HTTP 连接实现了简单便捷的实时传输机制，服务器端容易部署，客户端也容易打补丁。可是，现有网络中间设备，比如代理服务器和防火墙，都不支持 SSE，而这有可能带来问题：中间设备可能会缓冲事件流数据，导致额外延迟，甚至彻底毁掉 SSE 连接。</p></blockquote><blockquote><p>如果你碰到了这样或类似的问题，那么可以考虑通过 TLS 发送 SSE 事件流。</p></blockquote><h2 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h2><p>WebSocket 可以实现客户端与服务器间双向、基于消息的文本或二进制数据传输。</p><h3 id="接收文本和二进制数据"><a href="#接收文本和二进制数据" class="headerlink" title="接收文本和二进制数据"></a>接收文本和二进制数据</h3><p>WebSocket 协议不作格式假设，对应用的净荷也没有限制：文本或者二进制数据都没问题。从内部看，协议只关注消息的两个信息：净荷长度和类型（前者是一个可变长度字段），据以区别 UTF-8 数据和二进制数据。</p><p>浏览器接收到新消息后，如果是文本数据，会自动将其转换成 DOMString 对象，如果是二进制数据或 Blob 对象，会直接将其转交给应用。唯一可以（作为性能暗示和优化措施）多余设置的，就是告诉浏览器把接收到的二进制数据转换成 ArrayBuffer而非 Blob。</p><blockquote><p>用户代理可以将这个选项看作一个暗示，以决定如何处理接收到的二进制数据：如果这里设置为“blob”，那就可以放心地将其转存到磁盘上；而如果设置为“arraybuffer”，那很可能在内存里处理它更有效。自然地，我们鼓励用户代理使用更细微的线索，以决定是否将到来的数据放到内存里…… ——The WebSocket API W3C Candidate Recommendation</p></blockquote><p>Blob 对象一般代表一个不可变的文件对象或原始数据。如果你不需要修改它或者不需要把它切分成更小的块，那这种格式是理想的（比如，可以把一个完整的 Blob 对象传给 img 标签）。而如果你还需要再处理接收到的二进制数据，那么选择 ArrayBuffer 应该更合适。</p><h3 id="子协议协商"><a href="#子协议协商" class="headerlink" title="子协议协商"></a>子协议协商</h3><p><font color="DeepPink"><strong>WebSocket 协议对每条消息的格式事先不作任何假设：仅用一位标记消息是文本还是二进制，以便客户端和服务器有效地解码数据，而除此之外的消息内容就是未知的。</strong></font></p><p>此外，与 HTTP 或 XHR 请求不同——它们是通过每次请求和响应的 HTTP 首部来沟通元数据，WebSocket 并没有等价的机制。因此，如果需要沟通关于消息的元数据，客户端和服务器必须达成沟通这一数据的子协议。</p><ul><li><p>客户端和服务器可以提前确定一种固定的消息格式，比如所有通信都通过 JSON编码的消息或者某种自定义的二进制格式进行，而必要的元数据作为这种数据结构的一个部分。</p></li><li><p>如果客户端和服务器要发送不同的数据类型，那它们可以确定一个双方都知道的消息首部，利用它来沟通说明信息或有关净荷的其他解码信息。</p></li><li><p>混合使用文本和二进制消息可以沟通净荷和元数据，比如用文本消息实现 HTTP首部的功能，后跟包含应用净荷的二进制消息。</p></li></ul><blockquote><p>子协议名由应用自己定义，且在初次 HTTP 握手期间发送给服务器。除此之外，指定的子协议对核心 WebSocket API 不会有任何影响。</p></blockquote><h3 id="WebSocket协议"><a href="#WebSocket协议" class="headerlink" title="WebSocket协议"></a>WebSocket协议</h3><blockquote><p>WebSocket 协议尝试在既有 HTTP 基础设施中实现双向 HTTP 通信，因此也使用 HTTP 的 80 和 443 端口……不过，这个设计不限于通过 HTTP 实现WebSocket 通信，未来的实现可以在某个专用端口上使用更简单的握手，而<br>不必重新定义么一个协议。  ——WebSocket Protocol RFC 6455</p></blockquote><h4 id="二进制分帧层-1"><a href="#二进制分帧层-1" class="headerlink" title="二进制分帧层"></a>二进制分帧层</h4><p>客户端和服务器 WebSocket 应用通过基于消息的 API 通信：发送端提供任意 UTF-8或二进制的净荷，接收端在整个消息可用时收到通知。为此，WebSocket 使用了自定义的二进制分帧格式（图 17-1），把每个应用消息切分成一或多个帧，发送到目的地之后再组装起来，等到接收到完整的消息后再通知接收端。</p><p><img src="/images/high-performance-browser-networking-note/%E5%9B%BE171WebSocket%E5%B8%A7%E6%A0%BC%E5%BC%8F.png" alt></p><ul><li>帧<br>最小的通信单位，包含可变长度的帧首部和净荷部分，净荷可能包含完整或部分应用消息。</li><li>消息<br>一系列帧，与应用消息对等。</li><li>每一帧的第一位（FIN）表示当前帧是不是消息的最后一帧。一条消息有可能只对应一帧。</li><li>操作码（4 位）表示被传输帧的类型：传输应用数据时，是文本（1）还是二进制（2）；连接有效性检查时，是关闭（8）、呼叫（ping，9）还是回应（pong，10）。</li><li>掩码位表示净荷是否有掩码（只适用于客户端发送给服务器的消息）。 </li><li>净荷长度由可变长度字段表示：<ul><li>如果是 0~125，就是净荷长度；</li><li>如果是 126，则接下来 2 字节表示的 16 位无符号整数才是这一帧的长度；</li><li>如果是 127，则接下来 8 字节表示的 64 位无符号整数才是这一帧的长度。</li></ul></li><li>掩码键包含 32 位值，用于给净荷加掩护。</li><li>净荷包含应用数据，如果客户端和服务器在建立连接时协商过，也可以包含自定义的扩展数据。</li></ul><blockquote><p>所有客户端发送帧的净荷都要使用帧首部中指定的值加掩码，这样可以防止客户端中运行的恶意脚本对不支持 WebSocket 的中间设备进行缓存投毒攻击（cache poisoning attack）。要了解这种攻击的细节，请参考 W2SP<br>2011 的论文“Talking to Yourself for Fun and Profit”（<a href="http://w2spconf.com/2011/papers/websocket.pdf" target="_blank" rel="noopener">http://w2spconf.com/2011/papers/websocket.pdf</a>）。</p></blockquote><p>算下来，服务器发送的每个 WebSocket 帧会产生 2~10 字节的分帧开销。而客户端必须发送掩码键，这又会增加 4 字节，结果就是 6~14 字节的开销。除此之外，没有其他元数据（比如首部字段或其他关于净荷的信息）：所有 WebSocket 通信都是通过交换帧实现的，而帧将净荷视为不透明的应用数据块。</p><blockquote><p>WebSocket 的多路复用及队首阻塞<br>WebSocket 很容易发生队首阻塞的情况：消息可能会被分成一或多个帧，但不同消息的帧不能交错发送，因为没有与 HTTP 2.0 分帧机制中“流 ID”对等的字段。<br>显然，如果一个大消息被分成多个 WebSocket 帧，就会阻塞其他消息的帧。如果你的应用不容许有交付延迟，那可以小心控制每条消息的净荷大小，甚至可以考虑把大消息拆分成多个小消息！<br><font color="DeepPink"><strong>WebSocket 不支持多路复用，还意味着每个 WebSocket 连接都需要一个专门的TCP 连接。对于 HTTP 1.x 而言，由于浏览器针对每个来源有连接数量限制，因此可能会导致问题。</strong></font><br>好 在，HyBi Working Group 正 着 手 制 定 的 新 的“Multiplexing Extension for WebSockets”（WebSockets 多路复用扩展）会解决这个问题：<br>这个扩展通过封装帧并加上信道 ID，可以让一个 TCP 连接支持多个虚拟 WebSocket 连接……这个多路复用扩展维护独立的逻辑信道，每个逻辑信道与独立的 WebSocket 连接没有差别，包括独立的握手首部。<br>——WebSocket Multiplexing（Draft 10）<br>有了这个扩展后，多个 WebSocket 连接（信道）就可能在同一个 TCP 连接上得到复用。可是，每个信道依旧容易产生队首阻塞问题！可能的解决方案是使用不同的信道，或者专用 TCP 连接，多路并行发送消息。<br>最后，注意前面的扩展仅对 HTTP 1.x 连接是必要的。虽然通过 HTTP 2.0 传输WebSocket 帧的官方规范尚未发布，但相对来说就容易多了。因为 HTTP 2.0 内置了流的多路复用，只要通过 HTTP 2.0 的分帧机制来封装 WebSocket 帧，多个WebSocket 连接就可以在一个会话中传输。</p></blockquote><h4 id="协议扩展"><a href="#协议扩展" class="headerlink" title="协议扩展"></a>协议扩展</h4><p>WebSocket 规范允许对协议进行扩展：数据格式和 WebSocket 协议的语义可以通过新的操作码和数据字段扩展。虽然有些不同寻常，但这却是一个非常强大的特性，因为它允许客户端和服务器在基本的 WebSocket 分帧层之上实现更多功能，又不需要应用代码介入或协作。</p><p>要使用扩展，客户端必须在第一次的 Upgrade 握手中通知服务器，服务器必须选择并确认要在商定连接中使用的扩展。</p><h4 id="HTTP升级协商"><a href="#HTTP升级协商" class="headerlink" title="HTTP升级协商"></a>HTTP升级协商</h4><p>WebSocket 协议提供了很多强大的特性：基于消息的通信、自定义的二进制分帧层、子协议协商、可选的协议扩展，等等。换句话说，在交换数据之前，客户端必须与服务器协商适当的参数以建立连接。</p><p>利用 HTTP 完成握手有几个好处。首先，让 WebSockets 与现有 HTTP 基础设施兼容：WebSocket 服务器可以运行在 80 和 443 端口上，这通常是对客户端唯一开放的端口。其次，让我们可以重用并扩展 HTTP 的 Upgrade 流，为其添加自定义的WebSocket 首部，以完成协商。</p><ul><li>Sec-WebSocket-Version<br>客户端发送，表示它想使用的 WebSocket 协议版本（“13”表示 RFC 6455）。如果服务器不支持这个版本，必须回应自己支持的版本。</li><li>Sec-WebSocket-Key<br>客户端发送，自动生成的一个键，作为一个对服务器的“挑战”，以验证服务器支持请求的协议版本。<br>Sec-WebSocket-Accept<br>服务器响应，包含 Sec-WebSocket-Key 的签名值，证明它支持请求的协议版本。</li><li>Sec-WebSocket-Protocol<br>用于协商应用子协议：客户端发送支持的协议列表，服务器必须只回应一个协议名。</li><li>Sec-WebSocket-Extensions<br>用于协商本次连接要使用的 WebSocket 扩展：客户端发送支持的扩展，服务器通过返回相同的首部确认自己支持一或多个扩展。</li></ul><p>有了这些协商字段，就可以在客户端和服务器之间进行 HTTP Upgrade 并协商新的WebSocket 连接了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET /socket HTTP/1.1</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: websocket ➊</span><br><span class="line">Sec-WebSocket-Version: 13 ➋</span><br><span class="line">Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== ➌</span><br><span class="line">Sec-WebSocket-Protocol: appProtocol, appProtocol-v2 ➍</span><br><span class="line">Sec-WebSocket-Extensions: x-webkit-deflate-message, x-custom-extension ➎</span><br></pre></td></tr></table></figure><p>➊ 请求升级到 WebSocket 协议<br>➋ 客户端使用的 WebSocket 协议版本<br>➌ 自动生成的键，以验证服务器对协议的支持<br>➍ 可选的应用指定的子协议列表<br>➎ 可选的客户端支持的协议扩展列表<br>与浏览器中客户端发起的任何连接一样，WebSocket 请求也必须遵守同源策略：浏览器会自动在升级握手请求中追加 Origin 首部，远程服务器可能使用 CORS 判断接受或拒绝跨源请求。要完成握手，服务器必须返回一个成功的“Switching Protocols”（切换协议）响应，并确认选择了客户端发送的哪个选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 101 Switching Protocols ➊</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Access-Control-Allow-Origin: http://example.com ➋</span><br><span class="line">Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= ➌</span><br><span class="line">Sec-WebSocket-Protocol: appProtocol-v2 ➍</span><br><span class="line">Sec-WebSocket-Extensions: x-custom-extension ➎</span><br></pre></td></tr></table></figure><p>➊ 101 响应码确认升级到 WebSocket 协议<br>➋ CORS 首部表示选择同意跨源连接<br>➌ 签名的键值验证协议支持<br>➍ 服务器选择的应用子协议<br>➎ 服务器选择的 WebSocket 扩展</p><blockquote><p>所有兼容 RFC 6455 的 WebSocket 服务器都使用相同的算法计算客户端挑战的答案：将 Sec-WebSocket-Key 的内容与标准定义的唯一 GUID 字符串拼接起来，计算出 SHA1 散列值，结果是一个 base-64 编码的字符串，把这个字符串发给客户端即可。</p></blockquote><p>最低限度，成功的 WebSocket 握手必须是客户端发送协议版本和自动生成的挑战值，服务器返回 101 HTTP 响应码（Switching Protocols）和散列形式的挑战答案，确认选择的协议版本：</p><ul><li>客户端必须发送Sec-WebSocket-Version 和 Sec-WebSocket-Key ；</li><li>服务器必须返回Sec-WebSocket-Accept 确认协议；</li><li>客户端可以通过Sec-WebSocket-Protocol 发送应用子协议列表；</li><li>服务器必须选择一个子协议并通过Sec-WebSocket-Protocol 返回协议名；如果服务器不支持任何一个协议，连接断开；</li><li>客户端可以通过Sec-WebSocket-Extensions 发送协议扩展；</li><li>服务器可以通过Sec-WebSocket-Extensions 确认一或多个扩展；如果服务器没有返回扩展，则连接不支持扩展。</li></ul><p>最后，前述握手完成后，如果握手成功，该连接就可以用作双向通信信道交换WebSocket 消息。从此以后，客户端与服务器之间不会再发生 HTTP 通信，一切由WebSocket 协议接管。</p><blockquote><p>代理、中间设备与 WebSocket<br>实践中，考虑到安全和保密，很多用户都只开放有限的端口，通常只有 80（HTTP）和 443（HTTPS）。正因为如此，WebSocket 协商是通过 HTTP Upgrade流进行的，这样可以确保与现有网络策略及基础设施兼容。<br>不过，正如 “Web 代理、中间设备、TLS 与新协议”所说，很多现有的HTTP 中间设备可能不理解新的 WebSocket 协议，而这可能导致各种问题：盲目的连接升级、意外缓冲 WebSocket 帧、不明就里地修改内容、把 WebSocket 流量误当作不完整的 HTTP 通信，等等。<br>WebSocket 的 Key 和 Accept 握手可以解决其中一些问题：这是服务器的一个安全策略，而盲目“升级”连接的中间设备可能并不理解 WebSocket 协议。虽然这个预防措施对某些代理可以解决问题，但对于那些“透明代理”还是不行，它们可能会分析并意外地修改数据。<br>解决之道？建立一条端到端的安全通道。比如，使用 WSS ！在执行 HTTP Upgrade 握手之前，先协商一次 TLS 会话，在客户端与服务器之间建立一条加密通道，就可以解决前述所有问题。这个方案尤其适合移动客户端，因为它们的流量经常要穿越各种代理服务，这些代理服务很可能不认识 WebSocket。</p></blockquote><h3 id="WebSocket使用场景及性能"><a href="#WebSocket使用场景及性能" class="headerlink" title="WebSocket使用场景及性能"></a>WebSocket使用场景及性能</h3><h4 id="请求和响应流"><a href="#请求和响应流" class="headerlink" title="请求和响应流"></a>请求和响应流</h4><blockquote><p>把传输机制从 XHR 切换为 SSE 或 WebSocket 并不会减少客户端与服务器间的往返次数！不管什么传输机制，数据包的传播延迟都一样。不过，除了传播延迟，还有一个排队延迟——消息在被发送给另一端之前必须在客户端或服务器上等待的时间。</p></blockquote><h2 id="WebRTC"><a href="#WebRTC" class="headerlink" title="WebRTC"></a>WebRTC</h2><p>略</p><p>PDF书籍下载地址：<a href="https://github.com/jiankunking/books-recommendation/tree/master/HTTP" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/HTTP</a></p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Network </tag>
            
            <tag> TCP </tag>
            
            <tag> UDP </tag>
            
            <tag> HTTP </tag>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java ForkJoin 解析</title>
      <link href="/java-forkjoin.html"/>
      <url>/java-forkjoin.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文主要想了解两个地方：如何窃取任务、task如何等待（join）<br>代码基于 OpenJDK 12</p></blockquote><a id="more"></a><h1 id="窃取算法（work-stealing）"><a href="#窃取算法（work-stealing）" class="headerlink" title="窃取算法（work-stealing）"></a>窃取算法（work-stealing）</h1><p>从<a href="/attachments/ForkJoin-Paper-DougLea.pdf" target="_blank">ForkJoin-Paper-DougLea</a>中可以看出:</p><ul><li>每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。</li><li>队列使用的是双端队列，支持LIFO、FIFO。</li><li>子任务会被放到线程（不一定是当前线程）的队列中。</li><li>工作线程按照LIFO的顺序处理自己队列中数据。</li><li>当一个工作线程处理完自己队列中数据的时候，会随机挑选一个工作线程，并“窃取”的该工作线程队列队尾的task。</li></ul><p><img src="/images/java-forkjoin/steal.png" alt></p><p>到了这里就可以知道，窃取任务从其他线程队列的尾部窃取的了。</p><h2 id="窃取算法优缺点"><a href="#窃取算法优缺点" class="headerlink" title="窃取算法优缺点"></a>窃取算法优缺点</h2><p>工作窃取算法的优点：<font color="DeepPink"><strong>充分利用线程进行并行计算，减少了线程间的竞争。</strong></font><br>工作窃取算法的缺点：<font color="DeepPink"><strong>在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。</strong></font></p><h1 id="Task-等待（join）"><a href="#Task-等待（join）" class="headerlink" title="Task 等待（join）"></a>Task 等待（join）</h1><p>Join方法的主要作用是阻塞当前线程并等待获取结果。具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public final V join() &#123;</span><br><span class="line">    int s;</span><br><span class="line">    if (((s = doJoin()) &amp; ABNORMAL) != 0)</span><br><span class="line">        reportException(s);</span><br><span class="line">    return getRawResult();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，它调用了doJoin()方法，通过doJoin()方法得到当前任务的状态来判断返回什么结果，任务状态有4种：已完成（NORMAL）、被取消（CANCELLED）、信号（SIGNAL）和出现异常（EXCEPTIONAL）。</p><ul><li>如果任务状态是已完成，则直接返回任务结果。</li><li>如果任务状态是被取消，则直接抛出CancellationException。</li><li>如果任务状态是抛出异常，则直接抛出对应的异常。</li></ul><p>让我们再来分析一下doJoin()方法的实现代码:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Implementation for join, get, quietlyJoin. Directly handles</span><br><span class="line"> * only cases of already-completed, external wait, and</span><br><span class="line"> * unfork+exec.  Others are relayed to ForkJoinPool.awaitJoin.</span><br><span class="line"> *</span><br><span class="line"> * @return status upon completion</span><br><span class="line"> */</span><br><span class="line">private int doJoin() &#123;</span><br><span class="line">    int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;</span><br><span class="line">    return </span><br><span class="line">        //已完成,返回status</span><br><span class="line">    (s = status) &lt; 0 ? s :</span><br><span class="line">    //未完成,如果当前线程是ForkJoinWorkerThread,从该线程中取出workQueue,并尝试将</span><br><span class="line">        //当前task出队然后执行,执行的结果是完成则返回状态,否则使用当线程池所在的ForkJoinPool的awaitJoin方法等待</span><br><span class="line">        ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?</span><br><span class="line">        (w = (wt = (ForkJoinWorkerThread)t).workQueue).tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) :</span><br><span class="line">        //当前线程不是ForkJoinWorkerThread,调用externalAwaitDone方法</span><br><span class="line">        //externalAwaitDone: Blocks a non-worker-thread until completion.</span><br><span class="line">        externalAwaitDone();</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Pops the given task only if it is at the current top.</span><br><span class="line"> */</span><br><span class="line">final boolean tryUnpush(ForkJoinTask&lt;?&gt; task) &#123;</span><br><span class="line">    boolean popped = false;</span><br><span class="line">    int s, cap; ForkJoinTask&lt;?&gt;[] a;</span><br><span class="line">    if ((a = array) != null &amp;&amp; (cap = a.length) &gt; 0 &amp;&amp;</span><br><span class="line">        (s = top) != base &amp;&amp;</span><br><span class="line">        (popped = QA.compareAndSet(a, (cap - 1) &amp; --s, task, null)))</span><br><span class="line">        TOP.setOpaque(this, s);</span><br><span class="line">    return popped;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Primary execution method for stolen tasks. Unless done, calls</span><br><span class="line"> * exec and records status if completed, but doesn&apos;t wait for</span><br><span class="line"> * completion otherwise.</span><br><span class="line"> *</span><br><span class="line"> * @return status on exit from this method</span><br><span class="line">*/</span><br><span class="line">final int doExec() &#123;</span><br><span class="line">    int s; boolean completed;</span><br><span class="line">    // 仅未完成的任务会运行,其他情况会忽略.</span><br><span class="line">    if ((s = status) &gt;= 0) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            //exec是abstract方法</span><br><span class="line">            //调用ForkJoinTask子类中exec</span><br><span class="line">            completed = exec();</span><br><span class="line">        &#125; catch (Throwable rex) &#123;</span><br><span class="line">            completed = false;</span><br><span class="line">            s = setExceptionalCompletion(rex);</span><br><span class="line">        &#125;</span><br><span class="line">        if (completed)</span><br><span class="line">            s = setDone();</span><br><span class="line">        &#125;</span><br><span class="line">        return s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在doJoin()方法里，首先通过查看任务的状态，看任务是否已经执行完成，如果执行完成，则直接返回任务状态；如果没有执行完，则从任务队列中取出任务并执行。如果任务顺利执行完成，则设置任务状态为NORMAL，如果出现异常，则记录异常，并将任务状态设置为EXCEPTIONAL。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JUC </tag>
            
            <tag> ForkJoin </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java ThreadLocal</title>
      <link href="/java-threadlocal.html"/>
      <url>/java-threadlocal.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>基于OpenJDK 12</p></blockquote><a id="more"></a><h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>本文主要想了解两个地方：</p><ol><li>ThreadLocal实例看起来是在多个线程共享，但实际上是彼此独立的，这个是怎么实现的？</li><li>ThreadLocal使用不当真的会OOM吗？如果会，那么原因是啥？</li></ol><p>先看一下<a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/ThreadLocal.html" target="_blank" rel="noopener">ThreadLocal的官方API</a>解释为：</p><blockquote><p>该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或 set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本[原文：These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable.]。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。</p></blockquote><p>大概的意思有两点：</p><ul><li><font color="DeepPink"><strong>ThreadLocal提供了一种访问某个变量的特殊方式：访问到的变量属于当前线程，即保证每个线程的变量不一样，而同一个线程在任何地方拿到的变量都是一致的，这就是所谓的线程隔离。</strong></font></li><li><font color="DeepPink"><strong>如果要使用ThreadLocal，通常定义为private static类型，在我看来最好是定义为private static final类型。</strong></font></li></ul><p>看一段代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">// 代码来自：</span><br><span class="line">// http://tutorials.jenkov.com/java-concurrency/threadlocal.html</span><br><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            //注意这里 set的值是run函数的内部变量，如果是MyRunnable的全局变量</span><br><span class="line">            //则无法起到线程隔离的作用</span><br><span class="line">            threadLocal.set((int) (Math.random() * 100D));</span><br><span class="line">            try &#123;</span><br><span class="line">                //sleep两秒的作用是让thread2 set操作在thread1的输出之前执行</span><br><span class="line">                //如果线程之间是共用threadLocal，则thread2 set操作会覆盖掉thread1的set操作</span><br><span class="line">                //从而两者的输出都是thread2 set的值</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(threadLocal.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">38</span><br><span class="line">thread1 join</span><br><span class="line">78</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>MyRunnable run中sleep两秒的作用是让thread2 set操作在thread1的输出之前执行，如果线程之间是共用threadLocal，则thread2 set操作会覆盖掉thread1的set操作，两者的输出都是thread2 set的值，从而输出的应该是同一个值。</p><p>但从代码执行结果来看，thread1、thread2的threadLocal是不同的，也就是实现了线程隔离。</p><h1 id="ThreadLocal实例在线程间是如何独立的？"><a href="#ThreadLocal实例在线程间是如何独立的？" class="headerlink" title="ThreadLocal实例在线程间是如何独立的？"></a>ThreadLocal实例在线程间是如何独立的？</h1><p>看一眼ThreadLocal set方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public void set(T value) &#123;</span><br><span class="line">    //currentThread是个native方法，会返回对当前执行线程对象的引用。</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    //getMap 返回线程自身的threadLocals</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    if (map != null) &#123;</span><br><span class="line">        //把value set到线程自身的ThreadLocalMap中了</span><br><span class="line">        map.set(this, value);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //线程自身的ThreadLocalMap未初始化，则先初始化，再set</span><br><span class="line">        createMap(t, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">ThreadLocalMap getMap(Thread t) &#123;</span><br><span class="line">    return t.threadLocals;</span><br><span class="line">&#125;</span><br><span class="line">//Thread类中</span><br><span class="line">//ThreadLocalMapset的set方法未执行深拷贝，需要注意传递值的类型</span><br><span class="line">ThreadLocal.ThreadLocalMap threadLocals = null;</span><br></pre></td></tr></table></figure><p>从代码中可以看到，在set的时候，会根据Thread对象的引用来将值添加到各自线程中。但set的值value还是同一个对象,既然传递的是同一个对象，那就涉及到另一个问题：参数值传递、引用传递的问题了。</p><h2 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        // MyRunnable 全局变量</span><br><span class="line">        int random;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            random = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(random);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(threadLocal.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值不同</span><br><span class="line">16</span><br><span class="line">thread1 join</span><br><span class="line">75</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出可以看出两者隔离了。</p><h2 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h2><h3 id="全局引用"><a href="#全局引用" class="headerlink" title="全局引用"></a>全局引用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        // MyRunnable 全局变量</span><br><span class="line">        Obj obj = new Obj();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            obj.value = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(obj);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(((Obj) threadLocal.get()).value);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        class Obj &#123;</span><br><span class="line">            int value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值相同</span><br><span class="line">36</span><br><span class="line">36</span><br><span class="line">thread1 join</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出结果来看，当set操作的值是MyRunnable的全局变量，并且是引用类型的时候，无法起到隔离的作用。</p><h3 id="局部引用"><a href="#局部引用" class="headerlink" title="局部引用"></a>局部引用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        //Obj obj = new Obj();</span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            Obj obj = new Obj();</span><br><span class="line">            obj.value = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(obj);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(((Obj) threadLocal.get()).value);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        class Obj &#123;</span><br><span class="line">            int value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值不同</span><br><span class="line">12</span><br><span class="line">19</span><br><span class="line">thread1 join</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出结果看，局部引用，可以相互隔离。</p><p><font color="DeepPink"><strong>到这里可以看出ThreadLocal，只是把set值或引用绑定到了当前线程，但却没有进行相应的深拷贝，所以ThreadLocal要想做的线程隔离，必须是基本类型或者run的局部变量。</strong></font></p><h1 id="ThreadLocal-OOM-？"><a href="#ThreadLocal-OOM-？" class="headerlink" title="ThreadLocal OOM ？"></a>ThreadLocal OOM ？</h1><p>看一下ThreadLocalMap内部Entry：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;</span><br><span class="line">    /** The value associated with this ThreadLocal. */</span><br><span class="line">    Object value;</span><br><span class="line"></span><br><span class="line">    Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;</span><br><span class="line">        super(k);</span><br><span class="line">        value = v;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码中看到，Entry继承了WeakReference，并将ThreadLocal设置为了WeakReference，value设置为强引用。也就是：当没有强引用指向ThreadLocal变量时，它可被回收。</p><p>但是，还有一个问题：<font color="DeepPink"><strong>ThreadLocalMap维护ThreadLocal变量与具体实例的映射，当ThreadLocal变量被回收后，该映射的key变为 null，而该Entry还是在ThreadLocalMap中，从而这些无法清理的Entry，会造成内存泄漏。</strong></font></p><blockquote><p>ThreadLocal自带的remove、set方法，都无法处理ThreadLocal自身为null的情况，因为代码中都直接取ThreadLocal的threadLocalHashCode属性了，所以如果ThreadLocal自身已经是null，这时调用remove、set会报空指针异常（java.lang.NullPointerException）的。</p></blockquote><p>所以，在使用ThreadLocal的时候，在使用完毕记得remove（remove方法会将Entry的value及Entry自身设置为null并进行清理）。</p><p>JDK 12 ThreadLocal代码地址：<br><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/lang/ThreadLocal.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/lang/ThreadLocal.java</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> ThreadLocal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 Java Concurrent Atomic Package详解</title>
      <link href="/java-concurrent-atomic-package.html"/>
      <url>/java-concurrent-atomic-package.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>翻译自：Package java.util.concurrent.atomic</p></blockquote><a id="more"></a><blockquote><p>地址：<br><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html#package.description" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html#package.description</a><br>翻译JDK8而不是12的原因是JDK8对与内存语义部分讲解更加详细。</p></blockquote><p><strong>Package java.util.concurrent.atomic 对于单个变量支持无锁、线程安全操作的工具类。</strong></p><p>类摘要：</p><table><thead><tr><th>类名</th><th>描述</th></tr></thead><tbody><tr><td>AtomicBoolean</td><td>可以原子性更新的boolean值。</td></tr><tr><td>AtomicInteger</td><td>可以原子性更新的int值。</td></tr><tr><td>AtomicIntegerArray</td><td>一个int数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicIntegerFieldUpdater<t></t></td><td>基于反射，可以对指定类的指定 volatile int 字段进行原子更新。</td></tr><tr><td>AtomicLong</td><td>可以原子性更新的long值。</td></tr><tr><td>AtomicLongArray</td><td>一个long数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicLongFieldUpdater<t></t></td><td>基于反射，可以对指定类的指定 volatile long 字段进行原子更新。</td></tr><tr><td>AtomicMarkableReference<v></v></td><td>维护带有标记位的对象引用，可以原子方式对其进行更新。</td></tr><tr><td>AtomicReference<v></v></td><td>可以原子性更新的对象引用</td></tr><tr><td>AtomicReferenceArray<e></e></td><td>一个对象引用数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicReferenceFieldUpdater&lt;T,V&gt;</td><td>基于反射，可以对指定类的指定 volatile reference 字段进行原子更新。</td></tr><tr><td>AtomicStampedReference<v></v></td><td>维护带有整数版本标志的对象引用，可以原子方式对其进行更新。</td></tr><tr><td>DoubleAccumulator</td><td>One or more variables that together maintain a running double value updated using a supplied function.</td></tr><tr><td>DoubleAdder</td><td>One or more variables that together maintain an initially zero double sum.</td></tr><tr><td>LongAccumulator</td><td>One or more variables that together maintain a running long value updated using a supplied function.</td></tr><tr><td>LongAdder</td><td>One or more variables that together maintain an initially zero long sum.</td></tr></tbody></table><blockquote><p>DoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder 均是Striped64的子类，内部维护的是一个数组，当并发更新时，每个线程操作的是数组中的元素，从而降低锁的粒度。</p></blockquote><p>本质上，该package下的类扩展了volatile值、字段、数组元素的概念，提供以下形式的原子更新操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean compareAndSet(expectedValue, updateValue);</span><br></pre></td></tr></table></figure><p>该方法（在不同类中的参数类型不同）原子地将变量设置为updateValue，如果它当前持有expectedValue，更新成功返回true。该包中的类还包含获取和无条件设置（set）值的方法。</p><p>这些方法的规范使实现能够采用当代处理器上可用的高效机器级原子指令。 然而，<font color="DeepPink"><strong>在某些平台上，支持可能需要某种形式的内部锁定。因此，这些方法不是严格保证是非阻塞的（线程可能在执行操作之前暂时阻塞）。</strong></font></p><p>AtomicBoolean、AtomicInteger、AtomicLong和AtomicReference类的实例都提供对对应类型的单个变量的访问和更新。每个类还提供了适用于该类型的实用方法。例如，类AtomicLong和AtomicInteger提供原子增量方法。 一个应用是生成序列号，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Sequencer &#123;</span><br><span class="line">  private final AtomicLong sequenceNumber = new AtomicLong(0);</span><br><span class="line">  public long next() &#123;</span><br><span class="line">    return sequenceNumber.getAndIncrement();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原子性访问和更新内存效果，与volatiles遵循同样的规则，如<a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4" target="_blank" rel="noopener">The Java Language Specification (17.4 Memory Model)</a>所述：</p><ul><li>get与volatile读效果一样</li><li>set与volatile写效果一样</li><li>lazySet与写入(分配)volatile变量的效果一样【写操作不会与之前的任何写操作重新排序】，但它可能被后续操作重排【也就是，<font color="DeepPink"><strong>在volatile写或者同步操作之前，可能对于其它线程不可见</strong></font>】。</li><li>compareAndSet和所有其他读取和更新操作(如getAndIncrement)一样，与volatile变量读取和写入具有相同的内存效果。</li></ul><blockquote><p>lazySet是使用Unsafe.putOrderedObject方法，这个方法在对低延迟代码是很有用的，它能够实现非阻塞的写入，这些写入不会被Java的JIT重新排序指令(instruction reordering)，这样它使用快速的存储-存储(store-store) barrier, 而不是较慢的存储-加载(store-load) barrier, 后者总是用在volatile的写操作上，这种性能提升是有代价的，虽然便宜，也就是写后结果并不会被其他线程看到，甚至是自己的线程，通常是几纳秒后被其他线程看到，这个时间比较短，所以代价可以忍受。<br>设想如下场景: 设置一个 volatile 变量为 null，让这个对象被 GC 掉，volatile write 是消耗比较大（store-load 屏障）的，但是 putOrderedInt 只会加 store-store 屏障，损耗会小一些。</p></blockquote><p>添加lazySet方法的原因:<a href="https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6275329" target="_blank" rel="noopener">https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6275329</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">As probably the last little JSR166 follow-up for Mustang,</span><br><span class="line">we added a &quot;lazySet&quot; method to the Atomic classes</span><br><span class="line">(AtomicInteger, AtomicReference, etc). This is a niche</span><br><span class="line">method that is sometimes useful when fine-tuning code using</span><br><span class="line">non-blocking data structures. The semantics are</span><br><span class="line">that the write is guaranteed not to be re-ordered with any</span><br><span class="line">previous write, but may be reordered with subsequent operations</span><br><span class="line">(or equivalently, might not be visible to other threads) until</span><br><span class="line">some other volatile write or synchronizing action occurs).</span><br><span class="line"></span><br><span class="line">The main use case is for nulling out fields of nodes in</span><br><span class="line">non-blocking data structures solely for the sake of avoiding</span><br><span class="line">long-term garbage retention; it applies when it is harmless</span><br><span class="line">if other threads see non-null values for a while, but you&apos;d</span><br><span class="line">like to ensure that structures are eventually GCable. In such</span><br><span class="line">cases, you can get better performance by avoiding</span><br><span class="line">the costs of the null volatile-write. There are a few</span><br><span class="line">other use cases along these lines for non-reference-based</span><br><span class="line">atomics as well, so the method is supported across all of the</span><br><span class="line">AtomicX classes.</span><br><span class="line"></span><br><span class="line">For people who like to think of these operations in terms of</span><br><span class="line">machine-level barriers on common multiprocessors, lazySet</span><br><span class="line">provides a preceeding store-store barrier (which is either</span><br><span class="line">a no-op or very cheap on current platforms), but no</span><br><span class="line">store-load barrier (which is usually the expensive part</span><br><span class="line">of a volatile-write).</span><br></pre></td></tr></table></figure><blockquote><p>weakCompareAndSet JDK 9之后Deprecated，本文已跳过。</p></blockquote><p>除了表示单个值的类之外，package中还包含Updater类，可用于在类的volatile字段上执行compareAndSet操作。 AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater和AtomicLongFieldUpdater是基于反射的，可提供对相关字段类型的访问。这些主要用于原子数据结构，同一节点的几个volatile字段（例如，树节点的链接）独立地原子更新。<strong>这些类在如何以及何时使用原子更新方面提供了更大的灵活性，但代价是更加笨拙的基于反射的设置、更不方便的使用和更弱的保证。</strong></p><p>AtomicIntegerArray、AtomicLongArray和AtomicReferenceArray类进一步将原子操作支持扩展到这些类型的数组。这些类还<strong>提供了数组元素的volatile访问语义，这是普通数组不支持的。</strong></p><p>AtomicMarkableReference类将单个布尔值与引用相关联。 例如，该位可能在数据结构中使用，表示被引用的对象在逻辑上已被删除。 AtomicStampedReference类将整数值与引用相关联。 例如，这可以用于表示与一系列更新相对应的版本号。</p><p>原子类主要设计为用于实现非阻塞数据结构和相关基础结构类的构建。 compareAndSet方法不是锁定的一般替代方法。 仅当对象的关键更新仅限于单个变量时，它才适用。</p><p>原子类不是java.lang.Integer和相关类的通用替换。它们没有定义equals，hashCode和compareTo等方法（由于原子变量预期会发生变化，所以它们不适合作为哈希表键）。</p><blockquote><p>后续会出文章解析：AtomicLong、Striped64、LongAdder<br>本文的目的主要是从大体上了解atomic及其内存语义</p></blockquote><blockquote><p>JDK 12<br><a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/concurrent/atomic/package-summary.html" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/concurrent/atomic/package-summary.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JDK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Concurrent </tag>
            
            <tag> Atomic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java JUC Atomic AtomicLong</title>
      <link href="/java-juc-atomic-atomiclong.html"/>
      <url>/java-juc-atomic-atomiclong.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>基于OpenJDK 12<br>本文的目的是为后续文章解析LongAdder做一个引子，以便两者对比。</p></blockquote><a id="more"></a><p><a href="https://www.jiankunking.com/java-concurrent-atomic-package.html" target="_blank" rel="noopener">Atomic Package解析参考（比如lazySet原理解析）</a></p><p>AtomicLong的常用方法如下：</p><ul><li>long addAndGet(long delta)：以原子方式将输入的数值与实例中的值（AtomicLong里的<br>value）相加，并返回结果。</li><li>compareAndSet(long expectedValue, long newValue)：如果输入的数值等于预期值，则以原子方<br>式将该值设置为输入的值。</li><li>long getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</li><li>void lazySet(long newValue)：最终会设置成newValue，<font color="DeepPink"><strong>使用lazySet设置值后，可能导致其他<br>线程在之后的一小段时间内还是可以读到旧的值</strong></font>。</li><li>long getAndSet(long newValue)：以原子方式设置为newValue的值，并返回旧值。</li></ul><p>AtomicLong示例代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class AtomicLongTest &#123;</span><br><span class="line">    static AtomicLong ai = new AtomicLong(1);</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        System.out.println(ai.getAndIncrement());</span><br><span class="line">        System.out.println(ai.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td></tr></table></figure><p>那么getAndIncrement是如何实现原子操作的呢？让我们一起分析其实现原理，getAndIncrement的源码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public final long getAndIncrement() &#123;</span><br><span class="line">   return U.getAndAddLong(this, VALUE, 1L);</span><br><span class="line">&#125;</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final long getAndAddLong(Object o, long offset, long delta) &#123;</span><br><span class="line">    long v;</span><br><span class="line">    do &#123;</span><br><span class="line">        v = getLongVolatile(o, offset);</span><br><span class="line">    &#125; while (!weakCompareAndSetLong(o, offset, v, v + delta));</span><br><span class="line">    return v;</span><br><span class="line">&#125;</span><br><span class="line">/** Volatile version of &#123;@link #getLong(Object, long)&#125;  */</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public native long getLongVolatile(Object o, long offset);</span><br><span class="line"></span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final boolean weakCompareAndSetLong(Object o, long offset,</span><br><span class="line">                                           long expected,</span><br><span class="line">                                           ong x) &#123;</span><br><span class="line">    return compareAndSetLong(o, offset, expected, x);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Atomically updates Java variable to &#123;@code x&#125; if it is currently</span><br><span class="line"> * holding &#123;@code expected&#125;.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;This operation has memory semantics of a &#123;@code volatile&#125; read</span><br><span class="line"> * and write.  Corresponds to C11 atomic_compare_exchange_strong.</span><br><span class="line"> *</span><br><span class="line"> * @return &#123;@code true&#125; if successful</span><br><span class="line"> */</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final native boolean compareAndSetLong(Object o, long offset,</span><br><span class="line">                                              long expected,</span><br><span class="line">                                              long x);</span><br></pre></td></tr></table></figure><blockquote><p>@HotSpotIntrinsicCandidate JDK的源码中，被@HotSpotIntrinsicCandidate标注的方法，在HotSpot中都有一套高效的实现，该高效实现基于CPU指令，运行时，HotSpot维护的高效实现会替代JDK的源码实现，从而获得更高的效率。</p></blockquote><p>源码getAndAddLong(Object o, long offset, long delta)中do while循环体是实现的关键所在，其逻辑是：<br>第一步先取得AtomicLong里存储的数值，<br>第二步对AtomicLong的当前数值进行加1操作，<br>第三步调用weakCompareAndSetLong方法来进行原子更新操作，该方法先检查当前数值是否等于v，等于意味着AtomicLong的值没有被其他线程修改过，则将weakCompareAndSetLong的当前数值更新成v+delta的值，如果不等于v，weakCompareAndSetLong方法会返回false，<font color="DeepPink"><strong>程序会进入do while循环重新进行</strong></font>weakCompareAndSetLong操作。</p><p><font color="DeepPink"><strong>这里隐含了一个问题，当对于共享变量（假设变量名字是a）的竞争非常激烈的时候，在当前线程读取a、改变a之间，a的值会被别的线程改变，从而导致当前线程一直重试（自旋），一直占用CPU。</strong></font></p><p><font color="DeepPink"><strong>这就引出另一个问题，对于锁抢占很激烈的时候，串行是最好的解决办法。比如使用synchronized。</strong></font></p><blockquote><p>java.util.concurrent.atomic中的原子操作基本是基于Unsafe或者VarHandle实现的。</p></blockquote><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/AtomicLong.java" target="_blank" rel="noopener">AtomicLong源码</a></p><blockquote><p>本文参考 《Java并发编程的艺术》 作者：方腾飞　魏鹏　程晓明</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JDK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Concurrent </tag>
            
            <tag> Atomic </tag>
            
            <tag> AtomicLong </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java JUC Atomic LongAdder</title>
      <link href="/java-juc-atomic-longadder.html"/>
      <url>/java-juc-atomic-longadder.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>基于OpenJDK 12</p></blockquote><a id="more"></a><p>阅读本文前，推荐先阅读以下两篇文章，以便能更好的对比理解：</p><ul><li><a href="https://www.jiankunking.com/java-concurrent-atomic-package.html" target="_blank" rel="noopener">译-Java-Concurrent-Atomic-Package-详解</a></li><li><a href="https://jiankunking.com/java-juc-atomic-atomiclong.html">Java-JUC-Atomic-AtomicLong</a></li></ul><p>LongAdder是JDK 1.8 新增的原子类，基于Striped64实现。 从官方文档看，LongAdder在高并发的场景下会比AtomicLong 具有更好的性能，代价是消耗更多的内存空间：</p><blockquote><p>This class is usually preferable to AtomicLong when multiple threads update a common sum that is used for purposes such as collecting statistics, not for fine-grained synchronization control. <font color="DeepPink"><strong>Under low update contention, the two classes have similar characteristics. But under high contention, expected throughput of this class is significantly higher, at the expense of higher space consumption.</strong></font></p></blockquote><p>那么LongAdder是怎么实现的？</p><p>先看一下LongAdder的类图：<br><img src="/images/java-juc-atomic-longadder/LongAdder%E7%B1%BB%E5%9B%BE.png" alt></p><p>基类Number，Number是一个抽象类其中没有任何逻辑，该类是byte、double、float、int、long、short的基类。</p><h1 id="Striped64"><a href="#Striped64" class="headerlink" title="Striped64"></a>Striped64</h1><h2 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h2><p>该部分翻译自Striped64源码注释，可以略过，概括起来就是：</p><blockquote><p>分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p></blockquote><hr><p>从Striped64类注释可以看到：</p><blockquote><p>Striped64是package内使用的，对于在64位元素上动态分片提供统一实现（感觉有点像：AbstractQueuedSynchronizer）<br>Striped64继承了Number类，这也就是说具体实现的子类也必须实现相关的内容</p></blockquote><p>该类维护一个原子更新变量的延迟初始化表，以及一个额外的“base”字段。表的大小是2的幂。索引使用掩码下的每个线程的hash code。这个类中的几乎所有声明都是package私有的，由子类直接访问。</p><p>表格内的元素是Cell类，Cell类是一个为了减少缓存争用而填充的AtomicLong的变种。填充对于大多数原子来说是多余的，因为它们通常不规则地分散在内存中，因此彼此之间不会有太多的干扰。但是，驻留在数组中的原子对象往往是彼此相邻的，因此在没有这种预防措施的情况下，最常见的情况是共享高速缓存线(这对性能有很大的负面影响)。</p><p>在某种程度上，因为Cell类相对较大，只有他们真正被需要的时候，我们才创建。<font color="DeepPink"><strong>如果没有竞争，那么所有的更新操作将对base字段实现。当发生第一次争用（也就是说如果第一次对base字段的CAS操作失败），初始化为大小是2的表格。当进一步的争用发生的时候,表的大小会加倍，直到达到等于大于cpu的数量。表在未使用之前一直为null。</strong></font></p><p>利用一个自旋锁（cellsBusy）来初始化和调整表的大小，以及用新Cells填充slots。这个地方没有必要使用阻塞锁，如果锁不可达，线程可以尝试其他的slots，或者尝试base字段。在这些重试期间，竞争加剧，但是降低了局部性，这仍然比阻塞锁来得好。</p><p>通过ThreadLocalRandom维护的Thread.probe字段用作每个线程的哈希码。我们让它们保持未初始化（为零）(如果它们以这种方式出现)，直到它们在插槽0竞争。出现竞争后初始化为通常不会和其他的的值冲突的值，比如线程的哈希码。在执行更新时发生CAS操作失败意味着出现了争用或者表碰撞，或两者都有。在发生冲突时，如果表的大小小于容量，那么它的大小将加倍，除非其他线程持有锁。如果哈希后的slot为空，并且锁可用，则创建一个新单元格。如果存在了那么会进行CAS尝试。通过双重哈希进行重试，利用一个辅助哈希（Marsaglia XorShift随机数算法）来尝试寻找一个空闲的slot。</p><p><font color="DeepPink"><strong>表的大小是有上限的，因为当线程多于CPU时，假设每个线程都绑定到一个CPU，就会有一个完美的散列函数将线程映射到插槽，从而消除冲突。当我们达到容量时，我们通过随机改变冲突线程的哈希代码来搜索这个映射。因为搜索是随机的，冲突只有通过CAS失败才知道，收敛可能会很慢，而且因为线程通常不会永远绑定到CPU，所以根本不会发生。然而，尽管有这些限制，在这些情况下观察到的竞争率通常很低。</strong></font></p><p><font color="DeepPink"><strong>Cell可能会出现不可用的情况，包括进行哈希的线程终止，或者由于table扩容导致线程哈希不正确。我们不尝试检测或删除这样的单元格，假设对于长时间运行的实例，争用会再次发生，因此最终将再次需要这些单元格;而对于短时间运行的实例，花费时间去销毁又没有什么必要。</strong></font></p><hr><h2 id="Cell类"><a href="#Cell类" class="headerlink" title="Cell类"></a>Cell类</h2><p>Atomiclong的变体，仅支持原始访问和CAS。</p><blockquote><p>Cell类被注解@jdk.internal.vm.annotation.Contended修饰。<br>Contended的作用（详细信息参见：<a href="http://openjdk.java.net/jeps/142" target="_blank" rel="noopener">JEP 142</a>）：<br>Define a way to specify that one or more fields in an object are likely to be highly contended across processor cores so that the VM can arrange for them not to share cache lines with other fields, or other objects, that are likely to be independently accessed.</p></blockquote><h2 id="示意图"><a href="#示意图" class="headerlink" title="示意图"></a>示意图</h2><p><img src="/images/java-juc-atomic-longadder/%E7%83%AD%E7%82%B9%E5%88%86%E7%A6%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>Striped64的核心方法是longAccumulate、doubleAccumulate，两者类似，下面主要看一下longAccumulate，<strong>对于这种代码，个人建议是理解思路即可，毕竟咱们又不是过来修改JDK的，如果真的要修改了或者有类似的需求了，再回来细看即可。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line">//x  元素</span><br><span class="line">//fn  更新函数，如果是add可以为null（这个约定避免了longadder中定义额外的变量或者函数）</span><br><span class="line">//wasUncontended 如果CAS在调用之前失败了，这个值为false</span><br><span class="line">final void longAccumulate(long x, LongBinaryOperator fn,</span><br><span class="line">                          boolean wasUncontended) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    //获取当前线程的probe值，如果为0，则需要初始化该线程的probe值</span><br><span class="line">    if ((h = getProbe()) == 0) &#123;</span><br><span class="line">    ThreadLocalRandom.current(); // force initialization</span><br><span class="line">        h = getProbe();</span><br><span class="line">        wasUncontended = true;</span><br><span class="line">    &#125;</span><br><span class="line">    boolean collide = false;  // True if last slot nonempty</span><br><span class="line">    done: for (;;) &#123;</span><br><span class="line">        Cell[] cs; Cell c; int n; long v;</span><br><span class="line">        //Cells不为空，进行操作</span><br><span class="line">        if ((cs = cells) != null &amp;&amp; (n = cs.length) &gt; 0) &#123;</span><br><span class="line">            //通过（hashCode &amp; (length - 1)）这种算法来实现取模 有种看到HashMap代码的感觉</span><br><span class="line">            //如果当前位置为null说明需要初始化</span><br><span class="line">            if ((c = cs[(n - 1) &amp; h]) == null) &#123;</span><br><span class="line">                //判断锁状态</span><br><span class="line">                if (cellsBusy == 0) &#123;       // Try to attach new Cell</span><br><span class="line">                    Cell r = new Cell(x);   // Optimistically create</span><br><span class="line">                    //再次判断锁状态，同时获取锁</span><br><span class="line">                    if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">                        try &#123;               // Recheck under lock</span><br><span class="line">                            Cell[] rs; int m, j;</span><br><span class="line">                            if ((rs = cells) != null &amp;&amp;</span><br><span class="line">                                (m = rs.length) &gt; 0 &amp;&amp;</span><br><span class="line">                                rs[j = (m - 1) &amp; h] == null) &#123;</span><br><span class="line">                                rs[j] = r;</span><br><span class="line">                                //创建成功跳出</span><br><span class="line">                                break done;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; finally &#123;</span><br><span class="line">                            //释放锁</span><br><span class="line">                            cellsBusy = 0;</span><br><span class="line">                        &#125;</span><br><span class="line">                        continue;           // Slot is now non-empty</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                collide = false;</span><br><span class="line">            &#125;</span><br><span class="line">            //运行到此说明cell的对应位置上已经有相应的Cell了，</span><br><span class="line">            //不需要初始化了</span><br><span class="line">            //CAS操作已经失败了，出现了竞争</span><br><span class="line">            else if (!wasUncontended)       // CAS already known to fail</span><br><span class="line">                wasUncontended = true;      // Continue after rehash</span><br><span class="line">            //这里尝试将x值加到a的value上 </span><br><span class="line">            else if (c.cas(v = c.value,</span><br><span class="line">                           (fn == null) ? v + x : fn.applyAsLong(v, x)))</span><br><span class="line">                //如果尝试成功，跳出循环，方法退出</span><br><span class="line">                break;</span><br><span class="line">            //cell数组最大为cpu的数量，</span><br><span class="line">            //cells != as表明cells数组已经被更新了 </span><br><span class="line">            //标记为最大状态或者说是过期状态</span><br><span class="line">            else if (n &gt;= NCPU || cells != cs)</span><br><span class="line">                collide = false;            // At max size or stale</span><br><span class="line">            else if (!collide)</span><br><span class="line">                collide = true;</span><br><span class="line">            //扩容 当前容量 * 2</span><br><span class="line">            else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    if (cells == cs)        // Expand table unless stale</span><br><span class="line">                        cells = Arrays.copyOf(cs, n &lt;&lt; 1);</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    cellsBusy = 0;</span><br><span class="line">                &#125;</span><br><span class="line">                collide = false;</span><br><span class="line">                continue;                   // Retry with expanded table</span><br><span class="line">            &#125;</span><br><span class="line">            h = advanceProbe(h);</span><br><span class="line">        &#125;</span><br><span class="line">        //尝试获取锁之后扩大Cells</span><br><span class="line">        else if (cellsBusy == 0 &amp;&amp; cells == cs &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">            try &#123;                           // Initialize table</span><br><span class="line">                if (cells == cs) &#123;</span><br><span class="line">                    //初始化cell表，初始容量为2。 </span><br><span class="line">                    Cell[] rs = new Cell[2];</span><br><span class="line">                    rs[h &amp; 1] = new Cell(x);</span><br><span class="line">                    cells = rs;</span><br><span class="line">                    break done;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                //释放cellsBusy锁</span><br><span class="line">                cellsBusy = 0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //如果创建cell表由于竞争导致失败，尝试将x累加到base上</span><br><span class="line">        // Fall back on using base</span><br><span class="line">        else if (casBase(v = base,</span><br><span class="line">                         (fn == null) ? v + x : fn.applyAsLong(v, x)))</span><br><span class="line">            break done;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * CASes the cellsBusy field from 0 to 1 to acquire lock.</span><br><span class="line"> */</span><br><span class="line">final boolean casCellsBusy() &#123;</span><br><span class="line">    return CELLSBUSY.compareAndSet(this, 0, 1);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * CASes the base field.</span><br><span class="line"> */</span><br><span class="line">final boolean casBase(long cmp, long val) &#123;</span><br><span class="line">    return BASE.compareAndSet(this, cmp, val);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一段的核心是这样的：</p><ul><li>longAccumulate会根据当前线程来计算一个哈希值，然后根据(hashCode &amp; (length - 1))取模，以定位到该线程被分散到的Cell数组中的位置</li><li>如果Cell数组还没有被创建，那么就去获取cellBusy这个锁（相当于锁，但是更为轻量级），如果获取成功，则初始化Cell数组，初始容量为2，初始化完成之后将x包装成一个Cell，哈希计算之后分散到相应的index上。如果获取cellBusy失败，那么会试图将x累计到base上，更新失败会重新尝试直到成功。</li><li>如果Cell数组已经被初始化过了，那么就根据线程的哈希值分散到一个Cell数组元素上，获取这个位置上的Cell并且赋值给变量a，如果a为null，说明该位置还没有被初始化，那么就初始化，当然在初始化之前需要竞争cellBusy变量。</li><li>如果Cell数组的大小已经最大了（大于等于CPU的数量），那么就需要重新计算哈希，来重新分散当前线程到另外一个Cell位置上再走一遍该方法的逻辑，否则就需要对Cell数组进行扩容，然后将原来的计数内容迁移过去。由于Cell里面保存的是计数值，所以扩容后没有必要做其他处理，直接根据index将旧的Cell数组内容复制到新的Cell数组中。</li></ul><h1 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h1><blockquote><p>LongAdder的基本思路就是分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p></blockquote><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>保持一个或者多个变量，初始值设置为零用于求和。当更新出现多个线程竞争时，变量集合动态增长以减少争用。最后当需要求和的时候或者说需要这个Long型的值时，可以通过把当前这些变量求和，合并后得出最终的和。</p><p><font color="DeepPink"><strong>LongAdder在一些高并发场景下表现要比AtomicLong好，比如多个线程同时更新一个求和的变量，比如统计集合的数量，但是不能用于细粒度同步控制，换句话说这个是可能有误差的（因为更新与读取是并行的）。在低并发场景场景下LongAdder和AtomicLong的性能表现没什么差别，但是当高并发竞争的时候，这个类将具备更好的吞吐性能，但是相应的也会耗费相当的空间。</strong></font></p><p>LongAdder继承了Number抽象类，但是并没有实现一些方法例如: equals、hashCode、compareTo，因为LongAdder实例的预期用途是进行一些比较频繁的变化，所以也不适合作为集合的key。</p><h2 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h2><p>看一下LongAdder有哪些方法：<br><img src="/images/java-juc-atomic-longadder/LongAdder%E5%87%BD%E6%95%B0%E5%88%97%E8%A1%A8.png" alt></p><p>下面主要解析LongAdder increment、sum方法，先看一下源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Equivalent to &#123;@code add(1)&#125;.</span><br><span class="line"> */</span><br><span class="line">public void increment() &#123;</span><br><span class="line">add(1L);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* Adds the given value.</span><br><span class="line">*</span><br><span class="line">* @param x the value to add</span><br><span class="line">*/</span><br><span class="line">public void add(long x) &#123;</span><br><span class="line">    Cell[] cs; long b, v; int m; Cell c;</span><br><span class="line">    if ((cs = cells) != null || !casBase(b = base, b + x)) &#123;</span><br><span class="line">    //到了这里 表明cs不为null or 线程有并发冲突，导致caseBase失败</span><br><span class="line">        boolean uncontended = true;</span><br><span class="line">        if (cs == null || // cells 为null</span><br><span class="line">            (m = cs.length - 1) &lt; 0 || // cells 不为null 但只有一个元素</span><br><span class="line">            (c = cs[getProbe() &amp; m]) == null || //哈希取模 对应位置元素为null</span><br><span class="line">            !(uncontended = c.cas(v = c.value, v + x))) //cas 替换失败（并发竞争）</span><br><span class="line">            longAccumulate(x, null, uncontended);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">* CASes the base field (Striped64类中的方法)</span><br><span class="line">*/</span><br><span class="line">final boolean casBase(long cmp, long val) &#123;</span><br><span class="line">    return BASE.compareAndSet(this, cmp, val);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//当在sum的过程中，有可能别的线程正在操作cells（因为没有加锁）</span><br><span class="line">//sum取的值，不一定准确</span><br><span class="line">public long sum() &#123;</span><br><span class="line">     Cell[] cs = cells;</span><br><span class="line">     long sum = base;</span><br><span class="line">     if (cs != null) &#123;</span><br><span class="line">        for (Cell c : cs)</span><br><span class="line">            if (c != null)</span><br><span class="line">                sum += c.value;</span><br><span class="line">    &#125;</span><br><span class="line">    return sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="LongAdder-vs-AtomicLong-Performance"><a href="#LongAdder-vs-AtomicLong-Performance" class="headerlink" title="LongAdder vs AtomicLong Performance"></a>LongAdder vs AtomicLong Performance</h2><p><a href="http://blog.palominolabs.com/2014/02/10/java-8-performance-improvements-longadder-vs-atomiclong/" target="_blank" rel="noopener">Java 8 Performance Improvements: LongAdder vs AtomicLong</a></p><h1 id="对比LongAccumulator"><a href="#对比LongAccumulator" class="headerlink" title="对比LongAccumulator"></a>对比LongAccumulator</h1><p>LongAdder类可以看做是LongAccumulator的一个特例，LongAccumulator提供了比LongAdder更强大、灵活的功能。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Creates a new instance using the given accumulator function</span><br><span class="line"> * and identity element.</span><br><span class="line"> * @param accumulatorFunction a side-effect-free function of two arguments</span><br><span class="line"> * @param identity identity (initial value) for the accumulator function</span><br><span class="line">*/</span><br><span class="line">public LongAccumulator(LongBinaryOperator accumulatorFunction,</span><br><span class="line">                           long identity) &#123;</span><br><span class="line">    this.function = accumulatorFunction;</span><br><span class="line">    base = this.identity = identity;</span><br><span class="line">&#125;</span><br><span class="line">@FunctionalInterface</span><br><span class="line">public interface LongBinaryOperator &#123;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Applies this operator to the given operands.</span><br><span class="line"> *</span><br><span class="line"> * @param left the first operand</span><br><span class="line"> * @param right the second operand</span><br><span class="line"> * @return the operator result</span><br><span class="line">*/</span><br><span class="line">long applyAsLong(long left, long right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构造函数其中accumulatorFunction一个双目运算接口，根据输入的两个参数返回一个计算值，identity则是LongAccumulator累加器的初始值。</p><p>accumulatorFunction主要用于Striped64 longAccumulate中使用，如果fn==null，则默认是相加，否则会调用fn.applyAsLong(v, x)</p><blockquote><p>LongAccumulator相比于LongAdder，可以为累加器提供非0的初始值，而LongAdder只能提供默认的0值。<br>另外，LongAccumulator还可以指定累加规则，比如累加或者相乘，只需要在构造LongAccumulator时，传入自定义的双目运算器即可，后者则内置累加规则。</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/LongAdder.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/LongAdder.java</a></p><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/jdk/internal/vm/annotation/Contended.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/jdk/internal/vm/annotation/Contended.java</a></p><p><a href="https://www.jianshu.com/p/9a7de5644dd4" target="_blank" rel="noopener">https://www.jianshu.com/p/9a7de5644dd4</a></p><p><a href="http://openjdk.java.net/jeps/142" target="_blank" rel="noopener">http://openjdk.java.net/jeps/142</a></p><p><a href="http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html</a></p>]]></content>
      
      
      <categories>
          
          <category> JDK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Concurrent </tag>
            
            <tag> Atomic </tag>
            
            <tag> LongAdder </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JRockit权威指南深入理解JVM 笔记</title>
      <link href="/java-jrockit-notes.html"/>
      <url>/java-jrockit-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《JRockit权威指南深入理解JVM》 </p><p>作者：Marcus Hirt , Marcus Lagergren</p><p>出版时间：2018-12-10</p><a id="more"></a><h1 id="起步"><a href="#起步" class="headerlink" title="起步"></a>起步</h1><h2 id="将应用程序迁移到JRockit"><a href="#将应用程序迁移到JRockit" class="headerlink" title="将应用程序迁移到JRockit"></a>将应用程序迁移到JRockit</h2><h3 id="命令行选项"><a href="#命令行选项" class="headerlink" title="命令行选项"></a>命令行选项</h3><p>在<font color="DeepPink"><strong>JRockit JVM中,主要有3类命令行选项,分别是系统属性、标准选项(以-X开头)和非标准选项(以-XX开头)。</strong></font></p><p>1、系统属性</p><p>设置JVM启动参数的方式有多种。以-D开头的参数会作为系统属性使用,这些属性可以为Java类库(如RMI等)提供相关的配置信息。例如,在启动的时候,如果设置了-Dcom.Rockin.mc.debug=true参数,则JRockit Mission Control会打印出调试信息。不过,R28之后的JRockit JVM版本废弃了很多之前使用过的系统属性,转而采用非标准选项和类似 HotSpot中虚拟机标志(VM flag)的方式设置相关选项。</p><p>2、标准选项</p><p>以-X开头的选项是大部分JVM厂商都支持的通用设置。例如,用于设置堆大小最大值的选项-Xmx在包括 JRockit在内的大部分JVM中都是相同的。当然,也存在例外,如JRockit中的选项-Xverbose会打印出可选的子模块日志信息,而在 HotSpot中,类似的(但实际上有更多的限制)选项是-verbose。</p><p>3、非标准选项</p><p>以-XX开头的命令行选项是各个JVM厂商自己定制的。这些选项可能会在将来的某个版本中被废弃或修改。如果JVM的参数配置中包含了以-XX开头的命令行选项,则在将Java应用程序从一种JVM迁移到另一种时,应该在启动M之前去除这些非标准选项确定了新的VM选项后才可以启动Java应用程序。</p><h1 id="自适应代码生成"><a href="#自适应代码生成" class="headerlink" title="自适应代码生成"></a>自适应代码生成</h1><h2 id="Java虚拟机"><a href="#Java虚拟机" class="headerlink" title="Java虚拟机"></a>Java虚拟机</h2><h3 id="字节码格式"><a href="#字节码格式" class="headerlink" title="字节码格式"></a>字节码格式</h3><p><a href="https://github.com/jiankunking/jvm-opcode" target="_blank" rel="noopener">Opcodes for the Java Virtual Machine</a></p><h4 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h4><p>程序,包含数据和代码两部分,其中数据作为操作数使用。对于字节码程序来说,如果操作数非常小或者很常用(如常量0),则这些操作数是直接内嵌在字节码指令中的。</p><p>较大块的数据,例如常量字符串或比较大的数字,是存储在class文件开始部分的常量池(constant pool)中的。当使用这类数据作为操作数时,使用的是常量池中数据的索引位置,而不是实际数据本身。</p><p>此外,<font color="DeepPink"><strong>Java程序中的方法、属性和类的元数据等也作为clas文件的组成部分,存储在常量池中。</strong></font></p><h2 id="自适应代码生成-1"><a href="#自适应代码生成-1" class="headerlink" title="自适应代码生成"></a>自适应代码生成</h2><h3 id="优化动态程序"><a href="#优化动态程序" class="headerlink" title="优化动态程序"></a>优化动态程序</h3><p>在汇编代码中,方法调用是通过call指令完成的。不同平台上call指令的具体形式不尽相同,不同类型的call指令,其具体格式也不尽相同。</p><p><font color="DeepPink"><strong>在面向对象的语言中,虚拟方法分派通常被编译为对分派表(dispatch table)中地址的间接调用(indirect call,即需要从内存中读取真正的调用地址)。这是因为,根据不同的类继承结构分派虚拟调用时可能会有多个接收者。每个类中都有一个分派表,其中包含了其虚拟调用的接收者信息。静态方法和确知只有一个接收者的虚拟方法可以被编译为对固定调用地址的直接调用(direct call)。一般来说,这可以大大加快执行速度。</strong></font><br><img src="/images/java-jrockit-note/%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E8%99%9A%E6%8B%9F%E8%B0%83%E7%94%A8.png" alt></p><p>假设应用程序是使用C++开发的,对代码生成器来说,在编译时已经可以获取到程序的所有结构性信息。例如,由于在程序运行过程中,代码不会发生变化,所以在编译时就可以从代码中判断出,某个虚拟方法是否只有一种实现。正因如此,编译器不仅不需要因为废弃代码而记录额外的信息,还可以将那些只有一种实现的虚拟方法转化为静态调用。</p><p>假如应用程序是使用Java开发的,起初某个虚拟方法可能只有一种实现,但Java允许在程序运行过程中修改方法实现。当JIT编译器需要编译某个虚拟方法时,更喜欢的是那些永远只存在一种实现的,这样编译器就可以像前面提到的C++编译器一样做很多优化,例如将虚拟调用转化为直接调用。但是,由于Java允许在程序运行期间修改代码,如果某个方法没有声明final修饰符,那它就有可能在运行期间被修改,即使它看起来几乎不可能有其他实现,编译器也不能将之优化为直接调用。</p><p>在Java世界中,有一些场景现在看起来一切正常,编译器可以大力优化代码,但是如果某天程序发生了改变的话,就需要将相关的优化全部撤销。对于Java来说,为了能够媲美C++程序的执行速度,就需要一些特殊的优化措施。</p><p>JVM使用的策略就是“赌”。JVM代码生成策略的假设条件是,正在运行的代码永远不变。事实上,大部分时间里确实如此。但如果正在运行的代码发生了变化,违反了代码优化的假设条件,就会触发其簿记系统(bookkeeping system)的回调功能。此时,基于原先假设条件生成的代码就需要被废弃掉,重新生成,例如为已经转化为直接调用的虚拟调用重新生成相关代码。因此,“赌输”的代价是很大的,但如果“赌赢”的概率非常高,则从中获得的性能提升就会非常大,值得一试。</p><p>一般来说,JVM和JIT编译器所做的典型假设包括以下几点：</p><ul><li>虚拟方法不会被覆盖。由于某个虚拟方法只存在一种实现,就可以将之优化为一个直接调用。</li><li>浮点数的值永远不会是NaN。大部分情况下,可以使用硬件指令来替换对本地浮点数函数库的调用。</li><li>某些try语句块中几乎不会抛出异常。因此,可以将catch语句块中的代码作为冷方法对待。</li><li>对于大多数三角函数来说,硬件指令fsin都能够达到精度要求。如果真的达不到,就抛出异常,调用本地浮点数函数库完成计算。</li><li>锁竞争并不会太激烈,初期可以使用自旋锁(spinlock)替代。</li><li>锁可能会周期性地被同一个线程获取和释放,所以,可以将对锁的重复获取操作和重复释放操作直接省略掉。</li></ul><h2 id="深入JIT编译器"><a href="#深入JIT编译器" class="headerlink" title="深入JIT编译器"></a>深入JIT编译器</h2><h3 id="优化字节码"><a href="#优化字节码" class="headerlink" title="优化字节码"></a>优化字节码</h3><blockquote><p>有些时候,对Java源代码做优化会适得其反。绝大部分写出可读性很差的代码的人都声称是为了优化性能,其实就是照着一些基准测试报告的结论写代码,而这些性能测试往往只涉及了字节码解释执行,没有经过JIT编译器优化,所以并不能代表应用程序在运行时的真实表现。例如,某个服务器端应用程序中包含了大量对数组元素的迭代访问操作,程序员参考了那些报告中的结论,没有设置循环条件,而是写一个无限for循环,置于try语句块中,并在catch语句块中捕获ArrayIndexOutOfBoundsException异常。这种糟糕的写法不仅使代码可读性极差,而且一旦运行时对之优化编译的话,其执行效率反而比普通循环方式低得多。原因在于,JVM的基本假设之一就是“异常是很少发生的”。基于这种假设,JVM会做一些相关优化,所以当真的发生异常时,处理成本就很高。</p></blockquote><h2 id="代码流水线"><a href="#代码流水线" class="headerlink" title="代码流水线"></a>代码流水线</h2><h3 id="代码生成概述"><a href="#代码生成概述" class="headerlink" title="代码生成概述"></a>代码生成概述</h3><blockquote><p>在生成优化代码时,如何分配寄存器非常重要。编译器教材上都将寄存器分配问题作为图的着色问题处理,这是因为同时用到的两个变量不能共享同一个寄存器,从这点上讲,与着色问题相同。同时使用的多个变量可以用图中相连接的节点来表示,这样,寄存器分配问题就可以被抽象为“如何为图中的节点着色,才能使相连节点有不同的颜色”。这里可用颜色的数量等于指定平台上可用寄存器的数量。不过,遗憾的是,从计算复杂性上讲,着色问题是NP-hard的,也就是说现在还没有一个高效的算法(指可以在多项式时间内完成计算)能解决这个问题。但是,着色问题可以在线性对数时间内给出近似解,因此大多数编译器都使用着色算法的某个变种来处理寄存器分配问题。</p></blockquote><h1 id="自适应内存管理"><a href="#自适应内存管理" class="headerlink" title="自适应内存管理"></a>自适应内存管理</h1><h2 id="堆管理基础"><a href="#堆管理基础" class="headerlink" title="堆管理基础"></a>堆管理基础</h2><h3 id="对象的分配与释放"><a href="#对象的分配与释放" class="headerlink" title="对象的分配与释放"></a>对象的分配与释放</h3><p><font color="DeepPink"><strong>一般来说,为对象分配内存时,并不会直接在堆上划分内存,而是先在线程局部缓冲(thread local buffer)或其他类似的结构中找地方放置对象,然后随着应用程序的运行、新对象的不断分配,垃圾回收逐次执行,这些对象可能最终会被提升到堆中保存,也有可能会当作垃圾被释放掉。</strong></font></p><p>为了能够在堆中给新创建的对象找一个合适的位置,内存管理系统必须知道堆中有哪些地方是空闲的,即还没有存活对象占用。内存管理系统使用空闲列表(free list)—串联起内存中可用内存块的链表,来管理内存中可用的空闲区域,并按照某个维度的优先级排序。</p><p>在空闲列表中搜索足够存储新对象的空闲块时,可以选择大小最适合的空闲块,也可以选择第一个放得下的空闲块。这其中会用到几种不同的算法去实现,各有优劣,后文会详细讨论。</p><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><p><font color="DeepPink"><strong>在后文中,根集合(root set)专指上述搜索算法的初始输入集合,即开始执行引用跟踪时的存活对象集合。一般情况下,根集合中包括了因为执行垃圾回收而暂停的应用程序的当前栈帧中所有的对象,包含了可以从当前线程上下文的用户栈和寄存器中能得到的所有信息。此外,根集合中还包含全局数据,例如类的静态属性。简单来说就是,根集合中包含了所有无须跟踪引用就可以得到的对象。</strong></font></p><p>Java使用的是准确式垃圾回收器(exact garbage collector),可以将对象指针类型数据和其他类型的数据区分开,只需要将元数据信息告知垃圾回收器即可,这些元数据信息,一般可以从Java方法的代码中得到。</p><p>近些年,使用信号来暂停线程的方式受到颇多争议。实践发现,在某些操作系统上,尤以Linux为例,应用程序对信号的使用和测试很不到位,还有一些第三方的本地库不遵守信号约定,导致信号冲突等事件的发生。因此,与信号相关的外部依赖已经不再可靠。</p><h3 id="分代垃圾回收"><a href="#分代垃圾回收" class="headerlink" title="分代垃圾回收"></a>分代垃圾回收</h3><p>事实上,将堆划分为两个或多个称为代(generation)的空间,并分别存放具有不同长度生命周期的对象,可以提升垃圾回收的执行效率。<font color="DeepPink"><strong>在JRockit中,新创建(young)的对象存放在称为新生代(nursery)的空间中,一般来说,它的大小会比老年代(old collections)小很多,随着垃圾回收的重复执行,生命周期较长的对象会被提升(promote)到老年代中。</strong></font>因此,新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生,分别用于对各自空间中的对象执行垃圾回收。</p><p>新生代垃圾回收的速度比老年代快几个数量级,即使新生代垃圾回收的频率更高,执行效率也仍然比老年代垃圾回收强,这是因为大多数对象的生命周期都很短,根本无须提升到老年代。理想情况下,新生代垃圾回收可以大大提升系统的吞吐量,并消除潜在的内存碎片。</p><h4 id="写屏障"><a href="#写屏障" class="headerlink" title="写屏障"></a>写屏障</h4><p>在实现分代式垃圾回收时,大部分JVM都是用名为写屏障(write barrier)的技术来记录执行垃圾回收时需要遍历堆的哪些部分。当对象A指向对象B时,即对象B成为对象A的属性的值时,就会触发写屏障,在完成属性域赋值后执行一些辅助操作。</p><p>写屏障的传统实现方式是将堆划分成多个小的连续空间(例如每块512字节),每块空间称为卡片(card),于是,堆被映射为一个粗粒度的卡表(card table)。当Java应用程序将某个对象赋值给对象引用时,会通过写屏障设置脏标志位(dirty bit),将该对象所在的卡片标记为脏。</p><p>这样,遍历从老年代指向新生代的引用时间得以缩短,垃圾回收器在做新生代垃圾回收时只需要检查老年代中被标记为脏的卡片所对应的内存区域即可。</p><h3 id="JRockit中的垃圾回收"><a href="#JRockit中的垃圾回收" class="headerlink" title="JRockit中的垃圾回收"></a>JRockit中的垃圾回收</h3><h4 id="老年代垃圾回收"><a href="#老年代垃圾回收" class="headerlink" title="老年代垃圾回收"></a>老年代垃圾回收</h4><p>JRockit不仅将卡表应用于分代式垃圾回收,还用在并发标记阶段结束时的清理工作,避免搜索整个存活对象图。这是因为JRockit需要找出在执行并发标记操作时,应用程序又创建了哪些对象。修改引用关系时通过写屏障可以更新卡表,存活对象图中的每个区域使用卡表中的一个卡片表示,卡片的状态可以是干净或者脏,有新对象创建或者对象引用关系修改了的卡片会被标记为脏。在并发标记阶段结束时,垃圾回收器只需要检查那些标记为脏的卡片所对应的堆中区域即可,这样就可以找到在并发标记期间新创建的和被更新过引用关系的对象。</p><h2 id="性能与伸缩性"><a href="#性能与伸缩性" class="headerlink" title="性能与伸缩性"></a>性能与伸缩性</h2><h3 id="线程局部分配"><a href="#线程局部分配" class="headerlink" title="线程局部分配"></a>线程局部分配</h3><p><font color="DeepPink"><strong>在JRockit中,使用了名为线程局部分配(thread local allocation)的技术来大幅加速对象的分配过程。正常情况下,在线程内的缓冲区中为对象分配内存要比直接在需要同步操作的堆上分配内存快得多。垃圾回收器在堆上直接分配内存时是需要对整个堆加锁的,对于多线程竞争激烈的应用程序来说,这将会是一场灾难。</strong></font>因此,如果每个Java线程能够有一块局部对象缓冲区那么绝大部分的对象分配操作只需要移动一下指针即可完成,在大多数硬件平台上,只需要一条汇编指令就行了。这块转为分配对象而保留的区域,就称为线程局部缓冲区(thread local area,TLA)。</p><p>为了更好地利用缓存,达到更高的性能,一般情况下,TLA的大小介于16KB到128KB之间,当然,也可以通过命令行参数显式指定。<font color="DeepPink"><strong>当TLA被填满时,垃圾回收器会将TLA中的内容提升到堆中。因此,可以将TLA看作是线程中的新生代内存空间</strong></font>。</p><p>当Java源代码中有new操作符,并且JIT编译器对内存分配执行高级优化之后,内存分配的伪代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">object allocateNewobject(Class objectclass)&#123;</span><br><span class="line">Thread current getcurrentThread():</span><br><span class="line">int objectSize=alignedSize(objectclass)</span><br><span class="line">if(current.nextTLAOffset+objectSize&gt; TLA_SIZE)&#123;</span><br><span class="line">current.promoteTLAToHeap();//慢,而且是同步操作</span><br><span class="line">current.nextTLAOffset=0;</span><br><span class="line">&#125;</span><br><span class="line">Object ptr= current.TLAStart+current.nextTLAOffset:</span><br><span class="line">current.nextTLAOffset + objectSize;</span><br><span class="line">return ptr:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>为了说明内存分配问題,在上面的伪代码中省略了很多其他关联操作。例如如果待分配的对象非常大,超过了某个阈值,或对象太大导致无法存放在TLA中,则会直接在堆中为对象分配内存。</p></blockquote><h3 id="NUMA架构"><a href="#NUMA架构" class="headerlink" title="NUMA架构"></a>NUMA架构</h3><p>NUMA(non-uniform memory access,非统一内存访问模型)架构的出现为垃圾回收带来了更多挑战。<font color="DeepPink"><strong>在NUMA架构下,不同的处理器核心通常访问各自的内存地址空间,这是为了避免因多个CPU核心访问同一内存地址造成的总线延迟。</strong></font>每个CPU核心都配有专用的内存和总线，因此CPU核心在访问其专有内存时速度很快,而要访问相邻CPU核心的内存时就会相对慢些,CPU核心相距越远,访问速度越慢(也依赖于具体配置)传统上,多核CPU是按照UMA(uniform memory access,统一内存访问模型)架构运行的,所有的CPU核心按照统一的模式无差别地访问所有内存。</p><p>为了更好地利用NUMA架构,垃圾回收器线程的组织结构应该做相应的调整。如果某个CPU核心正在运行标记线程,那么该线程所要访问的那部分堆内存最好能够放置在该CPU的专有内存中,这样才能发挥NUMA架构的最大威力。在最坏情况下,如果标记线程所要访问的对象位于其他NUMA节点的专有内存中,这时垃圾回收器通常需要一个启发式对象移动算法。这是为了保证使用时间上相近的对象在存储位置上也能相近,如果这个算法能够正确工作,还是可以带来不小的性能提升的。这里所面临的主要问题是如何避免对象在不同NUMA节点的专有内存中重复移动。理论上,自适应运行时系统应该可以很好地处理这个问题。</p><h3 id="大内存页"><a href="#大内存页" class="headerlink" title="大内存页"></a>大内存页</h3><p>内存分配是通过操作系统及其所使用的页表完成的。操作系统将物理内存划分成多个页来管理,从操作系统层面讲,页是实际分配内存的最小单位。传统上,页的大小是以4KB为基本单位划分的,页操作对进程来说是透明的,进程所使用的是虚拟地址空间,并非真正的物理地址。为了便于将虚拟页面转换为实际的物理内存地址,可使用名为旁路转换缓冲(translation lookaside buffer,TLB)的缓存来加速地址的转换操作。从实现上看,如果页面的容量非常小的话,会导致频繁出现旁路转换缓冲丢失的情况。</p><p>修复这个问题的一种方法就是将页面的容量调大几个数量级,例如以MB为基本单位。现代操作系统普遍倾向于支持这种大内存页机制。</p><p>很明显,当多个进程分别在各自的寻址空间中分配内存,而页面的容量又比较大时,随着使用的页面数量越来越多,碎片化的问题就愈发严重,像进程要分配的内存比页面容量稍微大一点的情况,就会浪费很多存储空间。对于在进程内自己管理内存分配回收、并有大量内存空间可用的运行时来说,这不算什么问题,因为运行时可以通过抽象出不同大小的虚拟页面来解决。</p><blockquote><p>通常情况下,对于那些内存分配和回收频繁的应用程序来说,使用大内存页可以使系统的整体性能至少提升10%。 JRockit对大内存页有很好的支持。</p></blockquote><h2 id="近实时垃圾回收"><a href="#近实时垃圾回收" class="headerlink" title="近实时垃圾回收"></a>近实时垃圾回收</h2><h3 id="JRockit-Real-Time"><a href="#JRockit-Real-Time" class="headerlink" title="JRockit Real Time"></a>JRockit Real Time</h3><p><font color="DeepPink"><strong>低延迟的代价是垃圾回收整体时间的延长</strong></font>。相比于并行垃圾回收,在程序运行的同时并发垃圾回收的难度更大,而频繁中断垃圾回收则可能带来更多的麻烦。事实上,这并非什么大问题,因为大多数使用JRockit Real Time的<font color="DeepPink"><strong>用户更关心系统的可预测性,而不是减少垃圾回收的总体时间。大多数用户认为暂停时间的突然增长比垃圾回收总体时间的延长更具危害性</strong></font>。</p><h4 id="软实时的有效性"><a href="#软实时的有效性" class="headerlink" title="软实时的有效性"></a>软实时的有效性</h4><p>软实时是JRockit Real Time的核心机制。但<font color="DeepPink"><strong>非确定性系统如何提供指定程度的确定性,例如像垃圾回收器这样的系统如何保证应用程序的暂停时间不会超过某个阈值?严格来说,无法提供这样的保证</strong></font>,但由于这样的极端案例很少,所以也就无关紧要了。</p><p>当然,没有什么万全之策,确实存在无法保证暂停时间的场景。但实践证明,对于那些堆中存活对象约占30%-50%的应用程序来说, JRockit Real Time的表现可以满足服务需要,而且随着JRockit Real Time各个版本的发行,30%-50%这个阈值在不断提升,可支持的暂停时间阈值则不断降低。</p><h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ul><li>高效的并行执行</li><li>细分垃圾回收过程,将之变成几个可回滚、可中断的子任务(work packet)</li><li>高效的启发式算法</li></ul><p><font color="DeepPink"><strong>事实上,实现低延迟的关键仍是尽可能多让Java应用程序运行,保持堆的使用率和碎片化程度在一个较低的水平</strong></font>。在这一点上, JRockit Real Time使用的是贪心策略,即尽可能推迟STW式的垃圾回收操作,希望问题能够由应用程序自身解决,或者能够减少不得不执行STW式操作的情况,最好在具体执行的时候需要处理的对象也尽可能少一些。</p><p>JRockit Real Time中,垃圾回收器的工作被划分为几个子任务。如果在执行其中某个子任务时(例如整理堆中的某一部分内存),应用程序的暂停时间超过了阈值,那么就放弃该子任务恢复应用程序的执行。用户根据业务需要指定可用于完成垃圾回收的总体时间,有些时候,某些子任务已经完成,但没有足够的时间完成整个垃圾回收工作,这时为了保证应用程序的运行,不得不废弃还未完成的子任务,待到下次垃圾回收的时候再重新执行,指定的响应时间越短,则废弃的子任务可能越多。</p><p>前面介绍过的标记阶段的工作比较容易调整,可以与应用程序并发执行。但清理和整理阶段则需要暂停应用程序线程(STW)。幸运的是,标记阶段会占到垃圾回收总体时间的90%。如果暂停应用程序的时间过长,则不得不终止当前垃圾回收任务,重新并发执行,期望问题可以自动解决。之所以将垃圾回收划分为几个子任务就是为了便于这一目标的实现。</p><h2 id="内存操作相关API"><a href="#内存操作相关API" class="headerlink" title="内存操作相关API"></a>内存操作相关API</h2><h3 id="析构方法"><a href="#析构方法" class="headerlink" title="析构方法"></a>析构方法</h3><blockquote><p>Java中的析构函数的设计就是一个失误,应避免使用。</p></blockquote><p>这不仅仅是我们的意见,也是Java社区的一致意见。</p><h3 id="JVM的行为差异"><a href="#JVM的行为差异" class="headerlink" title="JVM的行为差异"></a>JVM的行为差异</h3><p>对于JVM来说,一定谨记,编程语言只能提醒垃圾回收器工作。就Java而言,在设计上它本身并不能精确控制内存系统。例如,假设两个ⅣM厂商所实现软引用在缓存中具有相同的存活时间,这本就是不切实际的。</p><p>另外一个问题就是大量用户对System.gc()方法的错误使用。<font color="DeepPink"><strong>System.gc()方法仅仅是提醒运行时“现在可以做垃圾回收了”。在某些JVM实现中,频繁调用该方法导致了频繁的垃圾回收操作,而在某些JVM实现中,大部分时间忽略了该调用。</strong></font></p><p>我过去任职为性能顾问期间,多次看到该方法被滥用。很多时候,只是去掉对 System.gc方法的几次调用就可以大幅提升性能,这也是 JRock中会有命令行参数-xx:AllowSystemGC=False来禁用System,gc方法的原因。</p><h2 id="陷阱与伪优化"><a href="#陷阱与伪优化" class="headerlink" title="陷阱与伪优化"></a>陷阱与伪优化</h2><p>部分开发人员在写代码时,有时会写一些“经过优化的”的代码,期望可以帮助完成垃圾回收的工作,但实际上,这只是他们的错觉。记住,过早优化是万恶之源。就Java来说,很难在语言层面控制垃圾回收的行为。这里的主要问题时,开发人员误以为垃圾回收器有固定的运行模式,并妄图去控制它。</p><p>除了垃圾回收外,对象池(object poll)也是Java中常见的伪优化(false optimization)。有人认为,保留一个存活对象池来重新使用已创建的对象可以提升垃圾回收的性能,但实际上,对象池不仅增加了应用程序的复杂度,还很容易出错。对于现代垃圾收集器来说,使用java.lang.ref.Reference系列类实现缓存,或者直接将无用对象的引用置为null就好了,不用多操心。</p><p>事实上,基于现代VM,如果能够合理利用书本上的技巧,例如正确使用java.lang.ref.Reference系列类,注意Java的动态特性,完全可以写出运行良好的应用程序。<font color="DeepPink"><strong>如果应用程序真的有实时性要求,那么一开始就不该用Java编写,而应该使用那些由程序员手动控制内存的静态编程语言来实现应用程序。</strong></font></p><h2 id="JRockit中的内存管理"><a href="#JRockit中的内存管理" class="headerlink" title="JRockit中的内存管理"></a>JRockit中的内存管理</h2><p><font color="DeepPink"><strong>需要注意的是,花大力气鼓捣JVM参数并不一定会使应用程序性能有多么大的提升,而且反而可能会干扰JVM的正常运行。</strong></font></p><h1 id="线程与同步"><a href="#线程与同步" class="headerlink" title="线程与同步"></a>线程与同步</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>每个对象都持有与同步操作相关的信息,例如当前对象是否作为锁使用,以及锁的具体实现等。一般情况下,为了便于快速访问,这些信息被保存在每个对象的对象头的锁字(lock word)中。JRockit使用锁字中的一些位来存储垃圾回收状态信息,虽然其中包含了垃圾回收信息,但是本书还是称之为锁字。</p><p>对象头还包含了指向类型信息的指针,在 JRockit中,这称为类块(class block)下图是 JRockit中Java对象在不同的CPU平台上的内存布局。为了节省内存,并加速解引用操作,对象头中所有字的长度是32位。类块是一个32位的指针,指向另一个外部结构,该结构包含了当前对象的类型信息和虚分派表(virtual dispatch table)等信息。</p><p><img src="/images/java-jrockit-note/%E5%AF%B9%E8%B1%A1%E5%A4%B4%E5%B8%83%E5%B1%80.png" alt><br>就目前来看,在绝大部分JVM(包括JRockit)中,对象头是使用两个32位长的字来表示的。在JRockit中,偏移为0的对象指针指向当前对象的类型信息,接下来是4字节的锁字。在SPARC平台上,对象头的布局刚好反过来,因为在使用原子指令操作指针时,如果没有偏移的话,效率会更高。与锁字不同,类块并不为原子操作所使用,因此在SPARC平台上,类块被放在锁字后面。</p><blockquote><p>原子操作(atomic operation)是指全部执行或全部不执行的本地指令。当原子指令全部执行时,其操作结果需要对所有潜在访问者可见。</p></blockquote><p><font color="DeepPink"><strong>原子操作用于读写锁字,具有排他性,这是实现JVM中同步块的基础。</strong></font></p><h3 id="难以调试"><a href="#难以调试" class="headerlink" title="难以调试"></a>难以调试</h3><blockquote><p>死锁是指两个线程都在等待对方释放自己所需的资源,结果导致两个线程都进入休眠状态。很明显,它们再也醒不过来了。活锁的概念与死锁类似,区别在于线程在竟争时会采取主动操作,但无法获取锁。这就像两个人面对面前进,在一个很窄的走廊相遇,为了能继续前进,他们都向侧面移动,但由于移动的方向相反导致还是无法前进。</p></blockquote><h2 id="Java-API"><a href="#Java-API" class="headerlink" title="Java API"></a>Java API</h2><h3 id="synchronized关键字"><a href="#synchronized关键字" class="headerlink" title="synchronized关键字"></a>synchronized关键字</h3><p>在Java中,关键字synchronized用于定义一个临界区,既可以是一段代码块,也可以是个完整的方法,如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public synchronized void setGadget(Gadget g)&#123;</span><br><span class="line">this.gadget = g;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的方法定义中包含synchronized关键字,因此每次只能有一个线程修改给定对象的gadget域。</p><p><font color="DeepPink"><strong>在同步方法中,监视器对象是隐式的,即当前对象this,而对静态同步方法来说,监视器对象是当前对象的类对象。</strong></font>上面的示例代码与下面的代码是等效的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public void setGadget(Gadget g)&#123;</span><br><span class="line">synchronized(this)&#123;</span><br><span class="line">this.gadget = g;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="java-lang-Thread类"><a href="#java-lang-Thread类" class="headerlink" title="java.lang.Thread类"></a>java.lang.Thread类</h3><p>Java中的线程也有优先级概念,但是否真的起作用取决于JVM的具体实现。setPriority方法用于设置线程的优先级,提示JVM该线程更加重要或不怎么重要。当然,对于大多数JVM来说,显式地修改线程优先级没什么大帮助。当运行时“有更好的方案”时, JRockit JVM甚至会忽略Java线程的优先级。</p><p>正在运行的线程可以通过调用yield方法主动放弃剩余的时间片,以便其他线程运行,自身休眠(调用wait方法)或等待其他线程结束再运行(调用join方法)。</p><h3 id="volatile-关键字"><a href="#volatile-关键字" class="headerlink" title="volatile 关键字"></a>volatile 关键字</h3><p>在多线程环境下,对某个属性域或内存地址进行写操作后,其他正在运行的线程未必能立即看到这个结果。在某些场景中,要求所有线程在执行时需要得知某个属性最新的值,为此,Java提供了关键字volatile来解决此问题。</p><p><font color="DeepPink"><strong>使用volatile修饰属性后,可以保证对该属性域的写操作会直接作用到内存中。原本,数据操作仅仅将数据写到CPU缓存中,过一会再写到内存中,正因如此,在同一个属性域上,不同的线程可能看到不同的值。目前,JVM在实现volatile关键字时,是通过在写属性操作后插入内存屏障代码来实现的,只不过这种方法有一点性能损耗。</strong></font></p><p>人们常常难以理解“为什么不同的线程会在同一个属性域上看到不同的值”。<font color="DeepPink"><strong>一般来说,目前的机器的内存模型已经足够强,或者应用程序的本身结构就不容易使非volatile属性出现这个问题。但是,考虑到JIT优化编译器可能会对程序做较大改动,如果开发人员不留心的话,还是会出现问题的。</strong></font>下面的示例代码解释了在Java程序中,为什么内存语义如此重要,尤其是当问题还没表现出来的时候。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public class My Thread extends Thread&#123;</span><br><span class="line">private volatile boolean finished;</span><br><span class="line">public void run()&#123;</span><br><span class="line">while(!finished)&#123;</span><br><span class="line">   //</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">public void signalDone()&#123;</span><br><span class="line">this.finished = true</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果定义变量finished时没有加上volatile关键字,那么在理论上,JIT编译器在优化时,可能会将之修改为只在循环开始前加载一次finished的值,但这就改变了代码原本的含义如果finished的值是false,那么程序就会陷入无限循环,即使其他线程调用了signalDone方法也没用。<font color="DeepPink"><strong>Java语言规范指明,如果编译器认为合适的话,可以为非 volatile变量在线程内创建副本以便后续使用。</strong></font></p><blockquote><p>由于一般会使用内存屏障来实现volatile关键字的语义,会导致CPU缓存失效,降低应用程序整体性能,使用的时候要谨慎。</p></blockquote><h2 id="Java中线程与同步机制的实现"><a href="#Java中线程与同步机制的实现" class="headerlink" title="Java中线程与同步机制的实现"></a>Java中线程与同步机制的实现</h2><h3 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h3><p>现在CPU架构中,普遍使用了数据缓存机制以大幅提升CPU对数据的读写速度,减轻处理器总线的竞争程度。正如所有的缓存系统一样,这里也存在一致性问题,对于多处理器系统来说尤其重要,因为多个处理器有可能同时访问内存中同一位置的数据内存模型定义了不同的CPU,在同时访问内存中同一位置时,是否会看到相同的值的情况。</p><p>强内存模型(例如x86平台)是指,当某个CPU修改了某个内存位置的值后,其他的CPU几乎自动就可以看到这个刚刚保存的值。在这种内存模型之下,内存写操作的执行顺序与代码中的排列顺序相同。弱内存模型(例如IA-64平台)是指,当某个CPU修改了某个内存位置的值后其他的CPU不一定可以看到这个刚刚保存的值(除非CPU在执行写操作时附有特殊的内存屏障类指令),更普遍的说,所有由Java程序引起的内存访问都应该对其他所有CPU可见,但事实上却不能保证立即可见。</p><h3 id="同步的实现"><a href="#同步的实现" class="headerlink" title="同步的实现"></a>同步的实现</h3><h4 id="原生机制"><a href="#原生机制" class="headerlink" title="原生机制"></a>原生机制</h4><p>从计算机最底层CPU结构来说,同步是使用原子指令实现的,各个平台的具体实现可能有所不同。以x86平台为例,它使用了专门的锁前缀(lock prefix)来实现多处理器环境中指令的原子性。</p><p>在大多数CPU架构中,标准指令(例如加法和减法指令)都可以实现为原子指令。</p><p>在微架构( micro- architecture)层面,原子指令的执行方式在各个平台上不尽相同。一般情况下,它会暂停CPU流水线的指令分派,直到所有已有的指令都完成执行,并将操作结果刷入到内存中。此外,该CPU还会阻止其他CPU对相关缓存行的访问,直到该原子指令结束执行。在现代x86硬件平台上,如果屏障指令(fence instruction)中断了比较复杂的指令执行,则该原子指令可能需要等上很多个时钟周期才能完成执行。<font color="DeepPink"><strong>因此,不仅是过多的临界区会影响系统性能锁的具体实现也会影响性能,当频繁对较小的临界区执行加锁、解锁操作时,性能损耗更是巨大。</strong></font></p><h3 id="同步在字节码中的实现"><a href="#同步在字节码中的实现" class="headerlink" title="同步在字节码中的实现"></a>同步在字节码中的实现</h3><p>Java字节码中有两条用于实现同步的指令,分别是monitorenter和monitorexit,它们都会从执行栈中弹出一个对象作为其操作数。使用javac编译源代码时,若遇到显式使用监视器对象的同步代码,则为之生成相应的monitorenter指令和monitorexit指令。</p><h2 id="对于线程与同步的优化"><a href="#对于线程与同步的优化" class="headerlink" title="对于线程与同步的优化"></a>对于线程与同步的优化</h2><h3 id="锁膨胀与锁收缩"><a href="#锁膨胀与锁收缩" class="headerlink" title="锁膨胀与锁收缩"></a>锁膨胀与锁收缩</h3><blockquote><p>默认情况下, JRockit使用一个小的自旋锁来实现刚膨胀的胖锁,只持续很短的时间。乍看之下,这不太符合常理,但这么做确实是很有益处的。如果锁的竟争确实非常激烈,而导致线程长时间自旋的话,可以使用命令行参数-XX:UseFatSpin=false禁用此方式。作为胖锁的一部分,自旋锁也可以利用自适应运行时获取到的反馈信息,这部分功能默认是禁用的,可以使用命令行参数-XX:UseAdaptiveFatSpin=true来开启。</p></blockquote><h3 id="延迟解锁"><a href="#延迟解锁" class="headerlink" title="延迟解锁"></a>延迟解锁</h3><p>如何分析很多线程局部的解锁,以及重新加锁的操作只会降低程序执行效率?这是否是程序运行的常态?运行时是否可以假设每个单独的解锁操作实际上都是不必要的?</p><p>如果某个锁每次被释放后又立刻都被同一个线程获取,则运行时可以做上述假设。但只要有另外某个线程试图获取这个看起来像是未被加锁的监视器对象(这种情况是符合语义的),这种假设就不再成立了。这时为了使这个监视器对象看起来像是一切正常,原本持有该监视器对象的线程需要强行释放该锁。这种实现方式称为延迟解锁,在某些描述中也称为偏向锁(biased locking)。</p><p>即使某个锁完全没有竞争,执行加锁和解锁操作的开销仍旧比什么都不做要大。而使用原子指令会使该指令周围的Java代码都产生额外的执行开销。</p><p>从以上可以看出,假设大部分锁都只在线程局部起作用而不会出现竞争情况,是有道理的。在这种情况下,使用延迟解锁的优化方式可以提升系统性能。当然,天下没有免费的午餐,如果某个线程试图获取某个已经延迟解锁优化的监视器对象,这时的执行开销会被直接获取普通监视器对象大得多,因为这个看似未加锁的监视器对象必须要先被强行释放掉因此,不能一直假设解锁操作是不必要的,需要对不同的运行时行为做针对性的优化。</p><p>1.实现</p><p>实现延迟解锁的语义其实很简单。</p><p>实现 monitorenter指令。</p><ul><li><font color="DeepPink"><strong>如果对象是未锁定的,则加锁成功的线程将继续持有该锁,并标记该对象为延迟加锁的。</strong></font></li><li><font color="DeepPink"><strong>如果对象已经被标记为延迟加锁的</strong></font>：<ul><li><font color="DeepPink"><strong>如果对象是被同一个线程加锁的,则什么也不做(大体上是一个递归锁)</strong></font></li><li><font color="DeepPink"><strong>如果对象是被另一个线程加锁的,则暂停该线程对锁的持有状态,检查该对象真实的加锁状态,即是已加锁的还是未加锁的,这一步操作代价高昂,需要遍历调用栈。如果对象是已加锁的,则将该锁转换为瘦锁,否则强制释放该锁,以便可以被新线程获取到。</strong></font></li></ul></li></ul><p>实现monitorexit指令:如果是延迟加锁的对象,则什么也不做,保留其已加锁状态,即执行延迟解锁。</p><p>为了能解除线程对锁的持有状态,必须要先暂停该线程的执行,这个操作有不小的开销。在释放锁之后,锁的实际状态会通过检查线程栈中的锁符号来确定。延迟解锁使用自己的锁符号,以表示“该对象是被延迟锁定的”。</p><p>如果延迟锁定的对象从来也没有被撤销过,即所有的锁都只在线程局部内发挥作用,那么使用延迟锁定就可以大幅提升系统性能。但在实际应用中,如果我们的假设不成立,运行时就不得不一遍又一遍地释放已经被延迟加锁的对象,这种性能消耗实在承受不起。因此,运行时需要记录下监视器对象被不同线程获取到的次数,这部分信息存储在监视器对象的锁字中,称为转移位(transfer bit)。</p><p>如果监视器对象在不同的线程之间转移的次数过多,那么该对象、其类对象或者其类的所有实例都可能会被禁用延迟加锁,只会使用标准的胖锁和瘦锁来处理加锁或解锁操作。</p><p>正如之前介绍过的,对象首先是未加锁状态的,然后线程T1执行monitorenter指令,使之进入延迟加锁状态。但<font color="DeepPink"><strong>如果线程T1在该对象上执行了monitorexit指令,这时系统会假装已经解锁了,但实际上仍是锁定状态,锁对象的锁字中仍记录着线程T1的线程ID</strong></font>。在此之后线程T1如果再执行加锁操作,就不用再执行相关操作了。</p><p><font color="DeepPink"><strong>如果另一个线程T2试图获取同一个锁,则之前所做“该锁绝大部分被线T1程使用”的假设不再成立,会受到性能惩罚,将锁字中的线程ID由线程T1的ID替换为线程T2的</strong></font>。如果这情况经常出现,那么可能会禁用该对象作为延迟锁,并将该对象作为普通的瘦锁使用。</p><h2 id="陷阱与伪优化-1"><a href="#陷阱与伪优化-1" class="headerlink" title="陷阱与伪优化"></a>陷阱与伪优化</h2><h3 id="Thread-stop、Thread-resume和Thread-suspend"><a href="#Thread-stop、Thread-resume和Thread-suspend" class="headerlink" title="Thread.stop、Thread.resume和Thread.suspend"></a>Thread.stop、Thread.resume和Thread.suspend</h3><p>永远不要使用Thread.stop方法、Thread.resume方法或Thread.suspend方法并小心处理使用这些方法的历史遗留代码。</p><p>普遍建议使用wait方法、notify方法或volatile变量来做线程间的同步处理。</p><h3 id="双检查锁"><a href="#双检查锁" class="headerlink" title="双检查锁"></a>双检查锁</h3><p>如果对内存模型和CPU架构缺乏理解的话,即使使用平遇到问题。以下面的代码为例,其目的是实现单例模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class Gadget Holder&#123;</span><br><span class="line">private Gadget theGadget;</span><br><span class="line">public synchronized Gadget cetGadget()&#123;</span><br><span class="line">if (this.theGadget == null)&#123;</span><br><span class="line">this.theGadget = new Gadget();</span><br><span class="line">&#125;</span><br><span class="line">return this.theGadget;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码是线程安全的,因为getGadget方法是同步但当Gadget类的构造函数已经执行过一次之后,再执行同优化性能,将之改造为下面的代码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public Gadget getGadget()&#123;</span><br><span class="line">if (this.theGadget == null)&#123;</span><br><span class="line">synchronized(this)&#123;</span><br><span class="line">if(this.theGadget == null))&#123;</span><br><span class="line">this.theGadget = new Gadget();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return this.theGadget;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码使用了一个看起来很“聪明”的技巧,如果行同步操作,而是直接返回已有的对象;如果对象还未创建值。这样可以保证“线程安全”。</p><p>上述代码就是所谓的双检查锁(double checked locking),下面分析一下这段代码的问题。<font color="DeepPink"><strong>假设某个线程经过内层的空值检查,开始初始化theGadget字段的值,该线程需要为新对象分配内存,并对theGadget字段赋值。可是,这一系列操作并不是原子的,且执行顺序无法保证。如果在此时正好发生线程上下文切换,则另一个线程看到的theGadget字段的值可能是未经完整初始化的,有可能会导致外层的控制检查失效,并返回这个未经完整初始化的对象。不仅仅是创建对象可能会出问题,处理其他类型数据时也要小心。例如,在32位平台上,写入一个long型数据通常需要执行两次32位数据的写操作,而写入int数据则无此顾虑。</strong></font></p><p>上述问题可以通过将 theGadget字段声明为 volatile来解决(注意,只在新版本的内存模型下才有效),增加的执行开销尽管比使用synchronized方法的小,但还是有的。如果不确定当前版本的内存模型是否实现正确,不要使用双检查锁。网上有很多文章介绍了为什么不应该使用双检查锁,不仅限于Java,其他语言也是。</p><p><font color="DeepPink"><strong>双检查锁的危险之处在于,在强内存模型下,它很少会使程序崩溃。Intel IA-64平台就是个典型示例,其弱内存模型臭名远扬,原本好好运行的Java应用程序却出现故障。如果某个应用程序在x86平台运行良好,在x64平台却出问题,人们很容易怀疑是JVM的bug,却忽视了有可能是Java应用程序自身的问题。</strong></font></p><p>使用静态属性来实现单例模式可以实现同样的语义,而无须使用双检查锁,如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public class GadgetMaker&#123;</span><br><span class="line">public static Gadget theGadget= new Gadget();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>Java语言保证类的初始化是原子操作, GadgetMaker类中没有其他的域,因此,在首次主动使用该类时会自动创建 Gadget类的实例。并赋值给theGadget字段。这种方法在新旧两种内存模型下均可正常工作。</strong></font></p><p>总之,使用Java做并行程序开发有很多需要小心的地方,如果能够正确理解Java内存模型那么是可以避开这些陷阱的。开发人员往往不太关心当前的硬件架构,但如果不能理解Java内存模型,迟早会搬起石头砸自己的脚。</p><h1 id="基准测试与性能调优"><a href="#基准测试与性能调优" class="headerlink" title="基准测试与性能调优"></a>基准测试与性能调优</h1><h2 id="wait方法、notify方法与胖锁"><a href="#wait方法、notify方法与胖锁" class="headerlink" title="wait方法、notify方法与胖锁"></a>wait方法、notify方法与胖锁</h2><h3 id="Java并非万能的"><a href="#Java并非万能的" class="headerlink" title="Java并非万能的"></a>Java并非万能的</h3><p>Java是一门强大的通用编程语言,因其友好的语义和内建的内的开发进度,但Java不是万能的,这里来谈谈不宜使用Java解决的场景：</p><ul><li>要开发一个有近实时性要求的电信应用程序,并且其中会有其中会有成千上万的线程并发执行。</li><li>应用程序的数据库层所返回的数据经常是20MB的字节数组。</li><li>应用程序性能和行为的确定性,完全依赖于底层操作系统的调度器，即使调度器有微小变化也会对应用程序性能产生较大影响。</li><li>开发设备驱动程序。</li><li>使用 C/Fortran/COBOL等语言开发的历史遗留代码太多,目前团队手中还没有好用的工具可以将这些代码转换为Java代码。</li></ul><p>除了上面的示例外,还有其他很多场景不适宜使用Java。通过JvM对底层操作系统的抽象Java实现了“一次编写,到处运行”,也因此受到了广泛关注。但夸大一点说,ANSI C也能做到这一点,只不过在编写源代码时,要花很多精力来应对可移植性问题。因此要结合实际场景选择合适的工具。Java是好用,但也不要滥用。</p><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> JVM </tag>
            
            <tag> JRockit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JVM＆G1GC 笔记</title>
      <link href="/java-jvm-gc-g1-notes.html"/>
      <url>/java-jvm-gc-g1-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《深入理解JVM＆G1GC》 作者：周明耀<br><strong>本书很一般，建议粗略的看看就行</strong><br>出版时间：2017-06-01</p><a id="more"></a><h1 id="JVM-GC基本知识"><a href="#JVM-GC基本知识" class="headerlink" title="JVM GC基本知识"></a>JVM GC基本知识</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>G1内部主要有四个操作阶段：</p><ul><li>年轻代回收(A Young Collection)</li><li>运行在后台的并行循环(A Background，Concurrent Cycle)</li><li>混合回收(A Mixed Collection)</li><li>全量回收(A Full GC)</li></ul><h2 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h2><h3 id="Java相关术语"><a href="#Java相关术语" class="headerlink" title="Java相关术语"></a>Java相关术语</h3><h4 id="Interned-Strings"><a href="#Interned-Strings" class="headerlink" title="Interned Strings"></a>Interned Strings</h4><p><font color="DeepPink"><strong>在Java语言中有8种基本类型和一种比较特殊的类型 String这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。常量池就类似一个Java系统级别提供的缓存。</strong></font>8种基本类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种。</p><ul><li>直接使用双引号声明出来的String对象会直接存储在常量池中</li><li>如果不是用双引号声明的String对象，可以使用String提供的Intern方法。 intern方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。</li></ul><p>通俗点讲，Interned String就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。注意，这个值会被存放在字符串内部池(String Intern Pool)。</p><p>Java 7中Oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串池的位置调整到Java堆内，这个改动意味着你再也不会被固定的内存空间限制了。所有的字符串都保存在堆(Heap)中，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。字符串池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java7中使用 String intern()。</p><h3 id="Java-对象头"><a href="#Java-对象头" class="headerlink" title="Java 对象头"></a>Java 对象头</h3><p>在HotSpot虚拟机中，对象在内存中的布局可以分成对象头、实例数据、对齐填充三部分。</p><ul><li>对象头:它主要包括对象自身的运行行元数据，比如哈希码、GC分代年龄、锁状态标志等，同时还包含一个类型指针，指向类元数据，表明该对象所属的类型。</li><li>实例数据:它是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段(包括从父类继承下来的和本身拥有的字段)。</li><li>对齐填充:它不是必要存在的，仅仅起着占位符的作用</li></ul><p>对象头大小在32位HotSpot VM和64位 HotSpot VM之间是不一样的，对象头在32位系统上占用8yte，在64位系统上占用16yte。我们可以通过Java对象布局工具获取头大小，这个工具简称为JOL。</p><h2 id="G1-涉及术语"><a href="#G1-涉及术语" class="headerlink" title="G1 涉及术语"></a>G1 涉及术语</h2><h3 id="Metaspace"><a href="#Metaspace" class="headerlink" title="Metaspace"></a>Metaspace</h3><p>JDK8 HotSpot JVM使用<font color="DeepPink"><strong>本地内存</strong></font>来存储类元数据信息并称为元空间(Metaspace)。</p><p><font color="DeepPink"><strong>默认情况下，大部分类元数据都在本地内存中分配，类元数据只受可用的本地内存限制(容量取决于是32位或是64位操作系统的可用虚拟内存大小)。新参数(MaxMetaspace Size)用于限制本地内存分配给类元数据的大小。如果没有指定这个参数，元空间会在运行时根据需要动态调整。</strong></font></p><p>一般情况下，适时地监控和调整元空间对于减小垃圾回收频率和减少延时是很有必要的。持续的元空间垃圾回收情况如果频繁发生，说明可能存在类、类加载器导致的内存泄漏或是大小设置不合适。</p><p>G1 GC与Metaspace相关的选项如下：</p><ul><li>-XX:MetaspaceSize:初始化元空间的大小(默认12 Mbytes在32bit client VM and 16 Mbytes在32bit server VM，在64 bit VM上会更大些)。 </li><li>-XX:MaxMetaspaceSize:最大元空间的大小(默认本地内存)。</li><li>-XX:MinMetaspaceFreeRatio:扩大空间的最小比率，当GC后，内存占用超过这一比率，就会扩大空间。</li><li>-XX:MaxMetaspaceFreeRatio:缩小空间的最小比率，当GC后，内存占用低于这一比率，就会缩小空间。</li></ul><h3 id="Mixed-GC-Event"><a href="#Mixed-GC-Event" class="headerlink" title="Mixed GC Event"></a>Mixed GC Event</h3><p>即混合GC事件，在这个事件内部，所有的年轻代Region和一部分老年代Region一起被回收。混合GC事件一定是跟在Minor GC之后的，并且混合GC只有在存活对象元数据存在的情况下才会触发。</p><h3 id="Reclaimable"><a href="#Reclaimable" class="headerlink" title="Reclaimable"></a>Reclaimable</h3><p><font color="DeepPink"><strong>Gl GC为了能够回收，创建了一系列专门用于存放可回收对象的Region</strong></font>。这些Region都在个链表队列里面，这个队列只包含存活率小于-XX: G1MixedGCLiveThresholdPercent(默认85%)的Region。Region的值除以整个Java堆区，如果大于-XX:G1HeapWastePercen(默认5%)，则启动回收机制。</p><h3 id="Rset"><a href="#Rset" class="headerlink" title="Rset"></a>Rset</h3><p><font color="DeepPink"><strong>全称Remembered Set，简称Rset，即跟踪指向某个堆区(Region)内的对象引用。</strong></font></p><p><font color="DeepPink"><strong>在标记存活对象时，G1使用RememberSet的概念，将每个分区外指向分区内的引用记录在该分区的RememberSet中，避免了对整个Heap的扫描，使得各个分区的GC更加独立。堆内存中的每个区都有一个RSet，Rset的作用是让堆区能并行独立地进行垃圾集合。</strong></font>RSet所占用的JVM内存小于总大小的5%。在这样的背景下，可以看出G1GC大大提高了触发 Full GC时的Heap占用率，同时也使得 Minor GC的暂停时间更加可控，对于内存较大的环境非常友好。</p><p>G1 GC引入了一些新的选项。G1RSetUpdatingPauseTimePercent设置STW阶段(独占阶段)为G1收集器指定更新RememberSet的时间占总STW时间的期望比例，默认为10。而G1ConcRefinementThreads则是在程序运行时维护RememberSet的线程数目。通过对这两个值的对应调整，我们可以把STW阶段的RememberSet更新工作压力更多地移到并行阶段。</p><h3 id="CSet"><a href="#CSet" class="headerlink" title="CSet"></a>CSet</h3><p><font color="DeepPink"><strong>全称Collection Set，简称CSet，即收集集合，保存一次GC中将执行垃圾回收的区间(Region)。GC时在CSet中的所有存活数据(Live Data)都会被转移(复制/移动)。</strong></font>集合中的堆区可以是Eden， Survivor和/或Old Generation。CSets所占用的JVM内存小于总大小的1%。</p><p>从这里可以知道，实际上CSet相当于一个大圈，里面包含了很多的小圈(Rset)，这些圈圈都是需要被回收的信息。这样可以把CSet比作垃圾场，RSet是垃圾场里面一个个绿色的可回收垃圾桶。</p><h3 id="PLAB"><a href="#PLAB" class="headerlink" title="PLAB"></a>PLAB</h3><p>全称为Promotion Local Allocation Buffers，它被用于年轻代回收。PLAB的作用是避免多线程竞争相同的数据，处理方式是每个线程拥有独立的PLAB，用于针对幸存者和老年空间。当应用开启的线程较多时，最好使用-XX:-ResizePlaB来关闭PLAB()的大小调整，以避免大量的线程通信所导致的性能下降。</p><h3 id="TLAB"><a href="#TLAB" class="headerlink" title="TLAB"></a>TLAB</h3><p>全称为Thread Local Allocation Buffers，即线程本地分配缓存，是一个线程专用的内存分配区域。</p><p>总的来说，<font color="DeepPink"><strong>TLAB是为了加速对象分配而生的</strong></font>。由于对象一般会分配在堆上，而堆是全局共享的。因此在同一时间，可能会有多个线程在堆上申请空间。因此，每一次对象分配都必须要进行同步，而在竞争激烈的场合分配的效率又会进一步下降。考虑到对象分配几乎是Java最最常用的操作，所以JVM就使用了TLAB这种线程专属的区间来避免多线程冲突，提高对象分配的效率。<font color="DeepPink"><strong>TLAB本身占用了Eden区的空间</strong></font>，即JVM会为每一个Java线程分配一块TLAB空间。</p><p><font color="DeepPink"><strong>对于G1 GC来说，TLAB是Eden的一个Region，被一个单一线程用于分配资源。主要用途是让一个线程通过栈操作方式独享内存空间，用于对象分配，这样比多个线程之间共享资源要快很多。如果每个线程的分配内存不够，那么它会去全局内存池申请新的内存。这样也就是说，如果TLAB值设置过小，容易造成频繁申请，也就会造成GC性能下降。反之，如果设置过大，会造成TLAB使用不完，也就是说内存浪费。</strong></font></p><h3 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h3><p>从字面上来说， Region表示一个区域，每个区域里面的字母代表不同的分代内存空间类型(如[E]Eden，[O]Old，[S]Survivor)，<font color="DeepPink"><strong>空白的区块不属于任何一个分区</strong></font>。G1可以在需要的时候任意指定这个区域属于Eden或是O区之类的。</p><h3 id="Ergonomics-Heuristic-Decision"><a href="#Ergonomics-Heuristic-Decision" class="headerlink" title="Ergonomics Heuristic Decision"></a>Ergonomics Heuristic Decision</h3><p>在很多英文书里都能看到这串单词，特别是Ergonomics Heuristi，它们的字面意思是人体工程学，可以理解为适合人类理解的行为、习惯。GC日志里面看到Ergonomics这个单词，它后面一般跟着的是G1 GC相关的详细描述，比如堆内存日志、CSet划分等，通常采用选项-XX:+PrintAdaptiveSizePolicy时会看到这个单词。</p><h3 id="Top-at-mark-start"><a href="#Top-at-mark-start" class="headerlink" title="Top-at-mark-start"></a>Top-at-mark-start</h3><p>每个区间记录着两个TAMS指针(Top-at-mark-start)，分别为prevTAMS和nextTAMS在TAMS以上的对象是新分配的，因而被视为隐式标记。</p><h1 id="JVM-amp-GC-深入知识"><a href="#JVM-amp-GC-深入知识" class="headerlink" title="JVM&amp;GC 深入知识"></a>JVM&amp;GC 深入知识</h1><h2 id="Java虚拟机内存模型"><a href="#Java虚拟机内存模型" class="headerlink" title="Java虚拟机内存模型"></a>Java虚拟机内存模型</h2><p><img src="/images/java-jvm-gc-g1-note/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png" alt></p><h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>程序计数器，英文全称Program Counter Register，它是一块很小的内存空间，它是运行速度最快的存储区域，这是因为它位于不同于其他存储区的地方—处理器内部。寄存器的数量极其有限，所以寄存器由编译器根据需求进行分配。实际上在Java应用程序内部不能直接控制寄存器，也不能在程序中感觉到寄存器存在的任何迹象。<font color="DeepPink"><strong>可以把程序计数器看作当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器的工作就是通过改变程序计数器的值来选择下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都要依赖这个计数器来完成。</strong></font></p><p>简单概括上面的描述，即在多线程环境下，为了让线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器，各个线程之间互不影响、独立存储，因此这块内存是线程私有的。<font color="DeepPink"><strong>JVM中的寄存器类似于物理寄存器的一种抽象模拟，正如前面说的，它是线程私有的，所以生命周期与线程的生命周期保持一致。</strong></font></p><p><font color="DeepPink"><strong>根据Java虚拟机定义来看，程序寄存器区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemory Error情况的区域。</strong></font></p><h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><p>JVM的架构是基于栈的，即程序指令的每一个操作都要经过入栈和出栈这样的组合型操作才能完成。</p><p>总的来说，栈的优势是访问速度比堆要快，它仅次于寄存器，并且栈数据是可以被共享的。栈的缺点是存储在栈里面的数据大小与生存期必须是确定的，从这一点来看，栈明显缺乏灵活性。虚拟机栈内主要被用来存放一些基本类型的变量，例如int、 short、long、byte、foat、 double、boolea、char，以及对象引用。</p><p>前面说过，<font color="DeepPink"><strong>虚拟机栈有一个很重要的特殊性，就是存放在栈内的数据可以共享。</strong></font>假设同时定义:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int a=1;</span><br><span class="line">int b=1;</span><br></pre></td></tr></table></figure><p>对于上面的代码，虚拟机处理第一条语句，首先它会在栈内创建一个变量为a的引用，然后查找栈内是否有1这个值，如果没找到，就将1存放进来，然后将a指向1。接下来处理第二条语句，在创建完b的引用变量后，因为在栈内已经有1这个值，便将b直接指向1。这样，就出现了a与b同时均指向1的情况。这时，如果存在第三条语句，它针对a再次定义为a=4，那么编译器会重新搜索栈内是否有4值，如果没有，则将4存放进来，并令a指向4，如果已经有了，则直接将a指向这个地址，因此a值的改变不会影响到b的值。要注意这种数据的共享与两个对象的引用同时指向一个对象的这种共享的方式存在明显的不同，因为这种情况a的修改并不会影响到b，它是由虚拟机完成的，这样的做法有利于节省空间。而一个对象引用变量修改了这个对象的内部状态，会影响到另一个对象引用变量。</p><p>与程序计数器一样，<font color="DeepPink"><strong>Java虚拟机栈也是线程私有的内存空间，它和Java线程在同一时间创建，它保存方法的局部变量、部分结果，并参与方法的调用和返回</strong></font>。</p><p>虚拟机栈在运行时使用一种叫作栈帧的数据结构保存上下文数据，栈帧里面存放了方法的局部变量表、操作数栈、动态连接方法和返回地址等信息。每一个方法的调用都伴随着栈帧的入栈操作，相应地，方法的返回则表示栈帧的出栈操作。<br><img src="/images/java-jvm-gc-g1-note/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%E5%BC%95%E7%94%A8%E5%9B%BE.png" alt></p><blockquote><p>使用JClassLib工具可以查看Class文件中每个方法所分配的最大局部变量区的容量。JClassLib工具是开源软件，它可以用于查看 Class文件的结构，包括常量池、接口、属性、方法，还可以用于查看文件的字节码。</p></blockquote><h3 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h3><p>Java堆区在JVM启动的时候即被创建，它只要求逻辑上是连续的，在物理空间上可以是不连续。所有的线程共享Java堆，在这里可以划分线程私有的缓冲区(Thread Local Allocation Buffer，TLAB)。</p><p>正是因为Java堆区是GC的重点回收区域，所以GC极有可能会在大内存的使用和频繁进行垃圾回收过程上成为系统性能瓶颈。为了解决这个问题，JVM的设计者们开始考虑是否一定需要将对象实例存储到Java堆区内。基于OpenJDK深度定制的TaobaoJVM，其中创新的GCIH(GC invisible heap)技术实现了off-heap，即将生命周期较长的Java对象从heap中移到heap之外，并且GC不能管理GCH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。</p><h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p><font color="DeepPink"><strong>方法区主要保存的信息是类的元数据</strong></font>。方法区与堆空间类似，它也是被JVM中所有的线程共享的区域。如下图所示，<font color="DeepPink"><strong>方法区中最为重要的是类的类型信息、常量池、域信息、方法信息。</strong></font>类型信息包括类的完整名称、父类的完整名称、类型修饰符(public/protected/private)和类型的直接接口类表。<br><img src="/images/java-jvm-gc-g1-note/%E6%96%B9%E6%B3%95%E5%8C%BA%E7%BB%84%E6%88%90%E5%9B%BE.png" alt></p><p><font color="DeepPink"><strong>常量池包括类方法、域等信息所引用的常量信息。域信息包括域名称、域类型和域修饰符。方法信息包括方法名称、返回类型、方法参数、方法修饰符、方法字节码、操作数栈和方法栈帧的局部变量区大小以及异常表。方法区是线程间共享的，当两个线程同时需要加载一个类型时，只有一个类会请求ClassLoader加载，另一个线程则会等待。总而言之，方法区内保存的信息大部分来自于Class件，是Java应用程序运行必不可少的重要数据。</strong></font></p><p>在Hotspot虚拟机中，方法区也被称为永久区，是一块独立于Java堆的内存空间。虽然被叫作永久区，但是在永久区中的对象同样也是可以被GC回收的，只是对于GC的对应策略与Java堆空间略有不同。</p><p>GC针对永久区的回收，通常主要从两个方面分析:一是GC对永久区常量池的回收，二是永久区对类元数据的回收。HotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。</p><h2 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h2><h3 id="根搜索算法"><a href="#根搜索算法" class="headerlink" title="根搜索算法"></a>根搜索算法</h3><p><font color="DeepPink"><strong>在HotSpot中，根对象集合中包含了5个元素，Java栈内的对象引用、本地方法栈内的对象引用、运行时常量池中的对象引用、方法区中类静态属性的对象引用以及与一个类对应的唯一数据类型的Class对象。</strong></font></p><blockquote><p>这部分了解一下就好<br>注意，在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程。如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize方法。当对象没有覆盖finalize方法，或者finalized方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由条由虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize方法中执行缓慢，或者发生了死循环(更极端的情况)，很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalized中成功拯救自己—只要重新与引用链上的任何一个对象建立关联即可，譬如把自己(this关键字)赋值给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合。如果对象这时候还没有逃脱，那它就真的离死不远了。</p></blockquote><h3 id="标记清除算法-Mark-Sweep"><a href="#标记清除算法-Mark-Sweep" class="headerlink" title="标记清除算法(Mark-Sweep)"></a>标记清除算法(Mark-Sweep)</h3><p>算法涉及几个概念，先来了解一下mutator和collector，这两个名词经常在垃圾收集算法中出现，<font color="DeepPink"><strong>collector指的就是垃圾收集器，而 mutator是指除了垃圾收集器之外的部分，比如说我们的应用程序本身。</strong></font>mutator的职责一般是NEW(分配内存)、READ(从内存中读取内容)、WRITE(将内容写入内存)，而collector则就是回收不再使用的内存来供mutator进行NEW操作的使用。mutator根对象一般指的是分配在堆内存之外，可以直接被mutator直接访问到的对象，一般是指静态/全局变量以及ThreadLocal变量。</p><h3 id="复制算法-Copying"><a href="#复制算法-Copying" class="headerlink" title="复制算法(Copying)"></a>复制算法(Copying)</h3><p>基于分代的概念，Java堆区如果还要更进一步细分的话，还可以划分为年轻代(YoungGen)和老年代(OldGen)，其中年轻代又可以被划分为Eden空间、From Survivor空间和To Survivor空间。<font color="DeepPink"><strong>在HotSpot中，Eden空间和另外两个Survivor空间默认所占的比例是8:1，当然开发人员可以通过选项“-XX:SurvivorRatio”调整这个空间比例</strong></font>。当执行一次Minor GC(年轻代的垃圾回收)，Eden空间中的存活对象会被复制到To空间内，并且之前已经经历过一次 Minor GC并在From空间中存活下来的对象如果还年轻的话同样也会被复制到To空间内。需要注意的是，在满足两种特殊情况下，Eden和From空间中的存活对象将不会被复制到To空间内。首先是如果存活对象的分代年龄超过选项“-XX:MaxTenuringThreshold”所指定的阈值时，将会直接晋升到老年代中。其次当To空间的容量达到阈值时，存活对象同样也是直接晋升到老年代中。当所有的存活对象都被复制到To空间或者晋升到老年代后，剩下的均为垃圾对象，这就意味着GC可以对这些已经死亡了的对象执行一次Minor GC，释放掉其所占用的内存空间。</p><h3 id="标记压缩算法-Mark-Compact"><a href="#标记压缩算法-Mark-Compact" class="headerlink" title="标记压缩算法(Mark-Compact)"></a>标记压缩算法(Mark-Compact)</h3><p>在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。简单来说，就是针对不同的代空间，从而结合使用不同的垃圾收集算法。<font color="DeepPink"><strong>为年轻代选择的垃圾收集算法通常是以速度优先，因为年轻代中所存储的瞬时对象生命周期非常短暂，可以有针对性地使用复制算法，因此执行Minor GC时，一定要保持高效和快速。而年轻代中的生存空间通常都比较小，所以回收年轻代时一定会非常频繁。但老年代通常使用更节省内存的回收算法，因为老年代中所存储的对象生命周期都非常长，并且老年代占据了大部分的堆空间，所以老年代的Full GC并不会跟年轻代的Minor GC一样频繁，不过一旦程序中发生一次Full GC，将会耗费更长的时间来完成，那么在老年代中使用标记-清除算法或者标记-压缩算法执行垃圾回收将会是不错的选择。</strong></font></p><h2 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h2><h3 id="GC-概念"><a href="#GC-概念" class="headerlink" title="GC 概念"></a>GC 概念</h3><p>在许多情况下，GC不应该成为影响系统性能的瓶颈，可以根据以下六点来评估一款GC的性能。</p><ul><li>吞吐量：程序的运行时间(程序的运行时间+内存回收的时间)。</li><li>垃圾收集开销：吞吐量的补数，垃圾收集器所占时间与总时间的比例。</li><li>暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间。</li><li>收集频率：相对于应用程序的执行，收集操作发生的频率。</li><li>堆空间：Java堆区所占的内存大小。</li><li>快速：一个对象从诞生到被回收所经历的时间。</li></ul><h3 id="Parallel收集器"><a href="#Parallel收集器" class="headerlink" title="Parallel收集器"></a>Parallel收集器</h3><p><font color="DeepPink"><strong>需要注意的是，垃圾收集器中吞吐量和低延迟这两个目标本身是相互矛盾的，因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。</strong></font></p><p>举个例子，在60s的JVM总运行时间里，GC的执行频率是20秒/次，那么60s内一共会执行3次内存回收，按照每次GC耗时100ms来计算，最终一共会有300ms(3×100)被用于执行垃圾回收。但是如果我们将选项“-XX:MaxGCPauseMills”的值调小后，年轻代的内存空间也会自动调整，内存空间越小就越容易被耗尽，也就越容易造成GC的执行频繁发生。之前在60s的JVM总运行时间里，最终会有300ms被用于执行内存回收，而如今GC的执行频率却是10s/次，60s内将会执行6次内存回收，按照每次GC耗时60ms来计算，虽然看上去暂停时间更短了，但最终会耗时360ms(6×60)用于执行内存回收，很明显程序的吞吐量下降了。所以大家在设置这两个选项时，一定需要注意控制在一个折中的范围之内。Parallel收集器还提供个“-XX:UseAdaptiveSizePolicy”选项用于设置GC的自动分代大小调节策略，一旦设置这个选项后，就意味着开发人员将不再需要显式地设置年轻代中的一些细节参数，JVM会根据自身当前的运行情况动态调整这些相关参数。</p><h3 id="Garbage-First-G1-GC"><a href="#Garbage-First-G1-GC" class="headerlink" title="Garbage First (G1) GC"></a>Garbage First (G1) GC</h3><p><font color="DeepPink"><strong>G1很重视老年代的垃圾回收，一旦整个堆空间占有率达到指定的阈值(启动时可配置)，G1会立即启动一个独占的并行初始标记阶段(initial-mark phase)进行垃圾回收。在G1 GC，判断的是整个Java堆内部老年代的占有率，足以见G1对老年代的重视。</strong></font></p><p>初始标记阶段一般和年轻代GC一起运行，一旦初始标记阶段结束，并行多线程的标记阶段就开始启动去标记所有老年代还存活的对象，注意这个标记阶段不是独占式的，它允许应用程序线程和它并行执行。当这个标记阶段运行完毕之后，为了再次确认是否有逃过扫描的对象，“启动一个独占式的再次标记阶段(remark phase)，尝试标记所有遗漏的对象。在这个再次标记阶段结束之后，G1就掌握了所有的老年代 Region的标记信息，这和国家的户口统计方式差不多。一旦老年代的某些Region内部不存在任何的存活对象，它就可以在下一个阶段，即清除阶段(cleanup phase)被清除了，就是可以销户了，又被放回了可用Region队列。同样地，再次标记阶段结束后就可以对一些老年代执行收集动作。</p><p>前面提到了CSet概念，一个CSet里面可以包含多少Region取决于多少空间可以被释放、G1停顿目标时间这两个因素。前面说起过混合GC(Mixed GC)，这里就要具体说明一下了。当CSet被确定之后，会在接下来的一个年轻代回收过程当中对CSet进行回收，通过年轻代GC的几个阶段，一部分的老年代Region会被回收并放入年轻代使用。这个概念很灵活，<font color="DeepPink"><strong>即G1只关注你有没有存活对象了，如果没有，无论你属于老年代，还是属于年轻代，你都会被回收并放入可用Region队列，下一次你被分配到哪里就不确定了。</strong></font>也正是因为Region、混合收集这些特性，让G1对老年代的垃圾收集方式有别于Serial GC、Parallel GC和CMS GC，G1采用Region方式让对象之间的联系存在于虚拟地址之上，这样就不需要针对老年代的压缩和回收动作对整个Java堆执行扫描，为老年代回收节约了时间。</p><h4 id="G1-设计思路"><a href="#G1-设计思路" class="headerlink" title="G1 设计思路"></a>G1 设计思路</h4><p>Gl把整个Java堆划分为若干个区间(Region)。每个Region大小为2的倍数，范围在1MB~32MB之间，可能为1MB、2MB、4MB、8MB、16MB、32MB。<font color="DeepPink"><strong>所有的Region有一样的大小，在JVM生命周期内不会被改变。</strong></font></p><p>注意，在年轻代、混合代、Full GC这三个阶段，年轻代的Eden Region和Survivor Region的数量会随时变化。<font color="DeepPink"><strong>Humongous Region(大对象 Region)是老年代Region的一部分</strong></font>，里面的对象超过每个Region的50%空间，这一点有别于一般对象Region。</p><p>从之前的介绍我们知道没有必要去刻意区分Region的用途，因为G1设计Region的分配原则是很灵活的。一开始G1会从可用 Region队列里面挑选出Region并设置为Eden Region，一个Eden Region里面填满对象以后，又会从可用Region队列里再挑出一个。当所有的Eden Region都被填满时，一个年轻代GC收集就会开始执行了，在这个收集阶段，我们会收集Eden和Survivor Region，所有的存活对象要么进入到下一个Survivor region，要么进入老年代Region。</p><p><font color="DeepPink"><strong>G1提供了一个选项-XX:InitiatingHeapOccupancyPercent，默认值是Java堆空间的45%，这个选项决定了是否开始一次老年代回收动作，即年轻代GC结束之后，G1会评估剩余的对象是否达到了45%这个阈值。</strong></font></p><p>如果标记阶段(Marking Phase)结束后一个老年代的Region已经不存在对象，那么它会被放回可用Region队列，反之，它会被放入混合收集器。</p><p>由于标记阶段不是一个独占式的多线程并行程序，这样应用程序线程就会和它一起并行执行。<font color="DeepPink"><strong>为了避免标记阶段占用过多的CPU资源，G1采用时间片方式分段执行操作，即在时间片内全力运行，然后休息一段时间，这个休息时间就是让应用程序尽可能多地使用CPU资源运行。</strong></font></p><h4 id="大对象-Humongous-Object"><a href="#大对象-Humongous-Object" class="headerlink" title="大对象(Humongous Object)"></a>大对象(Humongous Object)</h4><p>大对象Region属于老年代的一部分，它只包含一个对象。当并行标记阶段发现没有存活对象时，G1会回收这个大对象 Region，注意这个动作可以是一个批量回收。</p><h4 id="全垃圾收集-Full-Garbage-Collection"><a href="#全垃圾收集-Full-Garbage-Collection" class="headerlink" title="全垃圾收集(Full Garbage Collection)"></a>全垃圾收集(Full Garbage Collection)</h4><p>G1的Full GC和Serial GC的Full GC采用的是同一种算法。<font color="DeepPink"><strong>Full GC会对整个Java堆进行压缩。G1的Full GC是单线程的，会引起较长的停顿时间，因此G1的设计目标是减少Full GC的发生次数。</strong></font></p><h4 id="并行循环-Concurrent-Cycle"><a href="#并行循环-Concurrent-Cycle" class="headerlink" title="并行循环(Concurrent Cycle)"></a>并行循环(Concurrent Cycle)</h4><p>一个G1并行循环包括几个阶段的活动:初始标记(Initial Marking)、并行Root区间扫描(Concurrent Root Region Scanning)、并行标记(Concurrent Marking)、重标记(Remarking)和清除(Cleanup)。除了最后的Cleanup阶段以外，其余阶段都属于标记存活对象阶段。</p><p>初始标记阶段的目的是收集所有GC根(Roots)。 Roots是一个对象的起源指针。为了收集根引用，从应用线程开始，应用线程必须停下来，所以初始标记阶段是一个独占式的。由于个年轻代GC必须收集所有的Roots，所以G1的初始标记在一个年轻代GC里完成。</p><p><font color="DeepPink"><strong>并行根区间扫描阶段必须扫描和标记所有幸存者区间的对象引用，这一阶段所有的应用程序线程都可以并行执行，唯一的约束是扫描必须在下一个GC开始前完成。这一约束的原因是个新的GC事件会产生一堆新的幸存者对象集合，这些对象和初始化标记阶段的幸存者对象不一样，容易发生混淆。</strong></font></p><p>并行标记阶段完成了几乎所有的标记工作。在这一阶段，利用多线程并行标记存活对象及对应的逻辑地图。这一阶段允许所有的Java线程并行执行，但是对应用程序来说总体的吞吐量可能会下降。其实任何一个系统都和人体循环一样，当没有外部干扰时，系统可以正常运行，如果受到外部干扰，人体系统也会出现混乱，甚至出现短时间的休克。</p><p>重标记阶段是一个独占式阶段，通常是一个很短的停顿，这个阶段会完成所有的标记工作。</p><p>最后一个并行标记步骤是清除阶段。在这个阶段，没有包含存活对象的Region会被回收，并随即被加入可用Region队列。这个阶段的重要意义是最终决定了哪些 Region可以进入混合GC。在G1内部，混合GC是非常重要的释放内存机制，避免了G1出现没有可用Region的情况发生，否则就会触发Full GC事件。</p><h4 id="堆大小（Heap-Sizing）"><a href="#堆大小（Heap-Sizing）" class="headerlink" title="堆大小（Heap Sizing）"></a>堆大小（Heap Sizing）</h4><p>G1在以下几种情况下可能会增大堆内存大小：</p><ul><li>Full GC阶段。</li><li>Young或Mixed GC发生时，G1计算GC花费的时间与Java线程的花费时间比例，如果-XX:GCTimeRatio设置GC花费时间很长，则堆大小会增大，这样的设计思路是希望G1发生GC的频率降低，这样GC花费时间和Java线程花费时间比例也会相应下降。<br>  -XX:GCTimeRatio选项的默认值是9，所有其他HotSpot GC的默认值是99。这个值越大，代表Java堆空间大小增长越偏激，即越容易扩大堆空间大小，这样也是为了达到降低GC花费时间的设计目标。</li><li>如果一个对象分配失败，即便一个GC刚刚结束，G1采用的策略不是立即重复Full GC，而是通过增大堆内存大小，确保对象分配成功。这样的设计理念符合G1的避免Full GC发生的最初思想。</li><li>和第3条一样，如果出现一个大对象分配失败，前面说过，大对象需要几个连续的Region区间才能确保对象分配成功。如果发生这种分配失败的情况，采用的设计理念也不是调用Full GC，而是扩大堆内存。</li><li>当GC申请加入一个新的Region时。</li></ul><p>引用一段在StackOverfall.com上看到的经验分享，”我在一个真实的、较大规模的应用程序中使用过G1:大约分配有60GB-70GB内存，存活对象大约在20GB~50GB之间。服务器运行Linux操作系统，JDK版本为6u22。G1与PS/PS Old相比，最大的好处是停顿时间更加可控可预测。如果我在PS中设置一个很低的最大允许GC时间，譬如期望50ms内完成GC(-XX:MaxGCPauseMillis=50)，但在65GB的Java堆下有可能得到的直接结果是一次长达30s至2min的漫长的Stop-the-World过程。而Gl与CMS相比，它们都立足于低停顿时间，CMS仍然是我现在的选择，但是随着Oracle对G1的持续改进，我相信Gl会是最终的胜利者。如果你现在采用的收集器没有出现问题，那么就没有任何理由现在去选择G1;如果你的应用追求低停顿，那么G1现在己经可以作为一个可尝试的选择:如果你的应用追求吞吐量，那么G1并不会为你带来什么特别的好处。”</p><h1 id="G1-GC应用示例"><a href="#G1-GC应用示例" class="headerlink" title="G1 GC应用示例"></a>G1 GC应用示例</h1><p>G1 GC给我们提供了很多的命令行选项，也就是参数，这些参数一类以布尔类型打头，“+”表示启用该选项，“-”表示关闭该选项。另一类采用数字赋值，不需要布尔类型打头。</p><h2 id="选项解释及应用"><a href="#选项解释及应用" class="headerlink" title="选项解释及应用"></a>选项解释及应用</h2><p>首先在cmd命令行模式下输入java -X，，如C:Users\Administrator&gt; java -X，输出如代码如下：<br><img src="/images/java-jvm-gc-g1-note/javax%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA.png" alt></p><h3 id="XX-PrintGCDetails"><a href="#XX-PrintGCDetails" class="headerlink" title="-XX:+PrintGCDetails"></a>-XX:+PrintGCDetails</h3><p>该选项用于记录GC运行时的详细数据信息并输出，是最基本、使用最普遍的一个选项这个选项适用于所有GC，输出内容主要包括新生成对象占用内存大小以及耗费时间、各个年龄代的情况、每次回收的对应数据等。</p><h3 id="Xloggc"><a href="#Xloggc" class="headerlink" title="-Xloggc"></a>-Xloggc</h3><p>如果想要以文件形式保存这些GC日志，可以在启动参数中输入-XX:+PrintGCDetails -verbose:gc -XLoggc:gc.log，运行后我们会发现生成了一个 gc.log文件。</p><blockquote><p>-Xloggc:example_gc.log （设置垃圾回收日志打印的文件，文件名称可以自定义） </p></blockquote><p>-XX:initialHeapSize和-XX:MaxHeapSize就是我们比较熟悉的-Xms和-Xmx，它们允许我们指定JVM的初始和最大堆内存大小-XX:+UseCompressedClassPointers、XX:+UseCompressedOops<br>以及-XX:-UseLargePagesIndividualAllocation这三个选项和OOP有关。OOP的全称是Ordinary Object Pointer，即普通对象指针。通常64位JVM消耗的内存会比32位的大1.5倍，这是因为对象指针在64位架构下，长度会翻倍(更宽的寻址)。对于那些将要从32位平台移植到64位的应用来说，平白无故多了1/2的内存占用，作为开发者一定不愿意看到这种场景。所以，从JDK1.6 update4开始，64 bit JVM正式支持了-XX:+UseCompressedOops这个可以压缩指针，起到节约内存占用的选项。CompressedOops的实现方式是在机器码中植入压缩与解压指令，可能会给JVM增加额外的开销。-XX:+UseCompressedClassPointers选项是在JDK8出现的，也是在永久区消失之后出现的新的选项，主要用于对类的元数据进行压缩。-XX:UseLargePagesIndividualAllocation和oops是一起使用的，在大页内存使用发生时这个选项也会自动启用。</p><h3 id="XX-PrintGCApplicationStoppedTime"><a href="#XX-PrintGCApplicationStoppedTime" class="headerlink" title="-XX:+PrintGCApplicationStoppedTime"></a>-XX:+PrintGCApplicationStoppedTime</h3><p>打印垃圾回收期间程序暂停的时间，如果使用该选项，会输出GC造成应用程序暂停的时间。一般和-XX:+PrintGCApplicationConcurrentTime组合起来一起使用，这样比较有利于查看输出。</p><h3 id="XX-ConcGCThreads"><a href="#XX-ConcGCThreads" class="headerlink" title="-XX:ConcGCThreads"></a>-XX:ConcGCThreads</h3><p>这个选项用来设置与Java应用程序线程并行执行的GC线程数量，默认为GC独占时运行线程的1/4。这个选项设置过大会导致Java应用程序可以使用的CPU资源减少，如果小一点则会对应用程序有利，但是过小就会增加GC并行循环的执行时间，反过来减少Java应用程序的运行时间(因为独占期时间拉长)。</p><h3 id="XX-G1HeapRegionSize"><a href="#XX-G1HeapRegionSize" class="headerlink" title="-XX:G1HeapRegionSize"></a>-XX:G1HeapRegionSize</h3><p>这是G1GC独有的选项，它是专门针对Region这个概念的对应设置选项，后续GC应该会继续采用 Region这个概念。 Region的大小默认为堆大小的1/200，.也可以设置为1MB、2MB、4MB、8MB、16MB，以及32MB，这六个划分档次。</p><p>增大Region块的大小有利于处理大对象。前面介绍过，大对象没有按照普通对象方式进行管理和分配空间，如果增大Region块的大小，则一些原本走特殊处理通道的大对象就可以被纳入普通处理通道了。这就好比我们在机场安检，飞行员、空姐可以走特殊通道，乘客如果也搞特殊化，一部分人去特殊通道处理，那么特殊通道就得増加几个，相应的普通通道就得减少了，对效率就起了降低作用。反之，如果Region大小设置过小，则会降低G1的灵活性，对于各个年龄代的大小都会造成分配问题。</p><h3 id="XX-G1HeapWastePercent"><a href="#XX-G1HeapWastePercent" class="headerlink" title="-XX:G1HeapWastePercent"></a>-XX:G1HeapWastePercent</h3><p>这个选项控制G1 GC不会回收的空闲内存比例，默认是堆内存的5%。G1 GC在回收过程中会回收所有Region的内存，并持续地做这个工作直到空闲内存比例达到设置的这个值为止，所以对于设置了较大值的堆内存来说，需要采用比较低的比例，这样可以确保较小部分的内存不被回收。这个很容易理解，城市越大就越容易出现一些死角，出于性能的原因可以不去关注那里，但是这个比例不能大。</p><h3 id="XX-G1MixedGCCountTarget"><a href="#XX-G1MixedGCCountTarget" class="headerlink" title="-XX:G1MixedGCCountTarget"></a>-XX:G1MixedGCCountTarget</h3><p>老年代Region的回收时间通常来说比年轻代Region稍长一些，这个选项可以设置一个并行循环之后启动多少个混合GC，默认值是8个。设置一个比较大的值可以让G1 GC在老年代Region回收时多花一些时间，如果一个混合GC的停顿时间很长，说明它要做的事情很多，所以可以增大这个值的设置，但是如果这个值过大，也会造成并行循环等待混合GC完成的时间相应的增加。</p><blockquote><p>当占用内存超过InitiatingHeapOccupancyPercent阀值时， 最多通过多少次Mixed GC来将内存控制在阀值之下。</p></blockquote><h3 id="XX-G1PrintRegionLivenessInfo"><a href="#XX-G1PrintRegionLivenessInfo" class="headerlink" title="-XX:+G1PrintRegionLivenessInfo"></a>-XX:+G1PrintRegionLivenessInfo</h3><p>由于开启这个选项会在标记循环阶段完成之后输出详细信息，专业一点的叫法是诊断选项，所以在使用前需要开启选项UnlockDiagnosticVMOptions。这个选项启用后会打印堆内存内部每个Region里面的存活对象信息，这些信息包括使用率、RSet大小、回收一个Region的价值(Region内部回收价值评估，即性价比)。</p><p>这个选项输出的信息对于调试堆内Region是很有效的，不过对于一个很大的堆内存来说，由于每个 Region信息都输出了，所以信息量也是挺大的。</p><h3 id="XX-G1ReservePercent"><a href="#XX-G1ReservePercent" class="headerlink" title="-XX:G1ReservePercent"></a>-XX:G1ReservePercent</h3><p>每个年龄代都会有一些对象可以进入下一个阶段，为了确保这个提升过程正常完成，我们允许G1GC保留一些内存，这样就可以避免出现“ to space exhausted”错误，这个选项就是为了这个用途。</p><p>这个选项默认保留堆内存的10%。注意，这个预留内存空间不能用于年轻代。</p><p>对于一个拥有大内存的堆内存来说，这个值不能过大，因为它不能用于年轻代，这就意味着年轻代可用内存降低了。减小这个值有助于给年轻代留出更大的内存空间、更长的GC时间，这对提升性能吞吐量有好处。</p><h3 id="XX-G1SummarizeRSetStats"><a href="#XX-G1SummarizeRSetStats" class="headerlink" title="-XX:+G1SummarizeRSetStats"></a>-XX:+G1SummarizeRSetStats</h3><p>和GIPrintRegionLivenessInfo选项一样，这个选项也是一个诊断选项，所以也需要开启UnlockDiagnosticVMOptions选项后才能使用，这也就意味着-XX:+UnlockDiagnosticVMOptions选项需要放在-XX:+G1SummarizeRSetStats选项的前面。</p><p>这个选项和-XX:G1SummarizePeriod一起使用的时候会阶段性地打印RSets的详细信息，这有助于找到RSet里面存在的问题。</p><h3 id="XX-G1TraceConcRefinement"><a href="#XX-G1TraceConcRefinement" class="headerlink" title="-XX:+G1TraceConcRefinement"></a>-XX:+G1TraceConcRefinement</h3><p>这是一个诊断选项。如果启动这个诊断选项，那么并行Refinement线程相关的信息会被打印。注意，线程启动和结束时的信息都会被打印。</p><p>这里提到了Refinement线程，我们来提前梳理这个概念。请看每一代GC对应的GC线程:</p><table><thead><tr><th>Garbage Collector</th><th>Worker Threads Used</th></tr></thead><tbody><tr><td>Parallel GC</td><td>ParallelGCThreads</td></tr><tr><td>CMS GC</td><td>ParallelGCThreads<br>ConcGCThreads</td></tr><tr><td>G1 GC</td><td>ParallelGCThreads<br>ConcGCThreads<br>G1ConcRefinementThreads</td></tr></tbody></table><p>上面列出了三类GC线程，分别是ParallelGCThreads、ConcGCThreads和G1ConcRefinementThreads。关于这三个线程的区别：</p><table><thead><tr><th>名称</th><th>选项控制</th><th>作用</th></tr></thead><tbody><tr><td>ParallelGC Thread</td><td>-XX:ParallelGCThreads</td><td>GC的并行工作线程，专门用于独占阶段的工作，比如拷贝存活对象</td></tr><tr><td>ParallelMarkingThreads</td><td>-XX:ConcGCThreads</td><td>并行标记阶段的并行线程，它由一个主控(Master)线程和一些工作(Worker)线程组成，可以和应用程序并行执行</td></tr><tr><td>G1ConcurrentRefinementThreads</td><td>-XX:G1ConcRefinementThreads</td><td>和应用程序一起运行，用于更新RSet，如果ConcurrentRefinementThreads没有设置，那么默认为ParallelGCThreads+1</td></tr></tbody></table><h3 id="XX-G1UseAdaptiveConcRefinement"><a href="#XX-G1UseAdaptiveConcRefinement" class="headerlink" title="-XX:+G1UseAdaptiveConcRefinement"></a>-XX:+G1UseAdaptiveConcRefinement</h3><p>这个选项默认是开启的。它会动态地对每一次GC中XX:G1ConcRefinementGreenZone、-XX:G1ConcRefinementYellowZone、-XX:G1ConcRefinementRedZone的值进行重新计算。</p><p>并行Refinement线程是持续运行的，并且会随着update log buffer积累的数量而动态调节。前面说到的三个配置选项-XX:G1ConcRefinementGreenZone、-XX:G1ConcRefinementYellowZone、-XX:G1ConcRefinementRedZone，是被用来根据不同的 buffer使用不同的Refinement线程，目的就是为了保证 Refinement线程一定要尽可能地跟上update log buffer产生的步伐。但是这个Refinement线程不是无限增加的，一旦出现 Refinement线程跟不上update log buffer产生的速度、update log buffer开始出现积压的情况，Mutator线程(即应用业务线程)就会协助Refinement线程执行RSet的更新工作。这个 Mutator线程实际上就是应用业务线程，当业务线程去参与Rset修改时，系统性能一定会受到影响，所以需要尽力去避免这种状况。</p><h3 id="XX-GCTimeRatio"><a href="#XX-GCTimeRatio" class="headerlink" title="-XX:GCTimeRatio"></a>-XX:GCTimeRatio</h3><p>这个选项代表Java应用线程花费的时间与GC线程花费时间的比率。通过这个比率值可以调节Java应用线程或者GC线程的工作时间，保障两者的执行时间.</p><p>HotSpot VM转换这个值为一个百分比，公式是100/(1+GCTimeRatio)，默认值是9，表示花费在GC工作量上的时间占总时间的10%。</p><h3 id="XX-HeapDumpBeforeFullGC-XX-HeapDumpAfterFullGC"><a href="#XX-HeapDumpBeforeFullGC-XX-HeapDumpAfterFullGC" class="headerlink" title="-XX:+HeapDumpBeforeFullGC/-XX:+HeapDumpAfterFullGC"></a>-XX:+HeapDumpBeforeFullGC/-XX:+HeapDumpAfterFullGC</h3><p>这个选项启用之后，在Full GC开始之前有一个hprof文件会被创建。建议这个选项和-XX:+HeapDumpAfterFullGC一起使用，可以通过对Full GC发生前后的Java堆内存进行对比，找出内存泄漏和其他问题。</p><blockquote><p>获取full GC前后的heap dump</p></blockquote><h3 id="XX-InitiatingHeapOccypancyPercent"><a href="#XX-InitiatingHeapOccypancyPercent" class="headerlink" title="-XX:InitiatingHeapOccypancyPercent"></a>-XX:InitiatingHeapOccypancyPercent</h3><p>该选项的默认值是45，表示G1 GC并行循环初始设置的堆大小值，这个值决定了一个并行循环是不是要开始执行。它的逻辑是在一次GC完成后，比较老年代占用的空间和整个Java堆之间的比例。如果大于这个值，则预约下一次GC开始一个并行循环回收垃圾，从初始标记阶段开始。这个值越小，GC越频繁，反之，值越大，可以让应用程序执行时间更长。不过在内存消耗很快的情况下，我认为早运行并行循环比晚运行要好，看病要趁早。</p><h3 id="XX-UseStringDeduplication"><a href="#XX-UseStringDeduplication" class="headerlink" title="-XX:+UseStringDeduplication"></a>-XX:+UseStringDeduplication</h3><p>该选项启动Java String对象的去重工作。JDK8u20开始引入该选项，默认为不启用。我们知道一个判断Java String对象值是否一样的语句“Stringl equals(String2)tue”，如果开启了该选项，并且如果两个对象包含相同的内容，即返回“tue”，则两个String对象只会共享一个字符数组。这个选项是G1GC独有的，也可以和其他GC一起使用。</p><p>延伸一点我们的知识面，一个去重对象的必备条件有如下三点:</p><ul><li>Java.lang String对象的一个实例。</li><li>这个对象在年轻代堆区间。</li><li>这个对象的年龄达到去重年龄代，或者这个对象已经在老年代堆区间并且对象年龄比去重年龄小。选项-XX:StringDeduplicationAgeThreshold设置了这个年龄界限。</li></ul><p>前面介绍过的可修改和不可修改字符串的处理方式有所不同，不可修改字符串默认就是去重的，在插入到HotSpot VM的String Table时已经注明了是去重的，这样就避免了HotSpot服务器JIT编译优化措施。</p><h3 id="XX-StringDeduplicationAgeThreshold"><a href="#XX-StringDeduplicationAgeThreshold" class="headerlink" title="-XX:StringDeduplicationAgeThreshold"></a>-XX:StringDeduplicationAgeThreshold</h3><p>这个选项是针对-XX:+UseStringDeduplication选项的，默认值是3。它的意思是一个字符串对象的年龄超过设定的阈值，或者提升到G1 GC老年代Region之后，就会成为字符串去重的候选对象，去重操作只会有一次。</p><h3 id="XX-PrintStringDeduplicationStatistics"><a href="#XX-PrintStringDeduplicationStatistics" class="headerlink" title="-XX:+PrintStringDeduplicationStatistics"></a>-XX:+PrintStringDeduplicationStatistics</h3><p>这个选项挺有用的，能够帮助我们通过读取输出的统计资料来了解是否字符串去重后节约了大量的堆内存空间，默认是关闭的，就是说不会输出字符串去重的统计资料。</p><h3 id="XX-G1UseAdaptiveIHOP"><a href="#XX-G1UseAdaptiveIHOP" class="headerlink" title="-XX:+G1UseAdaptiveIHOP"></a>-XX:+G1UseAdaptiveIHOP</h3><p>JDK9提供的新的选项。<font color="DeepPink"><strong>这个选项的作用是通过动态调节标记阶段开始的时间，以达到提升应用程序吞吐量的目标，主要通过尽可能迟地触发标记循环方式来避免消耗老年代空间。</strong></font></p><p>这个选项的值在VM刚开始启动时和-XX:InitiatingHeapOccupancyPercent的值一样，如果出现标记循环阶段内存不够用，则它会自动调节大小，确保标记循环启用更多的堆内存。</p><p>注意，-XX:+G1UseAdaptiveIHOP这个选项会在JDK9里默认启用，即-XX:InitiatingHeapOccupancyPercent和XX:+GIUseAdaptivelHOP在JDK9之后只需要启用一个就可以了。</p><p>JDK8环境下运行该选项会输出:“Unrecognized VM option ‘G1UseAdaptivelHOP’”</p><h3 id="XX-MaxGCPauseMills"><a href="#XX-MaxGCPauseMills" class="headerlink" title="-XX:+MaxGCPauseMills"></a>-XX:+MaxGCPauseMills</h3><p>这个选项比较重要。它设置了G1的目标停顿时间，单位是ms，默认值为200ms。这个值是一个目标时间，而不是最大停顿时间。G1 GC尽最大努力确保年轻代的回收时间可以控制在这个目标停顿时间范围里面，在G1GC使用过程中，这个选项和-Xms、Xmx两个选项一起使用，它们三个也最好在JVM启动时就一起配置好。</p><h3 id="XX-MinHeapFreeRatio"><a href="#XX-MinHeapFreeRatio" class="headerlink" title="-XX:+MinHeapFreeRatio"></a>-XX:+MinHeapFreeRatio</h3><p>这个选项设置堆内存里可以空闲的最小的内存空间大小，默认值为堆内存的40%。当空闲堆内存大小小于这个设置的值时，我们需要判断-Xms和-Xmx这两个值的初始化设置值，如果-Xms和-Xmx不一样，那么我们就有机会扩展堆内存，否则就无法扩展。</p><h3 id="XX-MaxHeapFreeRatio"><a href="#XX-MaxHeapFreeRatio" class="headerlink" title="-XX:+MaxHeapFreeRatio"></a>-XX:+MaxHeapFreeRatio</h3><p>这个选项设置最大空闲空间大小，默认值为堆内存的70%。这个选项和上面那个最小堆内存空闲大小刚好相反，当大于这个空闲比率时，G1 GC会自动减少堆内存大小。需要判断-Xms和-Xmx这两个值的初始化设置值，如果-Xms和-Xmx不一样，那么就有机会减小堆内存，否则就无法减小。</p><h3 id="XX-PrintAdaptiveSizePolicy"><a href="#XX-PrintAdaptiveSizePolicy" class="headerlink" title="-XX:+PrintAdaptiveSizePolicy"></a>-XX:+PrintAdaptiveSizePolicy</h3><p>这个选项决定是否开启堆内存大小变化的相应记录信息打印，即是否打印这些信息到GC日志里面。这个信息对于Parallel GC和G1 GC都很有用。</p><h3 id="XX-ResizePLAB"><a href="#XX-ResizePLAB" class="headerlink" title="-XX:+ResizePLAB"></a>-XX:+ResizePLAB</h3><p>GC使用的本地线程分配缓存块采用动态值还是静态值进行设置是由这个选项决定的，它默认是开启的，这个设置对应的是GC在提升对象时是否会调整PLAB的大小。</p><p>这个选项大家还是慎用，据说会出现性能问题，启用后可能会增加GC的停顿时间。当应用开启的线程较多时，最好使用-XX:ResizePlaB来关闭PLAB()的大小调整，以避免大量的线程通信所导致的性能下降。</p><h3 id="XX-ResizeTLAB"><a href="#XX-ResizeTLAB" class="headerlink" title="-XX:+ResizeTLAB"></a>-XX:+ResizeTLAB</h3><p>Java应用线程使用的本地线程分配缓存块采用动态值还是静态值进行设置是由这个选项决定的，它默认是开启的，即TLAB值会被动态调整。</p><h3 id="XX-ClassUnloadingWithConcurrentMark"><a href="#XX-ClassUnloadingWithConcurrentMark" class="headerlink" title="-XX:+ClassUnloadingWithConcurrentMark"></a>-XX:+ClassUnloadingWithConcurrentMark</h3><p>这个选项开启在G1 GC并行循环阶段卸载类，尤其是在老年代的并行回收阶段，默认是开启的。这个选项开启后会在并行循环的重标记阶段卸载JVM没有用到的类，这些工作也可以放在Full GC里面去做，但是提前做了有很大的好处。但因为开启它意味着重标记阶段的GC停顿时间会拉长，这时候我们就要判断性价比了，如果GC停顿时间比我们设置的最大GC停顿目标时间还长，并且需要卸载的类也不多，那还是关闭这个选项吧。</p><h3 id="XX-ClassUnloading"><a href="#XX-ClassUnloading" class="headerlink" title="-XX:+ClassUnloading"></a>-XX:+ClassUnloading</h3><p>默认值是Ture，决定了JVM是否会卸载所有无用的类，如果关闭了这个选项，无论是并行回收循环，还是Full GC，都不会再卸载这些类了，所以需谨慎关闭。</p><h3 id="XX-UnlockDiagnosticVMOptions"><a href="#XX-UnlockDiagnosticVMOptions" class="headerlink" title="-XX:+UnlockDiagnosticVMOptions"></a>-XX:+UnlockDiagnosticVMOptions</h3><p>这个选项决定是否开启诊断选项，默认值是False，即不开启在GC里面有一些选项称之为诊断选项(Diagnostic Options)，通过-XX:+PrintFlagsFinal 和XX:+Unlock。DiagnosticVMOptions这两个选项组合起来运行，就可以输出并查看这些选项。</p><h3 id="XX-UnlockExperimentalVMOptions"><a href="#XX-UnlockExperimentalVMOptions" class="headerlink" title="-XX:+UnlockExperimentalVMOptions"></a>-XX:+UnlockExperimentalVMOptions</h3><p>除了之前说的诊断选项以外，JVM还有一些叫作试验选项(Experimental Options)，这些选项也需要通过XX:+UnlockExperimentalVMOptions这个选项开启，默认是关闭的。</p><p>和诊断选项一样，也可以和-XX:+PrintFlagsFinal选项联合使用，即-XX:+PrintFlagsFinal和-XX:+UnlockExperimental VMOptions这两个选项联合使用时可以输出日志，输出的日志已经包含在了前一个选项-XX:+UnlockDiagnosticVMOptions的运行输出里，这里就不再重复。</p><p>总的来说，这些试验选项对整体应用性能可能会有些好处，但是它们并没有经历完整的测试环节，所以称为试验选项。</p><h3 id="XX-UnlockCommercialFeatures"><a href="#XX-UnlockCommercialFeatures" class="headerlink" title="-XX:+UnlockCommercialFeatures"></a>-XX:+UnlockCommercialFeatures</h3><p>这个选项判断是否使用 Oracle特有的特性，默认是关闭的。</p><p>有一些属性是Oracle公司针对Oracle的Java运行时独有的，没有被包含在OpenJDK里面。举个例子，比如说 Oracle的监控和管理工具Java Mission Control，它有一个特性叫作Java Flight Recorder，这个特性作为Java Mission Control的一部分，属于事件回收框架，可以被用来显示应用程序和JVM的底层信息。</p><h1 id="深入G1-GC"><a href="#深入G1-GC" class="headerlink" title="深入G1 GC"></a>深入G1 GC</h1><h2 id="G1-GC概念简介"><a href="#G1-GC概念简介" class="headerlink" title="G1 GC概念简介"></a>G1 GC概念简介</h2><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><p>G1使用了全新的分区算法，其特点如下所示：</p><ul><li>并行性：G1在回收期间，可以有多个GC线程同时工作，可以有效利用多核的计算能力</li><li>并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况。</li><li>分代GC：G1依然是一个分代收集器，但是和之前的各类回收器不同，它同时兼顾了年轻代和老年代。对比其他回收器，它们或者工作在年轻代，或者工作在老年代。</li><li>空间整理：G1在回收过程中，会进行适当的对象移动，不像CMS那样只是简单地标记清理对象。在若干次GC后，CMS必须进行一次碎片整理。而G1不同，它每次回收都会有效地复制对象，减少空间碎片，进而提升内部循环速度。</li><li>可预见性：由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。</li></ul><p><font color="DeepPink"><strong>随着G1 GC的出现，GC从传统的连续堆内存布局逐渐走向了不连续内存块布局，这是通过引入Region概念实现的，也就是说，由一堆不连续的Region组成了堆内存。其实也不能说是不连续的，只是它从传统的物理连续逐渐改变为逻辑上的连续</strong></font>，这是通过Region的动态分配方式实现的，可以把一个Region分配给Eden、Surviⅳvor、老年代、大对象区间、空闲区间等区间的任意一个，而不是固定它的作用，因为越是固定，越是呆板。</p><h3 id="G1的区间设计灵感"><a href="#G1的区间设计灵感" class="headerlink" title="G1的区间设计灵感"></a>G1的区间设计灵感</h3><p><font color="DeepPink"><strong>在G1中，堆被平均分成若干个大小相等的区域(Region)。每个Region都有个关联的Remembered Set(简称RS)，RS的数据结构是Hash表，里面的数据是Card Table(堆中每512byte映射在card table 1byte)。简单地说，RS里面存在的是Region中存活对象的指针。当Region中数据发生变化时，首先反映到Card Table中的一个或多个Card上，RS通过扫描内部的Card Table得知Region中内存使用情况和存活对象。在使用Region过程中，如果Region 被填满了，分配内存的线程会重新选择一个新的Region，空闲Region被组织到一个基于链表的数据结构(LinkedList里面，这样可以快速找到新的Region。</strong></font></p><h2 id="G1-GC分代管理"><a href="#G1-GC分代管理" class="headerlink" title="G1 GC分代管理"></a>G1 GC分代管理</h2><h3 id="年轻代"><a href="#年轻代" class="headerlink" title="年轻代"></a>年轻代</h3><p>除非我们显示地通过命令行方式声明了年轻代的初始化值和最大值的大小，否则，<strong>一般来说，初始化值默认是整个Java堆大小的5%(通过选项-XX:G1NewSizePercent设置)，最大值默认是整个Java堆大小的60%(通过选项-XX:G1MaxNewSizePercent设置)。</strong></p><h3 id="回收集合及其重要性"><a href="#回收集合及其重要性" class="headerlink" title="回收集合及其重要性"></a>回收集合及其重要性</h3><p>任何一次垃圾回收都会释放CSet里面的所有区间。一个CSet由一系列的等待回收的区间所组成。在一次垃圾回收过程中，这些回收候选区间的存活对象会被整体评估，并且在回收结束后这些区间会被加入到空闲区间队列(LinkedList队列)。在一次年轻代回收过程中，CSet只会包含年轻代区间，而在一个混合回收过程中，CSet会在年轻代区间基础上再包含一些老年代区间，这就是新增的混合回收概念，不再对年轻代和老年代完全切分。</p><p>G1 GC提供了两个选项用于帮助选择进入CSet的候选老年代区间: </p><ul><li>-XX:G1MixedGCLiveThresholdPercent:JDK8u45默认值为一个G1 GC区间的85%。这个值是一个存活对象的阈值，并且起到了从混合回收的CSet里排除一些老年代区间的作用，即可以理解为G1 GC限制CSet仅包含低于这个阈值(默认85%)的老年代区间，这样可以减少垃圾回收过程中拷贝对象所消耗的时间。</li><li>-XX:G1OldCSetRegionThresholdPercent:JDK8u45默认值为整个Java堆区的10%。这个值设置了可以被用于一次混合回收暂停所回收的最大老年代区间数量。这个阈值取决于JVM进程所能使用的Java堆的空闲空间。</li></ul><h3 id="RSet及其重要性"><a href="#RSet及其重要性" class="headerlink" title="RSet及其重要性"></a>RSet及其重要性</h3><p>一个RSet是一个数据结构，这个数据结构帮助维护和跟踪在它们单元内部的对象引用信息，在G1 GC里，这个单元就是区间(Region)，也就是说，G1 GC里每一个RSet对应的是一个区间内部的对象引用情况。有了RSet，就不需要扫描整个堆内存了，当G1 GC执行STW独占回收(年轻代、混合代回收)时，只需要扫描每一个区间内部的RSet就可以了。因为所有RSet都保存在CSet里面，即Region-RSet-CSet这样的概念，所以一旦区间内部的存活对象被移除，RSet里面保存的引用信息也会立即被更新。这样我们就能够理解RSet就是一张虚拟的对象引用表了，每个区间内部都有这么一张表存在，帮助对区间内部的对象存活情况、基本信息做有序高效的管理。</p><p>G1 GC的年轻代回收或者混合回收阶段，由于年轻代被尽可能地设计为最大量的回收，这样的设计方式减少了对于RSet的依赖，即减弱了对于年轻代里面存储的跟踪引用信息的依赖程度，进而减弱了多余RSet的消耗。G1 GC只在以下两个场景依赖RSet。</p><ul><li>老年代到年轻代的引用：G1 GC维护了从老年代区间到年轻代区间的指针，这个指针保存在年轻代的RSet里面。</li><li>老年代到老年代的引用：G1 GC维护了从老年代区间到老年代区间的指针，这个指针保存在老年代的RSet里面。</li></ul><p>每一个区间只会有一个RSet由于对于对象的引用是基于Java应用程序的需求的，所以有可能会出现RSet内部的“热点”，即一个区间出现很多次的引用更新，都出现在同一个位置的情况。</p><p>对于一个访问很频繁的区间来说，这样的方式会影响RSet的扫描时间。</p><p>注意，区间(Region)并不是最小单元，每个区间会被进一步划分为若干个块(Chunks)。在G1 GC区间里，最小的单元是一个512个字节的堆内存块(Card)。G1 GC为每个区间设置了一个全局内存块表来帮助维护所有的堆内存块，如下图所示：<br><img src="/images/java-jvm-gc-g1-note/%E5%85%A8%E5%B1%80%E5%8D%A1%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><p>当一个指针引用到了RSet里面的一个区间时，包含该指针的堆内存块就会在PRT里面被标记。如果需要快速地扫描一张数据表，最好的方式是建立索引，一个粗粒度的PRT就是基于哈希表建立的。对于一个细粒度的PRT来说，哈希表内部的每一个入口对应一个区间，而区间内部的内存块索引也是存储在位图里面的。当细粒度PRT的最大值被突破的时候，我们就会开始采用粗粒度方式处理PRT。</p><p>在垃圾回收过程中，当扫描RSet并且内存块确实存在于PRT里时，G1 GC会在全局堆内存块数据表里标记对应的入口，这种做法避免了重新扫描这个内存块。G1 GC会在回收循环阶段默认清除内存堆表，在GC线程的并行工作(主要包括根外部扫描、更新和扫描RSet、对象拷贝、终止协议等)完成之后紧跟着的就是清除堆内存表标记(Clear CT)阶段。Update RS和Scan RS对应的是RSet的更新和扫描动作。</p><p>RSet的作用是很明显的，但是在使用过程中我们也遇到了写保护和并行更新线程的维护成本。</p><p>OpenJDK HotSpot的并行老年代和CMS GC都在执行JVM的一个对象引用写操作时使用了写保护机制，如代码object field = some_other_object。还记得我们对于每个区间是采用针对最小单元堆内存块进行管理的吗?这个写保护机制也会通过更新一个类似于堆内存块表的数据结构来跟踪跨年代引用。堆内存表在最小垃圾回收时会被扫描。写保护算法基于Urs Holzle的快速写保护算法，这个算法减少了编译代码时的外部指令消耗。</p><p>当跨越区间的更新发生的时候，G1 GC会将这些对应的堆内存块放入一个缓存，我们可以称这个缓存为“更新日志缓存”，写入该缓存的方式和写入队列的方式一样。G1 GC会使用一个专门的线程组去维持RSet信息，它们的职责是扫描“更新日志缓存”，然后更新RSet。JDK8u45采用选项-XX:G1ConcRefinementThreads设置这个线程组的数量，如果你没有设置，那么默认采用-XX:ParallelGCThreads选项。</p><p>一旦“更新日志缓存”达到了最大可用，它会被放入全局化的满载队列并启用一个新的缓存块。一旦更新线程在全局满载队列里面发现了入口，它们就开始并行处理整个满载缓存队列。</p><p>G1 GC针对并行更新线程采用的是分层方法，为了保证更新速度会加入更多的线程，如果实在跟不上速度，Java应用程序线程也会加入战斗，但尽量不要出现这样的情况，这种情况是发生了线程窃取，会造成应用程序花费了本可以用于自身程序算法运行的能力。</p><h3 id="并行标记循环"><a href="#并行标记循环" class="headerlink" title="并行标记循环"></a>并行标记循环</h3><p>并行标记循环的过程是初始标记阶段→根区间扫描阶段→并行标记阶段→重标记阶段→清除阶段，其中一部分是可以与应用程序并行执行的，一部分是独占式的。</p><h4 id="1-初始标记阶段"><a href="#1-初始标记阶段" class="headerlink" title="1.初始标记阶段"></a>1.初始标记阶段</h4><p>这个阶段是独占式的，它会停止所有的Java线程，然后开始标记根节点可及的所有对象。这个阶段可以和年轻代回收同时执行，这样的设计方式主要是为了加快独占阶段的执行速度。</p><p>在这个阶段，每一个区间的NATMS值会被设置在区间的顶部。</p><h4 id="2-根区间扫描阶段"><a href="#2-根区间扫描阶段" class="headerlink" title="2.根区间扫描阶段"></a>2.根区间扫描阶段</h4><p>设置了每个区间的TAMS值之后，Java应用程序线程重新开始执行，根区间扫描阶段也会和Java应用程序线程并行执行。基于标记算法原理，在年轻代回收的初始标记阶段拷贝到幸存者区间的对象需要被扫描并被当作标记根元素，相应地，G1 GC因此开始扫描幸存者区间。任何从幸存者区间过来的引用都会被标记，基于这个原理，幸存者区间也被称为根区间。</p><p>根区间扫描阶段必须在下一个垃圾回收暂停之前完成，这是因为所有从幸存者区间来的引用需要在整个堆区间扫描之前完成标记工作。</p><h4 id="3-并行标记阶段"><a href="#3-并行标记阶段" class="headerlink" title="3.并行标记阶段"></a>3.并行标记阶段</h4><p>首先可以明确的是，并行标记阶段是一个并行的且多线程的阶段，可以通过选项-XX:ConcGCThreads来设置并行线程的数量。默认情况下，G1 GC设置并行标记阶段线程数量为选项-XX:ParallelGCThreads(并行GC线程)的1/4。并行标记线程一次只扫描一个区间，扫描完毕后会通过标记位方式标记该区间已经扫描完毕为了满足SATB并行标记算法的要求，G1 GC采用一个写前barrier执行相应的动作。</p><h4 id="4-重标记阶段"><a href="#4-重标记阶段" class="headerlink" title="4.重标记阶段"></a>4.重标记阶段</h4><p>重标记阶段是整个标记阶段的最后一环。这个阶段是一个独占式阶段，在整个独占式过程中，G1 GC完全处理了遗留的SATB日志缓存、更新。这个阶段主要的目标是统计存活对象的数量，同时也对引用对象进行处理。</p><p>G1 GC采用多线程方式加快并行处理日志缓存文件，这样可以节省下来很多时间，通过选项-XX:ParallelGCThreads可以设置GC数量。</p><p>注意，如果你的应用程序使用了大量的引用对象，例如弱引用、软引用、虚引用、强引用，那么这个重标记阶段的耗时会有所增加。</p><h4 id="5-清除阶段"><a href="#5-清除阶段" class="headerlink" title="5.清除阶段"></a>5.清除阶段</h4><p>前面各个阶段在做的主要事情就是为了标记对象，那么为什么需要针对每一个区间进行标记呢?这是因为如果我们知道了每个区间的存活对象数量，如果这个区间没有一个存活对象，那么就可以很快地清除RSet，并且立即放入空闲区间队列，而不是将这个区间放入排队序列，等待一个混合垃圾回收暂停阶段的回收。RSet也可以被用来帮助检测过期引用，例如，如果标记阶段发现所有在特定堆块上的对象都已经死亡，那么RSet可以快速清除这块堆块。</p><p>一句话总结，清除阶段会识别并清理完全空闲的区域。它是并发的清理，不会引起停顿。</p><h3 id="评估失败和完全回收"><a href="#评估失败和完全回收" class="headerlink" title="评估失败和完全回收"></a>评估失败和完全回收</h3><p>如果在年轻代区间或者老年代区间执行拷贝存活对象操作的时候，找不到一个空闲的区间，那么这个时候就可以在GC日志里看到诸如“to-space exhausted”这样的错误日志打印。</p><p>发生这个错误的同时，G1 GC会尝试去扩展可用的Java堆内存大小。如果扩展失败，G1 GC会触发它的失败保护机制并且启动单线程的完全回收动作。</p><p>在这个完全回收阶段，单线程会针对整个堆内存里的所有区间进行标记、清除、压缩等动作。在完成回收后，堆内存就完全由存活对象填充，并且所有的年龄代对应的区间都已经完成了压缩任务。</p><p>也正是因为这个完全回收是单线程执行的，所以当堆内存很大时势必耗时很长，所以需要谨慎使用，最好不要让它经常发生，以避免不必要的长时间的应用程序暂停。</p><h2 id="G1-GC使用场景"><a href="#G1-GC使用场景" class="headerlink" title="G1 GC使用场景"></a>G1 GC使用场景</h2><p>如果应用程序具有如下的一个或多个特征，那么将垃圾收集器从CMS或ParallelOldGC切换到G1将会大大提升性能:</p><ul><li>Full GC次数太频繁或者消耗时间太长</li><li>对象分配的频率或代数提升(promotion)显著变化。</li><li>受够了太长的垃圾回收或内存整理时间(超过0.5~1s)</li></ul><p>注意，如果正在使用CMS或ParallelOldGC，而应用程序的垃圾收集停顿时间并不长，那么继续使用现在的垃圾收集器是个好主意。</p><h1 id="G1-GC性能优化方案"><a href="#G1-GC性能优化方案" class="headerlink" title="G1 GC性能优化方案"></a>G1 GC性能优化方案</h1><h2 id="G1的年轻代回收"><a href="#G1的年轻代回收" class="headerlink" title="G1的年轻代回收"></a>G1的年轻代回收</h2><h3 id="External-Root-Regions"><a href="#External-Root-Regions" class="headerlink" title="External Root Regions"></a>External Root Regions</h3><p><font color="DeepPink"><strong>外部根区间扫描指的是从根部开始扫描通过JNI中本地的类中调用Malloc函数分配出的内存。这个步骤是并行任务的第一个任务。这个阶段堆外(off-heap)根节点被开始扫描，这些扫描范围包括JVM系统字典、VM数据结构、JNI线程句柄、硬件注册器、全局变量，以及线程栈根部等，这个过程主要是为了找到并行暂停阶段是否存在指向当前收集集合(CSet)的指针。</strong></font></p><p>这里还有一个情况需要引起大家的重视，就是查看工作线程是否在处理一个单一的根节点时耗时过长，导致感觉类似挂起的现象。这个现象可以通过查看工作线程对应的“termination”日志看出来。如果存在这个现象，你需要去查看是否存在比较大的系统字典(JVM System Dictionary)，如果这个系统字典被当成了一个单一根节点进行处理，那么当存在大量的加载类时就会出现较长时间的耗时。</p><h3 id="Rememebered-Sets-and-Processed-Buffers"><a href="#Rememebered-Sets-and-Processed-Buffers" class="headerlink" title="Rememebered Sets and Processed Buffers"></a>Rememebered Sets and Processed Buffers</h3><p>Rset帮助维护和跟踪指向G1区间的引用，而这些区间本身拥有这些RSet。还记得我们在第4章介绍过的并行Refinement线程吗?这些线程的任务是扫描更新日志缓存，并且更新区间的RSet。为了更加有效地支援这些Refinement线程的工作，在并行回收阶段，所有未被处理的缓存(已经有日志写在里面了)都会被工作线程拿来处理，这些缓存也被称为日志里面的处理缓存。</p><p>为了限制花费在更新RSet上的时间，G1通过选项-XX:MaxGCPauseMills设置了目标暂停时间，采用相对于整个停顿目标时间百分比的方式，限制了更新RSet花费的总时长，让评估暂停阶段把最大量的时候花费在拷贝存活对象上。这个目标时间默认为整个停顿时间的10%，例如整个停顿时间是10s，那么花费在更新RSet上的时间最大为ls。G1 GC的设计目标是让更多的停顿时间花费在拷贝存活对象上面，因此暂停时间的10%被用于更新RSet也是比较合理的，百分比大了，花在干具体业务(各阶段拷贝存活对象)上的时间也就少了。</p><p>如果你发现这个值不太准确或者不符合你的实际需求，这里可以通过更新选项-XX:G1RSetUpdatingPauseTimePercent来改变这个更新RSet的目标时间值。切记，如果你改变了花费在更新RSet上的时间，那你必须有把握工作线程可以在回收暂停阶段完成它们的工作，如果不能，那这部分工作会被放到并行Refinement线程里面去执行，这会导致并行工作量增加、并行回收次数增多。最坏的情况是如果并行Refinement线程也不能完成任务，那么Java应用程序就会被暂停，原本负责执行Java应用程序的资源就会直接接手任务，这个画面“太美”不敢看!大家要尽量避免这种情况发生。</p><p>注意，-XX:G1ConcRefinementThreads选项的值默认和-XX:ParallelGCThreads的值一样，这意味着对于-XX:ParallelGCThreads选项的修改会同样改变-XX:G1ConcRefinementThreads选项的值。</p><p>在当前CSet里面回收之前，CSet内部的每个区间的Rset都需要被扫描，主要目的是找到CSet区间内部的引用关系。一个有较多存活对象的区间容易导致Rset的粒度变细，即每个区间对应的表格会从粗粒度变为细粒度，也可以理解为里面对象增多后扫描一个Rset需要更长的扫描时间，这样你就会看到更多的时间被花费在了扫描RSet上面。也可以理解为扫描时间取决于RSet数据结构的粗细粒度。</p><h3 id="Summarizing-Remembered-Sets"><a href="#Summarizing-Remembered-Sets" class="headerlink" title="Summarizing Remembered Sets"></a>Summarizing Remembered Sets</h3><p>XX:+G1SummarizeRSetStats选项用于统计RSet的密度数量(细粒度或者粗粒度)，这个密度帮助决定是否并行Refinement线程有能力去应对更新缓存的工作，并且收集更多关于Nmethods的信息。这个选项每隔n次GC暂停收集一次RSet的统计信息，这个n次由选项-XX:G1SummarizeRSetStatsPeriod=n决定，也是需要通过选项进行设置的。</p><p>注意，-XX:+G1SummarizeRSetStats选项是一个诊断选项，因此必须启用-XX:+UnlockDiagnosticVMOptions选项才可以启用-XX:+G1SummarizeRSetStats选项。</p><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> G1 </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库索引设计与优化 笔记</title>
      <link href="/relational-database-index-design-and-the-optimizers-notes.html"/>
      <url>/relational-database-index-design-and-the-optimizers-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《数据库索引设计与优化》 作者：Tapio Lahdenmaki，Michael Leach</p><p>出版时间：2015-06-01</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="索引误区"><a href="#索引误区" class="headerlink" title="索引误区"></a>索引误区</h2><h3 id="误区1：索引层级不要超过5层"><a href="#误区1：索引层级不要超过5层" class="headerlink" title="误区1：索引层级不要超过5层"></a>误区1：索引层级不要超过5层</h3><p>由于非叶子页通常都会留在内存或者读缓存中，所以通常索引任意一个叶子页的时间为10ms~20ms，这是固定的。所以，对索引层数的限制是没有什么意义的。</p><h3 id="误区2：单表的索引数不要超过6个"><a href="#误区2：单表的索引数不要超过6个" class="headerlink" title="误区2：单表的索引数不要超过6个"></a>误区2：单表的索引数不要超过6个</h3><p>我建议不要给表的索引数目设置上限。</p><p>保证所有的SQL语句都能够流畅运行是设计的底线。我们总能找到一种方法来达到这一点。如果为了达到这一点需要在表上创建10个索引，那么你就应该在表上建立10个索引。</p><h3 id="误区3：不应该索引不稳定的列"><a href="#误区3：不应该索引不稳定的列" class="headerlink" title="误区3：不应该索引不稳定的列"></a>误区3：不应该索引不稳定的列</h3><p><font color="DeepPink"><strong>索引行是按索引键的顺序存储的，所以当索引键中存一列被更新时，DBMS可能不得不把相应的行从旧的索引位置移到新的位置来保持这一顺序。这个新的位迓可能与旧的位置位于相同的叶子页上，在这种情况下，只有一个页会受到影响。然而，如果被修改的键是第一列或唯一的列，那么新的索引行可能必须被迁移到一个不同的叶子页上，即DBMS必须更新两个叶子页。三十年前，如果这个索引为一个4层索引，这也许需要6次磁盘随机读取：3次常规读取，即2次非叶子页读取和1次叶子页读取，加上新的位置所涉及的3次随机读取。当一次随机读取耗时30ms 时，迁移一个索引行可能会给该更新操作额外增加6 x 30ms =180ms 的响应时间。因此，不稳定的列很少被索引就不足为奇了。</strong></font></p><p><font color="DeepPink"><strong>现在，当四层索引中三个层级的非叶子页保留在内存中时，一次磁盘随机读取需要 l0 ms ，响应的时间变成了 2 x 10ms = 20ms 。此外，许多索引为多列索引，也称作复合或组合索引，它通常包含多列，以使得索引键值唯一。当不稳定的列为复合索引的尾列更新这个不稳定的列绝不会导致其迁移到新的叶子页。因此，在当前的磁盘条件下，更新一个不稳定的列只会对该更新操作增加10ms的响应时间。</strong></font></p><p>在当前磁盘条件下，只有在更新频率多于10次/秒的情况下，不稳定列才可能成为问题。</p><blockquote><p>创建索引的目的应该是在硬件容量限制的前提下保证所有的数据库调用运行的足够快。</p></blockquote><h2 id="系统化的索引设计"><a href="#系统化的索引设计" class="headerlink" title="系统化的索引设计"></a>系统化的索引设计</h2><ul><li>找到由于索引不合适而导致运行<strong>太慢</strong>的查询语句<br>  最差输入：导致执行时间最长的变量值</li><li>设计索引，使所有查询语句都运行的足够快<br>  表的维护（插入、更新、删除）也必须足够快</li></ul><h1 id="表和索引结构"><a href="#表和索引结构" class="headerlink" title="表和索引结构"></a>表和索引结构</h1><p>DBMS 会意识到多个索引或表页需要被顺序地读取，且能识別出那些不在缓冲池中的页。随后，它将发出多页I/O请求，每次请求的页的数量由DBMS决定。<font color="DeepPink"><strong>只有那些不在缓冲池中的页会被从磁盘服务器上读取，因为那些已经在缓冲池中的页中可能包含了尚未被写人磁盘的更新数据。</strong></font></p><h1 id="SQL处理过程"><a href="#SQL处理过程" class="headerlink" title="SQL处理过程"></a>SQL处理过程</h1><h2 id="谓词"><a href="#谓词" class="headerlink" title="谓词"></a>谓词</h2><p>WHERE子句由一个或者多个<font color="DeepPink"><strong>谓词（搜索参数）</strong></font>组成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># SQL 3.1</span><br><span class="line">WHERE SEX = &apos;M&apos;</span><br><span class="line">      AND</span><br><span class="line">      (WEIGHT &gt; 90</span><br><span class="line">      OR</span><br><span class="line">      HEIGHT &gt; 190)</span><br></pre></td></tr></table></figure><p>SQL 3.1中有三个简单谓词，它们是：</p><ul><li>SEX = ‘M’</li><li>WEIGHT &gt; 90</li><li>HEIGHT &gt; 190</li></ul><p>同样，它们也可以被认为是两个组合谓词：</p><ul><li>WEIGHT &gt; 90 OR HEIGHT &gt; 190</li><li>SEX = ‘M’ AND  ( WEIGHT &gt; 90 OR HEIGHT &gt; 190 )</li></ul><p>谓词表达式是索引设计的主要入手点。如果一个索引能够满足SELECT查询语句的所有谓词表达式，那么优化器就很有可能建立起一个高效的访问路径。</p><p>核实确认访问路径（执行计划）<br><img src="/images/database-index-design-optimizers/%E4%BC%98%E5%8C%96%E5%99%A8%E4%BD%95%E6%97%B6%E9%80%89%E6%8B%A9%E8%AE%BF%E9%97%AE%E8%B7%AF%E5%BE%84.png" alt></p><h1 id="为SELETE语句创建理想的索引【重点】"><a href="#为SELETE语句创建理想的索引【重点】" class="headerlink" title="为SELETE语句创建理想的索引【重点】"></a>为SELETE语句创建理想的索引【重点】</h1><blockquote><p>很多调优人员（尽管没经验）认为，如果一个SQL语句使用了索引，那这个 SQL就是被很好地优化过的，我对此感到很惊讶。你应该总是问自己，”这是不是可用的最好的索引？” 或 “再添加另外一个索引能否提升响应性能？”，又或者 “全表扫描会不会更快地返回结果？”</p></blockquote><h2 id="三星索引"><a href="#三星索引" class="headerlink" title="三星索引"></a>三星索引</h2><blockquote><p>三星索引：查询语句的理想索引。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DECLARE CURSOR41 CURSOR FOR</span><br><span class="line">SELECT    CNO, FNAME</span><br><span class="line">FROM      CUST</span><br><span class="line">WHERE     LNAME = :LNAME</span><br><span class="line">          AND</span><br><span class="line">          CITY  = :CITY</span><br><span class="line">ORDER BY  FNAME</span><br></pre></td></tr></table></figure><p><img src="/images/database-index-design-optimizers/%E5%9B%BE4.2.png" alt></p><h2 id="星级是如何给定的"><a href="#星级是如何给定的" class="headerlink" title="星级是如何给定的"></a>星级是如何给定的</h2><p>如果与一个查询相关的索引行是相邻的，或者至少相距足够靠近的话，那这个索引就可以被标记上第一颗星。这<font color="DeepPink"><strong>最小化</strong></font>了必须扫描的索引片的宽度。 </p><p>如果索引行的顺序与查询语句的需求一致，则索引可以被标记上第二颗星。这<font color="DeepPink"><strong>排除了排序操作</strong></font>。 </p><p>如果索引行包含的查询语句中的所有列，那么索引就可以被标记上第三颗星。这避免了访问表的操作：<font color="DeepPink"><strong>仅访问索引就可以了</strong></font>。 </p><p><font color="DeepPink"><strong>对于这三颗星，第三颗通常是最重要的。将一个列排除在索引之外可能会导致许多速度较慢的磁盘随机读。</strong></font>我们把一个至少包含第三颗星的索引称为对应查询语句的宽索引。</p><blockquote><p>宽索引：宽索引是指一个至少满足第三颗星的索引。该索引包含了SELECT语句所涉及的所有列，因而能够使得查询只需访问索引而无需访问表。</p></blockquote><p><strong>为了满足第一颗星</strong><br>首先取出所有等值谓词的列（WHERE COL=…）。把这些列作为索引最开头的列——以任意顺序都可以。对于CURSOR41来说，三星索引可以以LNAME、CITY或者以CITY、LNAME开头。在这两种情况下，必须扫描的索引片宽度将被缩减至最窄。</p><p><strong>为了满足第二颗星</strong><br>将ORDER BY列加入到索引中。不要改变这些列的顺序，但是忽略那些在第一步中已经加入索引的列。例如，如果CURSOR41在ORDER BY 中有重复的列，如ORDER BY LNAME、FNAME或者是ORDER BY FNAME、CITY，只有FNAME需要在这步中被加入到索引中去。当FNAME是索引的第三列时，结果集中的记录无须排序就已经是以正确的顺序排列的了。第一次读取操作将返回FNAME值最小的那一行。</p><p><strong>为了满足第三颗星</strong><br>将查询语句中剩余的列加到索引中去，列在索引中添加的顺序对查询语句的性能没有影响，但是将易变的列放在最后能降低更新的成本。现在，索引已包含了满足无须回表的访问路径所需的所有列。</p><p>最终三星索引将会是：(LNAME, CITY, FNAME, CNO) 或 (CITY, LNAME, FNAME, CNO)</p><p>CURSOR41在以下方面是最为挑剔的：</p><ul><li>WHERE 条件不包含范围谓词（BETWEEN、&gt;、&gt;=等）</li><li>FROM 语句只涉及单表</li><li>所有谓词对于优化器来说都足够简单</li></ul><h2 id="范围谓词与三星索引"><a href="#范围谓词与三星索引" class="headerlink" title="范围谓词与三星索引"></a>范围谓词与三星索引</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DECLARE CURSOR43 CURSOR FOR</span><br><span class="line">SELECT    CNO, FNAME</span><br><span class="line">FROM      CUST</span><br><span class="line">WHERE     LNAME BETWEEN :LNAME1 AND :LNAME2</span><br><span class="line">          AND</span><br><span class="line">          CITY  = :CITY</span><br><span class="line">          ORDER BY  FNAME</span><br></pre></td></tr></table></figure><p>让我们尝试为这个 CURSOR 设计一个三星索引。大部分的推论与 CURSOR41 相同，但是“BETWEEN 谓词”将“=谓词”替代后将会有很大的影响。我们将会以相反的顺序依次考虑三颗星，按理说，这代表了理解的难度。</p><p>首先是最简单的星（虽然非常重要），第三颗星。按照先前所述，<strong>确保查询语句中的所有列都在索引中就能满足第三颗星。这样不需要访问表，那么同步读也就不会造成问题。</strong></p><p>添加 ORDER BY 列能使索引满足第二颗星，但是这个仅在将其放在 BETWEEN 谓词列 LNAME 之前的情况下才成立，如索引 (CITY, FNAME, LNAME)。由于 CITY 的值只有一个（=谓词），所以使用这个索引可以使结果集以 FNAME 的顺序排列，而不需要额外的排序。但是如果 ORDER BY 字段加在 BETWEEN 谓词列 LNAME 后面，如索引 (CITY, LNAME, FNAME)，那么索引行不是按 FNAME 顺序排列的，因而就需要进行排序操作。因此，为了满足第二颗星，FNAME 必须在 BETWEEN 谓词列 LNAME 前面，如索引 (FNAME, …) 或索引 (CITY, FNAME, …)。</p><p>再考虑第一颗星，如果 CITY 是索引的第一个列，那我们将会有一个相对较窄的索引片需要扫描（MC=1），这取决于 CITY 的过滤因子。但是如果用索引 (CITY, LNAME, …) 的话，索引片会更窄，这样在有两个匹配列的情况下我们只需要访问真正需要的索引行。但是，为了做到这样，并从一个很窄的索引片中获益，其他列（如 FNAME）就不能放在这两列之间。</p><blockquote><p>MC:match column（匹配列）</p></blockquote><p>所以我们的理想索引会有几颗星呢？首先它一定能有第三颗星，但是，正如我们刚才所说，我们只能有第一颗星或者第二颗星，而不能同时拥有两者！换句话说，我们只能二选一：</p><ul><li>避免排序 — 拥有第二颗星</li><li>拥有可能的最窄索引片，不仅将需要处理的索引行数降至最低，而且将后续处理量，特别是表中数据行的同步读，减少到最少 — 拥有第一颗星</li></ul><p>在这个例子中，BETWEEN 谓词或者任何其他范围谓词的出现，意味着我们不能同时拥有第一颗星和第二颗星。也就是说我们不能拥有一个三星索引。这就意味着我们需要在第一颗星和第二颗星中做出选择。通常这不是一个困难的选择，<strong>因为第一颗星一般比第二颗星更重要，虽然并不总是这样</strong>。</p><h2 id="为查询语句设计最佳索引的算法"><a href="#为查询语句设计最佳索引的算法" class="headerlink" title="为查询语句设计最佳索引的算法"></a>为查询语句设计最佳索引的算法</h2><p><font color="DeepPink"><strong>根据以上的讨论，理想的索引是一个三星索引。然而，正如我们所见，当存在范围谓词时，这是不可能实现的。我们（也许）不得不牺牲第二颗星来满足一个更窄的索引片（第一颗星），这样，最佳索引就只拥有两颗星。这也就是为什么我们需要仔细区分理想和最佳。</strong></font>在这个例子中理想索引是不可能实现的。将这层因素考虑在内，我们可以对所有情况下创建最佳索引（也许不是理想索引）的过程公式化。创建出的索引将拥有三颗星或者两颗星。</p><p><strong>首先设计一个索引片尽可能窄（第一颗星）的宽索引（第三颗星）。如果查询使用这个索引时不需要排序（第二颗星），那这个索引就是三星索引。否则这个索引只能是二星索引，牺牲第二颗星。或者采用另一种选择，避免排序，牺牲第一颗星保留第二颗星。这种二星索引中的一个将会是相应查询语句的最佳索引。</strong></p><h3 id="为查询语句创建最佳索引的算法"><a href="#为查询语句创建最佳索引的算法" class="headerlink" title="为查询语句创建最佳索引的算法"></a>为查询语句创建最佳索引的算法</h3><h4 id="候选-A"><a href="#候选-A" class="headerlink" title="候选 A"></a>候选 A</h4><ol><li>取出对于优化器来说不过分复杂的等值谓词列。将这些列作为索引的前导列(以任意顺序皆可)。</li><li>将选择性最好的范围谓词作为索引的下一个列，如果存在的话。最好的选择性是指对于最差的输入值有最低的过滤因子。只考虑对于优化器来说不过分复杂的范围谓词。</li><li>以正确的顺序添加ORDER BY语列，忽略在第一步或者第二步已添加的列。</li><li>以任意顺序将 SELECT 语句中其余的列添加至索引中（但是需要以不易变的列开始）。</li></ol><p>举例：CURSOR43</p><p>候选 A 为 (CITY, LNAME, FNAME, NCNO)。</p><p>由于 FNAME 在范围谓词列 LNAME 的后面，候选 A 引起了 CURSOR43 的一次排序操作。</p><h4 id="候选-B"><a href="#候选-B" class="headerlink" title="候选 B"></a>候选 B</h4><p>如果候选 A 引起了所给查询语句的一次排序操作，那么还可以设计候选 B。根据定义，对于候选 B 来说第二颗星比第一颗星更重要。</p><ol><li>取出对于优化器来说不过分复杂的等值谓词列。将这些列作为索引的前导列(以任意顺序皆可)。</li><li>以正确顺序添加 ORDER BY 列（如果 ORDER BY 列有 DESC 的话，加上 DESC）。忽略在第1步中已经添加的列。</li><li>以任意顺序将 SELECT 语句中其余的列添加至索引中（但是需要以不易变的列开始）。</li></ol><p>举例：CURSOR43</p><p>候选 B 为 (CITY, FNAME, LNAME, CNO)。</p><blockquote><p>需要注意的是，到目前为止，我们所做的只是设计理想索引或是最佳索引。但是这是否是实际可行的，我们在这个阶段还不好说。</p></blockquote><h1 id="前瞻性的索引设计"><a href="#前瞻性的索引设计" class="headerlink" title="前瞻性的索引设计"></a>前瞻性的索引设计</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h3><p>根据定义，DBMS读取一个索引行或一个表行的成本称为一次访问 : 索引访问或表访问。如果DBMS扫描索引或表的一个片段(被读取的行在物理上是彼此相邻的)，那么第一行的读取即为一次随机访问。对于后续行的读取，每行都是一次顺序访问。在当前的硬件条件下，顺序访问的成本比随机访问的成本低得多。一次索引访问的成本与一次表访问的成本基本上是相同的。</p><h3 id="读取一组连续的索引行"><a href="#读取一组连续的索引行" class="headerlink" title="读取一组连续的索引行"></a>读取一组连续的索引行</h3><p>物理上彼此相邻是什么意思?</p><p>索引上的所有行都通过指针链接在一起，链接的先后顺序由索引的键值严格定义。当几个索引行的键值相同时，就根据索引行存储的指针值进行链接。在传统的索引设计(从某个角度看，是理想化的)中，链表从LP1(叶子页1)开始，随后链接LP2，以此类推。这样(假设每个磁道可以放12个叶子页，当前的硬件通常可以容纳更多)，叶子页就组成了一个连续的文件，LP1至LP12存储在磁盘柱面的第一个磁道，LP13至LP24存储在下一个磁道，如此继续，当第一个柱面存满后，下一组LP就会被存储在下一个柱面的首个磁道上。换句话说，就是叶子页之间没有其他页。</p><p>现在，读取一个连续的索引行(即一个索引片，或者包含了单个键值或者一个范围的键值所对应的索引行)就非常快了。一次磁盘旋转会将多个叶子页读取进内存中，而且只有在磁盘指针移到下一个柱面时才需要进行一次短暂的寻址、</p><p>不过，这个完美的顺序还是会被打破的，至少有以下三个影响因素 :</p><ol><li>如果一个叶子页没有足够的空间存储新插入的索引行，那么叶子页就必须被分裂。之后链表仍会按照正确的顺序链接索引行，但是这与底层的物理存储顺序就不再一致了，一些按道理应该是顺序的访问就变成随机访问了。不过索引的充足可以再次恢复最理想的顺序。</li><li>意向不到的数据增长可能会填满原本连续的空间(区或类似的概念)。操作系统于是就会寻找另外有一个连续的空间，并将它连接到原来空间的后面。这时候从第一个区跨到第二个区访问就会产生一次随机访问，不过这种情况影响不大。</li><li>RAID 5条带会将前几个叶子页存储在一个驱动器上，将后面的叶子页存放在另外的驱动器上。这就会产生额外的随机读，但实际上条带的积极作用要大过随机读带来的性能恶化，一个智能的磁盘服务器可以将后续的叶子页并行的从多个驱动器上读取至磁盘缓存中，从而大大降低了单个叶子页的I/O时间。此外，在RAID 5条带策略下，一个被频繁访问的索引的不太可能导致某一个磁盘负载过高，因为I/O请求会被均匀低分布到RAID 5阵列内的多个磁盘驱动器。</li></ol><p>忽略上述情况，我们仍然假设，如果两个索引行在链表上彼此相邻(或者在唯一索引中，相同键值的行指针意味着彼此相邻)，那么我们就认为这两行在物理上也相邻。这就意味着QUBE认为所有的索引都有最理想的顺序。</p><h3 id="读取一组连续的表行"><a href="#读取一组连续的表行" class="headerlink" title="读取一组连续的表行"></a>读取一组连续的表行</h3><p>读取一组连续的表行有如下两种情况：</p><ol><li>全表扫描<br>从TP1(表页1)开始，读取该页上所有的记录，然后再访问TP2，一次类推。按照记录在表页中存储的顺序进行读取，没有其他特殊的顺序。</li><li>聚簇索引扫描<br>读取索引片上第一个索引行，然后获取相应的表行，再访问第二个索引行，以此类推。如果索引行与对应的表行记录顺序完全一致(聚簇率为100%)，那么除了第一次之外的所有表访问就都是顺序访问。表记录的链接方式跟索引不一样。单个表页中记录的顺序无关紧要，只要访问的下一个表记录在同一个表页或者相邻的下一个表页内就可以了。</li></ol><p>同索引一样，存储表的传统方式也是将所有表页保留在一个连续的空间内。引起顺序杂乱或碎片化的因素也和索引中的相似，但又两个地方不同：</p><ol><li>如果往表中插入的记录在聚簇索引所定义的主页中装不下，则通常不会移动现有的行，而是会将新插入的记录存储到离主页尽可能近的表页中。对第二个页的随机I/O会使聚簇索引扫描变得更慢，但是如果这条记录离主页很近，这些额外的开销就可以被避免，因为顺预读功能会一次性将多个表页装载到数据库缓存中。即使顺序预读功能没有使用，也只有当该页在数据库缓存被覆盖的情况下才会发生额外的随机I/O。</li><li>一条记录被更新后，可能因为表行过长导致其无法再存储于当前的表页中。这是DBMA就必须将该行记录迁移至另外一个表页中，同时在原有的表页中存储指向新表页的指针。当该行被访问时，会引入额外的随机访问。<br>表可以通过重组来还原行记录的顺序，从而减少不必要的随机访问。</li></ol><h2 id="计算访问次数"><a href="#计算访问次数" class="headerlink" title="计算访问次数"></a>计算访问次数</h2><h3 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a>随机访问</h3><p>我们首先思考一下磁盘读与访问的区别。<strong>一次磁盘读所访问的对象是一个页，而一次访问的访问对象则是一行。</strong>一次随机磁盘读会将一整页(通常会包含很多行)读取至数据库的缓冲池中，但是根据定义，前后两次随机读不太可能会访问到同一个页。</p><h2 id="使用满足需求的成本最低的索引还是所能达到的最有索引"><a href="#使用满足需求的成本最低的索引还是所能达到的最有索引" class="headerlink" title="使用满足需求的成本最低的索引还是所能达到的最有索引"></a>使用满足需求的成本最低的索引还是所能达到的最有索引</h2><p><font color="DeepPink"><strong>当有多个等值谓词作为匹配列时，我们需要考虑这些列在索引上的先后顺序。经常变化的列应当尽可能的排在后面。</strong></font></p><blockquote><p>更改现有索引列的顺序和在现有索引列之间添加新列同样危险。在这两种情况下，现有的select的执行速度都可能会急剧下降，因为匹配列减少了，或者引入了排序(导致过早产生结果集)</p></blockquote><h2 id="半宽索引-最大化索引过滤"><a href="#半宽索引-最大化索引过滤" class="headerlink" title="半宽索引(最大化索引过滤)"></a>半宽索引(最大化索引过滤)</h2><p>在现有索引的末端添加缺少的谓词列可以消除大量的随机访问，因为这样能引入索引过滤过程。</p><h1 id="影响索引设计过程的因素"><a href="#影响索引设计过程的因素" class="headerlink" title="影响索引设计过程的因素"></a>影响索引设计过程的因素</h1><p>I/O时间估算:</p><ul><li>随机读取 10ms(页的大小为4KB或8KB)</li><li>顺序读取 40MB/s</li></ul><p>这些数据是假定系统使用当前硬件并在一个合理的负载下运行时的值。一些系统可能运行的更慢或处理超负荷状态。</p><h2 id="困难谓词"><a href="#困难谓词" class="headerlink" title="困难谓词"></a>困难谓词</h2><p>大体上，假设一个谓词的判定结果为false，而这时如果不检查其他谓词就不能确定地将一行记录排除在外，那么这类谓词对优化器而言就是太过困难的。</p><h2 id="过滤因子隐患"><a href="#过滤因子隐患" class="headerlink" title="过滤因子隐患"></a>过滤因子隐患</h2><p>当以下三个条件同时满足时，这种过滤因子隐患可能会产生 :</p><ul><li>访问路径中没有排序</li><li>第一屏结果一建立就回应</li><li>不是所有的谓词字段都参与定义带扫描的索引片–换句话说就是，不是所有的字段都是匹配字段。</li></ul><h1 id="被动式索引设计"><a href="#被动式索引设计" class="headerlink" title="被动式索引设计"></a>被动式索引设计</h1><blockquote><p>被动式的方法与莱特兄弟创造守架飞机的经历非常相似。本质上就是把查询放在一起，推下悬崖，然后看他能否起飞。换句话说，就是为应用设计一个没有索引的原型，然后开始运行一些查询。又或者，创建原始索引集，然后通过运行应用来看那些索引被用到，那些没有被用到。即使是一个小型的数据库系统，运行速度慢的查询也会被很快凸显出来。</p><p>被动式调优的方法也被用来理解和调优一个性能没有满足预期的已有应用。</p></blockquote><h2 id="对结果集排序"><a href="#对结果集排序" class="headerlink" title="对结果集排序"></a>对结果集排序</h2><p>除了全表扫描和全索引扫描，结果集的排序就是最有用的警示信号了。引起排序的原因可能有以下两种:</p><ul><li>没有可使查询语句避免排序的索引。</li><li>优化器所选择的访问路径包含了一次多余的排序。</li></ul><blockquote><p>有很多数据库顾问将排序视为敌人。我们认为，哪些强调随机I/O带来致命影响的顾问更值得信任。</p></blockquote><h2 id="成本估算"><a href="#成本估算" class="headerlink" title="成本估算"></a>成本估算</h2><p>一些数据库管理系统的EXPLAIN功能显示了优化器对所选访问路径的本地响应时间的估算，或至少显示了对CPU时间的估算。</p><p>不幸的是，以下两个严重问题限制了使用成本估算方法的价值:</p><ul><li>优化器所做出的的本地响应时间估算可能与实际相差很大</li><li>当谓词使用绑定变量时(显然这是很普遍的)，优化器对过滤因子的估算是基于平均输入值的，或更差情况下，基于默认值。为了获取更有价值的最差情况估值，EXPLAIN中的绑定变量必须用最差情况下的输入值来代替。这是一个需要应用知识的累人操作。</li></ul><h1 id="为表连接设计索引"><a href="#为表连接设计索引" class="headerlink" title="为表连接设计索引"></a>为表连接设计索引</h1><h2 id="预测表的访问顺序"><a href="#预测表的访问顺序" class="headerlink" title="预测表的访问顺序"></a>预测表的访问顺序</h2><p>在大部分情况下，可以使用以下经验法则来预测最佳的表访问顺序 : 将包含<strong>最低数量本地行</strong>的表作为外层表。</p><blockquote><p>本地行的数量是指最大过滤因子过滤本地谓词之后所剩余的行数。</p></blockquote><p>经验法则忽略了以下因素:</p><ol><li>排序。</li><li>很小的表。<font color="DeepPink"><strong>非常小的表及其索引可能长期存在于数据库的缓冲池中</strong></font>，至少在一个连接查询中，没有页会被读取多次。在这样的表和索引上进行随机读取所耗费的时间小于0.1ms，至少在页被第一次读取之后是这样的。所以，当这样的表不是外层表时，对其大量的随机读取也不会称为问题。</li><li>聚簇比例。索引中行的顺序和表中行的顺序的关联性(对于聚簇索引而言，该关联性在表重组后为100%)，可能会影响对最佳访问顺序的选择，当然，除非索引是宽索引。</li></ol><p>最好的基于成本的优化器在进行路径选择时会把这些因素考虑进来。因此，他找出的访问顺序可能比我们基于本地行的数量的经验所得出的结果更优。</p><h2 id="合并扫描连接和哈希连接"><a href="#合并扫描连接和哈希连接" class="headerlink" title="合并扫描连接和哈希连接"></a>合并扫描连接和哈希连接</h2><h3 id="合并扫描连接"><a href="#合并扫描连接" class="headerlink" title="合并扫描连接"></a>合并扫描连接</h3><p>执行过程如下</p><ul><li>执行表或索引扫描以找出满足本地谓词的所有行。</li><li>随后可能会进行排序，如果这些扫描未按所要求的顺序提供结果集。</li><li>对前两者生成的临时表进行合并。</li></ul><p>在以下情况下，合并扫描会比嵌套循环快。</p><ol><li>用于连接的字段上没有可用的索引。在这种情况下，若使用嵌套循环，那么内层表可能需要被扫描很多次。在实际情况中，用于连接的列上面没有索引的情况很少见，因为大部分连接谓词都是基于“主键等于外键”这一条件的。</li><li>结果表很大。在这种情况下，若使用嵌套循环连接，可能会导致相同的页被不断的重复访问。</li><li>连接查询中不止一张表的过滤因子很低。如我们所见，嵌套循环可能导致对内层表(或者内层表索引)的大量随机访问。</li></ol><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DECLARE CURSOR81 CURSOR FOR</span><br><span class="line">SELECT CNAME, CTYPE, INO, IEUR</span><br><span class="line">FROM CUST, INVOICE</span><br><span class="line">WHERE CUST.CTYPE = :CTYPE</span><br><span class="line">      AND</span><br><span class="line">      IDATE &gt; :IDATE</span><br><span class="line">      AND</span><br><span class="line">      CUST.CNO = INVOICE.CNO</span><br></pre></td></tr></table></figure><h3 id="哈希连接"><a href="#哈希连接" class="headerlink" title="哈希连接"></a>哈希连接</h3><p>哈希连接本质上是用哈希算法代替排序算法的合并扫描连接。首先，对较小的结果集用哈希算法计算其连接字段，并将其保存在一个临时表中；然后，再扫描其他的表(或索引片)，并通过(计算得到的)哈希值将满足本地谓词条件的每一行记录与临时表中相应的行进行匹配。</p><p>若结果行集已在索引中满足了所要求的顺序，那么合并扫描的速度将更快。若合并扫描需要进行排序，那么哈希连接的速度可能更快，尤其是当其中一个行集能够全部留在内存中时(对一个哈希表进行一次随机访问所花费的CPU时间，通常会比排序和合并一行所花费的时间少)。如果两个行集很大，那么哈希表会根据可用内存的大小对哈希表进行分区(同一时间内存中只有一个分区)，而另外一个行集会被扫描多次。</p><h2 id="为什么连接的性能表现较差"><a href="#为什么连接的性能表现较差" class="headerlink" title="为什么连接的性能表现较差"></a>为什么连接的性能表现较差</h2><h3 id="模糊的索引设计"><a href="#模糊的索引设计" class="headerlink" title="模糊的索引设计"></a>模糊的索引设计</h3><p>“在连接字段上建索引”是最古老的索引建议之一。事实上，这是基于建议的一个扩展 : “<strong>为主键创建一个索引，并且为每一个外键创建一个由此外键作为前导列的索引</strong>”。在连接谓词上建索引使得嵌套循环称为一个可行的方案，但包含连接谓词列并不一定能够提供完全可接受的响应时间。连接谓词列上的索引和本地谓词上的索引通常都需要是宽索引。而且，不同的表访问顺序可能导致完全不同的索引需求。</p><h2 id="为子查询设计索引"><a href="#为子查询设计索引" class="headerlink" title="为子查询设计索引"></a>为子查询设计索引</h2><p>从性能的角度看，子查询与连接十分相似。<strong>实际上，现今的优化器通常会在进行访问路径的选择之前，先将子查询重写为一个连接。</strong>若优化器没有进行重写，那么子查询的类型本身可能就决定了表访问顺序。内外层无关联的子查询通常会从最内层的SELECT开始执行。结果集被保存在一张临时表中，等待下一个SELECT的访问。内外层有关联的子查询通常会从最内层的SELECT开始执行。无论是何种情况，同连接一样，应当基于能够形成最快访问路径的表访问顺序进行索引设计。若最佳的表访问顺序未被选中，那么程序开发人员可能需要对语句进行重写，在某些情况下还可能要使用连接。</p><h2 id="为UNION语句设计索引"><a href="#为UNION语句设计索引" class="headerlink" title="为UNION语句设计索引"></a>为UNION语句设计索引</h2><p>通过UNION或UNION ALL连接的SELECT语句是逐个分别进行优化和指向的。因此，应该为每个独立的SELECT设计合适的索引。需要注意一点，带ORDER BY的UNION可能会导致提前物化。</p><h2 id="对于表设计的思考"><a href="#对于表设计的思考" class="headerlink" title="对于表设计的思考"></a>对于表设计的思考</h2><h3 id="冗余数据"><a href="#冗余数据" class="headerlink" title="冗余数据"></a>冗余数据</h3><p>有两种通过冗余数据优化连接速度的方法：</p><ol><li>将某列拷贝至依赖表(向下反范式法)。</li><li>将汇总数据添加至父表(向上反范式法)。</li></ol><h3 id="向下反范式化"><a href="#向下反范式化" class="headerlink" title="向下反范式化"></a>向下反范式化</h3><p>不过，总体而言，当我们考虑引入向下反范式化时，需要预测一下冗余字段更新时可能会导致最差情况下的索引随机访问次数。</p><h3 id="反范式化的成本"><a href="#反范式化的成本" class="headerlink" title="反范式化的成本"></a>反范式化的成本</h3><p>考虑性能时最令人关注的通常是，为了更新表及索引上的冗余字段锁带来的I/O时间。在向下反范式化中，这可能需要移动大量的索引行，从而导致一个简单的UPDATE运行的很慢。向上反范式化不太可能因为一次简单的更新操作而引发I/O剧增。不过INSERT，UPDATE和DELETE可能导致父表及其索引上的一些额外I/O。在极端情况下，如每秒10次以上的INSERT或UPDATE，由这些I/O带来的磁盘负载可能会成为问题。</p><h2 id="嵌套循环连接和合并扫描连接-哈希连接-VS-反范式化"><a href="#嵌套循环连接和合并扫描连接-哈希连接-VS-反范式化" class="headerlink" title="嵌套循环连接和合并扫描连接/哈希连接 VS 反范式化"></a>嵌套循环连接和合并扫描连接/哈希连接 VS 反范式化</h2><p>许多数据库专家不愿意将冗余列添加至事务型表上，这是可以理解的。反范式化不仅仅是查询速度和更新速度之间的一个权衡，在某种程度上，他还是性能和数据完整性之间的一个权衡，即使在使用触发器来维护冗余数据的情况下。然而，当嵌套循环引入了过多的随机访问，且MS/HJ耗费了过多的CPU时间时，反范式化可能成为唯一的选择。尽管如此，在决定采用这一极端的方案之前，我们必须确保所有能够避免这一方案的方法都已经考虑过了。</p><h2 id="无意识的表设计"><a href="#无意识的表设计" class="headerlink" title="无意识的表设计"></a>无意识的表设计</h2><p>从性能的角度看，我们非常难以理解为何有那么多的数据库中存在具有1 : 1或1: C(C = 有条件的;即0或1)关系的表。</p><p>为何要建四张表而非只建一张CUST表？只要关系永远不会变成1 : M，那么灵活性就不会成为问题。在本例中，客户要么是公司，要么是个人，且不会有客户死亡两次!</p><p>将这四张表合成一张部分字段为空的表(对于每一行，要么公司相关的字段为空，要么个人相关的字段为空；同样，所有活着的客户的死亡相关的字段为空)，这是存储空间和性能(随机访问的次数)之间的权衡。为空的数据并不违反范式。</p><p>在不考虑硬件性能的情况下设计表可能会有如下问题 :</p><ul><li>即便是在最佳索引条件下，随机访问的次数仍可能会很高。</li><li>复杂连接可能使得索引设计变得非常困难。</li><li>优化器可能对复杂连接做出错误的访问路径选择。</li></ul><h1 id="星型连接"><a href="#星型连接" class="headerlink" title="星型连接"></a>星型连接</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>星型连接与普通连接的差别主要有两个方面：</p><ol><li>如下图所示，位于星型结构中心位置的表称为<strong>事实表</strong>，它的数据量远大于它周围的表—<strong>维度表</strong>。</li><li>最佳的访问路径通常是包含维度表的<strong>笛卡尔积</strong>，这意味着他们<strong>没有相同的冗余列</strong>，满足本地谓词的维度表数据行都会参与连接。</li></ol><p><img src="/images/database-index-design-optimizers/%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" alt></p><p>SALES 销售记录<br>STORE 出售的店铺<br>ITEM  出售的商品<br>DATE  出售的时间<br>CUST  出售的客户</p><p>在星型连接中，事实表的数据量通过都比较大。在这种情况下，至少依据经验法则，事实表应该作为嵌套循环连接方式中最内层的表。一般情况下未读表都没有共同的列，所以这种链接顺序意味着是笛卡尔连接。</p><h2 id="事实表的索引"><a href="#事实表的索引" class="headerlink" title="事实表的索引"></a>事实表的索引</h2><p>事实上，宽索引通常比事实表还大，原因有两个 :</p><ol><li>表通常都进行了压缩处理，而索引没有。</li><li>新增一条记录通常都追加到表的尾部，因此事实表并不需要分散的空闲空间。但插入到索引(除了聚簇索引)上的位置是随机的。为了避免频繁的索引重组，在当前硬件条件下，通常10亿行的表将花费几个小时，大多数的索引在叶子节点上都需要留出足够的空闲空间，可能为30% ~ 40%。</li></ol><h2 id="汇总表"><a href="#汇总表" class="headerlink" title="汇总表"></a>汇总表</h2><p>即使是在理想索引的情况下，一些针对10亿条记录的事实表进行的查询也会导致大量的I/O访问。提高这类查询的性能的唯一方式就是使用汇总表(查询表)。这类表是反范式化的事实表。如果表不是特别大(比如只包含几百万行数据)，那么这是一个比较可行的方案，因为反模式化查询只需针对汇总表，而不需要多表关联。</p><p>如果频繁查询每周的销售情况，那么可以针对每周的消费记录建立一张汇总表。比较好的汇总表设计是根据周，商品，商店汇总一条记录。汇总表根据周和商品进行汇总后，数据量可以大幅度减少。在这种情况下，查询的响应时间可能降低到不到1秒钟。</p><p>汇总表上的索引通常会比较小，他唯一的显示因素就是刷新此表所需的时间。如同所有新鲜事物一样，汇总表的方案也会带来新的问题。</p><ol><li>如果用户的查询需求多样，汇总表的设计会比索引的设计更困难，不过，已经有一些工具基于查询日志来协助汇总表的设计。</li><li>如果优化器不能选择正确的汇总表，那么汇总表的意义就不大；我们不能指望用户来指定查询使用某个合适的汇总表。最好的优化器已经在试着访问合适的表了，虽然SELECT语句实际上查询的是事实表。如果优化器不具备这个能力，或者它的正确率不够高，那么可能就不得不强制指定每个用户只能访问一个汇总表。用户不得不自己选择要使用的汇总表。优化器能自动识别的汇总表通常被称为自动汇总表或物化视图。</li></ol><h1 id="多索引访问"><a href="#多索引访问" class="headerlink" title="多索引访问"></a>多索引访问</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>许多数据库管理系统支持从一张表的多个索引处收集制作，或是从单个索引的几个索引片收集，然后比较这些指针集并访问满足WHERE语句中所有谓词条件的数据行。这一能力被称为多索引访问，或被称为索引与(索引交集)和索引或(索引并集)。</p><blockquote><p>多索引访问的思想是：对表中数据分别使用各个索引，最后将满足条件的进行交集或并集操作。</p></blockquote><h1 id="索引和索引重组"><a href="#索引和索引重组" class="headerlink" title="索引和索引重组"></a>索引和索引重组</h1><h2 id="DBMS如何查找索引行"><a href="#DBMS如何查找索引行" class="headerlink" title="DBMS如何查找索引行"></a>DBMS如何查找索引行</h2><p><font color="DeepPink"><strong>在当前的硬件条件下，非叶子页很可能已经被缓存在数据库缓冲池中，或者至少在磁盘的读缓存中，因为它们经常被频繁的访问。</strong></font></p><h2 id="插入一行会发生什么？"><a href="#插入一行会发生什么？" class="headerlink" title="插入一行会发生什么？"></a>插入一行会发生什么？</h2><p>如果一张表有一个聚簇索引，那么DBMS会根据聚簇索引的键值尝试将插入的记录放在它所属的表页(主页)中。如果这行记录在主页里放不下，或者当前页被锁住，那么DBMS将会检查邻近的页。在最坏的情况下，新的行会被插入到标的最坏一页。<font color="DeepPink"><strong>依赖于DBMS和表的类型，已经插入的行通常都不会被移动，否则这将意味着更新表上已经建立的所有索引上的相关指针。</strong></font>当有许多表行未能存在在主页中时，如果表行的顺序很重要，则需要对这个表进行重组—对于那些涉及多张大表的大规模批处理任务而言，通常需要这么做。</p><p>当往表中插入一条记录时，DBMS会尝试将索引行添加至其索引建所属的叶子页上，但是该索引页可能没有足够的空闲空间来存放这个索引行，在这种情况下，DBMS将会分裂该叶子页。其中一半的行将被移动到一个新的叶子页上，并尽可能地靠近被分裂的页，但是在最坏的情况下，这个索引页可能会被放置在索引的末尾。除了在每个叶子页上预留部分比例的空闲空间外，也许可以在索引被创建或重组时，每n个页面预留一个空页—当索引分裂无法避免时，这会是一个不错的办法。</p><p><font color="DeepPink"><strong>当一个索引有一个不断增长的键值时，新行将被添加到索引页的最后，索引页可能永远也不会进行分裂,这样的索引可能不需要任何空闲空间。</strong></font></p><h2 id="叶子页的分裂严重吗？"><a href="#叶子页的分裂严重吗？" class="headerlink" title="叶子页的分裂严重吗？"></a>叶子页的分裂严重吗？</h2><p>分裂一个索引页只需一次额外的同步读，约10ms。除了两个叶子页以外，DBMS通常还必须更新一个非叶子页，而它很可能已经在内存或者读缓存中了。</p><p>在叶子页分裂后，查询任何一条索引行的速度很可能同之前一样快。在最坏情况下，一次分裂会创建一个新的索引层级，但是如果不是从磁盘读取非叶子页的话，这只会增加很少的CPU时间。</p><p>然而，叶子页的分裂会导致一个索引片变得更慢。目前为止，我们在所有的场景中都假设串联索引行的链指针总是指向同一页或者下一页，这些页可能已被DBMS预读取。在索引被创建或者重组后，这种假设是接近真实情况的，但是索引片上的每处叶子页分裂都可能会增加额外的两次随机访问—一次是为了查找索引行被移动至的索引页，一次是为了返回到扫描的原始位置。其中第一次随机访问很可能会导致一次磁盘的随机读取(10ms)。</p><h2 id="什么时候应该对索引进行重组？"><a href="#什么时候应该对索引进行重组？" class="headerlink" title="什么时候应该对索引进行重组？"></a>什么时候应该对索引进行重组？</h2><h3 id="插入模式"><a href="#插入模式" class="headerlink" title="插入模式"></a>插入模式</h3><p>索引重组是为了恢复索引行正确的物理位置，他对于索引片扫描和全索引扫描的性能而言很重要。因为插入模式的不同，增加的索引行可能会以无序的方式来创建。我们需要记住，更新一个列意味着需要删除旧的索引行，并增加一个新的索引行，新索引行的位置由新的索引键值来确定。</p><p>下文对三种基本插入模式的讨论基于如下假设</p><ol><li>索引是唯一索引。</li><li>被删除的索引行锁腾出的空间在重组之前可以被新的索引行重用。</li></ol><h3 id="新索引行被添加至索引的尾部-永远递增的键"><a href="#新索引行被添加至索引的尾部-永远递增的键" class="headerlink" title="新索引行被添加至索引的尾部(永远递增的键)"></a>新索引行被添加至索引的尾部(永远递增的键)</h3><p>假设插入了一个索引行，其索引键值比任何已经存在的索引键值都要大，则DBMS就不会分类最后的叶子页，那么就不需要空闲的空间或者进行索引重组了。然而，如果在索引前面的索引行被定期地删除，那么为了回收空闲的空间，索引可能不得不进行重组(一个“爬行”的索引)。</p><h3 id="随机插入模式"><a href="#随机插入模式" class="headerlink" title="随机插入模式"></a>随机插入模式</h3><p>我们稍后将会看到，尽管考虑了空闲空间和重组，对于不同的索引行长度(短，中，长)的处理也是不同的。越长的索引行越难处理，越短的越好处理。</p><p>有一个重要的例外场景 : 如果索引行是变长的，那么就需要有空闲的空间去适应任何索引行的增长。</p><h2 id="索引重组的代价"><a href="#索引重组的代价" class="headerlink" title="索引重组的代价"></a>索引重组的代价</h2><p>一个索引可以以多种方式进行重组：</p><ol><li>全索引扫描（随机访问且无须排序，或者顺序访问并排序）。</li><li>全表扫描（类似 CREATE INDEX; 顺序访问及一次排序）。</li></ol><p>由索引重组产生的锁等待依赖于具体的数据库和选项。如果使用的是简易的工具,那么当表或者索引正在被扫描吋，整个表可能被加上一个S锁(更新操作会被阻塞）。如果工具能在扫描期间将更新操作保存下来，并在排序前将它们应用到数据行上，那么锁等待的时间将会缩短很多。</p><p>有些时候，大的索引可能不得不在不合适的时间被重组。在最坏情况下，锁的问题可能会导致频繁的重组无法实现。在这种情况下 ， 一些易变的索引可能必需被强制缓存在内存中（将其固定在内存中）。</p><h1 id="数据库管理系统相关的索引限制"><a href="#数据库管理系统相关的索引限制" class="headerlink" title="数据库管理系统相关的索引限制"></a>数据库管理系统相关的索引限制</h1><h2 id="索引列的数量"><a href="#索引列的数量" class="headerlink" title="索引列的数量"></a>索引列的数量</h2><p>能够复制到索引上的列的个数上限在16至64之间。并非每个人都将这视为一个问题。 Gulutzan 和 Pelzer提出了一个出人意料的<br>建议，如下:</p><blockquote><p>针对所有数据库管理系统的总体建议为：在一个复合索引中最多使用5列。虽然你能够确定数据库管理系统至少能够支持16列，但是5列是一些专家所认为的合理上限。</p></blockquote><h2 id="索引列的总长度"><a href="#索引列的总长度" class="headerlink" title="索引列的总长度"></a>索引列的总长度</h2><p>复制到索引的列的总长度存在一个上限，该上限的值取决于数据库管理系统。随着宽索引变得越来越流行，这一上限在数据库筲理系统的新版本中在变大。</p><h2 id="单表索引数量上限"><a href="#单表索引数量上限" class="headerlink" title="单表索引数量上限"></a>单表索引数量上限</h2><p>在单表索引数量限制方面，许多数据库产品要么没有上限，要么上限太高以至于无关紧要。</p><h2 id="索引大小上限"><a href="#索引大小上限" class="headerlink" title="索引大小上限"></a>索引大小上限</h2><p>典型的索引大小上限为几GB,而且这一上限正在持续增大。就像大表一样，大索引通常是分区的，这样能够使执行维护程序的成本最小化，并且能将索引分散到多个磁盘驱动器或RAID组上。</p><h2 id="索引锁定"><a href="#索引锁定" class="headerlink" title="索引锁定"></a>索引锁定</h2><p>从更新的时间点到提交的时间点内，如果数据库管理系统给一个索引页或者一个索引页的一部分（如一个子页）加了锁，那么该索引页或子页很能会成为瓶颈，因为插入操作将会变为顺序的。例如，SQL Server 2000就是这样做的，但如果上锁的粒度仅为一行，那么这不可能会成一个问题。</p><p>在DB2数据库的z/OS版本中，使用闩锁来保证索引页的物理完幣性。当用闩锁对一个缓冲池中的页加锁时，实际上是在数据库缓冲池中进行了一次置位操作，当释放闩锁时再进行重置。一个页只有在读取或修改时才会被加上闩锁，在当前的处理器条件下耗费时间不到一微秒。而数据完幣性是通过对索引行所指向的表页或表行加上普通锁来保证的（仅对数据上锁）。当程序修改一个表行或表页。这些锁一直不会释放，直至修改被提交。</p><h1 id="数据库索引选项"><a href="#数据库索引选项" class="headerlink" title="数据库索引选项"></a>数据库索引选项</h1><p>索引键决定了这一索引行在索引结构中的位置。当索引键被修改后,DBMS会删除原来的索引行，并将其插入到新的位置上。在最差情况下，索引行会被移动到其他的叶子页上。</p><h1 id="其他评估事项"><a href="#其他评估事项" class="headerlink" title="其他评估事项"></a>其他评估事项</h1><h2 id="宽索引还是理想索引"><a href="#宽索引还是理想索引" class="headerlink" title="宽索引还是理想索引"></a>宽索引还是理想索引</h2><p>单纯从响应时间来看，理想的索引并非具有完全的优势，我们给出了如下结论 :</p><blockquote><p>虽然三星索引有一定的优势，尤其是在结果集为空的情况下，但是这个优势并不也别明显，而且会带来与新增索引相关的额外开销。</p></blockquote><h1 id="组织索引设计过程"><a href="#组织索引设计过程" class="headerlink" title="组织索引设计过程"></a>组织索引设计过程</h1><h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><p>在大公司里，一个合理的折中方案是聘用50/50的专家，他们会将50%的时间用来应用程序开发，另外50%的时间用于协助同事进行索引评估及其他性能问题的处理（比如根据EXPLAIN的输出内容解决某个优化器问题）。经验显示，为每5至10位应用开发者配一名50/50专家的方式效果很好。</p><p>索引设计需要同事掌握技术技能以及应用系统知识。相比让数据库专家熟悉应用系统的细节而言，教会开发人员索引技能是更容易的。</p><hr><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Database" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Database</a></p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> Design </tag>
            
            <tag> Database </tag>
            
            <tag> Oracle </tag>
            
            <tag> SQL Server </tag>
            
            <tag> DB2 </tag>
            
            <tag> Index </tag>
            
            <tag> Optimizers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java性能优化权威指南 笔记</title>
      <link href="/java-performance-notes.html"/>
      <url>/java-performance-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《Java性能优化权威指南》 </p><p>作者：Charlie Hunt / Binu John </p><p>出版时间：2014-03</p><a id="more"></a><h1 id="操作系统性能监控"><a href="#操作系统性能监控" class="headerlink" title="操作系统性能监控"></a>操作系统性能监控</h1><h2 id="CPU使用率"><a href="#CPU使用率" class="headerlink" title="CPU使用率"></a>CPU使用率</h2><p>大多数的操作系统的CPU使用率分为用户态CPU使用率和系统态CPU使用率。</p><p>用户态CPU使用率是指执行应用程序代码的时间占总CPU时间的百分比。</p><p>系统态CPU使用率是指应用执行操作系统调用的时间占总CPU时间的百分比。<font color="DeepPink"><strong>系统态CPU使用率高意味着共享资源有竞争或者I/O设备之间有大量的交互。</strong></font></p><p>既然原本用于执行操作系统内核调用的CPU周期也可以用来执行应用代码，所以理想情况下，应用达到最高性能和扩展性时，它的系统态CPU使用率为0%，所以提高应用性能和扩展性的一个目标是尽可能降低系统态CPU使用率。</p><p>对于计算密集型应用来说，不仅要监控用户态和系统态CPU使用率，还要进一步监控每时钟指令数（Instructions Per Clock，IPC）或每指令时钟周期（Cycles Per Instruction，CPI）等指标。这两个指标对于计算密集型应用来说很重要，因为<font color="DeepPink"><strong>现代操作系统自带的CPU使用率监控工具只能报告CPU使用率，而没有CPU执行指令占用CPU时钟周期的百分比，这意味着，即便CPU在等待着内存中的数据，操作系统工具仍然会报告CPU繁忙。这种情况通常被称为停滞。当CPU执行指令所用的操作数据不在寄存器或者缓存中时，就会发生停滞，由于指令执行前必须等待数据从内存中装入CPU寄存器，所以一旦发生停滞，就会浪费时钟周期。</strong></font>CPU停滞通常会等待好几百个时钟周期，因此提高计算密集型应用性能的策略就是减少停滞或者改善CPU高速缓存使用率，从而减少CPU在等待内存数据时浪费的时钟周期。</p><h2 id="CPU调度程序运行队列"><a href="#CPU调度程序运行队列" class="headerlink" title="CPU调度程序运行队列"></a>CPU调度程序运行队列</h2><p>监控CPU调度程序运行队列对于分辨系统是否满负荷也有重要意义。<font color="DeepPink"><strong>运行队列中就是那些已准备好运行、正等待可用CPU的轻量级进程。如果准备运行的轻量级进程数超过系统所能处理的上限，运行队列就会很长。</strong></font>运行队列长表明系统负载可能饱和。系统运行队列长度等于虚拟机处理器的个数时，用户不会明显感觉到性能下降。此处虚拟处理器的个数就是系统硬件线程的个数，也是Java API Runtime.availableProcessors()的返回值。当运行队列长度达到虚拟处理的4倍或者更多时，系统的响应就非常迟缓了。</p><p>一般性的指导原则是：如果在很长一段时间里，运行队列的长度一直都超过虚拟处理器个数的1倍，就需要关注了，只是暂时还不需要立刻采取行动。<font color="DeepPink"><strong>如果在很长一段时间里，运行队列长度达到虚拟处理器个数的3~4倍或更高，则需要立刻引起注意和采取行动。</strong></font></p><h2 id="内存使用率"><a href="#内存使用率" class="headerlink" title="内存使用率"></a>内存使用率</h2><p>系统在进行页面交换或者使用虚拟内存时，Java应用或JVM会表现出明显的性能问题。当应用运行所需的内存超过可用物理内存时，就会发生页面交换。为了应对这种可能出现的情况，通常要为系统配置swap空间。swap空间一般会在一个独立的磁盘分区上。当应用耗尽内存时，操作系统会将应用的一部分置换到磁盘上的swap空间。通常是应用中最少运行的部分，以免影响整个应用或者应用最忙的那部分。当访问应用中被置换出去的部分时，就必须将它从磁盘置换进内存，而这种置换活动会对应用的响应性和吞吐量造成很大影响。</p><p><font color="DeepPink"><strong>JVM垃圾收集器在系统页面交换时的性能也很差，这是由于垃圾收集器为了回收不可达对象所占用的空间，需要访问大量的内存。如果Java堆得一部分被置换出去，就必须先置换进内存以便垃圾收集器扫描存活对象，这会增加垃圾收集的持续时间。</strong></font>垃圾收集是一种Stop-The-World操作，即停止所有正在运行的应用线程，如果此时系统正在进行页面交换，则会引起JVM长时间的停顿。</p><h3 id="监控抢占式上下文切换"><a href="#监控抢占式上下文切换" class="headerlink" title="监控抢占式上下文切换"></a>监控抢占式上下文切换</h3><p>让步式上下文切换时指执行线程主动释放CPU，抢占式上下文切换时指线程因为分配的时间片用尽而被迫放弃CPU或者被其他优先级更高的线程锁抢占。pidstat的输出结果中<font color="DeepPink"><strong>cswch/s</strong></font>是每秒的让步式上下文切换，<font color="DeepPink"><strong>nvccswch/s</strong></font>是抢占式上下文切换。</p><h3 id="监控线程迁移"><a href="#监控线程迁移" class="headerlink" title="监控线程迁移"></a>监控线程迁移</h3><p>我们发现，待运行线程在处理器之前的迁移也会导致性能的下降。大多数操作系统的CPU调度程序会将待运行线程分配给上次运行它的虚拟处理器。如果这个虚拟处理器忙，调度程序就会将待处理线程迁移到其他可用的虚拟处理器。<font color="DeepPink"><strong>线程迁移会对应用性能造成影响，这是因为新的虚拟处理器缓存中可能没有待运行线程所需的数据或状态信息。</strong></font>多核系统上运行Java应用可能会发生大量的线程迁移，减少迁移的策略是创建处理器组并将应用分配给这些处理器组。一般性准则是，<font color="DeepPink"><strong>如果横跨多核或虚拟处理器的Java应用每秒迁移超过500次，将Java应用绑定在处理器组上就有好处。</strong></font></p><h2 id="网络I-O使用率"><a href="#网络I-O使用率" class="headerlink" title="网络I/O使用率"></a>网络I/O使用率</h2><h3 id="应用性能改进的考虑"><a href="#应用性能改进的考虑" class="headerlink" title="应用性能改进的考虑"></a>应用性能改进的考虑</h3><p>单次读写数据量小而网络读写量大的应用会消耗大量的系统态CPU，产生大量的系统调用。对于这类应用，减少系统态CPU的策略是减少网络读写的系统调用。此外，使用非阻塞的Java NIO而不是阻塞的java.net.Socket，减少处理请求和发送相应的线程数，也可以改善应用性能。</p><p>从非阻塞Socket中读取数据的策略是，应用在每次读请求时尽可能多地读取数据。同样，当往Socket中写数据时，每个写调用应该尽可能多地写。</p><h1 id="JVM概览"><a href="#JVM概览" class="headerlink" title="JVM概览"></a>JVM概览</h1><h2 id="HotSpot-运行时"><a href="#HotSpot-运行时" class="headerlink" title="HotSpot 运行时"></a>HotSpot 运行时</h2><h3 id="命令行选项"><a href="#命令行选项" class="headerlink" title="命令行选项"></a>命令行选项</h3><p>HotSpot VM 命令行选项有3类：</p><ul><li>标准选项（Standard option）：标准选项是Java virtual Machine Specification要求所有java JVM 都必须实现的选项。</li><li>非标准选项（NonStandard option）：非标准选项(以–X为前缀)，不保证也不强制所有JVM实现都必须支持。</li><li>非稳定选项（Developer option）：非稳定选项(以-XX为前缀),通常为了特定需要而对JVM的运行进行矫正。选项名称前+代表 true启用，-代表false关闭。</li></ul><h3 id="VM生命周期"><a href="#VM生命周期" class="headerlink" title="VM生命周期"></a>VM生命周期</h3><p>启动器启动HotSpot VM时会执行一系列操作。步骤概述如下：</p><ol><li>解析命令行选项</li><li>设置堆的大小和JIT编译器<br>如果命令行没有明确设置堆的大小和JIT编译器，启动器则通过自动优化进行设置。</li><li>设定环境变量如：LD_LIBRARY_PATH和CLASSPATH</li><li>如果命令行有-jar选项，启动器则从指定JAR的manifest中查找Main-Class，否则从命令行读取Main-Class</li><li>使用标准Java本地接口（Java Native Interface，JNI）方法JNI_CreateJavaVM在新创建的线程中创建HotSpot VM</li><li>一旦创建并初始化号HotSpot VM，就会加载Java Main-Class，启动器也会从Java Main-Class中取得Java main方法的参数</li><li>HotSpot VM通过JNI方法CallStartVoidMethod调用Java main方法，并将命令行选项传给它</li></ol><h3 id="VM类加载阶段"><a href="#VM类加载阶段" class="headerlink" title="VM类加载阶段"></a>VM类加载阶段</h3><h4 id="类加载阶段"><a href="#类加载阶段" class="headerlink" title="类加载阶段"></a>类加载阶段</h4><p>对于给定的Java类或接口，类加载时会依据它的名字找到Java类的二进制类文件，定义Java类，然后创建代表这个类或者接口的java.lang.Class对象。如果没有找到Java类或接口的二进制表示就会抛出NoClassDefFound。此外，类加载阶段会对类的格式进行语法检查，如果有错，则会抛出ClassFormatError或UnsupportedClassVersionError。Java类加载前，HotSpot VM必须先加载它的所有超类和超接口，如果类的继承层次有错，例如Java类是它自己的超类或超接口（类层次递归）,HotSpot VM则会抛出ClassCircularityError。如果所引用的直接超接口本身并不是接口，或者直接超类实际上是接口，HotSpot VM则会抛出IncompatibleClassChangeError。</p><p>链接的第一步是验证，检查类文件的语义、常量池符号以及类型。如果检查有错，就会抛出VerifyError。链接的下一步是准备，它会创建静态字段，初始化为标准默认值，以及分配方法表。请注意，此时还没有执行任何Java代码。接下来解析符号引用，这一步是可选的。然后初始化类，运行类构造器。这是迄今为止，类中运行的第一段Java代码。值得注意的是，<font color="DeepPink"><strong>初始化类需要首先初始化超类（不会初始化超接口）</strong></font>。</p><blockquote><p>如：int的标准默认值为0；public static int value=123，准备阶段将其初始化为0而不是123，value=123的赋值操作在类构造器&lt;clinit&gt;()中。<br>public static final int value=123，编译时会为value在字段属性表中生成ConstantValue，从而在准备阶段就被初始化成123。</p></blockquote><p>Java Virtual Machine Specification规定首次使用类时进行类初始化，而Java Language Specification则允许在链接阶段符号解析时灵活处理，只要保持语言的语义不变，JVM依次执行加载、链接和初始化，保证及时抛出错误即可。出于性能优化的考虑，通常直到类初始化时HotspotVM才会加载和链接类。<font color="DeepPink"><strong>这意味着，类A引用类B。加载A不一定导致加载B（除非B需要验证）。执行B的第一条指令会导致初始化B，从而加载和链接B。</strong></font></p><h4 id="类加载器委派"><a href="#类加载器委派" class="headerlink" title="类加载器委派"></a>类加载器委派</h4><p>当请求类加载器查找和加载某个类时，该类加载器可以转而请求别的类加载器来加载。这被称为类加载器委派。类的首个类加找器称为初始类加载器（Initiating ClassLoader)，最终定义类的类加载器称为定义类加载器（Defining ClassLoader）。<font color="DeepPink"><strong>就字节码解析而言，某个类的初始类加载器是指对该类进行常量池符号解析的类加载器。</strong></font></p><p>类加载器之间是层级化关系，每个类加载器都可以委派给上一级类加载器。这种委派关系定义了二进制类的查找顺序。<font color="DeepPink"><strong>Java SE类加载器的层级查找顺序为启动类加载器、扩展类加载器及系统类加载器。</strong></font>系统类加载器是默认的应用程序类加载器，它加载Java类的main方法并从classpath上加载类。<font color="DeepPink"><strong>应用程序类加载器可以是Java SE系统自带的类加载器，或者由应用程序开发人员提供。扩展类加载器则JavaSE系统实现，它负责从JRE(Java Runtime Environment,Java运行环境）的lib/ext目录下加载类。</strong></font></p><h4 id="启动类加载器"><a href="#启动类加载器" class="headerlink" title="启动类加载器"></a>启动类加载器</h4><p><font color="DeepPink"><strong>启动类加载器是由HotSpot VM实现的，负责加载BOOTCLASSPATH路径中的类，如包含Java SE类库的rt.jar。</strong></font>为了加快启动速度，Client模式的HotSpot VM可以通过称为类教据共享（Class Data Sharing）的特性使用已经预加载的类。这个特性默认为开启，可由HotSpot VM命令行开关-Xshare:on开启，-Xshare:off关闭。到本书编写时为止，Server模式的HotSpot VM还不支持类数据共享，而且即便是Client模式，也只有使用Serial收集器时才支持该机制。</p><h4 id="类型安全"><a href="#类型安全" class="headerlink" title="类型安全"></a>类型安全</h4><p>Java类或接口的名字为全限定名（包括包名）。Java的类型由全限定名和类加载器唯一确定。</p><h4 id="HotSpot类元数据"><a href="#HotSpot类元数据" class="headerlink" title="HotSpot类元数据"></a>HotSpot类元数据</h4><p>类加载时，HotSpot VM会在永久代创建类的内部表示instanceKlass或arrayKlass。instanceKlass应用了与之对应的java.lang.Class实例，后者是前者的Java镜像。HotSpot VM内部使用称为klassOop的数据结构访问instanceKlass。后缀“Oop”表示普通对象指针，所以klassOop是应用java.lang.Class的HotSpot内部抽象，它是指向Klass（与Java类对应的内部表示）的普通对象指针。</p><h4 id="内部的类加载数据"><a href="#内部的类加载数据" class="headerlink" title="内部的类加载数据"></a>内部的类加载数据</h4><p>类加载过程中，HotSpot VM维护了3张散列表。SystemDictionary包含已加载的类，它将建立类名/类加载器（包括初始类加载器和定义类加载器）与klassOop对象之间的映射。目前只有在安全点事才能移除SystemDictionary中的元素。Placeholder-Table包含当前正在加载的类，它用于检查ClassCircularityError，多线程类加载器并行加载类时也会用到它。LoaderConstraintTable用于追踪类型安全检查的约束条件。<font color="DeepPink"><strong>这些散列表都需要加锁保证访问安全，在HotSpot VM中，这个锁称为SystemDictionary_lock。通常，HotSpot VM借助类加载器对象锁对加载类的过程进行序列化。</strong></font></p><h3 id="字节码验证"><a href="#字节码验证" class="headerlink" title="字节码验证"></a>字节码验证</h3><p>Java是一门类型安全语言，官方标准的Java编译器（javac）可以生成合法的类文件和类型安全的字节码，但Java虚拟机无法确保字节码一定是由可信的javac编译器产生的，所以在链接时必须进行字节码验证以保障类型安全。</p><h3 id="类数据共享"><a href="#类数据共享" class="headerlink" title="类数据共享"></a>类数据共享</h3><p>类数据共享是Java 5引人的特性，以缩短Java程序（特別是小程序）的启动时间，同时也能减少它们的内存占用。使用Java HotSpot JRE安装程序在32位平台上安装Java运行环境（JRE)时，安装程序会加载系统jar中的部分类，变成私有的内部表示并转储成文件，称为共享文档(Shared Archive)。如果过没有使用Java HotSpot JRE安装程序，也可以手工生成该文件。之后调用Java虚拟机时，共享文档会映射到JVM内存中，从而减少减少加载这些类的开销，也使得这些类的大部分JVM允数椐能在多个JVM进程间共享。</p><h3 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h3><p>HotSpot VM解释器是一种基于模板的解释器。JVM启动时，HotSpot VM运行时系统利用内部TemplateTable中的信息在内存中生成解析器。TemplateTable包含于每个字节码对应的机器代码，每个模板描述一个字节码。</p><p>HotSpot VM解释器堪于模板的设计要好于传统的switch语句循环方式。switch语句需要重复执行比较操作，最差情况需要和所冇字节码比较。此外，switch语句必须使用单独的软件栈传递 Java 参数。HotSpot VM使用本地C栈传递 Java 参数。一些存储在C变量中的HotSpot VM内部变量，例如Java线程的程序计数器或栈指针，并不能保证总是存储在底层硬件寄存器中。结果，管理这些软件解释器数据结构就会占去总执行时间的相当大一部分。不过总体来说，HotSpot解释器显著缩短HotSpot VM和实体机之间的性能差距，解释速度也明显变快了，然而代价是大量与机器相关的代码。例如，Intel X86平台特定的代码大约有10000行，SPARC平台专用的代码大约打14000行。由于需要支持动态代码生成（JIT编译），整体的代码量和复杂度也显著变大。并且调 试动态生成的机器码（ JIT编译代码）比调试静态代码困难多了。虽然这些不利于运行时系统的改善，但也并非不可能完成的任务。</p><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>当与Java的语义约束冲突时，Java虚拟机会用异常通知程序。异常处理由HotSpot VM解释器、JIT编译器和其他HotSpot VM组件一起协作实现。异常处理主要有两种情形，同一方法中抛出和捕获异常，或由调用方法捕获异常。异常可以由抛出字节码、VM内部调用返回、JNI调用返回或Java调用返回所引发。</p><h3 id="线程管理"><a href="#线程管理" class="headerlink" title="线程管理"></a>线程管理</h3><p><font color="DeepPink"><strong>HotSpot VM通过协作、轮询的机制创建安全点</strong></font>。简中来说，线程会经常询问：“我该在安全点停住么？ ”高效地询问这个问题并不是件容易的事。线程在状态变迁的过程中，会经常询问这个问题，但并非所有的状态变迁都会如此询问，比如线程离开HotSpot VM进入本地代码的情况。此外，JIT编译代码从java方法中返回或正作循环迭代的某个阶段时，线程也会询问“我该在安全点停住吗？ ”。正在执行解释代码的线程通常不会询问它们是否该在安全点停住。相反，当解释器切换到不同的分配表时，会请求安全点。切换操作中包含一部分代码，用以询问何时离开安全点。当离开安全点时，分配表会再次切换回来。一旦请求了安全点，VMThread就必须在继续执行VM操作前等待，直到确定所行线程都已进入安全点保全状态为止。在安全点时，VMThread用Threads_lock阻塞所有正在运行的线程，VM操作完成后 , VMThread释放Threads_lock。</p><h3 id="Java本地接口（JNI）"><a href="#Java本地接口（JNI）" class="headerlink" title="Java本地接口（JNI）"></a>Java本地接口（JNI）</h3><p>切记，一旦在应用中使用JNI，就意味着丧失了Java平台的两个好处。首先，依赖JNI的Java应用难以在多种异构的硬件平台上运行。即便应用中Java语言编写的部分可以移植到多种硬件平台，采用本地编程语言的部分也需要重新编译。换句话说，一旦使用JNI就失去了Java承诺的特性，即“一次编写，到处运行”。其次，Java是强类型和安全的语言,本地语言如C或C++则不是。因此，Java开发者用JNI编写应用时必须格外小心。误用本地方法可能破坏整个应用。鉴于此，在调JNI方法前，Java应用常常需要安仝检查。额外的安全检查以及HotSpot VM在Java与JNI之间的数据复制会降低应用的性能。</p><p>HotSpot VM追踪正在执行本地方法的线程时必须特別小心。在HotSpot VM的某些活动过程中，尤其是垃圾收集的某些阶段，线程必须在安全点时暂停，以保证Java内存堆不被更改，确保垃圾收集的准确性。当HotSpot VM线程执行本地代码到达安全点时，线程可以继续执行本地代码，直到它Java代码或者发起JNI调用为止。</p><h3 id="VM致命错误处理"><a href="#VM致命错误处理" class="headerlink" title="VM致命错误处理"></a>VM致命错误处理</h3><p>HotSpot内部使用信号进行通信。当无法识别信号时，将调用致命错误处理程序。在无法识别的情况下，它可能来自应用程序JNI代码，OS本地库，JRE本地库或JVM本身的错误。</p><h2 id="HotSpot-VM垃圾收集器"><a href="#HotSpot-VM垃圾收集器" class="headerlink" title="HotSpot VM垃圾收集器"></a>HotSpot VM垃圾收集器</h2><h3 id="分代垃圾收集"><a href="#分代垃圾收集" class="headerlink" title="分代垃圾收集"></a>分代垃圾收集</h3><p>垃圾收集器不需要扫描整个（可能比新生代更大）老年代就能识别新生代中的存活对象，从而缩短Minor GC的时间。<font color="DeepPink"><strong>HotSpot VM的垃圾收集器使用称为卡表（CardTable)的数据结构来达到这个目的。老年代以512字节为块划分成若十张卡（Card)。卡表是个单字节数组，每个数组元素对应堆中的一张卡。每次老年代对象中某个引用新生代的字段发生变化时，HotSpot VM就必须将该卡所对位的卡表元素设置为适当的值，从而将该引用字段所在的卡标记为脏。在Minor GC过程中，垃圾收集器只会在脏卡中扫描查找老年代-新生代引用。</strong></font></p><p><img src="/images/java-performance-note/%E5%9B%BE3-3.png" alt></p><p><font color="DeepPink"><strong>HotSpot VM的字节码解释器和JIT编译器使用写屏障(Write Barrier)维护卡表。</strong></font>写屏障是一小段将卡状态设罝为脏的代码。解释器每次执行更新引用的字节码时，都会执行一段写屏障；JIT 编译器在生成更新引用的代码后，也会生成一段写屏障。虽然写屏障使得应用线程增加了一些性能开销，但Minor GC变快了许多，整天的垃圾收集效率也提高了许多。通常应用的吞吐量也会有所改善。</p><h3 id="新生代"><a href="#新生代" class="headerlink" title="新生代"></a>新生代</h3><p>需要指出的是，<font color="DeepPink"><strong>在Minor GC过程中，Survivor可能不足以容纳Eden和另一个Survivor中的存活对象。如果Survivor 中的存活对象溢出，多余的对象将被移到老年代。这称为过早提升(Premature Promotion)</strong></font>。这会导致老年代中短期存活对象的增长，可能会引发严重的性能问题。再进一步说，在Minor GC过程中，如果老年代满了而无法容纳更多的对象，Minor GC之后通常就会进行Full GC,这将导致遍历整个Java堆。这称为提升失败（Promotion Failure）。</p><h3 id="快速内存分配"><a href="#快速内存分配" class="headerlink" title="快速内存分配"></a>快速内存分配</h3><p>对象内存分配器的操作需要和垃圾收集器紧密配合。垃圾收集器必须记录它回收的空间，而分配器在重用堆空间之前需要找到可以满足其分配需求的空闲空间。垃圾收集器以复制方式回收HotSpot VM新生代，其好处在于回收以后Eden总为空，在Eden中运用被称为指计碰撞(Bump-the-Pointer)的技术就可以有效地分配空间。这种技术追踪最后一个分配的对象（常称为top),当有新的分配请求时，分配器只需要检查top和eden未端之间的空间是否能容纳。如果能容纳，top则跳到新近分配对象的未端。</p><p><font color="DeepPink"><strong>重要的Java应用大多是多线程的，因此内存分配的操作需要考虑多线程安全。如果只用全局锁，在Eden中的分配操作就会成为瓶颈而降低性能。HotSpot VM没有采用这种方式，而是以一种称为线程本地分配缓冲区（thread-Local Allocation Buffer,TLAB)的技术，为每个线程设置各自的缓冲区(即Eden的一小块），以此改善多线程分配的吞吐量。因为每个TLAB都只有一个线程从中分配对象，所以可以使用指针碰撞技术快速分配而不需要任何锁。然而当线程的TLAB填满需要获取新的空间时（不常见），它就需要采用多线程安全的方式了。大部分时候，HotSpot VM的new Object()操作只需要大约十条指令。垃圾收集器清空Eden区域，然后就可以支持快速内存分配了。</strong></font></p><h2 id="HotSpot-VM-JIT编译器"><a href="#HotSpot-VM-JIT编译器" class="headerlink" title="HotSpot VM JIT编译器"></a>HotSpot VM JIT编译器</h2><p>经典的寄存器分配策略是图着色算法，通常可以使机器寄存器的使用率达到最高，而且多余的值很少会卸载到栈中。图表示的是同时有哪些变量在使用．以及哪些寄存器可以存放这些变量。如果同时存活的变量数超过了可用的寄存器数，重要性最低的变量将被移到栈中，使得其他变量可以使用寄存器。指派某个变量给寄存器通常需要来回几次构建图和着色。这也导致了它的不足，图着色算法花费的时间、数据结构所需的空间都比较昂贵。</p><h1 id="JVM性能监控"><a href="#JVM性能监控" class="headerlink" title="JVM性能监控"></a>JVM性能监控</h1><h2 id="垃圾收集"><a href="#垃圾收集" class="headerlink" title="垃圾收集"></a>垃圾收集</h2><h3 id="重要的垃圾收集数据"><a href="#重要的垃圾收集数据" class="headerlink" title="重要的垃圾收集数据"></a>重要的垃圾收集数据</h3><p>重要的垃圾收集数据包括：</p><ul><li>当前使用的垃圾收集器</li><li>Java堆的大小</li><li>新生代和老年代的大小</li><li>永久代的大小</li><li>Minor GC的持续时间</li><li>Minor GC的频率</li><li>Minor GC的空间回收量</li><li>Full GC的持续时间</li><li>Full GC的频率</li><li>每个并发垃圾收集周期内的空间回收量</li><li>垃圾收集前后Java堆的占用量</li><li>垃圾收集前后新生代和老年代的占用量</li><li>垃圾收集前后永久代的占用量</li><li>是否老年代或永久代的占用触发了 Full GC</li><li>应用是否显式调用了 System.gc()</li></ul><h3 id="垃圾回收报告"><a href="#垃圾回收报告" class="headerlink" title="垃圾回收报告"></a>垃圾回收报告</h3><h3 id="JIT编译器"><a href="#JIT编译器" class="headerlink" title="JIT编译器"></a>JIT编译器</h3><p>可以使用-XX:+PrintCompilation监控HotSpot JIT编译器。-XX:+PrintCompilation为每次编译生成一行日志。</p><p>日志样例如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">7java. lang String: indexOf (151 bytes)</span><br><span class="line">8% !sun. awt. image. PNGImageDecoder: produceImage a 960 (1920 bytes)</span><br><span class="line">9  !sun awt. image. PNGImageDecoder: produceImage (1920 bytes)</span><br><span class="line">10java. lang. AbstractStringBuilder: append(40 bytes)</span><br><span class="line">11njava. lang System: arraycopy (static)</span><br><span class="line">12sjava util. Hashtable: get (69 bytes)</span><br><span class="line">13bjava util. HashMap: indexFor (6 bytes)</span><br><span class="line">14made zombie java. awt. geom. Path2DSIterator: isDone (20 bytes)</span><br></pre></td></tr></table></figure><h1 id="JVM性能调优入门"><a href="#JVM性能调优入门" class="headerlink" title="JVM性能调优入门"></a>JVM性能调优入门</h1><h2 id="应用程序的系统需求"><a href="#应用程序的系统需求" class="headerlink" title="应用程序的系统需求"></a>应用程序的系统需求</h2><h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p><font color="DeepPink"><strong>吞吐量是对单位时间内处理工作量的度量</strong></font>。设计吞吐量需求时,我们一般不考虑它对延迟或者响应时间的影响。通常情况下,增加吞吐量的代价是延迟的增加或内存使用的增加。</p><p>吞吐量性能需求的一个典型例子是,应用程序每秒需要完成2500次事务。</p><h3 id="延迟或响应性"><a href="#延迟或响应性" class="headerlink" title="延迟或响应性"></a>延迟或响应性</h3><p><font color="DeepPink"><strong>延迟,或者响应性,是对应用程序收到指令开始工作直到完成该工作所消耗时间的度量。</strong></font></p><p>定义延迟或响应性需求时并不考虑程序的吞吐量。通常情况下,提高响应性或缩小延迟的代价是更低的吞吐量、或者更多的内存消耗(或者二者同时发生)</p><p>延迟或响应需求的一个典型例子是,应用程序应该在60毫秒内完成交易请求的处理工作。</p><h3 id="内存占用"><a href="#内存占用" class="headerlink" title="内存占用"></a>内存占用</h3><p><font color="DeepPink"><strong>内存占用指在同等程度的吞吐量、延迟、可用性和可管理性前提下,运行应用程序所需的内存大小。</strong></font>内存占用通常以运行应用程序需要的Java堆大小或者运行应用程序需要的总内存大小来表述。一般情况下,通过增大Java堆的方式增加可用内存能够提高吞吐量、降低延迟或者兼顾二者。应用程序的可用内存减少时,吞吐量和延迟通常都会受到影响。应用程序的内存占用限制了固定内存的机器上能同时运行的应用程序实例数。</p><p>内存占用需求的一个典型例子是,应用程序需要在拥有8GB内存的系统上以单个实例方式运行或者在24GB内存的系统上以3个应用程序实例方式运行。</p><h2 id="性能收集调优基础"><a href="#性能收集调优基础" class="headerlink" title="性能收集调优基础"></a>性能收集调优基础</h2><h3 id="性能属性"><a href="#性能属性" class="headerlink" title="性能属性"></a>性能属性</h3><ul><li>吞吐量:是评价垃圾收集器能力的重要指标之一,指不考虑垃圾收集引起的停顿时间或内存消耗,垃圾收集器能支撑应用程序达到的最高性能指标。</li><li>延迟:也是评价垃圾收集器能力的重要指标,度量标准是缩短由于垃圾收集引起的停顿时间或完全消除因垃圾收集所引起的停顿,避免应用程序运行时发生抖动。</li><li>内存占用:垃圾收集器流畅运行所需要的内存数量。</li></ul><p><font color="DeepPink"><strong>这其中任何一个属性性能的提高几乎都是以另一个或两个属性性能的损失作代价的。换句话说,某一个属性上的性能提高总会牺牲另一个或两个属性。然而,对大多数的应用而言,极少出现这三个属性的重要程度都同等的情况。很多时候,某一个或两个属性的性能要比另一个重要。</strong></font></p><p>我们需要了解对应用程序而言哪些系统需求是最重要的,也需要知道对应用程序而言这三个性能属性哪些是最重要的。确定哪些属性最重要,并将其映射到应用程序的系统需求,对应用程序而言非常重要。</p><h3 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h3><p>谈到JVM垃圾收集器调优也有三个需要理解的基本原则。</p><ul><li>每次Minor GC都尽可能多地收集垃圾对象。我们把这称作“<font color="DeepPink"><strong>Minor GC回收原则</strong></font>”。遵守这原则可以减少应用程序发生 Full GC的频率。Full GC的持续时间总是最长的,是应用程序无法达到其延迟或吞吐量要求的罪魁祸首。</li><li>处理吞吐量和延迟问题时,垃圾处理器能使用的内存越大,即Java堆空间越大,垃圾收集的效果越好,应用程序运行也越流畅。我们称之为“<font color="DeepPink"><strong>GC内存最大化原则</strong></font>”。</li><li>在这三个性能属性(吞吐量、延迟、内存占用)中任意选择两个进行JVM垃圾收集器调优。我们称之为“<font color="DeepPink"><strong>GC调优的3选2原则</strong></font>”。</li></ul><p>调优JVM垃圾收集的过程中谨记这三条原则能帮助你更轻松地调优垃圾收集,达到应用程序的性能要求。</p><h2 id="确定内存占用"><a href="#确定内存占用" class="headerlink" title="确定内存占用"></a>确定内存占用</h2><h3 id="HotSpot-VM堆布局"><a href="#HotSpot-VM堆布局" class="headerlink" title="HotSpot VM堆布局"></a>HotSpot VM堆布局</h3><p>通过-Xmn可以很方便地设定新生代空间的初始值和最大值。有一点需要特别注意,如果-Xms和-Xmx并没有设定为同一个值,使用-Xmn选项时,Java堆的大小变化不会影响新生代空间,即新生代空间的大小总保持恒定,而不是随着Java堆大小的扩展或缩减做相应的调整。因此,请注意,<font color="DeepPink"><strong>只有在-Xms与-Xmx设定为同一值时才使用-Xmn选项。</strong></font></p><p>老年代空间的大小会根据新生代的大小隐式设定。老年代空间的初始值为-Xmx的值减去XX:    NewSize的值。老年代空间的最小值为-Xmx的值减去-XX:MaxNewSize的值。如果-Xms与Xmx设置为同一值,同时使用了-Xmn,或者-XX:NewSize与-XX:MaxNewsize一样,则老年代的大小为-Xmx(或-Xms)的值减去-Xmn。</p><p>实际上,当HotSpot VM发现当前可用空间不足以容纳下一次Minor GC提升的对象时就会进行Full GC。与因空间问题导致的Minor GC过程中的对象提升失败比较起来,这种方式的代价要小得多。从失败的对象提升中恢复是一个很昂贵的操作。永久代没有足够的空间存储新的VM或类元数据时也会发生Full GC。</p><p>如果Full GC缘于老年代空间已满,即使永久代空间并没有用尽,老年代和永久代都会进行垃圾收集。同样,如果Full GC由永久代空间用尽引起,老年代和永久代也都会进行垃圾收集,无论老年代是否还有空闲空间。开启-XX:+UseParallelGC或-XX:+UseParallelOldGC时,如果关闭-XX:-ScavengeBeforeFullGC, HotSpot VM在Full GC之前不会进行Minor GC,但Full GC过程中依然会收集新生代;如果开启-XX:+ScavengeBeforeFullGC, HotSpot VM在Full GC前会先做一次Minor GC,分担一部分Full GC原本要做的工作。</p><h3 id="堆大小调优着眼点"><a href="#堆大小调优着眼点" class="headerlink" title="堆大小调优着眼点"></a>堆大小调优着眼点</h3><p>如果你使用的HotSpot VM不接受-XX:+UseParallelOldGC选项,可以使用-XX:+UseParallelGC代替。如果你很清楚Java应用程序要使用多大的Java堆空间,可以将Java堆大小作为调优的入手点,使用-Xmx和-Xms设置Java堆的大小。如果你不清楚Java应用程序到底需要使用多大的Java堆,可以利用HotSpot VM自动选取Java堆的大小。启动Java应用程序时不指定-Xmx或-Xms的值, HotSpot VM会自动设定Java堆大小的初始值。换句话说,这是一个起始点。随着调优过程,后面会逐渐调整Java堆的大小。</p><p>通过HotSpot命令行选项-XX:+PrintCommandLineFlags还可以查看堆的初始值及最大值。-XX:+PrintCommandlineFlags选项可以输出HotSpot VM初始化时使用-XX:InitialHeapSize=&lt;n&gt; -XX:MaxHeapSize=&lt;m&gt;指定的堆的初始值及最大值,其中&lt;n&gt;是以字节为单位的初始Java堆大小,&lt;m&gt;是以字节为单位的堆的最大值。</p><h3 id="计算活跃数据大小"><a href="#计算活跃数据大小" class="headerlink" title="计算活跃数据大小"></a>计算活跃数据大小</h3><p><font color="DeepPink"><strong>活跃数据大小是应用程序运行于稳定态时,长期存活的对象在Java堆中占用的空间大小。换句话说,活跃数据大小是应用程序运行于稳定态,Full GC之后Java堆中老年代和永久代占用的空间大小。</strong></font></p><p>Java应用的活跃数据大小可以通过GC日志收集。活跃数据大小包括下面的内容:</p><ul><li>应用程序运行于稳定态时,老年代占用的Java堆大小;</li><li>应用程序运行于稳定态时,永久代占用的Java堆大小。</li></ul><p>除了活跃数据大小,稳定态的Full GC也会对延迟带来严重影响。</p><p>为了更好地度量应用程序的活跃数据大小,最好在多次Full GC之后再查看Java堆的占用情况。另外,需要确保Full GC发生时,应用程序正处于稳定态。</p><p>如果应用程序没有发生Full GC或者不经常发生Full GC,你可以使用JVM监控工具Visual VM或JConsole人工触发Full GC。你也可以使用HotSpot JDK发行版中提供的jmap命令,通过命令行强制进行Full GC。为了实现这个目的,jmap需要使用- histo:live命令行选项及JVM进程号。JVM进程号可以通过JDK的js命令获得。例如,Java应用程序的JM进程号是348,使用jmap触发Full GC的命令行如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -histo: live 348</span><br></pre></td></tr></table></figure><p>jmap命令触发 Full GC的同时也生成一份包含对象分配信息的堆分析文件。为了专注本步操作,你可以忽略生成的堆分析文件。</p><h3 id="初始化堆大小配置"><a href="#初始化堆大小配置" class="headerlink" title="初始化堆大小配置"></a>初始化堆大小配置</h3><p>推荐的做法是基于最差延迟进行估算。</p><table><thead><tr><th>空间</th><th>命令行选项</th><th>占用倍数</th></tr></thead><tbody><tr><td>Java堆</td><td>-Xms和-Xmx</td><td>3-4倍Full GC后的老年代空间占用量</td></tr><tr><td>永久代</td><td>-XX:Permsize<br>-XX:MaxPermSize</td><td>1.2-1.5倍Full GC后的永久代空间占用量</td></tr><tr><td>新生代</td><td>-Xmn</td><td>1~1.5倍 Full GC后的老年代空间占用量</td></tr><tr><td>老年代</td><td>Java堆大小减新生代大小</td><td>2-3倍Full GC后的老年代空间占用量</td></tr></tbody></table><h2 id="调优延迟-响应性"><a href="#调优延迟-响应性" class="headerlink" title="调优延迟/响应性"></a>调优延迟/响应性</h2><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><p>这一步调优有多个输入,都源于应用程序的系统性需求。</p><ul><li>应用程序可接受的平均停滞时间。平均停滞时间将与测量出的Minor GC持续时间进行比较。</li><li>可接受的Minor GC(会导致延迟)频率。 Minor GC的频率将与可容忍的值进行比较。对应用程序干系人而言,GC持续的时间往往比GC发生的频率更重要。</li><li>应用程序干系人可接受的应用程序的最大停顿时间。最大停顿时间将与最差情况下Full GC的持续时间进行比较。</li><li>应用程序干系人可接受的最大停顿发生的频率。最大停顿发生的频率基本上就是Full GC的频率。同样,对于大多数应用程序干系人而言,相对于GC的频率,他们更关心GC持续的平均停顿时间和最大停顿时间。</li></ul><h3 id="优化新生代的大小"><a href="#优化新生代的大小" class="headerlink" title="优化新生代的大小"></a>优化新生代的大小</h3><p>调整新生代空间时,需要谨记下面几个准则：</p><ul><li><font color="DeepPink"><strong>老年代空间大小不应该小于活跃数据大小的1.5倍。</strong></font></li><li><font color="DeepPink"><strong>新生代空间至少应为Java堆大小的10%</strong></font>,通过Xmx和-Xms可以设定该值。新生代过小可能适得其反,会导致频繁的Minor GC。</li><li>增大Java堆大小时,需要注意不要超过JVM可用的物理内存数。堆占用过多内存将导致底层系统交换到虚拟内存,反而会造成垃圾收集器和应用程序的性能低下。</li></ul><h3 id="监控晋升阈值"><a href="#监控晋升阈值" class="headerlink" title="监控晋升阈值"></a>监控晋升阈值</h3><p>最大晋升阈值可以通过HotSpot VM的命令行选项-XX: MaxTenuringThreshold=&lt;n&gt;设置。使用HotSpot VM的命令行选项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX: +PrintTenuringDistribution</span><br></pre></td></tr></table></figure><p>可以监控晋升的分布或者对象年龄分布,并以此为依据确定最优的最大晋升阈值值。</p><p>通过-XX:+PrintTenuringDistribution命令行选项可以观察Survivor空间中的对象是如何老化的。在-XX:+PrintTenuringDistribution生成的输出中,我们需要关注的是随着对象年龄的增加,各对象年龄上字节数减少的情况,以及 HotSpot VM计算出的晋升阈值是否等于或接近设置的最大晋升阈值。</p><p>XX:+PrintTenuringDistribution会输出每次Minor GC时晋升分布的情况。它也可以和其他的垃圾收集命令行选项,例如-XX:+PrintGCDateStamps、-XX:+PrintGcTime Stamps或-XX:+PrintgCDetails配合使用。对Survivor空间的有效对象老化进行微调时,应该使用选项XX:+PrintTenuringDistribution在垃圾收集日志中包含晋升分布的统计信息。同样,如果需要在生产环境中判断一个应用程序事件是否源于一次Stop-The-World压缩式垃圾收集,往往也需要获取晋升分布的日志信息,使用该选项是非常有帮助的。</p><blockquote><p><font color="DeepPink"><strong>通常情况下,观察到新的晋升阈值持续小于最大晋升阈值,或者观察到 Survivor空间大小小于总的存活对象大小都表明 Survivor空间过小。</strong></font></p></blockquote><h3 id="调整-Survivor空间的容量"><a href="#调整-Survivor空间的容量" class="headerlink" title="调整 Survivor空间的容量"></a>调整 Survivor空间的容量</h3><p>调整Survivor空间容量一个应该谨记于心的重要原则:<font color="DeepPink"><strong>调整Survivor空间容量时,如果新生代空间大小不变,增大Survivor空间会减少Eden空间;而减少Eden空间会增加Minor GC的频率。</strong></font>因此,为了同时满足应用程序Minor GC频率的要求,就需要增大当前新生代空间的大小;即增大Survivor空间大小时,Eden空间的大小应该保持不变。换句话说,每当 Survivor空间增加时,新生代空间都应该增大。如果可以增大Minor GC的频率,你可以选择用一部分Eden空间来增大Survivor空间,或者直接增大新生代空间大小。如果内存足够,相对于减少Eden空间.增加新生代大小通常是更好的选择。保持Eden空间大小恒定, Minor GC的频率就不会由于Survivor空间增大而发生变化。</p><blockquote><p>如果你观察到垃圾收集中晋升分布极少出现对象年龄为15的情况,并且也没有发生Survivor空间溢出,那么应该设置最大晋升阈值为其默认值15。这种场景下,对象都不是长期存活对象,在年龄很小的时候就被回收了,根本不会生存到最大晋升年限的年龄15。</p></blockquote><h4 id="调整目标Survivor空间占用"><a href="#调整目标Survivor空间占用" class="headerlink" title="调整目标Survivor空间占用"></a>调整目标Survivor空间占用</h4><p>目标Survivor空间占用是HotSpot VM尝试在Minor GC之后仍然维持的Survivor空间占用。通过 HotSpot VM的命令行选项-XX:TargetSurvivorRatio=&lt;percent&gt;可以对该值进行调整。通过命令行选项指定的参数实际上是Survivor空间占用的百分比而不是一个比率。它的默认值是50。</p><p>HotSpot VM研发团队对不同类型的应用程序进行了大量的负荷测试,结果表明50%的目标Survivor空间占用能适应大多数的应用程序,这是因为它能应对Minor GC时存活对象的急速增加。</p><p>极少发生需要对目标Survivor空间占用进行调优的情况。但是,如果应用程序有一个相对稳定的对象分配速率,可以考虑提高目标Survivor空间占用到80~90。这样可以减少用于老化对象的Survivor空间的数量。将-XX:TargetSurvivorRatio=&lt;percent&gt;设置得大于默认值会带来的问题是不能很好的适应迅速上涨的对象分配速率,导致提升对象的时机比预期更早。使用CMS时,如果对象提升过快会导致老年代占用增大,由于提升了一些非长期存活的对象,这些对象在将来的并发垃圾收集周期中一定会被回收,导致出现内存碎片的概率较高。碎片是我们要尽量避免的,因为它最终会导致Stop-The-World压缩式垃圾收集。</p><p><font color="DeepPink"><strong>成功的CMS收集器调优要能以对象从新生代提升到老年代的同等速度对老年代中的对象进行垃圾收集。达不到这个标准则称之为“失速”(Lost the Race)失速的结果就会发生Stop-The-World压缩式垃圾收集。避免失速的关键是要结合足够大的老年代空间和足够快地初始化CMS垃圾收集周期,让它以比提升速率更快的速度回收空间。</strong></font></p><p><font color="DeepPink"><strong>CMS周期的初始化基于老年代空间的占用情况。如果CMS周期开始得太晚,就会发生失速。如果它无法以足够快的速度回收对象,就无法避免老年代空间用尽。但是CMS周期开始得过早又会引起无用的消耗,影响应用程序的吞吐量。通常,早启动CMS周期要比晚启动CMS好,因为启动太晚的结果比启动过早的结果要恶劣得多。</strong></font></p><p>如果GC日志中发现concurrent mode failures字样,可以通过下面的命令行选项通知HotSpot在更早的时间启动CMS垃圾收集周期。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX: CMSInitiatingOccupancyFraction=&lt;percent&gt;</span><br></pre></td></tr></table></figure><p>设定的值是CMS垃圾收集周期在老年代空间占用达到多少百分比时启动。例如,如果你希望CMS周期在老年代空间占用达到65%时开始,可以设置-XX:CMSInitiatingOccupancyFraction=65。</p><p>另一个可以与-XX:CMSInitiatingOccupancyFraction=&lt;percent&gt;一起使用另一个Hotspot命令行选项是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UseCMSInitiatingOccupancyOnly</span><br></pre></td></tr></table></figure><p>-XX:+UseCMSInitiatingOccupancyOnly告知HotSpot VM总是使用-XX:CMSInitiatingOccupancyFraction设定的值作为启动CMS周期的老年代空间占用阈值。不使用-XX:+UseRs InitiatingOccupancyOnly, HotSpot VM仅在启动的第一个CMS周期里使用-XX:CMSInitiatingOccupancyFraction设定的值作为占用比率,之后的周期中又转向自适应地启动CMS周期,即第一次CMS周期之后就不再使用-XX:CMSInitiatingoccupancy Fraction设定的值。</p><blockquote><p>过选项设置何时启动CMS周期时,最好同时使用-XX:CMSInitiatingOccupancyFraction=&lt;percent&gt;和-XX:+UseCMSInitiatingOccupancyOnly</p></blockquote><p><font color="DeepPink"><strong>选项-XX:CMSInitiatingOccupancyFraction设定的空间占用值应该大于老年代占用空间和活跃数据大小之比。应用程序的活跃数据大小就是一次Full GC之后堆所占用的空间大小。如果使用-XX:CMSInitiatingOccupancyFraction设置的值小于活跃数据的占用百分比,CMS收集器一直运行陷入死循环。因此-XX:CMSInitiatingoccupancyFraction设置的一个通用原则是老年代占用百分比应该至少应该是活跃数据大小的1.5倍。</strong></font></p><p><font color="DeepPink"><strong>何时(提前或推迟)启动CMS周期取决于对象从新生代提升至老年代的速率,即老年代空间的增长率。如果老年代空间消耗得比较慢,可以在稍晩的时候启动CMS周期。如果老年代空间消耗迅速,你应该在较早的时候启动CMS周期,但是也不应低于活跃数据的占用的比率。</strong></font>不应该将启动CMS周期的值设置得比活跃数据的大小低,解决这个问题更好的方法是增大老年代空间的大小。</p><h3 id="显式的垃圾收集"><a href="#显式的垃圾收集" class="headerlink" title="显式的垃圾收集"></a>显式的垃圾收集</h3><p>使用CMS时,如果你观察到由显式调用System.gc()触发的Full GC,有2种处理的方法。</p><p>1、可以使用如下的 HotSpot VM命令行选项,指定 HotSpot VM以CMS垃圾收集周期的方式执行</p><p>-XX:+ExplicitGCInvokesConcurrent</p><p>或者</p><p>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses</p><p>前者需要Java6及以上版本。后者需要Java6 Update4及以上版本。如果你的JDK版本支持,最好使用-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses选项。</p><p>2、也可以使用下面的命令行通知HotSpot VM忽略显式的 System.gc()调用</p><p>-XX:+DisableExplicitGC</p><p>要留意的是,使用这个命令行选项也会导致其他 HotSpot VM的垃圾收集器忽略显式的System.gc()调用。</p><p>禁用显式的垃圾收集时应该慎重,它可能会对应用程序的性能造成较大影响。还有可能出现这样的场景,你需要及时对对象引用做处理,但与之对应的垃圾收集却跟不上其节奏。使用Java RMI的应用程序尤其容易碰到这种问题。我们建议除非有非常明确的理由,否则不要轻易地禁用显式的垃圾收集。与此同时,也建议只在有明确理由的情况下才在应用程序中使用System.gc()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2010-12-16T23:04:39.452-0600:[Full GC(System)</span><br><span class="line">CMS:418061K-&gt;428608K(16384K),0.2539726 secs</span><br><span class="line">418749K-&gt;4288608K(31168K),</span><br><span class="line">[CMS Perm:32428K-&gt;32428K(65536K)],</span><br><span class="line">0.2540393 secs]</span><br><span class="line">[Times: user=0. 12 sys=0. 01, real=0. 25 secs]</span><br></pre></td></tr></table></figure><p>请留意Full GC之后的(System)标签,它表明System.gc()触发了本次 Full GC。如果在垃圾收集日志中发现了显式的Full GC,你需要先判断为什么它会发生,之后再决定是否要禁用,是否要把该调用从代码中移除,或者是否有必要指定一个条件来触发CMS并发垃圾收集周期。</p><h2 id="应用程序吞吐量调优"><a href="#应用程序吞吐量调优" class="headerlink" title="应用程序吞吐量调优"></a>应用程序吞吐量调优</h2><blockquote><p>一个通用原则是使用 Throughput收集器时,垃圾收集的开销应该小于5%。如果可以将垃圾收集的开销减少到1%甚至更少,那基本上就已经到了极限,进一步优化花费的代价很大。</p></blockquote><h3 id="调优并行垃圾收集线程"><a href="#调优并行垃圾收集线程" class="headerlink" title="调优并行垃圾收集线程"></a>调优并行垃圾收集线程</h3><p>并行垃圾收集器使用的线程数也应该依据系统上运行的应用程序数以及底层的硬件平台进行相应的调优。多个应用程序运行于同一个系统上时,建议通过命令行选项-XX:ParallelGCThreads=&lt;n&gt;将并行垃圾收集的线程数设置为小于其默认值。</p><p>否则,由于大量的垃圾收集线程同时运行,其他应用程序的性能将受到严重影响。截至Java6 Update23,默认情况下并行垃圾收集的线程数等于Java API Runtime.availableProcessors()的返回值(如果该返回值小于等于8),否则其等于8+(Runtime.availableProcessors()-8)*5/8。<font color="DeepPink">多个应用程序运行于同一系统上时设置并行垃圾收集线程的一个通用原则是用虚拟处理器的数目 (Runtime.availableProcessors()的返回值)除以该系统上运行的应用程序数。</font>这里我们假设这些应用程序的负荷及堆大小的情况相差不大。如果应用程序的负荷及Java堆大小差异很大,那么为每个Java应用设置不同权重,并据此设置并行垃圾线程数是一个比较好的方法。</p><h3 id="在NUMA系统上部署"><a href="#在NUMA系统上部署" class="headerlink" title="在NUMA系统上部署"></a>在NUMA系统上部署</h3><p>如果应用程序需要在NUMA(非一致性内存架构)系统上部署,还有一个可以与Throughput收集器一起使用的HotSpot命令行选项是:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UseNUMA</span><br></pre></td></tr></table></figure><p>该命令行选项根据CPU与内存位置的关系在分配线程运行的本地内存中分配对象。这里依据的假设是分配对象的线程是近期最有可能访问该对象的线程。相对于远程的内存而言,在同一线程的本地内存中分配对象用更短的时间即能访问该对象的内容。</p><p>只有当JVM的部署跨CPU、不同CPU访问内存的拓扑有所不同,导致访问时间也有所差别的环境下才选择使用-XX:+UseNUMA选项。例如,虽然JVM部署到NUMA系统的一个处理器集上,但是这个处理器集并不存在跨CPU访问内存的拓扑,没有访问时间的差别,那么就不应该使用-XX:+UseNUMA选项。</p><blockquote><p>简而言之,支持NUMA的VM会根据NUMA节点划分堆,线程创建新的对象时,只会在该线程运行所在核的NUMA节点上分配对象,后续该线程如果需要使用这个对象,就直接从本地内存中访问。通常情况下,如果没有使用命令,臂如RHEL下使用numactl,设置CPU的亲和性(Affinity),默认就跨多个内存节点,满足-XX:+UseNUMA的使用条件。</p></blockquote><blockquote><p>注：Throughput garbage collector,实际指的是Parallel收集器</p></blockquote><h2 id="其它性能命令行选项"><a href="#其它性能命令行选项" class="headerlink" title="其它性能命令行选项"></a>其它性能命令行选项</h2><h3 id="大页面支持"><a href="#大页面支持" class="headerlink" title="大页面支持"></a>大页面支持</h3><p>计算机系统的内存被划分成称为“页”的固定大小的块。程序访问内存的过程中会将虚拟内存地址转换成物理内存地址。虚拟地址到物理地址的转换是通过表完成的。为了减少每次内存访问时访问页表的代价,通常的做法是使用一块快速缓存,对虚拟地址到物理地址的转换进行缓存。这块缓存被称为转译快查缓存(TLB)。</p><p>使用TLB完成从虚拟地址到物理地址的映射比遍历整个页表的方式要快得多。TLB通常只能容纳固定数量的条目。TLB中的一条记录就是按页面大小统计的一块内存地址区间的映射。因此系统的页面越大,每个条目能映射的内存地址区间越大,每个TLB能管理的空间也越大。TLB代表的地址区间越大,地址转译请求在TLB中失效的可能性就越小。当一个地址转译请求无法在TLB中找到匹配项时,我们称之发生了“TLB失效”。TLB失效事件发生时常常需要遍历内存中的页表,査找虚拟地址到物理地址的映射。与在TLB中查找地址映射比较起来,遍历页表是一项非常昂贵的操作。由此可见,<font color="DeepPink"><strong>使用大页面的好处是其减小了TLB失效的几率。</strong></font></p><p>HotSpot虚拟机在Oracle solaris(这之后称为Solaris)、 Linux和 Windows上都支持大页面。页面大小还可能随着处理器的不同有所不同。另外,为了使用大页面还可能需要对操作系统进行配置。</p><h1 id="Java-应用的基准测试"><a href="#Java-应用的基准测试" class="headerlink" title="Java 应用的基准测试"></a>Java 应用的基准测试</h1><h2 id="基准测试所面临的挑战"><a href="#基准测试所面临的挑战" class="headerlink" title="基准测试所面临的挑战"></a>基准测试所面临的挑战</h2><h3 id="基准测试的预热阶段"><a href="#基准测试的预热阶段" class="headerlink" title="基准测试的预热阶段"></a>基准测试的预热阶段</h3><p>执行基准测试时使用HotSpot VM命令行选项-XX:+PrintCompilation是一个好习惯,使用该命令行选项的输岀可以判断JIT编译器何时完成了预热阶段,确保在 HotSpot编译器到达稳定态后,即已经完成它的优化工作(生成了适合基准测试的优化机器码)后再开始基准数据采样。-XX:+PrintCompilation选项通知VM为每个它优化或逆优化的函数输出一条日志。下面是在一段微基准测试中使用-XX:+PrintCompilation选项输出的日志片段:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">11java.util.Random:: nextInt (60 bytes)</span><br><span class="line">12java.util.Random: next (47 bytes</span><br><span class="line">13java.util.concurrent atomic Atomi CLong: get (5 bytes)</span><br><span class="line">14java.util.HashSet: contains (9 bytes)</span><br><span class="line">15java.util.HashMap: transfer (83 bytes)</span><br><span class="line">16java.util.Arrays SArrayList: set (16 bytes)</span><br><span class="line">17java.util.Arrays SArrayList: set (16 bytes)</span><br><span class="line">18java.util.Collections: swap (25 bytes)</span><br><span class="line">19java.util.Arrays SArrayList: get (7 bytes)</span><br><span class="line">20java.lang.Long: &lt;init&gt; (10 bytes)</span><br><span class="line">21java.lang.Integer: longvalue (6 bytes)</span><br><span class="line">22java.lang.Long: valueOf (36 bytes)</span><br><span class="line">23java.lang.Integer: stringSize (21 bytes)</span><br><span class="line">24java.lang.Integer: getChars (131 bytes)</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>观察日志中已经不再有-XX:+PrintCompilation输出的信息(表明JIT编译器的优化工作已经完成)之后才正式开始采样数据。此外,基准测试还应该在不使用-XX:+PrintCompilation选项的情况下运行几次,比较其性能与使用-XX:+ PrintCompilation选项的结果是否一致。如果二者不一致,可能在创建基准测试或微基准测试时受到了其他因素的影响。</strong></font></p><blockquote><p>微基准测试中有一个惯例,即在开始采样间隔开始计时之前,先调用几次 System.gc()。多次调用 System.gc()的目的是希望通过Java对象的终结方法释放内存,而这往往需要进行多次垃圾收集才能完成。此外,当对象不可达,导致终结方法一直处于等待队列,或者部分执行队列中,调用System.runFinalization()接口可以请求JVM执行其fina1ize()方法,完成垃圾收集。</p></blockquote><h3 id="使用Java-Time接口"><a href="#使用Java-Time接口" class="headerlink" title="使用Java Time接口"></a>使用Java Time接口</h3><p>引入新的System.nanoTime()接口之前,大多数的Java基准测试或微基准测试都使用System.currentTimeMillis()接口获取采样间隔的开始和终止时间,根据终止时间与开始时间的间隔得到运行关注的代码所消耗的时间使用Java的System.currentTimeMillis()和System.nanoTime()接口都有一定程度的精度问题。虽然 System.currentTimeMillis()的返回值是以亳秒计的当前时间,但毫秒级的精度却取决于操作系统。Java API Specification中对于System.currentTimeMillis()有明确的陈述:虽然该接口的返回值是毫秒,但返回值的粒度取决于底层的操作系统。这一规范为操作系统使用自身的亳秒级系统接口提供了方便,但是可能存在这样的情况,尽管使用的是毫秒计数器,但是更新间隔却过大,譬如每30毫秒更新一次。这个规范有意地规定得比较宽松,试图让Java API尽可能地支持更多的操作系统,其中就包含一些无法提供毫秒级时钟精度的操作系统。使用Java API System. nanoTime()也有类似的问题。<font color="DeepPink"><strong>虽然该方法提供了纳秒级的精度,但接口并不保证提供纳秒级的精度: System.nanoTime()的 Java API Specification中明确提到不保证System.nanoTime()返回值的更新频度。</strong></font></p><p>因此,使用System.currentTimeMillis()计算时间消耗时,采样的时间间隔应该足够大,尽量减少System, currentTimeMillis()精度带来的影响。也即是说,采样的时间间隔需要比毫秒大(譬如几秒、或者尽可能几分钟)同样的原则也适用于 System.nanoTime()。根据Java API Specification,System.nanoTime()依赖底层的操作系统,返回系统中可用的最精确时钟的当前值。然而,最精确的可用系统时钟可能也没有纳秒级的精度。进行基准测试时,建议首先摸清楚这两个Java API在对应平台或操作系统上的粒度或精度。如果你不是很清楚,但手里有源代码,可以通过查看这两个API的底层实现,了解其粒度和精度。如果你使用System.currentTimeMillis()或System.nanoTime()。而且采样时间间隔很短(相对于毫秒或纳秒来讲),要特别注意这个问题。</p><blockquote><p>微基准测试时,使用System.nanoTime()获取启动和终止时间计算采样间隔是一种好方法。接着计算终止与启动的时间差就可以得到微基准测试的耗时,以及每次操作选代所消耗的纳秒数或者每秒所发生的迭代次数。<font color="DeepPink"><strong>最重要的是要确保微基准测试运行的时间要足够长,确保应用程序运行已达稳定态且采样的时间也足够长。</strong></font></p></blockquote><h3 id="剔除无效代码"><a href="#剔除无效代码" class="headerlink" title="剔除无效代码"></a>剔除无效代码</h3><p>为了避免微基准测试中的代码被定性为无效代码,引发过度简化的问题,可以采用下面的编程实践：</p><ul><li><font color="DeepPink"><strong>让该方法变得必不可少</strong></font></li><li><font color="DeepPink"><strong>在釆样阶段结束时直接输出计算的结果,或者保存该计算结果,在采样阶段结束后输出该值</strong></font></li></ul><p>要使计算有意义,就要向被测方法传入参数,并从被测方法返回计算结果。此外,在基准测试采样阶段内或在多个不同的基准测试采样阶段间变换迭代次数也是一个不错的方法,然后比较每毫秒内发生的迭代次数,判断迭代次数是否保持恒定,同时使用-XX:+PrintCompilation选项追踪记录JIT编译器的状态。</p><h3 id="内联"><a href="#内联" class="headerlink" title="内联"></a>内联</h3><p>HotSpot VM的Client和Server JIT编译器都能对方法进行内联。这意味着调用过程中,目标方法会被展开到调用方法中。这个过程是由JIT编译器完成的,JIT编译器通过降低方法调用的开销提升执行性能。此外,内联的代码可能提供更多的优化机会,整合后的代码可能更简单,或者消除了无效调用,而这些在不内联的情况下是无法实现的。内联在微基准测试中还可能实现让人眼前一亮的性能提升。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-XX:+PrintInlining</span><br><span class="line">-XX:MaxInlineSize=N</span><br></pre></td></tr></table></figure><h3 id="逆优化"><a href="#逆优化" class="headerlink" title="逆优化"></a>逆优化</h3><p>JIT编译器以其执行优化的能力而著称于世。但是,某些场景下JIT编译器也会进行“逆优化”。譬如,Java应用一旦开始运行,方法调用变得频繁;JIT编译器就可以根据从程序过程中了解到的信息做出优化决策。有些时候,优化的决策在后续可能被证明是错误的。当JIT编译器发现之前的优化作了错误的优化决策时就会进行逆优化。很多时候,在JIT编译器逆优化不久之后(一旦达到一定的执行次数阈值)就会接着再次进行优化。忽视发生的逆优化可能得出错误的性能结论。</p><blockquote><p>使用-XX:+PrintCompilation选项可以帮助确定是否发生了逆优化。-XX:+Printcompilation选项的输出中如果包含“mad not entrant”,即表明之前的编译优化被丢弃了,方法将通过解释器运行,直到该方法执行足够的次数再触发优化。</p></blockquote><p><font color="DeepPink"><strong>软件开发者应该专注于优秀的软件架构、设计以及实现,没有必要过度担忧现代JIT编译器的影响。如果对软件架构、设计或实现的修改是为了克服JIT编译器的一些性质,就应该考虑这是JIT编译器的缺陷或不足。</strong></font></p><h3 id="创建微基准测试的注意事项"><a href="#创建微基准测试的注意事项" class="headerlink" title="创建微基准测试的注意事项"></a>创建微基准测试的注意事项</h3><ol><li>明确你需要了解的性能指标是什么,设计相应的实验回答你需要解决的回题。不要受些无关痛痒的因素影响而忽略了你真正需要解决的问题。</li><li>确保采样阶段中每次使用同样的工作量。</li><li>计算并收集多种性能指标,譬如消耗时间、单位时间迭代次数或每次迭代的消耗时间用在预热阶段之后,采样阶段期间记录的性能指标。留意度量时间的精度和粒度,特别是使用了System.currentTimeMi1lis()和System.nanoTime()的情况。多次运行试验,并变换采样的周期数或釆样的持续时间。之后再比较其所消耗的时间,密切注意单位时间迭代次数或每迭代消耗时间指标的变化。微基准测试经历了足够的预热、达到稳定态时,后一个指标几乎应该与釆样阶段持续时间的变化保持一致。</li><li>开始釆样之前确认微基准测试已经到达稳定态。可遵循的一条通用原则是,确保微基准测试至少运行10秒以上。使用 HotSpot的-XX:+PrintCompilation选项通过插入表示微基准测试执行阶段的工具可以帮助确认基准测试已经到达稳定态。这一步的日的是确保在开始采样之前,微基准测试经过充分预热,在采样阶段不会发生进一步的优化或逆优化事件。</li><li>多次运行基准测试以确保观测的结果是可重复的。多次运行可以为你最终的结论提供有力支持。</li><li>运行实验及观测结果时特别要留意得到的结果是否合理。如果碰到无法解释或可疑的结果,要花时间去研究、回顾实验的设计,确保观察的结果合理。</li><li>通过传递随时变化的参数到关注的方法中、返回关注方法的执行结果、在采样周期之外打印输出计算结果使计算更有意义,避免在微基准测试中创建无效代码。</li><li>留意内联可能对微基准测试产生的影响。如果对结果存疑,可以通过XX:+PrintInlining和-XX:+PrintCompilation命令行选项,利用HotSpot Debug VM观察HotSpot JIT编译器进行内联决策的过程。</li><li>确保执行微基准测试时其他的应用程序不会对系统造成影响。执行微基准测试时即使向桌面窗口管理器中添加很小或者很简单的应用程序(譬如天气应用或者股票行情记录软件),都会对系统性能造成影响。</li><li>当你需要很明确地了解JIT编译器生成了什么样的优化代码时,可以使用Oracle Solaris Studio Performance Analyzer或者HotSpot Debug VM(使用-XX:+PrintOptoAssembly选项)查看生成的汇编代码。</li><li>采用小数据集或数据结构的微基准测试受缓存的影响很大。微基准测试的结果可能每次执行都不一样,在不同的机器上运行结果也差别很大。</li><li>对于采用多线程的微基准测试需要意识到线程调度可能不是确定性的,特别是在负荷较重的情况下。</li></ol><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Performance </tag>
            
            <tag> 读书笔记 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arthas 学习笔记</title>
      <link href="/arthas-learning-notes.html"/>
      <url>/arthas-learning-notes.html</url>
      
        <content type="html"><![CDATA[<p>阿里 Arthas 学习笔记</p><a id="more"></a><h1 id="thread"><a href="#thread" class="headerlink" title="thread"></a>thread</h1><p>查看当前线程信息，查看线程的堆栈。</p><p>参数说明：</p><table><thead><tr><th>参数名称</th><th>参数说明</th><th>示例</th></tr></thead><tbody><tr><td>id</td><td>线程id</td><td></td></tr><tr><td>[n:]</td><td>指定最忙的前N个线程并打印堆栈</td><td>thread -n 3</td></tr><tr><td>[b]</td><td>找出当前阻塞其他线程的线程</td><td>thread -b</td></tr><tr><td>[i <value>]</value></td><td>指定cpu占比统计的采样间隔，单位为毫秒</td><td></td></tr></tbody></table><blockquote><p>注意， 目前只支持找出synchronized关键字阻塞住的线程， 如果是java.util.concurrent.Lock， 目前还不支持。</p></blockquote><h1 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h1><p>查看当前JVM信息。</p><p>使用参考：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">$ jvm</span><br><span class="line"> RUNTIME                                                                                                                                                                                       </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> MACHINE-NAME                                           1@9db2689bb4d6                                                                                                                         </span><br><span class="line"> JVM-START-TIME                                         2019-07-16 18:18:06                                                                                                                    </span><br><span class="line"> MANAGEMENT-SPEC-VERSION                                2.0                                                                                                                                    </span><br><span class="line"> SPEC-NAME                                              Java Virtual Machine Specification                                                                                                     </span><br><span class="line"> SPEC-VENDOR                                            Oracle Corporation                                                                                                                     </span><br><span class="line"> SPEC-VERSION                                           12                                                                                                                                     </span><br><span class="line"> VM-NAME                                                OpenJDK 64-Bit Server VM                                                                                                               </span><br><span class="line"> VM-VENDOR                                              Oracle Corporation                                                                                                                     </span><br><span class="line"> VM-VERSION                                             12.0.1+12                                                                                                                              </span><br><span class="line"> INPUT-ARGUMENTS                                        -XX:G1PeriodicGCInterval=120000                                                                                                        </span><br><span class="line">                                                        -XX:G1PeriodicGCSystemLoadThreshold=0                                                                                                  </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line"> CLASS-PATH                                             application.jar                                                                                                                        </span><br><span class="line"> BOOT-CLASS-PATH                                                                                                                                                                               </span><br><span class="line"> LIBRARY-PATH                                           /usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib                                                                                 </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> CLASS-LOADING                                                                                                                                                                                 </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> LOADED-CLASS-COUNT                                     11046                                                                                                                                  </span><br><span class="line"> TOTAL-LOADED-CLASS-COUNT                               11377                                                                                                                                  </span><br><span class="line"> UNLOADED-CLASS-COUNT                                   331                                                                                                                                    </span><br><span class="line"> IS-VERBOSE                                             false                                                                                                                                  </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> COMPILATION                                                                                                                                                                                   </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> NAME                                                   HotSpot 64-Bit Tiered Compilers                                                                                                        </span><br><span class="line"> TOTAL-COMPILE-TIME                                     74558(ms)                                                                                                                              </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> GARBAGE-COLLECTORS                                                                                                                                                                            </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> G1 Young Generation                                    12027/52593(ms)                                                                                                                        </span><br><span class="line"> [count/time]                                                                                                                                                                                  </span><br><span class="line"> G1 Old Generation                                      0/0(ms)                                                                                                                                </span><br><span class="line"> [count/time]                                                                                                                                                                                  </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> MEMORY-MANAGERS                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> CodeCacheManager                                       CodeHeap &apos;non-nmethods&apos;                                                                                                                </span><br><span class="line">                                                        CodeHeap &apos;profiled nmethods&apos;                                                                                                           </span><br><span class="line">                                                        CodeHeap &apos;non-profiled nmethods&apos;                                                                                                       </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line"> Metaspace Manager                                      Metaspace                                                                                                                              </span><br><span class="line">                                                        Compressed Class Space                                                                                                                 </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line"> G1 Young Generation                                    G1 Eden Space                                                                                                                          </span><br><span class="line">                                                        G1 Survivor Space                                                                                                                      </span><br><span class="line">                                                        G1 Old Gen                                                                                                                             </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line"> G1 Old Generation                                      G1 Eden Space                                                                                                                          </span><br><span class="line">                                                        G1 Survivor Space                                                                                                                      </span><br><span class="line">                                                        G1 Old Gen                                                                                                                             </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> MEMORY                                                                                                                                                                                        </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> HEAP-MEMORY-USAGE                                      184549376(176.00 MiB)/2113929216(1.97 GiB)/32178700288(29.97 GiB)/60812520(58.00 MiB)                                                  </span><br><span class="line"> [committed/init/max/used]                                                                                                                                                                     </span><br><span class="line"> NO-HEAP-MEMORY-USAGE                                   115539968(110.19 MiB)/7667712(7.31 MiB)/-1(-1 B)/108227072(103.21 MiB)                                                                 </span><br><span class="line"> [committed/init/max/used]                                                                                                                                                                     </span><br><span class="line"> PENDING-FINALIZE-COUNT                                 0                                                                                                                                      </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> OPERATING-SYSTEM                                                                                                                                                                              </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> OS                                                     Linux                                                                                                                                  </span><br><span class="line"> ARCH                                                   amd64                                                                                                                                  </span><br><span class="line"> PROCESSORS-COUNT                                       32                                                                                                                                     </span><br><span class="line"> LOAD-AVERAGE                                           2.25                                                                                                                                   </span><br><span class="line"> VERSION                                                3.10.0-514.26.2.el7.x86_64                                                                                                             </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> THREAD                                                                                                                                                                                        </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> COUNT                                                  1060                                                                                                                                   </span><br><span class="line"> DAEMON-COUNT                                           25                                                                                                                                     </span><br><span class="line"> PEAK-COUNT                                             1062                                                                                                                                   </span><br><span class="line"> STARTED-COUNT                                          2463                                                                                                                                   </span><br><span class="line"> DEADLOCK-COUNT                                         0                                                                                                                                      </span><br><span class="line">                                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> FILE-DESCRIPTOR                                                                                                                                                                               </span><br><span class="line">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> MAX-FILE-DESCRIPTOR-COUNT                              -1                                                                                                                                     </span><br><span class="line"> OPEN-FILE-DESCRIPTOR-COUNT                             -1                                                                                                                                     </span><br><span class="line">Affect(row-cnt:0) cost in 14 ms.</span><br></pre></td></tr></table></figure><h1 id="sysprop"><a href="#sysprop" class="headerlink" title="sysprop"></a>sysprop</h1><p>查看当前JVM的系统属性(System Property)。</p><p>与jinfo 信息类似，不过sysprop提供修改单个属性值的功能。</p><p>查看单个属性，支持通过TAB键自动补全。</p><h1 id="sysenv"><a href="#sysenv" class="headerlink" title="sysenv"></a>sysenv</h1><p>查看当前JVM的环境属性(System Environment Variables)。</p><p>查看单个属性，支持通过TAB键自动补全。</p><h1 id="sc、sm、jad"><a href="#sc、sm、jad" class="headerlink" title="sc、sm、jad"></a>sc、sm、jad</h1><h2 id="sc"><a href="#sc" class="headerlink" title="sc"></a>sc</h2><p>查看JVM已加载的类信息,可以package前缀模糊匹配。</p><h2 id="sm"><a href="#sm" class="headerlink" title="sm"></a>sm</h2><p>查看已加载类的方法信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ monitor com.jiankunking.logsearch.services.LogSearchService queryStringByKeyWord</span><br><span class="line">Press Q or Ctrl+C to abort.</span><br><span class="line">Affect(class-cnt:1 , method-cnt:1) cost in 90 ms.</span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:37:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  61     61       0     96.68       0.00%                                                       </span><br><span class="line"></span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:38:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  27     27       0     51.06       0.00%                                                       </span><br><span class="line"></span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:39:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  0      0        0     0.00        0.00%</span><br></pre></td></tr></table></figure><h2 id="jad"><a href="#jad" class="headerlink" title="jad"></a>jad</h2><p>反编译指定已加载类的源码。</p><p>jad 命令将 JVM 中实际运行的 class 的 byte code 反编译成 java 代码，便于你理解业务逻辑；</p><ul><li>在 Arthas Console 上，反编译出来的源码是带语法高亮的，阅读更方便</li><li>当然，反编译出来的 java 代码可能会存在语法错误，但不影响你进行阅读理解</li></ul><blockquote><p>sc、sm、jad 三个命令可以结合使用。</p></blockquote><h1 id="classloader"><a href="#classloader" class="headerlink" title="classloader"></a>classloader</h1><p>查看classloader的继承树，urls，类加载信息。</p><p>classloader 命令将 JVM 中所有的classloader的信息统计出来，并可以展示继承树，urls等。</p><p>可以让指定的classloader去getResources，打印出所有查找到的resources的url。对于ResourceNotFoundException比较有用。</p><h1 id="mc、redefine"><a href="#mc、redefine" class="headerlink" title="mc、redefine"></a>mc、redefine</h1><h2 id="mc"><a href="#mc" class="headerlink" title="mc"></a>mc</h2><p>Memory Compiler/内存编译器，编译.java文件生成.class。</p><h2 id="redefine"><a href="#redefine" class="headerlink" title="redefine"></a>redefine</h2><p>加载外部的.class文件，redefine jvm已加载的类。</p><blockquote><p>mc、redefine 可以结合使用</p></blockquote><h1 id="monitor"><a href="#monitor" class="headerlink" title="monitor"></a>monitor</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ monitor com.jiankunking.logsearch.services.LogSearchService queryStringByKeyWord</span><br><span class="line">Press Q or Ctrl+C to abort.</span><br><span class="line">Affect(class-cnt:1 , method-cnt:1) cost in 90 ms.</span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:37:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  61     61       0     96.68       0.00%                                                       </span><br><span class="line"></span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:38:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  27     27       0     51.06       0.00%                                                       </span><br><span class="line"></span><br><span class="line"> timestamp            class                                                method                total  success  fail  avg-rt(ms)  fail-rate                                                   </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------                                                  </span><br><span class="line"> 2019-08-02 10:39:50  com.jiankunking.logsearch.services.LogSearchService  queryStringByKeyWord  0      0        0     0.00        0.00%</span><br></pre></td></tr></table></figure><h1 id="watch"><a href="#watch" class="headerlink" title="watch"></a>watch</h1><p>方法执行数据观测。</p><p>让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写OGNL 表达式进行对应变量的查看。</p><blockquote><p>这个有点强大啊</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">$ watch  com.jiankunking.logsearch.services.LogSearchService queryStringByKeyWord  &quot;&#123;params,target,returnObj&#125;&quot; -x 2 -b -s -n 2</span><br><span class="line">Press Q or Ctrl+C to abort.</span><br><span class="line">Affect(class-cnt:1 , method-cnt:1) cost in 111 ms.</span><br><span class="line">ts=2019-08-02 10:48:48; [cost=0.006503ms] result=@ArrayList[</span><br><span class="line">    @Object[][</span><br><span class="line">        @String[monitor],</span><br><span class="line">        @String[console],</span><br><span class="line">        null,</span><br><span class="line">        @String[all],</span><br><span class="line">        @String[all],</span><br><span class="line">        null,</span><br><span class="line">        null,</span><br><span class="line">        @Integer[100],</span><br><span class="line">        @Long[1564713816522],</span><br><span class="line">        @Long[1564714116522],</span><br><span class="line">        null,</span><br><span class="line">        @[desc],</span><br><span class="line">    ],</span><br><span class="line">    @LogSearchService[</span><br><span class="line">        log=@Logger[Logger[com.jiankunking.logsearch.services.LogSearchService]],</span><br><span class="line">        esFilterService=@ESFilterService[com.jiankunking.logsearch.services.ESFilterService@58ebfd03],</span><br><span class="line">        indexPrefixService=@IndexPrefixService[com.jiankunking.logsearch.services.IndexPrefixService@19fb8826],</span><br><span class="line">        searchAfterSort=@String[][isEmpty=false;size=3],</span><br><span class="line">    ],</span><br><span class="line">    null,</span><br><span class="line">]</span><br><span class="line">ts=2019-08-02 10:48:48; [cost=91.878471ms] result=@ArrayList[</span><br><span class="line">    @Object[][</span><br><span class="line">        @String[monitor],</span><br><span class="line">        @String[console],</span><br><span class="line">        null,</span><br><span class="line">        @String[all],</span><br><span class="line">        @String[all],</span><br><span class="line">        null,</span><br><span class="line">        null,</span><br><span class="line">        @Integer[100],</span><br><span class="line">        @Long[1564713816522],</span><br><span class="line">        @Long[1564714116522],</span><br><span class="line">        null,</span><br><span class="line">        @[desc],</span><br><span class="line">    ],</span><br><span class="line">    @LogSearchService[</span><br><span class="line">        log=@Logger[Logger[com.jiankunking.logsearch.services.LogSearchService]],</span><br><span class="line">        esFilterService=@ESFilterService[com.jiankunking.logsearch.services.ESFilterService@58ebfd03],</span><br><span class="line">        indexPrefixService=@IndexPrefixService[com.jiankunking.logsearch.services.IndexPrefixService@19fb8826],</span><br><span class="line">        searchAfterSort=@String[][isEmpty=false;size=3],</span><br><span class="line">    ],</span><br><span class="line">    @SearchResult[</span><br><span class="line">        metadata=@MetaData[MetaData(total=21431)],</span><br><span class="line">        items=@ArrayList[isEmpty=false;size=100],</span><br><span class="line">    ],</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h1 id="trace"><a href="#trace" class="headerlink" title="trace"></a>trace</h1><p>方法内部调用路径，并输出方法路径上的每个节点上耗时</p><p>trace 命令能主动搜索 class-pattern／method-pattern 对应的方法调用路径，渲染和统计整个调用链路上的所有性能开销和追踪调用链路。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">$ trace  com.jiankunking.logsearch.services.LogSearchService queryStringByKeyWord </span><br><span class="line">Press Q or Ctrl+C to abort.</span><br><span class="line">Affect(class-cnt:1 , method-cnt:1) cost in 182 ms.</span><br><span class="line">`---ts=2019-08-02 10:53:36;thread_name=http-nio-8080-exec-8;id=42d;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@1095194</span><br><span class="line">    `---[416.520613ms] com.jiankunking.logsearch.services.LogSearchService:queryStringByKeyWord()</span><br><span class="line">        +---[0.019415ms] org.elasticsearch.search.builder.SearchSourceBuilder:&lt;init&gt;() #78</span><br><span class="line">        +---[0.011853ms] org.elasticsearch.index.query.QueryBuilders:boolQuery() #79</span><br><span class="line">        +---[0.02617ms] com.jiankunking.logsearch.services.ESFilterService:addProjectFilter() #80</span><br><span class="line">        +---[0.005593ms] com.jiankunking.logsearch.util.StringUtils:isEmpty() #81</span><br><span class="line">        +---[0.006519ms] java.lang.String:equals() #81</span><br><span class="line">        +---[0.002157ms] com.jiankunking.logsearch.util.StringUtils:isEmpty() #84</span><br><span class="line">        +---[0.002046ms] java.lang.String:equals() #84</span><br><span class="line">        +---[0.004284ms] com.jiankunking.logsearch.util.StringUtils:isNotEmpty() #87</span><br><span class="line">        +---[0.002342ms] com.jiankunking.logsearch.util.StringUtils:isNotEmpty() #90</span><br><span class="line">        +---[0.002066ms] com.jiankunking.logsearch.util.StringUtils:isNotEmpty() #98</span><br><span class="line">        +---[0.005008ms] org.elasticsearch.index.query.QueryBuilders:rangeQuery() #114</span><br><span class="line">        +---[0.005904ms] com.jiankunking.logsearch.util.TimeUtils:toDate() #115</span><br><span class="line">        +---[0.006666ms] org.elasticsearch.index.query.RangeQueryBuilder:gte() #115</span><br><span class="line">        +---[0.002128ms] com.jiankunking.logsearch.util.TimeUtils:toDate() #116</span><br><span class="line">        +---[0.004161ms] org.elasticsearch.index.query.RangeQueryBuilder:lte() #116</span><br><span class="line">        +---[0.347063ms] org.elasticsearch.index.query.BoolQueryBuilder:must() #117</span><br><span class="line">        +---[min=0.002196ms,max=0.030129ms,total=0.036436ms,count=3] org.elasticsearch.search.builder.SearchSourceBuilder:sort() #126</span><br><span class="line">        +---[0.005683ms] org.elasticsearch.search.builder.SearchSourceBuilder:fetchSource() #131</span><br><span class="line">        +---[0.003406ms] org.elasticsearch.search.builder.SearchSourceBuilder:size() #133</span><br><span class="line">        +---[0.003613ms] org.elasticsearch.search.builder.SearchSourceBuilder:query() #133</span><br><span class="line">        +---[0.321264ms] org.elasticsearch.search.builder.SearchSourceBuilder:toString() #134</span><br><span class="line">        +---[0.00689ms] org.springframework.http.HttpMethod:name() #136</span><br><span class="line">        +---[0.172438ms] com.jiankunking.logsearch.services.IndexPrefixService:getIndexPrefix() #136</span><br><span class="line">        +---[0.012968ms] com.jiankunking.logsearch.util.ESQueryUtils:getEndpoint() #136</span><br><span class="line">        +---[398.953869ms] com.jiankunking.logsearch.util.ESQueryUtils:performRequest() #136</span><br><span class="line">        +---[0.336319ms] com.alibaba.fastjson.JSON:parse() #138</span><br><span class="line">        +---[min=0.002461ms,max=0.013798ms,total=0.016259ms,count=2] java.util.Map:get() #140</span><br><span class="line">        +---[0.006434ms] java.lang.Integer:intValue() #140</span><br><span class="line">        +---[min=0.001908ms,max=0.002073ms,total=0.003981ms,count=2] java.util.Map:get() #141</span><br><span class="line">        +---[0.007532ms] com.jiankunking.logsearch.dto.SearchResult:&lt;init&gt;() #145</span><br><span class="line">        +---[0.004286ms] java.util.ArrayList:&lt;init&gt;() #146</span><br><span class="line">        +---[0.005725ms] com.alibaba.fastjson.JSONArray:iterator() #148</span><br><span class="line">        +---[min=8.07E-4ms,max=0.010324ms,total=0.124433ms,count=101] java.util.Iterator:hasNext() #148</span><br><span class="line">        +---[min=8.16E-4ms,max=0.009674ms,total=0.114893ms,count=100] java.util.Iterator:next() #148</span><br><span class="line">        +---[min=8.38E-4ms,max=0.013835ms,total=0.130734ms,count=100] com.alibaba.fastjson.JSONObject:get() #150</span><br><span class="line">        +---[min=8.69E-4ms,max=0.005654ms,total=0.112518ms,count=100] com.jiankunking.logsearch.util.MapUtils:getSize() #151</span><br><span class="line">        +---[min=7.84E-4ms,max=0.005522ms,total=0.106345ms,count=100] java.util.HashMap:&lt;init&gt;() #151</span><br><span class="line">        +---[min=8.4E-4ms,max=0.016457ms,total=0.12907ms,count=100] com.alibaba.fastjson.JSONArray:iterator() #152</span><br><span class="line">        +---[min=8.21E-4ms,max=0.002612ms,total=0.106495ms,count=100] java.util.Iterator:hasNext() #152</span><br><span class="line">        +---[min=8.07E-4ms,max=0.018355ms,total=0.143992ms,count=100] java.util.Iterator:next() #152</span><br><span class="line">        +---[min=8.72E-4ms,max=0.008687ms,total=0.132524ms,count=100] java.lang.String:valueOf() #153</span><br><span class="line">        +---[min=8.07E-4ms,max=0.008049ms,total=0.110329ms,count=100] java.lang.String:contains() #153</span><br><span class="line">        +---[min=8.46E-4ms,max=0.002612ms,total=0.109295ms,count=100] java.lang.String:valueOf() #156</span><br><span class="line">        +---[min=8.86E-4ms,max=0.041239ms,total=0.178986ms,count=100] java.util.HashMap:put() #156</span><br><span class="line">        +---[min=7.96E-4ms,max=0.008521ms,total=0.113489ms,count=100] com.alibaba.fastjson.JSONObject:get() #159</span><br><span class="line">        +---[min=8.2E-4ms,max=0.016801ms,total=0.125154ms,count=100] java.util.Map:get() #159</span><br><span class="line">        +---[min=8.39E-4ms,max=0.002089ms,total=0.106842ms,count=100] java.util.HashMap:put() #159</span><br><span class="line">        +---[min=7.86E-4ms,max=0.002836ms,total=0.104852ms,count=100] com.alibaba.fastjson.JSONObject:get() #160</span><br><span class="line">        +---[min=8.4E-4ms,max=0.003068ms,total=0.10763ms,count=100] java.util.HashMap:put() #160</span><br><span class="line">        +---[min=8.02E-4ms,max=0.020112ms,total=0.122423ms,count=100] com.alibaba.fastjson.JSONObject:get() #161</span><br><span class="line">        +---[min=8.22E-4ms,max=0.001939ms,total=0.104809ms,count=100] java.util.HashMap:put() #161</span><br><span class="line">        +---[min=7.99E-4ms,max=0.00186ms,total=0.10316ms,count=100] com.alibaba.fastjson.JSONObject:get() #162</span><br><span class="line">        +---[min=8.17E-4ms,max=0.012238ms,total=0.115955ms,count=100] java.util.Map:get() #162</span><br><span class="line">        +---[min=8.14E-4ms,max=0.018342ms,total=0.124331ms,count=100] java.util.HashMap:put() #162</span><br><span class="line">        +---[min=8.47E-4ms,max=0.003852ms,total=0.113692ms,count=100] com.alibaba.fastjson.JSONObject:containsKey() #164</span><br><span class="line">        +---[min=8.11E-4ms,max=0.017145ms,total=0.122375ms,count=100] com.alibaba.fastjson.JSONObject:containsKey() #167</span><br><span class="line">        +---[min=7.85E-4ms,max=0.002459ms,total=0.10233ms,count=100] com.alibaba.fastjson.JSONObject:get() #167</span><br><span class="line">        +---[min=8.57E-4ms,max=0.005959ms,total=0.11281ms,count=100] java.util.Map:containsKey() #167</span><br><span class="line">        +---[min=7.86E-4ms,max=0.016889ms,total=0.116022ms,count=100] com.alibaba.fastjson.JSONObject:get() #171</span><br><span class="line">        +---[min=8.27E-4ms,max=0.007969ms,total=0.121529ms,count=100] java.util.Map:get() #171</span><br><span class="line">        +---[min=8.24E-4ms,max=0.017969ms,total=0.126264ms,count=100] java.util.Map:containsKey() #171</span><br><span class="line">        +---[min=7.83E-4ms,max=0.001924ms,total=0.101244ms,count=100] com.alibaba.fastjson.JSONObject:get() #172</span><br><span class="line">        +---[min=7.92E-4ms,max=0.247702ms,total=0.502606ms,count=200] java.util.Map:get() #172</span><br><span class="line">        +---[min=8.61E-4ms,max=0.010095ms,total=0.124106ms,count=100] java.util.HashMap:put() #172</span><br><span class="line">        +---[min=7.84E-4ms,max=0.002789ms,total=0.100561ms,count=100] com.alibaba.fastjson.JSONObject:get() #174</span><br><span class="line">        +---[min=8.18E-4ms,max=0.003825ms,total=0.105746ms,count=100] java.util.Map:get() #174</span><br><span class="line">        +---[min=8.17E-4ms,max=0.003044ms,total=0.108946ms,count=100] java.util.Map:containsKey() #174</span><br><span class="line">        +---[min=7.83E-4ms,max=0.010689ms,total=0.10957ms,count=100] com.alibaba.fastjson.JSONObject:get() #175</span><br><span class="line">        +---[min=7.92E-4ms,max=0.018299ms,total=0.225606ms,count=200] java.util.Map:get() #175</span><br><span class="line">        +---[min=8.53E-4ms,max=0.002182ms,total=0.108485ms,count=100] java.util.HashMap:put() #175</span><br><span class="line">        +---[min=7.84E-4ms,max=0.005874ms,total=0.103371ms,count=100] com.alibaba.fastjson.JSONObject:get() #177</span><br><span class="line">        +---[min=8.02E-4ms,max=0.002017ms,total=0.101695ms,count=100] java.util.Map:get() #177</span><br><span class="line">        +---[min=8.26E-4ms,max=0.002735ms,total=0.106121ms,count=100] java.util.Map:containsKey() #177</span><br><span class="line">        +---[min=8.0E-4ms,max=0.017176ms,total=0.130393ms,count=100] com.alibaba.fastjson.JSONObject:get() #178</span><br><span class="line">        +---[min=8.03E-4ms,max=0.003318ms,total=0.204767ms,count=200] java.util.Map:get() #178</span><br><span class="line">        +---[min=8.55E-4ms,max=0.008081ms,total=0.115006ms,count=100] java.util.HashMap:put() #178</span><br><span class="line">        +---[min=9.11E-4ms,max=0.014017ms,total=0.136197ms,count=100] java.util.List:add() #180</span><br><span class="line">        +---[0.005288ms] com.jiankunking.logsearch.dto.SearchResult:setItems() #182</span><br><span class="line">        `---[0.002643ms] com.jiankunking.logsearch.dto.SearchResult:setTotal() #183</span><br></pre></td></tr></table></figure><h1 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h1><p>输出当前方法被调用的调用路径。</p><p>很多时候我们都知道一个方法被执行，但这个方法被执行的路径非常多，或者你根本就不知道这个方法是从那里被执行了，此时你需要的是 stack 命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">$ stack  com.jiankunking.logsearch.services.LogSearchService queryStringByKeyWord </span><br><span class="line">Press Q or Ctrl+C to abort.</span><br><span class="line">Affect(class-cnt:1 , method-cnt:1) cost in 173 ms.</span><br><span class="line">ts=2019-08-02 10:55:44;thread_name=http-nio-8080-exec-1;id=426;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@1095194</span><br><span class="line">    @com.jiankunking.logsearch.controller.LogSearchController.searchByKeyWord()</span><br><span class="line">        at com.jiankunking.logsearch.controller.LogSearchController$$FastClassBySpringCGLIB$$61775844.invoke(&lt;generated&gt;:-1)</span><br><span class="line">        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)</span><br><span class="line">        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746)</span><br><span class="line">        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)</span><br><span class="line">        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)</span><br><span class="line">        at com.jiankunking.logsearch.aspect.ControllerTimeConsumeAspect.doAround(ControllerTimeConsumeAspect.java:34)</span><br><span class="line">        at jdk.internal.reflect.GeneratedMethodAccessor91.invoke(null:-1)</span><br><span class="line">        at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:567)</span><br><span class="line">        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)</span><br><span class="line">        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)</span><br><span class="line">        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)</span><br><span class="line">        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)</span><br><span class="line">        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)</span><br><span class="line">        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185)</span><br><span class="line">        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)</span><br><span class="line">        at com.jiankunking.logsearch.controller.LogSearchController$$EnhancerBySpringCGLIB$$2f145034.searchByKeyWord(&lt;generated&gt;:-1)</span><br><span class="line">        at jdk.internal.reflect.GeneratedMethodAccessor97.invoke(null:-1)</span><br><span class="line">        at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:567)</span><br><span class="line">        at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)</span><br><span class="line">        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)</span><br><span class="line">        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)</span><br><span class="line">        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:891)</span><br><span class="line">        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797)</span><br><span class="line">        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)</span><br><span class="line">        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)</span><br><span class="line">        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)</span><br><span class="line">        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)</span><br><span class="line">        at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866)</span><br><span class="line">        at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)</span><br><span class="line">        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)</span><br><span class="line">        at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)</span><br><span class="line">        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)</span><br><span class="line">        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)</span><br><span class="line">        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)</span><br><span class="line">        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)</span><br><span class="line">        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)</span><br><span class="line">        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)</span><br><span class="line">        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)</span><br><span class="line">        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)</span><br><span class="line">        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)</span><br><span class="line">        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)</span><br><span class="line">        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)</span><br><span class="line">        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)</span><br><span class="line">        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)</span><br><span class="line">        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)</span><br><span class="line">        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806)</span><br><span class="line">        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1498)</span><br><span class="line">        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)</span><br><span class="line">        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:835)</span><br></pre></td></tr></table></figure><h1 id="tt"><a href="#tt" class="headerlink" title="tt"></a>tt</h1><p>方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测。</p><h1 id="options"><a href="#options" class="headerlink" title="options"></a>options</h1><p>全局开关</p><table><thead><tr><th>名称</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>unsafe</td><td>false</td><td>是否支持对系统级别的类进行增强，打开该开关可能导致把JVM搞挂，请慎重选择！</td></tr><tr><td>dump</td><td>false</td><td>是否支持被增强了的类dump到外部文件中，如果打开开关，class文件会被dump到/${application dir}/arthas-class-dump/目录下，具体位置详见控制台输出</td></tr><tr><td>batch-re-transform</td><td>true</td><td>是否支持批量对匹配到的类执行retransform操作</td></tr><tr><td>json-format</td><td>false</td><td>是否支持json化的输出</td></tr><tr><td>disable-sub-class</td><td>false</td><td>是否禁用子类匹配，默认在匹配目标类的时候会默认匹配到其子类，如果想精确匹配，可以关闭此开关</td></tr><tr><td>debug-for-asm</td><td>false</td><td>打印ASM相关的调试信息</td></tr><tr><td>save-result</td><td>false</td><td>是否打开执行结果存日志功能，打开之后所有命令的运行结果都将保存到/home/admin/logs/arthas/arthas.log中</td></tr><tr><td>job-timeout</td><td>id</td><td>异步后台任务的默认超时时间，超过这个时间，任务自动停止；比如设置 1d, 2h, 3m, 25s，分别代表天、小时、分、秒</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
            <tag> Arthas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序员常用词汇</title>
      <link href="/coder-vocabulary.html"/>
      <url>/coder-vocabulary.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>下面是工作中，经常用到的一些词汇，持续更新</p></blockquote><a id="more"></a><p>在线：<a href="/attachments/words.txt" target="_blank">程序员常用词汇</a></p>]]></content>
      
      
      <categories>
          
          <category> Words </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Words </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[译]ZGC: 一个可伸缩的低延迟垃圾收集器</title>
      <link href="/zgc-a-scalable-low-latency-garbage-collector.html"/>
      <url>/zgc-a-scalable-low-latency-garbage-collector.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>翻译自：JEP 333</p></blockquote><a id="more"></a><blockquote><p>地址：<a href="https://openjdk.java.net/jeps/333" target="_blank" rel="noopener">https://openjdk.java.net/jeps/333</a></p></blockquote><h1 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h1><p>Z垃圾收集器，也称为ZGC，是一个可伸缩的低延迟垃圾收集器。</p><h1 id="二、目标"><a href="#二、目标" class="headerlink" title="二、目标"></a>二、目标</h1><ul><li>GC暂停时间不超过10ms</li><li>能处理大小从相对较小(几百MB)到非常大(TB级)的堆</li><li>与使用G1相比，应用程序吞吐量减少不超过15%</li><li>方便日后在此基础上利用彩色指针和内存屏障进一步优化收集器及实现新特性。【原文：Lay a foundation for future GC features and optimizations leveraging colored pointers and load barriers】</li><li>支持平台:Linux/x64</li></ul><blockquote><p>注：此处及下文中的内存屏障即load barrier，在ZGC中用的是读屏障。</p></blockquote><h1 id="三、动机"><a href="#三、动机" class="headerlink" title="三、动机"></a>三、动机</h1><p>垃圾收集是Java的主要优势之一。但是，当垃圾收集暂停太长时，就会对应用程序的响应时间产生负面影响。通过大幅度缩短停顿时间，我们可以让Java适用于更多类型的应用程序。</p><p>此外，现代系统中可用的内存数量还在继续增长。<strong>用户和应用程序开发人员希望JVM能够以一种有效的方式充分利用这种内存，并且不会出现很长的GC暂停时间。</strong></p><h1 id="四、-描述"><a href="#四、-描述" class="headerlink" title="四、 描述"></a>四、 描述</h1><p>ZGC是一个并发的、单代（不再区分新生代和老年代）的、基于region的、支持numa的压缩收集器。Stop-the-world阶段仅限于根扫描，所以GC暂停时间不会随着堆或存活对象的多少而增加。</p><p><font color="DeepPink"><strong>ZGC的一个核心设计原则是结合使用内存屏障和彩色对象指针。这使得ZGC能够在运行Java应用程序线程时执行并发操作，比如对象重定位。从Java线程的角度来看，在Java对象中加载引用字段的行为受到内存屏障的限制。除了对象地址之外，有色对象指针还包含内存屏障需要的信息，用于确定在允许Java线程使用该指针之前是否需要采取某些操作。</strong></font>例如，对象可能已经被重新定位，在这种情况下，内存屏障将检测情况并采取适当的操作。</p><p>与其他技术相比，我们认为颜色指针方案提供了一些非常吸引人的特性。特别是:</p><ul><li><p>这允许我们在移动对象/整理内存阶段，在指向可回收/重用区域的指针确定之前回收/重用这部分内存【原文：It allows us to reclaim and reuse memory during the relocation/compaction phase, before pointers pointing into the reclaimed/reused regions have been fixed. 】。这有助于降低堆开销。这还意味着不需要实现单独的标记压缩算法来处理完整的GC。</p></li><li><p>这允许我们使用相对较少且简单的GC屏障。这有助于降低运行时开销。这还意味着在解释器和JIT编译器中更容易实现、优化和维护GC barrier代码。</p></li><li><p>我们目前将标记和重新定位相关信息存储在彩色指针中。然而，此方案的通用性允许我们存储任何类型的信息(只要我们能将其放入指针中)，并允许内存屏障根据该信息采取它想要采取的任何操作。我们相信这将为将来的许多特性打下基础。举一个例子，在异构内存环境中，这可以用来跟踪堆访问模式，以指导GC重新定位决策，将很少使用的对象移动到冷存储(不常访问的内存区域)中【原文：To pick one example, in a heterogeneous memory environment, this could be used to track heap access patterns to guide GC relocation decisions to move rarely used objects to cold storage.】。</p></li></ul><h1 id="五、性能"><a href="#五、性能" class="headerlink" title="五、性能"></a>五、性能</h1><p>我们已经使用SPECjbb 2015[1]做了常规性能测试。从吞吐量和延迟角度来看，性能都很好。下面是使用128G堆在复合模式下比较ZGC和G1的典型基准分数(以百分比为单位，根据ZGC的max-jOPS进行标准化)【原文：Below are typical benchmark scores (in percent, normalized against ZGC’s max-jOPS), comparing ZGC and G1, in composite mode using a 128G heap.】：</p><blockquote><p>越高越好</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ZGC</span><br><span class="line">       max-jOPS: 100%</span><br><span class="line">  critical-jOPS: 76.1%</span><br><span class="line"></span><br><span class="line">G1</span><br><span class="line">       max-jOPS: 91.2%</span><br><span class="line">  critical-jOPS: 54.7%</span><br></pre></td></tr></table></figure><p>下面是来自相同基准测试的GC暂停时间。ZGC设法保持远低于10ms的目标。注意，确切的数字可能会根据使用的机器和设置而变化(上下都有，但不是很明显)。</p><blockquote><p>越低越好</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ZGC</span><br><span class="line">                avg: 1.091ms (+/-0.215ms)</span><br><span class="line">    95th percentile: 1.380ms</span><br><span class="line">    99th percentile: 1.512ms</span><br><span class="line">  99.9th percentile: 1.663ms</span><br><span class="line"> 99.99th percentile: 1.681ms</span><br><span class="line">                max: 1.681ms</span><br><span class="line"></span><br><span class="line">G1</span><br><span class="line">                avg: 156.806ms (+/-71.126ms)</span><br><span class="line">    95th percentile: 316.672ms</span><br><span class="line">    99th percentile: 428.095ms</span><br><span class="line">  99.9th percentile: 543.846ms</span><br><span class="line"> 99.99th percentile: 543.846ms</span><br><span class="line">                max: 543.846ms</span><br></pre></td></tr></table></figure><p>我们还对其他各种SPEC®基准测试和内部工作负载进行了特别的性能测量。一般情况下，ZGC能够维护个位数的毫秒暂停时间。</p><h1 id="六、-局限性"><a href="#六、-局限性" class="headerlink" title="六、 局限性"></a>六、 局限性</h1><p>ZGC的初始实验版本将不支持类卸载。默认情况下，classunload和ClassUnloadingWithConcurrentMark选项将被禁用。即便你启用也是不生效的。</p><p>此外，ZGC最初不支持JVMCI(即Graal)。如果启用EnableJVMCI选项，将打印一条错误消息。</p><p>这些限制将在本项目的后期解决。</p><h1 id="七、-构建和使用"><a href="#七、-构建和使用" class="headerlink" title="七、 构建和使用"></a>七、 构建和使用</h1><p>按照惯例，构建系统默认禁用JVM中的实验性特性。ZGC是一个实验性特性，因此不会出现在JDK构建中，除非在编译时使用configure选项:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--with-jvm-features=zgc</span><br></pre></td></tr></table></figure><p>显式地启用它。</p><p>(ZGC将出现在Oracle发布的所有Linux/x64 JDK版本中)</p><p>JVM中的实验特性还需要在运行时显式地解锁。因此，要启用/使用ZGC，需要以下JVM选项:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+ unlockexperimental alvmoptions -XX:+UseZGC</span><br></pre></td></tr></table></figure><p>有关如何设置和调优ZGC的更多信息，请参阅ZGC项目Wiki（wiki地址：<a href="https://wiki.openjdk.java.net/display/zgc/Main）。" target="_blank" rel="noopener">https://wiki.openjdk.java.net/display/zgc/Main）。</a></p><p>ZGC paper可以参考Azul Pauseless GC Algorithm：</p><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/Azul_Pauseless_GC_Algorithm.pdf" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/Azul_Pauseless_GC_Algorithm.pdf</a></p><p>ZGC 简介PPT:</p><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/ZGC-FOSDEM-2018.pdf" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/ZGC-FOSDEM-2018.pdf</a></p>]]></content>
      
      
      <categories>
          
          <category> GC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> JVM </tag>
            
            <tag> ZGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch 查询的秘密</title>
      <link href="/elasticsearch-query-secret.html"/>
      <url>/elasticsearch-query-secret.html</url>
      
        <content type="html"><![CDATA[<p>最近在参与一个基于Elasticsearch作为底层数据框架提供大数据量(亿级)的实时统计查询的方案设计工作，花了些时间学习Elasticsearch的基础理论知识，整理了一下，希望能对Elasticsearch感兴趣/想了解的同学有所帮助。同时也希望有发现内容不正确或者有疑问的地方，望指明，一起探讨，学习，进步。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎.</p></blockquote><p>Elasticsearch 是一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.<br>当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:</p><ul><li>分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。</li><li>实时分析的分布式搜索引擎。</li><li>可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。</li></ul><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>先说Elasticsearch的文件存储，Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用JSON作为文档序列化的格式，比如下面这条用户数据：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span> :     <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"sex"</span> :      <span class="string">"Male"</span>,</span><br><span class="line">    <span class="attr">"age"</span> :      <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"birthDate"</span>: <span class="string">"1990/05/01"</span>,</span><br><span class="line">    <span class="attr">"about"</span> :    <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">    <span class="attr">"interests"</span>: [ <span class="string">"sports"</span>, <span class="string">"music"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用Mysql这样的数据库存储就会容易想到建立一张User表，有balabala的字段等，在Elasticsearch里这就是一个<em>文档</em>，当然这个文档会属于一个User的<em>类型</em>，各种各样的类型存在于一个<em>索引</em>当中。这里有一份简易的将Elasticsearch和关系型数据术语对照表:</p><p>关系数据库     ⇒ 数据库 ⇒ 表    ⇒ 行    ⇒ 列(Columns)</p><p>Elasticsearch  ⇒ 索引   ⇒ 类型  ⇒ 文档  ⇒ 字段(Fields)</p><p>一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。</p><p>Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT /megacorp/employee/1</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span> :     <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"sex"</span> :      <span class="string">"Male"</span>,</span><br><span class="line">    <span class="attr">"age"</span> :      <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"about"</span> :    <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">    <span class="attr">"interests"</span>: [ <span class="string">"sports"</span>, <span class="string">"music"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更新，查询也是类似这样的操作，具体操作手册可以参见<a href="http://www.learnes.net/data/README.html" target="_blank" rel="noopener">Elasticsearch权威指南</a></p><hr><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>Elasticsearch最关键的就是提供强大的索引能力了，其实InfoQ的这篇<a href="http://www.infoq.com/cn/articles/database-timestamp-02?utm_source=infoq&utm_medium=related_content_link&utm_campaign=relatedContent_articles_clk" target="_blank" rel="noopener">时间序列数据库的秘密(2)——索引</a>写的非常好，我这里也是围绕这篇结合自己的理解进一步梳理下，也希望可以帮助大家更好的理解这篇文章。</p><p>Elasticsearch索引的精髓：</p><blockquote><p>一切设计都是为了提高搜索的性能</p></blockquote><p>另一层意思：为了提高搜索的性能，难免会牺牲某些其他方面，比如插入/更新，否则其他数据库不用混了:)</p><p>前面看到往Elasticsearch里插入一条记录，其实就是直接PUT一个json的对象，这个对象有多个fields，比如上面例子中的<em>name, sex, age, about, interests</em>，那么在插入这些数据到Elasticsearch的同时，Elasticsearch还默默的为这些字段建立索引–倒排索引，因为Elasticsearch最核心功能是搜索。</p><blockquote><p>Elasticsearch默认会为每个字段根据value的类型分别建立索引，如果不想为某些字段建立索引或者不做分词分析的话，需要通过FieldMapping注明。</p></blockquote><h3 id="Elasticsearch是如何做到快速索引的"><a href="#Elasticsearch是如何做到快速索引的" class="headerlink" title="Elasticsearch是如何做到快速索引的"></a>Elasticsearch是如何做到快速索引的</h3><p>InfoQ那篇文章里说Elasticsearch使用的倒排索引比关系型数据库的B-Tree索引快，为什么呢？</p><h4 id="什么是B-Tree索引"><a href="#什么是B-Tree索引" class="headerlink" title="什么是B-Tree索引?"></a>什么是B-Tree索引?</h4><p>上大学读书时老师教过我们，二叉树查找效率是logN，同时插入新的节点不必移动全部节点，所以用树型结构存储索引，能同时兼顾插入和查询的性能。</p><p>因此在这个基础上，再结合磁盘的读取特性(顺序读/随机读)，传统关系型数据库采用了B-Tree/B+Tree这样的数据结构：</p><p><img src="/images/elasticsearch-query-secret/b-tree.png" alt></p><p>为了提高查询的效率，减少磁盘寻道次数，将多个值作为一个数组通过连续区间存放，一次寻道读取多个数据，同时也降低树的高度。</p><h4 id="什么是倒排索引"><a href="#什么是倒排索引" class="headerlink" title="什么是倒排索引?"></a>什么是倒排索引?</h4><p><img src="/images/elasticsearch-query-secret/inverted-index.png" alt></p><p>继续上面的例子，假设有这么几条数据(为了简单，去掉about, interests这两个field):</p><table><thead><tr><th>ID</th><th align="center">Name</th><th align="right">Age</th><th align="right">Sex</th></tr></thead><tbody><tr><td>1</td><td align="center">Kate</td><td align="right">24</td><td align="right">Female</td></tr><tr><td>2</td><td align="center">John</td><td align="right">24</td><td align="right">Male</td></tr><tr><td>3</td><td align="center">Bill</td><td align="right">29</td><td align="right">Male</td></tr></tbody></table><p>ID是Elasticsearch自建的文档id，那么Elasticsearch建立的索引如下:</p><p><strong>Name:</strong> </p><table><thead><tr><th>Term</th><th align="center">Posting List</th></tr></thead><tbody><tr><td>Kate</td><td align="center">1</td></tr><tr><td>John</td><td align="center">2</td></tr><tr><td>Bill</td><td align="center">3</td></tr></tbody></table><p><strong>Age:</strong></p><table><thead><tr><th>Term</th><th align="center">Posting List</th></tr></thead><tbody><tr><td>24</td><td align="center">[1,2]</td></tr><tr><td>29</td><td align="center">3</td></tr></tbody></table><p><strong>Sex:</strong></p><table><thead><tr><th>Term</th><th align="center">Posting List</th></tr></thead><tbody><tr><td>Female</td><td align="center">1</td></tr><tr><td>Male</td><td align="center">[2,3]</td></tr></tbody></table><h5 id="Posting-List"><a href="#Posting-List" class="headerlink" title="Posting List"></a>Posting List</h5><p>Elasticsearch分别为每个field都建立了一个倒排索引，Kate, John, 24, Female这些叫term，而[1,2]就是<strong>Posting List</strong>。Posting list就是一个int的数组，存储了所有符合某个term的文档id。</p><p>看到这里，不要认为就结束了，精彩的部分才刚开始…</p><p>通过posting list这种索引方式似乎可以很快进行查找，比如要找age=24的同学，爱回答问题的小明马上就举手回答：我知道，id是1，2的同学。但是，如果这里有上千万的记录呢？如果是想通过name来查找呢？</p><h5 id="Term-Dictionary"><a href="#Term-Dictionary" class="headerlink" title="Term Dictionary"></a>Term Dictionary</h5><p>Elasticsearch为了能快速找到某个term，将所有的term排个序，二分法查找term，logN的查找效率，就像通过字典查找一样，这就是<strong>Term Dictionary</strong>。现在再看起来，似乎和传统数据库通过B-Tree的方式类似啊，为什么说比B-Tree的查询快呢？</p><h5 id="Term-Index"><a href="#Term-Index" class="headerlink" title="Term Index"></a>Term Index</h5><p>B-Tree通过减少磁盘寻道次数来提高查询性能，Elasticsearch也是采用同样的思路，直接通过内存查找term，不读磁盘，但是如果term太多，term dictionary也会很大，放内存不现实，于是有了<strong>Term Index</strong>，就像字典里的索引页一样，A开头的有哪些term，分别在哪页，可以理解term index是一颗树：<br><img src="/images/elasticsearch-query-secret/term-index.png" alt></p><p>这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。<br><img src="/images/elasticsearch-query-secret/index.png" alt></p><p>所以term index不需要存下所有的term，而仅仅是他们的一些前缀与Term Dictionary的block之间的映射关系，再结合FST(Finite State Transducers)的压缩技术，可以使term index缓存到内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘随机读的次数。</p><p>这时候爱提问的小明又举手了:”那个FST是神马东东啊?”</p><p>一看就知道小明是一个上大学读书的时候跟我一样不认真听课的孩子，数据结构老师一定讲过什么是FST。但没办法，我也忘了，这里再补下课：</p><blockquote><p>FSTs are finite-state machines that <strong>map</strong> a <strong>term (byte sequence)</strong> to an arbitrary <strong>output</strong>.</p></blockquote><p>假设我们现在要将mop, moth, pop, star, stop and top(term index里的term前缀)映射到序号：0，1，2，3，4，5(term dictionary的block位置)。最简单的做法就是定义个Map&lt;String, Integer&gt;，大家找到自己的位置对应入座就好了，但从内存占用少的角度想想，有没有更优的办法呢？答案就是：<strong>FST</strong>(<a href="http://www.cs.nyu.edu/~mohri/pub/fla.pdf" target="_blank" rel="noopener">理论依据在此，但我相信99%的人不会认真看完的</a>)</p><p><img src="/images/elasticsearch-query-secret/fst.png" alt></p><p>⭕️表示一种状态</p><p>–&gt;表示状态的变化过程，上面的字母/数字表示状态变化和权重</p><p>将单词分成单个字母通过⭕️和–&gt;表示出来，0权重不显示。如果⭕️后面出现分支，就标记权重，最后整条路径上的权重加起来就是这个单词对应的序号。</p><blockquote><p>FSTs are finite-state machines that map a term (<strong>byte sequence</strong>) to an arbitrary output.</p></blockquote><p>FST以字节的方式存储所有的term，这种压缩方式可以有效的缩减存储空间，使得term index足以放进内存，但这种方式也会导致查找时需要更多的CPU资源。</p><p>后面的更精彩，看累了的同学可以喝杯咖啡……</p><hr><h4 id="压缩技巧"><a href="#压缩技巧" class="headerlink" title="压缩技巧"></a>压缩技巧</h4><p>Elasticsearch里除了上面说到用FST压缩term index外，对posting list也有压缩技巧。<br>小明喝完咖啡又举手了:”posting list不是已经只存储文档id了吗？还需要压缩？” </p><p>嗯，我们再看回最开始的例子，如果Elasticsearch需要对同学的性别进行索引(这时传统关系型数据库已经哭晕在厕所……)，会怎样？如果有上千万个同学，而世界上只有男/女这样两个性别，每个posting list都会有至少百万个文档id。<br>Elasticsearch是如何有效的对这些文档id压缩的呢？</p><h5 id="Frame-Of-Reference"><a href="#Frame-Of-Reference" class="headerlink" title="Frame Of Reference"></a>Frame Of Reference</h5><blockquote><p>增量编码压缩，将大数变小数，按字节存储</p></blockquote><p>首先，Elasticsearch要求posting list是有序的(为了提高搜索的性能，再任性的要求也得满足)，这样做的一个好处是方便压缩，看下面这个图例：<br><img src="/images/elasticsearch-query-secret/frameOfReference.png" alt></p><p>如果数学不是体育老师教的话，还是比较容易看出来这种压缩技巧的。</p><p><font color="DeepPink"><strong>原理就是通过增量，将原来的大数变成小数仅存储增量值，再精打细算按bit排好队，最后通过字节存储</strong></font>，而不是大大咧咧的尽管是2也是用int(4个字节)来存储。</p><h5 id="Roaring-bitmaps"><a href="#Roaring-bitmaps" class="headerlink" title="Roaring bitmaps"></a>Roaring bitmaps</h5><p>说到Roaring bitmaps，就必须先从bitmap说起。Bitmap是一种数据结构，假设有某个posting list：</p><p>[1,3,4,7,10]</p><p>对应的bitmap就是：</p><p>[1,0,1,1,0,0,1,0,0,1]</p><p>非常直观，用0/1表示某个值是否存在，比如10这个值就对应第10位，对应的bit值是1，这样用一个字节就可以代表8个文档id，旧版本(5.0之前)的Lucene就是用这样的方式来压缩的，但这样的压缩方式仍然不够高效，如果有1亿个文档，那么需要12.5MB的存储空间，这仅仅是对应一个索引字段(我们往往会有很多个索引字段)。于是有人想出了Roaring bitmaps这样更高效的数据结构。</p><p>Bitmap的缺点是存储空间随着文档个数线性增长，Roaring bitmaps需要打破这个魔咒就一定要用到某些指数特性：</p><p>将posting list按照65535为界限分块，比如第一块所包含的文档id范围在0 ~ 65535之间，第二块的id范围是65536 ~ 131071，以此类推。再用&lt;商，余数&gt;的组合表示每一组id，这样每组里的id范围都在0 ~ 65535内了，剩下的就好办了，既然每组id不会变得无限大，那么我们就可以通过最有效的方式对这里的id存储。</p><p><img src="/images/elasticsearch-query-secret/Roaringbitmaps.png" alt></p><p>细心的小明这时候又举手了:”为什么是以65535为界限?”</p><p>程序员的世界里除了1024外，65535也是一个经典值，因为它=2^16-1，正好是用2个字节能表示的最大数，一个short的存储单位，注意到上图里的最后一行“If a block has more than 4096 values, encode as a bit set, and otherwise as a simple array using 2 bytes per value”，如果是大块，用节省点用bitset存，小块就豪爽点，2个字节我也不计较了，用一个short[]存着方便。</p><p>那为什么用4096来区分采用数组还是bitmap的阀值呢？</p><p>这个是从内存大小考虑的，当block块里元素超过4096后，用bitmap更剩空间：<br>采用bitmap需要的空间是恒定的: 65536/8 = 8192bytes<br>而如果采用short[]，所需的空间是: 2*N(N为数组元素个数)<br>小明手指一掐N=4096刚好是边界:</p><p><img src="/images/elasticsearch-query-secret/block-memory.png" alt></p><hr><h4 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h4><p>上面说了半天都是单field索引，如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？</p><ul><li>利用跳表(Skip list)的数据结构快速做“与”运算，或者</li><li>利用上面提到的bitset按位“与”</li></ul><p>先看看跳表的数据结构：</p><p><img src="/images/elasticsearch-query-secret/skiplist.png" alt></p><p>将一个有序链表level0，挑出其中几个元素到level1及level2，每个level越往上，选出来的指针元素越少，查找时依次从高level往低查找，比如55，先找到level2的31，再找到level1的47，最后找到55，一共3次查找，查找效率和2叉树的效率相当，但也是用了一定的空间冗余来换取的。</p><p>假设有下面三个posting list需要联合索引：</p><p><img src="/images/elasticsearch-query-secret/combineIndex.png" alt></p><p>如果使用跳表，对最短的posting list中的每个id，逐个在另外两个posting list中查找看是否存在，最后得到交集的结果。</p><p>如果使用bitset，就很直观了，直接按位与，得到的结果就是最后的交集。</p><hr><h3 id="总结和思考"><a href="#总结和思考" class="headerlink" title="总结和思考"></a>总结和思考</h3><p>Elasticsearch的索引思路:</p><blockquote><p>将磁盘里的东西尽量搬进内存，减少磁盘随机读取次数(同时也利用磁盘顺序读特性)，结合各种奇技淫巧的压缩算法，用及其苛刻的态度使用内存。</p></blockquote><p>所以，对于使用Elasticsearch进行索引时需要注意:</p><ul><li>不需要索引的字段，一定要明确定义出来，因为默认是自动建索引的</li><li>同样的道理，对于String类型的字段，不需要analysis的也需要明确定义出来，因为默认也是会analysis的</li><li>选择有规律的ID很重要，随机性太大的ID(比如java的UUID)不利于查询</li></ul><p>看一下filebeat收集日志后，elasticsearch自动生成的id，如图：<br><img src="/images/elasticsearch-query-secret/filebeat_log_id.png" alt></p><p>关于最后一点，个人认为有多个因素:</p><p>其中一个(也许不是最重要的)因素: 上面看到的压缩算法，都是对Posting list里的大量ID进行压缩的，那如果ID是顺序的，或者是有公共前缀等具有一定规律性的ID，压缩比会比较高；</p><p>另外一个因素: 可能是最影响查询性能的，应该是最后通过Posting list里的ID到磁盘中查找Document信息的那步，因为Elasticsearch是分Segment存储的，根据ID这个大范围的Term定位到Segment的效率直接影响了最后查询的性能，如果ID是有规律的，可以快速跳过不包含该ID的Segment，从而减少不必要的磁盘读次数，具体可以参考这篇<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html" target="_blank" rel="noopener">如何选择一个高效的全局ID方案</a>(评论也很精彩)</p><p>后续再结合实际开发及调优工作分享更多内容，敬请期待！</p><hr><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="https://neway6655.github.io/elasticsearch/2015/09/11/elasticsearch-study-notes.html" target="_blank" rel="noopener">Elasticsearch 学习笔记</a></p>]]></content>
      
      
      <categories>
          
          <category> ElasticSearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
            <tag> Query </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Epoll 的本质是什么？</title>
      <link href="/epoll-principle.html"/>
      <url>/epoll-principle.html</url>
      
        <content type="html"><![CDATA[<p>从事服务端开发，少不了要接触网络编程。epoll 作为 Linux 下高性能网络服务器的必备技术至关重要，nginx、Redis、Skynet 和大部分游戏服务器都使用到这一多路复用技术。</p><p>epoll 很重要，但是 epoll 与 select 的区别是什么呢？epoll 高效的原因是什么？</p><p><img src="/images/linux-epoll/%E9%A6%96%E9%A1%B5%E5%9B%BE.jpg" alt></p><p>网上虽然也有不少讲解 epoll的文章，但要么是过于浅显，或者陷入源码解析，很少能有通俗易懂的。笔者于是决定编写此文，让缺乏专业背景知识的读者也能够明白 epoll 的原理。</p><p><font color="DeepPink"><strong>文章核心思想是：要让读者清晰明白 epoll 为什么性能好。</strong></font></p><p><font color="DeepPink"><strong>本文会从网卡接收数据的流程讲起，串联起 CPU 中断、操作系统进程调度等知识；再一步步分析阻塞接收数据、select 到 epoll 的进化过程；最后探究 epoll 的实现细节。</strong></font></p><h1 id="一、从网卡接收数据说起"><a href="#一、从网卡接收数据说起" class="headerlink" title="一、从网卡接收数据说起"></a>一、从网卡接收数据说起</h1><p>下边是一个典型的计算机结构图，计算机由 CPU、存储器（内存）与网络接口等部件组成，了解 epoll 本质的第一步，要从硬件的角度看计算机怎样接收网络数据。<br><img src="/images/linux-epoll/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%9B%BE.jpg" alt><br><em>计算机结构图（图片来源：Linux内核完全注释之微型计算机组成结构）</em></p><p>下图展示了网卡接收数据的过程。</p><ul><li>在 ① 阶段，网卡收到网线传来的数据；</li><li>经过 ② 阶段的硬件电路的传输；</li><li>最终 ③ 阶段将数据写入到内存中的某个地址上。</li></ul><p>这个过程涉及到 DMA 传输、IO 通路选择等硬件有关的知识，但我们只需知道：<font color="DeepPink"><strong>网卡会把接收到的数据写入内存</strong></font>。</p><p><img src="/images/linux-epoll/%E7%BD%91%E5%8D%A1%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E7%A8%8B.jpg" alt><br><em>网卡接收数据的过程</em></p><p>通过硬件传输，网卡接收的数据存放到内存中，操作系统就可以去读取它们。</p><h1 id="二、如何知道接收了数据？"><a href="#二、如何知道接收了数据？" class="headerlink" title="二、如何知道接收了数据？"></a>二、如何知道接收了数据？</h1><p>了解 epoll 本质的第二步，要从 CPU 的角度来看数据接收。理解这个问题，要先了解一个概念——<font color="DeepPink"><strong>中断</strong></font>。</p><p>计算机执行程序时，会有优先级的需求。比如，当计算机收到断电信号时，它应立即去保存数据，保存数据的程序具有较高的优先级（电容可以保存少许电量，供 CPU 运行很短的一小段时间）。</p><p><font color="DeepPink"><strong>一般而言，由硬件产生的信号需要 CPU 立马做出回应，不然数据可能就丢失了，所以它的优先级很高。CPU 理应中断掉正在执行的程序，去做出响应；当 CPU 完成对硬件的响应后，再重新执行用户程序。</strong></font>中断的过程如下图，它和函数调用差不多，只不过函数调用是事先定好位置，而中断的位置由“信号”决定。<br><img src="/images/linux-epoll/%E4%B8%AD%E6%96%AD%E7%A8%8B%E5%BA%8F%E8%B0%83%E7%94%A8.jpg" alt><br><em>中断程序调用</em></p><p>以键盘为例，当用户按下键盘某个按键时，键盘会给 CPU 的中断引脚发出一个高电平，CPU能够捕获这个信号，然后执行键盘中断程序。下图展示了各种硬件通过中断与 CPU 交互的过程。<br><img src="/images/linux-epoll/CPU%E4%B8%AD%E6%96%AD.jpg" alt><br><em>CPU 中断（图片来源：net.pku.edu.cn）</em></p><p>现在可以回答“<strong>如何知道接收了数据？</strong>”这个问题了：<font color="DeepPink"><strong>当网卡把数据写入到内存后，网卡向 CPU 发出一个中断信号，操作系统便能得知有新数据到来，再通过网卡中断程序去处理数据。</strong></font></p><h1 id="三、进程阻塞为什么不占用-CPU-资源？"><a href="#三、进程阻塞为什么不占用-CPU-资源？" class="headerlink" title="三、进程阻塞为什么不占用 CPU 资源？"></a>三、进程阻塞为什么不占用 CPU 资源？</h1><p>了解 epoll 本质的第三步，要从操作系统进程调度的角度来看数据接收。<font color="DeepPink"><strong>阻塞是进程调度的关键一环，指的是进程在等待某事件（如接收到网络数据）发生之前的等待状态，recv、select 和 epoll 都是阻塞方法</strong></font>。下边分析一下进程阻塞为什么不占用 CPU 资源？</p><p>为简单起见，我们从普通的 recv 接收开始分析，先看看下面代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//创建socket</span><br><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);   </span><br><span class="line">//绑定</span><br><span class="line">bind(s, ...)</span><br><span class="line">//监听</span><br><span class="line">listen(s, ...)</span><br><span class="line">//接受客户端连接</span><br><span class="line">int c = accept(s, ...)</span><br><span class="line">//接收客户端数据</span><br><span class="line">recv(c, ...);</span><br><span class="line">//将数据打印出来</span><br><span class="line">printf(...)</span><br></pre></td></tr></table></figure><p>这是一段最基础的网络编程代码，先新建 socket 对象，依次调用 bind、listen 与 accept，最后调用 recv 接收数据。recv 是个阻塞方法，当程序运行到 recv 时，它会一直等待，直到接收到数据才往下执行。</p><p>那么阻塞的原理是什么？</p><h2 id="工作队列"><a href="#工作队列" class="headerlink" title="工作队列"></a>工作队列</h2><p><font color="DeepPink"><strong>操作系统为了支持多任务，实现了进程调度的功能，会把进程分为“运行”和“等待”等几种状态。运行状态是进程获得 CPU 使用权，正在执行代码的状态；等待状态是阻塞状态，比如上述程序运行到 recv 时，程序会从运行状态变为等待状态，接收到数据后又变回运行状态。</strong></font>操作系统会分时执行各个运行状态的进程，由于速度很快，看上去就像是同时执行多个任务。</p><p>下图的计算机中运行着 A、B 与 C 三个进程，其中进程 A 执行着上述基础网络程序，一开始，这 3 个进程都被操作系统的工作队列所引用，处于运行状态，会分时执行。<br><img src="/images/linux-epoll/%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E4%B8%AD%E6%9C%89ABC%E4%B8%89%E4%B8%AA%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>工作队列中有 A、B 和 C 三个进程</em></p><h2 id="等待队列"><a href="#等待队列" class="headerlink" title="等待队列"></a>等待队列</h2><p>当进程 A 执行到创建 socket 的语句时，操作系统会创建一个由文件系统管理的 socket 对象（如下图）。这个 socket 对象包含了发送缓冲区、接收缓冲区与等待队列等成员。等待队列是个非常重要的结构，它指向所有需要等待该 socket 事件的进程。<br><img src="/images/linux-epoll/%E5%88%9B%E5%BB%BAsocket.jpg" alt><br><em>创建 socket</em></p><p><strong>当程序执行到 recv 时，操作系统会将进程 A 从工作队列移动到该 socket 的等待队列中</strong>（如下图）。由于工作队列只剩下了进程 B 和 C，依据进程调度，CPU 会轮流执行这两个进程的程序，不会执行进程 A 的程序。所以进程 A 被阻塞，不会往下执行代码，也不会占用 CPU 资源。<br><img src="/images/linux-epoll/socket%E7%9A%84%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97.jpg" alt><br><em>socket 的等待队列</em></p><blockquote><p>注：操作系统添加等待队列只是添加了对这个“等待中”进程的引用，以便在接收到数据时获取进程对象、将其唤醒，而非直接将进程管理纳入自己之下。上图为了方便说明，直接将进程挂到等待队列之下。</p></blockquote><h2 id="唤醒进程"><a href="#唤醒进程" class="headerlink" title="唤醒进程"></a>唤醒进程</h2><p><strong>当 socket 接收到数据后，操作系统将该 socket 队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。同时由于 socket 的接收缓冲区已经有了数据，recv 可以返回接收到的数据。</strong></p><h1 id="四、内核接收网络数据全过程"><a href="#四、内核接收网络数据全过程" class="headerlink" title="四、内核接收网络数据全过程"></a>四、内核接收网络数据全过程</h1><p>这一步，贯穿网卡、中断与进程调度的知识，叙述阻塞 recv 下，内核接收数据的全过程。</p><p>如下图所示，进程在 recv 阻塞期间，计算机收到了对端传送的数据（步骤①），数据经由网卡传送到内存（步骤②），然后网卡通过中断信号通知 CPU 有数据到达，CPU 执行中断程序（步骤③）。</p><p>此处的中断程序主要有两项功能，先将网络数据写入到对应 socket 的接收缓冲区里面（步骤④），再唤醒进程 A（步骤⑤），重新将进程 A 放入工作队列中。<br><img src="/images/linux-epoll/%E5%86%85%E6%A0%B8%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E8%BF%87%E7%A8%8B.jpg" alt><br><em>内核接收数据全过程</em></p><p>唤醒进程的过程如下图所示：<br><img src="/images/linux-epoll/%E5%94%A4%E9%86%92%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>唤醒进程</em></p><p>以上是内核接收数据全过程，这里我们可能会思考两个问题：</p><ul><li>其一，<strong>操作系统如何知道网络数据对应于哪个 socket？</strong></li><li>其二，<strong>如何同时监视多个 socket 的数据？</strong></li></ul><p>第一个问题：<font color="DeepPink"><strong>因为一个 socket 对应着一个端口号，而网络数据包中包含了 ip 和端口的信息，内核可以通过端口号找到对应的 socket。当然，为了提高处理速度，操作系统会维护端口号到 socket 的索引结构，以快速读取。</strong></font></p><p>第二个问题是多路复用的重中之重，也正是本文后半部分的重点。</p><h1 id="五、同时监视多个-socket-的简单方法"><a href="#五、同时监视多个-socket-的简单方法" class="headerlink" title="五、同时监视多个 socket 的简单方法"></a>五、同时监视多个 socket 的简单方法</h1><p>服务端需要管理多个客户端连接，而 recv 只能监视单个 socket，这种矛盾下，人们开始寻找监视多个 socket 的方法。<font color="DeepPink"><strong>epoll的要义就是高效地监视多个 socket</strong></font>。</p><p>从历史发展角度看，必然先出现一种不太高效的方法，人们再加以改进，正如 select 之于 epoll。</p><p>先理解不太高效的 select，才能够更好地理解 epoll 的本质。</p><p>假如能够预先传入一个 socket 列表，如果列表中的 socket 都没有数据，挂起进程，直到有一个 socket 收到数据，唤醒进程。这种方法很直接，也是 select 的设计思想。</p><p>为方便理解，我们先复习 select 的用法。在下边的代码中，先准备一个数组 fds，让 fds 存放着所有需要监视的 socket。然后调用 select，如果 fds 中的所有 socket 都没有数据，select 会阻塞，直到有一个 socket 接收到数据，select 返回，唤醒进程。用户可以遍历 fds，通过 FD_ISSET 判断具体哪个 socket 收到数据，然后做出处理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);  </span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...);</span><br><span class="line">int fds[] =  存放需要监听的socket;</span><br><span class="line">while(1)&#123;</span><br><span class="line">    int n = select(..., fds, ...)</span><br><span class="line">    for(int i=0; i &lt; fds.count; i++)&#123;</span><br><span class="line">        if(FD_ISSET(fds[i], ...))&#123;</span><br><span class="line">            //fds[i]的数据处理</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="select-的流程"><a href="#select-的流程" class="headerlink" title="select 的流程"></a>select 的流程</h2><p>select 的实现思路很直接，假如程序同时监视如下图的 sock1、sock2 和 sock3 三个 socket，那么在调用 select 之后，操作系统把进程 A 分别加入这三个 socket 的等待队列中。<br><img src="/images/linux-epoll/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8A%8A%E8%BF%9B%E7%A8%8BA%E5%88%86%E5%88%AB%E5%8A%A0%E5%85%A5%E8%BF%99%E4%B8%89%E4%B8%AAsocket%E7%9A%84%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E4%B8%AD.jpg" alt><br><em>操作系统把进程 A 分别加入这三个 socket 的等待队列中</em></p><p>当任何一个 socket 收到数据后，中断程序将唤起进程。下图展示了 sock2 接收到了数据的处理流程：</p><blockquote><p>注：recv 和 select 的中断回调可以设置成不同的内容。</p></blockquote><p><img src="/images/linux-epoll/sock2%E6%8E%A5%E6%94%B6%E5%88%B0%E4%BA%86%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%96%AD%E7%A8%8B%E5%BA%8F%E5%94%A4%E8%B5%B7%E8%BF%9B%E7%A8%8BA.jpg" alt><br><em>sock2 接收到了数据，中断程序唤起进程 A</em></p><p>所谓唤起进程，就是将进程从所有的等待队列中移除，加入到工作队列里面，如下图所示：<br><img src="/images/linux-epoll/%E5%B0%86%E8%BF%9B%E7%A8%8BA%E4%BB%8E%E6%89%80%E6%9C%89%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E4%B8%AD%E7%A7%BB%E9%99%A4%E5%86%8D%E5%8A%A0%E5%85%A5%E5%88%B0%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E9%87%8C%E9%9D%A2.jpg" alt><br><em>将进程 A 从所有等待队列中移除，再加入到工作队列里面</em></p><p>经由这些步骤，当进程 A 被唤醒后，它知道至少有一个 socket 接收了数据。程序只需遍历一遍 socket 列表，就可以得到就绪的 socket。</p><p>这种简单方式行之有效，在几乎所有操作系统都有对应的实现。</p><p>但是简单的方法往往有缺点，主要是：</p><p>其一，<strong>每次调用 select 都需要将进程加入到所有监视 socket 的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个 fds 列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定 select 的最大监视数量，默认只能监视 1024 个 socket。</strong></p><p>其二，<strong>进程被唤醒后，程序并不知道哪些 socket 收到数据，还需要遍历一次。</strong></p><p>那么，<font color="DeepPink"><strong>有没有减少遍历的方法？有没有保存就绪 socket 的方法？这两个问题便是 epoll 技术要解决的。</strong></font></p><blockquote><p>补充说明： 本节只解释了 select 的一种情形。当程序调用 select 时，内核会先遍历一遍 socket，如果有一个以上的 socket 接收缓冲区有数据，那么 select 直接返回，不会阻塞。这也是为什么 select 的返回值有可能大于 1 的原因之一。如果没有 socket 有数据，进程才会阻塞。</p></blockquote><h1 id="六、epoll-的设计思路"><a href="#六、epoll-的设计思路" class="headerlink" title="六、epoll 的设计思路"></a>六、epoll 的设计思路</h1><p>epoll 是在 select 出现 N 多年后才被发明的，是 select 和 poll（poll 和 select 基本一样，有少量改进）的增强版本。epoll 通过以下一些措施来改进效率：</p><h2 id="措施一：功能分离"><a href="#措施一：功能分离" class="headerlink" title="措施一：功能分离"></a>措施一：功能分离</h2><p>select 低效的原因之一是将“维护等待队列”和“阻塞进程”两个步骤合二为一。如下图所示，每次调用 select 都需要这两步操作，然而大多数应用场景中，需要监视的 socket 相对固定，并不需要每次都修改。epoll 将这两个操作分开，先用 epoll_ctl 维护等待队列，再调用 epoll_wait 阻塞进程。显而易见地，效率就能得到提升。<br><img src="/images/linux-epoll/%E7%9B%B8%E6%AF%94selectepoll%E6%8B%86%E5%88%86%E4%BA%86%E5%8A%9F%E8%83%BD.jpg" alt></p><p><em>相比 select，epoll 拆分了功能</em></p><p>为方便理解后续的内容，我们先了解一下 epoll 的用法。如下的代码中，先用 epoll_create 创建一个 epoll 对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到 epfd 中，最后调用 epoll_wait 等待数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);   </span><br><span class="line">bind(s, ...)</span><br><span class="line">listen(s, ...)</span><br><span class="line"></span><br><span class="line">int epfd = epoll_create(...);</span><br><span class="line">epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中</span><br><span class="line"></span><br><span class="line">while(1)&#123;</span><br><span class="line">    int n = epoll_wait(...)</span><br><span class="line">    for(接收到数据的socket)&#123;</span><br><span class="line">        //处理</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>功能分离，使得 epoll 有了优化的可能。</p><h2 id="措施二：就绪列表"><a href="#措施二：就绪列表" class="headerlink" title="措施二：就绪列表"></a>措施二：就绪列表</h2><p>select 低效的另一个原因在于程序不知道哪些 socket 收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的 socket，就能避免遍历。如下图所示，计算机共有三个 socket，收到数据的 sock2 和 sock3 被就绪列表 rdlist 所引用。当进程被唤醒后，只要获取 rdlist 的内容，就能够知道哪些 socket 收到数据。<br><img src="/images/linux-epoll/%E5%B0%B1%E7%BB%AA%E5%88%97%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt><br><em>就绪列表示意图</em></p><h1 id="七、epoll-的原理与工作流程"><a href="#七、epoll-的原理与工作流程" class="headerlink" title="七、epoll 的原理与工作流程"></a>七、epoll 的原理与工作流程</h1><p>本节会以示例和图表来讲解 epoll 的原理和工作流程。</p><h2 id="创建-epoll-对象"><a href="#创建-epoll-对象" class="headerlink" title="创建 epoll 对象"></a>创建 epoll 对象</h2><p>如下图所示，当某个进程调用 epoll_create 方法时，内核会创建一个 eventpoll 对象（也就是程序中 epfd 所代表的对象）。eventpoll 对象也是文件系统中的一员，和 socket 一样，它也会有等待队列。<br><img src="/images/linux-epoll/%E5%86%85%E6%A0%B8%E5%88%9B%E5%BB%BAeventpoll%E5%AF%B9%E8%B1%A1.jpg" alt><br><em>内核创建 eventpoll 对象</em></p><p>创建一个代表该 epoll 的 eventpoll 对象是必须的，因为内核要维护“就绪列表”等数据，“就绪列表”可以作为 eventpoll 的成员。</p><h2 id="维护监视列表"><a href="#维护监视列表" class="headerlink" title="维护监视列表"></a>维护监视列表</h2><p>创建 epoll 对象后，可以用 epoll_ctl 添加或删除所要监听的 socket。以添加 socket 为例，如下图，如果通过 epoll_ctl 添加 sock1、sock2 和 sock3 的监视，内核会将 eventpoll 添加到这三个 socket 的等待队列中。<br><img src="/images/linux-epoll/%E6%B7%BB%E5%8A%A0%E6%89%80%E8%A6%81%E7%9B%91%E5%90%AC%E7%9A%84socket.jpg" alt><br><em>添加所要监听的 socket</em></p><p>当 socket 收到数据后，中断程序会操作 eventpoll 对象，而不是直接操作进程。</p><h2 id="接收数据"><a href="#接收数据" class="headerlink" title="接收数据"></a>接收数据</h2><p>当 socket 收到数据后，中断程序会给 eventpoll 的“就绪列表”添加 socket 引用。如下图展示的是 sock2 和 sock3 收到数据后，中断程序让 rdlist 引用这两个 socket。<br><img src="/images/linux-epoll/%E7%BB%99%E5%B0%B1%E7%BB%AA%E5%88%97%E8%A1%A8%E6%B7%BB%E5%8A%A0%E5%BC%95%E7%94%A8.jpg" alt><br><em>给就绪列表添加引用</em></p><p>eventpoll 对象相当于 socket 和进程之间的中介，socket 的数据接收并不直接影响进程，而是通过改变 eventpoll 的就绪列表来改变进程状态。</p><p>当程序执行到 epoll_wait 时，如果 rdlist 已经引用了 socket，那么 epoll_wait 直接返回，如果 rdlist 为空，阻塞进程。</p><h2 id="阻塞和唤醒进程"><a href="#阻塞和唤醒进程" class="headerlink" title="阻塞和唤醒进程"></a>阻塞和唤醒进程</h2><p>假设计算机中正在运行进程 A 和进程 B，在某时刻进程 A 运行到了 epoll_wait 语句。如下图所示，内核会将进程 A 放入 eventpoll 的等待队列中，阻塞进程。<br><img src="/images/linux-epoll/epoll_wait%E9%98%BB%E5%A1%9E%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>epoll_wait 阻塞进程</em></p><p>当 socket 接收到数据，中断程序一方面修改 rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态（如下图）。也因为 rdlist 的存在，进程 A 可以知道哪些 socket 发生了变化。<br><img src="/images/linux-epoll/epoll%E5%94%A4%E9%86%92%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>epoll 唤醒进程</em></p><h1 id="八、epoll-的实现细节"><a href="#八、epoll-的实现细节" class="headerlink" title="八、epoll 的实现细节"></a>八、epoll 的实现细节</h1><p>至此，相信读者对 epoll 的本质已经有一定的了解。但我们还需要知道 eventpoll 的数据结构是什么样子？</p><p>此外，就绪队列应该应使用什么数据结构？eventpoll 应使用什么数据结构来管理通过 epoll_ctl 添加或删除的 socket？</p><p>如下图所示，eventpoll 包含了 lock、mtx、wq（等待队列）与 rdlist 等成员，其中 rdlist 和 rbr 是我们所关心的。<br><img src="/images/linux-epoll/epoll%E5%8E%9F%E7%90%86%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt><br><em>epoll 原理示意图，图片来源：《深入理解Nginx：模块开发与架构解析(第二版)》，陶辉</em></p><h2 id="就绪列表的数据结构"><a href="#就绪列表的数据结构" class="headerlink" title="就绪列表的数据结构"></a>就绪列表的数据结构</h2><p>就绪列表引用着就绪的 socket，所以它应能够快速的插入数据。</p><p>程序可能随时调用 epoll_ctl 添加监视 socket，也可能随时删除。当删除时，若该 socket 已经存放在就绪列表中，它也应该被移除。所以就绪列表应是一种能够快速插入和删除的数据结构。</p><p>双向链表就是这样一种数据结构，epoll 使用双向链表来实现就绪队列（对应上图的 rdllist）。</p><h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><p>既然 epoll 将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的 socket，至少要方便地添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是O(log(N))，效率较好，epoll 使用了红黑树作为索引结构（对应上图的 rbr）。</p><p>注：因为操作系统要兼顾多种功能，以及由更多需要保存的数据，rdlist 并非直接引用 socket，而是通过 epitem 间接引用，红黑树的节点也是 epitem 对象。同样，文件系统也并非直接引用着 socket。为方便理解，本文中省略了一些间接结构。</p><h1 id="九、小结"><a href="#九、小结" class="headerlink" title="九、小结"></a>九、小结</h1><p>epoll 在 select 和 poll 的基础上引入了 eventpoll 作为中间层，使用了先进的数据结构，是一种高效的多路复用技术。这里也以表格形式简单对比一下 select、poll 与 epoll，结束此文。希望读者能有所收获。</p><p><img src="/images/linux-epoll/%E5%B0%8F%E7%BB%93.jpg" alt></p><p>原文地址：<a href="https://my.oschina.net/editorial-story/blog/3052308" target="_blank" rel="noopener">https://my.oschina.net/editorial-story/blog/3052308</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Epoll </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 原子操作的实现原理</title>
      <link href="/java-atomic-operation-principle.html"/>
      <url>/java-atomic-operation-principle.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文整理自《Java并发编程的艺术》第二章 作者：方腾飞　魏鹏　程晓明</p></blockquote><a id="more"></a><p>原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。让我们一起来聊一聊在Intel处理器和Java里是如何实现原子操作的。</p><h1 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a>术语定义</h1><p>在了解原子操作的实现原理前，先要了解一下相关的术语:</p><style>table th:first-of-type {    width: 100px;}table th:nth-of-type(2) {    width: 150px;}</style><table><thead><tr><th>术语名称</th><th>英文</th><th>解释</th></tr></thead><tbody><tr><td>缓存行</td><td>Cache line</td><td>缓存的最小操作单位</td></tr><tr><td>比较并交换</td><td>Compare and Swap</td><td>CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。</td></tr><tr><td>CPU流水线</td><td>CPU pipeline</td><td>CPU流水线的工作方式就像工业生产上的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度</td></tr><tr><td>内存顺序冲突</td><td>Memory order violation</td><td>内存顺序冲突一般是由假共享引起的，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线</td></tr></tbody></table><h1 id="处理器如何实现原子操作"><a href="#处理器如何实现原子操作" class="headerlink" title="处理器如何实现原子操作"></a>处理器如何实现原子操作</h1><p>32位IA-32处理器使用<font color="DeepPink"><strong>基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作</strong></font>。首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。</p><blockquote><p>在Intel 2019年的文档中，该部分阐述基本不变，具体可以查考文末Intel文档的2957页 8.1 LOCKED ATOMIC OPERATIONS</p></blockquote><h2 id="使用总线锁保证原子性"><a href="#使用总线锁保证原子性" class="headerlink" title="使用总线锁保证原子性"></a>使用总线锁保证原子性</h2><p>第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图2-3所示。</p><p><img src="/images/java-atomic-operation-principle/%E5%9B%BE23.png" alt></p><p>原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。<font color="DeepPink"><strong>所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。</strong></font></p><blockquote><p>Intel文档的2959页 8.1.2 Bus Locking</p></blockquote><h2 id="使用缓存锁保证原子性"><a href="#使用缓存锁保证原子性" class="headerlink" title="使用缓存锁保证原子性"></a>使用缓存锁保证原子性</h2><p>第二个机制是通过缓存锁定来保证原子性。<font color="DeepPink"><strong>在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。</strong></font></p><p>频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。<font color="DeepPink"><strong>所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效</strong></font>，在如图2-3所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能同时缓存i的缓存行。</p><p>但是有两种情况下处理器不会使用缓存锁定：</p><ul><li>第一种情况是：<font color="DeepPink"><strong>当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。</strong></font></li><li>第二种情况是：<font color="DeepPink"><strong>有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。</strong></font>针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。</li></ul><blockquote><p>Intel文档的2961页 8.1.4 Effects of a LOCK Operation on Internal Processor Caches</p></blockquote><h1 id="Java如何实现原子操作"><a href="#Java如何实现原子操作" class="headerlink" title="Java如何实现原子操作"></a>Java如何实现原子操作</h1><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。</p><h2 id="使用循环CAS实现原子操作"><a href="#使用循环CAS实现原子操作" class="headerlink" title="使用循环CAS实现原子操作"></a>使用循环CAS实现原子操作</h2><p>JVM中的CAS操作正是利用了处理器提供的CMPXCHG(Compare and Exchange)指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器方法safeCount和一个非线程安全的计数器count。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">private AtomicInteger atomicI = new AtomicInteger(0);</span><br><span class="line">private int i = 0;</span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">    final Counter cas = new Counter();</span><br><span class="line">    List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600);</span><br><span class="line">    long start = System.currentTimeMillis();</span><br><span class="line">    for (int j = 0; j &lt; 100; j++) &#123;</span><br><span class="line">        Thread t = new Thread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                for (int i = 0; i &lt; 10000; i++) &#123;</span><br><span class="line">                    cas.count();</span><br><span class="line">                    cas.safeCount();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        ts.add(t);</span><br><span class="line">    &#125;</span><br><span class="line">    for (Thread t : ts) &#123;</span><br><span class="line">        t.start();</span><br><span class="line">    &#125;</span><br><span class="line">    // 等待所有线程执行完成</span><br><span class="line">    for (Thread t : ts) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            t.join();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(cas.i);</span><br><span class="line">    System.out.println(cas.atomicI.get());</span><br><span class="line">    System.out.println(System.currentTimeMillis() - start);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 使用CAS实现线程安全计数器</span><br><span class="line"> */</span><br><span class="line">private void safeCount() &#123;</span><br><span class="line">    for (; ; ) &#123;</span><br><span class="line">        int i = atomicI.get();</span><br><span class="line">        boolean suc = atomicI.compareAndSet(i, ++i);</span><br><span class="line">        if (suc) &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 非线程安全计数器</span><br><span class="line"> */</span><br><span class="line">private void count() &#123;</span><br><span class="line">    i++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和自减1。</p><h2 id="CAS实现原子操作的三大问题"><a href="#CAS实现原子操作的三大问题" class="headerlink" title="CAS实现原子操作的三大问题"></a>CAS实现原子操作的三大问题</h2><p>在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如LinkedTransferQueue类的Xfer方法。CAS虽然很高效地解决了原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作。</p><ol><li><font color="DeepPink"><strong>ABA问题</strong></font>。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。<font color="DeepPink"><strong>在变量前面追加上版本号，每次变量更新的时候把版本号加1</strong></font>，那么A→B→A就会变成1A→2B→3A。从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public boolean compareAndSet(</span><br><span class="line">V expectedReference, // 预期引用</span><br><span class="line">V newReference, // 更新后的引用</span><br><span class="line">int expectedStamp, // 预期标志</span><br><span class="line">int newStamp // 更新后的标志</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="2"><li><p><font color="DeepPink"><strong>循环时间长开销大</strong></font>。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而提高CPU的执行效率。</p></li><li><p><font color="DeepPink"><strong>只能保证一个共享变量的原子操作</strong></font>。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p></li></ol><h2 id="使用锁机制实现原子操作"><a href="#使用锁机制实现原子操作" class="headerlink" title="使用锁机制实现原子操作"></a>使用锁机制实现原子操作</h2><p>锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。</p><h1 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h1><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/CPU/Intel®%2064%20and%20IA-32%20architectures%20software%20developer’s%20manual.pdf" target="_blank" rel="noopener">Intel® 64 and IA-32 architectures software developer’s manual</a> </p>]]></content>
      
      
      <categories>
          
          <category> JDK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Concurrent </tag>
            
            <tag> Atomic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里分布式事务解决方案 Fescar 解析</title>
      <link href="/alibaba-seata-design.html"/>
      <url>/alibaba-seata-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>通过Fescar（Seata）了解分布式事务框架设计思路</p></blockquote><a id="more"></a><p>Fescar 是 <strong>阿里巴巴</strong> 开源的 <strong>分布式事务</strong>中间件，以 <strong>高效</strong> 并且对业务 <strong>0 侵入</strong> 的方式，解决 <strong>微服务</strong> 场景下面临的分布式事务问题。</p><h1 id="什么是微服务化带来的分布式事务问题？"><a href="#什么是微服务化带来的分布式事务问题？" class="headerlink" title="什么是微服务化带来的分布式事务问题？"></a>什么是微服务化带来的分布式事务问题？</h1><p>首先，设想一个传统的单体应用（Monolithic App），通过 3 个 Module，在同一个数据源上更新数据来完成一项业务。</p><p>很自然的，整个业务过程的数据一致性由本地事务来保证。</p><p><img src="/images/alibaba-seata-design/monolithic_architecture.png" alt></p><p>随着业务需求和架构的变化，单体应用被拆分为微服务：原来的 3 个 Module 被拆分为 3 个独立的服务，分别使用独立的数据源（<a href="http://microservices.io/patterns/data/database-per-service.html" target="_blank" rel="noopener">Pattern: Database per service</a>）。业务过程将由 3 个服务的调用来完成。</p><p><img src="/images/alibaba-seata-design/microservices_architecture.png" alt></p><p>此时，每一个服务内部的数据一致性仍由本地事务来保证。而整个业务层面的全局数据一致性要如何保障呢？这就是微服务架构下面临的，典型的分布式事务需求：我们需要一个分布式事务的解决方案保障业务全局的数据一致性。</p><p><img src="/images/alibaba-seata-design/fescar_solution.png" alt></p><h1 id="Fescar-的发展历程"><a href="#Fescar-的发展历程" class="headerlink" title="Fescar 的发展历程"></a>Fescar 的发展历程</h1><p>阿里是国内最早一批进行应用分布式（微服务化）改造的企业，所以很早就遇到微服务架构下的分布式事务问题。</p><p>2014 年，阿里中间件团队发布 <strong>TXC（Taobao Transaction Constructor）</strong>，为集团内应用提供分布式事务服务。</p><p>2016 年，TXC 经过产品化改造，以 <strong>GTS（Global Transaction Service）</strong> 的身份登陆阿里云，成为当时业界唯一一款云上分布式事务产品，在阿云里的公有云、专有云解决方案中，开始服务于众多外部客户。</p><p>2019 年起，基于 TXC 和 GTS 的技术积累，阿里中间件团队发起了开源项目 <strong>Fescar（Fast &amp; EaSy Commit And Rollback, FESCAR）</strong>，和社区一起建设这个分布式事务解决方案。</p><p>TXC/GTS/Fescar 一脉相承，为解决微服务架构下的分布式事务问题交出了一份与众不同的答卷。</p><h2 id="设计初衷"><a href="#设计初衷" class="headerlink" title="设计初衷"></a>设计初衷</h2><p>高速增长的互联网时代，<strong>快速试错</strong> 的能力对业务来说是至关重要的：</p><ul><li>一方面，不应该因为技术架构上的微服务化和分布式事务支持的引入，给业务层面带来额外的研发负担。</li><li>另一方面，引入分布式事务支持的业务应该基本保持在同一量级上的性能表现，不能因为事务机制显著拖慢业务。</li></ul><p>基于这两点，我们设计之初的最重要的考量就在于：</p><ul><li><strong>对业务无侵入：</strong> 这里的 <strong>侵入</strong> 是指，因为分布式事务这个技术问题的制约，要求应用在业务层面进行设计和改造。这种设计和改造往往会给应用带来很高的研发和维护成本。我们希望把分布式事务问题在 <strong>中间件</strong> 这个层次解决掉，不要求应用在业务层面做额外的工作。</li><li><strong>高性能：</strong> 引入分布式事务的保障，必然会有额外的开销，引起性能的下降。我们希望把分布式事务引入的性能损耗降到非常低的水平，让应用不因为分布式事务的引入导致业务的可用性受影响。</li></ul><h2 id="既有的解决方案为什么不满足？"><a href="#既有的解决方案为什么不满足？" class="headerlink" title="既有的解决方案为什么不满足？"></a>既有的解决方案为什么不满足？</h2><p>既有的分布式事务解决方案按照对业务侵入性分为两类，即：对业务无侵入的和对业务有侵入的。</p><h3 id="业务无侵入的方案"><a href="#业务无侵入的方案" class="headerlink" title="业务无侵入的方案"></a>业务无侵入的方案</h3><p>既有的主流分布式事务解决方案中，对业务无侵入的只有基于 XA 的方案，但应用 XA 方案存在 3 个方面的问题：</p><ol><li>要求数据库提供对 XA 的支持。如果遇到不支持 XA（或支持得不好，比如 MySQL 5.7 以前的版本）的数据库，则不能使用。</li><li>受协议本身的约束，事务资源（数据记录、数据库连接）的锁定周期长。长周期的资源锁定从业务层面来看，往往是不必要的，而因为事务资源的管理器是数据库本身，应用层无法插手。这样形成的局面就是，基于 XA 的应用往往性能会比较差，而且很难优化。</li><li>已经落地的基于 XA 的分布式解决方案，都依托于重量级的应用服务器（Tuxedo/WebLogic/WebSphere 等)，这是不适用于微服务架构的。</li></ol><h3 id="侵入业务的方案"><a href="#侵入业务的方案" class="headerlink" title="侵入业务的方案"></a>侵入业务的方案</h3><p>实际上，最初分布式事务只有 XA 这个唯一方案。XA 是完备的，但在实践过程中，由于种种原因（包含但不限于上面提到的 3 点）往往不得不放弃，转而从业务层面着手来解决分布式事务问题。比如：</p><ul><li>基于可靠消息的最终一致性方案</li><li>TCC</li><li>Saga </li></ul><p>都属于这一类。这些方案的具体机制在这里不做展开，网上这方面的论述文章非常多。总之，这些方案都要求在应用的业务层面把分布式事务技术约束考虑到设计中，通常每一个服务都需要设计实现正向和反向的幂等接口。这样的设计约束，往往会导致很高的研发和维护成本。</p><h2 id="理想的方案应该是什么样子？"><a href="#理想的方案应该是什么样子？" class="headerlink" title="理想的方案应该是什么样子？"></a>理想的方案应该是什么样子？</h2><p>不可否认，侵入业务的分布式事务方案都经过大量实践验证，能有效解决问题，在各行各业的业务应用系统中起着重要作用。但回到原点来思考，这些方案的采用实际上都是 <strong>迫于无奈</strong>。设想，如果基于 XA 的方案能够不那么 <strong>重</strong>，并且能保证业务的性能需求，相信不会有人愿意把分布式事务问题拿到业务层面来解决。</p><p>一个理想的分布式事务解决方案应该：像使用 <strong>本地事务</strong> 一样简单，业务逻辑只关注业务层面的需求，不需要考虑事务机制上的约束。</p><h1 id="原理和设计"><a href="#原理和设计" class="headerlink" title="原理和设计"></a>原理和设计</h1><p>我们要设计一个对业务无侵入的方案，所以从业务无侵入的 XA 方案来思考：</p><p>是否可以在 XA 的基础上演进，解决掉 XA 方案面临的问题呢？</p><h2 id="如何定义一个分布式事务？"><a href="#如何定义一个分布式事务？" class="headerlink" title="如何定义一个分布式事务？"></a>如何定义一个分布式事务？</h2><p>首先，很自然的，我们可以把一个分布式事务理解成一个包含了若干 <strong>分支事务</strong> 的 <strong>全局事务</strong>。<strong>全局事务</strong> 的职责是协调其下管辖的 <strong>分支事务</strong> 达成一致，要么一起成功提交，要么一起失败回滚。此外，通常 <strong>分支事务</strong> 本身就是一个满足 ACID 的 <strong>本地事务</strong>。这是我们对分布式事务结构的基本认识，与 XA 是一致的。</p><p><img src="/images/alibaba-seata-design/global_branch_transaction.png" alt></p><p>其次，与 XA 的模型类似，我们定义 3 个组件来协议分布式事务的处理过程。</p><p><img src="/images/alibaba-seata-design/fescar_model.png" alt></p><ul><li><strong>Transaction Coordinator (TC)：</strong> 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。</li><li><strong>Transaction Manager (TM)：</strong> 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。</li><li><strong>Resource Manager (RM)：</strong> 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。</li></ul><p>一个典型的分布式事务过程：</p><ol><li>TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID。</li><li>XID 在微服务调用链路的上下文中传播。</li><li>RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖。 </li><li>TM 向 TC 发起针对 XID 的全局提交或回滚决议。</li><li>TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</li></ol><p><img src="/images/alibaba-seata-design/architecture.png" alt></p><p>至此，Fescar 的协议机制总体上看与 XA 是一致的。</p><h3 id="与-XA-的差别在什么地方？"><a href="#与-XA-的差别在什么地方？" class="headerlink" title="与 XA 的差别在什么地方？"></a>与 XA 的差别在什么地方？</h3><h4 id="架构层次"><a href="#架构层次" class="headerlink" title="架构层次"></a>架构层次</h4><p><img src="/images/alibaba-seata-design/rm_in_architecture.png" alt></p><p>XA 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身（通过提供支持 XA 的驱动程序来供应用使用）。</p><p>而 <font color="DeepPink"><strong>Fescar 的 RM 是以二方包的形式作为中间件层部署在应用程序这一侧的，不依赖与数据库本身对协议的支持，当然也不需要数据库支持 XA 协议。</strong></font>这点对于微服务化的架构来说是非常重要的：应用层不需要为本地事务和分布式事务两类不同场景来适配两套不同的数据库驱动。</p><p>这个设计，剥离了分布式事务方案对数据库在 <strong>协议支持</strong> 上的要求。</p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p>先来看一下 XA 的 2PC 过程。</p><p><img src="/images/alibaba-seata-design/xa_2pc.png" alt></p><p>无论 Phase2 的决议是 commit 还是 rollback，事务性资源的锁都要保持到 Phase2 完成才释放。</p><p>设想一个正常运行的业务，大概率是 90% 以上的事务最终应该是成功提交的，我们是否可以在 Phase1 就将本地事务提交呢？这样 90% 以上的情况下，可以省去 Phase2 持锁的时间，整体提高效率。</p><p><img src="/images/alibaba-seata-design/seata_2pc.png" alt></p><ul><li>分支事务中数据的 <strong>本地锁</strong> 由本地事务管理，在分支事务 Phase1 结束时释放。</li><li>同时，随着本地事务结束，<strong>连接</strong> 也得以释放。</li><li>分支事务中数据的 <strong>全局锁</strong> 在事务协调器侧管理，在决议 Phase2 全局提交时，全局锁马上可以释放。只有在决议全局回滚的情况下，<strong>全局锁</strong> 才被持有至分支的 Phase2 结束。</li></ul><p>这个设计，极大地减少了分支事务对资源（数据和连接）的锁定时间，给整体并发和吞吐的提升提供了基础。</p><p>当然，你肯定会问：Phase1 即提交的情况下，Phase2 如何回滚呢？</p><h2 id="分支事务如何提交和回滚？"><a href="#分支事务如何提交和回滚？" class="headerlink" title="分支事务如何提交和回滚？"></a>分支事务如何提交和回滚？</h2><p>首先，<font color="DeepPink"><strong>应用需要使用 Fescar 的 JDBC 数据源代理，也就是 Fescar 的 RM。</strong></font></p><p><img src="/images/alibaba-seata-design/data_sourc_proxy.png" alt></p><p><strong>Phase1：</strong></p><p><font color="DeepPink">Fescar 的 JDBC 数据源代理通过对业务 SQL 的解析，把业务数据在更新前后的数据镜像组织成回滚日志，利用 <strong>本地事务</strong> 的 ACID 特性，将业务数据的更新和回滚日志的写入在同一个 <strong>本地事务</strong> 中提交。</font></p><p>这样，可以保证：<font color="DeepPink"><strong>任何提交的业务数据的更新一定有相应的回滚日志存在。</strong></font></p><p><img src="/images/alibaba-seata-design/branch_transaction_with_undo_log.png" alt></p><p>基于这样的机制，分支的本地事务便可以在全局事务的 Phase1 提交，马上释放本地事务锁定的资源。</p><p><strong>Phase2：</strong></p><ul><li><font color="DeepPink"><strong>如果决议是全局提交，此时分支事务此时已经完成提交，不需要同步协调处理（只需要异步清理回滚日志），Phase2 可以非常快速地完成。</strong></font></li></ul><p><img src="/images/alibaba-seata-design/global_commit.png" alt></p><ul><li><font color="DeepPink"><strong>如果决议是全局回滚，RM 收到协调器发来的回滚请求，通过 XID 和 Branch ID 找到相应的回滚日志记录，通过回滚记录生成反向的更新 SQL 并执行，以完成分支的回滚。</strong></font></li></ul><p><img src="/images/alibaba-seata-design/global_rollback.png" alt></p><h2 id="事务传播机制"><a href="#事务传播机制" class="headerlink" title="事务传播机制"></a>事务传播机制</h2><p>XID 是一个全局事务的唯一标识，事务传播机制要做的就是把 XID 在服务调用链路中传递下去，并绑定到服务的事务上下文中，这样，服务链路中的数据库更新操作，就都会向该 XID 代表的全局事务注册分支，纳入同一个全局事务的管辖。</p><p>基于这个机制，Fescar 是可以支持任何微服务 RPC 框架的。只要在特定框架中找到可以透明传播 XID 的机制即可，比如，Dubbo 的 Filter + RpcContext。</p><p>对应到 Java EE 规范和 Spring 定义的事务传播属性，Fescar 的支持如下：</p><ul><li><strong>PROPAGATION_REQUIRED：</strong> 默认支持</li><li><strong>PROPAGATION_SUPPORTS：</strong> 默认支持</li><li>PROPAGATION_MANDATORY：应用通过 API 来实现</li><li>PROPAGATION_REQUIRES_NEW：应用通过 API 来实现</li><li>PROPAGATION_NOT_SUPPORTED：应用通过 API 来实现</li><li>PROPAGATION_NEVER：应用通过 API 来实现</li><li>PROPAGATION_NESTED：不支持</li></ul><h2 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h2><p>全局事务的隔离性是建立在分支事务的本地隔离级别基础之上的。</p><p>在数据库本地隔离级别 <strong>读已提交</strong> 或以上的前提下，Fescar 设计了由事务协调器维护的 <strong>全局写排他锁</strong>，来保证事务间的 <strong>写隔离</strong>，将全局事务默认定义在 <strong>读未提交</strong> 的隔离级别上。</p><p>我们对隔离级别的共识是：微服务场景产生的分布式事务，绝大部分应用在 <strong>读已提交</strong> 的隔离级别下工作是没有问题的。而实际上，这当中又有绝大多数的应用场景，实际上工作在 <strong>读未提交</strong> 的隔离级别下同样没有问题。</p><p>在极端场景下，应用如果需要达到全局的 <strong>读已提交</strong>，Fescar 也提供了相应的机制来达到目的。默认，Fescar 是工作在 <strong>读未提交</strong> 的隔离级别下，保证绝大多数场景的高效性。</p><p><img src="/images/alibaba-seata-design/isolation.png" alt><br>事务的 ACID 属性在 Fescar 中的体现是一个比较复杂的话题，我们会有专门的文章来深入分析，这里不做进一步展开。</p><h1 id="适用场景分析"><a href="#适用场景分析" class="headerlink" title="适用场景分析"></a>适用场景分析</h1><p>前文所述的 <font color="DeepPink">Fescar 的核心原理中有一个 <strong>重要前提</strong>：分支事务中涉及的资源，<strong>必须</strong> 是支持 <strong>ACID 事务</strong>的 <strong>关系型数据库</strong>。分支的提交和回滚机制，都依赖于本地事务的保障。所以，如果应用使用的数据库是不支持事务的，或根本不是关系型数据库，就不适用。</font></p><p>另外，目前 Fescar 的实现还存在一些局限，比如：事务隔离级别最高支持到 <strong>读已提交</strong> 的水平，SQL 的解析还不能涵盖全部的语法等。</p><p>为了覆盖 Fescar 原生机制暂时不能支持应用场景，我们定义了另外一种工作模式。</p><p>上面介绍的 Fescar 原生工作模式称为 AT（Automatic Transaction）模式，这种模式是对业务无侵入的。与之相应的另外一种工作模式称为 MT（Manual Transaction）模式，这种模式下，分支事务需要应用自己来定义业务本身及提交和回滚的逻辑。</p><h2 id="分支的基本行为模式"><a href="#分支的基本行为模式" class="headerlink" title="分支的基本行为模式"></a>分支的基本行为模式</h2><p>作为全局事务一部分的分支事务，除本身的业务逻辑外，都包含 4 个与协调器交互的行为：</p><ul><li><strong>分支注册：</strong> 在分支事务的数据操作进行之前，需要向协调器注册，把即将进行的分支事务数据操作，纳入一个已经开启的全局事务的管理中去，在分支注册成功后，才可以进行数据操作。</li><li><strong>状态上报：</strong> 在分支事务的数据操作完成后，需要向事务协调器上报其执行结果。</li><li><strong>分支提交</strong>：响应协调器发出的分支事务提交的请求，完成分支提交。</li><li><strong>分支回滚</strong>：响应协调器发出的分支事务回滚的请求，完成分支回滚。</li></ul><p><img src="/images/alibaba-seata-design/how_does_rm_talk_to_tc.png" alt></p><h2 id="AT-模式分支的行为模式"><a href="#AT-模式分支的行为模式" class="headerlink" title="AT 模式分支的行为模式"></a>AT 模式分支的行为模式</h2><p>业务逻辑不需要关注事务机制，分支与全局事务的交互过程自动进行。</p><p><img src="/images/alibaba-seata-design/at_branch.png" alt></p><h2 id="MT-模式分支的行为模式"><a href="#MT-模式分支的行为模式" class="headerlink" title="MT 模式分支的行为模式"></a>MT 模式分支的行为模式</h2><p>业务逻辑需要被分解为 Prepare/Commit/Rollback 3 部分，形成一个 MT 分支，加入全局事务。</p><p><img src="/images/alibaba-seata-design/mt_branch.png" alt></p><p>MT 模式一方面是 AT 模式的补充。另外，更重要的价值在于，通过 MT 模式可以把众多非事务性资源纳入全局事务的管理中。</p><h2 id="混合模式"><a href="#混合模式" class="headerlink" title="混合模式"></a>混合模式</h2><p>因为 AT 和 MT 模式的分支从根本上行为模式是一致的，所以可以完全兼容，即，一个全局事务中，可以同时存在 AT 和 MT 的分支。这样就可以达到全面覆盖业务场景的目的：AT 模式可以支持的，使用 AT 模式；AT 模式暂时支持不了的，用 MT 模式来替代。另外，自然的，MT 模式管理的非事务性资源也可以和支持事务的关系型数据库资源一起，纳入同一个分布式事务的管理中。</p><h2 id="应用场景的远景"><a href="#应用场景的远景" class="headerlink" title="应用场景的远景"></a>应用场景的远景</h2><p>回到我们设计的初衷：一个理想的分布式事务解决方案是不应该侵入业务的。MT 模式是在 AT 模式暂时不能完全覆盖所有场景的情况下，一个比较自然的补充方案。我们希望通过 AT 模式的不断演进增强，逐步扩大所支持的场景，MT 模式逐步收敛。未来，我们会纳入对 XA 的原生支持，用 XA 这种无侵入的方式来覆盖 AT 模式无法触达的场景。</p><p><img src="/images/alibaba-seata-design/roadmap_of_transaction_mode.png" alt></p><h1 id="扩展点"><a href="#扩展点" class="headerlink" title="扩展点"></a>扩展点</h1><h2 id="微服务框架的支持"><a href="#微服务框架的支持" class="headerlink" title="微服务框架的支持"></a>微服务框架的支持</h2><p>事务上下文在微服务间的传播需要根据微服务框架本身的机制，订制最优的，对应用层透明的解决方案。有兴趣在这方面共建的开发者可以参考内置的对 Dubbo 的支持方案，来实现对其他微服务框架的支持。</p><h2 id="所支持的数据库类型"><a href="#所支持的数据库类型" class="headerlink" title="所支持的数据库类型"></a>所支持的数据库类型</h2><p>因为 AT 涉及 SQL 的解析，所以在不同类型的数据库上工作，会有一些特定的适配。有兴趣在这方面共建的开发者可以参考内置的对 MySQL 的支持方案，来实现对其他数据库的支持。</p><h2 id="配置和服务注册发现"><a href="#配置和服务注册发现" class="headerlink" title="配置和服务注册发现"></a>配置和服务注册发现</h2><p>支持接入不同的配置和服务注册发现解决方案。比如：Nacos、Eureka、ZooKeeper 等。</p><h2 id="MT-模式的场景拓展"><a href="#MT-模式的场景拓展" class="headerlink" title="MT 模式的场景拓展"></a>MT 模式的场景拓展</h2><p>MT 模式的一个重要作用就是，可以把非关系型数据库的资源，通过 MT 模式分支的包装，纳入到全局事务的管辖中来。比如，Redis、HBase、RocketMQ 的事务消息等。有兴趣在这方面共建的开发者可以在这里贡献一系列相关生态的适配方案。</p><h2 id="事务协调器的分布式高可用方案"><a href="#事务协调器的分布式高可用方案" class="headerlink" title="事务协调器的分布式高可用方案"></a>事务协调器的分布式高可用方案</h2><p>针对不同场景，支持不同的方式作为事务协调器 Server 端的高可用方案。比如，针对事务状态的持久化，可以是基于文件的实现方案，也可以是基于数据库的实现方案；集群间的状态同步，可以是基于 RPC 通信的方案，也可以是基于高可用 KV 存储的方案。</p><h1 id="Roadmap"><a href="#Roadmap" class="headerlink" title="Roadmap"></a>Roadmap</h1><h2 id="Lanscape"><a href="#Lanscape" class="headerlink" title="Lanscape"></a>Lanscape</h2><p><img src="/images/alibaba-seata-design/landscape.png" alt></p><p><strong>The green</strong> part is already open sourced, <strong>the yellow</strong> part will open source by Alibaba/AntFinancial, <strong>the blue</strong> part we want co-building with out community:</p><ul><li>Developers can refer to Seata implementation of MySQL support if you want to support different databases transaction</li><li>Developers can refer to Seata implementation of Dubbo support if you want to support different microservices</li><li>Developers can refer to Seata implementation of TCC support if you want to support different data source(such as MQ, NoSQL)</li><li>Developers can refer to Seata implementation of TCC support if you want to support different data source(such as MQ, NoSQL)</li><li>Developers can easily support configuration/registry services with just a little work</li><li><strong>The blue</strong> part is warmly welcome you, join it and contribute excellent solution</li><li>We will support XA which is the standard of distributed transaction in our product roadmap</li></ul><h2 id="Roadmap-1"><a href="#Roadmap-1" class="headerlink" title="Roadmap"></a>Roadmap</h2><h3 id="v0-1-0"><a href="#v0-1-0" class="headerlink" title="v0.1.0"></a>v0.1.0</h3><ul><li>Microservice framework support: Dubbo</li><li>Database support: MySQL</li><li>Spring AOP annotation Support</li><li>Transaction coordinator: Stand-alone Server</li></ul><h3 id="v0-5-x"><a href="#v0-5-x" class="headerlink" title="v0.5.x"></a>v0.5.x</h3><ul><li>Rename Fescar to Seata</li><li>Microservice framework support: SOFA, Spring Cloud</li><li>Support TCC(Try Confirm Cancel) transaction mode</li><li>Dynamic configuration</li><li>Services discovery</li></ul><h3 id="v0-6-x"><a href="#v0-6-x" class="headerlink" title="v0.6.x"></a>v0.6.x</h3><ul><li>Transaction coordinator: Cluster Server with HA</li></ul><h3 id="v0-8-x"><a href="#v0-8-x" class="headerlink" title="v0.8.x"></a>v0.8.x</h3><ul><li>Promethus support</li><li>Management console: Monitor, Deployment, Upgrating, etc.</li></ul><h3 id="v1-0-0"><a href="#v1-0-0" class="headerlink" title="v1.0.0"></a>v1.0.0</h3><ul><li>Production ready</li></ul><h3 id="v1-5-x"><a href="#v1-5-x" class="headerlink" title="v1.5.x"></a>v1.5.x</h3><ul><li>Database support: Oracle, PostgreSQL, OceanBase</li><li>Optimization of conflict datas</li><li>Independent of Spring Annotation</li><li>Multiple source of data transaction support: MessageQueue(RocketMQ), HBase, Redis, etc.</li></ul><h3 id="v2-0-0"><a href="#v2-0-0" class="headerlink" title="v2.0.0"></a>v2.0.0</h3><ul><li>XA transaction mode support</li></ul><p>当然，项目迭代演进的过程，我们最重视的是社区的声音，路线图会和社区充分交流及时进行调整。</p><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><ul><li><a href="https://github.com/alibaba/fescar" target="_blank" rel="noopener">FESCAR on GitHub</a></li><li><a href="https://help.aliyun.com/product/48444.html?spm=5176.doc55547.3.1.Gg1hcs" target="_blank" rel="noopener">GTS on Aliyun</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Architecture </tag>
            
            <tag> Fescar </tag>
            
            <tag> Seata </tag>
            
            <tag> Distributed </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>异地多活高可用架构设计</title>
      <link href="/multi-live-high-available-architecture-design.html"/>
      <url>/multi-live-high-available-architecture-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>如何构建应用的异地多活？</p></blockquote><a id="more"></a><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>随着业务的快速发展，对于很多公司来说，构建于单地域的技术体系架构，会面临诸如下面的多种问题：基础设施的有限性限制了业务的可扩展性；机房、城市级别的故障灾害，影响服务的可持续性。</p><p>为解决遇到的这些问题，公司可以选择构建异地多活架构，在同城/异地构建多个单元(业务中心)。各个业务单元可以分布在不同的地域，从而有效解决了单地域部署带来的基础设施的扩展限制、服务可持续性。</p><p>异地多活是近几年比较热门的一个话题，那么在实际业务中什么时候需要去做这件事？如何去做？做的时候需要考虑什么？</p><h2 id="何时去做？"><a href="#何时去做？" class="headerlink" title="何时去做？"></a>何时去做？</h2><p>个人感觉取决于以下几个方面：</p><ul><li>业务发展</li><li>基础设施状况</li><li>技术积淀</li></ul><h2 id="如何做？"><a href="#如何做？" class="headerlink" title="如何做？"></a>如何做？</h2><p>目前在网上搜索到的异地多活方案来看，基本都是阿里、饿了么、京东、微博这些互联网大厂的实践，这些大厂的方案有一个共同点就是：大量的自研组件，来做相关的数据同步，业务切分等等，那么，对于很多传统企业或者相对小一些的企业，应该如何来做这件事？</p><ul><li>根据业务特性借助合适的公有云服务</li></ul><h2 id="做的时候，需要注意什么？"><a href="#做的时候，需要注意什么？" class="headerlink" title="做的时候，需要注意什么？"></a>做的时候，需要注意什么？</h2><ul><li>真正需要做异地多活的业务有哪些？</li><li>基础设施如何？</li><li>对于不可用时间的容忍程度是多少？</li></ul><h1 id="业务背景"><a href="#业务背景" class="headerlink" title="业务背景"></a>业务背景</h1><ul><li>在所有的系统中用户中心都是核心业务，因为它是进入其它很多业务前提。</li><li>我们这边IDC不是很稳定，之前发生过几次机房大规模故障，比如机房网络挂了，整个机房对外不可用了。</li></ul><p>以上两点是我们这次要做用户中心异地容灾的出发点，以便在面对机房级别故障时，保证服务可用性。</p><h1 id="业务梳理"><a href="#业务梳理" class="headerlink" title="业务梳理"></a>业务梳理</h1><p>用户中心从整体来看，对外主要提供：注册、登陆、查询用户信息等服务。这些服务又有以下几个特点：</p><ul><li>登陆的优先级最高</li><li>事务性要求低</li></ul><p>涉及的公共组件主要有：</p><ul><li>MySQL：用户数据存储</li><li>Redis：Authorization Code、短信验证码、账号锁定、access token等的存储</li><li>Zookeeper：Dubbo依赖</li></ul><h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><p>用户中心是通过外包的形式进行开发的，目前已上线并交付给另一个外包商运维，所以在考虑容灾一期方案的时候，需要考虑尽量不动代码。</p><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><h3 id="一期目标"><a href="#一期目标" class="headerlink" title="一期目标"></a>一期目标</h3><p>当北京机房出现故障的时候，可以一定时间内把流量切到青岛机房这边，保证用户中心核心服务的基本可用。</p><h3 id="二期目标"><a href="#二期目标" class="headerlink" title="二期目标"></a>二期目标</h3><p>用户中心通过异地多活，实现高可用（需要集团智能DNS支持）。</p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h3 id="一期架构"><a href="#一期架构" class="headerlink" title="一期架构"></a>一期架构</h3><p>当北京机房发生故障的时候，可以把流量快速切换到青岛这边，以保障用户中心核心服务可用。</p><p>具体方案如下：</p><ul><li>通过otter近实时的将北京机房核心业务数据同步到青岛机房。</li><li>青岛机房部署Redis、ZooKeeper等中间件。</li><li>青岛机房部署用户中心的核心应用（实例正常部署、运行，只是平时不会有访问）。</li></ul><p>具体架构如下：<br><img src="/images/multi-live-high-available-architecture-design/%E4%B8%80%E6%9C%9F%E6%9E%B6%E6%9E%84.png" alt></p><p>可以达到的效果：</p><ul><li>当北京机房出现故障的时候，可以在一定时间内把流量切到青岛机房这边，保证用户中心核心服务的基本可用，但此时已登录用户需要重新登录。</li><li>一定时间：取决于DNS修改ip时间+DNS TTL时间，目前来看TTL是10分钟，人工修改ip应该很快，所以一定时间是10~20分钟。</li></ul><p>存在的缺点：</p><ul><li>北京机房非故障期间，青岛机房的机器，仅做数据库同步，存在一定的资源浪费。</li><li>当北京机房出现故障，流量切换到青岛机房后，只能保证登陆这一核心服务的可用。对于注册等需要修改数据库的服务，均不支持，如果在此期间访问这类服务，会发生异常。</li></ul><h3 id="二期架构"><a href="#二期架构" class="headerlink" title="二期架构"></a>二期架构</h3><p>二期的目的就是修正一期架构的缺点，通过异地多活，实现高可用。</p><p>二期青岛机房会替换为阿里云机房。</p><p>具体方案如下：</p><ul><li>通过阿里云DTS服务实现两地机房数据库同步，保证北京、阿里云数据的近实时一致性。</li><li>北京、阿里云两地机房均提供在线服务，提高资源利用率。</li><li>梳理服务优先级，修改应用代码，支持服务降级。</li><li>当某个机房（阿里云或者北京）出现故障的时候，通过DNS服务把流量切换到另一个机房。<ul><li>如果两地部署的时候，没有冗余一定硬件资源，则需要实施服务降级。</li><li>目前集团DNS解析，无法提供自动检测服务是否可用的功能，也就无法自动进行切换。<ul><li>服务可用性，可以通过我们这边的多点拨测进行监控，当多点拨测不可用的时候，发送告警通知给相关人员，以便人工介入。</li><li>多点拨测告警，应该会提供两类：1、某个拨测点不通的时候 2、所有拨测点均不可用的时候。</li></ul></li><li>目前集团DNS解析，TTL生效最短时间是10分钟，无法自定义TTL时间。</li></ul></li></ul><p>具体架构如下：<br><img src="/images/multi-live-high-available-architecture-design/%E4%BA%8C%E6%9C%9F%E6%9E%B6%E6%9E%84%E6%99%BA%E8%83%BDDNS.png" alt></p><p>可以达到的效果：</p><ul><li><p>如果集团DNS可以提供，类似阿里云云解析的网站监控功能并能灵活设置TTL时间，这时当北京机房或者阿里云机房出现故障后，就可以在很短的时间（部分服务最大异常时间）内自动进行流量切换。</p><blockquote><p>此处只是以阿里云云解析示例，只要能提供类似的服务均可。</p></blockquote></li><li><p>如果集团DNS无法提供类似阿里云云解析的网站监控及灵活设置TTL时间的功能，则部分服务最大异常时间还是取决于DNS修改ip时间+DNS TTL时间。</p></li></ul><h4 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h4><h5 id="什么是网站监控？"><a href="#什么是网站监控？" class="headerlink" title="什么是网站监控？"></a>什么是网站监控？</h5><p>HTTP/HTTPS实时探测域名解析记录，支持自定义端口，实时发现宕机立即告警；<br>全网分布式监控，在中国各个地区模拟用户端真实请求，监控结果真实可靠；<br>支持宕机暂停、容灾切换，最大限度的解决服务中断对您的业务带来的损失；<br>容灾切换支持A记录、CNAME域名，满足各种场景的容灾切换需求；</p><h5 id="什么情况会被网站监控判断为宕机并发送告警通知？"><a href="#什么情况会被网站监控判断为宕机并发送告警通知？" class="headerlink" title="什么情况会被网站监控判断为宕机并发送告警通知？"></a>什么情况会被网站监控判断为宕机并发送告警通知？</h5><p>监控结果中，HTTP/HTTPS的返回码大于500的服务器错误情况，才会报警通知。<br>举例说明：如果设置了四个探测点 北京联通、深圳阿里巴巴、上海电信、重庆联通。<br>场景一：四个探测点中50%的监控点无法收到您服务器的响应，或50%的监控点收到返回码大于等于500时，才会判断您的网站为宕机情况。<br>场景二：四个探测点中有50%以上的探测点探测您的网站返回码是小于500的情况，则不会判断您的网站为宕机。</p><h5 id="云解析DNS“流量管理”"><a href="#云解析DNS“流量管理”" class="headerlink" title="云解析DNS“流量管理”"></a>云解析DNS“流量管理”</h5><p>云解析“流量管理”可以在您设置的每条解析线路下，根据权重比例轮询返回解析结果。当线路下的IP宕机时可以通过监控自动发现，并将宕机IP从当前线路下摘除，直到监控IP正常时会恢复解析。同时，当一条解析线路下的所有IP都宕机时，可以切换至其他正常线路。最大程度保证您的网站服务高可用，减小损失。</p><h5 id="部分服务最大异常时间"><a href="#部分服务最大异常时间" class="headerlink" title="部分服务最大异常时间"></a>部分服务最大异常时间</h5><p>比如北京机房出现异常，这时转发到阿里云机房的流量是可以正常访问，只有转发到北京机房的流量是异常的。</p><p>这时如果使用网站监控或者类似服务，进行监控，并设置拨测间隔为1分钟，TTL生效时间为1秒，那么最多有60+1秒部分服务异常时间，之后DNS会自动把北京机房的ip自动踢掉，流量全部切到阿里云。</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ol><li><p>一期、二期方案的实现均强依赖于集团的DNS服务</p></li><li><p>用户中心通过ip暴露的服务，一但出现机房级别的故障，一期、二期方案均无法保证该部分服务可用。</p></li><li><p>其实除了DNS这种方案，还有一种方案就是用类似F5这种设备，作跨机房负载，但必须是gslb，而且两端必须是相同的设备。</p></li></ol><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>对于，非一线互联网大厂的公司而言，是实现异地容灾的时候，借助公有云是很有必要的，比如：</p><ul><li><p>数据跨机房同步，可以使用阿里云的DTS(Data Transmission Service) 服务，目前DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。<br><img src="/images/multi-live-high-available-architecture-design/%E9%98%BF%E9%87%8C%E4%BA%91DTS%E6%9C%8D%E5%8A%A1.jpg" alt></p></li><li><p>跨机房分布式数据库，可以使用OceanBase。金融环境下通常对数据可靠性有更高的要求，OceanBase每一次事务提交，对应日志总是会在多个数据中心实时同步，并持久化。即使是数据中心级别的灾难发生，总是可以在其他的数据中心恢复每一笔已经完成的交易，实现了真正金融级别的可靠性要求。</p></li><li><p>异地多活由于各个公司的业务、基础设施及要解决的问题皆不尽相同，所以选择适合自己的就好。</p></li><li><p>或者直接使用云数据库RDS MySQL 版<br><img src="/images/multi-live-high-available-architecture-design/%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%89%88.png" alt></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> Multi-Live </tag>
            
            <tag> High-Available </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Otter数据一致性</title>
      <link href="/otter-data-consistency.html"/>
      <url>/otter-data-consistency.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Otter数据一致性实现思路分析</p></blockquote><a id="more"></a><h1 id="技术选型分析"><a href="#技术选型分析" class="headerlink" title="技术选型分析"></a>技术选型分析</h1><p>需要处理一致性的业务场景：</p><ul><li>多地修改 (双A机房)</li><li>同一记录，同时变更</li></ul><p>同一记录定义：具体到某一张表，某一条pk，某一字段</p><p>同时变更定义：A地写入的数据在B地还未可见的一段时间范围</p><p>基本思路</p><ul><li>事前控制：比如paoxs协议，在多地数据写入各自数据存储之前，就已经决定好最后保留哪条记录</li><li>事后处理：指A/B两地修改的数据，已经保存到数据库之后，通过数据同步后保证两数据的一致性</li></ul><h1 id="事前控制"><a href="#事前控制" class="headerlink" title="事前控制"></a>事前控制</h1><p>paxos协议，相信大家研究的人也比较多，但是它有一些局限性，就拿zookeeper来说，它使用了paxos的一个变种，但基本原理还是相似的。</p><p>我们拿zookeeper的几种部署模式来看：</p><h2 id="1-先看：-A地部署leader-follower集群，B地部署observer"><a href="#1-先看：-A地部署leader-follower集群，B地部署observer" class="headerlink" title="1. 先看： A地部署leader/follower集群，B地部署observer."></a>1. 先看： A地部署leader/follower集群，B地部署observer.</h2><p>此时A地收到数据后，需要的网络操作基本为同机房的leader/follower的paxos协议，耗时基本可控</p><p>此时B地收到数据后，需要的网络操作为：</p><ul><li>B地接收到请求，转发给A地，一次机房网络</li><li>地接收到请求，由leader转发给follower进行投票决策，同机房网络</li><li>A地leader将投票的结构，反馈给B地，一次机房网络.</li></ul><p>这样一来，也就是说，事务时间 = 一次异地机房RTT + 同机房paxos算法耗时. 比如中美网络延迟200ms，那事务时间基本就是200ms+ 。 但此时，B地机房基本是一个只读镜像，读数据也有延迟，其系统写扩展性全在A机房，某一天当A机房不够用时，A机房进行拆分，就会遇到下一个问题。</p><h2 id="2-再看：A地和B地组成leader-follower"><a href="#2-再看：A地和B地组成leader-follower" class="headerlink" title="2. 再看：A地和B地组成leader/follower"></a>2. 再看：A地和B地组成leader/follower</h2><p>此时A地收到数据后，需要的网络操作为：(假如A不是leader，B是leader)</p><ul><li>首先需要发送数据到B，一次机房网络</li><li>B收到A的提议数据后，发起一个投票到A，一次机房网络</li><li>A收到提议后，返回一个投票结果到B，一次机房网络</li><li>B收到大部分投票结果，做出决定之后，将结果反馈给A，一次网络交互.</li></ul><p>这种理想无冲突的情况，总共会有2次RTT，如果优化A发起的提议自己默认投票，不返回给A进行投票，可以优化为1次RTT. 针对中美网络延迟200ms，那事务时间基本是200ms+. 如果A地和B地同时写入，那事务时间可能会翻倍。</p><p>总结：如果你能接受事务时间的影响(比如你A地和B地的网络延迟只有10ms)，那是可以考虑选择paxos协议. 但目前otter所要解决的需求为中美200ms的RTT，暂时无法接收paxos协议来解决一致性问题.</p><h1 id="事后处理"><a href="#事后处理" class="headerlink" title="事后处理"></a>事后处理</h1><p><font color="DeepPink"><strong>针对事后处理，不管哪种方案，一定会是一个最终一致性，因为在你做处理前，A地和B地的数据内容已经不一致了，你不论选择任何一个版本，对另一边来说都是一个数据版本丢失，最终一致性。</strong></font></p><p>针对数据最终一致性处理，GoldenGate文档中提到了几种case :</p><ul><li>trusted source. 信任站点，数据出现冲突时，永远以某一边为准覆盖另一边</li><li>timestamp，基于数据的修改时间戳，修改时间新的覆盖旧的数据</li><li>数据类型merge， 比如针对库存信息，A地库存减一，B地库存减二，两边同步之后A地和B地的数据应该是减三，合并两者减一和减二的操作</li></ul><p>针对trusted source/timestamp模型，一定需要建立一个冲突数据kv表，(比如trusted source场景，如果B地修改了记录，而A地没修改此记录，那B地可以覆盖A地，即使A地是trusted source) ，对应冲突数据KV表的插入和删除，如果插入和删除不及时，就会有各种各样的误判，导致数据不一致。</p><p>举个插入不及时的case: 比如A地和B地进行双向同步，同时修改了同一记录，但A地的binlog解析器因为异常挂起了，导致构建冲突数据KV表数据延迟了，而此时B地的数据就会认为无冲突，直接覆盖了A，即使A地是trusted source，然后A地数据解析恢复后，同步到B地时，因为A是trusted source，就会覆盖B地的数据，最后就是A和B两地各为两边之前的版本，导致数据不一致。</p><p>因为GoldenGate外部文档针对双A机房同步，数据一致性处理描述的比较少，我只能推测到这，基本结论是风险太大，所以otter需要有一种完全可靠的数据一致性方案，这也是本文讨论的重点。</p><h1 id="单向回环补救-基于trusted-source的改进版"><a href="#单向回环补救-基于trusted-source的改进版" class="headerlink" title="单向回环补救 (基于trusted source的改进版)"></a>单向回环补救 (基于trusted source的改进版)</h1><p><img src="/images/otter-data-consistency/%E5%8D%95%E5%90%91%E5%9B%9E%E7%8E%AF.png" alt></p><p>思路：最终一致性</p><p>适用场景： A地和B地数据不对等，比如A地为主，写入量比较高，B地有少量的数据写入</p><p>单向回环流程：(比如图中以HZ为trusted source站点)</p><ul><li>us-&gt;hz同步的数据，会再次进入hz-&gt;us队列，形成一次单向回环</li><li>hz-&gt;us同步的数据，不会进入us-&gt;hz队列(回环终止，保证不进入死循环)</li></ul><p>存在的问题：存在同步延迟时，会出现版本丢失高/数据交替性变化</p><ul><li>比如US同一条记录变更了10个版本，而且很快同步到了HZ，而HZ因为同步数据大，同步延迟，后续单向回环中将10个版本又在US进行了一次重放，导致出现数据交替</li><li>比如HZ同一条记录变更了10个版本，而且很快同步到了US，而US因为同步延迟，将一个比较早的版本同步到了HZ，后续通过单向回环，将此记录重放到了US，导致之前HZ到US的10个版本丢失.</li></ul><p>解决方案：</p><ul><li>反查数据库同步 (以数据库最新版本同步，解决交替性，比如设置一致性反查数据库延迟阀值为60秒，即当同步过程中发现数据延迟超过了60秒，就会基于PK反查一次数据库，拿到当前最新值进行同步，减少交替性的问题)</li><li>字段同步 (降低冲突概率)</li><li>同步效率 (同步越快越好，降低双写导致版本丢失概率，不需要构建冲突数据KV表)</li><li>同步全局控制 (比如HZ-&gt;US和US-&gt;HZ一定要一起启动，一起关闭，保证不会出现一边数据一直覆盖另一边，造成比较多的版本丢失)</li></ul><p>同步全局控制方案：(分布式Permit)</p><p><img src="/images/otter-data-consistency/%E5%88%86%E5%B8%83%E5%BC%8FPermit.png" alt></p><p>注意：A,B,C三点状态都正常才允许进行同步(解决数据单向覆盖)。 任何一边的canal不正常工作，都应该停掉整个双向同步，及时性越高越好。</p><h1 id="时间交集补救"><a href="#时间交集补救" class="headerlink" title="时间交集补救"></a>时间交集补救</h1><p><img src="/images/otter-data-consistency/%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86%E8%A1%A5%E6%95%91.jpg" alt></p><p>算法描述：</p><ol><li>首先定义两个时间概念</li></ol><ul><li>数据变更时间A ：代表业务数据在A地数据库中产生的时间，即图中的时间A</li><li>数据同步时间B：代表数据变更载入到B地数据库的时间，即图中的时间B</li></ul><ol start="2"><li><p>针对每条或者一批数据都记录变更时间A和同步时间B，同时保留历史同步过的数据记录</p></li><li><p>图中纵轴为时间轴，Aa代表从数据库A同步到数据库B的一个同步过程，Ba代表从数据库B到同步到的数据库A的一个同步过程,每个同步过程在纵轴上会有两个点，分别代表变更时间A和同步时间B.</p></li><li><p>根据同一时间的定义，在两边数据库的各自同步过程中，以数据库A为例，在数据库B的同步过程找到与Aa有时间交集的批次，比如这里就是Aa 与 (Ba , Bb , Bc)有时间交集</p></li><li><p>针对步骤４中的批次，根据同一数据的定义，在交集的每个批次中，比如首先拿Aa和Ba的历史同步数据记录，根据同一数据定义进行查找，然后再是Aa和Bb，依次类推。</p></li><li><p>针对步骤５中找到的同一数据，最后确定为需要进行单向回环的一致性算法的数据。</p></li></ol><p>此方案相比于单向回环方案：减少单向回环同步的数据量，解决A和B地数据对等的case，不过目前开源版本暂未实现。</p><p><a href="https://github.com/alibaba/otter/wiki" target="_blank" rel="noopener">otter wiki</a></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Otter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PaaS平台架构设计</title>
      <link href="/pass-platform-architecture-design.html"/>
      <url>/pass-platform-architecture-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>构建一个PaaS平台</p></blockquote><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>目前在用的PaaS平台是之前购买的一个商业产品，但没有源码，运维期也早就结束了，所以在后期使用过程中会遇到一些各种各样的问题，对于使用、运维都造成一定的困扰。</p><p>老PaaS的架构及基本功能如下：<br><img src="/images/pass-platform-design/%E8%80%81PaaS%E6%9E%B6%E6%9E%84.png" alt></p><h1 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h1><p>为什么选择重构PaaS平台而不是全部迁移kubernates集群？<br>kubernates集群的确提供了很多优秀的特性，比如：RC、滚动更新或回滚、资源监控和日志记录、负载均衡等等。</p><p>但在目前我们这边的环境来看，迁移kubernates集群有如下几个问题：</p><ul><li>无法无感知迁移，即迁移到kubernates集群的过程中及迁移到kubernates集群后，不增加用户的使用、学习成本，但应用引入kubernates集群之后，很难保证这一点。因为我们这边的用户大多是我们公司的供应商，供应商其实不太关心，你平台所提供的各种新特性、功能，更不想因为这些新特性、功能增加他们的使用、学习成本。</li><li>我们这边很多项目本身是有硬负载的，比如F5，所以kubernates提供的负载均衡功能，也就显的不那么重要。</li><li>日志部分，我们已经打通各个平台的日志、监控，不再需其他的组件。</li><li>滚动更新或回滚，老PaaS平台木有，重构后新版中准备加入（二期）。</li><li>RC类似功能，目前不打算支持。</li></ul><h2 id="架构及用到组件梳理"><a href="#架构及用到组件梳理" class="headerlink" title="架构及用到组件梳理"></a>架构及用到组件梳理</h2><p><img src="/images/pass-platform-design/%E6%96%B0PaaS%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BB%84%E4%BB%B6.png" alt></p><h2 id="新PaaS功能点梳理"><a href="#新PaaS功能点梳理" class="headerlink" title="新PaaS功能点梳理"></a>新PaaS功能点梳理</h2><p><img src="/images/pass-platform-design/PaaS%E5%8A%9F%E8%83%BD%E7%82%B9.png" alt></p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><p>通过无缝迁移，在用户无感知的情况下实现迁移。</p><blockquote><p>为什么要做到无感知迁移？<br>老PaaS中目前的项目数量是：193个，应用数量是：673个<br>总实例数：1485，其中生产环境的实例数：894<br>如果这些项目、应用，因为你的重构都需要改动的话，那么推广难度是很大的，所以需要尽量做到，对于用户来说无感知迁移。</p></blockquote><p>以下迁移部分，都需要在新PaaS上线前完成并在上线一段时间准实时同步过来。<br><img src="/images/pass-platform-design/%E8%80%81PaaS%E8%BF%81%E7%A7%BB.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> PaaS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 垃圾回收算法之G1</title>
      <link href="/java-gc-g1.html"/>
      <url>/java-gc-g1.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>有可能是全网最全的G1总结</p></blockquote><a id="more"></a><p>G1(Garbage-First)回收器是在JDK1.7中正式使用的全新垃圾回收器，G1拥有独特的垃圾回收策略，从分代上看，G1依然属于分代垃圾回收器，它会区分年代和老年代，依然有eden和survivor区，但从堆的结构上看，它并不要求整个eden区、年清代或者老年代都连续。它使用了全新的分区算法。</p><p>其特点如下：</p><ul><li><p>并行性：G1在回收期间，可以由多个GC线程同时工作，有效利用多核计算能力。</p></li><li><p>并发性：G1拥有与应用程序交替执行的能力，因此一般来说，不会在整个回收期间完全阻塞应用程序。</p></li><li><p>分代GC：与之前回收器不同，其他回收器，它们要么工作在年轻代要么工作在老年代。G1可以同时兼顾年轻代与老年代。</p></li><li><p>空间整理：G1在回收过程中，会进行适当的对象移动，不像CMS，只是简单的标记清除，在若干次GC后CMS必须进行一次碎片整理，G1在每次回收时都会有效的复制对象，减少空间碎片。</p></li><li><p>可预见性：由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收范围，因此对于全局停顿也能得到更好的控制。</p></li></ul><h1 id="一、G1的内存划分和主要收集过程"><a href="#一、G1的内存划分和主要收集过程" class="headerlink" title="一、G1的内存划分和主要收集过程"></a>一、G1的内存划分和主要收集过程</h1><p>G1收集回收器将堆进行分区，划分为一个个的区域，每次收集的时候，只收集其中几个区域，以此来控制垃圾回收产生一次停顿时间。</p><p>G1的收集过程可能有4个阶段：</p><ul><li><p>新生代GC</p></li><li><p>并发标记周期</p></li><li><p>混合收集</p></li><li><p>（如果需要）进行Full GC。</p></li></ul><h1 id="二、G1的新生代GC"><a href="#二、G1的新生代GC" class="headerlink" title="二、G1的新生代GC"></a>二、G1的新生代GC</h1><p>新生代GC的主要工作是回收eden区和survivor区。</p><p>一旦eden区被占满，新生代GC就会启动。新生代GC收集前后的堆数据如下图所示，其中E表示eden区，S表示survivor区，O表示老年代。</p><p><img src="/images/java-gc-g1/%E6%96%B0%E7%94%9F%E4%BB%A3.png" alt></p><p>可以看到，新生代GC只处理eden和survivor区，回收后，所有的eden区都应该被清空，而survivor区会被收集一部分数据，但是应该至少仍然存在一个survivor区，类比其他的新生代收集器，这一点似乎并没有太大变化。另一个重要的变化是老年代的区域增多，因为部分survivor区或者eden区的对象可能会晋升到老年代。</p><h1 id="三、G1并发标记周期"><a href="#三、G1并发标记周期" class="headerlink" title="三、G1并发标记周期"></a>三、G1并发标记周期</h1><p>G1的并发阶段和CMS有些类似，它们都是为了降低一次停顿时间，而将可以和应用程序并发执行的部分单独提取出来执行。</p><blockquote><p>并发标记周期针对老年代</p></blockquote><p>并发标记周期可分为以下几步：</p><ul><li><p>初始标记：标记从根节点直接可达的对象。这个阶段会伴随一次新生代GC，它是会产生<font color="DeepPink"><strong>全局停顿</strong></font>的，应用程序在这个阶段必须停止执行。</p></li><li><p>根区域扫描：由于初始标记必然会伴随一次新生代GC，所以在初始化标记后，eden被清空，并且存活对象被移到survivor区。在这个阶段，将扫描由survivor区直接可达的老年代区域，并标记这些直接可达的对象。这个过程是可以和应用程序并发执行的。但是根区域扫描不能和新生代GC同时发生（因为根区域扫描依赖survivor区的对象，而新生代GC会修改这个区域），故如果恰巧此时需要新生代GC，GC就需要等待根区域扫描结束后才能进行，如果发生这种情况，这次新生代GC的时间就会延长。</p></li><li><p>并发标记：G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断。</p></li><li><p>重新标记：和CMS一样，重新标记也是会使<font color="DeepPink"><strong>应用程序停顿</strong></font>，由于在并发标记过程中，应用程序依然运行，因此标记结果可能需要修正，所以在此阶段对上一次标记进行补充。在G1中，这个过程使用SATB（Snapshot-At-The-Begining）算法完成，即G1会在标记之初为存活对象创建一个快照，这个快照有助于加速重新标记的速度。</p></li><li><p>独占清理：顾名思义，这个阶段会引起<font color="DeepPink"><strong>停顿</strong></font>。它将计算各个区域的存活对象和GC回收比例并进行排序，识别可供混合回收的区域。在这个阶段，还会更新记忆集。该阶段给出了需要被混合回收的区域并进行了标记，在混合回收阶段，需要这些信息。</p></li><li><p>并发清理阶段：识别并清理完全空闲的区域。它是并发的清理，不会引起停顿。</p></li></ul><blockquote><p>SATB全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态：白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。灰：对象被标记了，但是它的field还没有被标记或标记完。黑：对象被标记了，且它的所有field也被标记完了。</p></blockquote><blockquote><p>SATB 利用 write barrier 将所有即将被删除的引用关系的旧引用记录下来，最后以这些旧引用为根 Stop The World 地重新扫描一遍即可避免漏标问题。 因此G1 Remark阶段 Stop The World 与 CMS了的remark有一个本质上的区别，那就是这个暂停只需要扫描有 write barrier 所追中对象为根的对象， 而 CMS 的remark 需要重新扫描整个根集合，因而CMS remark有可能会非常慢。</p></blockquote><h1 id="四、混合回收"><a href="#四、混合回收" class="headerlink" title="四、混合回收"></a>四、混合回收</h1><p><strong>在并发标记周期中，虽有部分对象被回收，但是回收的比例是非常低的。但是在并发标记周期后，G1已经明确知道哪些区域含有比较多的垃圾对象，在混合回收阶段，就可以专门针对这些区域进行回收。当然G1会优先回收垃圾比例较高的区域（回收这些区域的性价比高），这正是G1名字的由来（Garbage First Garbage Collector：译为垃圾优先的垃圾回收器），这里的垃圾优先（Garbage First）指的是回收时优先选取垃圾比例最高的区域。</strong></p><p>这个阶段叫做混合回收，是因为在这个阶段，即会执行正常的年轻代GC,又会选取一些被标记的老年代区域进行回收，同时处理了新生代和老年代。</p><p><font color="DeepPink"><strong>混合回收会被执行多次，直到回收了足够多的内存空间</strong></font>，然后，它会触发一次新生代GC。新生代GC后，又可能会发生一次并发标记周期的处理，最后又会引起混合回收，因此整个过程可能是如下图：</p><p><img src="/images/java-gc-g1/%E5%9B%9E%E6%94%B6%E5%BE%AA%E7%8E%AF.png" alt></p><h1 id="五、必要时的Full-GC"><a href="#五、必要时的Full-GC" class="headerlink" title="五、必要时的Full GC"></a>五、必要时的Full GC</h1><p>和CMS类似，并发收集让应用程序和GC线程交替工作，因此在特别繁忙的情况下无可避免的会发生回收过程中内存不足的情况，当遇到这种情况，G1会转入一个Full GC 进行回收。</p><p>以下4种情况会触发这类的Full GC：</p><h2 id="1、并发模式失效"><a href="#1、并发模式失效" class="headerlink" title="1、并发模式失效"></a>1、并发模式失效</h2><p>G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。</p><p>GC日志如下的示例：</p><p><img src="/images/java-gc-g1/%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F%E5%A4%B1%E6%95%88.png" alt></p><p>解决办法：发生这种失败意味着堆的大小应该增加了，或者G1收集器的后台处理应该更早开始，或者需要调整周期，让它运行得更快（如，增加后台处理的线程数）。</p><h2 id="2、晋升失败"><a href="#2、晋升失败" class="headerlink" title="2、晋升失败"></a>2、晋升失败</h2><p>（to-space exhausted或者to-space overflow）</p><p>G1收集器完成了标记阶段，开始启动混合式垃圾回收，清理老年代的分区，不过，老年代空间在垃圾回收释放出足够内存之前就会被耗尽。（G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用），由此触发了Full GC。</p><p>下面日志中（可以在日志中看到(to-space exhausted)或者（to-space overflow）），反应的现象是混合式GC之后紧接着一次Full GC。</p><p><img src="/images/java-gc-g1/%E6%99%8B%E5%8D%87%E5%A4%B1%E8%B4%A5.png" alt></p><p>这种失败通常意味着混合式收集需要更迅速的完成垃圾收集：每次新生代垃圾收集需要处理更多老年代的分区。</p><p>解决这种问题的方式是：</p><ul><li><p>增加 -XX:G1ReservePercent选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p></li><li><p>通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。</p></li><li><p>也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。</p></li></ul><h2 id="3、疏散失败"><a href="#3、疏散失败" class="headerlink" title="3、疏散失败"></a>3、疏散失败</h2><p>（to-space exhausted或者to-space overflow）</p><p>进行新生代垃圾收集是，Survivor空间和老年代中没有足够的空间容纳所有的幸存对象。这种情形在GC日志中通常是：</p><p><img src="/images/java-gc-g1/%E7%96%8F%E6%95%A3%E5%A4%B1%E8%B4%A5.png" alt></p><p>这条日志表明堆已经几乎完全用尽或者碎片化了。G1收集器会尝试修复这一失败，但可以预期，结果会更加恶化：G1收集器会转而使用Full GC。</p><p>解决这种问题的方式是：</p><ul><li><p>增加 -XX:G1ReservePercent选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p></li><li><p>通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。</p></li><li><p>也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。</p></li></ul><h2 id="4、Humongous-Object-分配失败"><a href="#4、Humongous-Object-分配失败" class="headerlink" title="4、Humongous Object 分配失败"></a>4、Humongous Object 分配失败</h2><p>当Humongous Object 找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。</p><blockquote><p>对于Humongous Object 的处理还有一种方式就是切换GC算法到ZGC，因为ZGC中对于Humongous Object 的回收不会特殊处理（比如不会延迟收集）。</p></blockquote><h1 id="六、巨型对象"><a href="#六、巨型对象" class="headerlink" title="六、巨型对象"></a>六、巨型对象</h1><p>Humongous Object：巨型对象<br>Humongous regions：巨型区域</p><p>对于G1而言，只要超过regin大小的一半，就被认为是巨型对象。巨型对象直接被分配到老年代中的“巨型区域”。这些巨型区域是一个连续的区域集。StartsHumongous 标记该连续集的开始，ContinuesHumongous 标记它的延续。</p><p>在分配巨型对象之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 Full GC。</p><p>对于巨型对象，有以下几个点需要注意：</p><ul><li><p>没有被引用的巨型对象会在标记清理阶段或者Full GC时被释放掉。</p></li><li><p>为了减少拷贝负载，只有在Full GC的时候，才会压缩大对象region。</p></li><li><p>每一个region中都只有一个巨型对象，该region剩余的部分得不到利用，会导致堆碎片化。</p></li><li><p>如果看到由于大对象分配导致频繁的并发回收，需要把大对象变为普通的对象，建议增大Region size。（或者切换到ZGC）</p></li></ul><blockquote><p>对于增大Region size有一个负面影响就是：减少了可用region的数量。因此，对于这种情况，你需要进行相应的测试，以查看是否实际提高了应用程序的吞吐量或延迟。</p></blockquote><h1 id="七、常见调优参数"><a href="#七、常见调优参数" class="headerlink" title="七、常见调优参数"></a>七、常见调优参数</h1><h2 id="1、-XX-MaxGCPauseMillis-N"><a href="#1、-XX-MaxGCPauseMillis-N" class="headerlink" title="1、-XX:MaxGCPauseMillis=N"></a>1、-XX:MaxGCPauseMillis=N</h2><p>默认200毫秒</p><p>前面介绍过使用GC的最基本的参数：</p><blockquote><p>-XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200</p></blockquote><p>前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。</p><ul><li><p>Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。</p></li><li><p>Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。</p></li></ul><p>在理解了这些后，我们再设置最大暂停时间就有了方向。首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。</p><h2 id="2、-XX-G1HeapRegionSize-n"><a href="#2、-XX-G1HeapRegionSize-n" class="headerlink" title="2、-XX:G1HeapRegionSize=n"></a>2、-XX:G1HeapRegionSize=n</h2><p>设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。</p><ul><li><p>-XX:ParallelGCThreads=n（调整G1垃圾收集的后台线程数）<br>设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。<br>如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。</p></li><li><p>-XX:ConcGCThreads=n（调整G1垃圾收集的后台线程数）<br>设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。</p></li></ul><h2 id="3、-XX-InitiatingHeapOccupancyPercent-45（调整G1垃圾收集运行频率）"><a href="#3、-XX-InitiatingHeapOccupancyPercent-45（调整G1垃圾收集运行频率）" class="headerlink" title="3、 -XX:InitiatingHeapOccupancyPercent=45（调整G1垃圾收集运行频率）"></a>3、 -XX:InitiatingHeapOccupancyPercent=45（调整G1垃圾收集运行频率）</h2><p>设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</p><p>该值设置太高：会陷入Full GC泥潭之中，因为并发阶段没有足够的时间在剩下的堆空间被填满之前完成垃圾收集。</p><p>如果该值设置太小：应用程序又会以超过实际需要的节奏进行大量的后台处理。</p><p>避免使用以下参数：避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。</p><h1 id="八、细节"><a href="#八、细节" class="headerlink" title="八、细节"></a>八、细节</h1><h2 id="1、G1-mixed-GC时机？"><a href="#1、G1-mixed-GC时机？" class="headerlink" title="1、G1 mixed GC时机？"></a>1、G1 mixed GC时机？</h2><p>mixed gc中也有一个阈值参数 -XX:InitiatingHeapOccupancyPercent，当老年代大小占整个堆大小百分比达到该阈值时，会触发一次mixed gc.</p><p>在分配humongous object之前先检查是否超过 initiating heap occupancy percent, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 Full GC。</p><p>为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。</p><p>一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。</p><h2 id="2、XX：G1-HeapRegionSize-默认值？"><a href="#2、XX：G1-HeapRegionSize-默认值？" class="headerlink" title="2、XX：G1 HeapRegionSize 默认值？"></a>2、XX：G1 HeapRegionSize 默认值？</h2><p>默认把堆内存按照2048份均分，最后得到一个合理的大小。</p><h2 id="3、直接内存配置"><a href="#3、直接内存配置" class="headerlink" title="3、直接内存配置"></a>3、直接内存配置</h2><p>Q: 什么时候用直接内存？</p><p>A: 读写频繁的场合，出于性能考虑，可以考虑使用直接内存。</p><p>直接内存也是 Java 程序中非常重要的组成部分，特别是 NIO 被广泛使用之后，直接内存可以跳过 Java 堆，使 Java 程序可以直接访问原生堆空间。因此可以在一定程度上加快内存的访问速度。直接内存可以用 -XX:MaxDirectMemorySize 设置，默认值为最大堆空间，也就是 -Xmx。当直接内存达到最大值的时候，也会触发垃圾回收，如果垃圾回收不能有效释放空间，直接内存溢出依然会引起系统的 OOM。</p><p>一般而言直接内存在访问读写上直接内存有较大优势（速度较快），但是在内存空间申请的时候，直接内存毫无优势而言。</p><h2 id="4、RSet"><a href="#4、RSet" class="headerlink" title="4、RSet"></a>4、RSet</h2><p>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p><p>RSet究竟是怎么辅助GC的呢？</p><p>在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。</p><h1 id="九、JDK-12中G1的新特性"><a href="#九、JDK-12中G1的新特性" class="headerlink" title="九、JDK 12中G1的新特性"></a>九、JDK 12中G1的新特性</h1><h2 id="1、可中断-mixed-GC"><a href="#1、可中断-mixed-GC" class="headerlink" title="1、可中断 mixed GC"></a>1、可中断 mixed GC</h2><p>如果 Mixed GC 的 G1 存在超出暂停目标的可能性，则使其可被中止。</p><h2 id="2、G1未使用分配内存即时返回"><a href="#2、G1未使用分配内存即时返回" class="headerlink" title="2、G1未使用分配内存即时返回"></a>2、G1未使用分配内存即时返回</h2><p>增强 G1垃圾收集器，以便在空闲时自动将 Java 堆内存返回给操作系统。</p><h1 id="十、GC-发展趋势"><a href="#十、GC-发展趋势" class="headerlink" title="十、GC 发展趋势"></a>十、GC 发展趋势</h1><p>其实可以看到Java 垃圾回收器的趋势，就是在大内存堆的前提下尽 GC 可能的降低对应用程序的影响；从 CMS 的分阶段增量标记，到 G1 通过 SATB 算法改正 remark 阶段的 Stop The World 的影响，再到 ZGC/C4甚至在标记阶段无需 Stop The World，莫不如此。</p><h1 id="十一、结尾"><a href="#十一、结尾" class="headerlink" title="十一、结尾"></a>十一、结尾</h1><p>推荐几种学习这种GC的方式：</p><ul><li><p>看JEP（JDK Enhancement Proposal）知道它的来龙去脉。</p></li><li><p>看相应算法的paper（之前看Shenandoah GC Paper的时候，就有一种收获很大的感觉，因为Shenandoah GC的处理方式，介于G1跟ZGC之间，所以看了Shenandoah GC Paper感觉对于G1、ZGC的理解也更加深入了）。</p></li></ul><p>会在文章结束，补充上JEP官网地址跟我收集的一些GC资料（包含部分paper）github地址。</p><p>补一个我自己归纳的GC图：</p><p><img src="/images/java-gc-g1/GC%E8%84%89%E7%BB%9C.png" alt></p><p>各种GC算法都是围绕着，图中内容展开的，只是各自的处理方式不同而已。</p><p>资料推荐：</p><p>1、GC算法及paper</p><p><a href="https://github.com/jiankunking/books-recommendation/tree/master/GC" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/GC</a></p><p>2、Java相关书籍推荐</p><p><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p><p>参考文献</p><p>1、实战JAVA虚拟机 JVM故障诊断与性能优化</p><p>2、jeps</p><p>3、其它</p><p><a href="https://www.oracle.com/technetwork/articles/java/g1gc-1984535.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/articles/java/g1gc-1984535.html</a></p><p><a href="https://plumbr.io/handbook/gc-tuning-in-practice/other-examples/humongous-allocations" target="_blank" rel="noopener">https://plumbr.io/handbook/gc-tuning-in-practice/other-examples/humongous-allocations</a></p>]]></content>
      
      
      <categories>
          
          <category> GC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> GC </tag>
            
            <tag> G1 </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式缓存的一致性Hash算法</title>
      <link href="/distributed-cache-consistent-hash-algorithm.html"/>
      <url>/distributed-cache-consistent-hash-algorithm.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《大型网站技术架构：核心原理与案例分析》<br>作者：李智慧<br>出版时间：2013-09</p><a id="more"></a><h1 id="一、一致性哈希算法"><a href="#一、一致性哈希算法" class="headerlink" title="一、一致性哈希算法"></a>一、一致性哈希算法</h1><p>一致性Hash算法通过一个叫做一致性Hash环的数据结构实现Key到缓存服务器的Hash映射，如图6.11所示：<br><img src="/images/distributed-cache-consistent-hash-algorithm/611.png" alt></p><p>算法过程如下：</p><p>先构造一个长度为2^32的整数环（这个环被称为一致性Hash环），根据节点名称的Hash值（其分布为[0，2^32-1]）将缓存服务器节点放置在这个Hash环上，然后根据需要缓存的数据的Key值计算得到其Hash值（其分布也为[0，2^32-1]），然后在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。</p><p>假设NODE1的Hash值为3,594,963,423，NODE2的Hash值为1,845,328,979，而KEY0的Hash值为2,534,256,785，那么KEY0在环上顺时计查找，找到的最近的节点就是NODE1。</p><p>当缓存服务器集群要扩容的时候，只需要将新加入的节点名称（NODE3)的Hash 值放入一致性Hash环中，由于KEY是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一小段。如图6.12中深色一段。<br><img src="/images/distributed-cache-consistent-hash-algorithm/612.png" alt></p><p>假设NODE3的Hash是2,790,324,235，那么加入 NODE3 后，KEYO（Hash值 2,534,256,785）顺时针查找得到的节点就是NODE3。</p><p>图6。12中，加入新节点NODE3后，原来的KEY大部分还能继续计算到原来的节点。只有KEY3、KEY0从原来的NODE1重新计算到NODE3。这样就能保证大部分被缓存的数据还可以继续命中。3台服务器扩容至4台服务器。可以继续命中原有缓存数据的概率是75%，远高于余数Hash的25%。而且随着集群规模越大。继续命中原有缓存数据的槪率也逐渐增大，100台服务器扩容增加1台服务器。继续命中的槪率是99%，虽然仍有小部分数据缓存在服务器中不能被读到，但是这个比例足够小。通过访问数据库获取也不会对数据库造成致命的负载压力。</p><p>具体应用中，这个长度为2^32 的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉査找树中查找不小于査找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。</p><p>从增加节点和减少节点的例子中觉察到了问题：新增一个节点时，除了新增的节点外，只有一个节点受影响，这个新增节点和受影响的节点的负载是明显比其他节点低的；减少一个节点时，除了减去的节点外，只有一个节点受影响，它要承担自己原来的和减去的节点的工作，压力明显比其他节点要高。如果4台机器的性能是一样的，那么这种结果显然不是我们需要的。这似乎要增加一倍节点或减去一半节点才能保持各个节点的负载均衡。如果真是这样，一致性哈希的优势就不明显了。</p><h1 id="二、虛拟节点对一致性哈希的改进（解决负载不均衡问题）"><a href="#二、虛拟节点对一致性哈希的改进（解决负载不均衡问题）" class="headerlink" title="二、虛拟节点对一致性哈希的改进（解决负载不均衡问题）"></a>二、虛拟节点对一致性哈希的改进（解决负载不均衡问题）</h1><p>计算机领域有句话：计算机的任何问题都可以通过增加一个虚拟层来解决。计算机硬件、计算机网络、计算机软件都莫不如此。计算机网络的7层协议，每一层都可以看作是下一层的虚拟层；计算机操作系统可以看作是计算机硬件的虚拟层；Java虚拟机可以看作是操作系统的虚拟层；分层的计算机软件架构事实上也是利用虚拟层的概念。</p><p>解决上述一致性Hash算法带来的负载不均衡问题，也可以通过使用虚拟层的手段： <font color="DeepPink"><strong>将每个节点虚拟为一组虚拟节点，将虚拟节点的Hash值放置在Hash环上，KEY在环上先找到虚拟节点，再得到物理节点的信息。</strong></font></p><p>这样新加入物理节点时，是将一组虚拟节点加入环中，如果虚拟节点的数目足够多，这组虚拟节点将会影响同样多数目的已经在环上存在的虚拟节点，这些已经存在的虚拟节点又对应不同的物理节点。最终的结果是：新加入一个物理节点，将会较为均匀地影响原来集群中已经存在的所有节点，也就是说分摊原有节点在集群中所有节点的一小部分负载，其总的影响范围和上面讨论过的相同。如图6.13所示。</p><p>在图6.13中，新加入节点NODE3对应的一组虚拟节点为V30，V31，V32，加入到 —致性Hash环上后，影响V01， V12， V22三个虚拟节点，而这三个虚拟节点分别对应 NODE0 NODE1， NODE2三个物理节点。最终集群中加入一个节点，但是同时影响到集群中已存在的三个物理节点，在理想情况下，每个物理节点受影响的数据量 为其节点缓存数据最的1/4（X/(N+X)），N为原有物理节点数，X为新加入物理节点数），也就是集群中已经被缓存的数据有75%可以被继续命中，和未使用虚拟节点的一致性Hash算法结果相同，只是解决的负载均衡的问题。<br><img src="/images/distributed-cache-consistent-hash-algorithm/613.png" alt></p><p><font color="DeepPink"><strong>显然每个物理节点对应的虚拟节点越多，各个物理节点之间的负载越均衡，新加入物理服务器对原有的物理服务器的影响越保持一致（这就是一致性Hash这个名称的由来)。</strong></font>那么在实践中，一台物理服务器虚拟为多少个虚拟服务器节点合适呢？太多会影响性能，太少又会导致负载不均衡，一般说来，经验值是150，当然根据集群规模和负载均衡的精度需求，这个值应该根据具体情况具体对待。</p><blockquote><p>要解决的问题：就是增减缓存集群机器的时候，仍然尽量保持较好的缓存命中率及较均衡的机器负载。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Architecture </tag>
            
            <tag> Distributed </tag>
            
            <tag> Cache </tag>
            
            <tag> Consistent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOFAMosn 如何提高 GoLang 的转发性能</title>
      <link href="/sofamosn-golang-performance.html"/>
      <url>/sofamosn-golang-performance.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>通过SOFAMosn了解goroutine只能在一定并发量级上降低并发编程的难度(goroutine内存占用2kb+)<br>高并发的场景还是NIO比较适合</p></blockquote><a id="more"></a><p>GoLang 的转发性能比起 C++ 肯定是稍有逊色的，为了尽可能的提高 MOSN 的转发性能，我们在线程模型上进行优化，当前 MOSN 支持两种线程模型，用户可根据场景选择开启适用的模型。</p><h1 id="模型一"><a href="#模型一" class="headerlink" title="模型一"></a>模型一</h1><p>如下图所示，使用 GoLang 默认的 epoll 机制，对每个连接分配独立的读写协程进行阻塞读写操作，proxy 层做转发时，使用常驻 worker 协程池负责处理 Stream Event</p><p><img src="/images/sofamosn-golang-performance/MOSNThreadModelStage1.png" alt></p><ul><li>此模型在 IO 上使用 GoLang 的调度机制，适用于连接数较少的场景，例如：mosn 作为 sidecar、与 client 同机部署的场景</li></ul><h1 id="模型二"><a href="#模型二" class="headerlink" title="模型二"></a>模型二</h1><p>如下图所示，基于 <a href="https://godoc.org/github.com/mailru/easygo/netpoll" target="_blank" rel="noopener">Netpoll</a> 重写 epoll 机制，将 IO 和 PROXY 均进行池化，downstream connection 将自身的读写事件注册到 netpoll 的 epoll/kqueue wait 协程，epoll/kqueue wait 协程接受到可读事件，触发回调，从协程池中挑选一个执行读操作。</p><p><img src="/images/sofamosn-golang-performance/MOSNThreadModelStage2.png" alt></p><ul><li>使用自定义 Netpoll IO 池化操作带来的好处是：<ul><li>当可读事件触发时，从协程池中获取一个 goroutine 来执行读处理，而不是新分配一个 goroutine，以此来控制高并发下的协程数量</li><li>当收到链接可读事件时，才真正为其分配 read buffer 以及相应的执行协程。这样 GetBytes() 可以降低因为大量空闲链接场景导致的额外协程和 read buffer 开销</li></ul></li><li>此模型适用于连接数较多、可读连接数量受限的情况，例如：mosn 作为 api gateway 的场景</li></ul><blockquote><p>本文整理自SOFAMosn官方文档</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Performance </tag>
            
            <tag> Go </tag>
            
            <tag> SOFAMosn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ReentrantReadWriteLock原理解析</title>
      <link href="/java-reentrantreadwritelock.html"/>
      <url>/java-reentrantreadwritelock.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Java JDK 11 ReentrantReadWriteLock 原理分析</p></blockquote><a id="more"></a><h1 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h1><p>希望在阅读本文之前，建议先看一下以下三篇文章：</p><p>1、<a href="https://www.jiankunking.com/java-aqs.html" target="_blank" rel="noopener">面试必备：Java AQS 实现原理（图文）分析</a> </p><p>2、<a href="https://www.jiankunking.com/java-aqs-condition.html" target="_blank" rel="noopener">面试必备：Java AQS Condition的实现分析</a> </p><p>3、<a href="https://www.jiankunking.com/java-volatile-aqs.html" target="_blank" rel="noopener">面试必备：Java Volatile的内存语义与AQS锁内存可见性</a> </p><p>读完了以上三篇文章，先看一下ReentrantReadWriteLock的代码路径：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package java.util.concurrent.locks;</span><br></pre></td></tr></table></figure><p>来先猜一下ReentrantReadWriteLock会如何实现？</p><p>都在java.util.concurrent包下，那么可以明确一点，那就是关于锁的实现，应该用的就是AQS，那么，读锁、写锁会不会对应的就是AQS中的共享模式与独占模式？</p><h1 id="2、读写锁使用场景"><a href="#2、读写锁使用场景" class="headerlink" title="2、读写锁使用场景"></a>2、读写锁使用场景</h1><p>读是多于写（比如cache）</p><blockquote><p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。</p></blockquote><h1 id="3、读写锁接口：ReadWriteLock"><a href="#3、读写锁接口：ReadWriteLock" class="headerlink" title="3、读写锁接口：ReadWriteLock"></a>3、读写锁接口：ReadWriteLock</h1><p>代码地址：<a href="https://github.com/jiankunking/openjdk11/blob/master/src/java.base/share/classes/java/util/concurrent/locks/ReadWriteLock.java" target="_blank" rel="noopener">ReadWriteLock</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public interface ReadWriteLock &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Returns the lock used for reading.</span><br><span class="line">     *</span><br><span class="line">     * @return the lock used for reading</span><br><span class="line">     */</span><br><span class="line">    Lock readLock();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Returns the lock used for writing.</span><br><span class="line">     *</span><br><span class="line">     * @return the lock used for writing</span><br><span class="line">     */</span><br><span class="line">    Lock writeLock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、读写锁的接口与示例</p><p>ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现：ReentrantReadWriteLock，除了接口方法之外，还提供了一些便于外界监控其内部工作状态的方法，这些方法以及描述如表所示：</p><p><img src="/images/java-reentrantreadwritelock/ReadWriteLock%E6%8E%A5%E5%8F%A3.png" alt><br>接下来，通过一个缓存示例说明读写锁的使用方式，示例代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public class Cache &#123;</span><br><span class="line">    static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();</span><br><span class="line">    static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();</span><br><span class="line">    static Lock r = rwl.readLock();</span><br><span class="line">    static Lock w = rwl.writeLock();</span><br><span class="line"></span><br><span class="line">    // 获取一个key对应的value</span><br><span class="line">    public static final Object get(String key) &#123;</span><br><span class="line">        r.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            return map.get(key);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            r.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 设置key对应的value，并返回旧的value</span><br><span class="line">    public static final Object put(String key, Object value) &#123;</span><br><span class="line">        w.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            return map.put(key, value);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            w.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 清空所有的内容</span><br><span class="line">    public static final void clear() &#123;</span><br><span class="line">        w.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            map.clear();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            w.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述示例中，Cache组合一个非线程安全的HashMap作为缓存的实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。在读操作get(String key)方法中，需要获取读锁，这使得并发访问该方法时不会被阻塞。写操作put(String key,Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性，同时简化了编程方式。</p><h1 id="5、ReentrantReadWriteLock脉络梳理"><a href="#5、ReentrantReadWriteLock脉络梳理" class="headerlink" title="5、ReentrantReadWriteLock脉络梳理"></a>5、ReentrantReadWriteLock脉络梳理</h1><p>代码地址：<a href="https://github.com/jiankunking/openjdk11/blob/master/src/java.base/share/classes/java/util/concurrent/locks/ReentrantReadWriteLock.java" target="_blank" rel="noopener">ReentrantReadWriteLock</a></p><p>先看一下继承结构：</p><p><img src="/images/java-reentrantreadwritelock/%E8%AF%BB%E5%86%99%E9%94%81%E6%8E%A5%E5%8F%A3%E7%BB%A7%E6%89%BF%E5%85%B3%E7%B3%BB.png" alt><br>再看一下代码结构：</p><p><img src="/images/java-reentrantreadwritelock/%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png" alt><br>图中可以看出ReentrantReadWriteLock的实现还是比较复杂的，所以接下来主要分析ReentrantReadWriteLock实现关键点，包括：</p><ul><li>读写状态的设计</li><li>写锁的获取与释放</li><li>读锁的获取与释放</li><li>锁降级</li></ul><h2 id="5-1-读写状态的设计"><a href="#5-1-读写状态的设计" class="headerlink" title="5.1 读写状态的设计"></a>5.1 读写状态的设计</h2><p>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。</p><p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如下图所示:</p><p><img src="/images/java-reentrantreadwritelock/32%E4%BD%8D%E8%AF%BB%E5%86%99%E6%A0%87%E8%AF%86.png" alt></p><p>当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？</p><p>答案是通过位运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。</p><blockquote><p>1、0x0000FFFF=00000000000000001111111111111111（16个0 16个1）</p></blockquote><blockquote><p>2、&gt;&gt;&gt;： 无符号右移，忽略符号位，空位都以0补齐</p></blockquote><blockquote><p>3、0x00010000=10000000000000000（1个1 16个0）</p></blockquote><p>根据状态的划分能得出一个推论：S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</p><h2 id="5-2-写锁的获取与释放"><a href="#5-2-写锁的获取与释放" class="headerlink" title="5.2 写锁的获取与释放"></a>5.2 写锁的获取与释放</h2><p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码如代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Walkthrough:</span><br><span class="line">             * 1. If read count nonzero or write count nonzero</span><br><span class="line">             *    and owner is a different thread, fail.</span><br><span class="line">             * 2. If count would saturate, fail. (This can only</span><br><span class="line">             *    happen if count is already nonzero.)</span><br><span class="line">             * 3. Otherwise, this thread is eligible for lock if</span><br><span class="line">             *    it is either a reentrant acquire or</span><br><span class="line">             *    queue policy allows it. If so, update state</span><br><span class="line">             *    and set owner.</span><br><span class="line">             */</span><br><span class="line">            Thread current = Thread.currentThread();</span><br><span class="line">            int c = getState();</span><br><span class="line">            int w = exclusiveCount(c);</span><br><span class="line">            if (c != 0) &#123;</span><br><span class="line">               // 存在读锁或者当前获取线程不是已经获取写锁的线程</span><br><span class="line">                if (w == 0 || current != getExclusiveOwnerThread())</span><br><span class="line">                    return false;</span><br><span class="line">                if (w + exclusiveCount(acquires) &gt; MAX_COUNT)</span><br><span class="line">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">                // Reentrant acquire</span><br><span class="line">                setState(c + acquires);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            if (writerShouldBlock() ||</span><br><span class="line">                !compareAndSetState(c, c + acquires))</span><br><span class="line">                return false;</span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。<font color="DeepPink"><strong>如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</strong></font></p><p><font color="DeepPink"><strong>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</strong></font></p><h2 id="5-3-读锁的获取与释放"><a href="#5-3-读锁的获取与释放" class="headerlink" title="5.3 读锁的获取与释放"></a>5.3 读锁的获取与释放</h2><p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。获取读锁的实现从Java 5到Java 6变得复杂许多，主要原因是新增了一些功能，例如getReadHoldCount()方法，作用是返回当前线程获取读锁的次数。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护，这使获取读锁的实现变得复杂。因此，这里将获取读锁的代码做了删减，保留必要的部分，如代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">protected final int tryAcquireShared(int unused) &#123;</span><br><span class="line">          for (;;) &#123;</span><br><span class="line">                  int c = getState();</span><br><span class="line">                  int nextc = c + (1 &lt;&lt; 16);</span><br><span class="line">                  if (nextc &lt; c)</span><br><span class="line">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">                  if (exclusiveCount(c) != 0 &amp;&amp; owner != Thread.currentThread())</span><br><span class="line">                    return -1;</span><br><span class="line">                  if (compareAndSetState(c, nextc))</span><br><span class="line">                    return 1;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。<font color="DeepPink"><strong>如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。</strong></font></p><p>读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1&lt;&lt;16）。</p><h2 id="5-4-锁降级"><a href="#5-4-锁降级" class="headerlink" title="5.4 锁降级"></a>5.4 锁降级</h2><p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</p><p>接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作，如代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public void processData() &#123;</span><br><span class="line">        readLock.lock();</span><br><span class="line">        if (!update) &#123;</span><br><span class="line">            // 必须先释放读锁</span><br><span class="line">            readLock.unlock();</span><br><span class="line">            // 锁降级从写锁获取到开始</span><br><span class="line">            writeLock.lock();</span><br><span class="line">            try &#123;</span><br><span class="line">                if (!update) &#123;</span><br><span class="line">                    // 准备数据的流程（略）</span><br><span class="line">                    update = true;</span><br><span class="line">                &#125;</span><br><span class="line">                readLock.lock();</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                writeLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">            // 锁降级完成，写锁降级为读锁</span><br><span class="line">        &#125;</span><br><span class="line">        try &#123;</span><br><span class="line">            // 使用数据的流程（略）</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            readLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>上述示例中，当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。</p><p><font color="DeepPink"><strong>锁降级中读锁的获取是否必要呢？答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。</strong></font></p><p><font color="DeepPink"><strong>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</strong></font></p><h1 id="6、小结"><a href="#6、小结" class="headerlink" title="6、小结"></a>6、小结</h1><p>RentrantReadWriteLock的具体流程梳理完了，回过头来想一下前言的问题，好像并没有得到答案，那么来到ReentrantReadWriteLock代码中，此处主要看一下读锁的获取、释放是否对应AQS中的共享模式。</p><h2 id="6-1-读锁的获取、释放"><a href="#6-1-读锁的获取、释放" class="headerlink" title="6.1 读锁的获取、释放"></a>6.1 读锁的获取、释放</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public void lock() &#123;</span><br><span class="line">         //看到这里是不是就明白了，我们的猜想是正确的</span><br><span class="line">         sync.acquireShared(1);</span><br><span class="line">     &#125;</span><br><span class="line">    public void unlock() &#123;</span><br><span class="line">         //看到这里是不是就明白了，我们的猜想是正确的</span><br><span class="line">         sync.releaseShared(1);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><p>先来看一下ReadLock的具体实现，在ReentrantReadWriteLock初始化的时候，会在构造函数中初始化ReadLock、WriteLock，具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public ReentrantReadWriteLock() &#123;</span><br><span class="line">       this(false);</span><br><span class="line">   &#125;</span><br><span class="line">   public ReentrantReadWriteLock(boolean fair) &#123;</span><br><span class="line">       sync = fair ? new FairSync() : new NonfairSync();</span><br><span class="line">       readerLock = new ReadLock(this);</span><br><span class="line">       writerLock = new WriteLock(this);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>从ReentrantReadWriteLock构造函数的代码中，可以看到ReadLock初始化的参数是ReentrantReadWriteLock，那么ReadLock需要ReentrantReadWriteLock来做什么呢？</p><p>来看一下ReadLock：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private final Sync sync;</span><br><span class="line">    protected ReadLock(ReentrantReadWriteLock lock) &#123;</span><br><span class="line">        sync = lock.sync;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>从ReadLock的构造函数中，可以看出，ReadLock需要获取到Sync，那么Sync是谁，又是用来做什么的？</p><blockquote><p>其实，如果看过JUC下面代码的话，看到Sync，就明白它应该就是AQS的实现类，通过它来实现相关锁的操作。</p></blockquote><p>来看一下代码验证一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Synchronization implementation for ReentrantReadWriteLock.</span><br><span class="line">     * Subclassed into fair and nonfair versions.</span><br><span class="line">     */</span><br><span class="line">    abstract static class Sync extends AbstractQueuedSynchronizer &#123;</span><br><span class="line">    //具体代码略</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>看到这里可以大体得出这么一个结果：ReadLock获取锁的时候，是通过ReentrantReadWriteLock 内部Sync类来获取的共享锁，也就是读锁的获取是对应AQS中的共享模式。</p><p>点进 sync.acquireShared(1)方法，可以看到是调用Sync的父类AQS中方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public final void acquireShared(int arg) &#123;</span><br><span class="line">        if (tryAcquireShared(arg) &lt; 0)</span><br><span class="line">            doAcquireShared(arg);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>看到这里，也就明白为啥AQS子类需要重写：</p><ul><li>tryAcquire</li><li>tryRelease</li><li>tryReleaseShared</li><li>isHeldExclusively</li></ul><p>等方法了。</p><h1 id="7、参考资料"><a href="#7、参考资料" class="headerlink" title="7、参考资料"></a>7、参考资料</h1><p>本文第4、5小节整理自：《Java并发编程的艺术》</p>]]></content>
      
      
      <categories>
          
          <category> JUC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> JUC </tag>
            
            <tag> AQS </tag>
            
            <tag> ReentrantReadWriteLock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java AQS Condition的实现分析</title>
      <link href="/java-aqs-condition.html"/>
      <url>/java-aqs-condition.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文整理自《Java并发编程的艺术》第五章 作者：方腾飞　魏鹏　程晓明</p></blockquote><a id="more"></a><p>AQS:AbstractQueuedSynchronizer</p><p>ConditionObject是同步器AQS的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。<font color="DeepPink"><strong>每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。</strong></font></p><p>下面将分析Condition的实现，主要包括：等待队列、等待和通知，下面提到的Condition如果不加说明均指的是ConditionObject。</p><h1 id="1、等待队列"><a href="#1、等待队列" class="headerlink" title="1、等待队列"></a>1、等待队列</h1><p><strong>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。</strong></p><p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列，等待队列的基本结构如图5-9所示。<br><img src="/images/java-juc-aqs-condition/59.png" alt></p><p>如图所示，Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于<font color="DeepPink">调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。 </font></p><p>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而<font color="DeepPink">并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列</font>，其对应关系如图5-10所示。</p><p><img src="/images/java-juc-aqs-condition/510.png" alt></p><h1 id="2、等待"><a href="#2、等待" class="headerlink" title="2、等待"></a>2、等待</h1><p><font color="DeepPink"><strong>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</strong></font></p><p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</p><p>Condition的await()方法，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public final void await() throws InterruptedException &#123;</span><br><span class="line">        if (Thread.interrupted())</span><br><span class="line">            throw new InterruptedException();</span><br><span class="line">        // 当前线程加入等待队列</span><br><span class="line">        Node node = addConditionWaiter();</span><br><span class="line">        // 释放同步状态，也就是释放锁</span><br><span class="line">        int savedState = fullyRelease(node);</span><br><span class="line">        int interruptMode = 0;</span><br><span class="line">        while (!isOnSyncQueue(node)) &#123;</span><br><span class="line">            LockSupport.park(this);</span><br><span class="line">            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)</span><br><span class="line">                break;</span><br><span class="line">        &#125;</span><br><span class="line">        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)</span><br><span class="line">            interruptMode = REINTERRUPT;</span><br><span class="line">        if (node.nextWaiter != null)</span><br><span class="line">            unlinkCancelledWaiters();</span><br><span class="line">        if (interruptMode != 0)</span><br><span class="line">            reportInterruptAfterWait(interruptMode);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。</p><p>当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p><p>如果从队列的角度去看，当前线程加入Condition的等待队列，该过程如图5-11示。</p><p>如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p><h1 id="3、通知"><a href="#3、通知" class="headerlink" title="3、通知"></a>3、通知</h1><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p><p>Condition的signal()方法，如代码清单5-23所示。<br><img src="/images/java-juc-aqs-condition/511.png" alt><br>代码清单5-23　ConditionObject的signal方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public final void signal() &#123;</span><br><span class="line">       //isHeldExclusively() AQS 子类实现</span><br><span class="line">       if (!isHeldExclusively())</span><br><span class="line">           throw new IllegalMonitorStateException();</span><br><span class="line">       Node first = firstWaiter;</span><br><span class="line">       if (first != null)</span><br><span class="line">           doSignal(first);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。</strong></font>接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p><p>节点从等待队列移动到同步队列的过程如图5-12所示。</p><p><img src="/images/java-juc-aqs-condition/512.png" alt><br>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p><p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p><p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p><p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p>]]></content>
      
      
      <categories>
          
          <category> JUC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> JUC </tag>
            
            <tag> AQS </tag>
            
            <tag> Condition </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB存储引擎：外键与锁</title>
      <link href="/mysql-innodb-foreign-key-lock.html"/>
      <url>/mysql-innodb-foreign-key-lock.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版 </p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p>外键主要用于引用完整性的约束检查<font color="DeepPink"><strong>在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎会自动对其加一个索引，因为这样可以避免表锁。</strong></font> 这比Oracle数据库做得好，Oracle数据库不会自动添加索引，用户必须自己手动添加，这也导致了Oracle数据库中可能产生死锁。</p><p><font color="DeepPink"><strong>对于外键值的插入或更新，首先需要检查父表中的记录，既SELECT父表。但是对于父表的SELECT操作，不是使用一致性非锁定读的方式，因为这会发生数据不一致的问题，因此这时使用的是SELECT…LOCK IN SHARE MODE方式，即主动对父表加一个S锁。</strong></font>如果这时父表上已经这样加X锁，子表上的操作会被阻塞，如下：<br><img src="/images/mysql-innodb-foreign-key-lock/%E5%A4%96%E9%94%AE%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png" alt><br>在上述的例子中，两个会话中的事务都没有进行COMMIT或ROLLBACK操作，而会话B的操作会被阻塞。这是因为 id为3的父表在会话 A中已经加了一个X锁，而此时在会话 B中用户又需要对父表中 id为3的行加一个 S锁，这时 INSERT的操作会被阻塞。设想如果访问父表时，使用的是一致性的非锁定读，这时Session B会读到父表有id=3的记录，可以进行插入操作。但是如果会话A对事务提交了，则父表中就不存在id为3的记录。数据在父、子表就会存在不一致的情况。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB存储引擎：行锁的3种算法</title>
      <link href="/mysql-innodb-row-lock-algorithm.html"/>
      <url>/mysql-innodb-row-lock-algorithm.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版 </p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><h1 id="行锁的三种算法"><a href="#行锁的三种算法" class="headerlink" title="行锁的三种算法"></a>行锁的三种算法</h1><p>InnoDB存储引擎有3种行锁的算法，其分别是：</p><ul><li>Record Lock：单个行记录上的范围</li><li><font color="DeepPink"><strong>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</strong></font></li><li><font color="DeepPink"><strong>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身</strong></font></li></ul><p>Record Lock总是会锁住索引记录，如果InnoDB存储引擎建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定。</p><p><font color="DeepPink"><strong>Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，innodb对于行的查询都是采用这种锁定算法。</strong></font>例如一个索引有9,11,13,20这4个值，那么该索引可能被Next-Key Locking的范围为（左开右闭 ）：<br>(- &amp;，9]<br>(9,11]<br>(13,20]<br>(20,+ &amp;)</p><p>采用Next-Key Lock的锁定技术称为Next-Key Locking。这种设计的目的是为了解决幻读（Phantom Problem）。利用这种锁定技术，锁定的不是单个值，而是一个范围。</p><blockquote><p>当查询的索引含有唯一属性时，innodb存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即锁住索引记录本身，而不再是范围。<br>对于唯一索引，其加上的是Record Lock，仅锁住记录本身。但也有特别情况，那就是唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么加锁的情况依然是Next-key lock。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE</span><br><span class="line">IF EXISTS t;</span><br><span class="line"></span><br><span class="line">CREATE TABLE t (a INT PRIMARY KEY);</span><br><span class="line"></span><br><span class="line">INSERT INTO t</span><br><span class="line">VALUES</span><br><span class="line">(1),</span><br><span class="line">(2),</span><br><span class="line">(5);</span><br></pre></td></tr></table></figure><p><img src="/images/mysql-innodb-row-lock-algorithm/%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E9%94%81%E5%AE%9A%E7%A4%BA%E4%BE%8B.png" alt><br>表t中共有1、2、5三个值。在上面的例子中，在会话A中首先对a=5进行X锁定。而由于a是主键且唯一，因此锁定的仅是5这个值，而不是(2,5)这个范围，这样在会话B中插入值4而不会阻塞，可以立即插入并返回。即锁定由Next-Key Lock算法降级为了Record Lock，从而提高应用的并发性。正如前面所介绍的，<font color="DeepPink"><strong>Next-Key降级为Record Lock仅在查询的列是唯一索引的情况下。若是辅助索引，则情况会完全不同。</strong></font>同样，首先根据如下代码创建测试表z：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Z (</span><br><span class="line">a INT,</span><br><span class="line">b INT,</span><br><span class="line">PRIMARY KEY (a),</span><br><span class="line">KEY (b)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO Z</span><br><span class="line">VALUES</span><br><span class="line">(1, 1),</span><br><span class="line">(3, 1),</span><br><span class="line">(5, 3),</span><br><span class="line">(7, 6),</span><br><span class="line">(10, 8);</span><br></pre></td></tr></table></figure><p>表z的列b是辅助索引，若在<strong>会话A</strong>中执行下面的SQL语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM Z WHERE b=3 FOR UPDATE;</span><br></pre></td></tr></table></figure><p>很明显，这时SQL语句通过索引列b进行查询，因此其使用传统的Next-Key Locking技术加锁，并且由于<strong>有两个索引，其需要分别进行锁定</strong>。<strong>对于聚集索引，其仅对列a等于5的索引加上Record Lock。而对于辅助索引，其加上的是Next-Key Locking，锁定的范围是(1,3)</strong>,特别需要注意的是，<font color="DeepPink"><strong>InnoDB存储引擎会对辅助索引下一个键值加上gap lock，即还有一个辅助索引范围为(3,6)的锁</strong></font>。 因此，若在新<strong>会话B</strong>中运行下面的SQL语句，都会被阻塞：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM Z WHERE a=5 LOCK IN SHARE MODE;</span><br><span class="line">INSERT INTO Z SELECT 4,2;</span><br><span class="line">INSERT INTO Z SELECT 6,5;</span><br></pre></td></tr></table></figure><p>第一个SQL语句不能执行，因为在会话A中执行的SQL语句已经聚集索引中列a=5的值加上X锁，因此执行会被阻塞。第二个SQL语句，主键插入4，没有问题，但是插入的辅助索引值2在锁定的范围（1，3）中因此执行同样会被阻塞。第三个SQL语句，插入的主键6没有被锁定，5也不在范围（1，3）之间。但插入的值5在另一个锁定范围（3，6）中，故同样需要等待。而下面的SQL语句，不会被阻塞，可以立即执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO Z SELECT 8,6;</span><br><span class="line">INSERT INTO Z SEELCT 2,0;</span><br><span class="line">INSERT INTO Z SELECT 6,7;</span><br></pre></td></tr></table></figure><p>从上面的例子中可以看到，<font color="DeepPink"><strong>Gap Lock的作用是为了阻止多个事务将记录插入到同一个范围内，而这会导致Phantom Problem问题的产生。</strong></font> 例如在上面的例子中，会话A中用户已经锁定了b=3的记录。若此时没有Gap Lock锁定（3，6），那么用户可以插入索引b列为3的记录，这会导致会话A中的用户再次执行同样查询时会返回不同的记录，导致Phantom Problem问题的产生。</p><p>用户可以通过以下两种方式来显式地关闭Gap Lock：</p><ul><li>将事务的隔离级别设置为READ COMMITTED</li><li>将参数innodb_locks_unsafe_for_binlog设置为1</li></ul><p>在上述的配置下，除了外键约束和唯一性检查依然需要的Gap Lock，其余情况仅使用Record Lock进行锁定。但需要牢记的是，上述设置破坏了事务的隔离性，并且对于replication，可能会导致主从数据的不一致。此外，从性能上来看，READ COMMITTED也不会优于默认的事务隔离级别READ REPEATABLE。</p><p>在InnoDB存储引擎中，对于INSERT的操作，其会检查插入记录的下一条记录是否被锁定，若已被锁定，则不允许查询。对于上面的例子，会话A已经锁定了表z中b=3的记录，即已经锁定了（1，3）的范围，这时若在其他会话中进行如下的插入同样会导致阻塞：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO Z SELECT 2,2;</span><br></pre></td></tr></table></figure><p>因为在辅助索引列b上插入值为2的记录时，会监测到下一个记录3已经被索引。而将插入修改为如下的值，可以立即执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO Z SELECT 2,0;</span><br></pre></td></tr></table></figure><blockquote><p>最后再次提醒的是，对于唯一键值的锁定,Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引一列。若唯一索引由多个列组成，而查询是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询故InnoDB存储引擎依然使用Next-Key Lock进行锁定。</p></blockquote><h1 id="解决-Phantom-Problem"><a href="#解决-Phantom-Problem" class="headerlink" title="解决 Phantom Problem"></a>解决 Phantom Problem</h1><p>在默认的事务隔离级别下，即REPEATABLE READ下，InnoDB存储引擎采用<br>Next-Key Locking机制来避免Phantom Problem (幻像问题）。这点可能不同于与其他的数据库，如Oracle数据库，因为其可能需要在SERIALIZABLE的事务隔离级别下才能解决 Phantom Problem。</p><p><strong>Phantom Problem是指在<font color="DeepPink"></font></strong>同一事务<strong>下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。</strong></p><p>下面将演示这个例子，使用前一小节所创建的表t。表t由1、2、5这三个值组成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE</span><br><span class="line">IF EXISTS t;</span><br><span class="line"></span><br><span class="line">CREATE TABLE t (a INT PRIMARY KEY);</span><br><span class="line"></span><br><span class="line">INSERT INTO t</span><br><span class="line">VALUES</span><br><span class="line">(1),</span><br><span class="line">(2),</span><br><span class="line">(5);</span><br></pre></td></tr></table></figure><p>若这时事务T1执行如下的SQL语句:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM t WHERE a&gt; 2 FOR UPDATE;</span><br></pre></td></tr></table></figure><p>注意这时事务T1并没有进行提交操作，上述应该返回5这个结果。若与此同时,另一个事务T2插入了 4这个值，并且数据库允许该操作，那么事务T1再次执行上述SQL语句会得到结果4和5。这与第一次得到的结果不同，违反了事务的隔离性，即当前事务能够看到其他事务的结果。其过程如表6-13所示：<br><img src="/images/mysql-innodb-row-lock-algorithm/%E5%B9%BB%E8%AF%BB%E9%97%AE%E9%A2%98%E6%BC%94%E7%A4%BA.png" alt><br>InnoDB存储引擎采用Next-Key Locking的算法避免Phantom Problem。对于上述的SQL语句SELECT * FROM t WHERE a&gt;2 FOR UPDATE,其锁住的不是5这单个值，而是对（2, +〇〇)这个范围加了 X锁。因此任何对于这个范围的插入都是不被允许的，从而避免 Phantom Problem。</p><p>InnoDB存储引擎默认的事务隔离级别是REPEATABLE READ,在该隔离级别下,<br>其采用Next-Key Locking的方式来加锁。而在事务隔离级别READ COMMITTED下,其仅采用Record Lock，因此在上述的示例中，会话A需要将事务的隔离级别设置为READ COMMITTED。</p><p>此外，<font color="DeepPink"><strong>用户可以通过InnoDB存储引擎的Next-Key Locking机制在应用层面实现唯一性的检查。</strong></font> 例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM table WHERE col=xxx LOCK IN SHARE MODE;</span><br><span class="line">If not found any row:</span><br><span class="line"># unique for insert value</span><br><span class="line">INSERT INTO table VALUES (...);</span><br></pre></td></tr></table></figure><p>如果用户通过索引査询一个值，并对该行加上一个SLock，那么即使査询的值不在，其锁定的也是一个范围，因此若没有返回任何行，那么新插人的值一定是唯一的。也许有读者会有疑问，如果在进行第一步SELECT •••LOCK IN SHARE MODE操作时，有多个事务并发操作，那么这种唯一性检査机制是否存在问题。其实并不会，因为这时会导致死锁，只有一个事务的插人操作会成功，而其余的事务会抛出死锁的错误，如表6-14所示。<br><img src="/images/mysql-innodb-row-lock-algorithm/%E5%94%AF%E4%B8%80%E6%80%A7%E6%A3%80%E6%9F%A5.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB存储引擎：分区表</title>
      <link href="/mysql-innodb-partition-table.html"/>
      <url>/mysql-innodb-partition-table.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版 </p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><h1 id="MySQL分区表介绍"><a href="#MySQL分区表介绍" class="headerlink" title="MySQL分区表介绍"></a>MySQL分区表介绍</h1><p>分区是一种表的设计模式，正确的分区可以极大地提升数据库的查询效率，完成更高质量的SQL编程。但是如果错误地使用分区，那么分区可能带来毁灭性的的结果。</p><p><font color="DeepPink"><strong>分区功能并不是在存储引擎层完成的，因此不只有InnoDB存储引擎支持分区，常见的存储引擎MyISAM、NDB等都支持分区。</strong></font> 但是并不是所有的存储引擎都支持，如CSV、FEDORATED、MERGE等就不支持分区。在使用此分区功能前，应该对选择的存储引擎对分区的支持有所了解。</p><p>MySQL数据库在5.1版本时添加了对分区的支持，<font color="DeepPink"><strong>分区的过程是将一个表或索引分解为多个更小、更可管理的部分。就访问数据库的应用而言，从逻辑上讲，只有一个表或一个索引，但是在物理上这个表或索引可能由数十个物理分区组成。每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。</strong></font></p><p>MySQL数据库支持的分区类型为<font color="DeepPink"><strong>水平分区</strong></font>（指将同一个表中不同行的记录分配到不同的物理文件中），并不支持垂直分区（指将同一表中不同列的记录分配到不同的物理文件中）。此外，<font color="DeepPink"><strong>MySQL数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。</strong></font>而全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。目前，MySQL数据库还不支持全局分区。</p><p>可以通过以下命令来查看当前数据库是否启用了分区功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &apos;%partition%&apos;;</span><br><span class="line">+-------------------+-------+</span><br><span class="line">| Variable_name     | Value |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">| have_partitioning | YES   |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">1 row in set (0.04 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show plugins</span><br><span class="line">*************************** 43. row ***************************</span><br><span class="line">   Name: partition</span><br><span class="line"> Status: ACTIVE</span><br><span class="line">   Type: STORAGE ENGINE</span><br><span class="line">Library: NULL</span><br><span class="line">License: GPL</span><br></pre></td></tr></table></figure><p>有时候可能会有这么一种误区，只要启用了分区，数据库就会运行的更快。这个结论结论是存在很多问题的，就经验来看，分区可能会给某些SQL语句性能带来提高，但是分区主要用于数据库高可用性的管理。在OLTP应用中，对于分区的使用应该非常小心，总之，如果只是一味地使用分区，而不理解分区是如何工作的，也不清楚你的应用如何使用分区，那么分区极有可能会对性能产生负面的影响。</p><h1 id="MySQL分区类型"><a href="#MySQL分区类型" class="headerlink" title="MySQL分区类型"></a>MySQL分区类型</h1><h2 id="RANGE分区"><a href="#RANGE分区" class="headerlink" title="RANGE分区"></a>RANGE分区</h2><p>RANGE分区，是最常用的一种分区类型，基于属于一个给定连续区间的列值，把多行分配给分区。这些区间要连续且不能相互重叠，使用VALUES LESS THAN操作符来进行定义。</p><h2 id="LIST分区"><a href="#LIST分区" class="headerlink" title="LIST分区"></a>LIST分区</h2><p>LIST分区和RANGE分区类似，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择，而非连续的。</p><p>LIST分区通过使用“PARTITION BY LIST(expr)”来实现，其中“expr” 是某列值或一个基于某个列值、并返回一个整数值的表达式，然后通过“VALUES IN (value_list)”的方式来定义每个分区，其中“value_list”是一个通过逗号分隔的整数列表。</p><h2 id="HASH分区"><a href="#HASH分区" class="headerlink" title="HASH分区"></a>HASH分区</h2><p>HASH分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区的数据量大致都是一样的。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中；而在HASH分区中，MySQL自动完成这些工作，用户所要做的只是基于将要进行哈希分区的列值指定一个列值或表达式，以及指定被分区的表将要被分隔成的分区数量。</p><p>要使用HASH分区来分割一个表，要在CREATE TABLE 语句上添加一个“PARTITION BY HASH (expr)”子句，其中“expr”是一个返回一个整数的表达式。它可以仅仅是字段类型为MySQL 整型的一列的名字。此外，你很可能需要在后面再添加一个“PARTITIONS num”子句，其中num是一个非负的整数，它表示表将要被分割成分区的数量，如果没有包括一个PARTITIONS子句，那么分区的数量将默认为1。</p><h2 id="LINER-HASH"><a href="#LINER-HASH" class="headerlink" title="LINER HASH"></a>LINER HASH</h2><p>MySQL还支持线性哈希功能，它与常规哈希的区别在于，线性哈希功能使用的一个线性的2的幂（powers-of-two）运算法则，而常规哈希使用的是求哈希函数值的模数。<br>线性哈希分区和常规哈希分区在语法上的唯一区别在于，在“PARTITION BY” 子句中添加“LINEAR”关键字。</p><h2 id="KEY分区"><a href="#KEY分区" class="headerlink" title="KEY分区"></a>KEY分区</h2><p>KEY分区和HASH分区相似，不同之处在于HASH分区使用用户定义的函数进行分区，支持字符串HASH分区，KEY分区使用MySQL数据库提供的函数进行分区，这些函数基于与PASSWORD()一样的运算法则。</p><h2 id="COLUMNS"><a href="#COLUMNS" class="headerlink" title="COLUMNS"></a>COLUMNS</h2><p>在前面说了RANGE、LIST、HASH和KEY这四种分区中，分区的条件是：数据必须为整形（interger），如果不是整形，那应该需要通过函数将其转化为整形，如YEAR()，TO_DAYS()，MONTH()等函数。MySQL5.5版本开始支持COLUMNS分区，可视为RANGE分区和LIST分区的一种进化。COLUMNS分区可以直接使用非整形的数据进行分区，分区根据类型直接比较而得，不需要转化为整形。此外，RANGE COLUMNS分区可以对多个列的值进行分区。</p><p>COLUMNS分区支持以下的数据类型：</p><ul><li>所有的整形类型，如INT、SMALLINT、TINYINT和BIGINT。而FLOAT和DECIMAL则不予支持。</li><li>日期类型，如DATE何DATETIME。其余的日期类型不予支持。</li><li>字符串类型，如CHAR、VARCHAR、BINARY和VARBINARY。而BLOB和TEXT类型不予支持。</li></ul><h1 id="分区中的NULL值"><a href="#分区中的NULL值" class="headerlink" title="分区中的NULL值"></a>分区中的NULL值</h1><p>MySQL数据库允许对NULL值做分区，但是处理的方法与其他数据库可能完全不同。MySQL数据库的分区总是视NULL值小于任何的一个非NULL值，这和MySQL数据库中处理NULL值的ORDER BY操作是一样的。 因此对于不同的分区类型，MySQL数据库对于NULL值的处理也是各不相同。</p><ul><li>对于RANGE分区，如果向分区列插入了NULL值，则MySQL数据库会将该值放入最左边的分区。</li><li>对于LIST分区，如果向分区列插入了NULL值，则必须显示地指出哪个分区放入NULL值，否则会报错。对于LIST分区，如果向分区列插入了NULL值，则必须显示地指出哪个分区放入NULL值，否则会报错。</li><li>对于HASH和KEY分区，对于NULL值的处理方法和RANGE分区、LIST分区不一样。任何分区函数都会将含有NULL值的记录返回为0。</li></ul><h1 id="分区和性能"><a href="#分区和性能" class="headerlink" title="分区和性能"></a>分区和性能</h1><p>分区真的会加快数据库的查询吗？实际上可能根本感觉不到查询速度的提升，甚至会发现查询速度急剧下降，因此在合理使用分区之前，必须了解分区的使用环境。</p><p>数据库的应用分为两类：一类是OLTP（在线事务处理），如Blog、电子商务、网络游戏等；另一类是OLAP（在线分析处理），如数据仓库、数据集市。对于OLAP的应用，分区的确是可以很好地提高查询的性能，因为OLAP应用大多数查询需要频繁地扫描一张很大的表。假设有一张1亿行的表，其中有一个时间戳属性列。用户的查询需要从这张表中获取一年的数据。如果按时间戳进行分区，则只需要扫描相应的分区即可。这就是前面介绍的分区修剪技术。</p><p><font color="DeepPink"><strong>对于OLTP的应用，分区应该非常小心。在这种应用下，通常不可能会获取一张大表10%的数据，大部分都是通过索引返回几条记录即可。而根据B+树索引的原理可知，对于一张大表，一般的B+树需要2~3次的磁盘IO。因此B+树可以很好地完成操作，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。</strong></font></p><p>如很多开发团队会认为含有1000w行的表是一张非常巨大的表，所以他们往往会选择采用分区，如对主键做10个HASH的分区，这样每个分区就只有100w的数据了，因此查询应该变得更快了。如select * from table where pk=@pk。但是有没有考虑过这样一种情况：100w和1000w行的数据本身构成的B+树的层次都是一样的，可能都是2~3层。那么上述走主键分区的索引并不会带来性能的提高。好的，如果1000w的B+树高度是3,100w的B+树高度是2，那么上述按主键分区的索引可以避免1次IO，从而提高查询的效率。这没问题，但是这张表只有主键索引，没有任何其他的列需要查询的。如果还有类似如下的SQL：select * from table where key=@key，这时对于key的查询需要扫描所有的10个分区，即使每个分区的查询开销为2次IO，则一共需要20次IO。而对于原来单表的设计，对于KEY的查询只需要2~3次IO。</p><p>由以上结论可以看出，对于在OLTP场景中使用分区一定要特别小心了。</p><h1 id="MySQL-5-7对分区的改进"><a href="#MySQL-5-7对分区的改进" class="headerlink" title="MySQL 5.7对分区的改进"></a>MySQL 5.7对分区的改进</h1><p>在MySQL 5.6里面，分区的信息是在MySQL Server层维护的（在.par文件里面），InnoDB引擎层是不知道有分区这个概念的，InnoDB引擎层把每一个分区都当成一张普通的InnoDB表。在打开一个分区表时，会打开很多个分区，打开这些分区表就相当于打开了同等数量的InnoDB表，这需要更多内存存放InnoDB表的元数据和各种与ibd文件打开相关的各种cache与handler的信息。在MySQL 5.7里面，InnoDB引入了Native Partitioning，它把分区的信息从Server层移到了InnoDB层，打开一个分区表和打开一个InnoDB表的内存开销基本是一样的。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB存储引擎：一致性锁定读</title>
      <link href="/mysql-innodb-consistent-locking-read.html"/>
      <url>/mysql-innodb-consistent-locking-read.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版 </p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p>在<a href="https://www.jiankunking.com/mysql-innodb-consistent-nonlocking-read.html" target="_blank" rel="noopener">前一小节</a>中讲到，在默认配置下，即事务的隔离级别为 REPEATABLE READ 模式下， InnoDB 存储引擎的 SELECT 操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read)操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT......FOR UPDATE</span><br><span class="line">SELECT......LOCK IN SHARE MODE</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>SELECT…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。</strong></font><br><font color="DeepPink"><strong>SELECT…LOCK IN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</strong></font></p><p>对于一致性非锁定读，即使读取的行已被执行了 SELECT…FOR UPDATE,也是可以进行读取的，这和之前讨论的情况一样。此外，SELECT…FOR UPDATE, SELECT…LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN,START TRANSACTION 或者SET AUTOCOMMIT =0 。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL InnoDB存储引擎：一致性非锁定读</title>
      <link href="/mysql-innodb-consistent-nonlocking-read.html"/>
      <url>/mysql-innodb-consistent-nonlocking-read.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版 </p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p><strong>一致性的非锁定行读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE、UPDATE操作，这是读取操作不会因此而会等待行上锁的释放，相反，InnoDB会去读取行的一个快照数据。</strong></p><p>下图直观展示了一致性的非锁定行读：<br><img src="/images/mysql-innodb-consistent-nonlocking-read/%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E9%94%81%E5%AE%9A%E8%A1%8C%E8%AF%BB.png" alt></p><p><strong>之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo段用来在此事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。</strong></p><p>可以看到，非锁定读机制极大地提髙了数据库的并发性。<strong>在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同。</strong></p><p>通过图6-4可以知道，快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。就图6-4所显示的，<strong>一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（MultiVersionConcurrencyControl MVCC）。</strong></p><p>在事务隔离级别READ COMMITTED和REPEATABLE READ(InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。<font color="DeepPink"><strong>在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本（关键在于事务之间的隔离性）。</strong></font>来看下面的一个例子，首先在当前MySQL数据库的连接会话A中执行如下SQL语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Session A</span><br><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">Sql&gt; SELECT * FROM parent WHERE id =1;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1 |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>会话A中已通过显式地执行命令BEGIN开启了一个事务，并读取了表parent中id为1的数据，但是事务并没有结束。与此同时，用户再开启另一个会话B，这样可以模拟并发的情况，然后对会话B做如下的操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE parent SET id=3 WHERE id=l;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1 Changed: 1 warnings: 0</span><br></pre></td></tr></table></figure><p>在会话B中将事务表parent中id为1的记录修改为id=3，但是事务同样没有提交，这样id=1的行其实加了一个X锁。这时如果在会话A中再次读取id为1的记录，根据InnoDB存储引擎的特性，即在READ COMMITTED和REPEATETABLE READ的事务隔离级别下会使用非锁定的一致性读。回到之前的会话A,接着上次未提交的事务，执行SQL语句SELECT * FROM parent WHERE id=1的操作，这时不管使用READ COMMITTED还是REPEATABLE READ的事务隔离级别，显示的数据应该都是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT FROM parent WHERE id =l;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1  |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>由于当前id=1的数据被修改了1次，因此只有一个行版本的记录。接着，在会话B中提交上次的事务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Session B</span><br><span class="line">mysql&gt; commit</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure><p>在会话B提交事务后，这时在会话A中再运行SELECT * FROM parent WHERE id=1的SQL语句，在READ COMMITTED和REPEATABLE事务隔离级别下得到结果 就不一样了。对于READ COMMITTED的事务隔离级别，它总是读取行的最新版本，如果行被锁定了，则读取该行版本的最新一个快照（fresh snapshot）。在上述例子中，因为会话B已经提交了事务，所以READ COMMITTED事务隔离级别下会得到如下结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;SELECT @@tx_isolation\G;</span><br><span class="line">**************************** 1.row ****************************</span><br><span class="line">@@tx_isolation: READ-COMMITTED</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT FROM parent WHERE id=1:</span><br><span class="line">Empty set (0.00 sec)</span><br></pre></td></tr></table></figure><p>而对于REPEATETABLE 的事务隔离级别，总是读取事务开始时的行数据。因此对于REPEATETABLE READ事务隔离级别,其得到的结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT @@tx_isolation\G;</span><br><span class="line">**************************** 1.row ****************************</span><br><span class="line">@@tx_isolation: REPEATABLE-READ</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT FROM parent WHERE id=1;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1  |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>下面将从时间的角度展现上述演示的示例过程，如表6-8所示。需要特别注意的是，对于READ COMMITTED 的事务隔离级别而言，从数据库理论的角度来看，其违反了事务ACID中的I的特性，即隔离性。<br><img src="/images/mysql-innodb-consistent-nonlocking-read/%E8%A1%A868.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> MySQL </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日志服务架构设计</title>
      <link href="/log-service-architecture-design.html"/>
      <url>/log-service-architecture-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>在满足业务需求的前提下，代码、架构，越简单，越稳定。</p></blockquote><a id="more"></a><p>最近想把之前做过的日志项目及个人的思考梳理一下，于是有了本文。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我们这边应用部署的环境比较复杂，主要有以下几种：</p><ul><li>机器直接部署</li><li>通过原生docker部署</li><li>通过kubernates集群部署</li></ul><p>部署环境不统一，导致查看应用日志很不方便。</p><h1 id="业务需求"><a href="#业务需求" class="headerlink" title="业务需求"></a>业务需求</h1><p>与部署环境对应，对于日志收集需求分为以下几类：</p><ul><li>机器上的文本日志（直接运行在物理机或者虚拟机中的应用日志）</li><li>运行在docker容器中的应用日志</li><li>运行在kubernates集群中的应用日志</li></ul><p>具体业务需求可以拆分为：</p><ul><li>按照项目、应用、实例维度检索日志并支持搜索关键字高亮（因为大家检索日志的时候，肯定是检索某个项目、某个应用、某个实例的日志）</li><li>支持检索出某条想要的日志后，可以查看上下文（查看该日志所在日志文件的日志上下文）</li><li>支持日志下载（目前支持两种场景：搜索结果下载、上下文下载；支持两种方式：在线下载、离线下载）</li><li>支持自动化批量部署、卸载Agent，部署、卸载过程可视化</li><li>单实例支持多elasticsearch集群</li><li>支持文本日志、docker日志、k8s日志并能与将日志与其业务意义对应上。（即不管是哪种日志形式、来源，最终都需要与业务意义上的项目、应用、实例对应起来，因为对于日志的使用者来说，查询日志的出发点肯定是查询某个项目、某个应用（可以不选）、某个实例（可以不选）、某段时间的日志。）</li><li>支持部署到业务自己的集群中</li></ul><p>需求已经明确了，下面看一下业界方案。</p><h1 id="业界日志系统架构"><a href="#业界日志系统架构" class="headerlink" title="业界日志系统架构"></a>业界日志系统架构</h1><p><img src="/images/log-service-architecture-design/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png" alt></p><ul><li>Collector的作用是：<ul><li>清洗、汇聚数据，减少对于后端集群的压力。</li><li>安全，不允许Agent直连kafka等内部集群，保证一定的安全性，即使后端发生调整也能保证对于Agent连接、认证方式的稳定。</li></ul></li><li>MQ的作用是削峰填谷、解耦、多次消费。</li></ul><p>上图的架构是业界比较通用的一种架构，对于各种场景都考虑的比较全。</p><p>既然业界的架构已经这么完备，那么我们是否就直接采用呢？</p><p>对于我们而言，有以下几个问题：</p><ul><li>涉及的组件比较多，链路比较长，运维比较麻烦</li><li>这一整套架构，不利于单独部署（比如某个业务应用部署机房网络是隔离的，而且项目又不大，只能提供有限的几台机器，这时候如果需要部署业界这套架构的话，资源就会比较受限，如果想做到即支持业界架构组件的可插拔（比如可灵活的决定是否需要Collector、MQ），那么就需要运维几套配置或代码）</li><li>最关键的就是其中组件提供的功能，我们目前用不到。比如MQ的削峰填谷、多次消费。</li></ul><h1 id="组件选择"><a href="#组件选择" class="headerlink" title="组件选择"></a>组件选择</h1><p>选择组件，我们这边主要是从以下几个方面进行考量的：</p><ol><li>组件对应的开源生态完整、活跃度高</li><li>对应的技术栈是我们所熟悉的，我们这边语言技术栈主要是Java、Go，如果组件语言是C、Ruby，应该就被排除了。</li><li>运维成本</li><li>易部署、性能好</li></ol><h2 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h2><p>一提到日志收集方案，大家第一个想到的肯定是ELK(Elasticsearch、Logstash、Kibana )，但Logstash依赖于JVM不管是性能还是简洁性，都不是日志收集agent的首选。</p><p>个人感觉一个好的agent应该是资源占用少，性能好，不依赖别的组件，可以独立部署。而Logstash明显不符合这几点要求，也许正是基于这些考虑elastic推出了Filebeat。</p><h2 id="Collector、MQ"><a href="#Collector、MQ" class="headerlink" title="Collector、MQ"></a>Collector、MQ</h2><p>Elasticsearch集群在部署的时候，一般都是提前估计好容量、机器、shard等信息，因为Elasticsearch集群运行后，再水平拓展，比较麻烦，而我们这边由于业务及成本限制无法很好的预估容量，所以就结合公司实际要求：使用日志服务的业务方自带机器，也就是业务方会有独立的Elasticsearch集群。</p><p>每个业务方都使用自己的Elasticsearch集群，所以集群压力不会很大，从而Collector、MQ这两个组件对于我们的作用也就很小了。</p><h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><p>因为Elasticsearch Ingest Node完全可以满足我们的解析需求，所以就没有必要再引入Logstash等相关组件了。</p><p>到这里，基本可以看出我们的架构如下：<br><img src="/images/log-service-architecture-design/%E7%B2%BE%E7%AE%80%E6%9E%B6%E6%9E%84.png" alt></p><blockquote><p>架构设计的几个原则：</p><ul><li>合适优于业界领先 </li><li>简单优于复杂</li><li>演化优于一步到位</li></ul></blockquote><h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><p>基于需求及EFK套件，梳理我们场景中特有的东西：</p><ul><li>docker日志的场景比较单一，都是通过之前一个产品A发布部署的，其docker命名规则比较统一，可以通过截取docker.container.name来获取应用名字；同时在部署的时候，可以知道部署目标机器的ip，这样就可以通过应用+ip来作为实例名称。</li><li>k8s场景也比较统一，都是通过之前一个产品B发布部署的，其pod命名规则比较统一，可以通过截取kubernetes.pod.name来获取应用名字（但需要通过namespaces关联到tenant，再通过tenant与项目一一对应）；k8s中的pod.name就是唯一的，以此来作为实例名称即可。</li><li>文本日志：因为文本日志主要的场景是已经裸机部署的应用，这种场景下，不存在应用自动迁移的情况，所以文本日志的应用名称、实例名称可以在部署的时候打上标签即可。</li></ul><p>具体规则及解析见下图（实例部分处理暂未标注）：<br><img src="/images/log-service-architecture-design/%E6%94%B6%E9%9B%86%E5%BA%94%E7%94%A8%E6%96%87%E6%9C%AC%E6%97%A5%E5%BF%97.png" alt></p><blockquote><p>推荐写日志到文本文件中，使用标准输出就好。</p></blockquote><p>到这里可以发现我们选择Filebeat来作为日志的收集端，Elasticsearch来存储日志并提供检索能力。</p><p>那么，日志的清洗在哪里做呢？</p><p>日志的清洗一般有两种方式：</p><ul><li>先把日志收集到kafka，再通过Logstash消费kafka的数据，来清洗数据</li><li>直接通过Elasticsearch的[Ingest Node]来清洗数据，因为Ingest Node也支持Grok表达式</li></ul><p>对于，我们的场景而言，我们需要清洗数据的要求比较简单，主要是应用、实例名称的截取还有文本日志中日志时间的处理（@timestamp重置，时区处理），所以我们选择了方案2。</p><p>在我们的方案中，并没有提供Kibana 的界面直接给用户用，而是我们自己根据公司业务独立开发的。</p><p>前端界面为什么不采用Kibana，而需要自己开发？</p><ol><li>kibana对于业务开发人员有一定的学习成本</li><li>kibana界面没有很好的将日志内容与业务意义关联起来（界面选择总比一次次的输入要好，这也是我们将日志的项目、应用、实例等业务信息解析出来的原因）</li><li><a href="https://github.com/jiankunking/log-search" target="_blank" rel="noopener">log-search</a>支持Query String，因此对于熟悉kibana的开发人员来说，在我们自己开发的前端界面检索效果是一样的。</li></ol><p><a href="https://github.com/jiankunking/log-search" target="_blank" rel="noopener">log-search</a>提供的功能可以参见github：<a href="https://github.com/jiankunking/log-search" target="_blank" rel="noopener">https://github.com/jiankunking/log-search</a></p><blockquote><p>如果日志需要清洗的比较多，可以采用方案1，或者先不清洗，先把数据落到Elasticsearch，然后在查询的时候，进行处理。比如在我们的场景中，可以先把日志落到Elasticsearch中，然后在需要检索应用名称的时候，通过代码来处理并获取app名字。</p></blockquote><h1 id="监控、告警"><a href="#监控、告警" class="headerlink" title="监控、告警"></a>监控、告警</h1><p>其实基于日志可以做很多事情，比如：</p><ul><li>基于日志做监控（Google Dapper）</li><li>基于日志做告警</li><li>基于日志做Machine Learning</li></ul><p>具体思路，可以参见下图：</p><p><img src="/images/log-service-architecture-design/%E5%9F%BA%E4%BA%8E%E6%97%A5%E5%BF%97%E7%9A%84%E7%9B%91%E6%8E%A7%E3%80%81%E5%91%8A%E8%AD%A6.png" alt></p><blockquote><p>前提：能要求使用方，按照某种规则打印日志。<br>监控发展：监控基本就是先打通链路trace，然后再在上报信息或者日志信息中，加强业务方面标识，即给监控添加业务维度方面的视角。</p></blockquote><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2><p>以DaemonSet方式部署Filebeat来收集日志，其实收集也是宿主机/var/lib/docker/containers目录下的日志。<br>Running Filebeat on Kubernetes</p><h2 id="Sidecar"><a href="#Sidecar" class="headerlink" title="Sidecar"></a>Sidecar</h2><p>一个POD中运行一个sidecar的日志agent容器，用于采集该POD主容器产生的日志。</p><p>莫名想起了istio。</p><blockquote><p>Filebeat可以以sidecar模式来进行容器日志的收集，也就是filebeat和具体的服务容器部署在同一个pod内，指定收集日志的路径或文件，&gt; 即可将日志发送到指定位置或Elasticsearch这类的搜索引擎。<br>每个pod内部署filebeat的模式，好处是和具体的应用服务低耦合，可扩展性强，不过需要在yaml进行额外配置。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> Log </tag>
            
            <tag> Elasticsearch </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当你在浏览器中输入 google.com 并且按下回车之后发生了什么？</title>
      <link href="/what-happens-when.html"/>
      <url>/what-happens-when.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>当你在浏览器中输入 google.com 并且按下回车之后发生了什么？<br>整理自 <a href="https://github.com/skyline75489/what-happens-when-zh_CN" target="_blank" rel="noopener">https://github.com/skyline75489/what-happens-when-zh_CN</a></p></blockquote><a id="more"></a><h1 id="当···时发生了什么？"><a href="#当···时发生了什么？" class="headerlink" title="当···时发生了什么？"></a>当···时发生了什么？</h1><p>这个仓库试图回答一个古老的面试问题：当你在浏览器中输入 google.com 并且按下回车之后发生了什么？</p><p>不过我们不再局限于平常的回答，而是想办法回答地尽可能具体，不遗漏任何细节。</p><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><h2 id="按下”g”键"><a href="#按下”g”键" class="headerlink" title="按下”g”键"></a>按下”g”键</h2><p>接下来的内容介绍了物理键盘和系统中断的工作原理，但是有一部分内容却没有涉及。当你按下“g”键，浏览器接收到这个消息之后，会触发自动完成机制。浏览器根据自己的算法，以及你是否处于隐私浏览模式，会在浏览器的地址框下方给出输入建议。大部分算法会优先考虑根据你的搜索历史和书签等内容给出建议。你打算输入”google.com”，因此给出的建议并不匹配。但是输入过程中仍然有大量的代码在后台运行，你的每一次按键都会使得给出的建议更加准确。甚至有可能在你输入之前，浏览器就将”google.com” 建议给你。</p><h2 id="回车键按下"><a href="#回车键按下" class="headerlink" title="回车键按下"></a>回车键按下</h2><p>为了从零开始，我们选择键盘上的回车键被按到最低处作为起点。在这个时刻，一个专用于回车键的电流回路被直接地或者通过电容器间接地闭合了，使得少量的电流进入了键盘的逻辑电路系统。这个系统会扫描每个键的状态，对于按键开关的电位弹跳变化进行噪音消除(debounce)，并将其转化为键盘码值。在这里，回车的码值是13。键盘控制器在得到码值之后，将其编码，用于之后的传输。现在这个传输过程几乎都是通过通用串行总线(USB)或者蓝牙(Bluetooth)来进行的，以前是通过PS/2或者ADB连接进行。</p><p><em>USB键盘：</em></p><ul><li>键盘的USB元件通过计算机上的USB接口与USB控制器相连接，USB接口中的第一号针为它提供了5V的电压</li><li>键码值存储在键盘内部电路一个叫做”endpoint”的寄存器内</li><li>USB控制器大概每隔10ms便查询一次”endpoint”以得到存储的键码值数据，这个最短时间间隔由键盘提供</li><li>键值码值通过USB串行接口引擎被转换成一个或者多个遵循低层USB协议的USB数据包</li><li>这些数据包通过D+针或者D-针(中间的两个针)，以最高1.5Mb/s的速度从键盘传输至计算机。速度限制是因为人机交互设备总是被声明成”低速设备”（USB 2.0 compliance）</li><li>这个串行信号在计算机的USB控制器处被解码，然后被人机交互设备通用键盘驱动进行进一步解释。之后按键的码值被传输到操作系统的硬件抽象层</li></ul><p><em>虚拟键盘（触屏设备）：</em></p><ul><li>在现代电容屏上，当用户把手指放在屏幕上时，一小部分电流从传导层的静电域经过手指传导，形成了一个回路，使得屏幕上触控的那一点电压下降，屏幕控制器产生一个中断，报告这次“点击”的坐标</li><li>然后移动操作系统通知当前活跃的应用，有一个点击事件发生在它的某个GUI部件上了，现在这个部件是虚拟键盘的按钮</li><li>虚拟键盘引发一个软中断，返回给OS一个“按键按下”消息</li><li>这个消息又返回来向当前活跃的应用通知一个“按键按下”事件</li></ul><h2 id="产生中断-非USB键盘"><a href="#产生中断-非USB键盘" class="headerlink" title="产生中断[非USB键盘]"></a>产生中断[非USB键盘]</h2><p>键盘在它的中断请求线(IRQ)上发送信号，信号会被中断控制器映射到一个中断向量，实际上就是一个整型数。CPU使用中断描述符表(IDT)把中断向量映射到对应函数，这些函数被称为中断处理器，它们由操作系统内核提供。当一个中断到达时，CPU根据IDT和中断向量索引到对应的中断处理器，然后操作系统内核出场了。</p><h2 id="Windows-一个-WM-KEYDOWN-消息被发往应用程序"><a href="#Windows-一个-WM-KEYDOWN-消息被发往应用程序" class="headerlink" title="(Windows)一个 WM_KEYDOWN 消息被发往应用程序"></a>(Windows)一个 <code>WM_KEYDOWN</code> 消息被发往应用程序</h2><p>HID把键盘按下的事件传送给 <code>KBDHID.sys</code>驱动，把HID的信号转换成一个扫描码(Scancode)，这里回车的扫描码是<br><code>VK_RETURN(0x0d)</code>。 <code>KBDHID.sys</code> 驱动和 <code>KBDCLASS.sys</code>(键盘类驱动,keyboard class driver)进行交互，这个驱动负责安全地处理所有键盘和小键盘的输入事件。之后它又去调用<code>Win32K.sys</code>，在这之前有可能把消息传递给安装的第三方键盘过滤器。这些都是发生在内核模式。</p><p><code>Win32K.sys</code> 通过 <code>GetForegroundWindow()</code>API函数找到当前哪个窗口是活跃的。这个API函数提供了当前浏览器的地址栏的句柄。Windows系统的”message pump”机制调用 <code>SendMessage(hWnd, WM_KEYDOWN, VK_RETURN, lParam)</code> 函数，<code>lParam</code>是一个用来指示这个按键的更多信息的掩码，这些信息包括按键重复次数（这里是0），实际扫描码（可能依赖于OEM厂商，不过通常不会是<code>VK_RETURN</code> ），功能键（alt, shift, ctrl）是否被按下（在这里没有），以及一些其他状态。</p><p>Windows的 <code>SendMessage</code> API直接将消息添加到特定窗口句柄 <code>hWnd</code>的消息队列中，之后赋给 <code>hWnd</code> 的主要消息处理函数 <code>WindowProc</code>将会被调用，用于处理队列中的消息。</p><p>当前活跃的句柄 <code>hWnd</code> 实际上是一个edit control控件，这种情况下，<code>WindowProc</code> 有一个用于处理 <code>WM_KEYDOWN</code><br>消息的处理器，这段代码会查看 <code>SendMessage</code> 传入的第三个参数 <code>wParam</code>，因为这个参数是 <code>VK_RETURN</code> ，于是它知道用户按下了回车键。</p><h2 id="Mac-OS-X-一个-KeyDown-NSEvent被发往应用程序"><a href="#Mac-OS-X-一个-KeyDown-NSEvent被发往应用程序" class="headerlink" title="(Mac OS X)一个 KeyDown NSEvent被发往应用程序"></a>(Mac OS X)一个 <code>KeyDown</code> NSEvent被发往应用程序</h2><p>中断信号引发了I/O Kit Kext键盘驱动的中断处理事件，驱动把信号翻译成键码值，然后传给OS X的<code>WindowServer</code> 进程。然后， <code>WindowServer</code>将这个事件通过Mach端口分发给合适的（活跃的，或者正在监听的）应用程序，这个信号会被放到应用程序的消息队列里。队列中的消息可以被拥有足够高权限的线程使用<code>mach_ipc_dispatch</code> 函数读取到。这个过程通常是由 <code>NSApplication</code>主事件循环产生并且处理的，通过 <code>NSEventType</code> 为 <code>KeyDown</code> 的 <code>NSEvent</code>。</p><h2 id="GNU-Linux-Xorg-服务器监听键码值"><a href="#GNU-Linux-Xorg-服务器监听键码值" class="headerlink" title="(GNU/Linux)Xorg 服务器监听键码值"></a>(GNU/Linux)Xorg 服务器监听键码值</h2><p>当使用图形化的 X Server 时，X Server会按照特定的规则把键码值再一次映射，映射成扫描码。当这个映射过程完成之后，X Server 把这个按键字符发送给窗口管理器(DWM，metacity,i3等等)，窗口管理器再把字符发送给当前窗口。当前窗口使用有关图形API把文字打印在输入框内。</p><h2 id="解析URL"><a href="#解析URL" class="headerlink" title="解析URL"></a>解析URL</h2><ul><li><p>浏览器通过 URL 能够知道下面的信息：</p><blockquote><ul><li><dl><dt><code>Protocol</code> “http”</dt><dd>使用HTTP协议</dd></dl></li><li><dl><dt><code>Resource</code> “/“</dt><dd>请求的资源是主页(index)</dd></dl></li></ul></blockquote></li></ul><h2 id="输入的是-URL-还是搜索的关键字？"><a href="#输入的是-URL-还是搜索的关键字？" class="headerlink" title="输入的是 URL 还是搜索的关键字？"></a>输入的是 URL 还是搜索的关键字？</h2><p>当协议或主机名不合法时，浏览器会将地址栏中输入的文字传给默认的搜索引擎。大部分情况下，在把文字传递给搜索引擎的时候，URL会带有特定的一串字符，用来告诉搜索引擎这次搜索来自这个特定浏览器。</p><h2 id="转换非-ASCII-的-Unicode-字符"><a href="#转换非-ASCII-的-Unicode-字符" class="headerlink" title="转换非 ASCII 的 Unicode 字符"></a>转换非 ASCII 的 Unicode 字符</h2><ul><li>浏览器检查输入是否含有不是 <code>a-z</code>， <code>A-Z</code>，<code>0-9</code>， <code>-</code> 或者 <code>.</code> 的字符</li><li>这里主机名是 <code>google.com</code>，所以没有非ASCII的字符；如果有的话，浏览器会对主机名部分使用<a href="https://en.wikipedia.org/wiki/Punycode" target="_blank" rel="noopener">Punycode</a> 编码</li></ul><h2 id="检查-HSTS-列表"><a href="#检查-HSTS-列表" class="headerlink" title="检查 HSTS 列表"></a>检查 HSTS 列表</h2><ul><li>浏览器检查自带的“预加载  HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站</li><li>如果网站在这个列表里，浏览器会使用 HTTPS 而不是 HTTP协议，否则，最初的请求会使用HTTP协议发送</li><li>注意，一个网站哪怕不在 HSTS 列表里，也可以要求浏览器对自己使用 HSTS    政策进行访问。浏览器向网站发出第一个HTTP请求之后，网站会返回浏览器一个响应，请求浏览器只使用 HTTPS    发送请求。然而，就是这第一个HTTP请求，却可能会使用户受到downgrade attack_ 的威胁，这也是为什么现代浏览器都预置了 HSTS 列表。</li></ul><h2 id="DNS-查询"><a href="#DNS-查询" class="headerlink" title="DNS 查询"></a>DNS 查询</h2><ul><li>浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开<a href="chrome://net-internals/#dns" target="_blank" rel="noopener"><a href="chrome://net-internals/#dns" target="_blank" rel="noopener">chrome://net-internals/#dns</a></a>）。</li><li>如果缓存中没有，就去调用 <code>gethostbyname</code>库函数（操作系统不同函数也不同）进行查询。</li><li><code>gethostbyname</code> 函数在试图进行DNS解析之前首先检查域名是否在本地Hosts 里，Hosts 的位置<a href="https://en.wikipedia.org/wiki/Hosts_%28file%29#Location_in_the_file_system" target="_blank" rel="noopener">不同的操作系统有所不同</a></li><li>如果 <code>gethostbyname</code> 没有这个域名的缓存记录，也没有在 <code>hosts</code>里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。</li><li>查询本地 DNS 服务器</li><li>如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询</li><li>如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询</li></ul><h2 id="ARP-过程"><a href="#ARP-过程" class="headerlink" title="ARP 过程"></a>ARP 过程</h2><p>要想发送 ARP（地址解析协议）广播，我们需要有一个目标 IP地址，同时还需要知道用于发送 ARP 广播的接口的 MAC 地址。</p><ul><li>首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC</li></ul><p>如果缓存没有命中：</p><ul><li>查看路由表，看看目标 IP  地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。</li><li>查询选择的网络接口的 MAC 地址</li><li>我们发送一个二层（ OSI 模型_ 中的数据链路层）ARP 请求：</li></ul><p><code>ARP Request</code>:</p><pre><code>Sender MAC: interface:mac:address:hereSender IP: interface.ip.goes.hereTarget MAC: FF:FF:FF:FF:FF:FF (Broadcast)Target IP: target.ip.goes.here</code></pre><p>根据连接主机和路由器的硬件类型不同，可以分为以下几种情况：</p><p>直连：</p><ul><li>如果我们和路由器是直接连接的，路由器会返回一个 <code>ARP Reply</code>（见下面）。</li></ul><p>集线器：</p><ul><li>如果我们连接到一个集线器，集线器会把 ARP 请求向所有其它端口广播，如果路由器也“连接”在其中，它会返回一个  <code>ARP Reply</code> 。</li></ul><p>交换机：</p><ul><li>如果我们连接到了一个交换机，交换机会检查本地 CAM/MAC 表，看看哪个端口有我们要找的那个 MAC地址，如果没有找到，交换机会向所有其它端口广播这个 ARP 请求。</li><li>如果交换机的 MAC/CAM 表中有对应的条目，交换机会向有我们想要查询的 MAC 地址的那个端口发送 ARP 请求</li><li>如果路由器也“连接”在其中，它会返回一个 <code>ARP Reply</code></li></ul><p><code>ARP Reply</code>:</p><pre><code>Sender MAC: target:mac:address:hereSender IP: target.ip.goes.hereTarget MAC: interface:mac:address:hereTarget IP: interface.ip.goes.here</code></pre><p>现在我们有了 DNS 服务器或者默认网关的 IP 地址，我们可以继续 DNS 请求了：</p><ul><li>使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议</li><li>如果本地/ISP DNS服务器没有找到结果，它会发送一个递归查询请求，一层一层向高层DNS服务器做查询，直到查询到起始授权机构，如果找到会把结果返回</li></ul><h2 id="使用套接字"><a href="#使用套接字" class="headerlink" title="使用套接字"></a>使用套接字</h2><p>当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数<code>socket</code> ，请求一个 TCP流套接字，对应的参数是 <code>AF_INET/AF_INET6</code> 和<code>SOCK_STREAM</code> 。</p><ul><li>这个请求首先被交给传输层，在传输层请求被封装成 TCP     segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range)</li><li>TCP segment 被送往网络层，网络层会在其中再加入一个 IP   头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet。</li><li>这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame   头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC   地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。</li></ul><p>到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输：</p><ul><li><a href="http://en.wikipedia.org/wiki/IEEE_802.3" target="_blank" rel="noopener">以太网</a></li><li><a href="https://en.wikipedia.org/wiki/IEEE_802.11" target="_blank" rel="noopener">WiFi</a></li><li><a href="https://en.wikipedia.org/wiki/Cellular_data_communication_protocol" target="_blank" rel="noopener">蜂窝数据网络</a></li></ul><p>对于大部分家庭网络和小型企业网络来说，封包会从本地计算机出发，经过本地网络，再通过调制解调器把数字信号转换成模拟信号，使其适于在电话线路，有线电视光缆和无线电话线路上传输。在传输线路的另一端，是另外一个调制解调器，它把模拟信号转换回数字信号，交由下一个<a href="https://en.wikipedia.org/wiki/Computer_network#Network_nodes" target="_blank" rel="noopener">网络节点</a>处理。节点的目标地址和源地址将在后面讨论。</p><p>大型企业和比较新的住宅通常使用光纤或直接以太网连接，这种情况下信号一直是数字的，会被直接传到下一个<a href="https://en.wikipedia.org/wiki/Computer_network#Network_nodes" target="_blank" rel="noopener">网络节点</a>进行处理。</p><p>最终封包会到达管理本地子网的路由器。在那里出发，它会继续经过自治区域(autonomous system, 缩写<br>AS)的边界路由器，其他自治区域，最终到达目标服务器。一路上经过的这些路由器会从IP数据报头部里提取出目标地址，并将封包正确地路由到下一个目的地。IP数据报头部time to live (TTL)域的值每经过一个路由器就减1，如果封包的TTL变为0，或者路由器由于网络拥堵等原因封包队列满了，那么这个包会被路由器丢弃。</p><p>上面的发送和接受过程在 TCP 连接期间会发生很多次：</p><ul><li><p>客户端选择一个初始序列号(ISN)，将设置了 SYN   位的封包发送给服务器端，表明自己要建立连接并设置了初始序列号</p></li><li><p>服务器端接收到 SYN 包，如果它可以建立连接：</p><pre><code>-   服务器端选择它自己的初始序列号-   服务器端设置 SYN 位，表明自己选择了一个初始序列号-   服务器端把 (客户端ISN + 1) 复制到 ACK 域，并且设置 ACK 位，表明自己接收到了客户端的第一个封包</code></pre></li><li><p>客户端通过发送下面一个封包来确认这次连接：</p><pre><code>-   自己的序列号+1-   接收端 ACK+1-   设置 ACK 位</code></pre></li><li><p>数据通过下面的方式传输：</p><pre><code>-   当一方发送了N个 Bytes 的数据之后，将自己的 SEQ 序列号也增加N-   另一方确认接收到这个数据包（或者一系列数据包）之后，它发送一个 ACK包，ACK的值设置为接收到的数据包的最后一个序列号</code></pre></li><li><p>关闭连接时：</p><pre><code>-   要关闭连接的一方发送一个 FIN 包-   另一方确认这个 FIN 包，并且发送自己的 FIN 包-   要关闭的一方使用 ACK 包来确认接收到了 FIN</code></pre></li></ul><h2 id="TLS-握手"><a href="#TLS-握手" class="headerlink" title="TLS 握手"></a>TLS 握手</h2><ul><li>客户端发送一个 <code>ClientHello</code> 消息到服务器端，消息中同时包含了它的Transport Layer Security (TLS) 版本，可用的加密算法和压缩算法。</li><li>服务器端向客户端返回一个 <code>ServerHello</code>消息，消息中包含了服务器端的TLS版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（Certificate Authority，缩写CA）签发的服务器公开证书，证书中包含了公钥。客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥</li><li>客户端根据自己的信任CA列表，验证服务器端的证书是否可信。如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它。这串随机数会被用于生成新的对称密钥</li><li>服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥</li><li>客户端发送一个 <code>Finished</code>消息给服务器端，使用对称密钥加密这次通讯的一个散列值</li><li>服务器端生成自己的 hash 值，然后解密客户端发送来的信息，检查这两个值是否对应。如果对应，就向客户端发送一个<code>Finished</code> 消息，也使用协商好的对称密钥加密</li><li>从现在开始，接下来整个 TLS 会话都使用对称秘钥进行加密，传输应用层（HTTP）内容</li></ul><h2 id="HTTP-协议"><a href="#HTTP-协议" class="headerlink" title="HTTP 协议"></a>HTTP 协议</h2><p>如果浏览器是 Google 出品的，它不会使用 HTTP 协议来获取页面信息，而是会与服务器端发送请求，商讨使用 SPDY 协议。</p><p>如果浏览器使用 HTTP 协议而不支持 SPDY 协议，它会向服务器发送这样的一个请求:</p><pre><code>GET / HTTP/1.1Host: google.comConnection: close[其他头部]</code></pre><p>“其他头部”包含了一系列的由冒号分割开的键值对，它们的格式符合HTTP协议标准，它们之间由一个换行符分割开来。（这里我们假设浏览器没有违反HTTP协议标准的bug，同时假设浏览器使用<code>HTTP/1.1</code> 协议，不然的话头部可能不包含 <code>Host</code> 字段，同时 <code>GET</code>请求中的版本号会变成 <code>HTTP/1.0</code> 或者 <code>HTTP/0.9</code> 。）</p><p>HTTP/1.1 定义了“关闭连接”的选项”close”，发送者使用这个选项指示这次连接在响应结束之后会断开。例如：</p><blockquote><p>Connection:close</p></blockquote><p>不支持持久连接的 HTTP/1.1 应用必须在每条消息中都包含 “close” 选项。</p><p>在发送完这些请求和头部之后，浏览器发送一个换行符，表示要发送的内容已经结束了。</p><p>服务器端返回一个响应码，指示这次请求的状态，响应的形式是这样的:</p><pre><code>200 OK[响应头部]</code></pre><p>然后是一个换行，接下来有效载荷(payload)，也就是 <code>www.google.com</code>的HTML内容。服务器下面可能会关闭连接，如果客户端请求保持连接的话，服务器端会保持连接打开，以供之后的请求重用。</p><p>如果浏览器发送的HTTP头部包含了足够多的信息（例如包含了 Etag 头部），以至于服务器可以判断出，浏览器缓存的文件版本自从上次获取之后没有再更改过，服务器可能会返回这样的响应:</p><pre><code>304 Not Modified[响应头部]</code></pre><p>这个响应没有有效载荷，浏览器会从自己的缓存中取出想要的内容。</p><p>在解析完 HTML之后，浏览器和客户端会重复上面的过程，直到HTML页面引入的所有资源（图片，CSS，favicon.ico等等）全部都获取完毕，区别只是头部的<code>GET / HTTP/1.1</code> 会变成 <code>GET /$(相对www.google.com的URL) HTTP/1.1</code> 。</p><p>如果HTML引入了 <code>www.google.com</code>域名之外的资源，浏览器会回到上面解析域名那一步，按照下面的步骤往下一步一步执行，请求中的<code>Host</code> 头部会变成另外的域名。</p><h2 id="HTTP-服务器请求处理"><a href="#HTTP-服务器请求处理" class="headerlink" title="HTTP 服务器请求处理"></a>HTTP 服务器请求处理</h2><p>HTTPD(HTTP Daemon)在服务器端处理请求/响应。最常见的 HTTPD 有 Linux上常用的 Apache 和 nginx，以及 Windows 上的 IIS。</p><ul><li><p>HTTPD 接收请求</p></li><li><p>服务器把请求拆分为以下几个参数：</p><pre><code>-   HTTP 请求方法(`GET`, `POST`, `HEAD`, `PUT`, `DELETE`,    `CONNECT`, `OPTIONS`, 或者 `TRACE`)。直接在地址栏中输入 URL    这种情况下，使用的是 GET 方法-   域名：google.com-   请求路径/页面：/ (我们没有请求google.com下的指定的页面，因此    / 是默认的路径)</code></pre></li><li><p>服务器验证其上已经配置了 google.com 的虚拟主机</p></li><li><p>服务器验证 google.com 接受 GET 方法</p></li><li><p>服务器验证该用户可以使用 GET 方法(根据 IP 地址，身份信息等)</p></li><li><p>如果服务器安装了 URL 重写模块（例如 Apache 的 mod_rewrite 和 IIS 的URL Rewrite），服务器会尝试匹配重写规则，如果匹配上的话，服务器会按照规则重写这个请求</p></li><li><p>服务器根据请求信息获取相应的响应内容，这种情况下由于访问路径是 “/“,会访问首页文件（你可以重写这个规则，但是这个是最常用的）。</p></li><li><p>服务器会使用指定的处理程序分析处理这个文件，假如 Google 使用PHP，服务器会使用 PHP 解析 index文件，并捕获输出，把 PHP的输出结果返回给请求者</p></li></ul><h2 id="浏览器背后的故事"><a href="#浏览器背后的故事" class="headerlink" title="浏览器背后的故事"></a>浏览器背后的故事</h2><p>当服务器提供了资源之后（HTML，CSS，JS，图片等），浏览器会执行下面的操作：</p><ul><li>解析 —— HTML，CSS，JS</li><li>渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制</li></ul><h2 id="浏览器"><a href="#浏览器" class="headerlink" title="浏览器"></a>浏览器</h2><p>浏览器的功能是从服务器上取回你想要的资源，然后展示在浏览器窗口当中。资源通常是HTML 文件，也可能是<br>PDF，图片，或者其他类型的内容。资源的位置通过用户提供的 URI(Uniform Resource Identifier) 来确定。</p><p>浏览器解释和展示 HTML 文件的方法，在 HTML 和 CSS的标准中有详细介绍。这些标准由 Web 标准组织 W3C(World Wide Web Consortium) 维护。</p><p>不同浏览器的用户界面大都十分接近，有很多共同的 UI 元素：</p><ul><li>一个地址栏</li><li>后退和前进按钮</li><li>书签选项</li><li>刷新和停止按钮</li><li>主页按钮</li></ul><p><strong>浏览器高层架构</strong></p><p>组成浏览器的组件有：</p><ul><li><strong>用户界面</strong> 用户界面包含了地址栏，前进后退按钮，书签菜单等等，除了请求页面之外所有你看到的内容都是用户界面的一部分</li><li><strong>浏览器引擎</strong> 浏览器引擎负责让 UI 和渲染引擎协调工作</li><li><strong>渲染引擎</strong> 渲染引擎负责展示请求内容。如果请求的内容是HTML，渲染引擎会解析 HTML 和 CSS，然后将内容展示在屏幕上</li><li><strong>网络组件</strong> 网络组件负责网络调用，例如 HTTP请求等，使用一个平台无关接口，下层是针对不同平台的具体实现</li><li><strong>UI后端</strong> UI 后端用于绘制基本 UI 组件，例如下拉列表框和窗口。UI后端暴露一个统一的平台无关的接口，下层使用操作系统的 UI 方法实现</li><li><strong>Javascript 引擎</strong> Javascript 引擎用于解析和执行 Javascript 代码</li><li><strong>数据存储</strong> 数据存储组件是一个持久层。浏览器可能需要在本地存储各种各样的数据，例如Cookie 等。浏览器也需要支持诸如 localStorage，IndexedDB，WebSQL 和 FileSystem 之类的存储机制</li></ul><h2 id="HTML-解析"><a href="#HTML-解析" class="headerlink" title="HTML 解析"></a>HTML 解析</h2><p>浏览器渲染引擎从网络层取得请求的文档，一般情况下文档会分成8kB大小的分块传输。</p><p>HTML 解析器的主要工作是对 HTML 文档进行解析，生成解析树。</p><p>解析树是以 DOM 元素以及属性为节点的树。DOM是文档对象模型(Document Object Model)的缩写，它是 HTML 文档的对象表示，同时也是 HTML 元素面向外部(如Javascript)的接口。树的根部是”Document”对象。整个 DOM 和HTML 文档几乎是一对一的关系。</p><p><strong>解析算法</strong></p><p>HTML不能使用常见的自顶向下或自底向上方法来进行分析。主要原因有以下几点:</p><ul><li>语言本身的“宽容”特性</li><li>HTML本身可能是残缺的，对于常见的残缺，浏览器需要有传统的容错机制来支持它们</li><li>解析过程需要反复。对于其他语言来说，源码不会在解析过程中发生变化，但是对于HTML 来说，动态代码，例如脚本元素中包含的 document.write()方法会在源码中添加内容，也就是说，解析过程实际上会改变输入的内容</li></ul><p>由于不能使用常用的解析技术，浏览器创造了专门用于解析 HTML的解析器。解析算法在 HTML5标准规范中有详细介绍，算法主要包含了两个阶段：标记化（tokenization）和树的构建。</p><p><strong>解析结束之后</strong></p><p>浏览器开始加载网页的外部资源（CSS，图像，Javascript 文件等）。</p><p>此时浏览器把文档标记为可交互的（interactive），浏览器开始解析处于“推迟（deferred）”模式的脚本，也就是那些需要在文档解析完毕之后再执行的脚本。之后文档的状态会变为“完成（complete）”，浏览器会触发“加载（load）”事件。</p><p>注意解析 HTML 网页时永远不会出现“无效语法（Invalid Syntax）”错误，浏览器会修复所有错误内容，然后继续解析。</p><h2 id="CSS-解析"><a href="#CSS-解析" class="headerlink" title="CSS 解析"></a>CSS 解析</h2><ul><li>根据 <a href="http://www.w3.org/TR/CSS2/grammar.html" target="_blank" rel="noopener">CSS词法和句法</a>分析CSS文件和 <code>&lt;style&gt;</code> 标签包含的内容以及 style 属性的值</li><li>每个CSS文件都被解析成一个样式表对象（<code>StyleSheet object</code>），这个对象里包含了带有选择器的CSS规则，和对应CSS语法的对象</li><li>CSS解析器可能是自顶向下的，也可能是使用解析器生成器生成的自底向上的解析器</li></ul><h2 id="页面渲染"><a href="#页面渲染" class="headerlink" title="页面渲染"></a>页面渲染</h2><ul><li>通过遍历DOM节点树创建一个“Frame树”或“渲染树”，并计算每个节点的各个CSS样式值</li><li>通过累加子节点的宽度，该节点的水平内边距(padding)、边框(border)和外边距(margin)，自底向上的计算”Frame树”中每个节点的首选(preferred)宽度</li><li>通过自顶向下的给每个节点的子节点分配可行宽度，计算每个节点的实际宽度</li><li>通过应用文字折行、累加子节点的高度和此节点的内边距(padding)、边框(border)和外边距(margin)，自底向上的计算每个节点的高度</li><li>使用上面的计算结果构建每个节点的坐标</li><li>当存在元素使用 <code>floated</code>，位置有 <code>absolutely</code> 或 <code>relatively</code> 属性的时候，会有更多复杂的计算，详见<a href="http://dev.w3.org/csswg/css2/" target="_blank" rel="noopener">http://dev.w3.org/csswg/css2/</a> 和 <a href="http://www.w3.org/Style/CSS/current-work" target="_blank" rel="noopener">http://www.w3.org/Style/CSS/current-work</a></li><li>创建layer(层)来表示页面中的哪些部分可以成组的被绘制，而不用被重新栅格化处理。每个帧对象都被分配给一个层</li><li>页面上的每个层都被分配了纹理(?)</li><li>每个层的帧对象都会被遍历，计算机执行绘图命令绘制各个层，此过程可能由CPU执行栅格化处理，或者直接通过D2D/SkiaGL在GPU上绘制</li><li>上面所有步骤都可能利用到最近一次页面渲染时计算出来的各个值，这样可以减少不少计算量</li><li>计算出各个层的最终位置，一组命令由Direct3D/OpenGL发出，GPU命令缓冲区清空，命令传至GPU并异步渲染，帧被送到Window Server。</li></ul><h2 id="GPU-渲染"><a href="#GPU-渲染" class="headerlink" title="GPU 渲染"></a>GPU 渲染</h2><ul><li>在渲染过程中，图形处理层可能使用通用用途的<code>CPU</code>，也可能使用图形处理器 <code>GPU</code></li><li>当使用 <code>GPU</code>用于图形渲染时，图形驱动软件会把任务分成多个部分，这样可以充分利用<code>GPU</code> 强大的并行计算能力，用于在渲染过程中进行大量的浮点计算。</li></ul><h2 id="Window-Server"><a href="#Window-Server" class="headerlink" title="Window Server"></a>Window Server</h2><h2 id="后期渲染与用户引发的处理"><a href="#后期渲染与用户引发的处理" class="headerlink" title="后期渲染与用户引发的处理"></a>后期渲染与用户引发的处理</h2><p>渲染结束后，浏览器根据某些时间机制运行JavaScript代码(比如Google Doodle动画)或与用户交互(在搜索栏输入关键字获得搜索建议)。类似Flash和Java的插件也会运行，尽管Google主页里没有。这些脚本可以触发网络请求，也可能改变网页的内容和布局，产生又一轮渲染与绘制。</p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>API网关架构设计</title>
      <link href="/api-gateway-design.html"/>
      <url>/api-gateway-design.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>构建一个API网关</p></blockquote><a id="more"></a><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>API Gateway一个比较广泛的定义如下：</p><blockquote><p>API网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。<br>API网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供REST/HTTP的访问API。服务端通过API-GW注册和管理服务。</p></blockquote><p>从定义中可以归纳出一下几个核心点：</p><ol><li>服务调用的统一入口</li><li>AuthN（Authentication is establishing the your identity.）</li><li>AuthZ （Authorization is establishing your privileges.）</li><li>监控（请求延迟、异常数、审计日志、访问日志）</li><li>高可用</li><li>白名单、黑名单</li><li>限流</li><li>熔断</li><li>服务发现</li><li>协议支持 （协议转换）</li><li>…</li></ol><h1 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h1><p><img src="/images/api-gateway-design/API-Gateway.png" alt></p><p>介绍几个概念：</p><ol><li><p>先说RC（Replication Controller）是什么？</p><p> RC保证在同一时间能够运行指定数量的Pod副本，保证Pod总是可用。如果实际Pod数量比指定的多就结束掉多余的，如果实际数量比指定的少就启动缺少的。当Pod失败、被删除或被终结时RC会自动创建新的Pod来保证副本数量。所以即使只有一个Pod也应该使用RC来进行管理。</p></li><li><p>HPA<br> Horizontal Pod Autoscaling，简称HPA，是Kubernetes中实现POD水平自动伸缩的功能。</p><p> HPA是kubernetes里面pod弹性伸缩的实现,它能根据设置的监控阀值进行pod的弹性扩缩容，目前默认HPA只能支持cpu和内存的阀值检测扩缩容，但也可以通过custom metric api 调用prometheus实现自定义metric 来更加灵活的监控指标实现弹性伸缩。</p></li></ol><h1 id="取舍"><a href="#取舍" class="headerlink" title="取舍"></a>取舍</h1><p>取舍也就是如何构建适合自己的API Gateway？</p><p>其实，这个问题也可以拓展为如何开发适应自己业务的某系统，个人感觉应该从以下几点考虑：</p><ul><li>自己的业务系统需要什么样的功能？</li><li>业界中该类系统都是如何实现的？</li><li>自己的基础设施情况（主要是PaaS及中间件）如何？</li></ul><p>综合1、2考虑，在满足业务需求的前提下，往远了考虑，往简单了实现（既满足目前的功能，又方便以后拓展）。<br>回到API Gateway这个话题，那就需要考虑一下，自己的业务系统是否需要以上列出的所有功能点？如果不是或者目前不是，那我应该先实现哪一部分？</p><p>其中，作为一个Gateway，以下几点应该是基础功能：</p><ul><li>服务调用的统一入口</li><li>AuthN（Authentication is establishing the your identity.）</li><li>AuthZ （Authorization is establishing your privileges.）</li><li>监控（请求延迟、异常数、审计日志、访问日志）</li><li>高可用</li></ul><p>剩下的功能实现就要看业务需要及时间了。<br>如果系统本身的访问量不大，那么限流、熔断是否就可以先不实现？</p><h2 id="为什么需要关注自己的基础设施情况（主要是PaaS及中间件）？"><a href="#为什么需要关注自己的基础设施情况（主要是PaaS及中间件）？" class="headerlink" title="为什么需要关注自己的基础设施情况（主要是PaaS及中间件）？"></a>为什么需要关注自己的基础设施情况（主要是PaaS及中间件）？</h2><p>比如基础设施中已提供Kubernetes集群服务，那么毫无疑问的高可用方案，应该选择RC方案。如果没有Kubernetes集群服务，那么高可用就需要考虑别的方案了。</p><blockquote><p>可以发现其实手撕一个api网关，也不是多么难的事情，其中很多点，底层包都已经提供了支持，只是需要支持的功能比较多。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Architecture </tag>
            
            <tag> Gateway </tag>
            
            <tag> Design </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Volatile的内存语义与AQS锁内存可见性</title>
      <link href="/java-volatile-aqs.html"/>
      <url>/java-volatile-aqs.html</url>
      
        <content type="html"><![CDATA[<p>提到volatile首先想到就是：</p><ul><li>保证此变量对所有线程的可见性，这里的 “可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。</li><li>禁止指令重排序优化。</li></ul><p>到这里大家感觉自己对volatile理解了吗？ </p><p>如果理解了，大家考虑这么一个问题：ReentrantLock（或者其它基于AQS实现的锁）是如何保证代码段中变量（变量主要是指共享变量，存在竞争问题的变量）的可见性？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private static ReentrantLock reentrantLock = new ReentrantLock();</span><br><span class="line">private static intcount = 0;</span><br><span class="line">//...</span><br><span class="line">// 多线程 run 如下代码</span><br><span class="line">reentrantLock.lock();</span><br><span class="line">try</span><br><span class="line">&#123;</span><br><span class="line">    count++;</span><br><span class="line">&#125; </span><br><span class="line">finally</span><br><span class="line">&#123;</span><br><span class="line">    reentrantLock.unlock();</span><br><span class="line">&#125;</span><br><span class="line">//...</span><br></pre></td></tr></table></figure><p>既然提到了可见性，那就先熟悉几个概念：</p><h1 id="1、JMM"><a href="#1、JMM" class="headerlink" title="1、JMM"></a>1、JMM</h1><p>JMM：Java Memory Model 即 Java 内存模型</p><blockquote><p>The Java Memory Model describes what behaviors are legal in multithreaded code, and how threads may interact through memory.</p></blockquote><blockquote><p>It describes the relationship between variables in a program and the low-level details of storing and retrieving them to and from memory or registers in a real computer system.</p></blockquote><blockquote><p>It does this in a way that can be implemented correctly using a wide variety of hardware and a wide variety of compiler optimizations.</p></blockquote><p><font color="DeepPink"><strong>Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。</strong></font>此处的变量主要是指共享变量，存在竞争问题的变量。Java内存模型规定所有的变量都存储在主内存中，而每条线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（<font color="DeepPink"><strong>根据Java虚拟机规范的规定，volatile变量依然有共享内存的拷贝，但是由于它特殊的操作顺序性规定——从工作内存中读写数据前，必须先将主内存中的数据同步到工作内存中，所有看起来如同直接在主内存中读写访问一般，因此这里的描述对于volatile也不例外</strong></font>）。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值得传递均需要通过主内存来完成。</p><h1 id="2、重排序"><a href="#2、重排序" class="headerlink" title="2、重排序"></a>2、重排序</h1><p>在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：</p><ul><li>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</li><li>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li><li>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</li></ul><p>从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序：</p><p><img src="/images/java-aqs-voliate/%E9%87%8D%E6%8E%92%E5%BA%8F.png" alt></p><p>对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。 </p><p>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。</p><h1 id="3、happens-before"><a href="#3、happens-before" class="headerlink" title="3、happens-before"></a>3、happens-before</h1><ul><li>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</li><li>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</li><li>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。（对一个volatile变量的读，总是能看到【任意线程】对这个volatile变量最后的写入）</li><li>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</li></ul><blockquote><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。</p></blockquote><h1 id="4、内存屏障"><a href="#4、内存屏障" class="headerlink" title="4、内存屏障"></a>4、内存屏障</h1><ul><li>硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。</li><li><font color="DeepPink"><strong>对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；</strong></font></li><li><font color="DeepPink"><strong>对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。</strong></font></li><li>内存屏障有两个作用：<ul><li>阻止屏障两侧的指令重排序；</li><li>强制把写缓冲区/高速缓存中的数据等写回主内存，让缓存中相应的数据失效。<h1 id="5、volatile的内存语义"><a href="#5、volatile的内存语义" class="headerlink" title="5、volatile的内存语义"></a>5、volatile的内存语义</h1></li></ul></li></ul><p>从JSR-133开始（即从JDK5开始），volatile变量的写-读可以实现线程之间的通信。</p><p><font color="DeepPink"><strong>从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果</strong></font>：</p><ul><li>volatile写和锁的释放有相同的内存语义；</li><li>volatile读与锁的获取有相同的内存语义。</li></ul><blockquote><p>volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。</p></blockquote><p>volatile变量自身具有下列特性：</p><ul><li>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</li><li>原子性：对任意单个volatile变量的读/写具有原子性，即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读/写就具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。</li></ul><p>volatile写和volatile读的内存语义：</p><ul><li><font color="DeepPink"><strong>线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。</strong></font></li><li><font color="DeepPink"><strong>线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。</strong></font></li><li><font color="DeepPink"><strong>线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。</strong></font></li></ul><p>JMM针对编译器制定的volatile重排序规则表</p><p><img src="/images/java-aqs-voliate/JMM%E9%92%88%E5%AF%B9%E7%BC%96%E8%AF%91%E5%99%A8%E5%88%B6%E5%AE%9A%E7%9A%84volatile%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99%E8%A1%A8.png" alt></p><ul><li><font color="DeepPink"><strong>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</strong></font></li><li><font color="DeepPink"><strong>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</strong></font></li><li><font color="DeepPink"><strong>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</strong></font></li></ul><p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。<strong>对于编译器来说，发现一个最优布置来最小化插入屏障几乎是不可能的。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。</strong></p><ul><li>在每个volatile写操作的前面插入一个StoreStore屏障。</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadStore屏障。</li></ul><blockquote><p>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</p></blockquote><blockquote><p>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。  LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</p></blockquote><blockquote><p>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。<br>上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。</p></blockquote><p>下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图. </p><p><img src="/images/java-aqs-voliate/volatile%E5%86%99%E6%8F%92%E5%85%A5%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%90%8E%E7%94%9F%E6%88%90%E7%9A%84%E6%8C%87%E4%BB%A4%E5%BA%8F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><p>图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为<strong>StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。</strong></p><p>这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。</p><p>下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图:<br><img src="/images/java-aqs-voliate/volatile%E8%AF%BB%E6%8F%92%E5%85%A5%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%90%8E%E7%94%9F%E6%88%90%E7%9A%84%E6%8C%87%E4%BB%A4%E5%BA%8F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt><br>图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 </p><p>上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。</p><h1 id="6、AQS"><a href="#6、AQS" class="headerlink" title="6、AQS"></a>6、AQS</h1><p>对于AQS需要了解这么几点： </p><ul><li>锁的状态通过volatile int state来表示。 </li><li>获取不到锁的线程会进入AQS的队列等待。 </li><li>子类需要重写tryAcquire、tryRelease等方法。</li></ul><p>AQS 详解参见：<a href="https://www.jiankunking.com/java-aqs.html" target="_blank" rel="noopener">面试必备：Java AQS 实现原理（图文）分析</a> </p><h1 id="7、ReentrantLock"><a href="#7、ReentrantLock" class="headerlink" title="7、ReentrantLock"></a>7、ReentrantLock</h1><p>以公平锁为例，看看 ReentrantLock 获取锁 &amp; 释放锁的关键代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The synchronization state.</span><br><span class="line"> */</span><br><span class="line">private volatile int state;</span><br><span class="line">/**</span><br><span class="line"> * Returns the current value of synchronization state.</span><br><span class="line"> * This operation has memory semantics of a &#123;@code volatile&#125; read.</span><br><span class="line"> * @return current state value</span><br><span class="line"> */</span><br><span class="line">protected final int getState() &#123;</span><br><span class="line">    return state;</span><br><span class="line">&#125;</span><br><span class="line">protected final boolean tryRelease(int releases) &#123;</span><br><span class="line">    int c = getState() - releases;</span><br><span class="line">    if (Thread.currentThread() != getExclusiveOwnerThread())</span><br><span class="line">        throw new IllegalMonitorStateException();</span><br><span class="line">    boolean free = false;</span><br><span class="line">    if (c == 0) &#123;</span><br><span class="line">        free = true;</span><br><span class="line">        setExclusiveOwnerThread(null);</span><br><span class="line">    &#125;</span><br><span class="line">    setState(c);// 释放锁的最后，写volatile变量state</span><br><span class="line">    return free;</span><br><span class="line">&#125;</span><br><span class="line"> protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">        final Thread current = Thread.currentThread();</span><br><span class="line">        int c = getState();// 获取锁的开始，首先读volatile变量state</span><br><span class="line">        if (c == 0) &#123;</span><br><span class="line">            if (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">                compareAndSetState(0, acquires)) &#123;</span><br><span class="line">                setExclusiveOwnerThread(current);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">            int nextc = c + acquires;</span><br><span class="line">            if (nextc &lt; 0)</span><br><span class="line">                throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">            setState(nextc);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。从而保证了代码段中变量（变量主要是指共享变量，存在竞争问题的变量）的可见性。</strong></font></p><h1 id="8、小结"><a href="#8、小结" class="headerlink" title="8、小结"></a>8、小结</h1><p>如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。 </p><ul><li>首先，<font color="DeepPink"><strong>声明共享变量为volatile。</strong></font></li><li>然后，<font color="DeepPink"><strong>使用CAS的原子条件更新来实现线程之间的同步。</strong></font></li><li>同时，<font color="DeepPink"><strong>配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。</strong></font><blockquote><p>前文我们提到过，编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。</p></blockquote></li></ul><p>本文参考： </p><p>1、《Java并发编程的艺术》 方腾飞　魏鹏　程晓明　著</p><p>2、<a href="https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247485795&idx=2&sn=73d5bcd83378f6176f9593d33dc402dc&chksm=eb538c55dc240543df3cd113cb3e586e98d3ccd0a93c6a87829a04e296b990a554596338046e#rd" target="_blank" rel="noopener">Java 可重入锁内存可见性分析</a> </p>]]></content>
      
      
      <categories>
          
          <category> JUC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> JUC </tag>
            
            <tag> AQS </tag>
            
            <tag> Volatile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Lambda表达式 实现原理分析</title>
      <link href="/java-lambda.html"/>
      <url>/java-lambda.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文分析基于JDK 9</p></blockquote><a id="more"></a><h1 id="一、目标"><a href="#一、目标" class="headerlink" title="一、目标"></a>一、目标</h1><p>本文主要解决两个问题： </p><p>1、函数式接口 到底是什么？ </p><p>2、Lambda表达式是怎么实现的？</p><p>先介绍一个jdk的bin目录下的一个字节码查看工具及反编译工具：javap</p><p><img src="/images/java-lambda/javap.png" alt></p><h1 id="二、函数式接口"><a href="#二、函数式接口" class="headerlink" title="二、函数式接口"></a>二、函数式接口</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过javap 反编译IFunctionTest.class 可以看到如下信息:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt;javap -p IFunctionTest.class</span><br><span class="line">Compiled from &quot;FunctionTest.java&quot;</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">  public abstract void print(T);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到函数式接口编译完之后依然是一个接口，这个接口具有唯一的一个抽像方法。</p><p>为什么说需要是唯一一个抽象方法？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">    public void print22(T x,int rr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/java-lambda/javac-FunctionTest.png" alt></p><p>虽然不能在函数式接口中定义多个方法，但可以定义默认方法、静态方法、定义java.lang.Object里的public方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">    default void doSomeMoreWork1()&#123;</span><br><span class="line">        // Method body</span><br><span class="line">    &#125;</span><br><span class="line">    static void printHello()&#123;</span><br><span class="line">        System.out.println(&quot;Hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    boolean equals(Object obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>反编译文件内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt;javap -p IFunctionTest.class</span><br><span class="line">Compiled from &quot;FunctionTest.java&quot;</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">  public abstract void print(T);</span><br><span class="line">  public void doSomeMoreWork1();</span><br><span class="line">  public static void printHello();</span><br><span class="line">  public abstract boolean equals(java.lang.Object);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="三、Lambda"><a href="#三、Lambda" class="headerlink" title="三、Lambda"></a>三、Lambda</h1><h2 id="3-1-示例代码"><a href="#3-1-示例代码" class="headerlink" title="3.1 示例代码"></a>3.1 示例代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void printString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        printString(&quot;test&quot;, (x) -&gt; System.out.println(x));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过javac编译LambdaTest.java文件，会生成LambdaTest.class、Print.class两个class文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac LambdaTest.java</span><br></pre></td></tr></table></figure><p><img src="/images/java-lambda/javac-LambdaTest.png" alt></p><h2 id="3-2-对于lambda实现的猜测"><a href="#3-2-对于lambda实现的猜测" class="headerlink" title="3.2 对于lambda实现的猜测"></a>3.2 对于lambda实现的猜测</h2><p>那么编译器对Lambda 都做了什么？反编译一下代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\Code\Java\study&gt;javap -p LambdaTest.class</span><br><span class="line">Compiled from &quot;LambdaTest.java&quot;</span><br><span class="line">public class LambdaTest &#123;</span><br><span class="line">  public LambdaTest();</span><br><span class="line">  public static void printString(java.lang.String, Print&lt;java.lang.String&gt;);</span><br><span class="line">  public static void main(java.lang.String[]);</span><br><span class="line">  private static void lambda$main$0(java.lang.String);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由上面的代码可以看出编译器会根据Lambda表达式生成一个私有的静态函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private static void lambda$main$0(java.lang.String);</span><br></pre></td></tr></table></figure><p>为了验证上面的转化是否正确? 我们在代码中定义一个lambda$main$0这个的函数，最终代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void printString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        printString(&quot;test&quot;, (x) -&gt; System.out.println(x));</span><br><span class="line">    &#125;</span><br><span class="line">    private static void lambda$main$0(String s) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码在编译时会报错，错误信息如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\Code\Java\study&gt;javac LambdaTest.java</span><br><span class="line">LambdaTest.java:8: 错误: 符号lambda$main$0(String)与LambdaTest中的 compiler-synt</span><br><span class="line">hesized 符号冲突</span><br><span class="line">    private static void lambda$main$0(String s) &#123;</span><br><span class="line">                        ^</span><br><span class="line">LambdaTest.java:1: 错误: 符号lambda$main$0(String)与LambdaTest中的 compiler-synt</span><br><span class="line">hesized 符号冲突</span><br><span class="line">public class LambdaTest &#123;</span><br><span class="line">^</span><br><span class="line">2 个错误</span><br></pre></td></tr></table></figure><p>有了上面的内容，可以知道的是Lambda表达式在Java 9中首先会生成一个私有的静态函数，这个私有的静态函数干的就是Lambda表达式里面的内容，那么又是如何调用的生成的私有静态函数（lambda$main$0(String s)）呢？</p><h2 id="3-3-反编译代码详解"><a href="#3-3-反编译代码详解" class="headerlink" title="3.3 反编译代码详解"></a>3.3 反编译代码详解</h2><p>查看更加详细的反编译结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt; javap -p -v -c LambdaTest.class</span><br><span class="line">Classfile /C:/Users/Code/Java/study/LambdaTest.class</span><br><span class="line">  Last modified 2018-4-5; size 1184 bytes</span><br><span class="line">  MD5 checksum b144b5a936a04a7c975eae93c7370174</span><br><span class="line">  Compiled from &quot;LambdaTest.java&quot;</span><br><span class="line">public class LambdaTest</span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 52</span><br><span class="line">  flags: ACC_PUBLIC, ACC_SUPER</span><br><span class="line">Constant pool:</span><br><span class="line">   #1 = Methodref          #9.#24         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">   #2 = InterfaceMethodref #25.#26        // Print.print:(Ljava/lang/Object;)V</span><br><span class="line">   #3 = String             #27            // test</span><br><span class="line">   #4 = InvokeDynamic      #0:#33         // #0:print:()LPrint;</span><br><span class="line">   #5 = Methodref          #8.#34         // LambdaTest.printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">   #6 = Fieldref           #35.#36        // java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">   #7 = Methodref          #37.#38        // java/io/PrintStream.println:(Ljava/lang/String;)V</span><br><span class="line">   #8 = Class              #39            // LambdaTest</span><br><span class="line">   #9 = Class              #40            // java/lang/Object</span><br><span class="line">  #10 = Utf8               &lt;init&gt;</span><br><span class="line">  #11 = Utf8               ()V</span><br><span class="line">  #12 = Utf8               Code</span><br><span class="line">  #13 = Utf8               LineNumberTable</span><br><span class="line">  #14 = Utf8               printString</span><br><span class="line">  #15 = Utf8               (Ljava/lang/String;LPrint;)V</span><br><span class="line">  #16 = Utf8               Signature</span><br><span class="line">  #17 = Utf8               (Ljava/lang/String;LPrint&lt;Ljava/lang/String;&gt;;)V</span><br><span class="line">  #18 = Utf8               main</span><br><span class="line">  #19 = Utf8               ([Ljava/lang/String;)V</span><br><span class="line">  #20 = Utf8               lambda$main$0</span><br><span class="line">  #21 = Utf8               (Ljava/lang/String;)V</span><br><span class="line">  #22 = Utf8               SourceFile</span><br><span class="line">  #23 = Utf8               LambdaTest.java</span><br><span class="line">  #24 = NameAndType        #10:#11        // &quot;&lt;init&gt;&quot;:()V</span><br><span class="line">  #25 = Class              #41            // Print</span><br><span class="line">  #26 = NameAndType        #42:#43        // print:(Ljava/lang/Object;)V</span><br><span class="line">  #27 = Utf8               test</span><br><span class="line">  #28 = Utf8               BootstrapMethods</span><br><span class="line">  #29 = MethodHandle       #6:#44         // invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #30 = MethodType         #43            //  (Ljava/lang/Object;)V</span><br><span class="line">  #31 = MethodHandle       #6:#45         // invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">  #32 = MethodType         #21            //  (Ljava/lang/String;)V</span><br><span class="line">  #33 = NameAndType        #42:#46        // print:()LPrint;</span><br><span class="line">  #34 = NameAndType        #14:#15        // printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">  #35 = Class              #47            // java/lang/System</span><br><span class="line">  #36 = NameAndType        #48:#49        // out:Ljava/io/PrintStream;</span><br><span class="line">  #37 = Class              #50            // java/io/PrintStream</span><br><span class="line">  #38 = NameAndType        #51:#21        // println:(Ljava/lang/String;)V</span><br><span class="line">  #39 = Utf8               LambdaTest</span><br><span class="line">  #40 = Utf8               java/lang/Object</span><br><span class="line">  #41 = Utf8               Print</span><br><span class="line">  #42 = Utf8               print</span><br><span class="line">  #43 = Utf8               (Ljava/lang/Object;)V</span><br><span class="line">  #44 = Methodref          #52.#53        // java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #45 = Methodref          #8.#54         // LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">  #46 = Utf8               ()LPrint;</span><br><span class="line">  #47 = Utf8               java/lang/System</span><br><span class="line">  #48 = Utf8               out</span><br><span class="line">  #49 = Utf8               Ljava/io/PrintStream;</span><br><span class="line">  #50 = Utf8               java/io/PrintStream</span><br><span class="line">  #51 = Utf8               println</span><br><span class="line">  #52 = Class              #55            // java/lang/invoke/LambdaMetafactory</span><br><span class="line">  #53 = NameAndType        #56:#60        // metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #54 = NameAndType        #20:#21        // lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line"></span><br><span class="line">  #55 = Utf8               java/lang/invoke/LambdaMetafactory</span><br><span class="line">  #56 = Utf8               metafactory</span><br><span class="line">  #57 = Class              #62            // java/lang/invoke/MethodHandles$Lookup</span><br><span class="line">  #58 = Utf8               Lookup</span><br><span class="line">  #59 = Utf8               InnerClasses</span><br><span class="line">  #60 = Utf8               (Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #61 = Class              #63            // java/lang/invoke/MethodHandles</span><br><span class="line">  #62 = Utf8               java/lang/invoke/MethodHandles$Lookup</span><br><span class="line">  #63 = Utf8               java/lang/invoke/MethodHandles</span><br><span class="line">&#123;</span><br><span class="line">  public LambdaTest();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=1, args_size=1</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">         4: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 1: 0</span><br><span class="line"></span><br><span class="line">  public static void printString(java.lang.String, Print&lt;java.lang.String&gt;);</span><br><span class="line">    descriptor: (Ljava/lang/String;LPrint;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=2, args_size=2</span><br><span class="line">         0: aload_1</span><br><span class="line">         1: aload_0</span><br><span class="line">         2: invokeinterface #2,  2            // InterfaceMethod Print.print:(Ljava/lang/Object;)V</span><br><span class="line">         7: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 3: 0</span><br><span class="line">        line 4: 7</span><br><span class="line">    Signature: #17                          // (Ljava/lang/String;LPrint&lt;Ljava/lang/String;&gt;;)V</span><br><span class="line"></span><br><span class="line">  public static void main(java.lang.String[]);</span><br><span class="line">    descriptor: ([Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: ldc           #3                  // String test</span><br><span class="line">         2: invokedynamic #4,  0              // InvokeDynamic #0:print:()LPrint;</span><br><span class="line">         7: invokestatic  #5                  // Method printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">        10: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 6: 0</span><br><span class="line">        line 7: 10</span><br><span class="line"></span><br><span class="line">  private static void lambda$main$0(java.lang.String);</span><br><span class="line">    descriptor: (Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PRIVATE, ACC_STATIC, ACC_SYNTHETIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: getstatic     #6                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">         3: aload_0</span><br><span class="line">         4: invokevirtual #7                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V</span><br><span class="line">         7: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 6: 0</span><br><span class="line">&#125;</span><br><span class="line">SourceFile: &quot;LambdaTest.java&quot;</span><br><span class="line">InnerClasses:</span><br><span class="line">     public static final #58= #57 of #61; //Lookup=class java/lang/invoke/MethodHandles$Lookup of class java/lang/invoke/MethodHandles</span><br><span class="line">BootstrapMethods:</span><br><span class="line">  0: #29 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;Method arguments:</span><br><span class="line">      #30 (Ljava/lang/Object;)V</span><br><span class="line">      #31 invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">      #32 (Ljava/lang/String;)V</span><br></pre></td></tr></table></figure><p>这个 class 文件展示了三个主要部分：常量池、构造器方法和 printString、main、lambdamainmain0方法还有lambda表达式生成的内部类。</p><h3 id="3-3-1-动态链接"><a href="#3-3-1-动态链接" class="headerlink" title="3.3.1 动态链接"></a>3.3.1 动态链接</h3><p>每个栈帧都有一个运行时常量池的引用。这个引用指向栈帧当前运行方法所在类的常量池。通过这个引用支持动态链接（dynamic linking）。</p><p>C/C++ 代码一般被编译成对象文件，然后多个对象文件被链接到一起产生可执行文件或者 dll。在链接阶段，每个对象文件的符号引用被替换成了最终执行文件的相对偏移内存地址。在 Java中，链接阶段是运行时动态完成的。</p><p><font color="DeepPink"><strong>当 Java 类文件编译时，所有变量和方法的引用都被当做符号引用存储在这个类的常量池中。符号引用是一个逻辑引用，实际上并不指向物理内存地址。JVM 可以选择符号引用解析的时机，一种是当类文件加载并校验通过后，这种解析方式被称为饥饿方式。另外一种是符号引用在第一次使用的时候被解析，这种解析方式称为惰性方式。无论如何 ，JVM 必须要在第一次使用符号引用时完成解析并抛出可能发生的解析错误。绑定是将对象域、方法、类的符号引用替换为直接引用的过程。绑定只会发生一次。一旦绑定，符号引用会被完全替换。如果一个类的符号引用还没有被解析，那么就会载入这个类。每个直接引用都被存储为相对于存储结构（与运行时变量或方法的位置相关联的）偏移量。</strong></font></p><h3 id="3-3-2-常量池"><a href="#3-3-2-常量池" class="headerlink" title="3.3.2 常量池"></a>3.3.2 常量池</h3><p>JVM 维护了一个按类型区分的常量池，一个类似于符号表的运行时数据结构。尽管它包含更多数据。Java 字节码需要数据。这个数据经常因为太大不能直接存储在字节码中，取而代之的是存储在常量池中，字节码包含这个常量池的引用。</p><p>常量池中可以存储多种类型的数据：</p><ul><li>数字型</li><li>字符串型</li><li>类引用型</li><li>域引用型</li><li>方法引用</li></ul><h3 id="3-3-3-方法"><a href="#3-3-3-方法" class="headerlink" title="3.3.3 方法"></a>3.3.3 方法</h3><p>每一个方法包含四个区域：</p><ul><li>签名和访问标签</li><li>字节码</li><li>LineNumberTable：为调试器提供源码中的每一行对应的字节码信息</li><li>LocalVariableTable：列出了所有栈帧中的局部变量</li></ul><table><thead><tr><th>操作码</th><th>作用</th></tr></thead><tbody><tr><td>aload0</td><td>这个操作码是aload格式操作码中的一个。它们用来把对象引用加载到操作码栈。表示正在被访问的局部变量数组的位置，但只能是0、1、2、3 中的一个。还有一些其它类似的操作码用来载入非对象引用的数据，如iload, lload, float 和 dload。其中 i 表示 int，l 表示 long，f 表示 float，d 表示 double。局部变量数组位置大于 3 的局部变量可以用 iload, lload, float, dload 和 aload 载入。这些操作码都只需要一个操作数，即数组中的位置。</td></tr><tr><td>ldc</td><td>这个操作码用来将常量从运行时常量池压栈到操作数栈。</td></tr><tr><td>getstatic</td><td>这个操作码用来把一个静态变量从运行时常量池的静态变量列表中压栈到操作数栈。</td></tr><tr><td>return</td><td>这个操作码属于ireturn、lreturn、freturn、dreturn、areturn 和 return 操作码组。每个操作码返回一种类型的返回值，其中 i 表示 int，l 表示 long，f 表示 float，d 表示 double，a 表示 对象引用。没有前缀类型字母的 return 表示返回 void。</td></tr></tbody></table><table><thead><tr><th>函数调用操作码</th><th>作用</th></tr></thead><tbody><tr><td>invokestatic</td><td>调用类方法（静态绑定，速度快）</td></tr><tr><td>invokevirtual</td><td>指令调用一个对象的实例方法（动态绑定）</td></tr><tr><td>invokespecial</td><td>指令调用实例初始化方法、私有方法、父类方法。（静态绑定，速度快）</td></tr><tr><td>invokeinterface</td><td>调用引用类型为interface的实例方法（动态绑定）</td></tr><tr><td>invokedynamic</td><td>JDK 7引入的，主要是为了支持动态语言的方法调用</td></tr></tbody></table><h3 id="3-3-4-代码分析"><a href="#3-3-4-代码分析" class="headerlink" title="3.3.4 代码分析"></a>3.3.4 代码分析</h3><p>注意反编译后main方法部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public static void main(java.lang.String[]);</span><br><span class="line">    descriptor: ([Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         // ldc 这个操作码用来将常量从运行时常量池压栈到操作数栈</span><br><span class="line">         0: ldc           #3                  // String test</span><br><span class="line">         // 注意下面两句：通过实例调用 print</span><br><span class="line">         2: invokedynamic #4,  0              // InvokeDynamic #0:print:()LPrint;        </span><br><span class="line">         //调用静态方法 printString</span><br><span class="line">         7: invokestatic  #5                  // Method printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">        10: return</span><br></pre></td></tr></table></figure><p>那么，既然是调用实例方法，那么实例在哪？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">InnerClasses:</span><br><span class="line">     public static final #58= #57 of #61; //Lookup=class java/lang/invoke/MethodHandles$Lookup of class java/lang/invoke/MethodHandles</span><br><span class="line">BootstrapMethods:</span><br><span class="line">  0: #29 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  Method arguments:</span><br><span class="line">      //对象类型终结符为 L 和 ;</span><br><span class="line">      //Object V</span><br><span class="line">      #30 (Ljava/lang/Object;)V</span><br><span class="line">      #31 invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">      #32 (Ljava/lang/String;)V</span><br></pre></td></tr></table></figure><p>可以在运行时加上-Djdk.internal.lambda.dumpProxyClasses，加上这个参数后，运行时，会将生成的内部类class码输出到一个文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -Djdk.internal.lambda.dumpProxyClasses LambdaTest</span><br></pre></td></tr></table></figure><p><img src="/images/java-lambda/dumpProxyClasses.png" alt><br>通过jad反编译LambdaTest$$Lambda$1.class文件，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// Decompiled by Jad v1.5.8g. Copyright 2001 Pavel Kouznetsov.</span><br><span class="line">// Jad home page: http://www.kpdus.com/jad.html</span><br><span class="line">// Decompiler options: packimports(3) </span><br><span class="line">final class LambdaTest$$Lambda$1 implements Print &#123;</span><br><span class="line">    private LambdaTest$$Lambda$1() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void print(Object obj) &#123;</span><br><span class="line">        LambdaTest.lambda$main$0((String) obj);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3-5-代码还原"><a href="#3-3-5-代码还原" class="headerlink" title="3.3.5 代码还原"></a>3.3.5 代码还原</h3><p>至此，我们可以推断出最终执行代码应该是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void PrintString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        PrintString(&quot;test&quot;, new LambdaTest$$Lambda$1());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void lambda$main$0(String x) &#123;</span><br><span class="line">        System.out.println(x);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static final class LambdaTest$$Lambda$1 implements Print &#123;</span><br><span class="line">        public void print(Object obj) &#123;</span><br><span class="line">            LambdaTest.lambda$main$0((String) obj);</span><br><span class="line">        &#125;</span><br><span class="line">        private LambdaTest$$Lambda$1() &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><ul><li>在类编译时，会生成一个私有静态方法+一个内部类；</li><li>在内部类中实现了函数式接口，在实现接口的方法中，会调用编译器生成的静态方法；</li><li>在使用lambda表达式的地方，通过传递内部类实例，来调用函数式接口方法。</li></ul><blockquote><p>就是传递个函数指针，在Java中搞得这么复杂。。。。。。</p></blockquote><p>参考资料： </p><p><a href="https://www.cnblogs.com/WJ5888/p/4667086.html" target="_blank" rel="noopener">https://www.cnblogs.com/WJ5888/p/4667086.html</a> </p><p><a href="https://www.jianshu.com/p/57bffc6e7acd" target="_blank" rel="noopener">https://www.jianshu.com/p/57bffc6e7acd</a> </p><p><a href="http://www.importnew.com/17770.html" target="_blank" rel="noopener">http://www.importnew.com/17770.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> Lambda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java AQS 实现原理（图文）分析</title>
      <link href="/java-aqs.html"/>
      <url>/java-aqs.html</url>
      
        <content type="html"><![CDATA[<p>AQS：AbstractQueuedSynchronizer</p><h1 id="1、AQS设计简介"><a href="#1、AQS设计简介" class="headerlink" title="1、AQS设计简介"></a>1、AQS设计简介</h1><ul><li>AQS的实现是基于一个FIFO的等待队列。</li><li><font color="DeepPink"><strong>使用单个原子变量来表示获取、释放锁状态（final int）改变该int值使用的是CAS。</strong></font>（思考：为什么一个int值可以保证内存可见性？）</li><li><font color="DeepPink"><strong>子类应该定义一个非公开的内部类继承AQS，并实现其中方法。</strong></font></li><li>AQS支持exclusive与shared两种模式。</li><li>内部类ConditionObject用于支持子类实现exclusive模式</li><li>子类需要重写：<ul><li>tryAcquire</li><li>tryRelease</li><li>tryReleaseShared</li><li>isHeldExclusively等方法，并确保是线程安全的。</li></ul></li></ul><p>贯穿全文的图（核心）：</p><p><img src="/images/java-juc-aqs/AQS%E5%9B%BE%E8%A7%A3.png" alt></p><blockquote><p>模板方法设计模式：定义一个操作中算法的骨架，而将一些步骤的实现延迟到子类中。</p></blockquote><h1 id="2、类结构"><a href="#2、类结构" class="headerlink" title="2、类结构"></a>2、类结构</h1><ul><li>ConditionObject类</li><li>Node类</li><li>N多方法</li></ul><p><img src="/images/java-juc-aqs/AQS%E7%B1%BB%E7%BB%93%E6%9E%84.png" alt></p><h1 id="3、FIFO队列"><a href="#3、FIFO队列" class="headerlink" title="3、FIFO队列"></a>3、FIFO队列</h1><p>等待队列是CLH（Craig, Landin, and Hagersten）锁队列。</p><p><strong>通过节点中的“状态”字段来判断一个线程是否应该阻塞。当该节点的前一个节点释放锁的时候，该节点会被唤醒。</strong> </p><p><img src="/images/java-juc-aqs/AQS%E9%98%9F%E5%88%97.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private transient volatile Node head;</span><br><span class="line">private transient volatile Node tail;</span><br><span class="line">//The synchronization state.</span><br><span class="line">//在互斥锁中它表示着线程是否已经获取了锁，0未获取，1已经获取了，大于1表示重入数。</span><br><span class="line">private volatile int state;</span><br></pre></td></tr></table></figure><p>AQS维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。</p><p>state的访问方式有三种:</p><ul><li>getState()</li><li>setState()</li><li>compareAndSetState()</li></ul><p>AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。</p><p>不同的自定义同步器争用共享资源的方式也不同。<font color="DeepPink"><strong>自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可</strong></font>，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p><p>自定义同步器实现时主要实现以下几种方法：</p><ul><li>isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。</li><li>tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。</li><li>tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。</li><li>tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</li><li>tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。</li></ul><p>以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，<font color="DeepPink"><strong>获取多少次就要释放多么次，这样才能保证state是能回到零态的。</strong></font></p><p>再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后续动作。</p><p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现：</p><ul><li>tryAcquire-tryRelease</li><li>tryAcquireShared-tryReleaseShared</li></ul><p>中的一种即可。</p><p>当然AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。</p><blockquote><p>以下部分来自源码注释：</p></blockquote><p>每次进入CLH队列时，需要对尾节点进入队列过程，是一个原子性操作。在出队列时，我们只需要更新head节点即可。在节点确定它的后继节点时， 需要花一些功夫，用于处理那些，由于等待超时时间结束或中断等原因， 而取消等待锁的线程。</p><p>节点的前驱指针，主要用于处理，取消等待锁的线程。如果一个节点取消等待锁，则此节点的前驱节点的后继指针，要指向，此节点后继节点中，非取消等待锁的线程（有效等待锁的线程节点）。</p><p>我们用next指针连接实现阻塞机制。每个节点均持有自己线程，节点通过节点的后继连接唤醒其后继节点。</p><p>CLH队列需要一个傀儡结点作为开始节点。我们不会再构造函数中创建它，因为如果没有线程竞争锁，那么，努力就白费了。取而代之的方案是，当有第一个竞争者时，我们才构造头指针和尾指针。</p><p>线程通过同一节点等待条件，但是用另外一个连接。条件只需要放在一个非并发的连接队列与节点关联，因为只有当线程独占持有锁的时候，才会去访问条件。当一个线程等待条件的时候，节点将会插入到条件队列中。当条件触发时，节点将会转移到主队列中。用一个状态值，描述节点在哪一个队列上。</p><h1 id="4、Node"><a href="#4、Node" class="headerlink" title="4、Node"></a>4、Node</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">static final class Node &#123;</span><br><span class="line">    //该等待节点处于共享模式</span><br><span class="line">    static final Node SHARED = new Node();</span><br><span class="line">    //该等待节点处于独占模式</span><br><span class="line">    static final Node EXCLUSIVE = null;</span><br><span class="line">    </span><br><span class="line">    //表示节点的线程是已被取消的</span><br><span class="line">    static final int CANCELLED =  1;</span><br><span class="line">    //表示当前节点的后继节点的线程需要被唤醒</span><br><span class="line">    static final int SIGNAL    = -1;</span><br><span class="line">    //表示线程正在等待某个条件</span><br><span class="line">    static final int CONDITION = -2;</span><br><span class="line">    //表示下一个共享模式的节点应该无条件的传播下去</span><br><span class="line">    static final int PROPAGATE = -3;</span><br><span class="line"></span><br><span class="line">    //状态位 ，分别可以使CANCELLED、SINGNAL、CONDITION、PROPAGATE、0 </span><br><span class="line">    volatile int waitStatus;</span><br><span class="line"></span><br><span class="line">    volatile Node prev;//前驱节点</span><br><span class="line">    volatile Node next;//后继节点</span><br><span class="line">    volatile Thread thread;//等待锁的线程</span><br><span class="line"></span><br><span class="line">    //ConditionObject链表的后继节点或者代表共享模式的节点。</span><br><span class="line">    //因为Condition队列只能在独占模式下被能被访问,我们只需要简单的使用链表队列来链接正在等待条件的节点。</span><br><span class="line">    //然后它们会被转移到同步队列（AQS队列）再次重新获取。</span><br><span class="line">    //由于条件队列只能在独占模式下使用，所以我们要表示共享模式的节点的话只要使用特殊值SHARED来标明即可。</span><br><span class="line">    Node nextWaiter;</span><br><span class="line">    //Returns true if node is waiting in shared mode</span><br><span class="line">    final boolean isShared() &#123;</span><br><span class="line">            return nextWaiter == SHARED;</span><br><span class="line">    &#125;</span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>waitStatus不同值含义：</p><ul><li>SIGNAL(-1)：当前节点的后继节点已经 (或即将)被阻塞（通过park） , 所以当当前节点释放或则被取消时候，一定要unpark它的后继节点。为了避免竞争，获取方法一定要首先设置node为signal，然后再次重新调用获取方法，如果失败，则阻塞。</li><li>CANCELLED(1)：当前节点由于超时或者被中断而被取消。一旦节点被取消后，那么它的状态值不在会被改变，且当前节点的线程不会再次被阻塞。</li><li>CONDITION(-2) ：该节点的线程处于等待条件状态,不会被当作是同步队列上的节点,直到被唤醒(signal),设置其值为0,重新进入阻塞状态.</li><li>PROPAGATE(-3：)共享模式下的释放操作应该被传播到其他节点。该状态值在doReleaseShared方法中被设置的。</li><li>0：以上都不是</li></ul><p>该状态值为了简便使用，所以使用了数值类型。非负数值意味着该节点不需要被唤醒。所以，大多数代码中不需要检查该状态值的确定值。</p><p>一个正常的Node，它的waitStatus初始化值是0。如果想要修改这个值，可以使用AQS提供CAS进行修改。</p><h1 id="5、独占模式与共享模式"><a href="#5、独占模式与共享模式" class="headerlink" title="5、独占模式与共享模式"></a>5、独占模式与共享模式</h1><p>在锁的获取时，并不一定只有一个线程才能持有这个锁（或者称为同步状态），所以此时有了独占模式和共享模式的区别，也就是在Node节点中由nextWaiter来标识。比如ReentrantLock就是一个独占锁，只能有一个线程获得锁，而WriteAndReadLock的读锁则能由多个线程同时获取，但它的写锁则只能由一个线程持有。</p><h2 id="5-1、独占模式"><a href="#5-1、独占模式" class="headerlink" title="5.1、独占模式"></a>5.1、独占模式</h2><h3 id="5-1-1-独占模式同步状态的获取"><a href="#5-1-1-独占模式同步状态的获取" class="headerlink" title="5.1.1 独占模式同步状态的获取"></a>5.1.1 独占模式同步状态的获取</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//忽略中断的（即不手动抛出InterruptedException异常）独占模式下的获取方法。</span><br><span class="line">//该方法在成功返回前至少会调用一次tryAcquire()方法(该方法是子类重写的方法，如果返回true则代表能成功获取).</span><br><span class="line">//否则当前线程会进入队列排队，重复的阻塞和唤醒等待再次成功获取后返回, </span><br><span class="line">//该方法可以用来实现Lock.lock</span><br><span class="line">public final void acquire(int arg) &#123;</span><br><span class="line">       if (!tryAcquire(arg) &amp;&amp;</span><br><span class="line">            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line">            selfInterrupt();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>该方法首先尝试获取锁(tryAcquire(arg)的具体实现定义在了子类中),如果获取到,则执行完毕,否则通过addWaiter(Node.EXCLUSIVE), arg)方法把当前节点添加到等待队列末尾,并设置为独占模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">private Node addWaiter(Node mode) &#123;</span><br><span class="line">        //把当前线程包装为node,设为独占模式</span><br><span class="line">        Node node = new Node(Thread.currentThread(), mode);</span><br><span class="line">        // 尝试快速入队，即无竞争条件下肯定成功。如果失败，则进入enq自旋重试入队</span><br><span class="line">        Node pred = tail;</span><br><span class="line">        if (pred != null) &#123;</span><br><span class="line">            node.prev = pred;</span><br><span class="line">            //CAS替换当前尾部。成功则返回</span><br><span class="line">            if (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">                pred.next = node;</span><br><span class="line">                return node;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        enq(node);</span><br><span class="line">        return node;</span><br><span class="line">    &#125;</span><br><span class="line">//插入节点到队列中，如果队列未初始化则初始化，然后再插入。</span><br><span class="line">private Node enq(final Node node) &#123;</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            Node t = tail;</span><br><span class="line">            if (t == null) &#123; // Must initialize</span><br><span class="line">                if (compareAndSetHead(new Node()))</span><br><span class="line">                    tail = head;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                node.prev = t;</span><br><span class="line">                if (compareAndSetTail(t, node)) &#123;</span><br><span class="line">                    t.next = node;</span><br><span class="line">                    return t;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>如果tail节点为空,执行enq(node);重新尝试,最终把node插入.在把node插入队列末尾后,它并不立即挂起该节点中线程,因为在插入它的过程中,前面的线程可能已经执行完成,所以它会先进行自旋操作acquireQueued(node, arg),尝试让该线程重新获取锁!当条件满足获取到了锁则可以从自旋过程中退出，否则继续。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">final boolean acquireQueued(final Node node, int arg) &#123;</span><br><span class="line">        boolean failed = true;</span><br><span class="line">        try &#123;</span><br><span class="line">            boolean interrupted = false;</span><br><span class="line">            for (;;) &#123;</span><br><span class="line">                final Node p = node.predecessor();</span><br><span class="line">                //如果它的前继节点为头结点,尝试获取锁,获取成功则返回           </span><br><span class="line">                if (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = null; // help GC</span><br><span class="line">                    failed = false;</span><br><span class="line">                    return interrupted;</span><br><span class="line">                &#125;</span><br><span class="line">                //判断当前节点的线程是否应该被挂起，如果应该被挂起则挂起。</span><br><span class="line">                //等待release唤醒释放</span><br><span class="line">                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    interrupted = true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (failed)</span><br><span class="line">                //在队列中取消当前节点</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>如果没获取到锁,则判断是否应该挂起,而这个判断则得通过它的前驱节点的waitStatus来确定:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;</span><br><span class="line">        int ws = pred.waitStatus;</span><br><span class="line">        //该节点如果状态如果为SIGNAL。则返回true，然后park挂起线程</span><br><span class="line">        if (ws == Node.SIGNAL)</span><br><span class="line">            return true;</span><br><span class="line">       //表明该节点已经被取消，向前循环重新调整链表节点</span><br><span class="line">        if (ws &gt; 0) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Predecessor was cancelled. Skip over predecessors and</span><br><span class="line">             * indicate retry.</span><br><span class="line">             */</span><br><span class="line">            do &#123;</span><br><span class="line">                node.prev = pred = pred.prev;</span><br><span class="line">            &#125; while (pred.waitStatus &gt; 0);</span><br><span class="line">            pred.next = node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            //执行到这里代表节点是0或者PROPAGATE，然后标记他们为SIGNAL，但是</span><br><span class="line">            //还不能park挂起线程。需要重试是否能获取，如果不能，则挂起。</span><br><span class="line">            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">//挂起当前线程，且返回线程的中断状态</span><br><span class="line">private final boolean parkAndCheckInterrupt() &#123;</span><br><span class="line">        LockSupport.park(this);</span><br><span class="line">        return Thread.interrupted();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>最后,我们对获取独占式锁过程对做个总结:</p><p>AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后-&gt;将线程构造成Node节点(addWaiter)-&gt;将Node节点添加到同步队列对尾(addWaiter)-&gt;节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点单获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。</p><p><font color="DeepPink"><strong>获取锁的过程：</strong></font></p><ul><li><font color="DeepPink"><strong>当线程调用acquire()申请获取锁资源，如果成功，则进入临界区。</strong></font></li><li><font color="DeepPink"><strong>当获取锁失败时，则进入一个FIFO等待队列，然后被挂起等待唤醒。</strong></font></li><li><font color="DeepPink"><strong>当队列中的等待线程被唤醒以后就重新尝试获取锁资源，如果成功则进入临界区，否则继续挂起等待。</strong></font></li></ul><h3 id="5-1-2-独占模式同步状态的释放"><a href="#5-1-2-独占模式同步状态的释放" class="headerlink" title="5.1.2 独占模式同步状态的释放"></a>5.1.2 独占模式同步状态的释放</h3><p>既然是释放,那肯定是持有锁的该线程执行释放操作,即head节点中的线程释放锁.</p><p>AQS中的release释放同步状态和acquire获取同步状态一样，都是模板方法，tryRelease释放的具体操作都有子类去实现，父类AQS只提供一个算法骨架。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public final boolean release(int arg) &#123;</span><br><span class="line">    if (tryRelease(arg)) &#123;</span><br><span class="line">        Node h = head;</span><br><span class="line">        if (h != null &amp;&amp; h.waitStatus != 0)</span><br><span class="line">            unparkSuccessor(h);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line">//如果node的后继节点不为空且不是作废状态,则唤醒这个后继节点,</span><br><span class="line">//否则从末尾开始寻找合适的节点,如果找到,则唤醒</span><br><span class="line">private void unparkSuccessor(Node node) &#123;</span><br><span class="line">        int ws = node.waitStatus;</span><br><span class="line">        if (ws &lt; 0)</span><br><span class="line">            compareAndSetWaitStatus(node, ws, 0);</span><br><span class="line">        Node s = node.next;</span><br><span class="line">        if (s == null || s.waitStatus &gt; 0) &#123;</span><br><span class="line">            s = null;</span><br><span class="line">            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)</span><br><span class="line">                if (t.waitStatus &lt;= 0)</span><br><span class="line">                    s = t;</span><br><span class="line">        &#125;</span><br><span class="line">        if (s != null)</span><br><span class="line">            LockSupport.unpark(s.thread);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>过程：首先调用子类的tryRelease()方法释放锁，然后唤醒后继节点，在唤醒的过程中，需要判断后继节点是否满足情况，如果后继节点不为空且不是作废状态，则唤醒这个后继节点，否则从tail节点向前寻找合适的节点，如果找到，则唤醒。</p><p><font color="DeepPink"><strong>释放锁过程：</strong></font></p><ul><li><font color="DeepPink"><strong>当线程调用release()进行锁资源释放时，如果没有其他线程在等待锁资源，则释放完成。</strong></font></li><li><font color="DeepPink"><strong>如果队列中有其他等待锁资源的线程需要唤醒，则唤醒队列中的第一个等待节点（先入先出）。</strong></font></li></ul><h2 id="5-2、共享模式"><a href="#5-2、共享模式" class="headerlink" title="5.2、共享模式"></a>5.2、共享模式</h2><h3 id="5-2-1-共享模式同步状态的获取"><a href="#5-2-1-共享模式同步状态的获取" class="headerlink" title="5.2.1 共享模式同步状态的获取"></a>5.2.1 共享模式同步状态的获取</h3><ul><li><font color="DeepPink"><strong>当线程调用acquireShared()申请获取锁资源时，如果成功，则进入临界区。</strong></font></li><li><font color="DeepPink"><strong>当获取锁失败时，则创建一个共享类型的节点并进入一个FIFO等待队列，然后被挂起等待唤醒。</strong></font></li><li><font color="DeepPink"><strong>当队列中的等待线程被唤醒以后就重新尝试获取锁资源，如果成功则唤醒后面还在等待的共享节点并把该唤醒事件传递下去，即会依次唤醒在该节点后面的所有共享节点，然后进入临界区，否则继续挂起等待。</strong></font></li></ul><h3 id="5-2-2-共享模式同步状态的释放"><a href="#5-2-2-共享模式同步状态的释放" class="headerlink" title="5.2.2 共享模式同步状态的释放"></a>5.2.2 共享模式同步状态的释放</h3><ul><li><font color="DeepPink"><strong>当线程调用releaseShared()进行锁资源释放时，如果释放成功，则唤醒队列中等待的节点，如果有的话。</strong></font></li></ul><h1 id="6-AQS小结"><a href="#6-AQS小结" class="headerlink" title="6. AQS小结"></a>6. AQS小结</h1><p>java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。<font color="DeepPink"><strong>AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。</strong></font></p><p>JDK中AQS被广泛使用，基于AQS实现的同步器包括：</p><ul><li>ReentrantLock</li><li>Semaphore</li><li>ReentrantReadWriteLock（后续会出文章讲解）</li><li>CountDownLatch</li><li>FutureTask</li></ul><p>每一个基于AQS实现的同步器都会包含两种类型的操作，如下：</p><ul><li>至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。</li><li>至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。</li></ul><p><font color="DeepPink"><strong>基于“复合优先于继承”的原则，基于AQS实现的同步器一般都是：声明一个内部私有的继承于AQS的子类Sync，对同步器所有公有方法的调用都会委托给这个内部子类。</strong></font></p><h1 id="7-后续"><a href="#7-后续" class="headerlink" title="7.后续"></a>7.后续</h1><p>后面会推出以下有关AQS的文章，已加深对于AQS的理解</p><ul><li><a href="https://www.jiankunking.com/java-aqs-condition.html" target="_blank" rel="noopener">AQS ConditionObject对象解析</a></li><li><a href="https://www.jiankunking.com/java-reentrantreadwritelock.html" target="_blank" rel="noopener">AQS 应用案例 ReentrantReadWriteLock解析</a></li><li><a href="https://www.jiankunking.com/java-volatile-aqs.html" target="_blank" rel="noopener">Java Volatile的内存语义与AQS锁内存可见性</a></li></ul><h1 id="8-感谢"><a href="#8-感谢" class="headerlink" title="8.感谢"></a>8.感谢</h1><p>本文很多内容整理自网络，参考文献：<br><a href="https://segmentfault.com/a/1190000011376192" target="_blank" rel="noopener">https://segmentfault.com/a/1190000011376192</a><br><a href="https://segmentfault.com/a/1190000011391092" target="_blank" rel="noopener">https://segmentfault.com/a/1190000011391092</a><br><a href="https://zhuanlan.zhihu.com/p/27134110" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27134110</a><br><a href="https://blog.csdn.net/wojiaolinaaa/article/details/50070031" target="_blank" rel="noopener">https://blog.csdn.net/wojiaolinaaa/article/details/50070031</a><br><a href="https://www.cnblogs.com/waterystone/p/4920797.html" target="_blank" rel="noopener">https://www.cnblogs.com/waterystone/p/4920797.html</a></p><p>FIFO队列:<a href="https://www.cnblogs.com/waterystone/p/4920797.html" target="_blank" rel="noopener">https://www.cnblogs.com/waterystone/p/4920797.html</a></p>]]></content>
      
      
      <categories>
          
          <category> JUC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> JUC </tag>
            
            <tag> AQS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP与UDP 笔记</title>
      <link href="/tcp-and-udp-notes.html"/>
      <url>/tcp-and-udp-notes.html</url>
      
        <content type="html"><![CDATA[<p>本文整理自：《图解TCP/IP 第5版》<br>作者：[日] 竹下隆史，[日] 村山公保，[日] 荒井透，[日] 苅田幸雄 著<br>译者：乌尼日其其格<br>出版时间：2013-07</p><a id="more"></a><p><img src="/images/tcp-and-udp-note/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82.png" alt></p><h1 id="传输层的作用"><a href="#传输层的作用" class="headerlink" title="传输层的作用"></a>传输层的作用</h1><p>TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。</p><h2 id="两种传输层协议TCP和UDP"><a href="#两种传输层协议TCP和UDP" class="headerlink" title="两种传输层协议TCP和UDP"></a>两种传输层协议TCP和UDP</h2><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><p>TCP是面向连接的、可靠的流协议。流就是指不间断的数据结构，你可以把它想象成排水管道中的水流。TCP为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。</p><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><p>UDP是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。UDP情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。</p><h2 id="TCP与UDP区分"><a href="#TCP与UDP区分" class="headerlink" title="TCP与UDP区分"></a>TCP与UDP区分</h2><p>TCP用于在传输层有必要实现可靠性传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的。所以它可以为应用提供可靠传输。</p><p>UDP主要用于那些对高速传输和实时性有较高要求的通信或广播通信。举一个IP电话进行通话的例子。如果使用TCP，数据在传送途中如果丢失会被重发，但是这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是影响某一小部分的通话。此外，在多播与广播通信中也使用UDP而不是TCP。RIP、DHCP等基于广播的协议也要依赖于UDP。</p><h1 id="端口号"><a href="#端口号" class="headerlink" title="端口号"></a>端口号</h1><h2 id="端口号定义"><a href="#端口号定义" class="headerlink" title="端口号定义"></a>端口号定义</h2><p><font color="DeepPink"><strong>数据链路和IP中的地址，分别指的是MAC地址和IP地址。前者用来识别同一链路中不同的计算机，后者用来识别TCP/IP网络中互连的主机和路由器。传输层也有类似概念，就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。</strong></font></p><h2 id="通过IP地址、端口号、协议号进行通信识别"><a href="#通过IP地址、端口号、协议号进行通信识别" class="headerlink" title="通过IP地址、端口号、协议号进行通信识别"></a>通过IP地址、端口号、协议号进行通信识别</h2><p><font color="DeepPink"><strong>TCP/IP或UDP/IP通信中通常采用5个信息来识别一个通信。它们是“源IP地址”、“目标IP地址”、“协议号”、“源端口号”、“目标端口号”。</strong></font>只要其中某一项不同，则被认为是其他通信。</p><h2 id="端口号与协议"><a href="#端口号与协议" class="headerlink" title="端口号与协议"></a>端口号与协议</h2><p><font color="DeepPink"><strong>端口号由其使用的传输层协议决定。因此，不同的传输协议可以使用相同的端口号。</strong></font>例如，TCP与UDP使用同一个端口号，但使用目的各不相同。</p><p>数据到达IP层后，会先检查IP首部中的协议号，再传给相应协议的模块。传给TCP或UDP去做端口号处理。即使是同一个端口号，由于传输协议是各自独立地进行处理，因此相互之间不会影响。</p><h1 id="UDP-1"><a href="#UDP-1" class="headerlink" title="UDP"></a>UDP</h1><p>UDP是User Datagram Protocol的缩写，即用户数据包协议。</p><p>UDP不提供复杂控制机制，利用IP提供面向无连接的通信服务。且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。</p><p>UDP面向无连接，可以随时发送数据。它常用于几个方面：</p><ul><li>包总量较少的通信（DNS、SNMP等）</li><li>视频、音频等多媒体通信（即时通信）</li><li>限定于LAN等特定网络中的应用通信</li><li>广播通信（广播、多播）</li></ul><h1 id="TCP-1"><a href="#TCP-1" class="headerlink" title="TCP"></a>TCP</h1><p>TCP是Transmission Control Protocol的缩写，传输控制协议。</p><p>TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。</p><blockquote><p>连接<br>连接是指各种设备、线路,或网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信线路,也叫做虚拟电路。<br>一旦建立了连接,进行通信的应用程序只是用这个虚拟的通信线路发送和接收数据,就可以保障信息的传输。应用程序不用顾虑IP网络上可能发生的各种问题,依然可以转发数据。TCP则负责控制链接的建立、断开、保持等管理工作。<br><img src="/images/tcp-and-udp-note/%E8%BF%9E%E6%8E%A5.png" alt></p></blockquote><h2 id="TCP的特点及其目的"><a href="#TCP的特点及其目的" class="headerlink" title="TCP的特点及其目的"></a>TCP的特点及其目的</h2><p>为了通过数据包实现可靠性传输,需要考虑很多事情,例如数据的破坏、丢包、重复记忆分片顺序混乱等问题。如不能解决这些问题,也就无从谈起可靠传输。</p><p><font color="DeepPink"><strong>TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。</strong></font></p><h2 id="通过序列号与确认应答提高可靠性"><a href="#通过序列号与确认应答提高可靠性" class="headerlink" title="通过序列号与确认应答提高可靠性"></a>通过序列号与确认应答提高可靠性</h2><p>在TCP中，当发送端数据到达接受主机时，接收端主机会返回一个已收到的消息的通知。这个消息叫做确认应答（ACK Positive Acknowledgement）。</p><p>TCP通过肯定的确认应答（ACK）实现可靠的数据传输。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。</p><p>在一定时间内没有等到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。</p><p>未确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。</p><p>为了防止出现随意重发的情况，就需要引入一种机制，它能够识别是否已经接收数据，又能判断是否需要接收。</p><p>这些确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现。<font color="DeepPink"><strong>序列号是按照顺序给发送数据的每个字节（8位字节）都标上号码的编号（序列号的初始值并非为0。而是在建立连接以后由随机数生成。而后面的计算则是对每一字节加一）。接收端查询接收数据TCP首部中序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。这样，通过序列号和确认应答号，TCP可以实现可靠传输。</strong></font></p><p><img src="/images/tcp-and-udp-note/%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.png" alt></p><h2 id="重发超时如何确定"><a href="#重发超时如何确定" class="headerlink" title="重发超时如何确定"></a>重发超时如何确定</h2><p>重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过了这个时间仍未收到确认应答，发送端将进行数据重发。那么这个重发超时的具体时间长度又是如何确定的呢？</p><p>最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。然而这个时间长短随着数据包途径的网络环境的不同而有所变化。例如在高速的LAN中时间相对较短，而在长距离的通信当中应该比LAN要长一些。即使是在同一个网络中，根据不同时段的网络堵塞程度时间的长短也会发生变化。TCP要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差相加重发超时的时间，就是比这个总和要稍大一点的值。</p><p><img src="/images/tcp-and-udp-note/%E5%BE%80%E8%BF%94%E6%97%B6%E9%97%B4%E7%9A%84%E8%AE%A1%E7%AE%97%E4%B8%8E%E9%87%8D%E5%8F%91%E8%B6%85%E6%97%B6%E7%9A%84%E6%97%B6%E9%97%B4%E6%8E%A8%E7%A7%BB.png" alt></p><p>在BSD的Unix以及Windows系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，由于最初的数据包还不知道往返时间，所以其重发超时一般设置为6秒左右。数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。</p><h2 id="连接管理"><a href="#连接管理" class="headerlink" title="连接管理"></a>连接管理</h2><p>TCP提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好通信两端之间的准备工作。</p><p>UDP是一种面向无连接的通信协议，因此不检查对端是否可以通信，直接将UDP包发出去。TCP与此相反，它会在数据通信之前，通过TCP首部发送一个SYN包作为建立连接的请求等待确认应答（<font color="DeepPink"><strong>TCP中发送第一个SYN包的一方叫客户端，接收这个的一方叫服务端</strong></font>）。如果对端发来确认应答，则认为可以进行数据通信。如果对端的确认应答未能到达，就不会进行数据通信。此外，在通信结束时会进行断开连接的处理（FIN包）。</p><p>可以使用TCP首部用于控制的字段来管理TCP连接（也叫控制域）。一个连接的建立与断开，正常过程至少需要来回发送7个包才能完成。（建立一个TCP连接需要发送3个包，这个过程也称为3次握手）</p><p><img src="/images/tcp-and-udp-note/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B%E4%B8%8E%E6%96%AD%E5%BC%80.png" alt></p><h2 id="TCP以段为单位发送数据"><a href="#TCP以段为单位发送数据" class="headerlink" title="TCP以段为单位发送数据"></a>TCP以段为单位发送数据</h2><p><font color="DeepPink"><strong>在建立TCP连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS：Maximum Segment Size）。</strong></font> 最理想的情况是，最大消息长度正好是IP中不会被分片处理的最大数据长度。</p><p>TCP在传输大量数据时，是以MSS的大小将数据进行分割发送的。进行重发时也是以MSS为单位。</p><p>MSS是在三次握手的时候，在两端主机之间被计算得出。<font color="DeepPink"><strong>两端的主机在发出建立连接的请求时，会在TCP首部中写入MSS选项，告诉对方自己的接口能够适应的MSS的大小（为附加MSS选项，TCP首部将不再是20字节，而是4字节的整数倍）。然后会在两者之间选择一个较小的值投入使用。</strong></font></p><p><img src="/images/tcp-and-udp-note/%E6%8E%A5%E5%85%A5%E4%BB%A5%E5%A4%AA%E7%BD%91%E4%B8%BB%E6%9C%BA%E4%B8%8E%E6%8E%A5%E5%85%A5FDDI%E4%B8%BB%E6%9C%BA%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84%E6%83%85%E5%86%B5.png" alt></p><blockquote><p>SYN(synchronous建立联机) ACK(acknowledgement 确认) FIN(finish结束) </p></blockquote><h2 id="利用窗口控制提高速度"><a href="#利用窗口控制提高速度" class="headerlink" title="利用窗口控制提高速度"></a>利用窗口控制提高速度</h2><p>TCP以1个段为单位，每发一个段进行一次确认应答的处理，如下图，这样传输的缺点是，包的往返时间越长通信性能就越低。</p><p><img src="/images/tcp-and-udp-note/%E6%8C%89%E6%95%B0%E6%8D%AE%E5%8C%85%E8%BF%9B%E8%A1%8C%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94.png" alt></p><p>为解决这个问题，TCP引入了窗口这个概念。如下图，确认应答不再是以每个分段，而是以更大的单位进行确认时，转发时间将会被大幅度的缩短。就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。</p><p><font color="DeepPink"><strong>窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。</strong></font> 如下图中，窗口大小为4个段。</p><p>这个机制实现了使用大量的缓冲区（Buffer 在此处标识临时保存收发数据的场所。通常是在计算机内存中开辟的一部分空间），通过对多个段同时进行确认应答的功能。</p><p>用滑动窗口方式并行处理：</p><p><img src="/images/tcp-and-udp-note/%E7%94%A8%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%96%B9%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.png" alt></p><p>下面的图中发送数据中高亮圈起的部分正是前面所提到的窗口。在这个窗口内的数据即便没有收到确认应答也可以发送出去。此外，<font color="DeepPink"><strong>从该窗口中能看到的数据因其某种数据已在传输中丢失，所以发送端才能收到确认应答，这种情况也需要重发。为此，发送端主机在等到确认应答返回之前，必须在缓冲区中保留这部分数据。</strong></font></p><p>在滑动窗口以外的部分包括尚未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再重发，此时数据皆可以从缓冲区清除。</p><p><font color="DeepPink"><strong>收到确认应答，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也被称为滑动窗口控制。</strong></font></p><p>滑动窗口方式：</p><p><img src="/images/tcp-and-udp-note/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%96%B9%E5%BC%8F.png" alt></p><h2 id="窗口控制与重发控制"><a href="#窗口控制与重发控制" class="headerlink" title="窗口控制与重发控制"></a>窗口控制与重发控制</h2><p>使用窗口控制中， 如果出现段丢失怎么办？</p><p>首先考虑确认应答未能返回的情况。这种情况下，数据已经达到对端，是不需要进行重发的。然而，在没有使用窗口控制的时候，没有收到确认应答的数据会被重发。而使用了窗口控制，如下图，某些确认应答即便丢失也无需重发。</p><p><img src="/images/tcp-and-udp-note/%E6%B2%A1%E6%9C%89%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94%E4%B9%9F%E4%B8%8D%E5%8F%97%E5%BD%B1%E5%93%8D.png" alt></p><p>其次，考虑一下某个报文段丢失的情况。如下图，接收主机如果收到一个自己应该接收的序号以外的数据时，会针对当前位置收到数据返回确认应答（不过<font color="DeepPink"><strong>即使接收端主机收到的包序号并不连续，也不会将数据丢弃而是暂时保存至缓冲区中</strong></font>）。</p><p>当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，这个确认应答好像在提醒发送端“我想接收的是从1001开始的数据”。因此，在窗口比较大，又出现报文段丢失的情况下，同一个序号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答（之所以连续收到3次而不是两次的理由是因为，即使数据段的序号被替换两次也不会触发重发机制）。就会将其所对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称作高速重发控制。</p><p><img src="/images/tcp-and-udp-note/%E9%AB%98%E9%80%9F%E9%87%8D%E5%8F%91%E6%8E%A7%E5%88%B6.png" alt></p><h2 id="流控制"><a href="#流控制" class="headerlink" title="流控制"></a>流控制</h2><p>发送端根据自己的实际情况发送数据。但是，接收端可能收到的是一个毫无关系的数据包有可能会在处理其他问题上花费一些时间。因此在为这个数据包做其他处理时会耗费一些时间，甚至在高负荷情况下无法接收任何数据。如此一来，如果接收端将本应该接收的数据丢弃的话，就又会触发重发机制，从而导致网络流量的浪费。</p><p>为了防止这种现象发生，<font color="DeepPink"><strong>TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的流控制。它的具体操作时，接收端主机向发送端主机通知自己可以接收数据的大小，于是发送端会发送不超过这个限制的数据。该大小限度就被称为窗口大小。</strong></font></p><p><font color="DeepPink"><strong>TCP首部中，专门有一个字段用来通知窗口大小。接收主机将自己的可以接收的缓冲区大小放入这个字段通知给发送端。这个值越大，说明网络的吞吐量越高。</strong></font></p><p><font color="DeepPink"><strong>不过，接收端这个缓冲区一旦面临数据溢出时，窗口大小的值也会随之被设置为一个更小的值通知给发送端，从而控制数据发送量。就是说，发送端主机会根据接收端主机的指示，对发送数据的量进行控制。这也形成了一个完整的TCP流控制（流量控制）。</strong></font></p><p>根据窗口大小控制流量过程示例：</p><p><img src="/images/tcp-and-udp-note/%E6%B5%81%E6%8E%A7%E5%88%B6.png" alt></p><p>当接收端收到从3001号开始的数据段后其缓冲区即满，不得不暂时停止接收数据。之后，在收到发送窗口更新通知后通信才得以继续进行。如果这个窗口更新通知在传输途中丢失，可能会导致无法继续通信。为避免此类问题，发送端主机会时不时发送一个叫做窗口探测的数据段，此数据段仅含一个字节以获取最新的窗口大小信息。</p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>有了TCP窗口控制，收发主机之间即使不再以一个数据段为单位发送确认应答，也能够连续发送大量数据包。然而，如果在通信刚开始就发送大量数据，也可能会引发其他问题。</p><p>TCP为了防止该问题的出现，在通信一开始就会通过一个叫做慢启动的算法得出的数值，对发送数据量进行控制。</p><p><font color="DeepPink"><strong>首先，为了在发送端调节所要发送数据的量，定义了一个叫做“拥塞窗口”的概念。于是在慢启动的时候，将这个拥塞窗口的大小设置为1个数据段（1MSS）发送数据，之后每收到一次确认应答（ACK），拥塞窗口的值就加1。在发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还要小的数据量。</strong></font></p><p><img src="/images/tcp-and-udp-note/%E6%85%A2%E5%90%AF%E5%8A%A8.png" alt></p><p>如果重发采用超时机制,那么拥塞窗口的初始值可以设置为1以后再进行慢启动修正。有了上述这些机制,就可以有限的减少通信开始时连续发包导致的网络拥堵,还可以避免网络拥塞情况的发生。</p><p>不过,随着包的每次往返,拥塞窗口也会以1、2、4等指数函数的增长,拥堵状况激增甚至导致网络拥塞的发生。为了防止这些,引入了慢启动阀值的概念。只要拥塞窗口的值超出这个阀值,在每收到一次确认应答时,只允许以下面这种比例方法拥塞窗口:</p><p><img src="/images/tcp-and-udp-note/%E6%8B%A5%E5%A1%9E%E8%B0%83%E6%95%B4%E5%85%AC%E5%BC%8F.png" alt></p><p><img src="/images/tcp-and-udp-note/TCP%E7%9A%84%E7%AA%97%E5%8F%A3%E5%8F%98%E5%8C%96.png" alt></p><p>拥塞窗口越大，确认应答的数目也会增加，不过随着每收到一个确认应答，其涨幅也会逐渐减少，甚至小过比一个数据段还要小的字节数。所以，拥塞窗口的大小会呈直线上升的趋势。</p><p>TCP通信开始时，并没有设置相应的慢启动阈值（与窗口的最大值相同)，而是在超时重发时才会设置为当时拥塞窗口一半的大小。</p><p>由重发确认应答而触发的高速重发与超时重发机制的处理多少有些不同。因为前者要求至少3次的确认应答数据段到达对方主机后才会触发，相比后者网络的拥堵要轻一些。</p><p>而由重复确认应答进行高速重发控制时，慢启动阈值的大小被设置为当时窗口大小的一半（严格来说，是设置为“实际已发送但未收到确认应答的数据量”的一半）。然后将窗口的大小设置为该慢启动阈值+3个数据段的大小。</p><p>有了这样一种控制，TCP的拥塞窗口如上图所示发生变化。由于窗口的大小会直接影响数据被转发的吞吐量，所以一般情况下，窗口越大，越会形成高吞吐量的通信。</p><p>当TCP通信开始以后,网络吞吐量会逐渐上升,但是随着网络拥堵的发生吞吐量也会急剧下降。于是会再次进入吞吐量慢慢上升的过程。因此所谓TCP的吞吐量的特点就好像是在逐步占领网络带宽的感觉。</p><h1 id="UDP首部的格式"><a href="#UDP首部的格式" class="headerlink" title="UDP首部的格式"></a>UDP首部的格式</h1><p>下图展示了UDP首部的格式。除去数据的部分正式UDP的首部。UDP首部由源端口号，目标端口号，包长和校验和组成。</p><p><img src="/images/tcp-and-udp-note/UDP%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%A0%BC%E5%BC%8F.png" alt></p><h2 id="源端口号（Source-Port）"><a href="#源端口号（Source-Port）" class="headerlink" title="源端口号（Source Port）"></a>源端口号（Source Port）</h2><p>表示发送端端口号，字段长16位。该字段是可选项，有时可能不会设置源端口号。没有源端口号的时候该字段的值设置为0。可用于不需要返回的通信中。</p><h2 id="目标端口号（Destination-Port）"><a href="#目标端口号（Destination-Port）" class="headerlink" title="目标端口号（Destination Port）"></a>目标端口号（Destination Port）</h2><p>表示接收端端口，字段长度16位。</p><h2 id="包长度（Length）"><a href="#包长度（Length）" class="headerlink" title="包长度（Length）"></a>包长度（Length）</h2><p>该字段保存了UDP首部的长度跟数据的长度之和。单位为字节（8位字节）。</p><h2 id="校验和（Checksum）"><a href="#校验和（Checksum）" class="headerlink" title="校验和（Checksum）"></a>校验和（Checksum）</h2><p>校验和是为了提供可靠的UDP首部和数据而设计。在计算校验和时，附加在UDP伪首部与UDP数据报之前。通过在最后一位增加一个“0”将全长增加16倍。此时将UDP首部的校验和字段设置为“0”。然后以16比特为单位进行1的补码和，并将所得到的1的补码和写入校验和字段。</p><p><img src="/images/tcp-and-udp-note/%E6%A0%A1%E9%AA%8C%E5%92%8C%E8%AE%A1%E7%AE%97%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84UDP%E4%BC%AA%E9%A6%96%E9%83%A8.png" alt></p><p>接收主机在收到UDP数据报以后，从IP首部获知IP地址信息构造UDP伪首部，再进行校验和计算。校验和制度按的值是校验和字段以外余下部分的1的补码和。因此，包括校验和字段在内的所有数据之和结果为“16位全部为1”时，才会被认为所收到的数据时正确的。</p><p>另外，UDP也可有可能不用校验和。此时，校验和字段中填入0。这种情况下，由于不进行校验和计算，协议处理的开销（在处理实际数据之外，为了进行通信控制的处理而不得不付出的必要的消耗部分）就会降低，从而提高数据转发的速度。然而，如果UDP首部的端口号或是IP首部的IP地址遇到损坏，那么可能会对其他通信造成不好的影响。因此，在互联网中比较推荐使用校验和检查。</p><blockquote><p>校验和计算中计算UDP伪首部的理由<br>TCP/IP中识别一个通信的应用需要5大要素，它们分别是“源IP地址”、“目标IP地址”、“源端口”、“目标端口”、“协议号”。然而，在UDP的首部中只包含它们当中的两项（源端口和目标端口），余下的3项都包含在IP首部里。<br>假定其他3项都被破坏？显然，这极有可能会导致应该收包的应用收不到包，不该收到包的应用却收到了包。<br>为了避免这类问题，有必要验证一个通信中必要的5项识别码是否正确。为此，在校验和的计算中就引入和伪首部的概念。<br>此外，IPv6中的IP首部没有检验和字段。TCP和UDP通过伪首部，得以对5项数字进行校验，从而实现即使在IP首部并不可靠的情况下仍然能够提供可靠的通信传输。</p></blockquote><h1 id="TCP首部格式"><a href="#TCP首部格式" class="headerlink" title="TCP首部格式"></a>TCP首部格式</h1><p><img src="/images/tcp-and-udp-note/TCP%E6%95%B0%E6%8D%AE%E6%AE%B5%E6%A0%BC%E5%BC%8F.png" alt></p><p>TCP中没有表示包长度和数据长度的字段。可由IP层获知TCP的包长，由TCO的包长可知数据的长度。</p><h2 id="源端口号（Source-Port）-1"><a href="#源端口号（Source-Port）-1" class="headerlink" title="源端口号（Source Port）"></a>源端口号（Source Port）</h2><p>表示发送端端口号，字段长16位。</p><h2 id="目标端口号（Destination-Port）-1"><a href="#目标端口号（Destination-Port）-1" class="headerlink" title="目标端口号（Destination Port）"></a>目标端口号（Destination Port）</h2><p>表示接收端端口号，字段长度16位。</p><h2 id="序列号（Sequence-Number）"><a href="#序列号（Sequence-Number）" class="headerlink" title="序列号（Sequence Number）"></a>序列号（Sequence Number）</h2><p>字段长32位。序列号（序号）是指发送数据的位置，每发送一次数据，就累加一次该数据字节数的大小。</p><p><font color="DeepPink"><strong>序列号不会从0或1开始，而是建立连接时由计算机生成的随机数作为其初始值，通过SYN包传给接收端主机。</strong></font>然后再将每转发过去的字节数累加到初始值上表示数据的位置。此外，在建立连接和断开连接时发送的SYN包和FIN包虽然并不携带数据，但是也会作为一个字节增加对应的序列号。</p><h2 id="确认应答号（Acknowledgement-Number）"><a href="#确认应答号（Acknowledgement-Number）" class="headerlink" title="确认应答号（Acknowledgement Number）"></a>确认应答号（Acknowledgement Number）</h2><p>确认应答号字段长度32位。是指下一次应该受到的数据的序列号。实际上，它是指已收到确认应答号减一为止的数据。发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。</p><h2 id="数据偏移（Data-Offset）"><a href="#数据偏移（Data-Offset）" class="headerlink" title="数据偏移（Data Offset）"></a>数据偏移（Data Offset）</h2><p>该字段表示TCP所传输的数据部分应该从TCP包的哪个位开始计算，当然也可以把它看做TCP首部的长度。该字段长4位，单位为4字节（即32位）。</p><h2 id="保留（Reserved）"><a href="#保留（Reserved）" class="headerlink" title="保留（Reserved）"></a>保留（Reserved）</h2><p>该字段主要是为了以后扩展时使用，其长度为4位。一般设置为0，但即使收到的包在该字段不为0，此包也不会被丢弃。</p><h2 id="控制位（Control-Flag）"><a href="#控制位（Control-Flag）" class="headerlink" title="控制位（Control Flag）"></a>控制位（Control Flag）</h2><p>字段长为8位，每一位从左至右分别为CWR、ECE、URG、ACK、PSH、RST、SYN、FIN。这些控制标志也叫作控制位。</p><p><img src="/images/tcp-and-udp-note/%E6%8E%A7%E5%88%B6%E4%BD%8D.png" alt></p><h3 id="CWR（Congestion-Window-Reduced）"><a href="#CWR（Congestion-Window-Reduced）" class="headerlink" title="CWR（Congestion Window Reduced）"></a>CWR（Congestion Window Reduced）</h3><p>CWR标志与后面的ECE标志都用于IP首部的ECN字段。ECE标志为1时，则通知对方已将拥塞窗口缩小。</p><h3 id="ECE（ECN-Echo）"><a href="#ECE（ECN-Echo）" class="headerlink" title="ECE（ECN-Echo）"></a>ECE（ECN-Echo）</h3><p>ECE标志表示ECN-Echo。置为1会通知通信对方，从对方到这边的网络有拥塞。在收到数据包的IP首部中ECN为1时将TCP首部中的ECE设置为1。</p><h3 id="URG（Urgent-Flag）"><a href="#URG（Urgent-Flag）" class="headerlink" title="URG（Urgent Flag）"></a>URG（Urgent Flag）</h3><p>该位为1时，确认应答的字段变为有效。TCP规定除了最初建立连接时的SYN包之外该位必须设置为1。</p><h3 id="PSH（Push-Flag）"><a href="#PSH（Push-Flag）" class="headerlink" title="PSH（Push Flag）"></a>PSH（Push Flag）</h3><p>该位为1时，表示需要将受到的数据立即传给上层应用协议。PSH为0时，则不需要立即传而是先进性缓存。</p><h3 id="RST（Reset-Flag）"><a href="#RST（Reset-Flag）" class="headerlink" title="RST（Reset Flag）"></a>RST（Reset Flag）</h3><p>该位为1时表示TCP连接中出现异常必须强制断开连接。</p><h3 id="SYN（Synchronize-Flag）"><a href="#SYN（Synchronize-Flag）" class="headerlink" title="SYN（Synchronize Flag）"></a>SYN（Synchronize Flag）</h3><p>用于建立连接。SYN为1 表示希望建立连接，并在其序列号的字段进行序列号初始值的设定。</p><h3 id="FIN（Fin-Flag）"><a href="#FIN（Fin-Flag）" class="headerlink" title="FIN（Fin Flag）"></a>FIN（Fin Flag）</h3><p>该位为1时，表示今后不会再有数据发送，希望断开连接。<br>窗口大小（Window Size）</p><h2 id="窗口大小（Window-Size）"><a href="#窗口大小（Window-Size）" class="headerlink" title="窗口大小（Window Size）"></a>窗口大小（Window Size）</h2><p>该字段长为16位。用于通知从相同TCP首部的确认应答号所指位置开始能够接收的数据大小（8位字节）。TCP不允许发送超过此处所示大小的数据。不过，如果窗口为0，则表示可以发送窗口探测，以了解最新的窗口大小。但这个数据必须是1个字节。</p><h2 id="校验和（Checksum）-1"><a href="#校验和（Checksum）-1" class="headerlink" title="校验和（Checksum）"></a>校验和（Checksum）</h2><p>TCP的校验和与UDP相似，区别在于TCP的校验和无法关闭。<br>TCP和UDP一样在计算校验和的时候使用TCP伪首部。</p><p>接收端在收到TCP数据段以后，从IP首部获取IP地址信息构造TCP伪首部，再进行校验和计算。由于校验和字段里保存着除本字段以外洽谈部分的和的补码值，一次如果计算校验和字段在内的所有数据的16位和以后，得出的结果是“16位全部为1”说明所收到数据是正确的。</p><h2 id="紧急指针（Urgent-Pointer）"><a href="#紧急指针（Urgent-Pointer）" class="headerlink" title="紧急指针（Urgent Pointer）"></a>紧急指针（Urgent Pointer）</h2><p>略</p><h2 id="选项（Options）"><a href="#选项（Options）" class="headerlink" title="选项（Options）"></a>选项（Options）</h2><p>略</p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> Network </tag>
            
            <tag> TCP </tag>
            
            <tag> UDP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解 Go Channels</title>
      <link href="/go-channels.html"/>
      <url>/go-channels.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Golang Channel</p></blockquote><a id="more"></a><h1 id="一、视频信息"><a href="#一、视频信息" class="headerlink" title="一、视频信息"></a>一、视频信息</h1><h2 id="1、视频观看地址"><a href="#1、视频观看地址" class="headerlink" title="1、视频观看地址"></a>1、视频观看地址</h2><p><a href="https://www.youtube.com/watch?v=KBZlN0izeiY" target="_blank" rel="noopener">https://www.youtube.com/watch?v=KBZlN0izeiY</a></p><h2 id="2、PPT下载地址"><a href="#2、PPT下载地址" class="headerlink" title="2、PPT下载地址"></a>2、PPT下载地址</h2><p><a href="http://download.csdn.net/download/xunzaosiyecao/10212884" target="_blank" rel="noopener">http://download.csdn.net/download/xunzaosiyecao/10212884</a></p><h2 id="3、博文"><a href="#3、博文" class="headerlink" title="3、博文"></a>3、博文</h2><p><a href="https://about.sourcegraph.com/go/understanding-channels-kavya-joshi/" target="_blank" rel="noopener">https://about.sourcegraph.com/go/understanding-channels-kavya-joshi/</a></p><h1 id="二、Go-的并发特性"><a href="#二、Go-的并发特性" class="headerlink" title="二、Go 的并发特性"></a>二、Go 的并发特性</h1><ul><li>goroutines: 独立执行每个任务，并可能<font color="DeepPink"><strong>并行执行</strong></font></li><li>channels: 用于 goroutines 之间的通讯、同步</li></ul><h2 id="1、一个简单的事务处理的例子"><a href="#1、一个简单的事务处理的例子" class="headerlink" title="1、一个简单的事务处理的例子"></a>1、一个简单的事务处理的例子</h2><p>对于下面这样的非并发的程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">  tasks := getTasks()</span><br><span class="line">  // 处理每个任务</span><br><span class="line">  for _, task := range tasks &#123;</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将其转换为 Go 的并发模式很容易，使用典型的 Task Queue 的模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">  //  创建带缓冲的 channel</span><br><span class="line">  ch := make(chan Task, 3)</span><br><span class="line">  //  运行固定数量的 workers</span><br><span class="line">  for i := 0; i &lt; numWorkers; i++ &#123;</span><br><span class="line">    go worker(ch)</span><br><span class="line">  &#125;</span><br><span class="line">  //  发送任务到 workers</span><br><span class="line">  hellaTasks := getTasks()</span><br><span class="line">  for _, task := range hellaTasks &#123;</span><br><span class="line">    ch &lt;- task</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">func worker(ch chan Task) &#123;</span><br><span class="line">  for &#123;</span><br><span class="line">    //  接收任务</span><br><span class="line">    task := &lt;-ch</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2、channels-的特性"><a href="#2、channels-的特性" class="headerlink" title="2、channels 的特性"></a>2、channels 的特性</h2><ul><li>goroutine-safe，多个 goroutine 可以同时访问一个 channel。</li><li>可以用于在 goroutine 之间存储和传递值</li><li>其语义是先入先出（FIFO）</li><li>可以导致 goroutine 的 block 和 unblock</li></ul><h1 id="三、解析"><a href="#三、解析" class="headerlink" title="三、解析"></a>三、解析</h1><h2 id="1、构造-channel"><a href="#1、构造-channel" class="headerlink" title="1、构造 channel"></a>1、构造 channel</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//  带缓冲的 channel</span><br><span class="line">ch := make(chan Task, 3)</span><br><span class="line">//  无缓冲的 channel</span><br><span class="line">ch := make(chan Task)</span><br></pre></td></tr></table></figure><p>回顾前面提到的 channel 的特性，特别是前两个。如果忽略内置的 channel，让你设计一个具有 goroutines-safe 并且可以用来存储、传递值的东西，你会怎么做？很多人可能觉得或许可以用一个带锁的队列来做。没错，事实上，channel 内部就是一个带锁的队列。<br><a href="https://golang.org/src/runtime/chan.go" target="_blank" rel="noopener">https://golang.org/src/runtime/chan.go</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">type hchan struct &#123;</span><br><span class="line">  ...</span><br><span class="line">  buf      unsafe.Pointer // 指向一个环形队列</span><br><span class="line">  ...</span><br><span class="line">  sendx    uint   // 发送 index</span><br><span class="line">  recvx    uint   // 接收 index</span><br><span class="line">  ...</span><br><span class="line">  lock     mutex  //  互斥量</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>buf 的具体实现很简单，就是一个环形队列的实现。sendx 和 recvx 分别用来记录发送、接收的位置。然后用一个 lock 互斥锁来确保无竞争冒险。</p><p>对于每一个 ch := make(chan Task, 3) 这类操作，都会在<font color="DeepPink"><strong>堆</strong></font>中，分配一个空间，建立并初始化一个 hchan 结构变量，而 ch 则是指向这个 hchan 结构的<font color="DeepPink"><strong>指针</strong></font>。</p><p>因为 ch 本身就是个指针，所以我们才可以在 goroutine 函数调用的时候直接将 ch 传递过去，而不用再 &amp;ch 取指针了，所以所有使用同一个 ch 的 goroutine 都指向了同一个实际的内存空间。</p><h2 id="2、发送、接收"><a href="#2、发送、接收" class="headerlink" title="2、发送、接收"></a>2、发送、接收</h2><p>为了方便描述，我们用 G1 表示 main() 函数的 goroutine，而 G2 表示 worker 的 goroutine。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// G1</span><br><span class="line">func main() &#123;</span><br><span class="line">  ...</span><br><span class="line">  for _, task := range tasks &#123;</span><br><span class="line">    ch &lt;- task</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">// G2</span><br><span class="line">func worker(ch chan Task) &#123;</span><br><span class="line">  for &#123;</span><br><span class="line">    task :=&lt;-ch</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-1-简单的发送、接收"><a href="#2-1-简单的发送、接收" class="headerlink" title="2.1 简单的发送、接收"></a>2.1 简单的发送、接收</h3><p>那么 G1 中的 ch &lt;- task0 具体是怎么做的呢？</p><ul><li>获取锁</li><li>enqueue(task0)（这里是内存复制 task0）</li><li>释放锁</li></ul><p>这一步很简单，接下来看 G2 的 t := &lt;- ch 是如何读取数据的。</p><ul><li>获取锁</li><li>t = dequeue()（同样，这里也是内存复制）</li><li>释放锁</li></ul><p>这一步也非常简单。但是我们从这个操作中可以看到，所有 goroutine 中共享的部分只有这个 hchan 的结构体，而所有通讯的数据都是<font color="DeepPink"><strong>内存复制</strong></font>。这遵循了 Go 并发设计中很核心的一个理念：</p><blockquote><p>Do not communicate by sharing memory;instead, share memory by communicating</p></blockquote><p>内存复制指的是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">// typedmemmove copies a value of type t to dst from src.</span><br><span class="line">// Must be nosplit, see #16026.</span><br><span class="line">//go:nosplit</span><br><span class="line">func typedmemmove(typ *_type, dst, src unsafe.Pointer) &#123;</span><br><span class="line">    if typ.kind&amp;kindNoPointers == 0 &#123;</span><br><span class="line">        bulkBarrierPreWrite(uintptr(dst), uintptr(src), typ.size)</span><br><span class="line">    &#125;</span><br><span class="line">    // There&apos;s a race here: if some other goroutine can write to</span><br><span class="line">    // src, it may change some pointer in src after we&apos;ve</span><br><span class="line">    // performed the write barrier but before we perform the</span><br><span class="line">    // memory copy. This safe because the write performed by that</span><br><span class="line">    // other goroutine must also be accompanied by a write</span><br><span class="line">    // barrier, so at worst we&apos;ve unnecessarily greyed the old</span><br><span class="line">    // pointer that was in src.</span><br><span class="line">    memmove(dst, src, typ.size)</span><br><span class="line">    if writeBarrier.cgo &#123;</span><br><span class="line">        cgoCheckMemmove(typ, dst, src, 0, typ.size)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3、阻塞和恢复"><a href="#3、阻塞和恢复" class="headerlink" title="3、阻塞和恢复"></a>3、阻塞和恢复</h2><h3 id="3-1-发送方被阻塞"><a href="#3-1-发送方被阻塞" class="headerlink" title="3.1 发送方被阻塞"></a>3.1 发送方被阻塞</h3><p>假设 G2 需要很长时间的处理，在此期间，G1 不断的发送任务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ch &lt;- task1</span><br><span class="line">ch &lt;- task2</span><br><span class="line">ch &lt;- task3</span><br></pre></td></tr></table></figure><p>但是当再一次 ch &lt;- task4 的时候，由于 ch 的缓冲只有 3 个，所以没有地方放了，于是 G1 被 block 了，当有人从队列中取走一个 Task 的时候，G1 才会被恢复。这是我们都知道的，不过我们今天关心的不是发生了什么，而是如何做到的？</p><h3 id="3-2-goroutine-的运行时调度"><a href="#3-2-goroutine-的运行时调度" class="headerlink" title="3.2 goroutine 的运行时调度"></a>3.2 goroutine 的运行时调度</h3><p>首先，goroutine <font color="DeepPink"><strong>不是操作系统线程</strong></font>，而是 <font color="DeepPink"><strong>用户空间线程</strong></font>。因此 goroutine 是由 Go runtime 来创建并管理的，而不是 OS，所以要比操作系统线程轻量级。</p><p>当然，goroutine 最终还是要运行于某个线程中的，控制 goroutine 如何运行于线程中的是 Go runtime 中的 scheduler （调度器）。</p><p>Go 的运行时调度器是 M:N 调度模型，既 N 个 goroutine，会运行于 M 个 OS 线程中。换句话说，一个 OS 线程中，可能会运行多个 goroutine。</p><p>Go 的 M:N 调度中使用了3个结构：</p><ul><li>M: OS 线程</li><li>G: goroutine</li><li>P: 调度上下文<ul><li>P 拥有一个运行队列，里面是所有可以运行的 goroutine 及其上下文</li></ul></li></ul><h3 id="3-3-goroutine-被阻塞的具体过程"><a href="#3-3-goroutine-被阻塞的具体过程" class="headerlink" title="3.3 goroutine 被阻塞的具体过程"></a>3.3 goroutine 被阻塞的具体过程</h3><p>那么当 ch &lt;- task4 执行的时候，channel 中已经满了，需要 <font color="DeepPink"><strong>pause</strong></font> G1。这个时候：</p><ol><li>G1 会调用运行时的 gopark</li><li>然后 Go 的运行时调度器就会接管</li><li>将 G1 的状态设置为 waiting</li><li>断开 G1 和 M 之间的关系（switch out)，因此 G1 脱离 M，换句话说，M 空闲了，可以安排别的任务了。</li><li>从 P 的运行队列中，取得一个可运行的 goroutine G</li><li>建立新的 G 和 M 的关系（Switch in)，因此 G 就准备好运行了。</li><li>当调度器返回的时候，新的 G 就开始运行了，而 G1 则不会运行，也就是 block 了。</li></ol><p>从上面的流程中可以看到，<font color="DeepPink"><strong>对于 goroutine 来说，G1 被阻塞了，新的 G 开始运行了；而对于操作系统线程 M 来说，则根本没有被阻塞。</strong></font></p><p>我们知道 OS 线程要比 goroutine 要沉重的多，因此这里尽量避免 OS 线程阻塞，可以提高性能。</p><h3 id="3-4-goroutine-恢复执行的具体过程"><a href="#3-4-goroutine-恢复执行的具体过程" class="headerlink" title="3.4 goroutine 恢复执行的具体过程"></a>3.4 goroutine 恢复执行的具体过程</h3><p>前面理解了阻塞，那么接下来理解一下如何恢复运行。不过，在继续了解如何恢复之前，我们需要先进一步理解 hchan 这个结构。因为，当 channel 不在满的时候，调度器是如何知道该让哪个 goroutine 继续运行呢？而且 goroutine 又是如何知道该从哪取数据呢？</p><p>在 hchan 中，除了之前提到的内容外，还定义有 sendq 和 recvq 两个队列，分别表示等待发送、接收的 goroutine，及其相关信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">type hchan struct &#123;</span><br><span class="line">  ...</span><br><span class="line">  buf      unsafe.Pointer // 指向一个环形队列</span><br><span class="line">  ...</span><br><span class="line">  sendq    waitq  // 等待发送的队列</span><br><span class="line">  recvq    waitq  // 等待接收的队列</span><br><span class="line">  ...</span><br><span class="line">  lock     mutex  //  互斥量</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 waitq 是一个链表结构的队列，每个元素是一个 sudog 的结构，其定义大致为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type sudog struct &#123;</span><br><span class="line">  g          *g //  正在等候的 goroutine</span><br><span class="line">  elem       unsafe.Pointer // 指向需要接收、发送的元素</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://golang.org/src/runtime/runtime2.go?h=sudog#L270" target="_blank" rel="noopener">https://golang.org/src/runtime/runtime2.go?h=sudog#L270</a></p><p>所以在之前的阻塞 G1 的过程中，实际上：</p><ol><li>G1 会<font color="DeepPink"><strong>给自己</strong></font>创建一个 sudog 的变量</li><li>然后追加到 sendq 的等候队列中，方便将来的<font color="DeepPink"><strong>receiver</strong></font> 来使用这些信息恢复 G1。</li></ol><p>这些都是<font color="DeepPink"><strong>发生在调用调度器之前</strong></font>。</p><p>那么现在开始看一下如何恢复。</p><p>当 G2 调用 t := &lt;- ch 的时候，channel 的状态是，缓冲是满的，而且还有一个 G1 在等候发送队列里，然后 G2 执行下面的操作：</p><ol><li>G2 先执行 dequeue() 从缓冲队列中取得 task1 给 t</li><li>G2 从 sendq 中弹出一个等候发送的 sudog</li><li>将弹出的 sudog 中的 elem 的值 enqueue() 到 buf 中</li><li>将弹出的 sudog 中的 goroutine，也就是 G1，状态从 waiting 改为 runnable<ol><li>然后，G2 需要通知调度器 G1 已经可以进行调度了，因此调用 goready(G1)。</li><li>调度器将 G1 的状态改为 runnable</li><li>调度器将 G1 压入 P 的运行队列，因此在将来的某个时刻调度的时候，G1 就会开始恢复运行。</li><li>返回到 G2<blockquote><p>注意，这里是由 G2 来负责将 G1 的 elem 压入 buf 的，这是一个优化。这样将来 G1 恢复运行后，就不必再次获取锁、enqueue()、释放锁了。这样就避免了多次锁的开销。</p></blockquote></li></ol></li></ol><h3 id="3-5-如果接收方先阻塞呢？"><a href="#3-5-如果接收方先阻塞呢？" class="headerlink" title="3.5 如果接收方先阻塞呢？"></a>3.5 如果接收方先阻塞呢？</h3><p>更酷的地方是接收方先阻塞的流程。</p><p>如果 G2 先执行了 t := &lt;- ch，此时 buf 是空的，因此 G2 会被阻塞，他的流程是这样：</p><ol><li>G2 给自己创建一个 sudog 结构变量。其中 g 是自己，也就是 G2，而 elem 则指向 t</li><li>将这个 sudog 变量压入 recvq 等候接收队列</li><li>G2 需要告诉 goroutine，自己需要 pause 了，于是调用 gopark(G2) <ol><li>和之前一样，调度器将其 G2 的状态改为 waiting</li><li>断开 G2 和 M 的关系</li><li>从 P 的运行队列中取出一个 goroutine</li><li>建立新的 goroutine 和 M 的关系</li><li>返回，开始继续运行新的 goroutine</li></ol></li></ol><p>这些应该已经不陌生了，那么当 G1 开始发送数据的时候，流程是什么样子的呢？</p><p>G1 可以将 enqueue(task)，然后调用 goready(G2)。不过，我们可以更聪明一些。</p><p>我们根据 hchan 结构的状态，已经知道 task 进入 buf 后，G2 恢复运行后，会读取其值，复制到 t 中。那么 G1 可以根本不走 buf，<font color="DeepPink"><strong>G1 可以直接把数据给 G2</strong></font>。</p><p>Goroutine 通常都有自己的栈，互相之间不会访问对方的栈内数据，<font color="DeepPink"><strong>除了 channel</strong></font>。这里，由于我们已经知道了 t 的地址（通过 elem指针），而且由于 G2 不在运行，所以我们可以很安全的直接赋值。当 G2 恢复运行的时候，既不需要再次获取锁，也不需要对 buf 进行操作。从而节约了内存复制、以及锁操作的开销。</p><h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><ul><li>goroutine-safe<ul><li>hchan 中的 lock mutex</li></ul></li><li>存储、传递值，FIFO<ul><li>通过 hchan 中的环形缓冲区来实现</li></ul></li><li>导致 goroutine 的阻塞和恢复<ul><li>hchan 中的 sendq和recvq，也就是 sudog 结构的链表队列</li><li>调用运行时调度器 (gopark(), goready())</li></ul></li></ul><h1 id="四、其它-channel-的操作"><a href="#四、其它-channel-的操作" class="headerlink" title="四、其它 channel 的操作"></a>四、其它 channel 的操作</h1><h2 id="1、无缓冲-channel"><a href="#1、无缓冲-channel" class="headerlink" title="1、无缓冲 channel"></a>1、无缓冲 channel</h2><p>无缓冲的 channel 行为就和前面说的<font color="DeepPink"><strong>直接发送</strong></font>的例子一样：</p><ul><li>接收方阻塞 → 发送方<font color="DeepPink"><strong>直接写入接收方的栈</strong></font></li><li>发送方阻塞 → 接受法<font color="DeepPink"><strong>直接从发送方的 sudog 中读取</strong></font></li></ul><h2 id="2、select"><a href="#2、select" class="headerlink" title="2、select"></a>2、select</h2><p><a href="https://golang.org/src/runtime/select.go" target="_blank" rel="noopener">https://golang.org/src/runtime/select.go</a></p><ol><li>先把所有需要操作的 channel 上锁</li><li>给自己创建一个 sudog，然后添加到所有 channel 的 sendq或recvq（取决于是发送还是接收）</li><li>把所有的 channel 解锁，然后 pause 当前调用 select 的 goroutine（gopark()）</li><li>然后当有任意一个 channel 可用时，select 的这个 goroutine 就会被调度执行。</li><li>resuming mirrors the pause sequence</li></ol><h1 id="五、为什么-Go-会这样设计？"><a href="#五、为什么-Go-会这样设计？" class="headerlink" title="五、为什么 Go 会这样设计？"></a>五、为什么 Go 会这样设计？</h1><h2 id="1、Simplicity"><a href="#1、Simplicity" class="headerlink" title="1、Simplicity"></a>1、Simplicity</h2><p>更倾向于带锁的队列，而不是无锁的实现。</p><p>性能提升不是凭空而来的，是随着复杂度增加而增加的。</p><p>dvyokov<br>后者虽然性能可能会更好，但是这个优势，并不一定能够战胜随之而来的实现代码的复杂度所带来的劣势。</p><h2 id="2、Performance"><a href="#2、Performance" class="headerlink" title="2、Performance"></a>2、Performance</h2><ul><li>调用 Go 运行时调度器，这样可以保持 OS 线程不被阻塞跨 goroutine 的栈读、写。</li><li>可以让 goroutine 醒来后不必获取锁。</li><li>可以避免一些内存复制。</li></ul><p>当然，<font color="DeepPink"><strong>任何优势都会有其代价</strong></font>。这里的代价是实现的复杂度，所以这里有更复杂的内存管理机制、垃圾回收以及栈收缩机制。</p><p>在这里性能的提高优势，要比复杂度的提高带来的劣势要大。</p><p>所以在 channel 实现的各种代码中，我们都可以见到这种<font color="DeepPink"><strong>simplicity vs performance</strong></font> 的权衡后的结果。</p><blockquote><p>本文转载自：<br><a href="https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> Channel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go 1.9 Sync Map</title>
      <link href="/go-sync-map.html"/>
      <url>/go-sync-map.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>基于Go 1.9 解析Sync Map</p></blockquote><a id="more"></a><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><h2 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h2><p><img src="/images/go-sync-map/package.png" alt></p><p>本文主要阐述：Load、Store、Delete，更加详细的阐述可以参考源码描述（建议先大体浏览一下Map源码）。</p><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ul><li>空间换时间。 通过冗余的两个数据结构(read、dirty),实现加锁对性能的影响。</li><li>使用只读数据(read)，避免读写冲突。</li><li>动态调整，miss次数多了之后，将dirty数据提升为read。</li><li>double-checking。</li><li>延迟删除。 删除一个键值只是打标记（会将key对应value的pointer置为nil，但read中仍然有这个key:key;value:nil的键值对），只有在提升dirty的时候才清理删除的数据。</li><li>优先从read读取、更新、删除，因为对read的读取不需要锁。</li><li>虽然read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的。</li></ul><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">// Map is a concurrent map with amortized-constant-time loads, stores, and deletes.</span><br><span class="line">// It is safe for multiple goroutines to call a Map&apos;s methods concurrently.</span><br><span class="line">//</span><br><span class="line">// It is optimized for use in concurrent loops with keys that are</span><br><span class="line">// stable over time, and either few steady-state stores, or stores</span><br><span class="line">// localized to one goroutine per key.</span><br><span class="line">//</span><br><span class="line">// For use cases that do not share these attributes, it will likely have</span><br><span class="line">// comparable or worse performance and worse type safety than an ordinary</span><br><span class="line">// map paired with a read-write mutex.</span><br><span class="line">//</span><br><span class="line">// The zero Map is valid and empty.</span><br><span class="line">//</span><br><span class="line">// A Map must not be copied after first use.</span><br><span class="line"></span><br><span class="line">//该 Map 是线程安全的，读取，插入，删除也都保持着常数级的时间复杂度。</span><br><span class="line">//多个 goroutines 协程同时调用 Map 方法也是线程安全的。该 Map 的零值是有效的，</span><br><span class="line">//并且零值是一个空的 Map 。线程安全的 Map 在第一次使用之后，不允许被拷贝。</span><br><span class="line">type Map struct &#123;</span><br><span class="line">mu Mutex</span><br><span class="line"></span><br><span class="line">// read contains the portion of the map&apos;s contents that are safe for</span><br><span class="line">// concurrent access (with or without mu held).</span><br><span class="line">//</span><br><span class="line">// The read field itself is always safe to load, but must only be stored with</span><br><span class="line">// mu held.</span><br><span class="line">//</span><br><span class="line">// Entries stored in read may be updated concurrently without mu, but updating</span><br><span class="line">// a previously-expunged entry requires that the entry be copied to the dirty</span><br><span class="line">// map and unexpunged with mu held.</span><br><span class="line"></span><br><span class="line"> // 一个只读的数据结构，因为只读，所以不会有读写冲突。</span><br><span class="line">    // 所以从这个数据中读取总是安全的。</span><br><span class="line">    // 实际上，实际也会更新这个数据的entries,如果entry是未删除的(unexpunged), 并不需要加锁。如果entry已经被删除了，需要加锁，以便更新dirty数据。</span><br><span class="line">read atomic.Value // readOnly</span><br><span class="line"></span><br><span class="line">// dirty contains the portion of the map&apos;s contents that require mu to be</span><br><span class="line">// held. To ensure that the dirty map can be promoted to the read map quickly,</span><br><span class="line">// it also includes all of the non-expunged entries in the read map.</span><br><span class="line">//</span><br><span class="line">// Expunged entries are not stored in the dirty map. An expunged entry in the</span><br><span class="line">// clean map must be unexpunged and added to the dirty map before a new value</span><br><span class="line">// can be stored to it.</span><br><span class="line">//</span><br><span class="line">// If the dirty map is nil, the next write to the map will initialize it by</span><br><span class="line">// making a shallow copy of the clean map, omitting stale entries.</span><br><span class="line"></span><br><span class="line">// dirty数据包含当前的map包含的entries,它包含最新的entries(包括read中未删除的数据,虽有冗余，但是提升dirty字段为read的时候非常快，不用一个一个的复制，而是直接将这个数据结构作为read字段的一部分),有些数据还可能没有移动到read字段中。</span><br><span class="line">    // 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争。</span><br><span class="line">    // 当dirty为空的时候， 比如初始化或者刚提升完，下一次的写操作会复制read字段中未删除的数据到这个数据中。</span><br><span class="line">dirty map[interface&#123;&#125;]*entry</span><br><span class="line"></span><br><span class="line">// misses counts the number of loads since the read map was last updated that</span><br><span class="line">// needed to lock mu to determine whether the key was present.</span><br><span class="line">//</span><br><span class="line">// Once enough misses have occurred to cover the cost of copying the dirty</span><br><span class="line">// map, the dirty map will be promoted to the read map (in the unamended</span><br><span class="line">// state) and the next store to the map will make a new dirty copy.</span><br><span class="line">// 当从Map中读取entry的时候，如果read中不包含这个entry,会尝试从dirty中读取，这个时候会将misses加一，</span><br><span class="line">    // 当misses累积到 dirty的长度的时候， 就会将dirty提升为read,避免从dirty中miss太多次。因为操作dirty需要加锁。</span><br><span class="line">misses int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="readOnly"><a href="#readOnly" class="headerlink" title="readOnly"></a>readOnly</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// readOnly is an immutable struct stored atomically in the Map.read field.</span><br><span class="line">type readOnly struct &#123;</span><br><span class="line">m       map[interface&#123;&#125;]*entry</span><br><span class="line">// true if the dirty map contains some key not in m.</span><br><span class="line">// 如果Map.dirty有些数据不在中的时候，这个值为true</span><br><span class="line">amended bool </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="entry"><a href="#entry" class="headerlink" title="entry"></a>entry</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">// An entry is a slot in the map corresponding to a particular key.</span><br><span class="line">type entry struct &#123;</span><br><span class="line">// p points to the interface&#123;&#125; value stored for the entry.</span><br><span class="line">//</span><br><span class="line">// If p == nil, the entry has been deleted and m.dirty == nil.</span><br><span class="line">//</span><br><span class="line">// If p == expunged, the entry has been deleted, m.dirty != nil, and the entry</span><br><span class="line">// is missing from m.dirty.</span><br><span class="line">//</span><br><span class="line">// Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty</span><br><span class="line">// != nil, in m.dirty[key].</span><br><span class="line">//</span><br><span class="line">// An entry can be deleted by atomic replacement with nil: when m.dirty is</span><br><span class="line">// next created, it will atomically replace nil with expunged and leave</span><br><span class="line">// m.dirty[key] unset.</span><br><span class="line">//</span><br><span class="line">// An entry&apos;s associated value can be updated by atomic replacement, provided</span><br><span class="line">// p != expunged. If p == expunged, an entry&apos;s associated value can be updated</span><br><span class="line">// only after first setting m.dirty[key] = e so that lookups using the dirty</span><br><span class="line">// map find the entry.</span><br><span class="line"></span><br><span class="line">//p有三种值：</span><br><span class="line">//nil: entry已被删除了，并且m.dirty为nil</span><br><span class="line">//expunged: entry已被删除了，并且m.dirty不为nil，而且这个entry不存在于m.dirty中</span><br><span class="line">//其它： entry是一个正常的值</span><br><span class="line">p unsafe.Pointer // *interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Value"><a href="#Value" class="headerlink" title="Value"></a>Value</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// A Value provides an atomic load and store of a consistently typed value.</span><br><span class="line">// Values can be created as part of other data structures.</span><br><span class="line">// The zero value for a Value returns nil from Load.</span><br><span class="line">// Once Store has been called, a Value must not be copied.</span><br><span class="line">//</span><br><span class="line">// A Value must not be copied after first use.</span><br><span class="line">type Value struct &#123;</span><br><span class="line">noCopy noCopy</span><br><span class="line"></span><br><span class="line">v interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/go-sync-map/map%E7%BB%93%E6%9E%84%E5%85%B3%E7%B3%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><h1 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h1><p>据指定的key,查找对应的值value,如果不存在，通过ok反映。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">func (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123;</span><br><span class="line">read, _ := m.read.Load().(readOnly)</span><br><span class="line">e, ok := read.m[key]</span><br><span class="line">// 如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁</span><br><span class="line">if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">m.mu.Lock()</span><br><span class="line">// Avoid reporting a spurious miss if m.dirty got promoted while we were</span><br><span class="line">// blocked on m.mu. (If further loads of the same key will not miss, it&apos;s</span><br><span class="line">// not worth copying the dirty map for this key.)</span><br><span class="line">//double check,避免加锁的时候m.dirty提升为m.read,这个时候m.read可能被替换了。</span><br><span class="line">read, _ = m.read.Load().(readOnly)</span><br><span class="line">e, ok = read.m[key]</span><br><span class="line">if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">e, ok = m.dirty[key]</span><br><span class="line">// Regardless of whether the entry was present, record a miss: this key</span><br><span class="line">// will take the slow path until the dirty map is promoted to the read</span><br><span class="line">// map.</span><br><span class="line">m.missLocked()</span><br><span class="line">&#125;</span><br><span class="line">m.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line">if !ok &#123;</span><br><span class="line">return nil, false</span><br><span class="line">&#125;</span><br><span class="line">return e.load()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (m *Map) missLocked() &#123;</span><br><span class="line">m.misses++</span><br><span class="line">if m.misses &lt; len(m.dirty) &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">m.read.Store(readOnly&#123;m: m.dirty&#125;)</span><br><span class="line">m.dirty = nil</span><br><span class="line">m.misses = 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/go-sync-map/get%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt></p><h1 id="Store"><a href="#Store" class="headerlink" title="Store"></a>Store</h1><p>更新或者新增一个entry</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">// Store sets the value for a key.</span><br><span class="line">func (m *Map) Store(key, value interface&#123;&#125;) &#123;</span><br><span class="line">read, _ := m.read.Load().(readOnly)</span><br><span class="line">// 从 read map 中读取 key 成功并且取出的 entry 尝试存储 value 成功，直接返回</span><br><span class="line">if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">m.mu.Lock()</span><br><span class="line">read, _ = m.read.Load().(readOnly)</span><br><span class="line">if e, ok := read.m[key]; ok &#123;</span><br><span class="line">if e.unexpungeLocked() &#123;//确保未被标记成删除，即e 指向的是非 nil 的</span><br><span class="line">// The entry was previously expunged, which implies that there is a</span><br><span class="line">// non-nil dirty map and this entry is not in it.</span><br><span class="line">//m.dirty中不存在这个键，所以加入m.dirty</span><br><span class="line">m.dirty[key] = e</span><br><span class="line">&#125;</span><br><span class="line">e.storeLocked(&amp;value)</span><br><span class="line">&#125; else if e, ok := m.dirty[key]; ok &#123;</span><br><span class="line">e.storeLocked(&amp;value)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">if !read.amended &#123;</span><br><span class="line">// We&apos;re adding the first new key to the dirty map.</span><br><span class="line">// Make sure it is allocated and mark the read-only map as incomplete.</span><br><span class="line">m.dirtyLocked()</span><br><span class="line">m.read.Store(readOnly&#123;m: read.m, amended: true&#125;)</span><br><span class="line">&#125;</span><br><span class="line">m.dirty[key] = newEntry(value)</span><br><span class="line">&#125;</span><br><span class="line">m.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// tryStore stores a value if the entry has not been expunged.</span><br><span class="line">//</span><br><span class="line">// If the entry is expunged, tryStore returns false and leaves the entry</span><br><span class="line">// unchanged.</span><br><span class="line">func (e *entry) tryStore(i *interface&#123;&#125;) bool &#123;</span><br><span class="line">p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">if p == expunged &#123;</span><br><span class="line">return false</span><br><span class="line">&#125;</span><br><span class="line">for &#123;</span><br><span class="line">if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) &#123;</span><br><span class="line">return true</span><br><span class="line">&#125;</span><br><span class="line">p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">if p == expunged &#123;</span><br><span class="line">return false</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">func (m *Map) dirtyLocked() &#123;</span><br><span class="line">if m.dirty != nil &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read, _ := m.read.Load().(readOnly)</span><br><span class="line">m.dirty = make(map[interface&#123;&#125;]*entry, len(read.m))</span><br><span class="line">for k, e := range read.m &#123;</span><br><span class="line">if !e.tryExpungeLocked() &#123;</span><br><span class="line">m.dirty[k] = e</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (e *entry) tryExpungeLocked() (isExpunged bool) &#123;</span><br><span class="line">p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">for p == nil &#123;</span><br><span class="line"> // 将已经删除标记为nil的数据标记为expunged</span><br><span class="line">if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) &#123;</span><br><span class="line">return true</span><br><span class="line">&#125;</span><br><span class="line">p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">&#125;</span><br><span class="line">return p == expunged</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// unexpungeLocked ensures that the entry is not marked as expunged.</span><br><span class="line">// If the entry was previously expunged, it must be added to the dirty map</span><br><span class="line">// before m.mu is unlocked.</span><br><span class="line"></span><br><span class="line">// unexpungeLocked 函数确保了 entry 没有被标记成已被清除。</span><br><span class="line">// 如果 entry 先前被清除过了，那么在 mutex 解锁之前，它一定要被加入到 dirty map 中</span><br><span class="line"></span><br><span class="line">//如果 entry 的 unexpungeLocked 返回为 true，那么就说明 entry </span><br><span class="line">//之前被标记成了 expunged，并经过 CAS 操作成功把它置为 nil。</span><br><span class="line">func (e *entry) unexpungeLocked() (wasExpunged bool) &#123;</span><br><span class="line">return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/go-sync-map/store%E6%B5%81%E7%A8%8B%E5%9B%BE.bmp" alt></p><h1 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h1><p>删除一个键值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">// Delete deletes the value for a key.</span><br><span class="line">func (m *Map) Delete(key interface&#123;&#125;) &#123;</span><br><span class="line">read, _ := m.read.Load().(readOnly)</span><br><span class="line">e, ok := read.m[key]</span><br><span class="line">if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">m.mu.Lock()</span><br><span class="line">read, _ = m.read.Load().(readOnly)</span><br><span class="line">e, ok = read.m[key]</span><br><span class="line">if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">delete(m.dirty, key)</span><br><span class="line">&#125;</span><br><span class="line">m.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line">if ok &#123;</span><br><span class="line">e.delete()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (e *entry) delete() (hadValue bool) &#123;</span><br><span class="line">for &#123;</span><br><span class="line">p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">// 已标记为删除</span><br><span class="line">if p == nil || p == expunged &#123;</span><br><span class="line">return false</span><br><span class="line">&#125;</span><br><span class="line">// 原子操作，e.p标记为nil</span><br><span class="line">if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) &#123;</span><br><span class="line">return true</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/go-sync-map/delete%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt></p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><h2 id="已经删除的key-再次Load的时候，会怎么样？"><a href="#已经删除的key-再次Load的时候，会怎么样？" class="headerlink" title="已经删除的key,再次Load的时候，会怎么样？"></a>已经删除的key,再次Load的时候，会怎么样？</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func (e *entry) load() (value interface&#123;&#125;, ok bool) &#123;</span><br><span class="line">p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">if p == nil || p == expunged &#123;</span><br><span class="line">return nil, false</span><br><span class="line">&#125;</span><br><span class="line">return *(*interface&#123;&#125;)(p), true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Map Load方法中调用e.load()时，load方法会识别该值是否已被删除</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://studygolang.com/articles/10511" target="_blank" rel="noopener">https://studygolang.com/articles/10511</a><br><a href="http://www.jianshu.com/p/43e66dab535b" target="_blank" rel="noopener">http://www.jianshu.com/p/43e66dab535b</a></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Go </tag>
            
            <tag> Sync </tag>
            
            <tag> Map </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cs-interview</title>
      <link href="/cs-interview.html"/>
      <url>/cs-interview.html</url>
      
        <content type="html"><![CDATA[<h1 id="Java部分"><a href="#Java部分" class="headerlink" title="Java部分"></a>Java部分</h1><ol><li>java比较 icompare</li><li>tomcat 热部署 加载方式与双亲委派模型？</li><li>java io api 过滤器模式？</li><li>threadLocal 实现原理？</li><li>tcp ip协议</li><li>服务端如何确定seesion是同一个？</li><li>内存屏障（Memory Barriers）</li><li>lock synchronized ReentrantLock</li><li>jvm JVM的年轻代分为哪几代？年轻代什么时候会进入老年代？</li><li>jvm JVM 垃圾回收算法？（注意年轻代与老年代是不一样的）?</li><li>jvm内存模型 一个变量初始化 怎么分配内存 分配到什么地方？</li><li>不使用双亲委派模型的缺点？</li><li>java 开源序列化框架有哪些？彼此之间有什么区别（优缺点）？</li><li>java.util.concurrent hashmap 相关问题</li><li>JAVA线程sleep和wait方法区别</li><li>PriorityQueue（优先级队列） 堆相关问题</li><li>常见的负载均衡算法</li><li>java 阻塞队列 相关问题，阻塞具体是如何实现的？</li><li>静态代码块. 构造代码块. 构造函数以及Java类初始化顺序</li><li>java 枚举的实现，内部如何进行存储的？</li><li>静态内部类与普通内部类，在用法. 初始化方面的区别？</li><li>java 原子性 可见性 顺序性是通过什么来保证的?</li><li>java 多线程内共享的模型</li><li>阻塞非阻塞与同步异步</li><li>java nio原理</li><li>读写锁 自旋锁 尝试锁（cas） cas如何保证，查询到修改这个过程是原子的？</li><li>一个类中的静态变量是在类加载的哪个步骤加载的？</li><li>synchronized与ReentrantLock 实现原理区别？</li><li>threadlocal 实现原理？应用场景？</li><li>常见的设计模式</li><li>分布式事务</li><li>线程池工作原理及机制</li><li>线程挂了 保活</li><li>keepalive 保活策略？</li><li>Protocol Buffers 适用场景？</li><li>http tcp 相比多了些什么？有什么不一样的地方？</li><li>http与https区别？加密算法是？</li><li>wait 是释放锁？为什么释放了锁，线程就挂起了。为什么线程wait了就挂起了？</li><li>CMS 垃圾回收</li><li>hashmap 线程不安全 什么时候会出现？会出现什么问题？（hashmap为啥线程不安全？）</li><li>equals 比较原理？</li><li>jvm 内存分布</li><li>arraylist linklist</li><li>interger 为null 转int 会发生什么？</li><li>hashmap与hashset的关系？</li><li>线程与协程的区别？协程的优势？</li><li>JDK8 如何实现协程？</li><li>java lambda 实现原理</li><li>java stream 实现原理</li><li>永久代(permanent generation)与Metaspace</li><li>如何保证GC ROOTS找的全？（比如中G1中）</li><li>G1清理老年代. 年轻代是遍历所有吗？</li><li>可重入锁和不可重入锁？不可重入锁有啥缺陷？</li><li>CPU密集型 Java线程池大小为何会大多被设置成CPU核心数+1？</li><li>什么情况下会出现ClassNotFoundException？</li><li>线程有几种状态？</li><li>如何动态上报JVM信息，以便后期排查OOM等问题？</li><li>ConcurrentHashMap put的时候加锁的是数组上的元素 还是啥？</li><li>Concurrenthashmap中用到的优化技巧？</li><li>LRU如何实现？</li></ol><h1 id="MySQL部分"><a href="#MySQL部分" class="headerlink" title="MySQL部分"></a>MySQL部分</h1><ol><li>mysql 时间 比较无效 原因？</li><li>mysql 数据库 索引 是以什么数据结构形式存储的？</li><li>mysql与sql server 异同点？ 原理上？</li><li>索引顺序对于索引效果的影响？</li><li>数据库索引如何优化（从哪几个方面）？</li><li>mysql优化有哪些？</li><li>比如一个表中有100条数据，a字段的值，是从1到100，我要更新其中的数据，where条件时a&gt;10<br>mysql通过innodb引擎的话，是通过表锁还是行锁？</li><li>mysql mvcc多版本并发控制</li><li>mysql为什么选中B+ TREE而不是B TREE？两种数据结构有什么区别？</li><li>mysql 范围查询？索引的数据结构是如何处理的？</li><li>mysql事务提交原理？</li><li>聚集索引 非聚集索引 查询效率？</li><li>mysql 乐观锁 悲观锁</li><li>数据库分库分表</li></ol><h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><ol><li>进程间通信方式有哪些？</li><li>有些信号你能捕获，有些信号你是捕获不了的，捕获不了的信号有哪些？</li><li>zookeeper 可以通过watch，用来做进程间通信，那么zk底层是使用什么方式来实现进程间通信的？依赖操作系统如何实现的？</li><li>socket通信</li><li>keepalive时间限制</li><li>tcp 如何处理粘包问题</li><li>http协议 如何区分header头还有body体</li><li>tcp 协议网络段 协议簇</li><li>一次完整的http请求</li><li>http code 302 304含义</li></ol><h1 id="线上"><a href="#线上" class="headerlink" title="线上"></a>线上</h1><ol><li>如何线上debug?比如线上的cpu爆了，这个步骤是？</li><li>线上fd耗光了，如何排查？</li><li>如何定位OOM 问题？</li></ol><h1 id="Kakfa"><a href="#Kakfa" class="headerlink" title="Kakfa"></a>Kakfa</h1><ol><li>kafka某个broker上是否可以有无限个topic?或者万级别的topic?</li><li>kafka 设计，还有broker上文件存储</li><li>kakfa是否支持顺序消费消息？</li><li>zk在kafka集群中的作用</li><li>kafka 消费时候可以批量拉取？</li><li>消息队列 选型 为什么选择kafka?</li><li>kafka增加. 删除节点时如何迁移数据？新的数据如何分配？</li><li>kafka写入消息 如何保证回滚或者保证不被消费</li><li>kafka 如何确保消息消费且只消费一次？</li></ol><h1 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h1><ol><li>在ElasticSearch中，集群(Cluster),节点(Node),分片(Shard),Indices(索引),replicas(备份)之间是什么关系？</li><li>elasticsearch整个建索引. 查询的过程</li><li>elasticsearch如何选举</li><li>ik 是如何进行分词的？</li><li>es Scroll 原理？ Search After原理？</li><li>es 副本作用？</li><li>mysql elasticsearch 查询对比？（比如整个搜索流程）</li></ol><h1 id="OpenTSDB"><a href="#OpenTSDB" class="headerlink" title="OpenTSDB"></a>OpenTSDB</h1><ol><li>OpenTSDB与HBase 关系</li></ol><h1 id="脑经急转弯"><a href="#脑经急转弯" class="headerlink" title="脑经急转弯"></a>脑经急转弯</h1><ol><li>判断一个整数是2的N次方？</li><li>二叉树拷贝（非递归）</li><li>BitMap算法（应用）</li></ol><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ol><li>分布式锁有哪些实现方式？</li><li>分布式事务</li><li>异地多活</li><li>zookeeper集群 当一个节点挂了一天，当再次启动的时候，如何识别哪个是leader？</li><li>有什么知名的开源apm(Application Performance Management)工具吗？</li><li>pinpoint 原理？</li><li>consul template作用？如何与prometheus交互的？</li></ol><h1 id="金融"><a href="#金融" class="headerlink" title="金融"></a>金融</h1><ol><li>同业拆借</li><li>信用卡消费一笔钱，是如何到收款人的账户的？（整个流转过程）</li><li>复式记账</li></ol><h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><ol><li>spring 注入 接口即如何注入一个接口的多个实现类？</li><li>spring 中用到的设计模式？spring中一次完整的http请求链路？</li></ol>]]></content>
      
      
      <categories>
          
          <category> Interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Spring AOP与IOC的个人思考</title>
      <link href="/spring-aop-ioc-think.html"/>
      <url>/spring-aop-ioc-think.html</url>
      
        <content type="html"><![CDATA[<p>在阅读本文前，强烈建议阅读：<br><a href="http://www.jiankunking.com/java-jdk-aop.html" target="_blank" rel="noopener">Java JDK 动态代理（AOP）使用及实现原理分析</a></p><a id="more"></a><p>AOP是Spring提供的关键特性之一。AOP即面向切面编程，是OOP编程的有效补充。使用AOP技术，可以将一些系统性相关的编程工作，独立提取出来，独立实现，然后通过切面切入进系统。从而避免了在业务逻辑的代码中混入很多的系统相关的逻辑——比如权限管理，事物管理，日志记录等等。这些系统性的编程工作都可以独立编码实现，然后通过AOP技术切入进系统即可。从而达到了将不同的关注点分离出来的效果。<br><img src="/images/spring-jdk-aop-think/AOP%E7%A4%BA%E6%84%8F.png" alt><br>本文深入剖析Spring的AOP的原理。</p><h1 id="一、AOP-的实现原理"><a href="#一、AOP-的实现原理" class="headerlink" title="一、AOP 的实现原理"></a>一、AOP 的实现原理</h1><p>AOP分为静态AOP和动态AOP。</p><p>静态AOP是指AspectJ实现的AOP，他是将切面代码直接编译到Java类文件中。</p><p>动态AOP是指将切面代码进行动态织入实现的AOP。</p><p>Spring的AOP为动态AOP，实现的技术为：JDK提供的动态代理技术 和 CGLIB(动态字节码增强技术)。尽管实现技术不一样，但都是基于代理模式，都是生成一个代理对象。</p><h2 id="1、JDK动态代理"><a href="#1、JDK动态代理" class="headerlink" title="1、JDK动态代理"></a>1、JDK动态代理</h2><p>JDK部分解析参考：<br><a href="https://www.jiankunking.com/java-jdk-aop.html" target="_blank" rel="noopener">Java JDK 动态代理（AOP）使用及实现原理分析</a></p><h2 id="2、CGLIB（code-generate-libary）"><a href="#2、CGLIB（code-generate-libary）" class="headerlink" title="2、CGLIB（code generate libary）"></a>2、CGLIB（code generate libary）</h2><p>字节码生成技术实现AOP，其实就是继承被代理对象，然后Override需要被代理的方法，在覆盖该方法时，自然是可以插入我们自己的代码的。</p><p><font color="DeepPink"><strong>因为需要Override被代理对象的方法，所以自然CGLIB技术实现AOP时，就必须要求需要被代理的方法不能是final方法，因为final方法不能被子类覆盖。</strong></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package net.aazj.aop;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line">import net.sf.cglib.proxy.Enhancer;</span><br><span class="line">import net.sf.cglib.proxy.MethodInterceptor;</span><br><span class="line">import net.sf.cglib.proxy.MethodProxy;</span><br><span class="line"></span><br><span class="line">public class CGProxy implements MethodInterceptor&#123;</span><br><span class="line">    private Object target;    // 被代理对象</span><br><span class="line">    public CGProxy(Object target)&#123;</span><br><span class="line">        this.target = target;</span><br><span class="line">    &#125;</span><br><span class="line">    public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;</span><br><span class="line">        System.out.println(&quot;do sth before....&quot;);</span><br><span class="line">        Object result = proxy.invokeSuper(obj, args);</span><br><span class="line">        System.out.println(&quot;do sth after....&quot;);</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line">    public Object getProxyObject() &#123;</span><br><span class="line">        Enhancer enhancer = new Enhancer();</span><br><span class="line">        // 设置父类</span><br><span class="line">        enhancer.setSuperclass(this.target.getClass());    </span><br><span class="line">        // 设置回调</span><br><span class="line">        enhancer.setCallback(this);    // 在调用父类方法时，回调 this.intercept()</span><br><span class="line">        // 创建代理对象</span><br><span class="line">        return enhancer.create();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public interface UserService &#123;</span><br><span class="line">    public void addUser(User user);</span><br><span class="line">    public User getUser(int id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class UserServiceImpl implements UserService &#123;</span><br><span class="line">    public void addUser(User user) &#123;</span><br><span class="line">        System.out.println(&quot;add user into database.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public User getUser(int id) &#123;</span><br><span class="line">        User user = new User();</span><br><span class="line">        user.setId(id);</span><br><span class="line">        System.out.println(&quot;getUser from database.&quot;);</span><br><span class="line">        return user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class CGProxyTest &#123;</span><br><span class="line">    public static void main(String[] args)&#123;</span><br><span class="line">         // 被代理的对象</span><br><span class="line">        Object proxyedObject = new UserServiceImpl();   </span><br><span class="line">        CGProxy cgProxy = new CGProxy(proxyedObject);</span><br><span class="line">        UserService proxyObject = (UserService) cgProxy.getProxyObject();</span><br><span class="line">        proxyObject.getUser(1);</span><br><span class="line">        proxyObject.addUser(new User());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">do sth before....</span><br><span class="line">getUser from database.</span><br><span class="line">do sth after....</span><br><span class="line">do sth before....</span><br><span class="line">add user into database.</span><br><span class="line">do sth after....</span><br></pre></td></tr></table></figure><p>它的原理是：生成一个父类<br>enhancer.setSuperclass(this.target.getClass())<br>的子类enhancer.create(),然后对父类的方法进行拦截enhancer.setCallback(this). </p><h1 id="二、思考"><a href="#二、思考" class="headerlink" title="二、思考"></a>二、思考</h1><p>从以上两种代理方式可以看出，<font color="DeepPink"><strong>实现AOP的关键是：动态代理，即将需要用的接口、类再包装一层，通过动态修改字节码文件实现各种拦截与通知。</strong></font></p><p><font color="DeepPink"><strong>注意，两者(JDK动态代理、CGLIB)都需要：要代理真实对象的实例。</strong></font></p><p>比如：在Spring MVC的Controller层一般@Autowired是Service接口，但带有@Service标识的却是实现Service接口的实体类，这样对于JDK动态代理来说已经足以生成代理类了(其实，不过是cglib还是jdk的动态代理，你直接@Autowired Service接口实现类，也是可以注入成功的，但不如注入Service接口灵活)，大家在跟踪代码的时候可以看一下Spring注入的bean真正的类型，你就可以发现它是代理生成的实例。 </p><p>比如这种： </p><p><img src="/images/spring-jdk-aop-think/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B.png" alt></p><p>带有注解标识的接口或者在Spring.XML中配置的bean会在Spring初始化的时候，被Spring通过反射加载实例化到Spring容器中。</p><blockquote><p>做过Client/Server架构开发的朋友应该知道，在Application运行过程中一般都会有一个应用上下文Context，一般将一些系统信息放在里面，比如一些登录信息、WCF连接实例等。这些信息在系统的任何地方都可以取到（其实就是一些顶级变量集合，生命周期最长的一些家伙）。</p></blockquote><blockquote><p>换个角度想一下，如果我们在Application初始化的时候，用反射（获取要代理对象的实例）和动态代理获取有注解标识或者在xml中配置bean的实例，并放到应用上下文Context中，在需要的地方都能取到，这不就是一个简单版的Spring 容器吗？</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> JDK </tag>
            
            <tag> Spring </tag>
            
            <tag> AOP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java HashMap</title>
      <link href="/java-hashmap.html"/>
      <url>/java-hashmap.html</url>
      
        <content type="html"><![CDATA[<blockquote><p> 代码基于 Jdk1.8</p></blockquote><a id="more"></a><p>最近在工作用到Map等一系列的集合，于是，想仔细看一下其具体实现。</p><h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;</span><br><span class="line">    implements Map&lt;K,V&gt;, Cloneable, Serializable</span><br></pre></td></tr></table></figure><h2 id="抽象类AbstractMap"><a href="#抽象类AbstractMap" class="headerlink" title="抽象类AbstractMap"></a>抽象类AbstractMap</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;</span><br></pre></td></tr></table></figure><p>该类实现了Map接口，具体结构如下：<br><img src="/images/java-hashmap/AbstractMap%E7%BB%93%E6%9E%84.png" alt><br>该类代码很简单，不再赘述。</p><h2 id="序列化接口：Serializable"><a href="#序列化接口：Serializable" class="headerlink" title="序列化接口：Serializable"></a>序列化接口：Serializable</h2><p>该接口没有什么好说的，但通过该接口，就解释了为什么HashMap总一些字段是用transient来修饰。</p><blockquote><p>一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p></blockquote><h1 id="阅读JDK中类注释"><a href="#阅读JDK中类注释" class="headerlink" title="阅读JDK中类注释"></a>阅读JDK中类注释</h1><h2 id="HashMap是无序的"><a href="#HashMap是无序的" class="headerlink" title="HashMap是无序的"></a>HashMap是无序的</h2><p>如果希望保持元素的输入顺序应该使用LinkedHashMap</p><h2 id="除了非同步和允许使用null之外，HashMap与Hashtable基本一致。"><a href="#除了非同步和允许使用null之外，HashMap与Hashtable基本一致。" class="headerlink" title="除了非同步和允许使用null之外，HashMap与Hashtable基本一致。"></a>除了非同步和允许使用null之外，HashMap与Hashtable基本一致。</h2><p>此处的非同步指的是多线程访问，并至少一个线程修改HashMap结构。结构修改包括任何新增、删除映射，但仅仅修改HashMap中已存在项值得操作不属于结构修改。</p><h2 id="初始容量与加载因子是影响HashMap的两个重要因素。"><a href="#初始容量与加载因子是影响HashMap的两个重要因素。" class="headerlink" title="初始容量与加载因子是影响HashMap的两个重要因素。"></a>初始容量与加载因子是影响HashMap的两个重要因素。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public HashMap(int initialCapacity, float loadFactor)</span><br></pre></td></tr></table></figure><p>初始容量默认值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The default initial capacity - MUST be a power of two.</span><br><span class="line"> */</span><br><span class="line">static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16</span><br></pre></td></tr></table></figure><p>加载因子默认值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The load factor used when none specified in constructor.</span><br><span class="line"> */</span><br><span class="line">static final float DEFAULT_LOAD_FACTOR = 0.75f;</span><br></pre></td></tr></table></figure><p>容量是HashMap在创建时“桶”的数量，而初始容量是哈希表在创建时分配的空间大小。加载因子是哈希表在其容量自动增加时能达到多满的衡量尺度（比如默认为0.75，即桶中数据达到3/4就不能再放数据了）。</p><blockquote><p>默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。<br>当重新调整HashMap大小的时候，会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。<br>所以 HashMap应该避免在多线程环境下使用。</p></blockquote><p>默认0.75这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。</p><h2 id="存储形式"><a href="#存储形式" class="headerlink" title="存储形式"></a>存储形式</h2><p>链表形式存储？树形结构？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* This map usually acts as a binned (bucketed) hash table, but</span><br><span class="line">* when bins get too large, they are transformed into bins of</span><br><span class="line">* TreeNodes, each structured similarly to those in</span><br><span class="line">* java.util.TreeMap. Most methods try to use normal bins, but</span><br><span class="line">* relay to TreeNode methods when applicable (simply by checking</span><br><span class="line">* instanceof a node).</span><br></pre></td></tr></table></figure><h1 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h1><h2 id="添加元素"><a href="#添加元素" class="headerlink" title="添加元素"></a>添加元素</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Associates the specified value with the specified key in this map.</span><br><span class="line">    * If the map previously contained a mapping for the key, the old</span><br><span class="line">    * value is replaced.</span><br><span class="line">    *</span><br><span class="line">    * @param key key with which the specified value is to be associated</span><br><span class="line">    * @param value value to be associated with the specified key</span><br><span class="line">    * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or</span><br><span class="line">    *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.</span><br><span class="line">    *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map</span><br><span class="line">    *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)</span><br><span class="line">    */</span><br><span class="line">   public V put(K key, V value) &#123;</span><br><span class="line">       return putVal(hash(key), key, value, false, true);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Implements Map.put and related methods</span><br><span class="line">    *</span><br><span class="line">    * @param hash hash for key</span><br><span class="line">    * @param key the key</span><br><span class="line">    * @param value the value to put</span><br><span class="line">    * @param onlyIfAbsent if true, don&apos;t change existing value</span><br><span class="line">    * @param evict if false, the table is in creation mode.</span><br><span class="line">    * @return previous value, or null if none</span><br><span class="line">    */</span><br><span class="line">   final V putVal(int hash, K key, V value, boolean onlyIfAbsent,</span><br><span class="line">                  boolean evict) &#123;</span><br><span class="line">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;</span><br><span class="line">       //hashmap第一次添加元素，调用resize()方法初始化table</span><br><span class="line">       if ((tab = table) == null || (n = tab.length) == 0)</span><br><span class="line">           n = (tab = resize()).length;</span><br><span class="line">       //通过与运算判断tab[hash]位置是否有值</span><br><span class="line">       //从newNode这里可以看出，hashmap中key value是以Node&lt;K,V&gt;实例的形式存放的</span><br><span class="line">       if ((p = tab[i = (n - 1) &amp; hash]) == null)</span><br><span class="line">           tab[i] = newNode(hash, key, value, null);</span><br><span class="line">       //tab[i]有元素，则需要遍历结点后再添加</span><br><span class="line">       else &#123;</span><br><span class="line">           Node&lt;K,V&gt; e; K k;</span><br><span class="line">           // hash、key均等，说明待插入元素和第一个元素相等，直接更新</span><br><span class="line">           if (p.hash == hash &amp;&amp;</span><br><span class="line">               ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">               e = p;</span><br><span class="line">           else if (p instanceof TreeNode)//如果p类型为TreeNode，调用树的添加元素方法(红黑树冲突插入)</span><br><span class="line">               e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span><br><span class="line">           else &#123;</span><br><span class="line">               //不是TreeNode,即为链表,遍历链表，查找给定关键字 </span><br><span class="line">               for (int binCount = 0; ; ++binCount) &#123;</span><br><span class="line">                   if ((e = p.next) == null) &#123;</span><br><span class="line">                   //到达链表的尾端也没有找到key值相同的节点，则生成一个新的Node</span><br><span class="line">                       p.next = newNode(hash, key, value, null);</span><br><span class="line">                       //创建新节点后若超出树形化阈值，则转换为树形存储  </span><br><span class="line">                       if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st</span><br><span class="line">                           treeifyBin(tab, hash);//当桶中链表的数量&gt;=9的时候，底层则改为红黑树实现</span><br><span class="line">                       break;</span><br><span class="line">                   &#125;</span><br><span class="line">                   //如果找到关键字相同的结点  </span><br><span class="line">                   if (e.hash == hash &amp;&amp;</span><br><span class="line">                       ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                       break;</span><br><span class="line">                   //更新p指向下一个节点</span><br><span class="line">                   p = e;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           // e不为空，即map中存在要添加的关键字  </span><br><span class="line">           if (e != null) &#123; // existing mapping for key</span><br><span class="line">               V oldValue = e.value;</span><br><span class="line">               if (!onlyIfAbsent || oldValue == null)</span><br><span class="line">                   e.value = value;</span><br><span class="line">               afterNodeAccess(e);</span><br><span class="line">               return oldValue;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       ++modCount;</span><br><span class="line">       if (++size &gt; threshold)</span><br><span class="line">           resize();//扩容</span><br><span class="line">       afterNodeInsertion(evict);</span><br><span class="line">       return null;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>小注：<br>1、回调</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">afterNodeAccess(e);</span><br><span class="line">afterNodeInsertion(evict);</span><br></pre></td></tr></table></figure><p>是为LinkedHashMap回调准备的。<br>2、计算hash值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Computes key.hashCode() and spreads (XORs) higher bits of hash</span><br><span class="line"> * to lower.  Because the table uses power-of-two masking, sets of</span><br><span class="line"> * hashes that vary only in bits above the current mask will</span><br><span class="line"> * always collide. (Among known examples are sets of Float keys</span><br><span class="line"> * holding consecutive whole numbers in small tables.)  So we</span><br><span class="line"> * apply a transform that spreads the impact of higher bits</span><br><span class="line"> * downward. There is a tradeoff between speed, utility, and</span><br><span class="line"> * quality of bit-spreading. Because many common sets of hashes</span><br><span class="line"> * are already reasonably distributed (so don&apos;t benefit from</span><br><span class="line"> * spreading), and because we use trees to handle large sets of</span><br><span class="line"> * collisions in bins, we just XOR some shifted bits in the</span><br><span class="line"> * cheapest possible way to reduce systematic lossage, as well as</span><br><span class="line"> * to incorporate impact of the highest bits that would otherwise</span><br><span class="line"> * never be used in index calculations because of table bounds.</span><br><span class="line"> */</span><br><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">int h;</span><br><span class="line">return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>‘&gt;&gt;&gt;’：无符号右移，忽略符号位，空位都以0补齐</p><blockquote><p>value &gt;&gt;&gt; num – num 指定要移位值value 移动的位数。</p></blockquote><p>即按二进制形式把所有的数字向右移动对应位数，低位移出（舍弃），高位的空位补零。对于正数来说和带符号右移相同，对于负数来说不同。</p><p>^异或：两个操作数的位中，相同则结果为0，不同则结果为1。</p><p>这也正好解释了为什么HashMap底层数组的长度总是 2 的 n 次方。因为这样（数组长度-1）正好相当于一个“低位掩码”。“异或”操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。<br>以初始长度16为例，16-1=15。<br>2进制表示是00000000 00000000 00001111。<br>和某hash值做“异或”操作如下，结果就是截取了最低的四位值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10100101 11000100 00100101</span><br><span class="line">00000000 00000000 00001111</span><br><span class="line">----------------------------------</span><br><span class="line">00000000 00000000 00000101    //高位全部归零，只保留末四位</span><br></pre></td></tr></table></figure><p>更详细的步骤如下： </p><p><img src="/images/java-hashmap/%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97.png" alt></p><p>3、存储结构 </p><p><img src="/images/java-hashmap/hashmap%E7%BB%93%E6%9E%84.png" alt><br><img src="/images/java-hashmap/table%E6%95%B0%E7%BB%84.png" alt></p><h2 id="获取元素"><a href="#获取元素" class="headerlink" title="获取元素"></a>获取元素</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns the value to which the specified key is mapped,</span><br><span class="line">    * or &#123;@code null&#125; if this map contains no mapping for the key.</span><br><span class="line">    *</span><br><span class="line">    * &lt;p&gt;More formally, if this map contains a mapping from a key</span><br><span class="line">    * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null :</span><br><span class="line">    * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise</span><br><span class="line">    * it returns &#123;@code null&#125;.  (There can be at most one such mapping.)</span><br><span class="line">    *</span><br><span class="line">    * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt;</span><br><span class="line">    * indicate that the map contains no mapping for the key; it&apos;s also</span><br><span class="line">    * possible that the map explicitly maps the key to &#123;@code null&#125;.</span><br><span class="line">    * The &#123;@link #containsKey containsKey&#125; operation may be used to</span><br><span class="line">    * distinguish these two cases.</span><br><span class="line">    *</span><br><span class="line">    * @see #put(Object, Object)</span><br><span class="line">    */</span><br><span class="line">   public V get(Object key) &#123;</span><br><span class="line">       Node&lt;K,V&gt; e;</span><br><span class="line">       return (e = getNode(hash(key), key)) == null ? null : e.value;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Implements Map.get and related methods</span><br><span class="line">    *</span><br><span class="line">    * @param hash hash for key</span><br><span class="line">    * @param key the key</span><br><span class="line">    * @return the node, or null if none</span><br><span class="line">    */</span><br><span class="line">   final Node&lt;K,V&gt; getNode(int hash, Object key) &#123;</span><br><span class="line">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;</span><br><span class="line">       if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">           //hash &amp; length-1 定位数组下标</span><br><span class="line">           (first = tab[(n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">           if (first.hash == hash &amp;&amp; // always check first node</span><br><span class="line">               ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">               return first;</span><br><span class="line">           if ((e = first.next) != null) &#123;</span><br><span class="line">               //第一个节点是TreeNode,则采用位桶+红黑树结构， </span><br><span class="line">               //调用TreeNode.getTreeNode(hash,key), </span><br><span class="line">               //遍历红黑树，得到节点的value  </span><br><span class="line">               if (first instanceof TreeNode)</span><br><span class="line">                   return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">               do &#123;</span><br><span class="line">                   if (e.hash == hash &amp;&amp;</span><br><span class="line">                       ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                       return e;</span><br><span class="line">               &#125; while ((e = e.next) != null);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       return null;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>树节点的查找：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Calls find for root node.</span><br><span class="line"> */</span><br><span class="line">final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123;</span><br><span class="line">    return ((parent != null) ? root() : this).find(h, k, null);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Finds the node starting at root p with the given hash and key.</span><br><span class="line"> * The kc argument caches comparableClassFor(key) upon first use</span><br><span class="line"> * comparing keys.</span><br><span class="line"> *通过hash值的比较，递归的去遍历红黑树，</span><br><span class="line"> compareableClassFor(Class k)：判断实例k对应的类是否实现了Comparable接口，如果实现了该接口并</span><br><span class="line"> 在某些时候如果红黑树节点的元素are of the same &quot;class C implements Comparable&lt;C&gt;&quot; type  </span><br><span class="line"> *利用他们的compareTo()方法来比较大小，这里需要通过反射机制来check他们到底是不是属于同一个类,是不是具有可比较性.</span><br><span class="line"> */</span><br><span class="line">final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123;</span><br><span class="line">    TreeNode&lt;K,V&gt; p = this;</span><br><span class="line">    do &#123;</span><br><span class="line">        int ph, dir; K pk;</span><br><span class="line">        TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q;</span><br><span class="line">        if ((ph = p.hash) &gt; h)</span><br><span class="line">            p = pl;</span><br><span class="line">        else if (ph &lt; h)</span><br><span class="line">            p = pr;</span><br><span class="line">        else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))</span><br><span class="line">            return p;</span><br><span class="line">        else if (pl == null)</span><br><span class="line">            p = pr;</span><br><span class="line">        else if (pr == null)</span><br><span class="line">            p = pl;</span><br><span class="line">        else if ((kc != null ||</span><br><span class="line">                  (kc = comparableClassFor(k)) != null) &amp;&amp;</span><br><span class="line">                 (dir = compareComparables(kc, k, pk)) != 0)</span><br><span class="line">            p = (dir &lt; 0) ? pl : pr;</span><br><span class="line">        else if ((q = pr.find(h, k, kc)) != null)</span><br><span class="line">            return q;</span><br><span class="line">        else</span><br><span class="line">            p = pl;</span><br><span class="line">    &#125; while (p != null);</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="元素包含containsKey"><a href="#元素包含containsKey" class="headerlink" title="元素包含containsKey"></a>元素包含containsKey</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the</span><br><span class="line"> * specified key.</span><br><span class="line"> *</span><br><span class="line"> * @param   key   The key whose presence in this map is to be tested</span><br><span class="line"> * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified</span><br><span class="line"> * key.</span><br><span class="line"> */</span><br><span class="line">public boolean containsKey(Object key) &#123;</span><br><span class="line">    return getNode(hash(key), key) != null;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Implements Map.get and related methods</span><br><span class="line"> *</span><br><span class="line"> * @param hash hash for key</span><br><span class="line"> * @param key the key</span><br><span class="line"> * @return the node, or null if none</span><br><span class="line"> */</span><br><span class="line">final Node&lt;K,V&gt; getNode(int hash, Object key) &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;</span><br><span class="line">    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">        //判断tab[hash]位置是否有值</span><br><span class="line">        (first = tab[(n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">        if (first.hash == hash &amp;&amp; // always check first node</span><br><span class="line">            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">            return first;</span><br><span class="line">        if ((e = first.next) != null) &#123;</span><br><span class="line">            if (first instanceof TreeNode)</span><br><span class="line">                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">            //遍历寻找 </span><br><span class="line">            do &#123;</span><br><span class="line">                if (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                    return e;</span><br><span class="line">            &#125; while ((e = e.next) != null);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br><span class="line"> /**</span><br><span class="line">  * Calls find for root node.</span><br><span class="line">  */</span><br><span class="line">  final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123;</span><br><span class="line">      return ((parent != null) ? root() : this).find(h, k, null);</span><br><span class="line">   &#125;</span><br><span class="line"> /**</span><br><span class="line">     * Returns root of tree containing this node.</span><br><span class="line">     * 获取红黑树的根</span><br><span class="line">     */</span><br><span class="line">    final TreeNode&lt;K,V&gt; root() &#123;</span><br><span class="line">        for (TreeNode&lt;K,V&gt; r = this, p;;) &#123;</span><br><span class="line">            if ((p = r.parent) == null)</span><br><span class="line">                return r;</span><br><span class="line">            r = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">/**</span><br><span class="line">     * Finds the node starting at root p with the given hash and key.</span><br><span class="line">     * The kc argument caches comparableClassFor(key) upon first use</span><br><span class="line">     * comparing keys.</span><br><span class="line">     */</span><br><span class="line">    final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123;// k即key，kc为null</span><br><span class="line">        TreeNode&lt;K,V&gt; p = this;</span><br><span class="line">        do &#123;</span><br><span class="line">            int ph, dir; K pk;</span><br><span class="line">            TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q;</span><br><span class="line">            if ((ph = p.hash) &gt; h)// ph存当前节点hash</span><br><span class="line">                p = pl;</span><br><span class="line">            else if (ph &lt; h) // 所查hash比当前节点hash大</span><br><span class="line">                p = pr;// 查右子树</span><br><span class="line">            else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))</span><br><span class="line">                return p;// hash、key均相同，【找到了！】返回当前节点</span><br><span class="line">            else if (pl == null)// hash等，key不等，且当前节点的左节点null</span><br><span class="line">                p = pr;//查右子树</span><br><span class="line">            else if (pr == null)</span><br><span class="line">                p = pl;</span><br><span class="line">           //get-&gt;getTreeNode传递的kc为null。||逻辑或,短路运算,有真即可</span><br><span class="line">           // false || (false &amp;&amp; ？？)</span><br><span class="line">            else if ((kc != null ||</span><br><span class="line">                      (kc = comparableClassFor(k)) != null) &amp;&amp;</span><br><span class="line">                     (dir = compareComparables(kc, k, pk)) != 0)</span><br><span class="line">                p = (dir &lt; 0) ? pl : pr;</span><br><span class="line">            else if ((q = pr.find(h, k, kc)) != null)</span><br><span class="line">                return q;</span><br><span class="line">            else</span><br><span class="line">                p = pl;</span><br><span class="line">        &#125; while (p != null);</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="移除remove"><a href="#移除remove" class="headerlink" title="移除remove"></a>移除remove</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Removes the mapping for the specified key from this map if present.</span><br><span class="line">   *</span><br><span class="line">   * @param  key key whose mapping is to be removed from the map</span><br><span class="line">   * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or</span><br><span class="line">   *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.</span><br><span class="line">   *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map</span><br><span class="line">   *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)</span><br><span class="line">   */</span><br><span class="line">  public V remove(Object key) &#123;</span><br><span class="line">      Node&lt;K,V&gt; e;</span><br><span class="line">      return (e = removeNode(hash(key), key, null, false, true)) == null ?</span><br><span class="line">          null : e.value;</span><br><span class="line">  &#125;</span><br><span class="line">   /**</span><br><span class="line">   * Implements Map.remove and related methods</span><br><span class="line">   *</span><br><span class="line">   * @param hash hash for key</span><br><span class="line">   * @param key the key</span><br><span class="line">   * @param value the value to match if matchValue, else ignored</span><br><span class="line">   * @param matchValue if true only remove if value is equal</span><br><span class="line">   * @param movable if false do not move other nodes while removing</span><br><span class="line">   * @return the node, or null if none</span><br><span class="line">   */</span><br><span class="line">  final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,</span><br><span class="line">                             boolean matchValue, boolean movable) &#123;</span><br><span class="line">      Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index;</span><br><span class="line">      if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">          (p = tab[index = (n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">          Node&lt;K,V&gt; node = null, e; K k; V v;</span><br><span class="line">          if (p.hash == hash &amp;&amp;</span><br><span class="line">          //先比较内存地址，如果地址不一致，再调用equals进行比较</span><br><span class="line">              ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">              node = p;</span><br><span class="line">          else if ((e = p.next) != null) &#123;</span><br><span class="line">              //如果是以红黑树处理冲突，则通过getTreeNode查找</span><br><span class="line">              if (p instanceof TreeNode)</span><br><span class="line">                  node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">              else &#123;</span><br><span class="line">                   //如果是以链式的方式处理冲突，则通过遍历链表来寻找节点</span><br><span class="line">                  do &#123;</span><br><span class="line">                      if (e.hash == hash &amp;&amp;</span><br><span class="line">                          ((k = e.key) == key ||</span><br><span class="line">                           (key != null &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                          node = e;</span><br><span class="line">                          break;</span><br><span class="line">                      &#125;</span><br><span class="line">                      p = e;</span><br><span class="line">                  &#125; while ((e = e.next) != null);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">           //比对找到的key的value跟要删除的是否匹配</span><br><span class="line">          if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                               (value != null &amp;&amp; value.equals(v)))) &#123;</span><br><span class="line">              if (node instanceof TreeNode)</span><br><span class="line">                  ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);</span><br><span class="line">              else if (node == p)</span><br><span class="line">                  tab[index] = node.next;</span><br><span class="line">              else</span><br><span class="line">                  p.next = node.next;</span><br><span class="line">              //已从结构上修改 此列表的次数</span><br><span class="line">              ++modCount;</span><br><span class="line">              --size;</span><br><span class="line">              //回调</span><br><span class="line">              afterNodeRemoval(node);</span><br><span class="line">              return node;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      return null;</span><br><span class="line">  &#125;</span><br><span class="line">      /**</span><br><span class="line">       * Removes the given node, that must be present before this call.</span><br><span class="line">       * This is messier than typical red-black deletion code because we</span><br><span class="line">       * cannot swap the contents of an interior node with a leaf</span><br><span class="line">       * successor that is pinned by &quot;next&quot; pointers that are accessible</span><br><span class="line">       * independently during traversal. So instead we swap the tree</span><br><span class="line">       * linkages. If the current tree appears to have too few nodes,</span><br><span class="line">       * the bin is converted back to a plain bin. (The test triggers</span><br><span class="line">       * somewhere between 2 and 6 nodes, depending on tree structure).</span><br><span class="line">       */</span><br><span class="line">      final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,</span><br><span class="line">                                boolean movable) &#123;</span><br><span class="line">          int n;</span><br><span class="line">          if (tab == null || (n = tab.length) == 0)</span><br><span class="line">              return;</span><br><span class="line">          int index = (n - 1) &amp; hash;</span><br><span class="line">          TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl;</span><br><span class="line">          TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev;</span><br><span class="line">          if (pred == null)</span><br><span class="line">              tab[index] = first = succ;</span><br><span class="line">          else</span><br><span class="line">              pred.next = succ;</span><br><span class="line">          if (succ != null)</span><br><span class="line">              succ.prev = pred;</span><br><span class="line">          if (first == null)</span><br><span class="line">              return;</span><br><span class="line">          if (root.parent != null)</span><br><span class="line">              root = root.root();</span><br><span class="line">          if (root == null || root.right == null ||</span><br><span class="line">              (rl = root.left) == null || rl.left == null) &#123;</span><br><span class="line">              tab[index] = first.untreeify(map);  // too small</span><br><span class="line">              return;</span><br><span class="line">          &#125;</span><br><span class="line">          TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement;</span><br><span class="line">          if (pl != null &amp;&amp; pr != null) &#123;</span><br><span class="line">              TreeNode&lt;K,V&gt; s = pr, sl;</span><br><span class="line">              while ((sl = s.left) != null) // find successor</span><br><span class="line">                  s = sl;</span><br><span class="line">              boolean c = s.red; s.red = p.red; p.red = c; // swap colors</span><br><span class="line">              TreeNode&lt;K,V&gt; sr = s.right;</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = p.parent;</span><br><span class="line">              if (s == pr) &#123; // p was s&apos;s direct parent</span><br><span class="line">                  p.parent = s;</span><br><span class="line">                  s.right = p;</span><br><span class="line">              &#125;</span><br><span class="line">              else &#123;</span><br><span class="line">                  TreeNode&lt;K,V&gt; sp = s.parent;</span><br><span class="line">                  if ((p.parent = sp) != null) &#123;</span><br><span class="line">                      if (s == sp.left)</span><br><span class="line">                          sp.left = p;</span><br><span class="line">                      else</span><br><span class="line">                          sp.right = p;</span><br><span class="line">                  &#125;</span><br><span class="line">                  if ((s.right = pr) != null)</span><br><span class="line">                      pr.parent = s;</span><br><span class="line">              &#125;</span><br><span class="line">              p.left = null;</span><br><span class="line">              if ((p.right = sr) != null)</span><br><span class="line">                  sr.parent = p;</span><br><span class="line">              if ((s.left = pl) != null)</span><br><span class="line">                  pl.parent = s;</span><br><span class="line">              if ((s.parent = pp) == null)</span><br><span class="line">                  root = s;</span><br><span class="line">              else if (p == pp.left)</span><br><span class="line">                  pp.left = s;</span><br><span class="line">              else</span><br><span class="line">                  pp.right = s;</span><br><span class="line">              if (sr != null)</span><br><span class="line">                  replacement = sr;</span><br><span class="line">              else</span><br><span class="line">                  replacement = p;</span><br><span class="line">          &#125;</span><br><span class="line">          else if (pl != null)</span><br><span class="line">              replacement = pl;</span><br><span class="line">          else if (pr != null)</span><br><span class="line">              replacement = pr;</span><br><span class="line">          else</span><br><span class="line">              replacement = p;</span><br><span class="line">          if (replacement != p) &#123;</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent;</span><br><span class="line">              if (pp == null)</span><br><span class="line">                  root = replacement;</span><br><span class="line">              else if (p == pp.left)</span><br><span class="line">                  pp.left = replacement;</span><br><span class="line">              else</span><br><span class="line">                  pp.right = replacement;</span><br><span class="line">              p.left = p.right = p.parent = null;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement);</span><br><span class="line"></span><br><span class="line">          if (replacement == p) &#123;  // detach</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = p.parent;</span><br><span class="line">              p.parent = null;</span><br><span class="line">              if (pp != null) &#123;</span><br><span class="line">                  if (p == pp.left)</span><br><span class="line">                      pp.left = null;</span><br><span class="line">                  else if (p == pp.right)</span><br><span class="line">                      pp.right = null;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          if (movable)</span><br><span class="line">              moveRootToFront(tab, r);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在创建 HashMap 时根据实际需要适当地调整 load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，程序员无需改变负载因子的值。</p><p>如果开始就知道 HashMap 会保存多个 key-value 对，可以在创建时就使用较大的初始化容量，如果 HashMap 中 Entry 的数量一直不会超过极限容量（capacity * load factor），HashMap 就无需调用 resize() 方法重新分配 table 数组，从而保证较好的性能。当然，开始就将初始容量设置太高可能会浪费空间（系统需要创建一个长度为 capacity 的 Entry 数组），因此创建 HashMap 时初始化容量设置也需要小心对待。</p><p>HashMap高性能需要以下几点： </p><ul><li>高效的hash算法 </li><li>保证hash值到内存地址（数组索引）的映射速度 </li><li>根据内存地址（数组索引）可以直接得到相应的值</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-JDK-动态代理（AOP）使用及实现原理分析</title>
      <link href="/java-jdk-aop.html"/>
      <url>/java-jdk-aop.html</url>
      
        <content type="html"><![CDATA[<h1 id="一、什么是代理？"><a href="#一、什么是代理？" class="headerlink" title="一、什么是代理？"></a>一、什么是代理？</h1><p>代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。</p><p>代理模式UML图：</p><p><img src="/images/spring-jdk-aop/UML.png" alt><br>简单结构示意图：</p><p><img src="/images/spring-jdk-aop/%E7%AE%80%E5%8D%95%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt><br>为了保持行为的一致性，代理类和委托类通常会实现相同的接口，所以在访问者看来两者没有丝毫的区别。通过代理类这中间一层，能有效控制对委托类对象的直接访问，也可以很好地隐藏和保护委托类对象，同时也为实施不同控制策略预留了空间，从而在设计上获得了更大的灵活性。Java 动态代理机制以巧妙的方式近乎完美地实践了代理模式的设计理念。</p><h1 id="二、Java-动态代理类"><a href="#二、Java-动态代理类" class="headerlink" title="二、Java 动态代理类"></a>二、Java 动态代理类</h1><p>Java动态代理类位于java.lang.reflect包下，一般主要涉及到以下两个类：</p><p>(1)Interface InvocationHandler：该接口中仅定义了一个方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public object invoke(Object obj,Method method, Object[] args)</span><br></pre></td></tr></table></figure><p>在实际使用时，<font color="DeepPink"><strong>第一个参数obj一般是指代理类，method是被代理的方法，如上例中的request()，args为该方法的参数数组。</strong></font>这个抽象方法在代理类中动态实现。</p><p>(2)Proxy：该类即为动态代理类，其中主要包含以下内容：</p><p>protected Proxy(InvocationHandler h)：构造函数，用于给内部的h赋值。</p><p>static Class getProxyClass(</p><p>ClassLoader loader,</p><p>Class[] interfaces)：获得一个代理类，其中loader是类装载器，interfaces是真实类所拥有的全部接口的数组。</p><p>static Object newProxyInstance(ClassLoaderloader, Class[] interfaces,InvocationHandler h)：返回代理类的一个实例，返回后的代理类可以当作被代理类使用(可使用被代理类的在Subject接口中声明过的方法)</p><p>所谓DynamicProxy是这样一种class：<font color="DeepPink"><strong>它是在运行时生成的class，在生成它时你必须提供一组interface给它，然后该class就宣称它实现了这些interface。</strong></font>你当然可以把该class的实例当作这些interface中的任何一个来用。当然，这个DynamicProxy其实就是一个Proxy，它不会替你作实质性的工作，<font color="DeepPink"><strong>在生成它的实例时你必须提供一个handler，由它接管实际的工作。</strong></font></p><p>在使用动态代理类时，我们必须实现InvocationHandler接口</p><p>通过这种方式，被代理的对象(RealSubject)可以在运行时动态改变，需要控制的接口(Subject接口)可以在运行时改变，控制的方式(DynamicSubject类)也可以动态改变，从而实现了非常灵活的动态代理关系。</p><p>动态代理步骤：</p><ol><li><p>创建一个实现接口InvocationHandler的类，它必须实现invoke方法</p></li><li><p>创建被代理的类以及接口</p></li><li><p>通过Proxy的静态方法</p></li></ol><p>newProxyInstance(ClassLoaderloader,Class[]interfaces,InvocationHandler h)创建一个代理</p><ol start="4"><li>通过代理调用方法</li></ol><h1 id="三、JDK的动态代理怎么使用？"><a href="#三、JDK的动态代理怎么使用？" class="headerlink" title="三、JDK的动态代理怎么使用？"></a>三、JDK的动态代理怎么使用？</h1><p>1、需要动态代理的接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 需要动态代理的接口</span><br><span class="line"> */</span><br><span class="line">public interface Subject &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 你好</span><br><span class="line">     *</span><br><span class="line">     * @param name</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public String SayHello(String name);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 再见</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public String SayGoodBye();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、需要代理的实际对象</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 实际对象</span><br><span class="line"> */</span><br><span class="line">public class RealSubject implements Subject &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 你好</span><br><span class="line">     *</span><br><span class="line">     * @param name</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public String SayHello(String name) &#123;</span><br><span class="line">        return &quot;hello &quot; + name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 再见</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public String SayGoodBye() &#123;</span><br><span class="line">        return &quot; good bye &quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、调用处理器实现类（有木有感觉这里就是传说中的AOP啊）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 调用处理器实现类</span><br><span class="line"> * 每次生成动态代理类对象时都需要指定一个实现了该接口的调用处理器对象</span><br><span class="line"> */</span><br><span class="line">public class InvocationHandlerImpl implements InvocationHandler &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 这个就是我们要代理的真实对象</span><br><span class="line">     */</span><br><span class="line">    private Object subject;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 构造方法，给我们要代理的真实对象赋初值</span><br><span class="line">     *</span><br><span class="line">     * @param subject</span><br><span class="line">     */</span><br><span class="line">    public InvocationHandlerImpl(Object subject) &#123;</span><br><span class="line">        this.subject = subject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 该方法负责集中处理动态代理类上的所有方法调用。</span><br><span class="line">     * 调用处理器根据这三个参数进行预处理或分派到委托类实例上反射执行</span><br><span class="line">     *</span><br><span class="line">     * @param proxy  代理类实例</span><br><span class="line">     * @param method 被调用的方法对象</span><br><span class="line">     * @param args   调用参数</span><br><span class="line">     * @return</span><br><span class="line">     * @throws Throwable</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class="line">        //在代理真实对象前我们可以添加一些自己的操作</span><br><span class="line">        System.out.println(&quot;在调用之前，我要干点啥呢？&quot;);</span><br><span class="line">        System.out.println(&quot;Method:&quot; + method);</span><br><span class="line">        //当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用</span><br><span class="line">        Object returnValue = method.invoke(subject, args);</span><br><span class="line">        //在代理真实对象后我们也可以添加一些自己的操作</span><br><span class="line">        System.out.println(&quot;在调用之后，我要干点啥呢？&quot;);</span><br><span class="line">        return returnValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 动态代理演示</span><br><span class="line"> */</span><br><span class="line">public class DynamicProxyDemonstration &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //代理的真实对象</span><br><span class="line">        Subject realSubject = new RealSubject();</span><br><span class="line">        /**</span><br><span class="line">         * InvocationHandlerImpl 实现了 InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发</span><br><span class="line">         * 其内部通常包含指向委托类实例的引用，用于真正执行分派转发过来的方法调用.</span><br><span class="line">         * 即：要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法</span><br><span class="line">         */</span><br><span class="line">        InvocationHandler handler = new InvocationHandlerImpl(realSubject);</span><br><span class="line"></span><br><span class="line">        ClassLoader loader = handler.getClass().getClassLoader();</span><br><span class="line">        Class&lt;?&gt;[] interfaces = realSubject.getClass().getInterfaces();</span><br><span class="line">        /**</span><br><span class="line">         * 该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例</span><br><span class="line">         */</span><br><span class="line">        Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;动态代理对象的类型：&quot; + subject.getClass().getName());</span><br><span class="line"></span><br><span class="line">        String hello = subject.SayHello(&quot;jiankunking&quot;);</span><br><span class="line">        System.out.println(hello);</span><br><span class="line">//        String goodbye = subject.SayGoodBye();</span><br><span class="line">//        System.out.println(goodbye);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5、输出结果如下：</p><p><img src="/images/spring-jdk-aop/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%BC%94%E7%A4%BA%E8%BE%93%E5%87%BA.png" alt></p><h1 id="四、动态代理怎么实现的？"><a href="#四、动态代理怎么实现的？" class="headerlink" title="四、动态代理怎么实现的？"></a>四、动态代理怎么实现的？</h1><p>从使用代码中可以看出，关键点在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br></pre></td></tr></table></figure><p>通过跟踪提示代码可以看出：<font color="DeepPink"><strong>当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用。</strong></font></p><p>也就是说，当代码执行到：subject.SayHello(“jiankunking”)这句话时，会自动调用InvocationHandlerImpl的invoke方法。这是为啥呢？</p><blockquote><p>下面是代码跟分析的过程，不想看的朋友可以直接看结论</p></blockquote><p>以下代码来自:JDK1.8.0_92</p><p>既然生成代理对象是用的Proxy类的静态方newProxyInstance，那么我们就去它的源码里看一下它到底都做了些什么？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Returns an instance of a proxy class for the specified interfaces</span><br><span class="line"> * that dispatches method invocations to the specified invocation</span><br><span class="line"> * handler.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;&#123;@code Proxy.newProxyInstance&#125; throws</span><br><span class="line"> * &#123;@code IllegalArgumentException&#125; for the same reasons that</span><br><span class="line"> * &#123;@code Proxy.getProxyClass&#125; does.</span><br><span class="line"> *</span><br><span class="line"> * @param   loader the class loader to define the proxy class</span><br><span class="line"> * @param   interfaces the list of interfaces for the proxy class</span><br><span class="line"> *          to implement</span><br><span class="line"> * @param   h the invocation handler to dispatch method invocations to</span><br><span class="line"> * @return  a proxy instance with the specified invocation handler of a</span><br><span class="line"> *          proxy class that is defined by the specified class loader</span><br><span class="line"> *          and that implements the specified interfaces</span><br><span class="line"> * @throws  IllegalArgumentException if any of the restrictions on the</span><br><span class="line"> *          parameters that may be passed to &#123;@code getProxyClass&#125;</span><br><span class="line"> *          are violated</span><br><span class="line"> * @throws  SecurityException if a security manager, &lt;em&gt;s&lt;/em&gt;, is present</span><br><span class="line"> *          and any of the following conditions is met:</span><br><span class="line"> *          &lt;ul&gt;</span><br><span class="line"> *          &lt;li&gt; the given &#123;@code loader&#125; is &#123;@code null&#125; and</span><br><span class="line"> *               the caller&apos;s class loader is not &#123;@code null&#125; and the</span><br><span class="line"> *               invocation of &#123;@link SecurityManager#checkPermission</span><br><span class="line"> *               s.checkPermission&#125; with</span><br><span class="line"> *               &#123;@code RuntimePermission(&quot;getClassLoader&quot;)&#125; permission</span><br><span class="line"> *               denies access;&lt;/li&gt;</span><br><span class="line"> *          &lt;li&gt; for each proxy interface, &#123;@code intf&#125;,</span><br><span class="line"> *               the caller&apos;s class loader is not the same as or an</span><br><span class="line"> *               ancestor of the class loader for &#123;@code intf&#125; and</span><br><span class="line"> *               invocation of &#123;@link SecurityManager#checkPackageAccess</span><br><span class="line"> *               s.checkPackageAccess()&#125; denies access to &#123;@code intf&#125;;&lt;/li&gt;</span><br><span class="line"> *          &lt;li&gt; any of the given proxy interfaces is non-public and the</span><br><span class="line"> *               caller class is not in the same &#123;@linkplain Package runtime package&#125;</span><br><span class="line"> *               as the non-public interface and the invocation of</span><br><span class="line"> *               &#123;@link SecurityManager#checkPermission s.checkPermission&#125; with</span><br><span class="line"> *               &#123;@code ReflectPermission(&quot;newProxyInPackage.&#123;package name&#125;&quot;)&#125;</span><br><span class="line"> *               permission denies access.&lt;/li&gt;</span><br><span class="line"> *          &lt;/ul&gt;</span><br><span class="line"> * @throws  NullPointerException if the &#123;@code interfaces&#125; array</span><br><span class="line"> *          argument or any of its elements are &#123;@code null&#125;, or</span><br><span class="line"> *          if the invocation handler, &#123;@code h&#125;, is</span><br><span class="line"> *          &#123;@code null&#125;</span><br><span class="line"> */</span><br><span class="line">@CallerSensitive </span><br><span class="line">public static Object newProxyInstance(ClassLoader loader,</span><br><span class="line">                                          Class&lt;?&gt;[] interfaces,</span><br><span class="line">                                          InvocationHandler h) throws IllegalArgumentException &#123;</span><br><span class="line">        //检查h 不为空，否则抛异常</span><br><span class="line">        Objects.requireNonNull(h);</span><br><span class="line"> </span><br><span class="line">        final Class&lt;?&gt;[] intfs = interfaces.clone();</span><br><span class="line">        final SecurityManager sm = System.getSecurityManager();</span><br><span class="line">        if (sm != null) &#123;</span><br><span class="line">            checkProxyAccess(Reflection.getCallerClass(), loader, intfs);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * 获得与指定类装载器和一组接口相关的代理类类型对象</span><br><span class="line">         */</span><br><span class="line">        Class&lt;?&gt; cl = getProxyClass0(loader, intfs);</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * 通过反射获取构造函数对象并生成代理类实例</span><br><span class="line">         */</span><br><span class="line">        try &#123;</span><br><span class="line">            if (sm != null) &#123;</span><br><span class="line">                checkNewProxyPermission(Reflection.getCallerClass(), cl);</span><br><span class="line">            &#125;</span><br><span class="line">            //获取代理对象的构造方法（也就是$Proxy0(InvocationHandler h)） </span><br><span class="line">            final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);</span><br><span class="line">            final InvocationHandler ih = h;</span><br><span class="line">            if (!Modifier.isPublic(cl.getModifiers())) &#123;</span><br><span class="line">                AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;</span><br><span class="line">                    public Void run() &#123;</span><br><span class="line">                        cons.setAccessible(true);</span><br><span class="line">                        return null;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            //生成代理类的实例并把InvocationHandlerImpl的实例传给它的构造方法</span><br><span class="line">            return cons.newInstance(new Object[]&#123;h&#125;);</span><br><span class="line">        &#125; catch (IllegalAccessException|InstantiationException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125; catch (InvocationTargetException e) &#123;</span><br><span class="line">            Throwable t = e.getCause();</span><br><span class="line">            if (t instanceof RuntimeException) &#123;</span><br><span class="line">                throw (RuntimeException) t;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                throw new InternalError(t.toString(), t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (NoSuchMethodException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>我们再进去getProxyClass0方法看一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Generate a proxy class.  Must call the checkProxyAccess method</span><br><span class="line"> * to perform permission checks before calling this.</span><br><span class="line"> */</span><br><span class="line">private static Class&lt;?&gt; getProxyClass0(ClassLoader loader,</span><br><span class="line">                                       Class&lt;?&gt;... interfaces) &#123;</span><br><span class="line">    if (interfaces.length &gt; 65535) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;interface limit exceeded&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    // If the proxy class defined by the given loader implementing</span><br><span class="line">    // the given interfaces exists, this will simply return the cached copy;</span><br><span class="line">    // otherwise, it will create the proxy class via the ProxyClassFactory</span><br><span class="line">    return proxyClassCache.get(loader, interfaces);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>真相还是没有来到，继续，看一下 proxyClassCache</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * a cache of proxy classes</span><br><span class="line"> */</span><br><span class="line">private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());</span><br></pre></td></tr></table></figure><p>奥，原来用了一下缓存啊</p><p>那么它对应的get方法啥样呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Look-up the value through the cache. This always evaluates the</span><br><span class="line"> * &#123;@code subKeyFactory&#125; function and optionally evaluates</span><br><span class="line"> * &#123;@code valueFactory&#125; function if there is no entry in the cache for given</span><br><span class="line"> * pair of (key, subKey) or the entry has already been cleared.</span><br><span class="line"> *</span><br><span class="line"> * @param key       possibly null key</span><br><span class="line"> * @param parameter parameter used together with key to create sub-key and</span><br><span class="line"> *                  value (should not be null)</span><br><span class="line"> * @return the cached value (never null)</span><br><span class="line"> * @throws NullPointerException if &#123;@code parameter&#125; passed in or</span><br><span class="line"> *                              &#123;@code sub-key&#125; calculated by</span><br><span class="line"> *                              &#123;@code subKeyFactory&#125; or &#123;@code value&#125;</span><br><span class="line"> *                              calculated by &#123;@code valueFactory&#125; is null.</span><br><span class="line"> */</span><br><span class="line">public V get(K key, P parameter) &#123;</span><br><span class="line">    Objects.requireNonNull(parameter);</span><br><span class="line">    expungeStaleEntries();</span><br><span class="line">    Object cacheKey = CacheKey.valueOf(key, refQueue);</span><br><span class="line">    // lazily install the 2nd level valuesMap for the particular cacheKey</span><br><span class="line">    ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey);</span><br><span class="line">    if (valuesMap == null) &#123;</span><br><span class="line">       //putIfAbsent这个方法在key不存在的时候加入一个值,如果key存在就不放入</span><br><span class="line">        ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey,valuesMap = new ConcurrentHashMap&lt;&gt;());</span><br><span class="line">        if (oldValuesMap != null) &#123;</span><br><span class="line">            valuesMap = oldValuesMap;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that</span><br><span class="line">    // subKey from valuesMap</span><br><span class="line">    Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));</span><br><span class="line">    Supplier&lt;V&gt; supplier = valuesMap.get(subKey);</span><br><span class="line">    Factory factory = null;</span><br><span class="line"> </span><br><span class="line">    while (true) &#123;</span><br><span class="line">        if (supplier != null) &#123;</span><br><span class="line">            // supplier might be a Factory or a CacheValue&lt;V&gt; instance</span><br><span class="line">            V value = supplier.get();</span><br><span class="line">            if (value != null) &#123;</span><br><span class="line">                return value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // else no supplier in cache</span><br><span class="line">        // or a supplier that returned null (could be a cleared CacheValue</span><br><span class="line">        // or a Factory that wasn&apos;t successful in installing the CacheValue)</span><br><span class="line"> </span><br><span class="line">        // lazily construct a Factory</span><br><span class="line">        if (factory == null) &#123;</span><br><span class="line">            factory = new Factory(key, parameter, subKey, valuesMap);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        if (supplier == null) &#123;        </span><br><span class="line">            supplier = valuesMap.putIfAbsent(subKey, factory);</span><br><span class="line">            if (supplier == null) &#123;</span><br><span class="line">                // successfully installed Factory</span><br><span class="line">                supplier = factory;</span><br><span class="line">            &#125;</span><br><span class="line">            // else retry with winning supplier</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (valuesMap.replace(subKey, supplier, factory)) &#123;</span><br><span class="line">                // successfully replaced</span><br><span class="line">                // cleared CacheEntry / unsuccessful Factory</span><br><span class="line">                // with our Factory</span><br><span class="line">                supplier = factory;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // retry with current supplier</span><br><span class="line">                supplier = valuesMap.get(subKey);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到它调用了 supplier.get(); 获取动态代理类，其中supplier是Factory,这个类定义在WeakCach的内部。</p><p>来瞅瞅，get里面又做了什么？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">public synchronized V get() &#123; // serialize access</span><br><span class="line">            // re-check</span><br><span class="line">            Supplier&lt;V&gt; supplier = valuesMap.get(subKey);</span><br><span class="line">            if (supplier != this) &#123;</span><br><span class="line">                // something changed while we were waiting:</span><br><span class="line">                // might be that we were replaced by a CacheValue</span><br><span class="line">                // or were removed because of failure -&gt;</span><br><span class="line">                // return null to signal WeakCache.get() to retry</span><br><span class="line">                // the loop</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">            // else still us (supplier == this)</span><br><span class="line"> </span><br><span class="line">            // create new value</span><br><span class="line">            V value = null;</span><br><span class="line">            try &#123;</span><br><span class="line">                value = Objects.requireNonNull(valueFactory.apply(key, parameter));</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                if (value == null) &#123; // remove us on failure</span><br><span class="line">                    valuesMap.remove(subKey, this);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            // the only path to reach here is with non-null value</span><br><span class="line">            assert value != null;</span><br><span class="line"> </span><br><span class="line">            // wrap value with CacheValue (WeakReference)</span><br><span class="line">            CacheValue&lt;V&gt; cacheValue = new CacheValue&lt;&gt;(value);</span><br><span class="line"> </span><br><span class="line">            // try replacing us with CacheValue (this should always succeed)</span><br><span class="line">            if (valuesMap.replace(subKey, this, cacheValue)) &#123;</span><br><span class="line">                // put also in reverseMap</span><br><span class="line">                reverseMap.put(cacheValue, Boolean.TRUE);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                throw new AssertionError(&quot;Should not reach here&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            // successfully replaced us with new CacheValue -&gt; return the value</span><br><span class="line">            // wrapped by it</span><br><span class="line">            return value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>发现重点还是木有出现，但我们可以看到它调用了valueFactory.apply(key, parameter)方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * A factory function that generates, defines and returns the proxy class given</span><br><span class="line"> * the ClassLoader and array of interfaces.</span><br><span class="line"> */</span><br><span class="line">private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123;</span><br><span class="line">    // prefix for all proxy class names</span><br><span class="line">    private static final String proxyClassNamePrefix = &quot;$Proxy&quot;;</span><br><span class="line"> </span><br><span class="line">    // next number to use for generation of unique proxy class names</span><br><span class="line">    private static final AtomicLong nextUniqueNumber = new AtomicLong();</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123;</span><br><span class="line">        Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length);</span><br><span class="line">        for (Class&lt;?&gt; intf : interfaces) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that the class loader resolves the name of this</span><br><span class="line">             * interface to the same Class object.</span><br><span class="line">             */</span><br><span class="line">            Class&lt;?&gt; interfaceClass = null;</span><br><span class="line">            try &#123;</span><br><span class="line">                interfaceClass = Class.forName(intf.getName(), false, loader);</span><br><span class="line">            &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">            if (interfaceClass != intf) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    intf + &quot; is not visible from class loader&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that the Class object actually represents an</span><br><span class="line">             * interface.</span><br><span class="line">             */</span><br><span class="line">            if (!interfaceClass.isInterface()) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    interfaceClass.getName() + &quot; is not an interface&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that this interface is not a duplicate.</span><br><span class="line">             */</span><br><span class="line">            if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    &quot;repeated interface: &quot; + interfaceClass.getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        String proxyPkg = null;     // package to define proxy class in</span><br><span class="line">        int accessFlags = Modifier.PUBLIC | Modifier.FINAL;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Record the package of a non-public proxy interface so that the</span><br><span class="line">         * proxy class will be defined in the same package.  Verify that</span><br><span class="line">         * all non-public proxy interfaces are in the same package.</span><br><span class="line">         */</span><br><span class="line">        for (Class&lt;?&gt; intf : interfaces) &#123;</span><br><span class="line">            int flags = intf.getModifiers();</span><br><span class="line">            if (!Modifier.isPublic(flags)) &#123;</span><br><span class="line">                accessFlags = Modifier.FINAL;</span><br><span class="line">                String name = intf.getName();</span><br><span class="line">                int n = name.lastIndexOf(&apos;.&apos;);</span><br><span class="line">                String pkg = ((n == -1) ? &quot;&quot; : name.substring(0, n + 1));</span><br><span class="line">                if (proxyPkg == null) &#123;</span><br><span class="line">                    proxyPkg = pkg;</span><br><span class="line">                &#125; else if (!pkg.equals(proxyPkg)) &#123;</span><br><span class="line">                    throw new IllegalArgumentException(</span><br><span class="line">                        &quot;non-public interfaces from different packages&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        if (proxyPkg == null) &#123;</span><br><span class="line">            // if no non-public proxy interfaces, use com.sun.proxy package</span><br><span class="line">            proxyPkg = ReflectUtil.PROXY_PACKAGE + &quot;.&quot;;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Choose a name for the proxy class to generate.</span><br><span class="line">         */</span><br><span class="line">        long num = nextUniqueNumber.getAndIncrement();</span><br><span class="line">        String proxyName = proxyPkg + proxyClassNamePrefix + num;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Generate the specified proxy class.</span><br><span class="line">         */</span><br><span class="line">        byte[] proxyClassFile = ProxyGenerator.generateProxyClass(</span><br><span class="line">            proxyName, interfaces, accessFlags);</span><br><span class="line">        try &#123;</span><br><span class="line">            return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);</span><br><span class="line">        &#125; catch (ClassFormatError e) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * A ClassFormatError here means that (barring bugs in the</span><br><span class="line">             * proxy class generation code) there was some other</span><br><span class="line">             * invalid aspect of the arguments supplied to the proxy</span><br><span class="line">             * class creation (such as virtual machine limitations</span><br><span class="line">             * exceeded).</span><br><span class="line">             */</span><br><span class="line">            throw new IllegalArgumentException(e.toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过看代码终于找到了重点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//生成字节码</span><br><span class="line">byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);</span><br></pre></td></tr></table></figure><p>那么接下来我们也使用测试一下，使用这个方法生成的字节码是个什么样子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"> </span><br><span class="line">import sun.misc.ProxyGenerator;</span><br><span class="line"> </span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * 动态代理演示</span><br><span class="line"> */</span><br><span class="line">public class DynamicProxyDemonstration &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //代理的真实对象</span><br><span class="line">        Subject realSubject = new RealSubject();</span><br><span class="line"> </span><br><span class="line">        /**</span><br><span class="line">         * InvocationHandlerImpl 实现了 InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发</span><br><span class="line">         * 其内部通常包含指向委托类实例的引用，用于真正执行分派转发过来的方法调用.</span><br><span class="line">         * 即：要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法</span><br><span class="line">         */</span><br><span class="line">        InvocationHandler handler = new InvocationHandlerImpl(realSubject);</span><br><span class="line"> </span><br><span class="line">        ClassLoader loader = handler.getClass().getClassLoader();</span><br><span class="line">        Class[] interfaces = realSubject.getClass().getInterfaces();</span><br><span class="line">        /**</span><br><span class="line">         * 该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例</span><br><span class="line">         */</span><br><span class="line">        Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br><span class="line">        System.out.println(&quot;动态代理对象的类型：&quot;+subject.getClass().getName());</span><br><span class="line"></span><br><span class="line">        String hello = subject.SayHello(&quot;jiankunking&quot;);</span><br><span class="line">        System.out.println(hello);</span><br><span class="line">        // 将生成的字节码保存到本地，</span><br><span class="line">        createProxyClassFile();</span><br><span class="line">    &#125;</span><br><span class="line">    private static void createProxyClassFile()&#123;</span><br><span class="line">        String name = &quot;ProxySubject&quot;;</span><br><span class="line">        byte[] data = ProxyGenerator.generateProxyClass(name,new Class[]&#123;Subject.class&#125;);</span><br><span class="line">        FileOutputStream out =null;</span><br><span class="line">        try &#123;</span><br><span class="line">            out = new FileOutputStream(name+&quot;.class&quot;);</span><br><span class="line">            System.out.println((new File(&quot;hello&quot;)).getAbsolutePath());</span><br><span class="line">            out.write(data);</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;finally &#123;</span><br><span class="line">            if(null!=out) try &#123;</span><br><span class="line">                out.close();</span><br><span class="line">            &#125; catch (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看一下这里代理对象的类型：</p><p><img src="/images/spring-jdk-aop/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B.png" alt><br>我们用jd-jui 工具将生成的字节码反编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line">import java.lang.reflect.UndeclaredThrowableException;</span><br><span class="line">import jiankunking.Subject;</span><br><span class="line"> </span><br><span class="line">public final class ProxySubject extends Proxy implements Subject &#123;</span><br><span class="line">  private static Method m1;</span><br><span class="line">  private static Method m3;</span><br><span class="line">  private static Method m4;</span><br><span class="line">  private static Method m2;</span><br><span class="line">  private static Method m0;</span><br><span class="line">  </span><br><span class="line">  public ProxySubject(InvocationHandler paramInvocationHandler) &#123;</span><br><span class="line">    super(paramInvocationHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final boolean equals(Object paramObject)&#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        return ((Boolean)this.h.invoke(this, m1, new Object[] &#123; paramObject &#125;)).booleanValue();</span><br><span class="line">    &#125; catch (Error|RuntimeException localError)&#123;</span><br><span class="line">        throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String SayGoodBye() &#123;</span><br><span class="line">    try&#123;</span><br><span class="line">      return (String)this.h.invoke(this, m3, null);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String SayHello(String paramString) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return (String)this.h.invoke(this, m4, new Object[] &#123; paramString &#125;);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError)&#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable)&#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String toString() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return (String)this.h.invoke(this, m2, null);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final int hashCode() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return ((Integer)this.h.invoke(this, m0, null)).intValue();</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  static</span><br><span class="line">  &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[] &#123; Class.forName(&quot;java.lang.Object&quot;) &#125;);</span><br><span class="line">      m3 = Class.forName(&quot;jiankunking.Subject&quot;).getMethod(&quot;SayGoodBye&quot;, new Class[0]);</span><br><span class="line">      m4 = Class.forName(&quot;jiankunking.Subject&quot;).getMethod(&quot;SayHello&quot;, new Class[] &#123; Class.forName(&quot;java.lang.String&quot;) &#125;);</span><br><span class="line">      m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]);</span><br><span class="line">      m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]);</span><br><span class="line">      return;</span><br><span class="line">    &#125; catch (NoSuchMethodException localNoSuchMethodException) &#123;</span><br><span class="line">      throw new NoSuchMethodError(localNoSuchMethodException.getMessage());</span><br><span class="line">    &#125; catch (ClassNotFoundException localClassNotFoundException) &#123;</span><br><span class="line">      throw new NoClassDefFoundError(localClassNotFoundException.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是最终真正的代理类，它继承自Proxy并实现了我们定义的Subject接口，也就是说：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br></pre></td></tr></table></figure><p>这里的subject实际是这个类的一个实例，那么我们调用它的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public final String SayHello(String paramString)</span><br></pre></td></tr></table></figure><p>就是调用我们定义的InvocationHandlerImpl的 invoke方法：</p><p><img src="/images/spring-jdk-aop/sayhello.png" alt></p><blockquote><p>上面是代码跟分析的过程，不想看的朋友可以直接看结论</p></blockquote><h1 id="五、结论"><a href="#五、结论" class="headerlink" title="五、结论"></a>五、结论</h1><p>到了这里，终于解答了：</p><p>subject.SayHello(“jiankunking”)这句话时，为什么会自动调用InvocationHandlerImpl的invoke方法？</p><p>因为JDK生成的最终真正的代理类，它继承自Proxy并实现了我们定义的Subject接口，在实现Subject接口方法的内部，通过反射调用了InvocationHandlerImpl的invoke方法。</p><p>通过分析代码可以看出Java 动态代理，具体有如下四步骤：</p><ol><li><p>通过实现 InvocationHandler 接口创建自己的调用处理器；</p></li><li><p>通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；</p></li><li><p>通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；</p></li><li><p>通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。</p></li></ol><p>演示代码下载：<br><a href="https://github.com/jiankunking/DynamicProxyDemo" target="_blank" rel="noopener">https://github.com/jiankunking/DynamicProxyDemo</a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> Java </tag>
            
            <tag> JDK </tag>
            
            <tag> Spring </tag>
            
            <tag> AOP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过IL分析C#中的委托、事件、Func、Action、Predicate之间的区别与联系</title>
      <link href="/csharp-il-delegate-event-func-action-predicate.html"/>
      <url>/csharp-il-delegate-event-func-action-predicate.html</url>
      
        <content type="html"><![CDATA[<p>一直以来都是对于事件与委托比较混淆，而且不太会用。找了个时间，总结了一下，感觉清晰了很多。</p><p>先说一下个人理解的结论吧：</p><blockquote><p>delegate是C#中的一种类型，它实际上是一个能够持有对某个方法的引用的类。</p></blockquote><p>delegate声明的变量与delegate声明的事件，并没有本质的区别，事件是在delegate声明变量的基础上包装而成的，类似于变量与属性的关系（在IL代码中可以看到每一个delegate声明的事件都对应是私有的delegate声明的变量），提升了安全性。</p><p>Action 与Func：这两个其实说白了就是系统定义好的Delegate，他有很多重载的方法，便于各种应用情况下的调用。他在系统的System命名空间下，因此全局可见。</p><p>首先了解一下， ILDasm中图标含义：<br><img src="/images/csharp-delegate/ILDasm.png" alt><br>该图来自：<a href="http://www.cnblogs.com/zery/p/3366175.html" target="_blank" rel="noopener">http://www.cnblogs.com/zery/p/3366175.html</a></p><p>委托创建步骤：</p><ol><li><font color="DeepPink"><strong>用delegate关键字创建一个委托，包括声明返回值和参数类型。</strong></font></li><li><font color="DeepPink"><strong>使用的地方接收这个委托。</strong></font></li><li><font color="DeepPink"><strong>创建这个委托的实例并指定一个返回值和参数类型匹配的方法传递过去。</strong></font></li></ol><h1 id="一、事件与委托"><a href="#一、事件与委托" class="headerlink" title="一、事件与委托"></a>一、事件与委托</h1><p>新建一个事件委托测试项目：EventDelegateTest。</p><p>具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">namespace EventDelegateTest</span><br><span class="line">&#123;</span><br><span class="line">    public class TestClass</span><br><span class="line">    &#123;</span><br><span class="line">        public delegate int delegateAction();</span><br><span class="line">        public event delegateAction OnActionEvent;</span><br><span class="line">        public delegateAction daNew;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译代码后，使用 Visual Studio 2010自带的ILDASM.EXE：<br><img src="/images/csharp-delegate/IL%E5%8F%8D%E6%B1%87%E7%BC%96%E7%A8%8B%E5%BA%8F.png" alt></p><p>打开该dll，可以看到如下信息：<br><img src="/images/csharp-delegate/%E5%8F%8D%E7%BC%96%E8%AF%91DLL%E4%BF%A1%E6%81%AF.png" alt></p><p>从上图可以看出如下几点信息：</p><h2 id="1、delegate"><a href="#1、delegate" class="headerlink" title="1、delegate"></a>1、delegate</h2><p>委托 public delegate int delegateAction();在IL中是以类（delegateAction）的形式存在的<br>.NET将委托定义为一个密封类，派生自基类System.MulticastDelegate，并继承了基类的三个方法:<br><img src="/images/csharp-delegate/delegateAction.png" alt></p><h2 id="2、event"><a href="#2、event" class="headerlink" title="2、event"></a>2、event</h2><p>public event delegateAction OnActionEvent;在IL中不仅仅对应event OnActionEvent而且还对应一个field OnActionEvent;而field OnActionEvent与 public delegateAction daNew生成的field daNew是一样的.<br><img src="/images/csharp-delegate/OnActionEvent.png" alt><br><img src="/images/csharp-delegate/daNew.png" alt><br>都是以字段（field ）的形式存在的。<br>双击event OnActionEvent可以看到如下信息：<br><img src="/images/csharp-delegate/event-OnActionEvent.png" alt></p><p>在IL中事件被封装成了包含一个add_前缀和一个remove_前缀的的代码段。<br>其中，add_前缀的方法其实是通过调用Delegate.Combine()方法来实现的，组成了一个多播委托；remove_就是调用Delegate.Remove()方法，用于移除多播委托中的某个委托。</p><blockquote><p>也就是说：事件其实就是一个特殊的多播委托。</p></blockquote><p>那么对于事件进行这一次封装有什么好处呢？<br>1、因为delegate可以支持的操作非常多，比如我们可以写onXXXChanged += aaaFunc，把某个函数指针挂载到这个委托上面，但是我们也可以简单粗暴地直接写onXXXChanged = aaaFunc，让这个委托只包含这一个函数指针。不过这样一来会产生一个安全问题：如果我们用onXXXChanged = aaaFunc这样的写法，那么会把这个委托已拥有的其他函数指针给覆盖掉，这大概不是定义onXXXChanged的程序员想要看到的结果。</p><blockquote><p>小注：虽然事件不能直接=某个函数，也不可以直接=null</p></blockquote><p><img src="/images/csharp-delegate/event_not_null.png" alt></p><p>2、还有一个问题就是onXXXChanged这个委托应该什么时候触发（即调用它所包含的函数指针）。从面向对象的角度来说，XXX改变了这个事实（即onXXXChaned的字面含义）应该由包含它的那个对象来决定。但实际上我们可以从这个对象的外部环境调用onXXXChanged，这既产生了安全问题也不符合面向对象的初衷。<br>说到这里对于事件与委托的管理算是说明白了，那么平时常用的Action与Func，与委托又有什么关系呢？</p><h1 id="二、Action-与Func"><a href="#二、Action-与Func" class="headerlink" title="二、Action 与Func"></a>二、Action 与Func</h1><p><strong>Action 委托：封装一个方法，该方法具有参数（0到16个参数）并且不返回值。</strong><br>具体形式如下：<a href="https://msdn.microsoft.com/zh-cn/library/system.action(v=vs.110).aspx" target="_blank" rel="noopener">https://msdn.microsoft.com/zh-cn/library/system.action(v=vs.110).aspx</a><br><img src="/images/csharp-delegate/Action.png" alt></p><p><strong>Func&lt;T, TResult&gt; 委托：封装一个具有参数（0到16个参数）并返回 TResult 参数指定的类型值的方法。</strong><br>具体形式如下：<a href="https://msdn.microsoft.com/zh-cn/library/bb534960(v=vs.110).aspx" target="_blank" rel="noopener">https://msdn.microsoft.com/zh-cn/library/bb534960(v=vs.110).aspx</a><br><img src="/images/csharp-delegate/Func_T_TResult.png" alt></p><p>那么这Action与Func是怎么实现的呢？<br>1、Action（以Action&lt;T1, T2&gt; 委托：封装一个方法，该方法具有两个参数并且不返回值为例）<br>从微软公布的源码中，可以看到，如下实现：<br><img src="/images/csharp-delegate/Action_T.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public Action&lt;bool,bool&gt;  ac;</span><br></pre></td></tr></table></figure><p>上面这个声明就是：该方法具有两个参数并且不返回值的委托。<br>其余使用方式与委托变量一样。<br>2、Func（以Func&lt;T1, T2, TResult&gt; 委托：封装一个具有两个参数并返回 TResult 参数指定的类型值的方法为例）<br>从微软公布的源码中，可以看到，如下实现：<br><img src="/images/csharp-delegate/Func_T_TResult_%E6%BA%90%E7%A0%81.png" alt></p><p>此处，可以看出Func与Action是类似的，唯一的区别就是，Func必须指定返回值的类型，使用方式与委托咱们自己使用委托变量是一样的，直接使用相应参数的Func或者Action声明变量，=或者+=挂载函数（方法即可）<br>这两个其实说白了就是系统定义好的Delegate，他有很多重载的方法，便于各种应用情况下的调用。他在系统的System命名空间下，因此全局可见。</p><h1 id="三、Predicate"><a href="#三、Predicate" class="headerlink" title="三、Predicate"></a>三、Predicate</h1><p><strong>是返回bool型的泛型委托，Predicate有且只有一个参数，返回值固定为bool。表示定义一组条件并确定指定对象是否符合这些条件的方法。</strong></p><p>此方法常在集合（Array 和 List<t>）的查找中被用到，如：数组，正则拼配的结果集中被用到。</t></p><p>官方文档：<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.predicate-1?redirectedfrom=MSDN&amp;view=netframework-4.8" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.predicate-1?redirectedfrom=MSDN&amp;view=netframework-4.8</a></p><p>具体用法demo如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">using System;</span><br><span class="line">using System.Collections.Generic;</span><br><span class="line">using System.ComponentModel;</span><br><span class="line">using System.Data;</span><br><span class="line">using System.Drawing;</span><br><span class="line">using System.Linq;</span><br><span class="line">using System.Text;</span><br><span class="line">using System.Windows.Forms;</span><br><span class="line"> </span><br><span class="line">namespace IconTest</span><br><span class="line">&#123;</span><br><span class="line">    public partial class Form2 : Form</span><br><span class="line">    &#123;</span><br><span class="line">        Predicate&lt;int&gt; myPredicate;</span><br><span class="line">        int[] myNum = new int[8] &#123; 12, 33, 89, 21, 15, 29, 40, 52 &#125;;</span><br><span class="line">        public int[] myResult;</span><br><span class="line">        public Form2()</span><br><span class="line">        &#123;</span><br><span class="line">            InitializeComponent();</span><br><span class="line">            myPredicate = delegate(int curNum) 　　　　　　　　　　　　</span><br><span class="line">            &#123;</span><br><span class="line">                if (curNum % 2 == 0)</span><br><span class="line">                &#123;</span><br><span class="line">                    return true;</span><br><span class="line">                &#125;</span><br><span class="line">                else</span><br><span class="line">                &#123;</span><br><span class="line">                    return false;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        private void Form2_Load(object sender, EventArgs e)</span><br><span class="line">        &#123;</span><br><span class="line">            myResult = Array.FindAll(myNum, myPredicate);</span><br><span class="line">        &#125;          </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上例中说明了Predicate的使用，FindAll方法中，参数2即是一个Predicate，在具体的执行中，每一个数组的元素都会执行指定的方法，如果满足要求返回true，并会被存放在结果集中，不符合的则被剔除，最终返回的集合，即是结果判断后想要的集合。<br>Array.FindAll 泛型方法：<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.array.findall?redirectedfrom=MSDN&amp;view=netframework-4.8#System_Array_FindAll__1___0___System_Predicate___0" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.array.findall?redirectedfrom=MSDN&amp;view=netframework-4.8#System_Array_FindAll__1___0___System_Predicate___0</a>__<br>以上代码执行结果为：<br><img src="/images/csharp-delegate/Form2_Load.png" alt><br>那么Predicate<t>与委托又有什么关系呢？<br><img src="/images/csharp-delegate/Predicate_T.png" alt></t></p><p>从微软源码中可以看出Predicate<t>是返回bool型的泛型委托，从本质上来说与Func、Action、事件、委托变量并无本质区别。</t></p><h1 id="四、资料"><a href="#四、资料" class="headerlink" title="四、资料"></a>四、资料</h1><p>参考文章：<br><a href="http://www.zhihu.com/question/28932542" target="_blank" rel="noopener">http://www.zhihu.com/question/28932542</a></p><p>关于事件部分应用注意可以参考：<br><a href="http://www.cnblogs.com/buptzym/archive/2013/03/15/2962300.html" target="_blank" rel="noopener">http://www.cnblogs.com/buptzym/archive/2013/03/15/2962300.html</a></p><p>.NET Framework 源码：<br><a href="https://referencesource.microsoft.com" target="_blank" rel="noopener">https://referencesource.microsoft.com</a><br>Delegate 类:<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.delegate?redirectedfrom=MSDN&amp;view=netframework-4.8" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.delegate?redirectedfrom=MSDN&amp;view=netframework-4.8</a></p><p><img src="/images/csharp-delegate/%E5%A7%94%E6%89%98%E5%9B%BE%E8%A7%A3.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> C# </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原创 </tag>
            
            <tag> C# </tag>
            
            <tag> Delegate </tag>
            
            <tag> Action </tag>
            
            <tag> Predicate </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
