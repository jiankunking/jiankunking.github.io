<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>[译]Elasticsearch自定义文档路由</title>
    <url>/customizing-your-document-routing.html</url>
    <content><![CDATA[<blockquote><p>注意:原文发表时间是13年,所以实现有可能与新版不一致.<br>原文地址:<a href="https://www.elastic.co/cn/blog/customizing-your-document-routing" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/customizing-your-document-routing</a></p></blockquote><a id="more"></a><h1>什么是路由</h1><p>您的所有数据都存在于集群中某个位置的主分片中。您可能有五个分片或五百个，但任何特定的文档都只位于其中一个。<font color="DeepPink"><strong>路由是确定文档将保存到哪个分片中的过程。</strong></font></p><p>因为Elasticsearch努力让90%的用户使用默认值，所以路由是自动处理的。对于大多数用户来说，文档存储在哪里并不重要。</p><p><font color="DeepPink"><strong>默认的路由方案对文档的ID进行hash，并使用它来查找分片。这包括用户提供的ID和Elasticsearch随机生成的ID。默认路由使文档在整个分片集中均匀分布 - 不会出现文档集中倾斜到某个分片上形成热点。</strong></font></p><h1>自定义路由试用的场景</h1><p>随机路由在大多数情况下都运行良好，但在某些情况下，可以通过自定义路由带来更好的性能。想象一个包含 20 个分片的索引（过度分配以支持未来的增长）。</p><p>当在集群上执行搜索请求时会发生什么？</p><ul><li>搜索请求命中节点</li><li>节点将此请求广播到索引中的每个分片（主分片或副本分片）</li><li>每个分片执行搜索查询并返回结果</li><li>结果在网关节点上合并、排序并返回给用户</li></ul><p>Elasticsearch 不知道在哪里查找您的文档。所有文档都随机分布在您的集群中……因此 Elasticsearch 别无选择，只能将请求广播到所有 20 个分片。这是不可忽略的开销，并且可能会影响性能。</p><p>如果我们能够告诉 Elasticsearch 该文档位于哪个分片中，岂不是很好？ 然后您只需搜索一个分片即可找到您需要的文档。</p><p>这正是自定义路由的作用。</p><p>您不需要盲目地向所有分片广播，而是告诉 Elasticsearch“嘿！ 搜索这个分片上的数据！ 一切都在那里，我保证！” 例如，您可以根据文档的 user_id 路由文档。或者他们的邮政编码。或者您的应用程序中经常搜索/过滤的任何内容。</p><p><font color="DeepPink"><strong>路由确保具有相同路由值的所有文档都将定位到同一个分片，从而无需广播搜索。</strong></font></p><h1>自定义路由速度很快</h1><p>自定义路由可确保仅查询一个分片。</p><p>如果您的问题适合自定义路由，那么这有可能显着提高性能。</p><p>无论索引中有 20 个还是 100 个分片，自定义路由都可以确保只查询保存数据的分片。</p><h1>配置自定义路由</h1><p>使用自定义路由时，每当索引、获取、删除或更新文档时提供路由值非常重要。</p><p>忘记路由值可能会导致文档在多个分片上建立索引。作为保护措施，可以配置 _routing 字段来创建所有 CRUD 操作所需的自定义路由值：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my-index-000002</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_routing&quot;: &#123;</span><br><span class="line">      &quot;required&quot;: true //文章所有操作都需要指定路由</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my-index-000002/_doc/1 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;No routing value provided&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>原文已经过时了，所有没有翻译原文；<br>这里是翻译自官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html</a></p></blockquote><h1>自定义路由搜索</h1><p>自定义路由可以减少搜索的影响。不必将搜索请求发送到索引中的所有分片，而是将请求仅发送到与特定路由值（或多个值）匹配的分片：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET my-index-000001/_search?routing=user1,user2 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;title&quot;: &quot;document&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>此搜索请求将仅在与 user1 和 user2 路由值关联的分片上执行。</p></blockquote><h1>注意事项</h1><p>在使用自定义路由时，您应该注意以下几个问题。</p><h2 id="Parent-Child-Grandchild-schemes">Parent/Child/Grandchild schemes</h2><p><font color="DeepPink"><strong>出于性能原因，父/子映射可确保所有子分片都路由到与父分片相同的分片。在内部，Elasticsearch 将子级的路由值设置为等于父级的 ID，确保每个人都位于同一个分片。</strong></font></p><p>但是，如果您添加第三层（孙子），父/子映射就会失败。查看这些示例文档：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT localhost:9200/parentchild/product/Product001 -d &apos;&#123;...&#125;&apos;</span><br><span class="line">curl -XPUT localhost:9200/parentchild/vendors/VendorABC?parent=Product001 -d &apos;&#123;...&#125;&apos;</span><br><span class="line">curl -XPUT localhost:9200/parentchild/vendordetails/LocationXYZ?parent=VendorABC -d &apos;&#123;...&#125;&apos;</span><br></pre></td></tr></table></figure><p>相当简单的嵌套关系。产品的子代被称为“供应商”，而这些产品则有自己的子代，称为“VendorDetails”。那么，为什么这不起作用呢？让我们看看派生的路由值：</p><table><thead><tr><th style="text-align:center">Doc ID</th><th style="text-align:center">Parent</th><th style="text-align:center">Routing Value</th></tr></thead><tbody><tr><td style="text-align:center">Product001</td><td style="text-align:center">-</td><td style="text-align:center"><strong>Product001</strong></td></tr><tr><td style="text-align:center">VendorABC</td><td style="text-align:center">Product001</td><td style="text-align:center"><strong>Product001</strong></td></tr><tr><td style="text-align:center">LocationXYZ</td><td style="text-align:center">VendorABC</td><td style="text-align:center"><strong>VendorABC</strong></td></tr></tbody></table><p>正如您所看到的，文档将自动使用其父级的ID进行路由。VendorABC使用Product001（到目前为止很好），但LocationXYZ使用VendorABC（坏）。这意味着数据没有被正确地并置。</p><p>解决方案很简单：告诉孙子（以及任何后续的曾孙）它的路由值应该是祖父母的ID。在内部，Elasticsearch将优先选择路由参数而不是父参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT localhost:9200/parentchild/product/Product001 -d &apos;&#123;...&#125;&apos;</span><br><span class="line">curl -XPUT localhost:9200/parentchild/vendors/VendorABC?parent=Product001 -d &apos;&#123;...&#125;&apos;</span><br><span class="line">curl -XPUT localhost:9200/parentchild/vendordetails/LocationXYZ?parent=VendorABC&amp;routing=Product001 -d &apos;&#123;...&#125;&apos;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">Doc ID</th><th style="text-align:center">Parent</th><th style="text-align:center">Routing Value</th></tr></thead><tbody><tr><td style="text-align:center">Product001</td><td style="text-align:center">-</td><td style="text-align:center"><strong>Product001</strong></td></tr><tr><td style="text-align:center">VendorABC</td><td style="text-align:center">Product001</td><td style="text-align:center"><strong>Product001</strong></td></tr><tr><td style="text-align:center">LocationXYZ</td><td style="text-align:center">VendorABC</td><td style="text-align:center"><strong>Product001</strong></td></tr></tbody></table><h2 id="热点">热点</h2><p>当Elasticsearch管理路由时，它可以确保所有碎片的分布相当均匀。然而，一旦您开始实现自己的自定义方案，就完全有可能失去这种一致性。假设您正在按userID进行路由。你的大多数用户都很小，只有少量的文档……但偶尔你会遇到一个拥有数百万的怪物用户。</p><p>自定义路由将确保MonsterUser的所有文档都指向一个shard，而不是在集群中均匀分布。这对性能有好处——搜索会很快执行。</p><p>但是，如果MonsterUser2和MonsterUser3也被分配到同一个碎片，会发生什么？现在，在一个碎片上有三个大用户，而其余的碎片只加载了少量。</p><p>情况不太好。这些类型的场景可以而且确实会发生。<font color="DeepPink"><strong>针对这些“数据热点”的最佳防御措施是手动识别大用户（或其他急需性能的用户），并将其拆分为自己的索引。然后，您可以设置一个别名，使分离对应用程序透明。</strong></font></p><p>现在，您可以两全其美：自定义路由将大多数用户沙盒在一个碎片中，而大用户则被拆分为自己的索引和一组碎片。</p><h2 id="You-can-check-out-any-time-you-like-but-you-can-never-leave">You can check-out any time you like, but you can never leave!</h2><p>一旦在索引文档时指定了自定义路由，无论何时更新或删除文档，都必须继续指定。您已经从Elasticsearch获得了一些控制权，如果您决定在某个时候停止使用自定义路由，则没有简单的方法可以恢复此控制权。唯一的方法是重新建立数据索引（不指定自定义路由）。</p><h1>结论</h1><p>自定义路由是一个强大的功能，可以在特定情况下提高性能。虽然默认路由对大多数人来说已经足够了，但有时您只需要对文档的放置进行更多的控制。</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Document</tag>
        <tag>Routing</tag>
      </tags>
  </entry>
  <entry>
    <title>三难选择(不可能三角)</title>
    <url>/mundellian-trilemma.html</url>
    <content><![CDATA[<h1>三元悖论</h1><p><a href="https://zh.wikipedia.org/wiki/%E4%B8%89%E5%85%83%E6%82%96%E8%AE%BA" target="_blank" rel="noopener">三元悖论</a>是国际金融学中的原则，指一个国家不可能同时完成下列三者：</p><ul><li>资本自由进出（Capital mobility）</li><li>固定汇率（Exchange rate）</li><li>独立自主的货币政策（Monetary policy）</li></ul><p><img data-src="/images/mundellian-trilemma/Impossible_trinity_diagram.svg.png" alt></p><h1>RUM猜想</h1><p>RUM猜想来自论文“<a href="https://stratos.seas.harvard.edu/files/stratos/files/rum.pdf" target="_blank" rel="noopener">Designing Access Methods: The RUM Conjecture</a>”（Manos Athanassoulis et al.(2016)），同时被SIGMOD和EDBT收录。它说的是，对任何数据结构来说，在Read Overhead（读）、Update Overhead（写） 和 Memory or Storage Overhead（存储） 中，同时优化两项时，需要以另一项劣化作为代价。</p><p><img data-src="/images/mundellian-trilemma/RUM%E7%8C%9C%E6%83%B3.png" alt></p><h1>CAP</h1><p><img data-src="/images/mundellian-trilemma/CAP.png" alt></p><h1>GC</h1><ul><li>Throughput represents the amount of work that can be done in a given time unit. In terms of this discussion, a garbage collection algorithm that performs more collection work per time unit is preferable, allowing higher throughput of the Java application.</li><li>Latency gives an indication of how long a single operation of the application takes. A garbage collection algorithm focused on latency tries to minimize impacting latency. In the context of a GC, the key concerns are whether its operation induces pauses, the extent of any pauses, and how long the pauses may be.</li><li>Memory footprint in the context of a GC means how much extra memory beyond the application’s Java heap memory usage the GC needs for proper operation. Data used purely for the management of the Java heap takes away from the application; if the amount of memory the GC (or, more generally, the JVM) uses is less, more memory can be provided to the application’s Java heap.</li></ul><p><img data-src="/images/mundellian-trilemma/GC.png" alt></p><p><a href="/attachments/mundellian-trilemma/Java garbage collection_ The 10-release evolution from JDK 8 to JDK 18.pdf" target="_blank">Java garbage collection_ The 10-release evolution from JDK 8 to JDK 18</a></p>]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>三元悖论</tag>
        <tag>不可能三角</tag>
        <tag>三难选择</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL必知必会 笔记</title>
    <url>/sql-must-know.html</url>
    <content><![CDATA[<p>SQL必知必会 笔记<br>作者： 陈旸</p><a id="more"></a><h1>索引的原理：我们为什么用B+树来做索引？</h1><p><a href="/attachments/SQL必知必会/24丨索引的原理：我们为什么用B+树来做索引.pdf" target="_blank">24丨索引的原理：我们为什么用B+树来做索引</a></p><h1>Hash索引的底层原理是什么</h1><p><a href="/attachments/SQL必知必会/25丨Hash索引的底层原理是什么.pdf" target="_blank">25丨Hash索引的底层原理是什么</a></p><h1>为什么没有理想的索引</h1><p><a href="/attachments/SQL必知必会/29丨为什么没有理想的索引.pdf" target="_blank">29丨为什么没有理想的索引</a></p><h1>锁：悲观锁和乐观锁是什么</h1><p><a href="/attachments/SQL必知必会/30丨锁：悲观锁和乐观锁是什么.pdf" target="_blank">30丨锁：悲观锁和乐观锁是什么</a></p><h1>为什么大部分RDBMS都会支持MVCC</h1><p><a href="/attachments/SQL必知必会/31丨为什么大部分RDBMS都会支持MVCC.pdf" target="_blank">31丨为什么大部分RDBMS都会支持MVCC</a></p><h1>查询优化器是如何工作的</h1><p><a href="/attachments/SQL必知必会/32丨查询优化器是如何工作的.pdf" target="_blank">32丨查询优化器是如何工作的</a></p><h1>如何使用性能分析工具定位SQL执行慢的原因</h1><p><a href="/attachments/SQL必知必会/33丨如何使用性能分析工具定位SQL执行慢的原因.pdf" target="_blank">33丨如何使用性能分析工具定位SQL执行慢的原因</a></p><h1>答疑篇：关于索引以及缓冲池的一些解惑</h1><p><a href="/attachments/SQL必知必会/34丨答疑篇：关于索引以及缓冲池的一些解惑.pdf" target="_blank">34丨答疑篇：关于索引以及缓冲池的一些解惑</a></p><h1>数据库没有备份，没有使用Binlog的情况下，如何恢复数据</h1><p><a href="/attachments/SQL必知必会/36丨数据库没有备份，没有使用Binlog的情况下，如何恢复数据.pdf" target="_blank">36丨数据库没有备份，没有使用Binlog的情况下，如何恢复数据</a></p><h1>SQL注入：你的SQL是如何被注入的</h1><p><a href="/attachments/SQL必知必会/37丨SQL注入：你的SQL是如何被注入的.pdf" target="_blank">37丨SQL注入：你的SQL是如何被注入的</a></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL99 和 SQL92 的区别</title>
    <url>/sql99-vs-sql92.html</url>
    <content><![CDATA[<p>这里主要说一下两者关于JOIN方面的区别：</p><p>SQL 92</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">  e.*, </span><br><span class="line">  d.dname, </span><br><span class="line">  c.cname </span><br><span class="line">from </span><br><span class="line">  emp e, </span><br><span class="line">  dept d, </span><br><span class="line">  city c </span><br><span class="line">where </span><br><span class="line">  (</span><br><span class="line">    e.deptno = d.deptno </span><br><span class="line">    and d.loc = c.cid </span><br><span class="line">    and sal &gt; 2000</span><br><span class="line">  ) </span><br><span class="line">  or (</span><br><span class="line">    e.deptno = d.deptno </span><br><span class="line">    and d.loc = c.cid </span><br><span class="line">    and comm is not null</span><br><span class="line">  ) </span><br><span class="line">order by </span><br><span class="line">  e.sal</span><br></pre></td></tr></table></figure><p>SQL 99</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">  * </span><br><span class="line">from </span><br><span class="line">  emp e </span><br><span class="line">  inner join dept d on e.deptno = d.deptno </span><br><span class="line">  inner join city c on d.loc = c.cid </span><br><span class="line">where </span><br><span class="line">  e.sal &gt; 2000 </span><br><span class="line">  or e.comm is not null </span><br><span class="line">order by </span><br><span class="line">  e.sal</span><br></pre></td></tr></table></figure><p>我个人建议多表连接使用 SQL99 标准，因为层次性更强，可读性更强。</p>]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>SQL99</tag>
        <tag>SQL92</tag>
        <tag>Standard</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis数据分布优化：如何应对数据倾斜?</title>
    <url>/data-distribution-optimization-how-to-deal-with-data-skewness.html</url>
    <content><![CDATA[<p>Redis 核心技术与实战 笔记<br>作者： 蒋德钧</p><a id="more"></a><p>在切片集群中，数据会按照一定的分布规则分散到不同的实例上保存。比如，在使用 Redis Cluster 或 Codis 时，数据都会先按照 CRC 算法的计算值对 Slot（逻辑槽）取模，同时，所有的 Slot 又会由运维管理员分配到不同的实例上。这样，数据就被保存到相应的实例上了。</p><p>虽然这种方法实现起来比较简单，但是很容易导致一个问题：数据倾斜。</p><p>数据倾斜有两类。</p><ul><li><strong>数据量倾斜</strong>：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。</li><li><strong>数据访问倾斜</strong>：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。</li></ul><p>如果发生了数据倾斜，那么保存了大量数据，或者是保存了热点数据的实例的处理压力就会增大，速度变慢，甚至还可能会引起这个实例的内存资源耗尽，从而崩溃。这是我们在应用切片集群时要避免的。</p><p>今天这节课，我就来和你聊聊，这两种数据倾斜是怎么发生的，我们又该怎么应对。</p><h1>数据量倾斜的成因和应对方法</h1><p>首先，我们来看数据量倾斜的成因和应对方案。</p><p>当数据量倾斜发生时，数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上，如下图所示：</p><p><img data-src="/images/data-distribution-optimization-how-to-deal-with-data-skewness/1.webp" alt></p><p>那么，数据量倾斜是怎么产生的呢？这主要有三个原因，分别是某个实例上保存了 bigkey、Slot 分配不均衡以及 Hash Tag。接下来，我们就一个一个来分析，同时我还会给你讲解相应的解决方案。</p><h2 id="bigkey-导致倾斜">bigkey 导致倾斜</h2><p>第一个原因是，某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。</p><p>而且，bigkey 的操作一般都会造成实例 IO 线程阻塞，如果 bigkey 的访问量比较大，就会影响到这个实例上的其它请求被处理的速度。</p><p>其实，bigkey 已经是我们课程中反复提到的一个关键点了。为了避免 bigkey 造成的数据倾斜，一个根本的应对方法是，<strong>我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。</strong></p><p>此外，<strong>如果 bigkey 正好是集合类型，我们还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。</strong></p><p>我给你举个例子。假设 Hash 类型集合 user:info 保存了 100 万个用户的信息，是一个 bigkey。那么，我们就可以按照用户 ID 的范围，把这个集合拆分成 10 个小集合，每个小集合只保存 10 万个用户的信息（例如小集合 1 保存的是 ID 从 1 到 10 万的用户信息，小集合 2 保存的是 ID 从 10 万零 1 到 20 万的用户）。这样一来，我们就可以把一个 bigkey 化整为零、分散保存了，避免了 bigkey 给单个切片实例带来的访问压力。</p><p>需要注意的是，当 bigkey 访问量较大时，也会造成数据访问倾斜，我一会儿再给你讲具体怎么应对。</p><p>接下来，我们再来看导致数据量倾斜的第二个原因：Slot 分配不均衡。</p><h2 id="Slot-分配不均衡导致倾斜">Slot 分配不均衡导致倾斜</h2><p>如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜。</p><p>我以 Redis Cluster 为例，来介绍下 Slot 分配不均衡的情况。</p><p>Redis Cluster 一共有 16384 个 Slot，假设集群一共有 5 个实例，其中，实例 1 的硬件配置较高，运维人员在给实例分配 Slot 时，就可能会给实例 1 多分配些 Slot，把实例 1 的资源充分利用起来。</p><p>但是，我们其实并不知道数据和 Slot 的对应关系，这种做法就可能会导致大量数据正好被映射到实例 1 上的 Slot，造成数据倾斜，给实例 1 带来访问压力。</p><p>为了应对这个问题，我们可以通过运维规范，在分配之前，我们就要避免把过多的 Slot 分配到同一个实例。如果是已经分配好 Slot 的集群，我们可以先查看 Slot 和实例的具体分配关系，从而判断是否有过多的 Slot 集中到了同一个实例。如果有的话，就将部分 Slot 迁移到其它实例，从而避免数据倾斜。</p><p>不同集群上查看 Slot 分配情况的方式不同：如果是 Redis Cluster，就用 CLUSTER SLOTS 命令；如果是 Codis，就可以在 codis dashboard 上查看。</p><p>比如说，我们执行 CLUSTER SLOTS 命令查看 Slot 分配情况。命令返回结果显示，Slot 0 到 Slot 4095 被分配到了实例 192.168.10.3 上，而 Slot 12288 到 Slot 16383 被分配到了实例 192.168.10.5 上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster slots</span><br><span class="line">1) 1) (integer) 0</span><br><span class="line">   2) (integer) 4095</span><br><span class="line">   3) 1) &quot;192.168.10.3&quot;</span><br><span class="line">      2) (integer) 6379</span><br><span class="line">2) 1) (integer) 12288</span><br><span class="line">   2) (integer) 16383</span><br><span class="line">   3) 1) &quot;192.168.10.5&quot;</span><br><span class="line">      2) (integer) 6379</span><br></pre></td></tr></table></figure><p>如果某一个实例上有太多的 Slot，我们就可以使用迁移命令把这些 Slot 迁移到其它实例上。在 Redis Cluster 中，我们可以使用 3 个命令完成 Slot 迁移。</p><ol><li>CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例。</li><li>CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key。</li><li>MIGRATE：把一个 key 从源实例实际迁移到目标实例。我来借助一个例子，带你了解下这三个命令怎么用。</li></ol><p>我来借助一个例子，带你了解下这三个命令怎么用。假设我们要把 Slot 300 从源实例（ID 为 3）迁移到目标实例（ID 为 5），那要怎么做呢？</p><p>实际上，我们可以分成 5 步。</p><p>第 1 步，我们先在目标实例 5 上执行下面的命令，将 Slot 300 的源实例设置为实例 3，表示要从实例 3 上迁入 Slot 300。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLUSTER SETSLOT 300 IMPORTING 3</span><br></pre></td></tr></table></figure><p>第 2 步，在源实例 3 上，我们把 Slot 300 的目标实例设置为 5，这表示，Slot 300 要迁出到实例 5 上，如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLUSTER SETSLOT 300 MIGRATING 5</span><br></pre></td></tr></table></figure><p>第 3 步，从 Slot 300 中获取 100 个 key。因为 Slot 中的 key 数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移 key。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLUSTER GETKEYSINSLOT 300 100</span><br></pre></td></tr></table></figure><p>第 4 步，我们把刚才获取的 100 个 key 中的 key1 迁移到目标实例 5 上（IP 为 192.168.10.5），同时把要迁入的数据库设置为 0 号数据库，把迁移的超时时间设置为 timeout。我们重复执行 MIGRATE 命令，把 100 个 key 都迁移完。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MIGRATE 192.168.10.5 6379 key1 0 timeout</span><br></pre></td></tr></table></figure><p>最后，我们重复执行第 3 和第 4 步，直到 Slot 中的所有 key 都迁移完成。</p><p>从 Redis 3.0.6 开始，你也可以使用 KEYS 选项，一次迁移多个 key（key1、2、3），这样可以提升迁移效率。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MIGRATE 192.168.10.5 6379 &quot;&quot; 0 timeout KEYS key1 key2 key3</span><br></pre></td></tr></table></figure><p>对于 Codis 来说，我们可以执行下面的命令进行数据迁移。其中，我们把 dashboard 组件的连接地址设置为 ADDR，并且把 Slot 300 迁移到编号为 6 的 codis server group 上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">codis-admin --dashboard=ADDR -slot-action --create --sid=300 --gid=6</span><br></pre></td></tr></table></figure><p>除了 bigkey 和 Slot 分配不均衡会导致数据量倾斜，还有一个导致倾斜的原因，就是使用了 Hash Tag 进行数据切片。</p><h2 id="Hash-Tag-导致倾斜">Hash Tag 导致倾斜</h2><p>Hash Tag 是指加在键值对 key 中的一对花括号{}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。</p><p>举个例子，假设 key 是 user:profile:3231，我们把其中的 3231 作为 Hash Tag，此时，key 就变成了 user:profile:{3231}。当客户端计算这个 key 的 CRC16 值时，就只会计算 3231 的 CRC16 值。</p><p>否则，客户端会计算整个“user:profile:3231”的 CRC16 值。使用 Hash Tag 的好处是，如果不同 key 的 Hash Tag 内容都是一样的，那么，这些 key 对应的数据会被映射到同一个 Slot 中，同时会被分配到同一个实例上。</p><p>下面这张表就显示了使用 Hash Tag 后，数据被映射到相同 Slot 的情况，你可以看下。</p><p><img data-src="/images/data-distribution-optimization-how-to-deal-with-data-skewness/2.webp" alt></p><p>其中，user:profile:{3231}和 user:order:{3231}的 Hash Tag 一样，都是 3231，它们的 CRC16 计算值对 16384 取模后的值也是一样的，所以就对应映射到了相同的 Slot 1024 中。user:profile:{5328}和 user:order:{5328}也是相同的映射结果。</p><p>那么，Hash Tag 一般用在什么场景呢？其实，它主要是用在 Redis Cluster 和 Codis 中，支持事务操作和范围查询。因为 Redis Cluster 和 Codis 本身并不支持跨实例的事务操作和范围查询，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果。</p><p>这样操作起来非常麻烦，所以，我们可以使用 Hash Tag 把要执行事务操作或是范围查询的数据映射到同一个实例上，这样就能很轻松地实现事务或范围查询了。</p><p>但是，使用 Hash Tag 的潜在问题，就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡。那么，该怎么应对这种问题呢？我们就需要在范围查询、事务执行的需求和数据倾斜带来的访问压力之间，进行取舍了。</p><p>我的建议是，如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用 Hash Tag 进行数据切片。因为事务和范围查询都还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用。</p><p>好了，到这里，我们完整地了解了数据量倾斜的原因以及应对方法。接下来，我们再来看数据访问倾斜的原因和应对方法。</p><h2 id="数据访问倾斜的成因和应对方法">数据访问倾斜的成因和应对方法</h2><p>发生数据访问倾斜的根本原因，就是实例上存在热点数据（比如新闻应用中的热点新闻内容、电商促销活动中的热门商品信息，等等）。</p><p>一旦热点数据被存在了某个实例中，那么，这个实例的请求访问量就会远高于其它实例，面临巨大的访问压力，如下图所示：</p><p><img data-src="/images/data-distribution-optimization-how-to-deal-with-data-skewness/3.webp" alt></p><p>那么，我们该如何应对呢？</p><p>和数据量倾斜不同，热点数据通常是一个或几个数据，所以，直接重新分配 Slot 并不能解决热点数据的问题。</p><p>通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。</p><p>这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的 key 又不一样，会被映射到不同的 Slot 中。在给这些 Slot 分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。</p><p>这里，有个地方需要注意下，**热点数据多副本方法只能针对只读的热点数据。**如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。</p><p>对于有读有写的热点数据，我们就要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力。</p><h1>小结</h1><p>这节课，我向你介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。</p><p>造成数据量倾斜的原因主要有三个：</p><ol><li>数据中有 bigkey，导致某个实例的数据量增加；</li><li>Slot 手工分配不均，导致某个或某些实例上有大量数据；</li><li>使用了 Hash Tag，导致数据集中到某些实例上。</li></ol><p>而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。</p><p>为了应对数据倾斜问题，我给你介绍了四个方法，也分别对应了造成数据倾斜的四个原因。我把它们总结在下表中，你可以看下。</p><p><img data-src="/images/data-distribution-optimization-how-to-deal-with-data-skewness/4.webp" alt></p><p>当然，如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。Redis Cluster 和 Codis 集群都提供了查看 Slot 分配和手工迁移 Slot 的命令，你可以把它们应用起来。</p><p>最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的 Slot。</p>]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Redis</tag>
        <tag>Optimization</tag>
        <tag>Data</tag>
        <tag>Skewness</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis的使用规范小建议</title>
    <url>/suggestion-for-redis-usage-standards.html</url>
    <content><![CDATA[<p>Redis 核心技术与实战 笔记<br>作者： 蒋德钧</p><a id="more"></a><p>毕竟，高性能和节省内存，是我们的两个目标，只有规范地使用Redis，才能真正实现这两个目标。如果说之前的内容教会了你怎么用，那么今天的内容，就是帮助你用好Redis，尽量不出错。</p><p>好了，话不多说，我们来看下键值对的使用规范。</p><h1>键值对使用规范</h1><p>关于键值对的使用规范，我主要想和你说两个方面：</p><ul><li>key 的命名规范，只有命名规范，才能提供可读性强、可维护性好的 key，方便日常管理；</li><li>value 的设计规范，包括避免bigkey、选择高效序列化方法和压缩方法、使用整数对象共享池、数据类型选择。</li></ul><h2 id="规范一：key-的命名规范">规范一：key 的命名规范</h2><p>一个 Redis 实例默认可以支持 16 个数据库，我们可以把不同的业务数据分散保存到不同的数据库中。</p><p>但是，在使用不同数据库时，客户端需要使用 SELECT 命令进行数据库切换，相当于增加了一个额外的操作。</p><p>其实，我们可以通过合理命名 key，减少这个操作。具体的做法是，<font color="DeepPink"><strong>把业务名作为前缀，然后用冒号分隔，再加上具体的业务数据名。</strong></font>这样一来，我们可以通过 key 的前缀区分不同的业务数据，就不用在多个数据库间来回切换了。</p><p>我给你举个简单的小例子，看看具体怎么命名 key。</p><p>比如说，如果我们要统计网页的独立访客量，就可以用下面的代码设置 key，这就表示，这个数据对应的业务是统计 unique visitor（独立访客量），而且对应的页面编号是 1024。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">uv:page:1024</span><br></pre></td></tr></table></figure><p>这里有一个地方需要注意一下。key 本身是字符串，底层的数据结构是 SDS。SDS 结构中会包含字符串长度、分配空间大小等元数据信息。从 Redis 3.2 版本开始，<strong>当 key 字符串的长度增加时，SDS 中的元数据也会占用更多内存空间。</strong></p><p>所以，我们在设置 key 的名称时，要注意控制 key 的长度。否则，如果 key 很长的话，就会消耗较多内存空间，而且，SDS 元数据也会额外消耗一定的内存空间。</p><p>SDS 结构中的字符串长度和元数据大小的对应关系如下表所示：</p><p><img data-src="/images/suggestion-for-redis-usage-standards/1.webp" alt></p><p>为了减少 key 占用的内存空间，我给你一个小建议：对于业务名或业务数据名，可以使用相应的英文单词的首字母表示，（比如 user 用 u 表示，message 用 m），或者是用缩写表示（例如 unique visitor 使用 uv）。</p><h2 id="规范二：避免使用-bigkey">规范二：避免使用 bigkey</h2><p>Redis 是使用单线程读写数据，bigkey 的读写操作会阻塞线程，降低 Redis 的处理效率。所以，在应用 Redis 时，关于 value 的设计规范，非常重要的一点就是避免 bigkey。</p><p>bigkey 通常有两种情况。</p><ul><li><p>情况一：键值对的值大小本身就很大，例如 value 为 1MB 的 String 类型数据。为了避免 String 类型的 bigkey，在业务层，<strong>我们要尽量把 String 类型的数据大小控制在 10KB 以下。</strong></p></li><li><p>情况二：键值对的值是集合类型，集合元素个数非常多，例如包含 100 万个元素的 Hash 集合类型数据。为了避免集合类型的 bigkey，我给你的设计规范建议是，<strong>尽量把集合类型的元素个数控制在 1 万以下</strong>。</p></li></ul><p>当然，这些建议只是为了尽量避免 bigkey，如果业务层的 String 类型数据确实很大，我们还可以通过数据压缩来减小数据大小；如果集合类型的元素的确很多，我们可以将一个大集合拆分成多个小集合来保存。</p><p>这里，还有个地方需要注意下，Redis 的 4 种集合类型 List、Hash、Set 和 Sorted Set，在集合元素个数小于一定的阈值时，会使用内存紧凑型的底层数据结构进行保存，从而节省内存。例如，假设 Hash 集合的 hash-max-ziplist-entries 配置项是 1000，如果 Hash 集合元素个数不超过 1000，就会使用 ziplist 保存数据。</p><p>紧凑型数据结构虽然可以节省内存，但是会在一定程度上导致数据的读写性能下降。所以，如果业务应用更加需要保持高性能访问，而不是节省内存的话，在不会导致 bigkey 的前提下，你就不用刻意控制集合元素个数了。</p><h2 id="规范三：使用高效序列化方法和压缩方法">规范三：使用高效序列化方法和压缩方法</h2><p>为了节省内存，除了采用紧凑型数据结构以外，我们还可以遵循两个使用规范，分别是使用高效的序列化方法和压缩方法，这样可以减少 value 的大小。</p><p>Redis 中的字符串都是使用二进制安全的字节数组来保存的，所以，我们可以把业务数据序列化成二进制数据写入到 Redis 中。</p><p>但是，<strong>不同的序列化方法，在序列化速度和数据序列化后的占用内存空间这两个方面，效果是不一样的</strong>。比如说，protostuff 和 kryo 这两种序列化方法，就要比 Java 内置的序列化方法（java-build-in-serializer）效率更高。</p><p>此外，业务应用有时会使用字符串形式的 XML 和 JSON 格式保存数据。</p><p>这样做的好处是，这两种格式的可读性好，便于调试，不同的开发语言都支持这两种格式的解析。</p><p><strong>缺点在于，XML 和 JSON 格式的数据占用的内存空间比较大。为了避免数据占用过大的内存空间，我建议使用压缩工具（例如 snappy 或 gzip），把数据压缩后再写入 Redis，这样就可以节省内存空间了。</strong></p><h2 id="规范四：使用整数对象共享池">规范四：使用整数对象共享池</h2><p>整数是常用的数据类型，Redis 内部维护了 0 到 9999 这 1 万个整数对象，并把这些整数作为一个共享池使用。</p><p>换句话说，如果一个键值对中有 0 到 9999 范围的整数，Redis 就不会为这个键值对专门创建整数对象了，而是会复用共享池中的整数对象。</p><p>这样一来，即使大量键值对保存了 0 到 9999 范围内的整数，在 Redis 实例中，其实只保存了一份整数对象，可以节省内存空间。</p><p>基于这个特点，我建议你，在满足业务数据需求的前提下，能用整数时就尽量用整数，这样可以节省实例内存。</p><p>那什么时候不能用整数对象共享池呢？主要有两种情况。</p><p>第一种情况是，<strong>如果 Redis 中设置了 maxmemory，而且启用了 LRU 策略（allkeys-lru 或 volatile-lru 策略），那么，整数对象共享池就无法使用了。</strong> 这是因为，LRU 策略需要统计每个键值对的使用时间，如果不同的键值对都共享使用一个整数对象，LRU 策略就无法进行统计了。</p><p>第二种情况是，如果集合类型数据采用 ziplist 编码，而集合元素是整数，这个时候，也不能使用共享池。因为 ziplist 使用了紧凑型内存结构，判断整数对象的共享情况效率低。</p><p>好了，到这里，我们了解了和键值对使用相关的四种规范，遵循这四种规范，最直接的好处就是可以节省内存空间。接下来，我们再来了解下，在实际保存数据时，该遵循哪些规范。</p><h1>数据保存规范</h1><h2 id="规范一：使用-Redis-保存热数据">规范一：使用 Redis 保存热数据</h2><p>为了提供高性能访问，Redis 是把所有数据保存到内存中的。</p><p>虽然 Redis 支持使用 RDB 快照和 AOF 日志持久化保存数据，但是，这两个机制都是用来提供数据可靠性保证的，并不是用来扩充数据容量的。而且，内存成本本身就比较高，如果把业务数据都保存在 Redis 中，会带来较大的内存成本压力。</p><p>所以，一般来说，在实际应用 Redis 时，我们会更多地把它作为缓存保存热数据，这样既可以充分利用 Redis 的高性能特性，还可以把宝贵的内存资源用在服务热数据上，就是俗话说的“好钢用在刀刃上”。</p><h2 id="规范二：不同的业务数据分实例存储">规范二：不同的业务数据分实例存储</h2><p>虽然我们可以使用 key 的前缀把不同业务的数据区分开，但是，如果所有业务的数据量都很大，而且访问特征也不一样，我们把这些数据保存在同一个实例上时，这些数据的操作就会相互干扰。</p><p>你可以想象这样一个场景：假如数据采集业务使用 Redis 保存数据时，以写操作为主，而用户统计业务使用 Redis 时，是以读查询为主，如果这两个业务数据混在一起保存，读写操作相互干扰，肯定会导致业务响应变慢。</p><p>那么，我建议你<font color="DeepPink"><strong>把不同的业务数据放到不同的 Redis 实例中。</strong></font>这样一来，既可以避免单实例的内存使用量过大，也可以避免不同业务的操作相互干扰。</p><p>规范三：在数据保存时，要设置过期时间</p><p>对于 Redis 来说，内存是非常宝贵的资源，而且，Redis 通常用于保存热数据。热数据一般都有使用的时效性。所以，在数据保存时，我建议你根据业务使用数据的时长，设置数据的过期时间。</p><p>不然的话，写入 Redis 的数据会一直占用内存，如果数据持续增多，就可能达到机器的内存上限，造成内存溢出，导致服务崩溃。</p><h2 id="规范四：控制-Redis-实例的容量">规范四：控制 Redis 实例的容量</h2><p><strong>Redis 单实例的内存大小都不要太大，根据我自己的经验值，建议你设置在 2~6GB 。这样一来，无论是 RDB 快照，还是主从集群进行数据同步，都能很快完成，不会阻塞正常请求的处理。</strong></p><h1>命令使用规范</h1><p>最后，我们再来看下在使用 Redis 命令时要遵守什么规范。</p><h2 id="规范一：线上禁用部分命令">规范一：线上禁用部分命令</h2><p>Redis 是单线程处理请求操作，如果我们执行一些涉及大量操作、耗时长的命令，就会严重阻塞主线程，导致其它请求无法得到正常处理，这类命令主要有 3 种。</p><ul><li>KEYS，按照键值对的 key 内容进行匹配，返回符合匹配条件的键值对，该命令需要对 Redis 的全局哈希表进行全表扫描，严重阻塞 Redis 主线程；</li><li>FLUSHALL，删除 Redis 实例上的所有数据，如果数据量很大，会严重阻塞 Redis 主线程；</li><li>FLUSHDB，删除当前数据库中的数据，如果数据量很大，同样会阻塞 Redis 主线程。</li></ul><p>所以，我们在线上应用 Redis 时，就需要禁用这些命令。<strong>具体的做法是，管理员用 rename-command 命令在配置文件中对这些命令进行重命名，让客户端无法使用这些命令。</strong></p><p>当然，你还可以使用其它命令替代这 3 个命令。</p><ul><li>对于 KEYS 命令来说，你可以用 SCAN 命令代替 KEYS 命令，分批返回符合条件的键值对，避免造成主线程阻塞；</li><li>对于 FLUSHALL、FLUSHDB 命令来说，你可以加上 ASYNC 选项，让这两个命令使用后台线程异步删除数据，可以避免阻塞主线程。</li></ul><h2 id="规范二：慎用-MONITOR-命令">规范二：慎用 MONITOR 命令</h2><p>Redis 的 MONITOR 命令在执行后，会持续输出监测到的各个命令操作，所以，我们通常会用 MONITOR 命令返回的结果，检查命令的执行情况。</p><p>但是，MONITOR 命令会把监控到的内容持续写入输出缓冲区。如果线上命令的操作很多，输出缓冲区很快就会溢出了，这就会对 Redis 性能造成影响，甚至引起服务崩溃。</p><p>所以，除非十分需要监测某些命令的执行（例如，Redis 性能突然变慢，我们想查看下客户端执行了哪些命令），你可以偶尔在短时间内使用下 MONITOR 命令，否则，我建议你不要使用 MONITOR 命令。</p><h2 id="规范三：慎用全量操作命令">规范三：慎用全量操作命令</h2><p>对于集合类型的数据来说，如果想要获得集合中的所有元素，一般不建议使用全量操作的命令（例如 Hash 类型的 HGETALL、Set 类型的 SMEMBERS）。这些操作会对 Hash 和 Set 类型的底层数据结构进行全量扫描，如果集合类型数据较多的话，就会阻塞 Redis 主线程。</p><p>如果想要获得集合类型的全量数据，我给你三个小建议。</p><ul><li>第一个建议是，你可以使用 SSCAN、HSCAN 命令分批返回集合中的数据，减少对主线程的阻塞。</li><li>第二个建议是，你可以化整为零，把一个大的 Hash 集合拆分成多个小的 Hash 集合。这个操作对应到业务层，就是对业务数据进行拆分，按照时间、地域、用户 ID 等属性把一个大集合的业务数据拆分成多个小集合数据。例如，当你统计用户的访问情况时，就可以按照天的粒度，把每天的数据作为一个 Hash 集合。</li><li>最后一个建议是，如果集合类型保存的是业务数据的多个属性，而每次查询时，也需要返回这些属性，那么，你可以使用 String 类型，将这些属性序列化后保存，每次直接返回 String 数据就行，不用再对集合类型做全量扫描了。</li></ul><h1>小结</h1><p>这节课，我围绕 Redis 应用时的高性能访问和节省内存空间这两个目标，分别在键值对使用、命令使用和数据保存三方面向你介绍了 11 个规范。</p><p>我按照强制、推荐、建议这三个类别，把这些规范分了下类，如下表所示：</p><p><img data-src="/images/suggestion-for-redis-usage-standards/2.webp" alt></p><p>我来解释一下这 3 个类别的规范。</p><ul><li>强制类别的规范：这表示，如果不按照规范内容来执行，就会给 Redis 的应用带来极大的负面影响，例如性能受损。</li><li>推荐类别的规范：这个规范的内容能有效提升性能、节省内存空间，或者是增加开发和运维的便捷性，你可以直接应用到实践中。</li><li>建议类别的规范：这类规范内容和实际业务应用相关，我只是从我的经历或经验给你一个建议，你需要结合自己的业务场景参考使用。</li></ul><p>我再多说一句，你一定要熟练掌握这些使用规范，并且真正地把它们应用到你的 Redis 使用场景中，提高 Redis 的使用效率。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">我总结的 Redis 使用规范分为两大方面，主要包括业务层面和运维层面。</span><br><span class="line"></span><br><span class="line">业务层面主要面向的业务开发人员：</span><br><span class="line"></span><br><span class="line">1、key 的长度尽量短，节省内存空间</span><br><span class="line">2、避免 bigkey，防止阻塞主线程</span><br><span class="line">3、4.0+版本建议开启 lazy-free</span><br><span class="line">4、把 Redis 当作缓存使用，设置过期时间</span><br><span class="line">5、不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE</span><br><span class="line">6、查询数据尽量不一次性查询全量，写入大量数据建议分多批写入</span><br><span class="line">7、批量操作建议 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET</span><br><span class="line">8、禁止使用 KEYS/FLUSHALL/FLUSHDB 命令</span><br><span class="line">9、避免集中过期 key</span><br><span class="line">10、根据业务场景选择合适的淘汰策略</span><br><span class="line">11、使用连接池操作 Redis，并设置合理的参数，避免短连接</span><br><span class="line">12、只使用 db0，减少 SELECT 命令的消耗</span><br><span class="line">13、读请求量很大时，建议读写分离，写请求量很大，建议使用切片集群</span><br><span class="line"></span><br><span class="line">运维层面主要面向的是 DBA 运维人员：</span><br><span class="line"></span><br><span class="line">1、按业务线部署实例，避免多个业务线混合部署，出问题影响其他业务</span><br><span class="line">2、保证机器有足够的 CPU、内存、带宽、磁盘资源</span><br><span class="line">3、建议部署主从集群，并分布在不同机器上，slave 设置为 readonly</span><br><span class="line">4、主从节点所部署的机器各自独立，尽量避免交叉部署，对从节点做维护时，不会影响到主节点</span><br><span class="line">5、推荐部署哨兵集群实现故障自动切换，哨兵节点分布在不同机器上</span><br><span class="line">6、提前做好容量规划，防止主从全量同步时，实例使用内存突增导致内存不足</span><br><span class="line">7、做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能</span><br><span class="line">8、实例设置最大连接数，防止过多客户端连接导致实例负载过高，影响性能</span><br><span class="line">9、单个实例内存建议控制在 10G 以下，大实例在主从全量同步、备份时有阻塞风险</span><br><span class="line">10、设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多需及时报警</span><br><span class="line">11、设置合理的 repl-backlog，降低主从全量同步的概率</span><br><span class="line">12、设置合理的 slave client-output-buffer-limit，避免主从复制中断情况发生</span><br><span class="line">13、推荐在从节点上备份，不影响主节点性能</span><br><span class="line">14、不开启 AOF 或开启 AOF 配置为每秒刷盘，避免磁盘 IO 拖慢 Redis 性能</span><br><span class="line">15、调整 maxmemory 时，注意主从节点的调整顺序，顺序错误会导致主从数据不一致</span><br><span class="line">16、对实例部署监控，采集 INFO 信息时采用长连接，避免频繁的短连接</span><br><span class="line">17、做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec，这些指标短时突增可能会有阻塞风险</span><br><span class="line">18、扫描线上实例时，记得设置休眠时间，避免过高 OPS 产生性能抖动</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Redis</tag>
        <tag>Standards</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch文件存储</title>
    <url>/elasticsearch-file-storage.html</url>
    <content><![CDATA[<blockquote><p>分析Elasticsearch Index文件是如何存储的？<br>主要是想看一下FST文件是以什么粒度创建的？</p></blockquote><a id="more"></a><p>首先通过kibana找一个索引的shard，此处咱们就以logstash-2023.05.30索引为例</p><p>查看下shard分布情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /_cat/shards/logstash-2023.05.30?v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">index               shard prirep state      docs   store ip             node</span><br><span class="line">logstash-2023.05.30 3     p      STARTED 1520736 408.1mb 10.138.40.73  10.138.40.73-node1</span><br><span class="line">logstash-2023.05.30 5     p      STARTED 1520888 409.9mb 10.138.40.74  10.138.40.74-node1</span><br><span class="line">logstash-2023.05.30 6     p      STARTED 1518331 408.2mb 10.138.40.221 10.138.40.221-node1</span><br><span class="line">logstash-2023.05.30 4     p      STARTED 1518186 409.3mb 10.138.204.194 10.138.204.194-node1</span><br><span class="line">logstash-2023.05.30 1     p      STARTED 1519231 408.8mb 10.138.40.220 10.138.40.220-node1</span><br><span class="line">logstash-2023.05.30 2     p      STARTED 1519970 409.9mb 10.138.204.195 10.138.204.195-node1</span><br><span class="line">logstash-2023.05.30 0     p      STARTED 1520024 410.6mb 10.138.204.193 10.138.204.193-node1</span><br></pre></td></tr></table></figure><p>这里以位于10.138.204.193上的shard 0为例分析。</p><p>要找到存储目录先要找到index的id</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /logstash-2023.05.30/_settings</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;logstash-2023.05.30&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;codec&quot; : &quot;best_compression&quot;,</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;refresh_interval&quot; : &quot;60s&quot;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;7&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;logstash-2023.05.30&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1685376005206&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;0&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;FYWtFGTIS2CLB8yJhFXG9g&quot;,//这里就是索引的id</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>登录机器，找到存储索引文件的对应目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/data3/10.138.204.193-node1/nodes/0/indices/FYWtFGTIS2CLB8yJhFXG9g</span><br></pre></td></tr></table></figure><p>展开一下该目录下的文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@prd-paas-es-01:/data3/10.138.204.193-node1/nodes/0/indices/FYWtFGTIS2CLB8yJhFXG9g# tree -C -s</span><br><span class="line">.</span><br><span class="line">├── [       4096]  0</span><br><span class="line">│   ├── [      20480]  index</span><br><span class="line">│   │   ├── [        158]  _17f.fdm</span><br><span class="line">│   │   ├── [   25578562]  _17f.fdt</span><br><span class="line">│   │   ├── [       1939]  _17f.fdx</span><br><span class="line">│   │   ├── [       4636]  _17f.fnm</span><br><span class="line">│   │   ├── [    7981735]  _17f.kdd</span><br><span class="line">│   │   ├── [      20898]  _17f.kdi</span><br><span class="line">│   │   ├── [        716]  _17f.kdm</span><br><span class="line">│   │   ├── [    7945983]  _17f_Lucene80_0.dvd</span><br><span class="line">│   │   ├── [       3916]  _17f_Lucene80_0.dvm</span><br><span class="line">│   │   ├── [    6230127]  _17f_Lucene84_0.doc</span><br><span class="line">│   │   ├── [    3875001]  _17f_Lucene84_0.pos</span><br><span class="line">│   │   ├── [    7448815]  _17f_Lucene84_0.tim</span><br><span class="line">│   │   ├── [     108786]  _17f_Lucene84_0.tip</span><br><span class="line">│   │   ├── [       1637]  _17f_Lucene84_0.tmd</span><br><span class="line">│   │   ├── [        593]  _17f.si</span><br><span class="line">│   │   ├── [        158]  _3uv.fdm</span><br><span class="line">│   │   ├── [   33652243]  _3uv.fdt</span><br><span class="line">│   │   ├── [       2555]  _3uv.fdx</span><br><span class="line">│   │   ├── [       4636]  _3uv.fnm</span><br><span class="line">│   │   ├── [   10520395]  _3uv.kdd</span><br><span class="line">│   │   ├── [      27689]  _3uv.kdi</span><br><span class="line">│   │   ├── [        716]  _3uv.kdm</span><br><span class="line">│   │   ├── [   10573208]  _3uv_Lucene80_0.dvd</span><br><span class="line">│   │   ├── [       3916]  _3uv_Lucene80_0.dvm</span><br><span class="line">│   │   ├── [    8298061]  _3uv_Lucene84_0.doc</span><br><span class="line">│   │   ├── [    5154427]  _3uv_Lucene84_0.pos</span><br><span class="line">│   │   ├── [    9716222]  _3uv_Lucene84_0.tim</span><br><span class="line">│   │   ├── [     142063]  _3uv_Lucene84_0.tip</span><br><span class="line">│   │   ├── [       1620]  _3uv_Lucene84_0.tmd</span><br><span class="line">│   │   ├── [        593]  _3uv.si</span><br><span class="line">│   │   ├── [        158]  _5bg.fdm</span><br><span class="line">│   │   ├── [   16433011]  _5bg.fdt</span><br><span class="line">│   │   ├── [       1259]  _5bg.fdx</span><br><span class="line">│   │   ├── [       4636]  _5bg.fnm</span><br><span class="line">│   │   ├── [    5158094]  _5bg.kdd</span><br><span class="line">│   │   ├── [      13396]  _5bg.kdi</span><br><span class="line">│   │   ├── [        716]  _5bg.kdm</span><br><span class="line">│   │   ├── [    5140762]  _5bg_Lucene80_0.dvd</span><br><span class="line">│   │   ├── [       3916]  _5bg_Lucene80_0.dvm</span><br><span class="line">│   │   ├── [    4005897]  _5bg_Lucene84_0.doc</span><br><span class="line">│   │   ├── [    2583880]  _5bg_Lucene84_0.pos</span><br><span class="line">│   │   ├── [    4873082]  _5bg_Lucene84_0.tim</span><br><span class="line">│   │   ├── [      70979]  _5bg_Lucene84_0.tip</span><br><span class="line">│   │   ├── [       1593]  _5bg_Lucene84_0.tmd</span><br><span class="line">│   │   ├── [        593]  _5bg.si</span><br><span class="line">│   │   ├── [        158]  _60h.fdm</span><br><span class="line">│   │   ├── [   24664753]  _60h.fdt</span><br><span class="line">│   │   ├── [       1886]  _60h.fdx</span><br><span class="line">│   │   ├── [       4636]  _60h.fnm</span><br><span class="line">│   │   ├── [    7640438]  _60h.kdd</span><br><span class="line">│   │   ├── [      19996]  _60h.kdi</span><br><span class="line">│   │   ├── [        716]  _60h.kdm</span><br><span class="line">│   │   ├── [    7754954]  _60h_Lucene80_0.dvd</span><br><span class="line">│   │   ├── [       3916]  _60h_Lucene80_0.dvm</span><br><span class="line">│   │   ├── [    6147241]  _60h_Lucene84_0.doc</span><br><span class="line">│   │   ├── [    3998559]  _60h_Lucene84_0.pos</span><br><span class="line">│   │   ├── [    7254035]  _60h_Lucene84_0.tim</span><br><span class="line">│   │   ├── [     105673]  _60h_Lucene84_0.tip</span><br><span class="line">│   │   ├── [       1719]  _60h_Lucene84_0.tmd</span><br><span class="line">│   │   ├── [        593]  _60h.si</span><br><span class="line">│   │   ├── [        200]  _7jq.fdm</span><br><span class="line">│   │   ├── [   63208093]  _7jq.fdt</span><br><span class="line">│   │   ├── [       4692]  _7jq.fdx</span><br><span class="line">│   │   ├── [       4636]  _7jq.fnm</span><br><span class="line">│   │   ├── [   19306117]  _7jq.kdd</span><br><span class="line">│   │   ├── [      51562]  _7jq.kdi</span><br><span class="line">│   │   ├── [        716]  _7jq.kdm</span><br><span class="line">│   │   ├── [   20228561]  _7jq_Lucene80_0.dvd</span><br><span class="line">│   │   ├── [       3916]  _7jq_Lucene80_0.dvm</span><br><span class="line">│   │   ├── [   15606568]  _7jq_Lucene84_0.doc</span><br><span class="line">│   │   ├── [    9581341]  _7jq_Lucene84_0.pos</span><br><span class="line">│   │   ├── [   17383473]  _7jq_Lucene84_0.tim</span><br><span class="line">│   │   ├── [     272615]  _7jq_Lucene84_0.tip</span><br><span class="line">│   │   ├── [       1592]  _7jq_Lucene84_0.tmd</span><br><span class="line">│   │   ├── [        593]  _7jq.si</span><br><span class="line">│   │   ├── [        437]  _82w.cfe</span><br><span class="line">│   │   ├── [    4489379]  _82w.cfs</span><br><span class="line">│   │   ├── [        408]  _82w.si</span><br><span class="line">│   │   ├── [        437]  _87w.cfe</span><br><span class="line">│   │   ├── [    4932636]  _87w.cfs</span><br><span class="line">│   │   ├── [        408]  _87w.si</span><br><span class="line">│   │   ├── [        437]  _8ao.cfe</span><br><span class="line">│   │   ├── [   13905317]  _8ao.cfs</span><br><span class="line">│   │   ├── [        408]  _8ao.si</span><br><span class="line">│   │   ├── [        437]  _8ls.cfe</span><br><span class="line">│   │   ├── [   20181047]  _8ls.cfs</span><br><span class="line">│   │   ├── [        408]  _8ls.si</span><br><span class="line">│   │   ├── [        437]  _8nq.cfe</span><br><span class="line">│   │   ├── [    1234712]  _8nq.cfs</span><br><span class="line">│   │   ├── [        408]  _8nq.si</span><br><span class="line">│   │   ├── [        437]  _8oa.cfe</span><br><span class="line">│   │   ├── [     872798]  _8oa.cfs</span><br><span class="line">│   │   ├── [        408]  _8oa.si</span><br><span class="line">│   │   ├── [        437]  _8pp.cfe</span><br><span class="line">│   │   ├── [    1593677]  _8pp.cfs</span><br><span class="line">│   │   ├── [        408]  _8pp.si</span><br><span class="line">│   │   ├── [        437]  _8r5.cfe</span><br><span class="line">│   │   ├── [     914008]  _8r5.cfs</span><br><span class="line">│   │   ├── [        408]  _8r5.si</span><br><span class="line">│   │   ├── [        437]  _8rf.cfe</span><br><span class="line">│   │   ├── [     940473]  _8rf.cfs</span><br><span class="line">│   │   ├── [        408]  _8rf.si</span><br><span class="line">│   │   ├── [        437]  _8rz.cfe</span><br><span class="line">│   │   ├── [    1315312]  _8rz.cfs</span><br><span class="line">│   │   ├── [        408]  _8rz.si</span><br><span class="line">│   │   ├── [        437]  _8s9.cfe</span><br><span class="line">│   │   ├── [    1121692]  _8s9.cfs</span><br><span class="line">│   │   ├── [        408]  _8s9.si</span><br><span class="line">│   │   ├── [        437]  _8sk.cfe</span><br><span class="line">│   │   ├── [     243476]  _8sk.cfs</span><br><span class="line">│   │   ├── [        408]  _8sk.si</span><br><span class="line">│   │   ├── [       1678]  segments_6</span><br><span class="line">│   │   └── [          0]  write.lock</span><br><span class="line">│   ├── [       4096]  _state</span><br><span class="line">│   │   ├── [        186]  retention-leases-2865.st</span><br><span class="line">│   │   └── [        125]  state-0.st</span><br><span class="line">│   └── [       4096]  translog</span><br><span class="line">│       ├── [         55]  translog-29.tlog</span><br><span class="line">│       └── [         88]  translog.ckp</span><br><span class="line">└── [       4096]  _state</span><br><span class="line">    └── [       1230]  state-2.st</span><br><span class="line"></span><br><span class="line">5 directories, 118 files</span><br></pre></td></tr></table></figure><p>有了文件信息，我们再来看下，segment信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /logstash-2023.05.30/_segments</span><br><span class="line"></span><br><span class="line">// 这里为了直观 只展示shard 0对应的segment</span><br><span class="line">&#123;</span><br><span class="line">	&quot;_shards&quot;: &#123;</span><br><span class="line">		&quot;total&quot;: 7,</span><br><span class="line">		&quot;successful&quot;: 7,</span><br><span class="line">		&quot;failed&quot;: 0</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;indices&quot;: &#123;</span><br><span class="line">		&quot;logstash-2023.05.30&quot;: &#123;</span><br><span class="line">			&quot;shards&quot;: &#123;</span><br><span class="line">				&quot;0&quot;: [</span><br><span class="line">					&#123;</span><br><span class="line">						&quot;routing&quot;: &#123;</span><br><span class="line">							&quot;state&quot;: &quot;STARTED&quot;,</span><br><span class="line">							&quot;primary&quot;: true,</span><br><span class="line">							&quot;node&quot;: &quot;4hEWcF8hRFWTEkQxlKQmqg&quot;</span><br><span class="line">						&#125;,</span><br><span class="line">						&quot;num_committed_segments&quot;: 17,</span><br><span class="line">						&quot;num_search_segments&quot;: 17,</span><br><span class="line">						&quot;segments&quot;: &#123;</span><br><span class="line">							&quot;_17f&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 1563,</span><br><span class="line">								&quot;num_docs&quot;: 210331,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 59203502,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: false,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_3uv&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 4999,</span><br><span class="line">								&quot;num_docs&quot;: 278411,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 78098502,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: false,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_5bg&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 6892,</span><br><span class="line">								&quot;num_docs&quot;: 132645,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 38291972,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: false,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_60h&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 7793,</span><br><span class="line">								&quot;num_docs&quot;: 199809,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 57599273,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: false,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_7jq&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 9782,</span><br><span class="line">								&quot;num_docs&quot;: 520420,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 145654675,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5204,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: false,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_82w&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 10472,</span><br><span class="line">								&quot;num_docs&quot;: 15416,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 4490224,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_87w&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 10652,</span><br><span class="line">								&quot;num_docs&quot;: 16837,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 4933481,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8ao&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 10752,</span><br><span class="line">								&quot;num_docs&quot;: 48855,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 13906162,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8ls&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11152,</span><br><span class="line">								&quot;num_docs&quot;: 70903,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 20181892,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 5140,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8nq&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11222,</span><br><span class="line">								&quot;num_docs&quot;: 3954,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 1235557,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6924,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8oa&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11242,</span><br><span class="line">								&quot;num_docs&quot;: 2785,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 873643,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6820,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8pp&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11293,</span><br><span class="line">								&quot;num_docs&quot;: 5194,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 1594522,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 7060,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8r5&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11345,</span><br><span class="line">								&quot;num_docs&quot;: 2936,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 914853,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6748,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8rf&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11355,</span><br><span class="line">								&quot;num_docs&quot;: 2920,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 941318,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6836,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8rz&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11375,</span><br><span class="line">								&quot;num_docs&quot;: 4304,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 1316157,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6820,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8s9&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11385,</span><br><span class="line">								&quot;num_docs&quot;: 3647,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 1122537,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 6892,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;,</span><br><span class="line">							&quot;_8sk&quot;: &#123;</span><br><span class="line">								&quot;generation&quot;: 11396,</span><br><span class="line">								&quot;num_docs&quot;: 657,</span><br><span class="line">								&quot;deleted_docs&quot;: 0,</span><br><span class="line">								&quot;size_in_bytes&quot;: 244321,</span><br><span class="line">								&quot;memory_in_bytes&quot;: 7620,</span><br><span class="line">								&quot;committed&quot;: true,</span><br><span class="line">								&quot;search&quot;: true,</span><br><span class="line">								&quot;version&quot;: &quot;8.8.2&quot;,</span><br><span class="line">								&quot;compound&quot;: true,</span><br><span class="line">								&quot;attributes&quot;: &#123;</span><br><span class="line">									&quot;Lucene87StoredFieldsFormat.mode&quot;: &quot;BEST_COMPRESSION&quot;</span><br><span class="line">								&#125;</span><br><span class="line">							&#125;</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">				]</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对比segment与shard目录中文件可以看出，两者是一一对应的。</p><p>看下es及对应lucene的版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;10.138.204.193-node1&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;XWDyVuo6TgK4yUp2XWD3lw&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.13.4&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;docker&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;c5f60e894ca0c61cdbae4f5a686d9f08bcefc942&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2021-07-14T18:33:36.673943207Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.8.2&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么shard目录中各种后缀的文件具体是什么含义呢？下面来看下</p><p><img data-src="/images/elasticsearch-file-storage/lucene_8.8.2_file_format.png" alt></p><blockquote><p>截图出处:<br><a href="https://lucene.apache.org/core/8_8_2/core/org/apache/lucene/codecs/lucene87/package-summary.html#package.description" target="_blank" rel="noopener">https://lucene.apache.org/core/8_8_2/core/org/apache/lucene/codecs/lucene87/package-summary.html#package.description</a></p></blockquote><p>从表格中可以看出与FST相关的文件后缀有:tip、tim,从这里就可以看出FST文件是以segment维度来创建的。</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Lucene</tag>
        <tag>Store</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]腾讯万亿级 Elasticsearch 内存效率提升解密</title>
    <url>/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption.html</url>
    <content><![CDATA[<p><strong>大家可以着重看下 FST 部分</strong></p><p>原文地址:<br><a href="https://cloud.tencent.com/developer/article/1636527" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1636527</a></p><a id="more"></a><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/1.png" alt></p><p>Elasticsearch( ES）是一款功能强大的开源分布式实时搜索引擎，在日志分析(主要应用场景）、企业级搜索、时序分析等领域有广泛应用，几乎是各大公司搜索分析引擎的开源首选方案。</p><p>Tencent ES 是内核级深度优化的 ES 分支，持续地进行高可用、高性能、低成本等全方位优化，已支撑的单集群规模达到千级节点、万亿级吞吐。Tencent ES 已在公司内部开源，同时也积极贡献开源社区，截止目前已向社区提交 PR 25+。</p><p>腾讯联合 Elastic 官方在腾讯云上提供了内核增强版 ES 云服务，支撑公司内部云、外部云、专有云达 60PB+ 的数据存储，服务 蘑菇街、知乎、B 站、凤凰网等业内头部客户。</p><p>本文主要介绍 Tencent ES 的主要优化点之一：零拷贝 内存 Off Heap，提升内存使用效率，降低存储成本。最终达到，在读写性能与源生逻辑一致的前提下，堆内存使用率降低 80%，单节点存储量从 5TB 提升至 50TB 的效果。</p><h1>问题：日志分析场景数据量大，ES 内存瓶颈导致存储成本较高</h1><p>上节提到，日志分析是 ES 的主要应用场景(占比60%），而日志数据的特点显著：</p><ul><li>数据量大，成本是主要诉求：我们大批线上大客户，数据量在几百 TB 甚至 PB 级，单集群占用几百台机器。如此规模的数据量，带来了较高的成本，甚至有些客户吐槽，日志的存储成本已超越产品自身的成本。</li><li>数据访问冷热特性明显：如下图所示，日志访问近多远少，历史极少访问却占用大量成本。</li></ul><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/2.png" alt></p><h2 id="分析：成本瓶颈在哪里：堆内存使用率过高">分析：成本瓶颈在哪里：堆内存使用率过高</h2><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/3.png" alt></p><p>我们对线上售卖的集群做硬件成本分析后，发现成本主要在磁盘和内存。</p><p>为了降低磁盘成本，我们采取冷热分离、Rollup、备份归档、数据裁剪等多种方式降成本。在冷热分离的集群，我们通过大容量的冷存储机型，来存储历史数据，使得磁盘成本下降 60% 左右。</p><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/4.png" alt></p><p>问题也随之而来：如上图所示，大容量的冷机型，存在磁盘使用率过低的问题( 40 % 以下），原因是堆内存使用率过高了( 70 % 左右），制约磁盘使用率无法提升。(其中单节点磁盘使用率 40%，约 13TB 左右，这已经是 Tencent ES 优化后的效果，源生只能支持到5 TB 左右）</p><p>所以，为了提升低成本的冷机型磁盘使用率，同时也为了降低内存成本，我们需要降低 ES 的堆内存使用率。</p><h2 id="堆内存使用率为什么会高？">堆内存使用率为什么会高？</h2><p>ES 是通过 JAVA 语言编写的，在介绍如何降低堆内存使用率之前，先了解下 JAVA 的堆内存：</p><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/5.png" alt></p><ul><li>堆内存就是由 JVM (JAVA虚拟机）管理的内存。建立在堆内存中的对象有生命周期管理机制，由垃圾回收机时自动回收过期对象占用的内存。</li><li>堆外内存是由用户程序管理的内存，堆外内存中的对象过期时，需要由用户代码显示释放。1.运营侧调整装箱策略能否解决问题？了解了 JAVA 堆内存后，我们看，能否通过调整运营策略来提升堆内存容量呢？</li><li>堆内存分配大一点行不行？<br>　超过32GB，指针压缩失效，内存浪费， 50GB堆内存性能与31GB接近且垃圾回收压力大，也影响性能</li><li>多节点部署提高堆内存总量是否可行？<br>　多节点部署，占用机器量更大，用户成本上升<br>　大客户节点数过多(几百个），集群元数据管理瓶颈，可用性下降<br>　反向推动云上用户拆分集群，阻力很大</li></ul><p>所以，简单的运营侧策略调整无法解决堆内存使用率过高的问题。那么我们就需要确认 ES 的堆内存是被什么数据占用了，能否优化。</p><h3 id="堆内存被什么数据占用了？">堆内存被什么数据占用了？</h3><p>我们对线上集群的堆内存分布情况做统计分析后，发现绝大部分堆内存主要被 FST（ Finite State Transducer ）占用了：</p><p>FST 内存占用量占分堆内存总量的 50% ~ 70%<br>FST 与 磁盘数据量成正比： 10TB 磁盘数据量，其对应的 FST 内存占用量在 10GB ~ 15GB 左右。<br>因此，我们的目标就是就是通过内核层的优化，降低 FST 的堆内存占用量。</p><h1>方案：降低 FST 堆内存占用量</h1><h2 id="什么是-FST-？">什么是 FST ？</h2><p>在介绍具体的方案前，先来了解下 FST 到底是什么。</p><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/6.png" alt></p><p>如上图所示，ES 底层存储采用 Lucene（搜索引擎），写入时会根据原始数据的内容，分词，然后生成倒排索引。</p><p>查询时，先通过查询倒排索引找到数据地址（DocID）），再读取原始数据（行存数据、列存数据）。</p><p>但由于 Lucene 会为原始数据中的每个词都生成倒排索引，数据量较大。所以倒排索引对应的倒排表被存放在磁盘上。这样如果每次查询都直接读取磁盘上的倒排表，再查询目标关键词，会有很多次磁盘 IO，严重影响查询性能。</p><p>为了解磁盘 IO 问题，Lucene 引入排索引的二级索引 FST Finite State Transducer 。原理上可以理解为前缀树，加速查询。</p><p>其原理如下：</p><ul><li>将原本的分词表，拆分成多个 Block ，每个 Block 会包含 25 ~ 48 个词（Term）。图中做了简单示意，Allen 和 After组成一个 Block 。</li><li>将每个 Block 中所有词的公共前缀抽取出来，如 Allen 和 After 的公共前缀是 A 。</li><li>将各个 Block 的公共前缀，按照类似前缀树的逻辑组合成 FST，其叶子节点携带对应 Block 的首地址 。（实际 FST 结构更为复杂，前缀后缀都有压缩，来降低内存占用量）</li><li>为了加速查询，FST 永驻堆内内存，无法被 GC 回收。</li><li>用户查询时，先通过关键词（Term）查询内存中的 FST ，找到该 Term 对应的 Block 首地址。再读磁盘上的分词表，将该 Block 加载到内存，遍历该 Block ，查找到目标 Term 对应的DocID。再按照一定的排序规则，生成DocID的优先级队列，再按该队列的顺序读取磁盘中的原始数据（行存或列存）。</li></ul><p>由此可知，FST常驻堆内内存，无法被 GC 回收 ， 长期占用 50% ~ 70% 的堆内存 ！</p><h2 id="解决方案">解决方案</h2><p>既然 FST 是常驻堆内内存，导致堆内存使用率过高，那么解决问题的思路有两种：</p><ul><li>降低 FST 在堆内的内存使用量</li><li>将 FST 从堆内存（OnHeap，有32GB容量限制）移到堆外内存（OffHeap）。因为堆外内存无容量上限，可通过扩充机器内存来提升容量。 （堆外内存容量限制近似为 物理内存 - JAVA堆内存）</li></ul><p>自然也就有了相应方案：</p><h3 id="解决方案一：降低-FST-在堆内的内存使用量">解决方案一：降低 FST 在堆内的内存使用量</h3><p>在 Tencent ES 成立前期，我们采用过这种方案。具体的做法是，将 FST 对应的 Block 大小，从 25 ~ 48，放大一倍至 49 ~ 96 。这样，在 关键词 Term 数相同的情况下，Block 数量降低了一倍，对应的 FST 内存理论上也会下降一倍。</p><ul><li>优点：我们实测发现，这种方案下，FST 的堆内存占用量下降了 40% 左右。</li><li>缺点：<ul><li>由于 Block内的 Term 数变多了，那么每次遍历 Block 查找目标 Term 时，需要从磁盘读取的数据量更大了，因此也带来了明显的查询性能损耗，约 20% 。</li><li>该方案只是让 FST 占用的内存下降了一半，仍无法控制 FST 占用的内存总量。不同场景下，FST 数据量大小差异也很大，在全文检索的字段较多时，仍然存在 FST 内存过高的问题。</li></ul></li></ul><p>由此我们可以看出，简单的降低 FST 的堆内存使用量，并不是一个普适性的方案，需要更为通用、彻底限制住 FST 总大小的方案。</p><h3 id="解决方案二：-将-FST-从堆内存（OnHeap）移到堆外内存（OffHeap）">解决方案二： 将 FST 从堆内存（OnHeap）移到堆外内存（OffHeap）</h3><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/7.png" alt></p><p>将 FST 从堆内存（OnHeap）移到堆外内存（OffHeap），几乎可以完全释放 FST 在堆内存占据的使用空间，这也是 JAVA 实践方向上一个普遍使用的方案。对于 JAVA 的堆内存不足，将部分内存移到堆外内存（OffHeap）的问题，ES 社区 和 其他 JAVA 系产品都有相应的解决方案。</p><h4 id="1-ES-社区方案：">1.<a href="https://jiankunking.com/significantly-decrease-your-elasticsearch-heap-memory-usage.html">ES 社区方案</a>：</h4><p>该方案是将 FST 从堆内存中剔除， 直接交由 MMAP 管理。FST 在磁盘上也是有对应的持久化文件的，Lucene 的 .tip 文件，该方案每次查询时直接通过 MMap 读取 .tip 文件，通过文件系统缓存 FST 数据。</p><p>优点：这种方实现简单，代码改动量小<br>缺点：<br>我们早期也试用过这种方式实现，但是由于 MMAP 属于 page cache 可能被系统回收掉。而且 ES 的大查询也会使用大量的系统缓存导致 FST 占用的内存被冲掉，瞬间产生较多的读盘操作，从而带来性能的 N 倍损耗，容易产生查询毛刺。特别是在 SATA 盘上，严重时查询时延有 10 倍的毛刺。<br><a href="https://jiankunking.com/significantly-decrease-your-elasticsearch-heap-memory-usage.html">Lucene 8.x 、ES 7.x 后才支持该功能，存量的 6.x 用户无法使用</a>。</p><h4 id="2-HBase-方案">2.HBase 方案</h4><p>HBase的方案是，在堆外搭建一个Cache，将其一部分堆内存（Bucket Cache，Data Block 缓存）移到堆外，释放堆内内存。</p><p>优点：数据缓存放在堆外，释放大量堆内内存<br>缺点：<br>淘汰策略完全依赖 LRU 策略<br>只是把数据缓存放置在堆外，索引的缓存还在堆内</p><h4 id="3-Tencent-ES-方案">3.Tencent ES 方案</h4><p>我们的方案总体上接近HBase的方案，相比之下：</p><p>优点：<br>相比于 ES 社区方案，我们堆外的 Cache 保证 FST 的内存空间不受系统影响。<br>相比于 HBase 方案，我们实现了更精准的数据淘汰策略，提高了内存使用率。也通过多级 Cache 解决性能问题，所以我们敢于把索引放置在堆外。</p><h2 id="实现：全链路-0-拷贝-FST-OffHeap-Cache">实现：全链路 0 拷贝 FST OffHeap Cache</h2><p>下面通过将由浅入深地向大家介绍我们实现 FST OffHeap 的过程，及其中碰见的问题和解决方案。</p><p>总体架构</p><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/8.png" alt></p><p>在实现 OffHeap 方案的初期，我们的架构如上图所示。</p><p>先来看下源生逻辑是怎样访问 FST 的：</p><ul><li><p>数据写入：ES 的一次 Refresh / Merge 动作，会生成一个新的 Lucene Segment，相应的在磁盘上生成该 Segment 对应的各种数据文件。其中 .tip 文件里面存储的就是该 Segment 各个字段的 FST 信息。在生成 .tip 文件后，Lucene 也会将每个字段（ Field ）的 FST 数据解析后，拷贝至该 Field 在 OnHeap 内存中的对象里，作为一个成员变量永驻内存，直到该 Segment 被删除 （ Index被删除、Segment Merge 时 ）。<br>数据查询：查询时，直接访问 OnHeap 的 FST 。<br>再来看下优化后的 Tencent ES 是怎样访问 FST 的：</p></li><li><p>数据写入： 在 OffHeap 内存放置一个 LRU Cache，在生成新的 Segment 时，不再将 .tip 中的 FST 数据拷贝至 OffHeap LRU Cache。将其对应的 Key 放置在 OnHeap 的 Field 中，不再将 FST 拷贝至 OnHeap 的 Field 中。这样就把 FST 从 OnHeap 移到了 OffHeap。<br>数据查询：查询时，通过 OnHeap Field 中保存的 Key，去 OffHeap LRU Cache 中查询 FST 数据，将其拷贝至 OnHeap后，做查询操作。若 Cache Miss ，则从磁盘的 .tip 文件中的相应位置读取该 Field 对应的 FST 做查询，同时将其放置到 OffHeap LRU Cache 中。</p></li></ul><p>将两种方案做个对比，如下表所示：</p><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/9.png" alt></p><p>那么可以总结出 Tencent ES 优化后的 FST 访问逻辑的优势和劣势：</p><ul><li>优势：在 OnHeap 我们用 100B 左右的 Key 置换 MB 级别的 FST，大大降低的内存占用量，使得单节点最大支持的磁盘数据量有了 5 倍以上的提升。</li><li>劣势：FST 在每次查询时都要从 OffHeap LRU Cache 拷贝至 OnHeap，相比于源生逻辑直接访问 OnHeap 的 FST ，读写都多了拷贝的动作，造成高并发读写时有 20%+ 的性能损耗。</li></ul><p>所以，我们要对 OffHeap LRU Cache 的读写路径做优化，减少 Copy 次数，提升读写性能。</p><p>具体的实现方案是全链路零拷贝 OffHeap FST 访问逻辑。</p><h3 id="全链路零拷贝-OffHeap-FST-访问逻辑">全链路零拷贝 OffHeap FST 访问逻辑</h3><p>ES 源生逻辑访问 FST 只支持堆内的操作，怎样做到让它能直接访问堆外的数据呢？</p><p>为此，我们做了两方面优化：<br><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/10.png" alt></p><ul><li>OffHeap LRU Cache： 改造读数据逻辑，Cache 只返回数据地址，封装为一个 Buffer，堆内只存数据地址，这样就把 FST 的访问从先拷贝至 OnHeap 再访问优化为直读 OffHeap 内存。</li><li>ES：重构 FST 读写逻辑，实现 FST 访问直读 OffHeap 内存：</li><li>FST 抽象为一个 FST Buffer，对外提供 FST 形式的各种访问接口。内部实现按 FST 的数据结构读取 OffHeap Buffer的逻辑，作为访问 OffHeap FST 的代理。</li><li>将 ES 访问 FST 的所有链路全部改造为 FST Buffer 接口的形式，优化 FST 的读写路径如下所示：</li></ul><p><img data-src="/images/tencent-trillion-level-elasticsearch-memory-efficiency-improves-decryption/11.png" alt></p><p>剩余部分略</p>]]></content>
      <tags>
        <tag>Performance</tag>
        <tag>转载</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式技术原理与算法解析 笔记</title>
    <url>/principles-and-algorithm-analysis-of-distributed-technology.html</url>
    <content><![CDATA[<p>分布式技术原理与算法解析 笔记<br>作者： 聂鹏程</p><a id="more"></a><h1>04 | 分布式选举：国不可一日无君</h1><h2 id="长者为大：Bully-算法">长者为大：Bully 算法</h2><p>Bully 算法是一种霸道的集群选主算法，为什么说是霸道呢？因为它的选举原则是“长者”为大，即在所有活着的节点中，选取 ID 最大的节点作为主节点。</p><p>在 Bully 算法中，节点的角色有两种：普通节点和主节点。初始化时，所有节点都是平等的，都是普通节点，并且都有成为主的权利。但是，当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点。当且仅当主节点故障或与其他节点失去联系后，才会重新选主。</p><p>Bully 算法在选举过程中，需要用到以下 3 种消息：</p><ul><li>Election 消息，用于发起选举；</li><li>Alive 消息，对 Election 消息的应答；</li><li>Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。</li></ul><p>Bully 算法选举的原则是“长者为大”，意味着它的<font color="red">假设条件是，集群中每个节点均知道其他节点的 ID。</font>在此前提下，其具体的选举过程是：</p><ol><li>集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权；</li><li>如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送Election 消息，并等待其他节点的回复；</li><li>若在给定的时间范围内，本节点没有收到其他节点回复的 Alive 消息，则认为自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点；若接收到来自比自己ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息；</li><li>若本节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。</li></ol><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-01-bully.png" alt></p><p>目前已经有很多开源软件采用了 Bully 算法进行选主，比如 MongoDB 的副本集故障转移功能。MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID，时间戳最新的<br>节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。</p><p>小结一下。Bully 算法的选择特别霸道和简单，谁活着且谁的 ID 最大谁就是主节点，其他节点必须无条件服从。这种算法的优点是，选举速度快、算法复杂度低、简单易实现。</p><p>但这种算法的缺点在于，需要每个节点有全局的节点信息，因此额外信息存储较多；其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致频繁切主。</p><h2 id="民主投票：Raft-算法">民主投票：Raft 算法</h2><p>采用 Raft 算法选举，集群节点的角色有 3 种：</p><ul><li>Leader，即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点；</li><li>Candidate，即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader；</li><li>Follower，Leader 的跟随者，不可以发起选举。</li></ul><p>Raft 选举的流程，可以分为以下几步：</p><ol><li>初始化时，所有节点均为 Follower 状态。</li><li>开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。</li><li>其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是，在每一轮选举中，一个节点只能投出一张票。</li><li>若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。</li><li>当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。</li></ol><p>节点的状态迁移如下所示（图中的 term 指的是选举周期）：<br><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-02-raft.png" alt></p><p>请注意，<font color="red">每一轮选举，每个节点只能投一次票。</font>这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期，任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者。对应到 Raft 算法中，选主是周期进行的，包括选主和任值两个时间段，选主阶段对应投票阶段，任值阶段对应节点成为主之后的任期。但也有例外的时候，如果主节点故障，会立马发起选举，重新选出一个主节点。</p><p>小结一下。Raft 算法具有选举速度快、算法复杂度低、易于实现的优点；缺点是，它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。</p><h2 id="具有优先级的民主投票：ZAB-算法">具有优先级的民主投票：ZAB 算法</h2><p>ZAB（ZooKeeper Atomic Broadcast）选举算法是为 ZooKeeper 实现分布式协调功能而设计的。相较于 Raft 算法的投票机制，ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主，节点 ID 和数据 ID 越大，表示数据越新，优先成为主。相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进。</p><p>使用 ZAB 算法选举时，集群中每个节点拥有 3 种角色：</p><ul><li>Leader，主节点；</li><li>Follower，跟随者节点；</li><li>Observer，观察者，无投票权。</li></ul><p>选举过程中，集群中的节点拥有 4 个状态：</p><ul><li>Looking 状态，即选举状态。当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。</li><li>Leading 状态，即领导者状态，表示已经选出主，且当前节点为 Leader。</li><li>Following 状态，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为Following，表示对 Leader 的追随。</li><li>Observing 状态，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。</li></ul><p>投票过程中，每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)，其中server_id 表示本节点的唯一 ID；server_zxID 表示本节点存放的数据 ID，数据 ID 越大表<br>示数据越新，选举权重越大；epoch 表示当前选取轮数，一般用逻辑时钟表示。</p><p>ZAB 选举算法的核心是“少数服从多数，ID 大的节点优先成为主”，因此选举过程中通过(vote_id, vote_zxID) 来表明投票给哪个节点，其中 vote_id 表示被投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。ZAB 算法选主的原则是：<font color="red">server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader。</font></p><p>接下来，我以 3 个 Server 的集群为例，此处每个 Server 代表一个节点，与你介绍 ZAB 选主的过程。</p><p>第一步：当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch=1，且 zxID 均为 0。此时每个服务器都推选自己，并将选票信息 &lt;epoch, vote_id, vote_zxID&gt; 广播出去。</p><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-03-zab-01.png" alt></p><p>第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因此比较 server_id，较大者即为推选对象，因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。</p><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-04-zab-02.png" alt></p><p>第三步：此时系统内所有服务器都推选了 Server 3，因此 Server 3 当选 Leader，处于Leading 状态，向其他服务器发送心跳包并维护连接；Server1 和 Server2 处于 Following 状态。</p><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-05-zab-03.png" alt></p><p>小结一下。ZAB 算法性能高，对系统无特殊要求，采用广播方式发送信息，若节点中有 n 个节点，每个节点同时广播，则集群中信息量为 n*(n-1) 个消息，容易出现广播风暴；且除了投票，还增加了对比节点 ID 和数据 ID，这就意味着还需要知道所有节点的 ID 和数据ID，所以选举时间相对较长。但该算法选举稳定性比较好，当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点数据 ID 和节点ID 最大，且获得投票数过半，才会导致切主。</p><h2 id="三种选举算法的对比分析">三种选举算法的对比分析</h2><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-06.png" alt></p><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/04-07.png" alt></p><h1>05 | 分布式共识：存异求同</h1><p>分布式共识就是在多个节点均可独自操作或记录的情况下，使得所有节点针对某个状态达成一致的过程。</p><p><a href="/attachments/分布式技术原理与算法解析/05分布式共识_存异求同.pdf" target="_blank">分布式共识：存异求同</a></p><h1>06 | 分布式事务：All or nothing</h1><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/06-01.png" alt></p><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/06-02.png" alt></p><h1>07 | 分布式锁：关键重地，非请勿入</h1><p><img data-src="/images/principles-and-algorithm-analysis-of-distributed-technology/07-01.png" alt></p><h1>特别放送</h1><p><a href="/attachments/分布式技术原理与算法解析/那些你不能错过的分布式系统论文.pdf" target="_blank">那些你不能错过的分布式系统论文</a></p>]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>算法</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 必知必会 笔记</title>
    <url>/mysql-must-know-and-must-know.html</url>
    <content><![CDATA[<p>MySQL 必知必会 笔记<br>作者： 朱晓峰</p><a id="more"></a><h1>02 | 字段：这么多字段类型，该怎么定义？</h1><h2 id="浮点数类型和定点数类型">浮点数类型和定点数类型</h2><p>MySQL 用 4 个字节存储 FLOAT 类型数据，用 8 个字节来存储 DOUBLE 类型数据。无论哪个，都是采用二进制的方式来进行存储的。比如 9.625，用二进制来表达，就是1001.101，或者表达成 1.001101×2^3。看到了吗？如果尾数不是 0 或 5（比如9.624），你就无法用一个二进制数来精确表达。怎么办呢？就只好在取值允许的范围内进行近似（四舍五入）。</p><p>现在你一定明白了，为什么数据类型是 DOUBLE 的时候，我们得到的结果误差更小一些，而数据类型是 FLOAT 的时候，误差会更大一下。原因就是，DOUBLE 有 8 位字节，精度更高。</p><p>说到这里，我想你已经彻底理解了浮点数据类型不精准的原因了。<br>那么，MySQL 有没有精准的数据类型呢？当然有，这就是定点数类型：DECIMAL。</p><p>就像浮点数类型的存储方式，决定了它不可能精准一样，DECIMAL 的存储方式决定了它一定是精准的。</p><p><font color="red">浮点数类型是把十进制数转换成二进制数存储，DECIMAL 则不同，它是把十进制数的整数部分和小数部分拆开，分别转换成十六进制数，进行存储。这样，所有的数值，就都可以精准表达了，不会存在因为无法表达而损失精度的问题。</font></p><p>MySQL 用 DECIMAL（M,D）的方式表示高精度小数。其中，M 表示整数部分加小数部分，一共有多少位，M&lt;=65。D 表示小数部分位数，D&lt;M。</p><blockquote><p>由于 DECIMAL 数据类型的精准性，在我们的项目中，除了极少数（比如商品编号）用到整数类型外，其他的数值都用的是 DECIMAL，原因就是这个项目所处的零售行业，要求精准，一分钱也不能差。</p></blockquote><h2 id="文本类型">文本类型</h2><p>因为不需要预先知道字符串的长度，系统会按照实际的数据长度进行存储，所以 TEXT 类型最为灵活方便;由于实际存储的长度不确定，MySQL 不允许 TEXT 类型的字段做主键。遇到这种情况，你只能采用 CHAR(M)，或者VARCHAR(M)。</p><p>我建议你，在你的项目中，<font color="red">只要不是主键字段，就可以按照数据可能的最大长度，选择这几种 TEXT 类型中的的一种，作为存储字符串的数据类型。</font></p><ul><li>TINYTEXT：255 字符（这里假设字符是 ASCII 码，一个字符占用一个字节，下同）。</li><li>TEXT： 65535 字符。</li><li>MEDIUMTEXT：16777215 字符。</li><li>LONGTEXT： 4294967295 字符（相当于 4GB）。</li></ul><h2 id="日期与时间类型">日期与时间类型</h2><p>用得最多的日期时间类型，就是 DATETIME。虽然 MySQL 也支持 YEAR（年）、TIME（时间）、DATE（日期），以及 TIMESTAMP 类型，但是我建议你，<font color="red">在实际项目中，尽量用 DATETIME 类型。因为这个数据类型包括了完整的日期和时间信息，使用起来比较方便。</font>毕竟，如果日期时间信息分散在好几个字段，就会很不容易记，而且查询的时候，SQL 语句也会更加复杂。</p><h1>04丨增删改查：如何操作表中的数据？</h1><p>INSERT…ON DUPLICATE 语句存在死锁的可能</p><p><a href="https://medium.com/@mingwho/mysql-deadlock-caused-by-insert-on-duplicate-key-update-893ef30993a8" target="_blank" rel="noopener">https://medium.com/@mingwho/mysql-deadlock-caused-by-insert-on-duplicate-key-update-893ef30993a8</a></p><h1>05丨主键：如何正确设置主键？</h1><p>用业务字段做主键，看起来很简单，但是我们应该尽量避免这样做。因为我们无法预测未来会不会因为业务需要，而出现业务字段重复或者重用的情况。</p><p>自增字段做主键，对于单机系统来说是没问题的。但是，如果有多台服务器，各自都可以录入数据，那就不一定适用了。因为如果每台机器各自产生的数据需要合并，就可能会出现主键重复的问题。</p><p>我们可以采用手动赋值的办法，通过一定的逻辑，确保字段值在全系统的唯一性，这样就可以规避主键重复的问题了。</p><h1>07丨条件语句：WHERE 与 HAVING有什么不同？</h1><p>首先，你要知道它们的 2 个典型区别。</p><p>第一个区别是，如果需要通过连接从关联表中获取需要的数据，WHERE 是先筛选后连接，而 HAVING 是先连接后筛选。</p><p>这一点，就决定了在关联查询中，WHERE 比 HAVING 更高效。因为 WHERE 可以先筛选，用一个筛选后的较小数据集和关联表进行连接，这样占用的资源比较少，执行效率也就比较高。HAVING 则需要先把结果集准备好，也就是用未被筛选的数据集进行关联，然后对这个大的数据集进行筛选，这样占用的资源就比较多，执行效率也较低。</p><p>第二个区别是，WHERE 可以直接使用表中的字段作为筛选条件，但不能使用分组中的计算函数作为筛选条件；HAVING 必须要与 GROUP BY 配合使用，可以把分组计算的函数和分组字段作为筛选条件。</p><p>这决定了，在需要对数据进行分组统计的时候，HAVING 可以完成 WHERE 不能完成的任务。这是因为，在查询语法结构中，WHERE 在 GROUP BY 之前，所以无法对分组结果进行筛选。HAVING 在 GROUP BY 之后，可以使用分组字段和分组中的计算函数，对分组的结果集进行筛选，这个功能是 WHERE 无法完成的。</p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>人名搜索 - 如何改进结果</title>
    <url>/human-names-searching-how-to-improve-results.html</url>
    <content><![CDATA[<blockquote><p>基于Elasticsearch如何实现一个好用的用户名检索?</p></blockquote><a id="more"></a><p>先说一下背景,需要提供一个检索接口,根据用户输入的值去检索：姓名、姓名拼音、工号、昵称等。</p><p>迭代过的版本：</p><ul><li>标准分词<ul><li>中文支持不好</li></ul></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/keyword.html#wildcard-field-type" target="_blank" rel="noopener">wildcard type</a><ul><li>因为有安全考虑,所以限制了总的返回条数为10,导致完整匹配的不是在前10条</li><li>这里还遇到了一个坑华为云elasticsearch是基于OpenSearch的,不支持wildcard这种类型</li></ul></li></ul><p>关于姓名这个,由于大多数用户的姓名是汉字,所以第一个想到的是<a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">ik</a></p><h1>IK方案</h1><h2 id="构建Dockerfile">构建Dockerfile</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM registry.jiankunking.com/library/elasticsearch:7.13.4</span><br><span class="line"></span><br><span class="line"># RUN ./bin/elasticsearch-plugin install --batch https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.13.4/elasticsearch-analysis-ik-7.13.4.zip</span><br><span class="line">ADD ik/elasticsearch-analysis-ik-7.13.4.zip /usr/share/elasticsearch</span><br><span class="line">RUN ./bin/elasticsearch-plugin install --batch file:///usr/share/elasticsearch/elasticsearch-analysis-ik-7.13.4.zip</span><br><span class="line"></span><br><span class="line">ADD pinyin/elasticsearch-analysis-pinyin-7.13.4.zip /usr/share/elasticsearch</span><br><span class="line">RUN ./bin/elasticsearch-plugin install --batch file:///usr/share/elasticsearch/elasticsearch-analysis-pinyin-7.13.4.zip</span><br><span class="line"></span><br><span class="line"># 移除插件安装包</span><br><span class="line">RUN rm -f /usr/share/elasticsearch/elasticsearch-analysis-ik-7.13.4.zip</span><br></pre></td></tr></table></figure><blockquote><p>IK插件已经上传到代码中,所有没有采用在线安装的方式<br>已将姓名字典放置到 elasticsearch-analysis-ik-7.13.4/config/custom_user_name.dic</p></blockquote><p>IKAnalyzer.cfg.xml也已修改</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">	&lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;</span><br><span class="line">	&lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span><br><span class="line">	&lt;entry key=&quot;ext_dict&quot;&gt;custom_user_name.dic&lt;/entry&gt;</span><br><span class="line">	 &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span><br><span class="line">	&lt;!-- &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt; --&gt;</span><br><span class="line">	&lt;!--用户可以在这里配置远程扩展字典 --&gt;</span><br><span class="line">	&lt;!-- &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; --&gt;</span><br><span class="line">	&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;</span><br><span class="line">	&lt;!-- &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; --&gt;</span><br><span class="line">&lt;/properties&gt;</span><br></pre></td></tr></table></figure><h2 id="验证">验证</h2><h3 id="模版">模版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /_template/jiankunking-attr</span><br><span class="line">&#123;</span><br><span class="line">	&quot;order&quot;: 0,</span><br><span class="line">	&quot;index_patterns&quot;: [</span><br><span class="line">		&quot;jiankunking-attrs&quot;,</span><br><span class="line">		&quot;jiankunking-attrs-dev&quot;</span><br><span class="line">	],</span><br><span class="line">	&quot;settings&quot;: &#123;</span><br><span class="line">		&quot;index&quot;: &#123;</span><br><span class="line">			&quot;number_of_shards&quot;: &quot;6&quot;,</span><br><span class="line">			&quot;number_of_replicas&quot;: &quot;1&quot;,</span><br><span class="line">			&quot;refresh_interval&quot;: &quot;200ms&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;mappings&quot;: &#123;</span><br><span class="line">		&quot;dynamic_templates&quot;: [</span><br><span class="line">			&#123;</span><br><span class="line">				&quot;strings&quot;: &#123;</span><br><span class="line">					&quot;mapping&quot;: &#123;</span><br><span class="line">						&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">					&#125;,</span><br><span class="line">					&quot;match_mapping_type&quot;: &quot;string&quot;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		],</span><br><span class="line">		&quot;properties&quot;: &#123;</span><br><span class="line">			&quot;id&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;attrs.user_name_ik.attrValue&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;text&quot;,</span><br><span class="line">				&quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">				&quot;search_analyzer&quot;: &quot;ik_smart&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;creator&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;updater&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;createdAt&quot;: &#123;</span><br><span class="line">				&quot;format&quot;: &quot;epoch_second&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;date&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;updatedAt&quot;: &#123;</span><br><span class="line">				&quot;format&quot;: &quot;epoch_second&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;date&quot;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查询验证过程略">查询验证过程略</h3><h2 id="结论">结论</h2><p>1、需要自定义词库<br>使用IK插件但不自定义词库的话,无法正确的分词姓名;<br>使用词库的话,需要穷举可能得搜索项,<br>假如,词典中只加载姓名,那么对于搜索后半段,比如：孙新伟,搜索：新伟,会搜索不到,这时候搜索结果就会不符合预期。<br>2、对于英文姓名分词有一定限制<br>比如搜索:dam,Adam Dean不会被检索到<br>3、需要安装IK插件,需要重启集群</p><h1>Ngram方案</h1><h2 id="验证-v2">验证</h2><h3 id="模版-v2">模版</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /_template/jiankunking-attr-ngram</span><br><span class="line">&#123;</span><br><span class="line">	&quot;order&quot;: 0,</span><br><span class="line">	&quot;index_patterns&quot;: [</span><br><span class="line">		&quot;jiankunking-attrs-v3-*&quot;</span><br><span class="line">	],</span><br><span class="line">	&quot;settings&quot;: &#123;</span><br><span class="line">		&quot;index&quot;: &#123;</span><br><span class="line">			&quot;max_ngram_diff&quot;: &quot;9&quot;,</span><br><span class="line">			&quot;refresh_interval&quot;: &quot;200ms&quot;,</span><br><span class="line">			&quot;analysis&quot;: &#123;</span><br><span class="line">				&quot;analyzer&quot;: &#123;</span><br><span class="line">					&quot;ngram_analyzer&quot;: &#123;</span><br><span class="line">						&quot;tokenizer&quot;: &quot;ngram&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;,</span><br><span class="line">				&quot;tokenizer&quot;: &#123;</span><br><span class="line">					&quot;ngram&quot;: &#123;</span><br><span class="line">						&quot;token_chars&quot;: [</span><br><span class="line">							&quot;letter&quot;,</span><br><span class="line">							&quot;digit&quot;</span><br><span class="line">						],</span><br><span class="line">						&quot;min_gram&quot;: &quot;1&quot;,</span><br><span class="line">						&quot;type&quot;: &quot;ngram&quot;,</span><br><span class="line">						&quot;max_gram&quot;: &quot;10&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;number_of_shards&quot;: &quot;10&quot;,</span><br><span class="line">			&quot;number_of_replicas&quot;: &quot;1&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;mappings&quot;: &#123;</span><br><span class="line">		&quot;dynamic_templates&quot;: [</span><br><span class="line">			&#123;</span><br><span class="line">				&quot;strings&quot;: &#123;</span><br><span class="line">					&quot;mapping&quot;: &#123;</span><br><span class="line">						&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">					&#125;,</span><br><span class="line">					&quot;match_mapping_type&quot;: &quot;string&quot;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		],</span><br><span class="line">		&quot;properties&quot;: &#123;</span><br><span class="line">			&quot;attrs.pinyin.attrValue&quot;: &#123;</span><br><span class="line">				&quot;search_analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;text&quot;,</span><br><span class="line">				&quot;fields&quot;: &#123;</span><br><span class="line">					&quot;keyword&quot;: &#123;</span><br><span class="line">						&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;createdAt&quot;: &#123;</span><br><span class="line">				&quot;format&quot;: &quot;epoch_second&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;date&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;creator&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;attrs.nickname.attrValue&quot;: &#123;</span><br><span class="line">				&quot;search_analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;text&quot;,</span><br><span class="line">				&quot;fields&quot;: &#123;</span><br><span class="line">					&quot;keyword&quot;: &#123;</span><br><span class="line">						&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;attrs.username.attrValue&quot;: &#123;</span><br><span class="line">				&quot;search_analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;text&quot;,</span><br><span class="line">				&quot;fields&quot;: &#123;</span><br><span class="line">					&quot;keyword&quot;: &#123;</span><br><span class="line">						&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;attrs.user_id.attrValue&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">				&quot;fields&quot;: &#123;</span><br><span class="line">					&quot;text&quot;: &#123;</span><br><span class="line">						&quot;search_analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">						&quot;analyzer&quot;: &quot;ngram_analyzer&quot;,</span><br><span class="line">						&quot;type&quot;: &quot;text&quot;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;id&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;attrs&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;object&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;updater&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;updatedAt&quot;: &#123;</span><br><span class="line">				&quot;format&quot;: &quot;epoch_second&quot;,</span><br><span class="line">				&quot;type&quot;: &quot;date&quot;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;aliases&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查询验证过程略-v2">查询验证过程略</h3><h2 id="结论-v2">结论</h2><p>搜索返回的数据中,会有相似数据<br>比如搜索:“土豆儿”,会匹配到:“王豆豆”、&quot;田豆豆&quot;等<br>Ngram分词会消耗大量资源(尤其是磁盘),reindex有可能会超时</p><h1>结论</h1><p>由于用户数据量不到100万,所以即使资源效果的多一些,也在可以接受的范围内,所以最终采取了Ngram方案</p><p>最优的查询语句如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;size&quot;: 10,</span><br><span class="line">	&quot;_source&quot;: [</span><br><span class="line">		&quot;attrs.username.attrValue&quot;,</span><br><span class="line">		&quot;attrs.pinyin.attrValue&quot;,</span><br><span class="line">		&quot;attrs.user_id.attrValue&quot;,</span><br><span class="line">		&quot;attrs.nickname.attrValue&quot;</span><br><span class="line">	],</span><br><span class="line">	&quot;query&quot;: &#123;</span><br><span class="line">		&quot;multi_match&quot;: &#123;</span><br><span class="line">			&quot;query&quot;: &quot;jiankunking&quot;,</span><br><span class="line">			&quot;type&quot;: &quot;best_fields&quot;,</span><br><span class="line">			&quot;fields&quot;: [</span><br><span class="line">				&quot;attrs.user_id.attrValue.text&quot;,</span><br><span class="line">				&quot;attrs.username.attrValue&quot;,</span><br><span class="line">				&quot;attrs.nickname.attrValue&quot;,</span><br><span class="line">				&quot;attrs.pinyin.attrValue&quot;</span><br><span class="line">			]</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Name</tag>
        <tag>User</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title>网关的一种实现方式</title>
    <url>/a-way-to-implement-gateway.html</url>
    <content><![CDATA[<blockquote><p>动手开发自己的API网关</p></blockquote><a id="more"></a><p>基于:</p><ul><li>Golang</li><li>Gin</li><li>ReverseProxy</li></ul><p><img data-src="/images/a-way-to-implement-gateway/%E7%BD%91%E5%85%B3.png" alt></p>]]></content>
      <categories>
        <category>网关</category>
      </categories>
      <tags>
        <tag>网关</tag>
        <tag>路由</tag>
        <tag>权限</tag>
        <tag>Gin</tag>
        <tag>Golang</tag>
        <tag>ReverseProxy</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]自上而下认识Elasticsearch</title>
    <url>/elasticsearch-from-the-top-down.html</url>
    <content><![CDATA[<blockquote><p>注意:原文发表时间是14年,所以实现有可能与新版不一致.<br>原文地址:<a href="https://www.elastic.co/cn/blog/found-elasticsearch-top-down" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/found-elasticsearch-top-down</a></p></blockquote><a id="more"></a><h1>Introduction</h1><p>在上一篇文章&quot;自下而上认识Elasticsearch&quot;中,我们从相当底层的数据结构开始,然后提升到抽象层以将它们置于上下文中.然而,我们专注于单个分片内发生的事情.</p><p>要查看所有这些如何在分布式环境中组合在一起,从另一端开始更容易:从用户的角度观察,从&quot;顶部&quot;开始.</p><p>我们将看看当用户向Elasticsearch发送索引和搜索请求时会发生什么,以及这些请求如何在网络中波动,直到我们到达前面介绍的较低级别的结构.首先,我们将查看接受请求的节点及其作为协调器的角色.我们将看看它如何将请求路由到分片的主索引请求,以及如何在副本之间平衡搜索请求的负载.</p><p>在被路由到正确的分片之后,我们将看看在分片级别发生了什么——例如什么构成了&quot;成功&quot;的索引操作,以及将文档和搜索转换为它们的Lucene等价物所需的转换.对于搜索请求,我们还将查看分散/聚集过程,这可能发生在多轮中.</p><h1>A Cluster of Nodes</h1><p>为了描述Elasticsearch的工作原理,我们需要某种集群拓扑.图中的集群描述了我们假设的集群类型.我们有一个带有两个分片的Elasticsearch索引,为了可用性在两个不同&quot;区域&quot;的节点之间进行复制——只有主节点在三个区域中运行.此外,我们有两个客户端节点,我们将通过它们发送请求.<br><img data-src="/images/elasticsearch-top-down/cluster-topology.svg" alt="Sample Cluster Topology"></p><p>集群中的不同节点可以具有不同的角色(data and/or master – or none as a client)以及属性(例如区域/zone).我们有数据节点、主节点和客户端节点——在不同的区域,即具有不同的 node.zone 属性.本文中我们关注数据节点.</p><h1>Request Coordinators</h1><p>当您向Elasticsearch中的节点发送请求时,该节点将成为该请求的协调器.它将决定将请求路由到哪些节点和分片,如何合并不同节点的响应,以及决定请求何时&quot;完成&quot;.虽然Elasticsearch会为您透明地处理这个问题,但高级分区方案需要有关内部处理和路由的知识.上述给定集群,客户端节点将充当协调器.</p><p><font color="DeepPink"><strong>为了能够充当协调器,节点需要知道集群的状态.集群状态被复制到集群中的每个节点.它具有分片路由表(哪些节点托管哪些索引和分片)、关于每个节点的元数据(例如它运行的位置和节点具有的属性)以及索引映射(其中可以包含重要的路由配置)和模板.集群状态被复制到所有节点是映射需要合理大小的一个重要原因.</strong></font></p><p>对于搜索请求,协调意味着选择分片的副本、发送请求以进行进一步处理,可能需要多轮处理,我们稍后将对此进行更多研究.选择副本是随机完成的,或者受请求偏好的影响.</p><p>索引请求(即创建、更新或删除文档的请求)略有不同.在这种情况下,请求必须路由到分片的主节点,以及一定数量的副本——取决于索引请求的write_consistency.写一致性可以是一个、quorum(默认是一个,除非你有≥2 个副本)或全部——即要求一个、大多数或每个副本都已确认.</p><h1>Index a Document to an Index of … Indexes?</h1><p>术语&quot;索引&quot;在很多上下文中使用,具有不同的含义.您将文档索引到Elasticsearch索引.<font color="DeepPink"><strong>Elasticsearch索引有分片,也就是 Lucene索引</strong></font>.那些有倒排索引.这可能会让人感到困惑.</p><p><font color="DeepPink"><strong>一个重要的见解是,从概念上讲,具有两个分片的Elasticsearch索引与每个具有一个分片的两个Elasticsearch索引完全相同.最终,它们是两个Lucene索引.不同之处主要在于Elasticsearch通过其路由功能提供的便利性.仅使用单个分片索引就可以实现相同的&quot;手动&quot;.(不是你应该!)</strong></font></p><p>重要的部分是通过分片的概念,认识到Elasticsearch索引是Lucene索引集合之上的抽象.当您需要考虑更高级的分区策略时,这会有所帮助.</p><h1>Index Requests</h1><p>索引请求是创建或更改索引中文档的请求.无论是新建文档、删除文档还是更新文档,都不是很重要,所以我们统称为&quot;索引请求&quot;.</p><p>考虑以下批量请求:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;index&quot;: &#123;</span><br><span class="line">		&quot;_index&quot;: &quot;tweets&quot;,</span><br><span class="line">		&quot;_type&quot;: &quot;tweet&quot;,</span><br><span class="line">		&quot;_id&quot;: &quot;502878691740090369&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;user&quot;: &quot;mikepluta&quot;,</span><br><span class="line">	&quot;tweet&quot;: &quot;Moore&apos;s Law for #BigData: The amount of nonsense packed into the term \&quot;BigData\&quot; doubles approximately every two years&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;index&quot;: &#123;</span><br><span class="line">		&quot;_index&quot;: &quot;tweets&quot;,</span><br><span class="line">		&quot;_type&quot;: &quot;tweet&quot;,</span><br><span class="line">		&quot;_id&quot;: &quot;475944863175671808&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;user&quot;: &quot;viktorklang&quot;,</span><br><span class="line">	&quot;tweet&quot;: &quot;For resilient software, \&quot;What could possibly go wrong?\&quot; should be the famous first words; not last.&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;index&quot;: &#123;</span><br><span class="line">		&quot;_index&quot;: &quot;logs-2014-10-14&quot;,</span><br><span class="line">		&quot;_type&quot;: &quot;log&quot;,</span><br><span class="line">		&quot;_consistency&quot;: &quot;all&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;@timestamp&quot;: &quot;2014-10-14T12:34:56Z&quot;,</span><br><span class="line">	&quot;message&quot;: &quot;Suddenly the Dungeon collapses!! - You die...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>处理这个请求的节点需要考虑几个问题:</p><ul><li>tweets和logs的路由配置是什么？这可以通过查看集群状态中的映射来确定.对于tweets,可能存在基于用户的路由,因此tweets的<font color="DeepPink"><strong>user</strong></font>属性应确定将文档路由到哪个分片.我们将在下一节中查看一些示例.</li><li>在确定了两条tweets的分片之后,我们什么时候可以认为文档真正被索引了？由于未指定任何内容,因此默认为节点的默认 <font color="DeepPink"><strong>action.write_consistency</strong></font>,默认为<font color="DeepPink"><strong>quorum</strong></font>.</li><li>logs消息没有与之关联的ID.所有文件都必须有一个,因此协调员必须为其分配一个.文档ID是协调器将用来路由请求的内容,如果操作或映射没有覆盖它的话.(然而,分配ID和具有幂等请求是最佳实践)</li><li>logs操作指定了严格的<font color="DeepPink"><strong>_consistency</strong></font>设置,因此在每个副本都返回成功之前无法确认请求.</li><li>什么时候可以整体完成批量请求？</li></ul><h1>Routing</h1><p>路由指定哪些文档去哪里,因此是请求如何在Elasticsearch内部流动的重要部分,包括搜索和索引请求.它是设计适当的数据流和索引分区不可或缺的一部分.在这里,我们专注于机制,因为索引和分片设计是一个大话题.</p><p><img data-src="/images/elasticsearch-top-down/routing.png" alt="routers"></p><h1>primaryConcerns</h1><p>当索引操作被路由时,它被转发到该分片的&quot;主&quot;.一个分片只有一个&quot;主&quot;,以及零个或多个副本.在这方面,primary可以被认为是分片的&quot;master&quot;,而replicas可以被认为是&quot;slaves&quot;.</p><p>主节点将充当该特定分片的索引操作的协调器.它会将索引操作发送到相关的副本,并等待所需的数量在指示成功之前得到确认.</p><p><img data-src="/images/elasticsearch-top-down/index-sequence.svg" alt="Sequence of an Index Operation"></p><p>当足够数量的副本已确认时,主副本将成功报告回原始请求协调器,在我们的例子中是客户端节点.对于&quot;quorum&quot;默认的写一致性,三个操作中的两个就足够了,所以不需要等到第三个操作才传递成功.</p><p>协调器/客户端节点并行地向分片的主节点发送操作.当所有操作都返回后,最终返回发起的批量请求.</p><p>&quot;成功&quot;操作的定义值得研究.</p><p>在上一篇文章中,我们了解了索引是如何构建的,以及如何在搜索速度、索引紧凑度、索引速度和操作变得可见所需的时间之间进行权衡.涵盖了Lucene内部结构,如不可变段,我们强调批量构建这些并延迟昂贵的磁盘同步操作很重要.</p><p>所有这一切似乎都与我们希望从索引操作中得到的东西背道而驰:安全耐用,但很快得到承认.为实现这一点,Elasticsearch有一个&quot;transaction log&quot;(文档中的&quot;translog&quot;)或&quot;write-ahead log&quot;,就像几乎每个数据库系统一样.写入仅追加的translog是分片成功的定义,而不是文档是否实际上是通过可搜索段的实时索引的一部分.</p><p><font color="DeepPink"><strong>在正常操作期间,Elasticsearch不会复制已经构建的索引片段(即段),而是重新应用相同更改所需的操作.(另一方面,在恢复或分片迁移期间,段是被复制的.)因此,所有副本本质上都在以相同的CPU成本执行相同数量的工作.副本不能&quot;重用&quot;主副本已经完成的工作.这是添加副本会降低整体索引吞吐量的一个重要原因——您需要等待更多节点确认操作.此外,您不能期望拥有&quot;只写&quot;节点和&quot;只读&quot;节点.</strong></font></p><h1>All in a Shard</h1><p>虽然在分片的事务日志中放置一个操作是一个很好的开始,但最终操作的效果应该在索引结构中结束.在上一篇文章中,我们介绍了倒排索引的工作原理及其构建方式.我们没有谈及映射,而是着重于分片是Lucene索引这一事实.</p><p><font color="DeepPink"><strong>Lucene没有映射(mapping)的概念,Lucene索引或文档也没有类型.在Lucene中,文档是无类型的并且具有任意数量的字段.这些字段具有特定类型(string/numeric)和属性(stored/indexed/…).映射是一个很好的抽象,用于表达如何将源文档转换为具有一堆字段的Lucene文档.映射具有类型、动态属性、多字段、脚本转换等概念.然而,Lucene对这些一无所知.只要Elasticsearch以Lucene期望的方式生成文档,Lucene就会很高兴.就Lucene而言,_all、_source 甚至 _type 等字段没有什么特别之处.</strong></font></p><p><img data-src="/images/elasticsearch-top-down/mapping-transform.svg" alt="Elasticsearchtransforms a source document to aLucenedocument"></p><p>许多人将Elasticsearch索引比作数据库,将类型比作表.就我个人而言,我认为这种比较会导致更多的混乱而不是清晰.对于两个不同的表,您可以合理地假设这些表在存储方式或存储位置方面没有任何共同之处.相反,您可以构建映射,使Elasticsearch生成名称相同但类型不同的字段.由于一切都是同一个倒排索引中的一堆术语,这可能会导致问题.如果您的过滤器对于某些文档是数字的,而对于其他文档是字符串的,您最终会得到错误或可能是意外的结果.对于具有相同类型(例如字符串)但具有不同分析器的字段也是如此.动态映射非常适合快速启动开发,但您可能不想完全依赖它.</p><h1>Index Request Summary</h1><p>总结索引请求的流程,会发生以下情况:</p><ol><li>接受请求的节点将成为协调器.它查询映射以确定将请求发送到哪个分片.</li><li>请求被发送到该分片的主节点.</li><li>primary将操作写入其translog,并将请求中继到replicas.</li><li>当足够数量的副本已确认时,主副本返回成功.</li><li>当所有子操作(例如批量请求)都成功时,协调器返回成功.</li></ol><p>发生这种情况时,每个分片将持续处理其文档队列,将输入文档转换为Lucene文档.然后将它们添加到索引缓冲区,最终刷新到一个新段中,甚至稍后完全提交.何时发生取决于托管分片的节点.刷新在节点之间不同步,因此搜索者可以在刷新传播时短暂地看到单独的&quot;时间线&quot;.</p><p><img data-src="/images/elasticsearch-top-down/index-buffer.svg" alt="Elasticsearchtransforms a source document to aLucenedocument"></p><h1>Search Requests</h1><p>我们已经看到将具有索引操作的请求转换为实际索引更改所需的来回次数.搜索请求的过程在某些方面相似,但在许多其他方面有所不同.</p><p><font color="DeepPink"><strong>与索引请求一样,必须路由搜索请求.如果没有指定路由,搜索将命中所有不同的分片——如果指定了路由,则搜索将命中特定的分片.</strong></font></p><p>识别出相关分片后,协调器将在该分片的可用副本中进行选择,以尝试平衡负载.</p><p>假设我们有以下搜索.我们对字段标题和描述进行了multi_match查询,搜索&quot;Holy Grail&quot;.我们想要排名前十的作者和排名前十的书,更喜欢标题匹配.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /books/book/_search</span><br><span class="line">query:</span><br><span class="line">    filtered:</span><br><span class="line">        filter:</span><br><span class="line">            term:</span><br><span class="line">                tag: python</span><br><span class="line">        query:</span><br><span class="line">            multi_match:</span><br><span class="line">                query: Holy Grail</span><br><span class="line">                fields: [title^5, description]</span><br><span class="line">aggregations:</span><br><span class="line">   author_id:</span><br><span class="line">        terms:</span><br><span class="line">            field:author_id</span><br><span class="line">            size: 10</span><br><span class="line">            shard_size: 100</span><br><span class="line">size: 10</span><br></pre></td></tr></table></figure><p>我们没有指定搜索的类型,所以将使用默认值——query_then_fetch.不要将这种&quot;搜索类型&quot;与上面讨论的类型混淆! 命名是困难的.</p><p>本质上,&quot;先查询再获取&quot;意味着会有两轮查找.稍后我们会将此搜索类型与其他搜索类型进行比较.</p><p>首先,每个分片都会找到前10个命中并发回它们的ID.这些ID然后将由协调员合并以找到真正的前10名,之后它将要求获胜者的实际文件.为了找到全球前10名的命中率,从每个分片中获取前10名就足够了.稍后我们将看到为什么这对于聚合是不同的.</p><p>但首先,让我们仔细看看第一轮,看看在搜索的分片级别发生了什么.</p><h1>Query Rewriting</h1><p><font color="DeepPink"><strong>在分片上执行搜索请求之前,需要重写搜索并使其适应Lucene查询图.</strong></font>Elasticsearch经常因具有深度嵌套和冗长的搜索DSL而受到批评,这在某种程度上假定了Lucene熟悉度.就我个人而言,我发现搜索DSL很棒——出于完全相同的原因:</p><p>首先,嵌套的性质使得以编程方式使用更容易.对于简单的事情来说肯定是冗长的,但是具有高度自定义评分和匹配的真正搜索需求并不简单.</p><p>其次,DSL中的查询和过滤器与Lucene中的查询和过滤器非常接近.这对于了解真正发生的事情很重要.</p><p>但是,也有一些例外.如上所述,映射概念对于Lucene来说是陌生的.然而,一些查询利用映射.例如,查询的match系列没有Lucene对应项.他们将根据字段的映射处理查询文本,并组成一个Lucene查询.我们的示例将被重写为如下所示:</p><blockquote><p>For example, the match family of queries have no Lucene counterpart. They will process the query text according to the fields’ mappings, and compose a Lucene query.</p></blockquote><p><img data-src="/images/elasticsearch-top-down/lucene-search-tree.svg" alt></p><p>请注意,根据为各个字段配置的分析器,查询文本&quot;Holy Grail&quot;已被标记化和小写.当没有得到你想要的结果时,一个常见的原因是索引和查询时间文本处理不兼容.例如,术语查询不会将Holy Grail 转换为holy, grail,因此不会匹配.</p><h1>Searching a Shard</h1><p>此时,我们已经准备好在每个分片上执行的Lucene查询运算符.我们处于搜索阶段的第一阶段——即&quot;查询&quot;,然后是&quot;获取&quot;——所以我们需要以下内容:</p><ul><li>前十位文档ID的列表.(不是整个文档)这些将由协调器合并,协调器将执行第二个&quot;获取&quot;阶段以获取实际文档.</li><li>所有命中的迭代器(尽管我们不需要所有命中的分数),用于聚合目的.</li><li>一种在给定文档ID的情况下快速查找书籍的<font color="DeepPink"><strong>author_id</strong></font>的方法:<a href="elastic.co/cn/blog/found-sizing-elasticsearch#field-data-and-document-values">a field cache or document values</a>.</li><li>前100名作者.(注意<font color="DeepPink"><strong>shard_size</strong></font>为100)</li></ul><table><thead><tr><th>维度</th><th><a href="https://www.elastic.co/guide/en/elasticsearch/reference/8.7/doc-values.html" target="_blank" rel="noopener">doc_values</a></th><th>fielddata</th></tr></thead><tbody><tr><td>创建时间</td><td>index时创建</td><td>使用时动态创建</td></tr><tr><td>创建位置</td><td>磁盘</td><td>内存(jvm heap)</td></tr><tr><td>优点</td><td>不占用内存空间</td><td>不占用磁盘空间</td></tr><tr><td>缺点</td><td>索引速度稍低</td><td>文档很多时，动态创建开销比较大，而且占内存</td></tr></tbody></table><p>自下而上文章中关于倒排索引和索引术语的部分描述了如何按段执行搜索,因此我们将在此跳过重复.然而,值得重复的是,搜索发生在多个独立的段上并合并——很像分片的工作方式.有几种缓存可以提高搜索性能,所有缓存都按段划分:</p><ul><li>如果tag:python过滤器被缓存,它可以立即被重用.</li><li>如果未启用文档值,则author_id字段必须在字段缓存中.如果不是,则必须将所有文档的所有author_id加载到内存中.</li><li>如果author_id使用文档值，那么保存所需值的磁盘页面可能在页面缓存中。如果是这样，那就太好了！</li></ul><blockquote><p>文档值:document values<br>字段缓存:field cache</p></blockquote><p>但是,不会缓存查询.因此,对于这些以及任何未缓存的过滤器和字段,我们将需要命中倒排索引.对于任何需要使用底层索引的东西,如果相关页面存在于操作系统的页面缓存中,那就太好了.(如果将所有内存分配给Elasticsearch进程,操作系统就没有任何内存了.)</p><p>最终,使用过滤器和聚合,您实际上是在操作位图来汇总您已经缓存的值.这就是为什么Elasticsearch可以如此快得令人难以置信的原因.</p><h1>… Then Fetch</h1><p>在每个分片都对结果做出贡献后,协调器将合并它们.具体来说,有两件事需要弄清楚:</p><ul><li>真正的前10名.分片将提供最多10个文档的ID及其分数.</li><li>前10位作者的近似值.每个分片提供了最多100位作者的计数.如果我们不这样做,并且只请求每个分片的前10名,那么如果真正的前10名作者之一实际上是其中一个分片中的第11名,会发生什么？它不会作为候选人提交,并导致特定的外衣脱落.这仍然是可能的,如果真正的前10位作者之一实际上是其中一个分片的第101位,但这种可能性应该较小.为了获得完全的准确性,Elasticsearch需要为每个分片收集所有作者的计数.这样做的成本可能高得令人望而却步,因此在这种情况下,以速度换取准确性是很常见的.</li></ul><p>合并过程将确定真正的前10个匹配项,然后联系托管文档的分片并请求整个文档.这个额外的步骤是有用的?还是最终增加整体延迟的优化?取决于您的用例.如果您有大量分片和相当大的文档,那么分两轮进行可能是值得的.如果您的文档很小且分片很少,则可以考虑使用<font color="DeepPink"><strong>query_and_fetch</strong></font>搜索类型.一如既往,测试和验证.</p><h1>Summary</h1><p>本文的目标是从客户端发送的索引和搜索请求开始,并达到本系列第一部分中介绍的内容.我们已经在集群状态、映射和可能的自定义路由的帮助下研究了分片路由.通过分片路由,我们已经看到分片的主节点如何协调对其副本的更改,以及事务logs如何平衡持久性和及时响应.</p><p>类似地,我们跟踪了搜索请求的流程——通过路由、平衡、分散、查询重写、响应收集、合并、后续获取等.</p><p>此外,我们还研究了映射和类型,它们为何不存在于&quot;Lucene land&quot;中,以及需要什么样的重写.索引时和搜索时.</p><p>希望您对Elasticsearch的分布式特性以及Elasticsearch和Lucene之间的界限有了更多的了解!</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]自下而上认识Elasticsearch</title>
    <url>/elasticsearch-from-the-bottom-up.html</url>
    <content><![CDATA[<blockquote><p>注意:原文发表时间是13年,所以实现有可能与新版不一致.<br>原文地址:<a href="https://www.elastic.co/cn/blog/found-elasticsearch-from-the-bottom-up" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/found-elasticsearch-from-the-bottom-up</a></p></blockquote><a id="more"></a><h1>Introduction</h1><p>在本系列文章中,我们从一个新的视角来看ElasticSearch.我们将从下往上,从抽象的底层实现到用户可见层,我们在向上移动的过程中研究各种内部数据结构和行为.</p><p>本系列文章的动机是更好地了解Elasticsearch,Lucene以及在某种程度上搜索引擎在引擎盖下是如何工作的.虽然您可以通过转动方向盘和踩下一些踏板来驾驶汽车,但高水平的驾驶员通常至少了解车辆的一些机械原理.搜索引擎也是如此.Elasticsearch提供了非常易于使用的API,它将使您入门并毫不费力地带您走得更远.但是,要充分利用它,对底层算法和数据结构有一些了解会有所帮助.这种理解使您能够充分利用其大量功能,从而改善用户的搜索体验,同时保持系统的性能、可靠性和(近乎)实时更新.</p><p>我们将从基本的索引结构开始:倒排索引.它是一种非常通用的数据结构.同时,它也易于使用和理解.也就是说,Lucene的实现是一项高度优化的,令人印象深刻的工程壮举.我们不会冒险讨论Lucene的实现细节,而是坚持如何使用和构建倒排索引.这就是影响我们如何搜索和索引的原因.</p><p>引入倒排索引作为抽象级别的&quot;底部&quot;后,我们将研究:</p><ul><li>如何执行简单的搜索.</li><li>哪些类型的搜索可以(和不能)有效地完成,以及为什么使用倒排索引来转换问题,直到它们看起来像字符串前缀问题.</li><li>为什么文本处理很重要.</li><li>如何在&quot;段&quot;中构建索引,以及这对搜索和更新有何影响.</li><li>什么构成Lucene-index.<br>*Elasticsearch分片和索引.</li></ul><p>到那时,我们将了解单个Elasticsearch节点在搜索和索引时会发生什么.本系列的第二篇文章将介绍Elasticsearch的分布式方面.</p><h1>Inverted Indexes AND Index Terms</h1><p><img data-src="/images/elasticsearch-from-the-bottom-up/inverted-index.svg" alt="Sample documents AND resulting inverted index"></p><p>假设我们有这三个简单的文档:“Winter is coming.”,“Ours is the fury.“和&quot;The choice is yours.”.经过一些简单的文本处理(小写、去掉标点、分词),我们就可以构造出如图所示的&quot;倒排索引”.</p><p>倒排索引将术语映射到包含该术语的文档(以及可能在文档中的位置).由于字典中的术语是排序的,我们可以快速找到一个术语,然后找到它在帖子结构中的出现.这与列出与特定文档相关的术语的&quot;前向索引&quot;相反.</p><blockquote><p>术语英文为term</p></blockquote><p>然后通过查找所有术语和它们的出现来完成一个包含多个术语的简单搜索,并获取出现集的交集(对于AND搜索)或并集(对于OR搜索)以获得文档的结果列表.更复杂类型的查询显然更精细,但方法是一样的:首先对字典进行操作,找到候选词,然后对相应的出现、位置等进行操作.</p><p>因此,索引术语是搜索的单位.我们生成的术语决定了我们可以(和不能)有效地进行哪些类型的搜索.例如,使用上图中的字典,我们可以高效地找到所有以&quot;c&quot;开头的术语.但是,我们无法有效地搜索包含&quot;ours&quot;的所有内容.为此,我们必须遍历所有术语,以发现&quot;yours&quot;也包含子字符串.当索引不是很小时,这是非常昂贵的.</p><blockquote><p>索引术语英文为index term</p></blockquote><p>换句话说,我们可以有效地找到给定术语前缀的东西.当我们只有一个倒排索引时,我们希望一切看起来都像一个字符串前缀问题.以下是此类转换的几个示例.有些很简单,最后一个近乎神奇.</p><ul><li>要找到以&quot;tastic&quot;结尾的所有内容,我们可以反向索引(例如&quot;fantastic&quot;→&quot;citsatnaf&quot;)并搜索以&quot;citsat&quot;开头的所有内容.</li><li>查找子字符串通常涉及将术语拆分为更小的术语,称为&quot;n-gram&quot;.例如,“yours&quot;可以拆分为”^yo&quot;、“you”、“our”、“urs”、“rs$”,这意味着我们可以通过搜索&quot;our&quot;和&quot;urs&quot;.</li><li>对于具有复合词的语言,例如挪威语和德语,我们需要将诸如&quot;Donaudampfschiff&quot;之类的词&quot;分解&quot;为例如{“donau”, “dampf”, “schiff”} 以便在搜索&quot;schiff&quot;时找到它.</li><li>诸如(60.6384, 6.5017)之类的地理坐标点可以转换为&quot;地理哈希值&quot;,在本例中为&quot;u4u8gyykk&quot;.字符串越长,精度越高.</li><li>为了启用语音匹配(例如对人名非常有用),有像 <a href="https://en.wikipedia.org/wiki/Metaphone" target="_blank" rel="noopener">Metaphone</a>这样的算法可以将&quot;Smith&quot;转换为 {“SM0”、“XMT”} 并将&quot;Schmidt&quot;转换为 {“XMT”、“SMT”}.</li><li>在处理数字数据(和时间戳)时,Lucene会以类似trie的方式自动生成多个具有不同精度的术语,因此可以高效地进行范围搜索<sup>1</sup>.简而言之,数字 123 可以存储为&quot;1&quot;-百位、“12”-十位和&quot;123&quot;.因此,搜索 [100, 199] 范围内的所有内容都是匹配&quot;1&quot;-hundreds-term 的所有内容.当然,这与搜索以&quot;1&quot;开头的所有内容不同,因为这还包括&quot;1234&quot;等.</li><li>&quot;Did you mean?&quot;键入搜索并找到接近输入的拼写,可以构建一个&quot;Levenshtein&quot;自动机来有效地遍历字典.这是异常复杂的,<a href="http://blog.mikemccandless.com/2011/03/lucenes-fuzzyquery-is-100-times-faster.html" target="_blank" rel="noopener">这里有一个关于它如何在Lucene中结束的引人入胜的故事</a>.</li></ul><p>对文本处理的技术深入研究是未来许多文章的基础,但我们强调了为什么对索引词生成一丝不苟的重要性:获得可以高效执行的搜索.</p><h1>Building Indexes</h1><p>在构建倒排索引时,我们需要优先考虑一些事情:搜索速度、索引紧凑度、索引速度以及新更改变得可见所需的时间.</p><p>搜索速度和索引紧凑度是相关的:当搜索较小的索引时,需要处理的数据较少,更适合内存中处理.正如我们将看到的,两者,尤其是紧凑性,都是以索引速度为代价的.</p><p>为了最小化索引大小,使用了各种压缩技术.例如,当存储帖子(可能会变得非常大)时,Lucene会使用可变数量的字节(小数字可以用一个字节保存),等等.</p><p>保持数据结构小而紧凑意味着牺牲有效更新它们的可能性.事实上,Lucene根本不会更新它们:Lucene写入的索引文档是不可变的,即它们永远不会更新.这与B树完全不同,例如,B树可以更新,并且通常允许您指定一个填充因子来指示您期望的更新量.</p><p>例外是删除.当您从索引中删除一个文档时,该文档会在一个特殊的删除文件中被标记为删除文件,该文件实际上只是一个更新成本低的位图.索引结构本身不会更新.</p><p>因此,更新先前索引的文档是删除后重新插入文档.请注意,这意味着更新文档比最初添加文档的成本更高.因此,在Lucene索引中存储诸如快速变化的计数器之类的东西通常不是一个好主意——没有值的就地更新.</p><p>添加新文档时(可能通过更新),索引更改首先缓冲在内存中.最终,索引文档全部刷新到磁盘.请注意,这是&quot;flush&quot;的Lucene含义.Elasticsearch的刷新操作涉及Lucene提交等,在事务日志部分中介绍.</p><p>何时刷新取决于各种因素:必须多快才能看到更改、可用于缓冲的内存、I/O饱和度等.通常,对于索引速度,缓冲区越大越好,只要它们足够小,您的I/O可以跟上<sup>2</sup>.我们将在下一节中更详细地介绍.</p><p>写入的文档组成一个索引段.</p><h1>Index Segments</h1><p><font color="DeepPink"><strong>Lucene索引由一个或多个不可变索引段组成,本质上是一个&quot;迷你索引&quot;.当您进行搜索时,Lucene会在每个段上进行搜索,过滤掉任何删除内容,并合并所有段的结果.显然,随着段数的增加,这会变得越来越乏味.为了保持段的数量可管理,当添加新段时,Lucene偶尔会根据一些合并策略合并段.<a href="https://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html" target="_blank" rel="noopener">Lucene极客Michael McCandless 有一篇很好的文章解释和可视化段合并</a><sup>3</sup>.当段被合并时,标记为已删除的文档最终被丢弃.这就是为什么添加更多文档实际上可以导致更小的索引大小:它可以触发合并.</strong></font></p><p>Elasticsearch和Lucene通常可以很好地处理何时合并段.可以通过配置合并设置来调整Elasticsearch的策略.您还可以使用优化API来强制合并.</p><p>在段被刷新到磁盘之前,更改被缓冲在内存中.在过去(Lucene&lt;2.3),每个添加的文档实际上都作为自己的小段存在<sup>4</sup>,并且所有这些都在刷新时合并.现在,有一个DocumentsWriter,它可以从一批文档中创建更大的内存段.在Lucene4中,现在每个线程都可以有一个,通过允许并发刷新来提高索引性能.(以前,索引必须等待刷新完成.)</p><p>随着新段的创建(由于刷新或合并),它们还会导致某些缓存失效,这会对搜索性能产生负面影响.像字段和过滤器缓存这样的缓存是按段的.Elasticsearch有一个<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-warmers.html" target="_blank" rel="noopener">warmer-API</a><sup>5</sup>,因此可以在新段可用于搜索之前&quot;预热&quot;必要的缓存.</p><p>使用Elasticsearch刷新的最常见原因可能是持续刷新索引,默认情况下每秒刷新一次.随着新段的刷新,它们可用于搜索,从而实现(近)实时搜索.虽然刷新不像提交那么昂贵(因为它不需要等待确认写入),但它确实会导致创建新段,使某些缓存无效,并可能触发合并.</p><p>当索引吞吐量很重要时,例如批量(re-)索引时,花费大量时间刷新和合并小段的效率不是很高.因此,在这些情况下,临时增加 refresh_interval设置,甚至完全禁用自动刷新通常是个好主意.人们总是可以手动刷新,和/或在索引完成时刷新.</p><h1>ElasticsearchIndexes</h1><blockquote><p>“计算机科学中的所有问题都可以通过另一个间接层次来解决.” – 大卫·J·惠勒</p></blockquote><p><font color="DeepPink"><strong>Elasticsearch索引由一个或多个分片组成,分片可以有零个或多个副本.这些都是单独的Lucene索引.也就是说,一个Elasticsearch索引由许多Lucene索引组成,而Lucene索引又由索引段组成.当您搜索Elasticsearch索引时,搜索会在所有分片上执行 - 进而在所有段上执行 - 并合并.搜索多个Elasticsearch索引时也是如此.实际上,用一个分片搜索两个Elasticsearch索引与用两个分片搜索一个索引几乎是一样的.在这两种情况下,都会搜索两个底层Lucene索引.</strong></font></p><p>从本文的这一点开始,当我们单独提及&quot;索引&quot;时,我们指的是Elasticsearch索引.</p><p>&quot;分片&quot;是Elasticsearch的基本伸缩单元.当文档被添加到索引中时,它被路由到一个分片.默认情况下,这是基于文档ID的哈希以循环方式完成的.在本系列的第二部分中,我们将更多地研究碎片是如何移动的.然而,重要的是要知道分片的数量是在创建索引时指定的,以后不能更改.Shay早期关于Elasticsearch的演讲很好地介绍了为什么分片实际上是一个完整的Lucene索引,以及它与其他方法相比的各种好处和权衡.</p><p>可以通过多种方式自定义哪些Elasticsearch索引以及将搜索请求发送到哪些分片(和副本).通过结合索引模式、索引别名以及文档和搜索路由,可以实现许多不同的分区和数据流策略.我们不会在这里深入探讨,但我们可以推荐 <a href="https://www.elastic.co/cn/blog/customizing-your-document-routing" target="_blank" rel="noopener">Zachary Tong 关于自定义文档路由的文章</a>和 Shay Banon 关于大数据、搜索和分析的演讲.只是为了给你一些想法,这里有一些例子:</p><ul><li>许多数据是基于时间的,例如日志、推文等.通过每天(或每周、每月……)创建索引,我们可以有效地将搜索限制在特定时间范围内——并删除旧数据.请记住,我们无法有效地从现有索引中删除,但删除整个索引的代价很小.</li><li>当搜索必须限于某个用户时(例如&quot;搜索您的消息&quot;),将该用户的所有文档路由到同一个分片可能很有用,以减少必须搜索的索引数量.</li></ul><h1>Transactions</h1><p><font color="DeepPink"><strong>虽然Lucene有事务的概念,但Elasticsearch没有.Elasticsearch中的所有操作都会添加到相同的时间线中,这不一定在节点之间完全一致,因为刷新依赖于时间.</strong></font></p><p>在分布式系统中跨节点跨索引管理不同段、缓存等的隔离和可见性非常困难.它没有试图这样做,而是优先考虑快速.</p><p>Elasticsearch有一个&quot;事务日志&quot;,其中附加了要索引的文档.附加到日志文档比构建段成本低得多,因此Elasticsearch可以将文档写入索引到持久的地方 - 除了内存缓冲区,该缓冲区在崩溃时会丢失.您还可以指定编制索引时所需的一致性级别.例如,您可以要求每个副本在索引操作返回之前为文档建立索引.</p><h1>Summary</h1><p>总而言之,当涉及到Lucene如何在单个节点上构建、更新和搜索索引时,这些是需要注意的重要属性:</p><ul><li>我们如何处理我们索引的文本决定了我们如何进行搜索.正确的文本分析很重要.</li><li>索引首先在内存中构建,然后偶尔以段的形式刷新到磁盘.</li><li>索引段是不可变的.删除的文件被标记为这样.</li><li>索引由多个段组成.对每个段进行搜索,并合并结果.</li><li>段偶尔会合并.</li><li>字段和过滤器缓存是按段的.</li><li>Elasticsearch没有事务.</li></ul><p>在本系列的下一篇文章中,我们将了解如何在集群中完成搜索和索引.</p><h1>References</h1><p>Busch, Michael: Realtime search withLucene– <a href="http://2010.berlinbuzzwords.de/sites/2010.berlinbuzzwords.de/files/busch_bbuzz2010.pdf" target="_blank" rel="noopener">http://2010.berlinbuzzwords.de/sites/2010.berlinbuzzwords.de/files/busch_bbuzz2010.pdf</a></p><p>Elasticsearch: Guide – <a href="https://www.elastic.co/guide" target="_blank" rel="noopener">https://www.elastic.co/guide</a></p><p>LuceneaPI documentation – <a href="http://lucene.apache.org/core/4_4_0/core/overview-summary.html" target="_blank" rel="noopener">http://lucene.apache.org/core/4_4_0/core/overview-summary.html</a></p><p>McCandless, Michael: VisualizingLucene’s segment merges, 2011 – <a href="http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html" target="_blank" rel="noopener">http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html</a></p><p>Willnauer, Simon: Gimme all resources you have - i can use them!, 2011 – <a href="http://blog.trifork.com/2011/04/01/gimme-all-resources-you-have-i-can-use-them/" target="_blank" rel="noopener">http://blog.trifork.com/2011/04/01/gimme-all-resources-you-have-i-can-use-them/</a></p><p>1.LuceneaPI documentation – <a href="http://lucene.apache.org/core/4_4_0/core/overview-summary.html" target="_blank" rel="noopener">http://lucene.apache.org/core/4_4_0/core/overview-summary.html</a>, NumericRangeQuery.↩<br>2.Simon Willnauer, Gimme all resources you have - i can use them!, 2011 – <a href="http://blog.trifork.com/2011/04/01/gimme-all-resources-you-have-i-can-use-them/.%E2%86%A9" target="_blank" rel="noopener">http://blog.trifork.com/2011/04/01/gimme-all-resources-you-have-i-can-use-them/.↩</a><br>3.Michael McCandless, VisualizingLucene’s segment merges, 2011 – <a href="http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html.%E2%86%A9" target="_blank" rel="noopener">http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html.↩</a><br>4.Michael Busch, Realtime search withLucene– <a href="http://2010.berlinbuzzwords.de/sites/2010.berlinbuzzwords.de/files/busch_bbuzz2010.pdf.%E2%86%A9" target="_blank" rel="noopener">http://2010.berlinbuzzwords.de/sites/2010.berlinbuzzwords.de/files/busch_bbuzz2010.pdf.↩</a><br>5.Elasticsearch, Guide – <a href="https://www.elastic.co/guide" target="_blank" rel="noopener">https://www.elastic.co/guide</a>, warmer-API.↩</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title>Gin获取Response Body引发的OOM</title>
    <url>/golang-gin-get-response-body-oom.html</url>
    <content><![CDATA[<blockquote><p>有轮子尽量用轮子 😭 😭 😭 😭 😭 😭</p></blockquote><a id="more"></a><p>我们在开发中基于Gin开发了一个Api网关，但上线后发现内存会在短时间内暴涨，然后被OOM kill掉。具体内存走势如下图：</p><p><img data-src="/images/golang-gin-get-response-body-oom/1.png" alt></p><p>放大其中一次</p><p><img data-src="/images/golang-gin-get-response-body-oom/2.png" alt></p><p>在图二中可以看到内存的增长是很快的，在一分半的时间内，内存增长了近2G。</p><blockquote><p>对于这种内存短时间暴涨的问题，pprof不太分析，除非写个脚本定时去pprof</p></blockquote><p>经过再次review代码，找到了原因</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package server</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;bytes&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com/gin-gonic/gin&quot;</span><br><span class="line">	jsoniter &quot;github.com/json-iterator/go&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">var json = jsoniter.ConfigCompatibleWithStandardLibrary</span><br><span class="line"></span><br><span class="line">type BodyDumpResponseWriter struct &#123;</span><br><span class="line">	gin.ResponseWriter</span><br><span class="line">	body *bytes.Buffer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (w *BodyDumpResponseWriter) Write(b []byte) (int, error) &#123;</span><br><span class="line">	w.body.Write(b) // 注意这一行</span><br><span class="line">	return w.ResponseWriter.Write(b)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ReadResponseBody(ctx *gin.Context) &#123;</span><br><span class="line">	rbw := &amp;BodyDumpResponseWriter&#123;body: &amp;bytes.Buffer&#123;&#125;, ResponseWriter: ctx.Writer&#125;</span><br><span class="line">	ctx.Writer = rbw</span><br><span class="line"></span><br><span class="line">	ctx.Next()</span><br><span class="line"></span><br><span class="line">	rawResp := rbw.body.String()</span><br><span class="line">	if len(rawResp) == 0 &#123;</span><br><span class="line">		AbnormalPrint(ctx, &quot;resp-empty&quot;, rawResp)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	ctx.Set(ctx_raw_response_body, rawResp)</span><br><span class="line"></span><br><span class="line">	// 序列化Body,并放到ctx中</span><br><span class="line">	// 读取响应Body的目的是记录审计日志用</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// AbnormalPrint 异常情况，打印信息到日志</span><br><span class="line">func AbnormalPrint(ctx *gin.Context, typ string, rawResp string) &#123;</span><br><span class="line">// 具体代码忽略</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单一看，这不就是Gin获取响应体一种标准的方式吗？毕竟GitHub及Stack Overflow上都是这么写的<br><a href="https://github.com/gin-gonic/gin/issues/1363" target="_blank" rel="noopener">https://github.com/gin-gonic/gin/issues/1363</a><br><a href="https://stackoverflow.com/questions/38501325/how-to-log-response-body-in-gin" target="_blank" rel="noopener">https://stackoverflow.com/questions/38501325/how-to-log-response-body-in-gin</a></p><p>那么问题出在哪呢？</p><p>再看下代码，可以看到这个代码的逻辑是每一个请求都会将响应的Body完整的缓存在内存一份，对于响应体很大的请求，在这里就会造成内存暴涨，比如：像日志下载。</p><p>找到了原因修改起来就比较简单了,根据请求响应的Header跳过文件下载类的请求;同时根据请求的Header跳过SSE及Websocket请求，因为这两类流的请求记录到审计日志中意义不大，而且在json序列化的时候也会有问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package server</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;bytes&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;net/http&quot;</span><br><span class="line">	&quot;strings&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com/gin-gonic/gin&quot;</span><br><span class="line">	jsoniter &quot;github.com/json-iterator/go&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">var json = jsoniter.ConfigCompatibleWithStandardLibrary</span><br><span class="line"></span><br><span class="line">type BodyDumpResponseWriter struct &#123;</span><br><span class="line">	gin.ResponseWriter</span><br><span class="line">	body *bytes.Buffer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (w *BodyDumpResponseWriter) Write(b []byte) (int, error) &#123;</span><br><span class="line">	// 文件下载类请求,不再缓存相应结果</span><br><span class="line">	if !isFileDownLoad(w.Header()) &#123;</span><br><span class="line">		w.body.Write(b)</span><br><span class="line">	&#125;</span><br><span class="line">	return w.ResponseWriter.Write(b)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func isNoNeedToReadResponse(req *http.Request) bool &#123;</span><br><span class="line">	if isSSE(req) || isWebsocket(req) &#123;</span><br><span class="line">		return true</span><br><span class="line">	&#125;</span><br><span class="line">	return false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func isSSE(req *http.Request) bool &#123;</span><br><span class="line">	contentType := req.Header.Get(&quot;Accept&quot;)</span><br><span class="line">	if contentType == &quot;&quot; &#123;</span><br><span class="line">		contentType = req.Header.Get(&quot;accept&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">	contentType = strings.ToLower(contentType)</span><br><span class="line">	// sse</span><br><span class="line">	if !strings.Contains(contentType, &quot;text/event-stream&quot;) &#123;</span><br><span class="line">		return false</span><br><span class="line">	&#125;</span><br><span class="line">	return true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types</span><br><span class="line">// https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Disposition</span><br><span class="line">func isFileDownLoad(responseHeader http.Header) bool &#123;</span><br><span class="line">	contentType := strings.ToLower(responseHeader.Get(&quot;Content-Type&quot;))</span><br><span class="line">	if strings.Contains(contentType, &quot;application/octet-stream&quot;) &#123;</span><br><span class="line">		return true</span><br><span class="line">	&#125;</span><br><span class="line">	contentDisposition := responseHeader.Get(&quot;Content-Disposition&quot;)</span><br><span class="line">	if contentDisposition != &quot;&quot; &#123;</span><br><span class="line">		return true</span><br><span class="line">	&#125;</span><br><span class="line">	return false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func isWebsocket(req *http.Request) bool &#123;</span><br><span class="line">	conntype := strings.ToLower(req.Header.Get(&quot;Connection&quot;))</span><br><span class="line">	upgrade := strings.ToLower(req.Header.Get(&quot;Upgrade&quot;))</span><br><span class="line">	if conntype == &quot;upgrade&quot; &amp;&amp; upgrade == &quot;websocket&quot; &#123;</span><br><span class="line">		return true</span><br><span class="line">	&#125;</span><br><span class="line">	return false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ReadResponseBody(ctx *gin.Context) &#123;</span><br><span class="line"></span><br><span class="line">	if isNoNeedToReadResponse(ctx.Request) &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rbw := &amp;BodyDumpResponseWriter&#123;body: &amp;bytes.Buffer&#123;&#125;, ResponseWriter: ctx.Writer&#125;</span><br><span class="line">	ctx.Writer = rbw</span><br><span class="line"></span><br><span class="line">	ctx.Next()</span><br><span class="line"></span><br><span class="line">	contentType := ctx.Writer.Header().Get(&quot;content-type&quot;)</span><br><span class="line">	if !strings.Contains(contentType, &quot;application/json&quot;) &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rawResp := rbw.body.String()</span><br><span class="line">	if len(rawResp) == 0 &#123;</span><br><span class="line">		AbnormalPrint(ctx, &quot;resp-empty&quot;, rawResp)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	ctx.Set(ctx_raw_response_body, rawResp)</span><br><span class="line"></span><br><span class="line">	// 序列化Body,并放到ctx中</span><br><span class="line">	// 读取响应Body的目的是记录审计日志用</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// AbnormalPrint 异常情况，打印信息到日志</span><br><span class="line">func AbnormalPrint(ctx *gin.Context, typ string, rawResp string) &#123;</span><br><span class="line">// 具体代码忽略</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实，写这篇文章的目的并不是为了阐述这个问题如何解决，而是想说:</p><ul><li>Copy 代码的时候需要留意下自己的场景</li><li>尽量用轮子，而不是自己去造轮子</li></ul><p>在我们手写API网关的时候，还遇到过以下问题</p><ul><li>第一版的网络处理也是手写的，导致对于各种Content-Type处理不好;</li></ul><ul><li>因为要解析Body，也没有精力去适配各种压缩协议，所以在网关这里会强制关闭压缩;</li><li>手写网络处理，会出现一些诡异的问题<ul><li>比如：我们支持页面终端连接到K8S集群，而这个终端连接走的是Websocket，假设支持该连接操作的服务是A(就是:页面&lt; - - - - - - &gt;网关&lt; - - - - - - &gt;服务A&lt; - - - - - - &gt;K8S集群)，那么后面过网关的请求部分请求会直接请求到服务A上(此时根本没有走网关的API router,直接就复用Websocket这个连接了)，即使这些API不是服务A的。</li></ul></li></ul><p>第一版手写网络请求处理的代码示意如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func proxyHttp(ctx context.Context, proxy_req *http.Request, domain string) &#123;</span><br><span class="line">	// origin request</span><br><span class="line">	req := ctx.Request()</span><br><span class="line"></span><br><span class="line">	response, err := HttpClient.Do(proxy_req)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		// 打印异常</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	defer response.Body.Close()</span><br><span class="line"></span><br><span class="line">	//copy response header</span><br><span class="line">	if response != nil &amp;&amp; response.Header != nil &#123;</span><br><span class="line">		for k, values := range response.Header &#123;</span><br><span class="line">			for _, value := range values &#123;</span><br><span class="line">				ctx.ResponseWriter().Header().Set(k, value)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	// status code</span><br><span class="line">	ctx.StatusCode(response.StatusCode)</span><br><span class="line">	buf := make([]byte, 1024)</span><br><span class="line"></span><br><span class="line">	for &#123;</span><br><span class="line">		len, err := response.Body.Read(buf)</span><br><span class="line">		if err != nil &amp;&amp; err != io.EOF &#123;</span><br><span class="line">			// 打印异常</span><br><span class="line">			break</span><br><span class="line">		&#125;</span><br><span class="line">		if len == 0 &#123;</span><br><span class="line">			break</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		ctx.ResponseWriter().Write(buf[:len])</span><br><span class="line">		ctx.ResponseWriter().Flush()</span><br><span class="line">		continue</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">	ctx.Next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func proxyWebSocket(ctx context.Context, request *http.Request, target string) &#123;</span><br><span class="line">	var logger = ctx.Application().Logger()</span><br><span class="line">	responseWriter := http.ResponseWriter(ctx.ResponseWriter())</span><br><span class="line"></span><br><span class="line">	conn, err := net.Dial(&quot;tcp&quot;, target)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		// 打印异常</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	hijacker, ok := responseWriter.(http.Hijacker)</span><br><span class="line">	if !ok &#123;</span><br><span class="line">		http.Error(responseWriter, &quot;Not a hijacker?&quot;, 500)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	nc, _, err := hijacker.Hijack()</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		// 打印异常</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	defer nc.Close()</span><br><span class="line">	defer conn.Close()</span><br><span class="line"></span><br><span class="line">	err = request.Write(conn)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		// 打印异常</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	errc := make(chan error, 2)</span><br><span class="line">	cp := func(dst io.Writer, src io.Reader) &#123;</span><br><span class="line">		_, err := io.Copy(dst, src)</span><br><span class="line">		errc &lt;- err</span><br><span class="line">	&#125;</span><br><span class="line">	go cp(conn, nc)</span><br><span class="line">	go cp(nc, conn)</span><br><span class="line"></span><br><span class="line">	// wait over</span><br><span class="line">	&lt;-errc</span><br><span class="line"></span><br><span class="line">	ctx.Application().Logger().Infof(&quot;websocket proxy to %s over&quot;, target)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后来换成了基础类库的httputil.ReverseProxy来处理网络连接，问题解决。</p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Gin</tag>
        <tag>OOM</tag>
        <tag>Go</tag>
        <tag>Response</tag>
        <tag>Body</tag>
      </tags>
  </entry>
  <entry>
    <title>权限的一种实现方式</title>
    <url>/a-way-to-implement-permissions.html</url>
    <content><![CDATA[<blockquote><p>动手开发自己的鉴权服务</p></blockquote><a id="more"></a><p><img data-src="/images/a-way-to-implement-permissions/%E6%9D%83%E9%99%90UML%E5%9B%BE-%E7%AE%80%E5%8C%96.png" alt></p><p>摘出两个功能点简单说一下</p><ul><li>资源类型<ul><li>支持动态新增资源类型</li><li>资源类型新增后，支持新增资源类型权限配置(资源数据的获取支持SQL、RPC等)</li></ul></li><li>资源类型支持属性<ul><li>通过资源类型的属性，实现ABAC的能力<ul><li>比如:</li><li>资源类型APP上添加属性env，并指定env的取值，那在配置权限的时候就通过env来配置权限</li></ul></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 环境在 stage、test、dev中</span><br><span class="line">&#123;</span><br><span class="line">        &quot;StringIn&quot;: &#123;</span><br><span class="line">                &quot;env&quot;: [</span><br><span class="line">                        &quot;stage&quot;,</span><br><span class="line">                        &quot;test&quot;,</span><br><span class="line">                        &quot;dev&quot;</span><br><span class="line">                ]</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>比如 添加时间</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 周一到周五 9点到18点</span><br><span class="line">&#123;</span><br><span class="line">        &quot;WeekDayIn&quot;: &#123;</span><br><span class="line">                &quot;time&quot;: [//周一到周五</span><br><span class="line">                        &quot;Monday&quot;,</span><br><span class="line">                        &quot;Tuesday&quot;,</span><br><span class="line">                        &quot;Wednesday&quot;,</span><br><span class="line">                        &quot;Thursday&quot;,</span><br><span class="line">                        &quot;Friday&quot;</span><br><span class="line">                ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;TimeLessThanEquals&quot;: &#123;</span><br><span class="line">                &quot;time&quot;: 36000 // 18点</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;TimeGreaterThanEquals&quot;: &#123;</span><br><span class="line">                &quot;time&quot;: 3600  //9点</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>权限</category>
      </categories>
      <tags>
        <tag>权限</tag>
        <tag>RBAC</tag>
        <tag>ABAC</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Git规范的必要性</title>
    <url>/the-need-for-git-specification.html</url>
    <content><![CDATA[<blockquote><p>原文地址:<a href="https://github.com/rfyiamcool/notes/blob/main/git.md" target="_blank" rel="noopener">https://github.com/rfyiamcool/notes/blob/main/git.md</a></p></blockquote><a id="more"></a><h4 id="分支管理">分支管理</h4><ul><li>代码提交在应该提交的分支</li><li>随时可以切换到线上稳定版本代码</li><li>多个版本的开发工作同时进行</li></ul><h4 id="记录的可读性">记录的可读性</h4><ul><li>所有commit必须有注释，<strong>内容必须按照注释格式严格执行！</strong></li><li>正确为每个项目设置Git提交用到的user.name和user.email信息，以公司邮箱为准，不可随意设置以影响无法正确识别。 查看当前项目配置信息的命令：<code>git config -l</code></li></ul><h4 id="版本号-tag">版本号(tag)</h4><ul><li>版本号(tag)命名规则<br>主版本号.次版本号.修订号，如2.1.13。(遵循GitHub语义化版本命名规范)</li><li>版本号仅标记于master分支，用于标识某个可发布/回滚的版本代码</li><li>对master标记tag意味着该tag能发布到生产环境</li><li>对master分支代码的每一次更新(合并)必须标记版本号</li><li>仅项目管理员有权限对master进行合并和标记版本号</li></ul><h2 id="语义化版本">语义化版本</h2><p><img data-src="/images/the-need-for-git-specification/1.png" alt></p><p>语义化版本:</p><ul><li><p>主版本号，重大升级改动，一般 API 的兼容性变化时，包括但不限于新增特性、修改机制、删除功能， 一般不兼容上一个主版本号.</p></li><li><p>次版本号 (minor)，新增或修改功能时，必须是向下兼容，不影响软件的整体流程或概念的更新.</p></li><li><p>修订号(patch)，当你做了向下兼容的问题修正，可以理解为Bug fix版本。</p></li></ul><p>版本例子:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">v1.0.0-alpha.0</span><br><span class="line">v1.0.0-alpha.1</span><br><span class="line">v1.0.0-beta.0</span><br><span class="line">v1.0.0-rc.0</span><br><span class="line">v1.0.0</span><br></pre></td></tr></table></figure><p>label:</p><ul><li><p>alpha：内部测试版</p></li><li><p>beta：公开测试版</p></li><li><p>rc: 候选版本, 不再增加新功能.</p></li></ul><h2 id="分支管理规范">分支管理规范</h2><h3 id="Git-Flow">Git-Flow</h3><p><img data-src="/images/the-need-for-git-specification/2.png" alt></p><h3 id="分支说明">分支说明</h3><table><thead><tr><th>名称</th><th>说明</th><th>命名规范</th><th>命名示例</th><th>合并目标</th><th>合并操作</th></tr></thead><tbody><tr><td>master</td><td>线上稳定版本</td><td>master</td><td>master</td><td>–</td><td>–</td></tr><tr><td>release</td><td>预发布分支</td><td>release/xxx</td><td>release/v1.0.0</td><td>master</td><td>merge request</td></tr><tr><td>develop</td><td>当前正在开发的分支</td><td>develop</td><td>develop</td><td>master</td><td>merge request</td></tr><tr><td>feature</td><td>功能分支, 每个功能需分别建立自己的子分支</td><td>feature/功能名</td><td>feature/login</td><td>develop</td><td>merge request</td></tr><tr><td>hotfix</td><td>紧急修复分支</td><td>hotfix/xxx</td><td>hotfix/v1.0.1-xxx</td><td>master</td><td>merge request</td></tr></tbody></table><h3 id="master-分支">master 分支</h3><p><strong>使用规范:</strong></p><ul><li>master分支存放的是随时可供在生产环境中部署的稳定版本代码</li><li>使用 tag 标记一个版本用于发布或回滚</li><li>master分支是保护分支，不可直接push到远程仓master分支</li></ul><h3 id="develop-分支">develop 分支</h3><p><strong>使用规范:</strong></p><ul><li>develop分支是保存当前最新开发成果的分支</li><li>develop分支衍生出各个feature分支</li><li>小的改动可以直接在 develop 分支进行，改动较多时切出新的 feature 分支进行</li></ul><p><strong>注:</strong> 更好的做法是develop 分支作为开发的主分支，也 <code>不允许直接提交代码</code>。小改动也应该以 feature 分支提 merge request 合并，目的是保证每个改动都经过了强制代码 review，降低代码风险。</p><h3 id="feature-分支">feature 分支</h3><p><strong>使用规范:</strong></p><ul><li>分支的命名格式建议 <code>feature/login</code>.</li><li>以功能为单位从 develop 拉一个 feature 分支</li><li>每个 feature 分支颗粒要尽量小，以利于快速迭代和避免冲突</li><li>当其中一个feature分支完成后，需合并回 develop 分支，另需删除 <code>feauter/xxx</code> 分支</li><li>feature分支只与 develop 分支交互，不能与 master 分支直接交互</li></ul><p><strong>流程</strong></p><p>feature分支做完后，必须合并回Develop分支, 合并完分支后一般会删点这个Feature分支，毕竟保留下来意义也不大。</p><p><img data-src="/images/the-need-for-git-specification/3.png" alt></p><h3 id="release-分支">release 分支</h3><p>使用规范：</p><ul><li><p>分支的命名格式建议 <code>release/*</code>, <code>*</code> 以本次发布的版本号为标识.</p></li><li><p>release主要用来为发布新版的测试、预发布、修复的分支.</p></li><li><p>release分支可以从develop分支上指定commit派生出.</p></li><li><p>release分支测试通过后，合并到master分支并且给master标记一个版本号.</p></li><li><p>如在 release 分支发现 <code>bug</code> 可在 release 中修复，测试完成后合并到 develop 和 master 分支.</p></li><li><p>release分支一旦建立就将独立，不可再从其他分支pull代码.</p></li><li><p>必须合并回develop分支和master分支.</p></li></ul><p><strong>流程:</strong></p><p>Release分支基于Develop分支创建，打完Release分支之后，我们可以在这个Release分支上测试，修改Bug等。同时，其它开发人员可以基于Develop分支新建Feature (记住：一旦打了Release分支之后不要从Develop分支上合并新的改动到Release分支)发布Release分支时，合并Release到Master和Develop， 同时在Master分支上打个Tag记住Release版本号，然后可以删除Release分支了。</p><p><img data-src="/images/the-need-for-git-specification/4.png" alt></p><p><strong>注意:</strong> 如项目不大可省略该分支，避免繁琐的 gitflow 过程.</p><h3 id="hotfix-分支">hotfix 分支</h3><p><strong>使用规范：</strong></p><ul><li>命名规则：<code>hotfix/*</code>，<code>*</code> 以本次发布的版本号为标识.</li><li>hotfix分支用来快速给已发布产品修复bug或微调功能.</li><li>只能从master分支指定tag版本衍生出来.</li><li>一旦完成修复bug，必须合并回master分支和develop分支.</li><li>master被合并后，应该被标记一个新的版本号.</li><li>hotfix分支一旦建立就将独立，不可再从其他分支pull代码.</li></ul><p><strong>流程:</strong></p><p>hotfix 分支基于 master 分支创建，开发完后需要合并回 master 和 develop 分支，同时在 master 上打一个tag.</p><p><img data-src="/images/the-need-for-git-specification/5.png" alt></p><h2 id="分支操作流程示例">分支操作流程示例</h2><p>这部分内容结合日常项目的开发流程，涉及到开发新功能、分支合并、发布新版本以及发布紧急修复版本等操作，展示常用的命令和操作。</p><ol><li><p>切到 develop 分支，更新 develop 最新代码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout develop</span><br><span class="line">git pull --rebase</span><br></pre></td></tr></table></figure></li><li><p>新建 feature 分支，开发新功能</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout -b feature/xxx</span><br><span class="line">...</span><br><span class="line">git add &lt;files&gt;</span><br><span class="line">git commit -m &quot;feat(xxx): commit a&quot;</span><br><span class="line">git commit -m &quot;feat(xxx): commit b&quot;</span><br><span class="line"># 其他提交</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>如果此时 develop 分支有一笔提交，影响到你的 feature 开发，可以 rebase develop 分支，前提是 该 feature 分支只有你自己一个在开发，如果多人都在该分支，需要进行协调：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 切换到 develop 分支并更新 develop 分支代码</span><br><span class="line">git checkout develop</span><br><span class="line">git pull --rebase</span><br><span class="line"></span><br><span class="line"># 切回 feature 分支</span><br><span class="line">git checkout feature/xxx</span><br><span class="line">git rebase develop</span><br></pre></td></tr></table></figure></li><li><p>完成 feature 分支，合并到 develop 分支</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 切到 develop 分支，更新下代码</span><br><span class="line">git checkout develop</span><br><span class="line">git pull --rebase</span><br><span class="line"></span><br><span class="line"># 合并 feature 分支</span><br><span class="line">git merge feature/xxx --no-ff</span><br><span class="line"></span><br><span class="line"># 删除 feature 分支</span><br><span class="line">git branch -d feature/xxx</span><br><span class="line"></span><br><span class="line"># 推到远端</span><br><span class="line">git push origin develop</span><br></pre></td></tr></table></figure></li><li><p>当某个版本所有的 feature 分支均合并到 develop 分支，就可以切出 release 分支，准备发布新版本，提交测试并进行 bug fix</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 当前在 develop 分支</span><br><span class="line">git checkout -b release/xxx</span><br><span class="line"></span><br><span class="line"># 在 release/xxx 分支进行 bug fix</span><br><span class="line">git commit -m &quot;fix(xxx): xxxxx&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>所有 bug 修复完成，准备发布新版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># master 分支合并 release 分支并添加 tag</span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff release/xxx --no-ff</span><br><span class="line"># 添加版本标记，这里可以使用版本发布日期或者具体的版本号</span><br><span class="line">git tag 1.0.0</span><br><span class="line"></span><br><span class="line"># develop 分支合并 release 分支</span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff release/xxx</span><br><span class="line"></span><br><span class="line"># 删除 release 分支</span><br><span class="line">git branch -d release/xxx</span><br></pre></td></tr></table></figure><p>至此，一个新版本发布完成。</p></li><li><p>线上出现 bug，需要紧急发布修复版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 当前在 master 分支</span><br><span class="line">git checkout master</span><br><span class="line"></span><br><span class="line"># 切出 hotfix 分支</span><br><span class="line">git checkout -b hotfix/xxx</span><br><span class="line"></span><br><span class="line">... 进行 bug fix 提交</span><br><span class="line"></span><br><span class="line"># master 分支合并 hotfix 分支并添加 tag(紧急版本)</span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff hotfix/xxx --no-ff</span><br><span class="line"># 添加版本标记，这里可以使用版本发布日期或者具体的版本号</span><br><span class="line">git tag 1.0.1</span><br><span class="line"></span><br><span class="line"># develop 分支合并 hotfix 分支(如果此时存在 release 分支的话，应当合并到 release 分支)</span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff hotfix/xxx</span><br><span class="line"></span><br><span class="line"># 删除 hotfix 分支</span><br><span class="line">git branch -d hotfix/xxx</span><br></pre></td></tr></table></figure><p>至此，紧急版本发布完成。</p></li></ol><h2 id="提交信息规范">提交信息规范</h2><p>git commit 格式 如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br></pre></td></tr></table></figure><p>各个部分的说明如下：</p><ul><li><p><strong>type 类型，提交的类别</strong></p><ul><li><strong>feat</strong>: 新功能</li><li><strong>fix</strong>: 修复 bug</li><li><strong>docs</strong>: 文档变动</li><li><strong>style</strong>: 格式调整，对代码实际运行没有改动，例如添加空行、格式化等</li><li><strong>refactor</strong>: bug 修复和添加新功能之外的代码改动</li><li><strong>perf</strong>: 提升性能的改动</li><li><strong>test</strong>: 添加或修正测试代码</li><li><strong>chore</strong>: 构建过程或辅助工具和库（如文档生成）的更改</li></ul></li><li><p><strong>scope 修改范围</strong></p><p>主要是这次修改涉及到的部分，简单概括，例如 login、train-order</p></li><li><p><strong>subject 修改的描述</strong></p><p>具体的修改描述信息</p></li><li><p><strong>范例</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">feat(detail): 详情页修改样式</span><br><span class="line">fix(login): 登录页面错误处理</span><br><span class="line">test(list): 列表页添加测试代码</span><br></pre></td></tr></table></figure></li></ul><p>这里对提交规范加几点说明：</p><ol><li><code>type + scope</code> 能够控制每笔提交改动的文件尽可能少且集中，避免一次很多文件改动或者多个改动合成一笔。</li><li><code>subject</code> 对于大部分国内项目而已，如果团队整体英文不是较高水平，比较推荐使用中文，方便阅读和检索。</li><li>避免重复的提交信息，如果发现上一笔提交没改完整，可以使用 <code>git commit --amend</code> 指令追加改动，尽量避免重复的提交信息。</li></ol><h2 id="hotfix">hotfix</h2><p>使用 <code>checkout</code> 命令，直接退回到最近一次上线的tag位置，然后以此为基准创建一个新的fix分支:</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -b hotfix/fix-login v1.1.0</span><br></pre></td></tr></table></figure><p>执行完以后就已经在新创建的 <code>hotfix/fix-login</code> 分支了，而且代码已经回到了最近一次上线的状态。完成修复以后直接commit并打上新的tag, 比如<code>v1.1.0</code>, 最后切回master分支，将<code>fix-bug</code>合并到master即可：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git commit <span class="string">'修复xxx问题'</span></span><br><span class="line">git tag v1.1.1</span><br><span class="line"></span><br><span class="line">git checkout master</span><br><span class="line">git merge v1.1.1</span><br></pre></td></tr></table></figure><h2 id="回滚代码">回滚代码</h2><p>直接 <code>git revert</code> 当前代码，然后通过 <code>cicd</code> 的特性对上一个 git tag号进行回滚.</p><h2 id="merge-vs-rebase">merge vs rebase</h2><p>同一个分支使用rebase</p><p>不同分支使用merge</p>]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>身份的焦虑笔记</title>
    <url>/status-anxiety-notes.html</url>
    <content><![CDATA[<p>本文整理自:《身份的焦虑》<br>作者:【英】阿兰·德波顿</p><p>生活就是用一种焦虑代替另一种焦虑,用一种欲望代替另一种欲望的过程。</p><a id="more"></a><ul><li><p><font color="red">我们身上那些更加隐秘的侧面——诸如我们的困惑、我们的愠怒,我们的罪恶感——有时竟然在某一书页上跟我们撞个正着,一种自我认同感于是油然而生。那位作者用确切的文字描述了一种我们原以为只有我们自己才有所会心的情境,一时间,我们就像两个早早地去赴约吃饭的爱人,兴奋不已地发现两人间竟有这么多的共同点（陶醉之下,只能嚼几口眼前的开胃小食,哪有心思再去吃什么正餐）,我们也会把书暂时放下,带点乖张地微笑着盯着书脊不放,仿佛在说,“何等幸运,邂逅此君。”</font></p><p><font color="red">马塞尔·普鲁斯特曾表达过类似的意思,他说,“事实上,每个读者只能读到已然存在于他内心的东西。书籍只不过是一种光学仪器,作者将其提供给读者,以便于他发现如果没有这本书的帮助他就发现不了的东西。”</font></p><p><font color="red">我们的个性并非如我们乐于想象的那般密不透风,我们自以为只归我们独有的很多东西其实根本没那么私密——当然并不是说它们就是客观超然的,像你在快餐店里招呼侍应生那么不带感情色彩,而是说它们其实都是人类所共有的东西。我们在发现自己并非如此孤立的同时也要付点代价:我们也并非如我们想象的那般与众不同。</font></p></li><li><p>新的经济自由使数亿中国人过上了富裕的生活。然而,在繁荣的经济大潮中,一个已经困扰西方世界长达数世纪的问题也东渡到了中国:那就是身份的焦虑。</p><p>身份的焦虑是我们对自己在世界中地位的担忧。不管我们是一帆风顺、步步高升,还是举步维艰、江河日下,都难以摆脱这种烦恼。为何身份的问题会令我们寝食难安呢？原因甚为简单,身份的高低决定了人情冷暖:当我们平步青云时,他人都笑颜逢迎;而一旦被扫地出门,就只落得人走茶凉了。其结果是,我们每个人都惟恐失去身份地位,如果察觉到别人并不怎么喜爱或尊敬我们时,就很难对自己保持信心。我们的&quot;自我&quot;或自我形象就像一只漏气的气球,需要不断充入他人的爱戴才能保持形状,而他人对我们的忽略则会轻而易举地把它扎破。因此,惟有外界对我们表示尊敬的种种迹象才能帮助我们获得对自己的良好感觉。</p></li><li><p>身份的焦虑是何时产生的呢？生活的基本需求总应该首先得到满足吧。<font color="red">在饿殍遍地的饥馑年月里,很少有人会因为身份而焦虑。历史证明,社会保障了生活的基本需求之际,就是身份的焦虑滋生之时。</font>在现代社会里,我们总爱拿自己的成就与被我们认为是同一层面的人相比较,身份的焦虑便缘此而生了。翻开报纸,发现上面有熟人光彩照人的相片（这足可以毁掉你整个早晨的心情）;你的好友兴冲冲地告诉你一个消息（他们升了职、他们即将结婚、他们的书上了畅销书排行榜）,因为他们幼稚地、甚至带点施虐性地认为这是一个好消息。在晚会上,有人用力地握着我们的手,问我们在&quot;干&quot;什么,而他自己筹集资金刚刚开张了一家新公司:每当这一切发生时,我们便为自己的身份地位而担心了。</p></li><li><p>现今,身份的焦虑比以往任何时候都强烈,因为每个人获取成功（性爱的成功、经济的成功和职业的成功）的可能性似乎比以往任何时候都大。要想觉得自己不是一个&quot;失败者&quot;,我们必须期望更多的东西。我们每时每刻都被成功人士的故事所包围。<font color="red">然而回顾历史,我们可以发现,在绝大多数时代里,人们的主导思想与之完全相反:对生活抱以很低的期待不仅正常,而且明智。仅有极少数的人立志追求财富与成就。就大多数人而言,他们知道自己活在世上就是为人奴役、逆来顺受。即使是今天,我们攀上社会顶层的可能性也微乎其微。我们很难获得能与比尔·盖茨一较高下的成功,就如同一个17世纪的人想获得路易十四那样的权力是痴人说梦一样。然而不幸的是,现在的人们觉得这一切并非没有实现的可能——这种想法来自于每个人阅读的杂志。事实上,如果谁没有为了实现这一切而全力以赴,那才是世间最荒唐无稽的事情。</font></p></li><li><p>富豪们是否也会受到身份焦虑的困扰？答案是肯定的,因为他们攀比的对象是与他们同等地位的人。我们所有人的做法都并无二致,故而即使我们比历史上的任何时期的人都富裕,到头来还是觉得一无所有、两手空空。并非我们不知好歹,而是因为我们并不以古人为参照来判断自己。与古人或与其他地域的人相比而显现出的富裕,并不能长时间地使我们开心。<font color="red">只有同那些一起长大的同伴、一起工作的同事、熟识的朋友,或是在公共场合与那些有认同感的新知相比较时,如果我们拥有和他们一样多或更多的东西的时候,我们才认为自己是幸运的。</font>因此,要想获得成功的感觉,最佳途径莫过于选择一个稍逊于己的人作为朋友……</p></li><li><p>毋庸置疑,对身份地位的渴望,同人类的任何欲望一样,都具有积极的作用:激发潜能、力臻完美、阻止离经叛道的有害行径,并增强社会共同价值产生的凝聚力。如同那些事业成功的失眠症患者历来所强调的那样,惟焦虑者方能成功,这或许具有一定的道理。但承认焦虑的价值,并不妨碍我们同时对此进行质疑。我们渴望得到地位和财富,但其实一旦如愿以偿,我们的生活反而会变得更加糟糕。我们的很多欲望总是与自己真正的需求毫无关系。过多地关注他人（那些在我们的葬礼上不会露面的人）对我们的看法,使我们把自己短暂一生之中最美好的时光破坏殆尽。假如我们不能停止忧虑,我们将会用生命中大量的光阴为错误的东西而担心,这才是最令人痛心疾首的事情。</p></li><li><p>身份的焦虑是一种担忧。担忧我们处在无法与社会设定的成功典范保持一致的危险中,从而被夺去尊严和尊重,这种担忧的破坏力足以摧毁我们生活的松紧度;以及担忧我们当下所处的社会等级过于平庸,或者会堕至更低的等级。</p></li><li><p><font color="red">这种焦虑由同事间的聊天中提到的辞职、裁员、晋升、退休等消息引起,由报纸上刊登的知名人士简介及友人更巨大的成功引起。如同承认自己嫉妒别人一样（这与焦虑情绪相联系）,表现出自己焦虑的程度在社交中是一种轻率之举,因此,反映内心变化的外部迹象并不显著,通常仅限于在听到别人的成就之后露出关切的眼神、尴尬的微笑或者过长的沉默。</font></p></li></ul><h1>第一部分　焦虑起因</h1><ul><li><p>威廉·詹姆斯在《心理学原理》（1890）中写道:“<font color="red">如果可行,对一个人最残忍的惩罚莫过如此:给他自由,让他在社会上逍游,却又视之如无物,完全不给他丝毫的关注。当他出现时,其他的人甚至都不愿稍稍侧身示意;当他讲话时,无人回应,也无人在意他的任何举止。如果我们周围每一个人见到我们时都视若无睹,根本就忽略我们的存在,要不了多久,我们心里就会充满愤怒,我们就能感觉到一种强烈而又莫名的绝望,相对于这种折磨,残酷的体罚将变成一种解脱。</font>”</p></li><li><p>亚当·斯密在他的《道德情操论》（1759）中说:“我们在这个世界上辛苦劳作、来回奔波到底为了什么呢？所有这些贪婪和欲望,所有这些对财富、权力和名声的追求,其目的到底何在呢？难道是为了满足自然的需求？如果是这样,最底层的劳动者的收入也足以满足人的自然需求。那么人类的一切被称为‘改善生存状况’的伟大目的的价值何在？”</p></li><li><p>“<font color="red">被他人注意、被他人关怀,得到他人的同情、赞美和支持,这就是我们想要从一切行为中得到的价值。</font>富有的人忘情于财富,是因为财富能够自然而然地为他吸引世界的目光。穷人则完全相反,他们以贫穷为耻。他们感觉到自己生活在世界的目光之外。一旦感到自己被世界所忽略,人类天性中最强烈的欲望将必然难以得到满足。穷人进出家门都不为人所注意,即使在闹市,他也会像独处在家一样默默无闻。而名流显贵们则不然,他们一直为世界所瞩目。所有的人都渴望能够一睹尊颜。他们的行为成为公众关心的对象。他们的片言只语、举手投足都不会被人忽略。”</p></li><li><p>人为什么要追求显耀的身份？对此问题的回答几成共识:要言之,无非是祈财、求名和扩大影响。<br>然而,有一个显然不为权势规则所关注的字眼却能更准确地表述我们心中的渴慕,那就是&quot;爱&quot;。衣食一旦无忧,累积的财物、掌控的权力就不再是我们在社会等级中追求成功的关键要素,我们开始在意的其实是显耀的身份为我们赢得的&quot;爱&quot;。金钱、名声和影响只能视为&quot;爱&quot;的表征——或者是获取爱的途径——而非终极目标。</p></li></ul><h2 id="第一章">第一章</h2><ul><li><p><font color="red">只要不觉得羞辱,人完全可以长期过着艰苦的生活而毫无怨言,如士兵和探险家们,他们愿意过着一种极其艰苦简陋的生活,其物质之匮乏远甚于现今社会上那些最窘困的群体,然而,他们能熬过一切的苦难。为什么会是这样呢？因为他们清楚自己受到他人的尊重。</font></p><p>同样,由显耀的身份所带来的东西也不仅仅局限在财富上。一些非常富足的人仍孜孜以求地聚敛财富,尽管他们所拥有的已足够供其后五代人挥霍之用。如果我们坚持以理性的财务视点来分析他们,也许会对他们的狂热感到难以理解,但是,如果我们看到在积累财富的同时,他们其实也在赢取他人的尊重,我们就不会奇怪了。很少有人只是一味地追求高雅情趣,也很少有人只是耽溺于奢华享乐,但我们每个人都渴求一种生存的尊严。因此我们可以大胆假设,如果未来社会是凭着积攒小小的塑料圆片（而非金钱）来获取他人的爱,那么,要不了多久,这种我们现在看来毫无价值的小玩意就会成为所有人追求和渴望的焦点。</p></li></ul><ul><li><p><font color="red">他人对我们的关注之所以如此重要,主要原因便在于人类对自身价值的判断有一种与生俱来的不确定性——我们对自己的认识在很大程度上取决于他人对我们的看法。我们的自我感觉和自我认同完全受制于周围的人对我们的评价。</font>如果我们讲出的笑话让他们开怀,我们就对自己逗笑的能力充满自信;如果我们受到他人的赞扬,我们就会对自己的优点开始留意。反之,如果我们进了一间屋子,人们甚至不屑于瞥上我们一眼,或者当我们告诉他们我们的职业时,他们马上表现出不耐烦,我们很可能会对自己产生怀疑,觉得自己一无是处。</p></li><li><p>当然,在一个理想世界中,我们可能更坚强一些。我们会固守自己的底线,不管别人是否在意我们,也不会顾虑别人的臧否。可能有人曲意奉承我们,但我们并不因此而自鸣得意;同样,只要我们对自身有清醒的认识,清楚自身价值之所在,他人不公允的看待也不会伤及我们,因为我们清楚自己的地位和境遇。然而,我们对自己特性和品质的认识总是在一些相互矛盾的评价中飘忽不定。一会儿觉得自己聪明机巧、幽默风趣、一言九鼎,一会儿又觉得自己蠢笨如牛、了无情趣、一钱不值,在这种摇摆无定的情状下,我们对自身价值的判断完全受制于社会的态度——若得褒扬,我们就会感觉良好;反之,则痛不欲生。仿佛我们对他人的情感负有亏欠似的。</p></li><li><p><font color="red">我们的&quot;自我&quot;或自我认知可以用一只漏气的气球来作比方——任何时候,我们都需要他人的爱（对于气球而言,便是源源不断的氦气）来填充自己的内心,而经不起哪怕是针尖麦芒大的刺伤。我们的情绪变得难以理喻,一会儿因他人的褒扬而开心,一会儿为他人的漠视而伤怀。同事的一句心不在焉的问候,几通没有应答的电话就可能使我们闷闷不乐;而如果有人记住了我们的名字,或送来一只果篮,我们又会觉得生活满洒阳光,人生何等惬意！</font></p></li></ul><h2 id="第二章">第二章</h2><ul><li><p>未成年时,没人在意我们的所作所为,我们可以无条件地受人宠爱。我们可以吃得打饱嗝而毋须顾忌,可以狂喊大叫而不顾他人感受,也可以不挣一分钱,不交一位有权有势的朋友,但是,我们还是周围的人关注的中心。</p></li><li><p>一旦成年了,就意味着我们得在这满是势利鬼和冰冷面孔的世间争取一个位置,这些人的影响是使我们产生身份焦虑的关键所在。尽管也有朋友和爱人承诺说永不抛弃我们——即便在我们破产和名誉扫地之时,他们也会和我们共同度过（有时候我们会真的相信他们）——现实却相当残酷:我们身边多的是势利小人,我们无时无刻不在他们势利的眼神下生活。</p></li><li><p>势利者关注的只是他人的声望和成就。一旦他相熟的人的声望和成就有所改变,这些势利者很可能闻风而动,重新排定他所谓最亲近的朋友,从而上演一出出悲喜剧。</p></li><li><p>深藏在我们内心的害怕其实才是势利产生的惟一根源,看清了这一点,我们也就能对势利有清楚的认识。对那些对自己的地位非常有把握的人来说,他们没有心思去把成心矮化他人当作某种消遣。傲慢的背后藏着的无非就是恐惧。由于总是感觉自己不如别人,因此才要想方设法让别人觉得他不如自己。</p></li><li><p>这种害怕还能世代相传。同人类所有的陋习一样,势利者也是代代相承。上一辈的人定会向下一代灌输低下的社会地位就是一种悲剧的观念,使下一辈不可能在感情上轻易摆脱低下的身份就意味着平庸,高尚的身份就意味着卓越的思维定势。</p></li><li><p><font color="red">然而,单凭个体的力量很难挣脱势利的桎梏,因为势利的病征是群体性的。年轻一代开始也许会对势利反感,但这还不足以将人类从势利的桎梏中解救出来。因为这很可能使他们渴望博得那些轻看他们的上层阶级的好感,因而也变得势利起来（我们可以不喜欢某些人,但这并不意味着我们不想讨得他们的欢心）。由此可见,杰出阶层的势利观念足以影响整个社会,使所有的人为了赢取别人的爱和认可而开始热衷于那些他们原本毫无兴趣的所谓追求。</font></p></li><li><p>我们也许会对买下这样一件家具的人极尽揶揄之能事,然而在我们嘲笑他们之前,我们其实应该设身处地,以更宽广的视野思考这样的问题:为什么有厂商要生产这样的家具？又为什么有人要买这样的家具？这样,我们也许不再拿这些买主打趣,因为该责备的正是我们置身其中的社会——是我们的社会预设了这样一种规范,让我们每个人都从心理上相信买下这样的橱柜是必要且值得的,因为这种过分雕琢、近乎怪诞的摆设能赢来别人的敬意。人们追求奢华,与其说是出于贪欲,倒不如说是源于一种情感上挥之不去的心结。往往是那些担心被人看不起的人,为了使自己不会显得太过寒碜,才会添置这样一件特别的家具,藉此传出一种信息:我也应该得到尊重！</p></li><li><p>在势利社会里,如果一个身份低贱的人所遭受的痛苦,在物质层面表现为贫困的话,那么被人忽略、受人白眼则是这些缺乏重要身份标志的人们在精神层面上所遭受的痛苦。</p></li><li><p><font color="red">我们所期待的远超出我们祖先们的想象,但我们付出的代价则是永远都挥之不去的焦虑——我们永远都不能安于现状,永远都有尚未企及的梦想。</font></p></li><li><p>卢梭的主要论点基于对财富的阐释。他认为,财富并不代表占有物的多少,而是拥有多少我们渴望得到的东西。它是相对的,相对于人们的欲望。任何时候,不管我们占有的财物多么丰富,只要我们还在追求某种我们不可能得到的东西,我们就谈不上富有;相反,如果我们总是满足于我们现时的拥有,不管我们实际占有的东西多么匮乏,我们是富有的。</p></li><li><p><font color="red">几个世纪以来,人们坚信苦难是人生的一部分。这一信念也就成为了人类最为重要的精神资产,成为人们面对苦难时的精神支柱。然而现代的社会观念使得人们充满渴望和期盼,也无情地改变了先前人们所固守的人生来就是受苦的理念。</font></p><p><font color="red">一旦人们觉得来世不过是一种臆想,或者从科学的角度把来世视为一种并不存在的精神鸦片,这时,追求现世成功和实现切近人生理想的压力就会无时无处不在,这使他们躁动不已,因为他们清楚人生苦短,任何的机会都可能稍纵即逝。现世的一切不再视为永恒世界的一段序曲,相反,现世的成功就是人生的一切。</font></p><p><font color="red">一个人若对来世的可能丧失信念,在希望受挫后他遭受的打击可能会更大。那些相信现世的一切只是永生世界的短暂序曲的人可能觉得他人在现世的成功不过是永恒世界中一现的昙花,因而不易心生妒嫉。</font></p></li><li><p><font color="red">“减少对自身的期望会使人有如释重负的快意,这同实现自己的期望一样,是件值得高兴的事情。倘若一个人在某个方面一无是处,而自己仍处之泰然,这将是一种难以言喻的轻松。如果有一天我们决定不必费心去减肥,也不再为青春难驻而烦忧,我们的生活该有多愉快呀！我们会说:‘谢天谢地,那些不切实际的念头终于都见鬼去了！’我们给自己增多一份期望,就是增多一份负担,虽然这也可能给自己增多一份自豪。”</font></p></li><li><p><font color="red">直到18世纪,几乎在所有西方国家,实施的还是森严的等级制度。在这种社会制度之下,除极少数例外情况,社会个体几无改变自己身份和地位的可能。这种索尔兹伯里的约翰和约翰·福蒂斯丘所高度颂扬的社会制度,从各个方面来说,都显然是极端不公正的,但它却让那些社会底层的人们有了一种自在和自由:他们不必将自己同社会中其他的人所取得的成就进行比照,因而,在心理上他们并没有感到自己严重缺乏社会身份,也没有如今底层人们那种强烈的一无所有和一无是处的焦虑。</font></p></li></ul><p><font color="red">当然,托克维尔非常清楚贵族统治制度的局限性,他并非想要回复到1776或1789年前的社会里。他看到了西方现代社会里广大民众的生活远胜于中世纪生活在社会底层的广大民众,然而,他也指出中世纪底层的民众却享有一种精神的宁静,这是现代的人们永远无法得到的。</font></p><ul><li><p>1651年,托马斯·霍布斯在其著作《利维坦》中指出,个体的存在先于社会的出现。个体是为了自己的利益才加入社会组织中,他们放弃自己的一些自由和权利,来换取社会的保护。</p></li><li><p><font color="red">18、19世纪政治和消费生产的巨大进步尽管极大程度上改善了人类的物质生活,但同时也为人类心理造成了难言苦痛,因为同社会体制和生产进步一起伴生的还有一种全新的理想——每个人都深信人生而平等,每个人都深信自己有足够的实力去实现自己的任何理想。</font></p><p><font color="red">在人类历史上长期存在的主导观念却同这种新的人人平等的思想完全相左:人与人之间的不平等才是正常;随遇而安,知足常乐才算明智。绝大多数的人深知在现实生活中他们只能接受剥削,而且逆来顺受,只有极少数的人渴望财富和实现自己的抱负。</font></p></li><li><p><font color="red">在《人性论》（1739）中,戴维·休谟这样写道:“产生这种妒忌的不是自己与他人之间的远远不成比例,反而是我们的互相接近。一个普通的士兵对他的将领不如对军曹或班长那样妒忌,一个卓越的作家遭不到一般平庸的小文人的多大妒忌,而却遭到和他地位相近的作家的妒忌。的确,人们也许会以为越是不成比例,则在比较之下所感到的不快必然越大。但是我们可以在另一方面考虑,远远的不成比例,就切断了关系,或者使我们根本不与我们距离很远的人物比较,或者就减弱了比较的效果。”</font></p><p><font color="red">我们每天都会经验到许多不平等的对待,但我们并不会因此而妒恨每一个比我们优越的人,这就是嫉妒的特别之处。有些人的生活胜过我们千倍万倍,但我们能心安无事;而另一些人一丁点的成功却能让我们耿耿于怀,寝食不安。我们妒嫉的只是和我们处在同一层次的人,即我们的比照群体。世上最难忍受的大概就是我们最亲近的朋友比我们成功。</font></p></li></ul><h2 id="第三章">第三章</h2><ul><li><p>乔治·奥威尔在他的《狮子和独角兽》（1941）一书中也记下了物质进步的各个方面:“几乎所有西方国家的公民现在都一样能使用便捷平坦的道路,享用清洁无菌的水,受到警察的保护,免费使用图书馆,还很有可能得到免费的教育。在很大程度上,穷人能和富人阅读同样的书籍,观看同样的电影,收听同样的节目。因为是大批量的生产,服装不再昂贵,再加上居住条件的改善,穷人和富人在生活方面的差异日渐缩小。要想寻找英国未来的雏形,你只需在那些轻工业区和公路沿线遛达一圈就可以了。不管是在斯劳、达格纳姆、巴尼特,还是在莱奇沃思、海斯,事实上,在任何大城市的郊区,你都能发现旧的生活模式已经日渐为新的模式所替代。在那些由玻璃和砖石砌成的新型城区里,人们的生活已然缺乏文化上的情趣。人们变得浮躁不定,和他们生活密切相关的无非是听装食品、宣传海报、收音机和内燃机等等。”</p></li><li><p><font color="red">令人奇怪的是,人类物质方面的实际拥有极大地丰富了,随之而来的竟然是一种挥之不去且愈显强烈的&quot;一无所有&quot;的感觉,以及对这种感觉的恐惧！同那些在中世纪的欧洲大地上辛勤耕作却对岁尾收成毫无把握的祖先比起来,现在的生活富有且充满机遇的这些欧洲后裔们对身份的焦虑、对所有之物的担忧远甚于他们的祖先。</font></p></li><li><p><font color="red">如果考虑到人们对&quot;怎样才算足够的&quot;判断标准中隐含的心理情愫,他们这种对&quot;一无所有&quot;的忧虑就并不奇怪了。我们从来就不会孤立地形成我们对事物（如财富和社会尊重）的相应期待,我们的判断必然有一个参照群体——那些我们认为和自己差不多的人。只有同他们比较,我们才能确定我们合适的期待视野。我们不可能孤立地欣赏自己拥有的东西,也不可能通过与中世纪祖先进行比较来衡量我们现在的拥有。同样,我们也不可能仅仅因为自己身处一个繁荣富足的历史时期而沾沾自喜。只有当我们所拥有的同儿时的朋友、现在的同事、我们看作朋友的人,以及在公众领域与我们身份相当的人一样多,甚至还要略多一些时,我们才会觉得自己是幸运的。</font></p><p><font color="red">即使我们所拥有的只是一间透风漏雨、周围环境极差的小屋子,但只要我们清楚和自己层次相当的人的生活情形也大致如此,这时,虽然我们也了解另外一个残酷的事实,即社会中的贵族住在规模宏大的庄园里,房间还有暖气供应,我们还是能认命并接受这一现实,对自身的处境亦无太多的哀怨。我们当然会觉得自己是不幸的,但这还不足以成为滋生妒嫉的温床。如果我们有了一个融乐的家庭,一份舒适的工作,但我们在一次同学聚会上发现一些老同学（再也没有任何群体比旧时的同学更堪为比照群体了）住的房子比我们大,工作更优裕,我们回家后反倒更容易生发强烈的不幸感。如果我们的比照群体比我们更加优越,更有成就,我们感到自己原本应该取得更大的成就,从而,焦虑,甚至愤恨会接踵而来。</font></p><p><font color="red">我们每天都会经验到许多不平等的对待,但我们并不会因此而妒恨每一个比我们优越的人,这就是嫉妒的特别之处。有些人的生活胜过我们千倍万倍,但我们能心安无事;而另一些人一丁点的成功却能让我们耿耿于怀,寝食不安。我们妒嫉的只是和我们处在同一层次的人,即我们的比照群体。世上最难忍受的大概就是我们最亲近的朋友比我们成功。</font></p><p><font color="red">在人类历史上长期存在的主导观念却同这种新的人人平等的思想完全相左:人与人之间的不平等才是正常;随遇而安,知足常乐才算明智。绝大多数的人深知在现实生活中他们只能接受剥削,而且逆来顺受,只有极少数的人渴望财富和实现自己的抱负。</font></p></li><li><p>尽管基督教教义也宣扬平等的观念,但基督教政治理论家几乎都回避了这样一个问题:为了使上帝的信徒能公平地享用世间的财富,我们是否可以对世间的社会等级结构做些改革和调整？是的,在上帝面前我们每个人都是平等的,但这并不表明我们在尘世就可以追求人与人之间的平等。</p></li><li><p><font color="red">“由皇室和贵族统治的国家尽管有其缺点,但在那样的社会里也有一些乐趣是现代人很难想见的。由于从没有构想过另一种社会形式,每个人仅仅了解自己的身份,而从来没有想过还会有可能改变自己的身份,所以他们绝不会产生和自己的上级或主人平起平坐的期望,因而那时的人们不会对自己的权利有任何怀疑。对他们的艰苦境遇,既无敌对反感之情绪,也无堕落蒙羞之心态,因为他们相信一切都是天定,他们只能接受。农奴的地位非常低下,但他们把自己的命运视为自然的法则。正因为如此,尽管不同阶层人民之间的命运如此迥异,但各个阶层之间并无恶意。你可以在这个社会看到很多的不平等,但你不会看到人们的心灵会因此而蒙羞。”</font></p></li><li><p><font color="red">但是,一个民主的社会拆去了所有束缚人们梦想的樊篱。一个人也许生活拮据,在物质方面远不如人,但这并不妨碍他们从理论上觉得他和任何人都是平等的。托克维尔写道:&quot;在美国,我遇到的每一个人,不管多么穷困潦倒,他们眼里都写满希望,同时心里无不对富人们的安逸舒适心生妒嫉。&quot;贫穷的国民打量着邻近街区里的富人们,坚信有一天自己也会过上富人们的生活。当然,他们的梦想并非完全是空穴来风,因为确有不少出身寒门的美国人取得了相当的成就。尽管如此,例外并不代表普遍情况,美国仍然有生活在底层的人们。同先前的贵族统治制度下的穷人不同,美国底层的人把他们差强人意的生活现状归咎于期望的泡汤或理想的受阻。</font></p></li><li><p>以仆人对主人的态度为基点,托克维尔认为,民主社会与贵族社会对贫穷的看法大相径庭。<font color="red">在贵族社会里,底层的仆人能泰然地接受他们的命运,用托克维尔的话来说,他们能&quot;愉快地生活,对自己的工作感到自豪,同时也不失自尊&quot;。然而,在一个民主社会里,有的只是报刊和社会舆论没完没了的鼓噪,让每个生活在底层的人都相信他们总有机会攀上社会金字塔的塔尖,有机会成为实业家、大法官、科学家,甚至是总统。这种无限机遇的论调在一开始也许能给人一种盲目的乐观,对那些底层的年轻人尤甚。但在他们之中,只有极少数最优秀的幸运儿才有机会脱颖而出,实现他们的梦想;而多数的人,随着时间一天天过去,他们并不能改变自己的身份,正如托克维尔所言,他们会转而变得意志消沉,内心极度痛楚,并轻贱自己,同时也憎恶自己的顶头上司们。</font></p></li><li><p><font color="red">直到18世纪,几乎在所有西方国家,实施的还是森严的等级制度。在这种社会制度之下,除极少数例外情况,社会个体几无改变自己身份和地位的可能。这种索尔兹伯里的约翰和约翰·福蒂斯丘所高度颂扬的社会制度,从各个方面来说,都显然是极端不公正的,但它却让那些社会底层的人们有了一种自在和自由:他们不必将自己同社会中其他的人所取得的成就进行比照,因而,在心理上他们并没有感到自己严重缺乏社会身份,也没有如今底层人们那种强烈的一无所有和一无是处的焦虑。</font></p></li><li><p>在托克维尔对美国进行考察数十年后,对这个问题予以关注的是一个美国人——威廉·詹姆斯。他从心理学的角度探讨了这种因社会使每一成员产生无限期望而带来的困扰。</p><p>詹姆斯认为,对自己感到满意,并不要求我们在任何领域都取得成功。<font color="red">失败并非任何时候都会给我们带来羞辱,只有某件事情我们不仅尽力而为了,而且在一开始就觉得此事关涉我们的自尊和成就感,结果却还是做砸了,这时我们才会觉得羞愧。因此我们对自己设定的目标决定了我们对成功和失败的解读。</font>詹姆斯,这位哈佛的心理学教授,曾经期望自己成为一位杰出的心理学家。如果不能实现这一理想,他会觉得自己颜面顿失。因此,他承认自己必定会妒嫉那些在心理学方面比自己更有研究的人,并感到羞愧。然而,如果有人能翻译整部《会饮篇》,而他费尽心思甚至还弄不明白该书的起首几行文句,对此,他倒不会有什么不自在,因为他从未立志学习古希腊文字。</p><p>詹姆斯认为:<font color="red">对于我们未曾想去尝试的事情,就不可用成败来衡量;既无失败,何来羞辱？</font></p></li><li><p>大众传媒的迅猛发展使得人们对自身的期望变得更高了。阿尔弗雷德·哈姆斯沃思,英国《每日邮报》的创办者,在1896年报纸首发仪式上坦率地告诉民众,他心目中的理想读者就是那些虽然现在&quot;年收入只有100英镑&quot;,心里却梦想着&quot;来年能有1000英镑进账的人&quot;。与此同时,在美国则有《妇女家庭杂志》（1883年创刊）、《大都市》（1886年创刊）、《芒赛》（1889年创刊）以及《时尚》（1892年创刊）等刊物杂志将各种奢华的生活推至读者眼前。例如,19世纪末的美国《时尚》杂志告诉读者的信息不外乎如下:美洲杯赛过后,有哪些人上了约翰·雅各布·阿斯特的诺马哈游艇狂欢,寄宿学校里最时尚的女孩正如何穿戴打扮,纽波特和南安普敦谁在筹办最棒的舞会,还有正餐的鱼子酱应该和什么配在一起（土豆和酸奶油）。</p><p>此外,电台广播和影视资讯也使人们越来越有可能了解上流社会的生活情况,并和上流阶层攀上一定的关系。到20世纪30年代,美国人每周耗在电影院的时间高达1.5亿小时,至于收听广播的时间更是高达10亿小时。1946年还只有0.02%的美国家庭拥有电视机,而这一比例到2000年已经攀至98%。</p><p>这些新的媒介所传达的内容和信息助长了人们对生活的渴望,而穿插在节目之间的广告更是推波助澜。</p></li><li><p><font color="red">诚然,现代社会前所未有地提高了我们的收入,至少使我们看起来更为富有。实际上,现代社会给人们真实的感受却是使我们愈来愈感觉到贫穷。现代社会激发了人们无限的期望,在我们想要得到的和能够得到的东西之间、在我们实际的地位和我们理想的地位之间造成了永远无法填补的鸿沟。我们可能比原始社会里的野人更觉得一无所有</font>——诚如卢梭所言（他的论断在此达到了最令人难以信服的地步）,原始的野人只要有一块屋顶遮住他们头顶的天,几只苹果和坚果填饱了他们的肚子,在晚上拨弄&quot;某些粗糙的乐器&quot;来聊以自慰,或&quot;用石斧做渔船&quot;来消磨时光,他们心中的满足就无以复加了。<br>卢梭对现代人和野蛮人之间幸福程度的比较使我们很自然联想到詹姆斯所说的期望对幸福的决定作用。也许我们拥有的不多,但由于期望的减少我们能知足常乐;反之,现代社会鼓励人们追求一切,尽管我们已经非常富有,我们却终日焦虑多愁。</p></li><li><p>卢梭所言的野人可谓是衣不遮体,一无所有。但同现代社会中住在&quot;泰姬陵&quot;里的人相比,他们至少能够享受因渴求很少而导致的极大的富裕。</p></li></ul><h2 id="第四章">第四章</h2><ul><li><p>就物质层面看,在社会等级中位居低层,此般境遇少有快乐可言。但从精神层面看就不尽然,低层的人不一定总得无时无地苦不堪言。在很大程度上,贫困对自尊的影响取决于周围的人对贫穷的理解和看法。</p></li><li><p>“有一次我和这样一个资产者在曼彻斯特街上走,和他谈到工人区的恶劣的不合卫生的建筑体系,谈到这些地区的可怕的居住条件,我说我还没有看到过比曼彻斯特建筑得更坏的城市。他静静地听完这一切,在走到拐角上和我告别的时候,他说:‘但是在这里到底可以赚很多钱。再见,先生！’英国资产者对自己的工人是否挨饿,是毫不在乎的,只要他自己能赚钱就行。一切生活关系都以能否赚钱来衡量,凡是不赚钱的都是蠢事,都不切实际,都是幻想。”</p></li><li><p>19世纪40年代曼彻斯特贫民窟的生活也许谈不上愉快,但如果生活在这里的穷困工人阶级了解到是他们雇主贪婪和残忍,是资本主义制度无处不在的贪污和腐化造成了他们眼下的困境（而且这种社会制度不可能凭他们个人的力量得到改变）,那么,这些工人们至少能获得一种道义上的优越感,而不致因自己艰难的生活现状而觉羞愧。</p></li><li><p>从公元30年到1989年,上述的三个故事通过各自不同的方式为身份低下的人们提供了精神上的慰藉。当然,诸如此类的故事还有很多,但这三个是最有说服力,也为最多的人所信奉。它们向世上不幸的穷人传达了三个观念:其一,他们才是社会财富的创造者,他们理应赢得尊重;其二,在上帝看来,世间的地位并不代表任何的道德意义;其三,从任何层面看,富人都不值得尊敬,他们冷酷无耻,而且终归在即将到来的无产者正义的革命风暴中灭亡。</p></li><li><p>如同旧的贵族阶层一样,新的精英论者一方面允许社会财富的分配存在极大的不均,但另一方面,同激进的平等主义者一样,坚持要求每个人在人生或事业起始之时必须完全平等。精英制度认为,如果每个人都能接受同样的教育,而后又有同等的工作机会,那么,日后即便出现了收入不均衡或声望不平等,也完全是可以接受的,因为这些不平等基本是人们智识和才干的差异造成的。所以,社会财富无须均分;一些人享有特权,是他们智识超人的结果,而一些人可能吃尽苦头,也只能自怨自艾,怪不得他人。</p></li><li><p>人们开始更倾向于认同这样的观念,即人的才识往往能影响或决定他在社会上的地位,这种认同反过来赋予了金钱一种新的道德涵义。过去,社会上的财富是依据血亲关联世代相袭,金钱的涵义自然只是昭示某人有幸而生于富贵之家,因而,人们自然也不会将金钱视为一个人智识和才能的指标。但在精英社会里,一个人如果没有相当的才干,他不可能有一份高声望、高薪酬的职位。故而财富成为一个人良好秉性的象征:富人不仅富有,而且就是比别人优秀。</p></li><li><p>对那些身份低微的人,这个故事不可避免地存在负面影响。既然成功者理应成功,那么失败者就理应失败。因此,在精英崇拜制度下人们致富无可厚非,同理,人们挨穷也不是没有缘由。正因为如此,一个人身份低微,其境遇固然令人同情,但一切也是咎由自取。</p></li><li><p>在过去,贵族阶层多是世袭其家族的钱财和庄园,而今精英统治的经济体系下的富裕阶层凭借的却是自己的个人奋斗,因此,他们的致富能够体现个人的价值,这是先前的贵族阶层从未体验过的。但另一方面,现今穷窘的底层民众也多了一份羞辱感,这也有别于先前的农夫们:先前的农夫们由于被剥夺了生活中的任何机会,因此他们幸运地无需为自己的境况感到羞辱。</p></li><li><p>在新的精英崇拜制度的年代,那些未获成功者要（对自己或别人）回答,为什么他无论从哪方面看都是优秀、聪明和有能力的,却仍然那么贫困,变得更为棘手和痛苦。</p></li><li><p>因为经济的精英崇拜制度的兴起,在世界不少地区,穷人已不再是不幸的人、需要慈善救济且让富人怀有负罪感的人,而变成了人生的失败者、让那些凭着积极心态自我进取的精英阶层所不齿的人。富人们已然不再因为他们奢华的生活而觉得羞愧,也不会对曾经和他们同伍、而今已被他们远抛身后的穷人们施与同情。</p></li><li><p>对于社会财富分配背后的正当理据,19世纪的社会达尔文主义的表述应该是最为直露了。社会达尔文主义者认为,一个社会的资源,即金钱、工作和荣誉等都相当有限;要获取这些资源,就必然有一番争斗。在这场争斗中,他们认为,社会里的所有人从一开始都是公平的。然而,争斗的结果却因人而异。一些人天性卓异,在这场争斗中占尽上风,他们并无任何不平等的优势,也不是凭什么运气。从道义上看,富人似乎形象不佳,但从自然进化的角度看,富人却远远胜出穷人,情形甚至令人生畏。富人强劲有力,他们的基因比穷人刚健,他们的思维之敏捷亦远过常人,从生物理论的角度看来,富人是人类丛林中的老虎。在19世纪这种生物理论异军突起,人人奉为圭臬,它认为富人应该富有,穷人应该贫穷。<br>更有甚者,社会达尔文主义者认为穷人窘促之境遇和早亡对整个社会不无裨益,政府理应顺其自然,而不可试图帮助穷人改变现状。他们坦言,弱者是大自然的劣质产品,最好的方式就是在他们成人之前任其死亡,这样他们才不致生儿育女,进而降低整个人类的素质。动物世界把身体畸形的动物抛弃的做法同样适用于人类。因而,一个人最大的善举不是去同情并接济社会中的孱弱者,而是要任这些孱弱者自生自灭。</p></li><li><p>英国社会达尔文主义者赫伯特·斯宾塞在《社会静力学》（1851）一书中认为行善的理念从根本上违背了生物学的规律。他指出:“让孤儿、寡妇艰难度日或贫寒致死似乎是一种残忍的行为,然而,如果从整个人类的利益出发,而不是孤立地来看,这种任劣者汰灭的做法,同那种让那些因父母残病而先天病弱且鲜能存活的婴儿及早弃世的做法一样,又何尝不是一种善行……社会的自然法则从来就是淘洗剔除那些病残、智障或胸无大志、毫无主见、缺乏信仰的成员。人,如果生而健全,他就一定能适应社会,生存下来,而且理应生存下来;反之,如果他生来就不健全,就不能生存于世,而且最好死去。”<br>当时,主宰着美国商界和报界的差不多都是些白手起家的精英阶层。这些社会新宠对斯宾塞的观点趋之若鹜,因为他的社会达尔文主义思想显然是一种科学利器,有助于精英们还击工会组织、马克思主义者和社会主义者对他们的指责,进而减轻他们在经济方面的损失。1882年,斯宾塞在美国四处演说,得到商界巨头们极力捧场,可谓风光无限。斯宾塞则投桃报李,每每把这些商界精英们抬捧为&quot;人类丛林中的老虎&quot;;他们没有任何行善的义务,对社会中弱势阶层悲惨的境遇,他们无须自疚。</p></li><li><p>还有不少人,尽管不是斯宾塞的追随者,他们对社会达尔文主义的一个主要观点却感同身受,那就是为穷人提供福利是没有必要的,甚至可能是错误的。既然每个人都有能力通过个人奋斗取得成功,那么,为社会底层提供福利的政治行为岂不是鼓励他们不思进取,安于现状？</p></li><li><p>苏格兰学者塞缪尔·斯迈尔斯在其著述《自助》（1859）中勉励底层的年轻人要为自己定下较高的生活目标,提升自己的教育程度,花钱得有计划,同时,在自我奋斗的路上应该抵制可能会施以援手的政府。他写道:“政府给予人民的任何福利都会减少人民自我奋斗的必要性,同时也打击了他们自我奋斗的积极性。在人类发展的进程中,我们一直过高地估计了立法的作用。事实上,任何一种法律,不论它如何苛严,都不可能使懒惰者变得勤劳,使挥霍者变得节俭,也不可能使酒鬼变得清醒起来。”</p></li><li><p><font color="red">贫穷本身就是一种痛苦,而在精英崇拜的社会里,贫穷更是一种羞辱。</font></p></li></ul><h2 id="第五章">第五章</h2><ul><li><p>在传统社会里,要获得上层身份异常困难,但值得欣慰的是,上层身份一旦获得,就不易丧失。要想使一个贵族不再成为贵族,其难度不亚于使一个下层民众不再成为下层民众,虽然两者地位悬殊,但情形相通。决定因素在于家庭出身,而不在于一生中通过发挥才智获得了何种成就。关键在于你是谁,而不在于你做了什么。</p></li><li><p>现代社会的主要欲望却使这一情形完全颠倒过来,废除世袭的特权身份和天生的下层身份,从而使社会身份完全取决于个人成就——主要指经济方面的成就。社会身份现在很少取决于恒定不变的世袭头衔,而往往取决于一个人在发展迅速、变化莫测的经济体系中的表现。</p></li><li><p><font color="red">由于经济体系的性质,获取社会身份的奋斗有一个非常明显的特征,那就是不确定性。我们对未来的思考总基于各种忧虑:可能被同事或竞争者打败,可能缺乏实现既定目标的能力,或可能在市场的浪潮中迷失方向、误入歧途——这一切失败可能因同行的成功而变得更加糟糕。</font></p></li></ul><p>焦虑是当代欲望的伴随产物,因为生计与名誉均受至少5种无法预测的因素的制约,这5种因素构成5个原因,可以用来解释如下问题,即:我们在等级社会里为何无法稳妥地获得或持有一个自己渴望的位置。</p><h3 id="1．受变幻无常的才能的制约">1．受变幻无常的才能的制约</h3><ul><li><p>如果我们的身份取决于我们的成就,那么人们普遍认为,成功所需的就是才能以及——当心灵的宁静上升到重要位置时——对才能的可靠把握。但在多数活动中,才能并不能供我们随意支配。它可以在一阵时间出现,然后径自消失,丢下一个烂摊子。我们不能随意召唤我们身上最优秀的品质。我们远远不能拥有自己偶尔展现的才华,我们的成就大多好像来自于某种外界力量所施的恩惠,而这种外界力量的出现与消失决定了我们的生活轨迹和达成目标的能力。</p></li><li><p>古希腊人通过塑造缪斯女神,创造了一种极为深刻的形象,来表现我们与才能之间的痛苦而多变的关系。根据希腊神话,总共有9位缪斯女神,每个女神执掌某种才能,并随机将其赋予世人。这9位女神分别负责史诗、历史、情诗、音乐、悲剧、圣歌、舞蹈、喜剧和天文。这些领域的任何胜利者都谨记这样一个事实,那就是才能并非他们自己真正所有,只要这些敏感的女神们改变了主意,她们就可能在举手投足之间把这些才能悄悄地收回。</p></li><li><p>虽然希腊女神活动的领域很难说就是反映了当前人们的关注对象,但这种神话观念依然在揭示着一个深刻的道理:<font color="red">我们很难对成功所需的能力进行把握,因而我们在与未来相关的事务中被迫处于一种屈从和焦虑的状态中。</font></p></li></ul><h3 id="2．受运气的制约">2．受运气的制约</h3><ul><li>把自己的身份建立在偶然因素之上固然令人恐慌,但在一个以理性控制为主要特征的世界里,几乎不能用&quot;坏运气&quot;对失败提供可信的辩解,生活在其中恐怕要更加困难。</li></ul><h3 id="3．受雇主的制约">3．受雇主的制约</h3><ul><li><p>因为另一种可能性的存在,我们生活状态的不可预测性变得更加糟糕,那就是我们的身份不得不受雇主优先的制约。</p></li><li><p>《三英亩地与自由》表达了一种思想,这一思想在19世纪中叶以后的欧美思潮中不断为人提及:要想过上幸福生活,一个人就应该努力逃脱对雇主的依赖而直接以自己的节奏、为自己的幸福工作。</p></li><li><p>作为一个雇员,其痛苦不仅来自于对不能被长期雇佣的担心,而且来自于各种工作模式和运作机制所产生的羞辱感。几乎任何机构都具有金字塔式的等级结构,其中最底层的广大员工受制于上层的管理人员,谁将受到奖励,谁将受到处罚,变成了工作中最令人压抑的问题之一。和其他各种焦虑一样,这种焦虑也源于不确定性。因为在多数领域中,对成绩很难进行准确评估,因此升迁之路或贬谪之途具有明显的偶然性。各种机构的金字塔中,成功爬到顶端的并不一定是工作中的佼佼者,却往往是那些精通权术之人,而权术在文明生活中很难得以传授。</p></li><li><p>“如果你在做一些重要事情,你必须隐藏失败,而夸大成绩。这虽然有欺骗之嫌,但既然你的命运经常取决于他人的观点,而并不取决于事实,因此给别人留下一切进展顺利的印象很有必要。”——圭恰尔迪尼</p></li><li><p><font color="red">“被人害怕远比被人爱戴安全。爱戴受感恩纽带的维系,但因为人总是极端自私,因此只要人们一有利己的机会,就会打破这种纽带。但害怕建立在对惩罚的恐惧上,而对惩罚的恐惧则是永远有效的。”</font>——马基雅弗利</p></li><li><p>“既然大多数人既非十分善良又非极其智慧,因此与他人相处应该更多地依赖严厉,而非仁慈。”——圭恰尔迪尼</p></li></ul><h3 id="4．受雇主盈利原则的制约">4．受雇主盈利原则的制约</h3><ul><li><p>雇佣工作的稳定可靠性不仅依赖于机构中的权术运作,而且依赖于公司在市场上保持盈利的能力,然而任何生产商都很难长期保持有竞争力的地位和价格上的优势。残酷的竞争会给很多员工带来焦虑感,如同站立于一块正在融化的浮冰上,因为公司提高盈利率的最有效、最快速的途径几乎无一例外的是大幅度地裁员。</p></li><li><p>背负财政压力的公司往往会解雇来自高收入国家的员工,而雇佣来自偏远的、低收入国家的员工。它们也可能会与竞争对手合并来提高盈利率,在此过程中可以裁掉因员工合并而形成的富余人员。</p></li><li><p>企业必须不断地为市场提供更新更好的产品,而员工也随时为企业的这种压力所能导致的结果忧心忡忡。在历史的长河中,物品和服务的生命周期曾经比提供和消费它们的人类的生命周期更为长久。在日本,和服和武士外套在400年间保持不变。在中国,18世纪的人的穿着打扮和他们16世纪的祖先并无二致。<font color="red">在北欧的1300至1660年之间,耕犁的样式没有发生过变化——这种稳定性肯定能够赋予技工和工人一种安全感,他们会觉得他们所从事的行业在他们的一生中不会有任何的改变。但自从19世纪中叶以来,产品的生命周期急剧缩短,从而破坏了工人认为自己从事的行业会保持长期稳定的心理。</font></p></li><li><p>新产品和新的服务方式的出现所导致的旧产品和旧的服务方式的急骤衰落在各个经济领域中司空见惯:铁路发明之后运河的衰落,喷气引擎发明之后客轮的衰落,汽车发明之后马匹作为运载工具的衰落,个人电脑出现后打字机的衰落等等。</p></li></ul><h3 id="5．受全球经济发展规律的制约">5．受全球经济发展规律的制约</h3><ul><li><p>公司和其员工的生存受到经济整体发展规律的威胁。</p></li><li><p>持续的焦虑绝非歇斯底里的体现,而是对经济环境的现实威胁所做出的真实反应。</p></li><li><p>如果失败的想法使我们痛苦,那是因为成功是惟一可以使这个世界给予我们其友好的可靠因素。家庭纽带、朋友之情或两性相悦可能有时候会使物质方面的动力变得无关紧要,但如果一个人依赖这些货币来寻求对自己需求的稳定满足,那么他不仅过于乐观,而且有欠审慎。人类除非具有强有力的理由,否则不会轻易喜笑颜开。</p></li><li><p><font color="red">这些感情反应向我们指出,在获得身份的领域中并存着两种需求:其一为经济需求,它要求企业的首要任务就是赚钱。其二为人性需求,它使员工追求经济的安全、他人的尊敬和对职位的保有。</font><br><font color="red">虽然这两种需求可能长期共存,而没有表现出明显的冲突,但任何依赖工资的工人都无法在其生活中摆脱持久的焦虑,因为他们明白,只要这两者遇到冲突、需要从中选择时,根据商业运行的逻辑本身,胜出的一方永远都是经济需求。</font></p></li><li><p>至少在发达国家,劳资之间的冲突不再像马克思所处的时代那样表现得赤裸裸。然而,不管工作条件和劳动立法有多完善,工人始终是经济程序中的工具而已,在这个程序中,工人自己的幸福和经济上的富裕其实是次要的。<font color="red">不管老板和工人之间发展出何等深厚的同志情谊,也不管员工表现得有多么好,对工作长时间以来一直是兢兢业业,工人时刻明白,同时也时刻在焦虑他们的身份并不能得到保证——他们的身份不仅取决于自己的工作表现,也取决于单位的经济状况;他们仅仅是生产利润的工具,而永远不会像他们在感情层面上矢志以求的那样,以他们自己的需求为归宿。</font></p></li><li><p>如果雇佣关系的这种不稳定性意义重大,那么绝不仅仅是出于金钱的原因。让我们回到前面提到的主题,这种不稳定性对工人的重要意义也缘于对爱的需求,因为工作是决定我们所能获得尊敬和关怀多寡的最关键因素。我们对从事什么行业这样一个问题——通常是与他人第一次接触时被问及的第一个问题——的回答将决定我们被他人所接受的程度。<br>但不幸的是,我们很少能够有把握拥有提供一个较高水平回答的能力。我们对此问题的回答取决于经济学家笔下的曲线图的沟沟壑壑、市场上的勾心斗角、运气和灵感的反复无常——但在另一方面,我们对爱的需求保持稳定不变,且丝毫不亚于孩提时代;因而在我们的需求和世界的不确定条件之间产生了一种不平衡,而这种不确定性构成了我们身份焦虑的第五个关键原因。</p></li></ul><h1>第二部分　解决方法</h1><h2 id="第一章-v2">第一章</h2><ul><li><p><font color="red">决斗现象体现了人们严重缺乏一种信心,那就是认为自己的身份是我们自己的事,我们自己能够对它进行决定,无需随他人评价的转变而做出调整。对决斗者而言,他在别人心目中的形象是能够帮助他建立他在自己心目中形象的惟一因素。如果周围的人认为他邪恶或卑鄙,认为他是一个胆小鬼或一个失败者,一个蠢蛋或一个女人气的男人,那么他在自己心目中的形象也变得无法接受。由于他的自我形象严重依赖他人的观点,因此他宁可死于枪弹或刀伤,也不能允许不利于他的想法在公众心目中继续存在。</font></p></li><li><p>整个社会把维护身份,或更确切地说,维护&quot;尊严&quot;变成了每一个成年男性的首要任务。在传统的希腊村镇社会中,尊严叫做&quot;tīmē&quot;;在穆斯林社会中,尊严叫做&quot;sharaf&quot;;在印度社会中,尊严叫做&quot;izzat&quot;——在上述任何一种社会中,人们都认为尊严需要通过暴力才能得以维护。在传统的西班牙社会,一个honra男人必须健壮勇猛、长于床笫之欢,婚前善于在女人之间厮混,婚后保持忠贞不贰,并能够挣下足够的钱来养家,对妻子有足够的权威,能够保证她不会跟别人说一些调情的言辞或跟其他男人睡到一起。对尊严的玷污不仅源于他自己对原则的违反,而且也源于他没有以足够的暴力去应对来自他人的injuria。如果一个人在市场上被人当面羞辱,或在大街上被人满怀恶意地瞪了一眼,只要他没有向对方提出决斗的挑战,那么就相当于证实了别人对他进行冒犯的理由。</p></li><li><p>虽然我们可能会不以为然地看待这些诉诸于暴力来解决尊严问题的人,但我们和他们在思维模式的关键方面具有相同之处:在他人的轻蔑之下非常容易受到伤害。如同绝大多数决斗者一样,我们的自尊心是由他人赋予我们的价值所决定的。<font color="red">决斗虽然看起来与我们相去甚远,已经消失在历史的烟尘当中,但这一现象依然有助于揭示一种更为普遍的、在面对身份问题时人们容易受伤的感情倾向。</font></p></li><li><p>希望他人看重自己的强烈需要在历史长河中并没有丝毫减弱,依然占据着我们心理关注的首要位置。我们都害怕成为西班牙语所称的&quot;deshonrado&quot;或&quot;蒙羞之人&quot;,这一种类的人在当前的语言表达中可以通过&quot;失败者&quot;一词来完美地代表,我们对此的恐惧丝毫不亚于卡尔德隆或洛佩·德·维加悲剧中的人物对此的恐惧。</p></li><li><p>如果因为我们没有达到某一职业目标或没有能力养家糊口,我们就会丧失自己应有的身份。这种情况对我们造成的痛苦跟传统社会中的人们在遭受尊严的损失之后感受到的痛苦并无二致,不管他们把尊严称为honra,tīmē,sharaf还是izzat。</p></li><li><p>一个过路人看见苏格拉底在市场上遭人侮辱,便问他:“你难道不在乎别人辱骂你吗？” &quot;为什么要在乎呢？难道你认为一头驴踢了我以后我会恨它吗？&quot;苏格拉底回答道。</p></li><li><p>皇帝兼哲学家马库斯·奥勒留一生都在罗马不稳定的政坛上奋斗,他提醒自己,把听到的任何关于他的人品和功绩的评价首先诉诸理性分析,然后决定是否让这些观点影响他的自我观念。这一思想贯穿于他的《沉思录》（公元167年）始终。&quot;［你的品质］并不取决于他人对你的评价,&quot;哲学家皇帝坚持认为,他所处的社会深信他人的评价决定一个人的尊严,但他对此提出质疑,&quot;难道东西一受到赞扬,它的品质就会提高？难道一块翡翠如没有人赞美它,它的品质就会降低？金子、象牙、鲜花或者一棵小草呢？&quot;马库斯没有像常人那样,在听到赞扬的时候欣喜若狂,在听到诬蔑的时候沮丧万分,他认为他的自我形象应该建立在自己的分析之上:“是否每个人都会轻蔑我？这是他们的事。而我自己的事就是保证没有做过或说过任何可以遭人轻蔑的事情。”</p></li><li><p>我们不应该从以上论述中得出结论,认为他人的批评和谴责毫无例外都是站不住脚的。让理智良心来决定我们的价值,并不是无条件地期待他人的爱。不管我们做过什么,也不管我们犯过多大的错误,父母和恋人依然会看重我们,但哲学家则不同,他们认为即使父母和恋人的爱也可以用一定的标准进行分析,只不过这种标准不同于外部大世界经常陷入其中的飘忽不定、难以把握的标准。的确在有些时候,理智良心要求我们对自己更加严格要求,远甚于他人对我们的要求。哲学并没有完全摒弃成功与失败的等级对立,而只是重新确立判断过程。根据哲学观点,主流价值体系有时候会有失公正地让一些人蒙羞,同样,有时候也会有失公正地让一些人赢得尊重——在一些不公正的情形下,哲学可以帮助我们确立一种信心,即就算我们没有得到他人的溢美之词,依然有资格赢得他人的爱戴。</p></li><li><p><font color="red">同样,哲学并没有否定某种类型的焦虑能够发挥积极的作用。就像一些在事业上非常成功的失眠症患者所一直强调的那样,唯焦虑者方能成功。</font></p></li><li><p>然而,我们虽然承认一些特定的焦虑感可以帮助我们追求安全的状态,发展自己的能力,但我们对与这些相同目标相关的其他感情的作用会持怀疑态度。我们会对一些境况或财物垂涎不已,但其实一旦拥有这些东西,反而会使我们为之烦心。我们会产生一些与我们的真正需求毫不相干的愿望,如果我们屈从于这些愿望,任由它们发展,我们既可能迈向健康与美德,也很可能会迈向放纵沉溺、雷霆大怒和自我毁灭。因为这些感情的根本特征就是要么超越目标,要么不及目标,所以哲学家建议我们,应该使用分析推理能力来引导这些感情,让它们朝一个正确的目标前进,确保我们想要得到的就是我们真正需要的,我们害怕的确实就是我们应该害怕的。</p></li><li><p>如果我们已经认真地听取了对我们行为的合理批评,对由我们的追求而引起的特定焦虑已经给予了足够重视,对我们的失败已经承担了应有责任,但社会依然赋予我们一个很低的身份,在这种情况下我们就有可能会采取西方传统中一些伟大的哲学家曾经采取的思维方式:在对我们身边的价值体系有了一个比较客观公正的理解之后,我们可能会采取一种理性的遁世态度,并且不带任何为自己的行为进行辩护或孤芳自赏的味道。</p></li><li><p><font color="red">他人对我们的赞赏可以说在两个方面对我们非常重要:一是物质方面,因为社会对我们的遗弃能够带来物质方面的缺乏与危险;二是精神方面,因为一旦他人停止对我们表示尊重,我们就很难对自己继续怀有信心。</font></p></li><li><p><font color="red">他人对我们缺乏关注所导致的第二种影响,正是一种哲学思维方式所针对的东西,并因此能够给我们带来益处,因为如果采取了一种哲学思维方式,我们就不会轻易让他人对我们的敌意或者忽视伤害我们,我们首先会对他人行为的合理性进行分析。只有那些既对我们非常不利又完全真实的言论和态度才会破坏我们的自尊心。我们经常处于一种自虐过程当中,在没有搞清他人观点是否值得关注之前就去寻求他人的赞赏;但只要我们对某些人的思想稍加研究,就会发现他们根本不值得我们尊敬,然而我们往往在弄清楚这一切之前就竭力想得到他们的爱戴。我们应该停止这一自虐过程。</font></p></li><li><p>从此我们可能会毫无恶意地蔑视一些人,就像他们蔑视我们一样——哲学史中充斥着表达以上遁世立场的各种观点鲜明的例子。</p></li><li><p>&quot;一旦我们充分了解了他人思想的肤浅和空洞的本质、他人观点的狭隘性、他人感情的琐碎无聊、他人想法的荒谬乖张,以及他人错误的防不胜防,我们就会逐渐对他人大脑中进行的一切活动变得漠不关心。……然后我们就会明白任何一个过度重视他人观点的人给了他人过高的尊严,&quot;哲学遁世主义的代表人物,阿瑟·叔本华如此说道。</p><p>这位哲学家在他的《附录与补遗》（1851）中建议,要想改掉希望被他人喜欢的毛病,最快的途径就是对他人的品格进行研究,而他认为,他人的品格绝大多数都粗野残忍、愚蠢麻木。&quot;打牌已经成为每一个国家最主要的社会娱乐方式,&quot;他说。&quot;它是判断社会价值的一种方式,同时也是思想与观点消亡的标志。&quot;而且,这些玩牌的人往往生性狡诈、人品低劣:&quot;coquin méprisable一词可以非常完美地用于形容世界上的相当一部分人群。&quot;如果有些人并不邪恶,那么他们很可能就是无聊透顶。叔本华带着非常赞赏的口吻引述了伏尔泰的一句话:“La terre est couverte de gens qui ne méritent pas qu’on leur parle.”</p><p>我们还能够非常重视这种人的观点吗？叔本华问。我们还能够在真正意义上继续允许他们的判断支配我们对自己的想法吗？我们还能够理智地把我们的自我形象置于一群玩牌者的手中吗？即使这些人的的确确对某人表示了尊重,但他们的尊重到底能值几何？或者如叔本华所提的问题,“如果一个音乐家已经知道,除了一两个人之外,所有的听众都是聋子,那么是否还会因这些听众发出的震耳欲聋的掌声而沾沾自喜呢？”</p></li><li><p>这种在一定情况下对我们非常有用的真知灼见也有其固有的缺点,我们会因为认识到了这点而变得没有朋友。叔本华的同行、哲学遁世主义者尚福尔提到了这个问题:“一旦我们下定决心只去理会那些对我们做出评价时显得品行端正、纯洁善良、通情达理和实事求是的人,而这样的人把传统、自负和仪式完全等同于文雅社会的道具,因而对此毫不关注;一旦我们下此决心（而且我们必须下此决心,否则我们就会变得愚蠢、软弱或恶毒卑劣）,其结果就是我们在一定程度上必须独自生活。”</p></li><li><p>叔本华认为这种情况无可厚非。“这个世界只允许我们在孤独与卑劣之间进行选择,“他说。而且他建议年轻人应该学会&quot;如何与孤独为伍……因为一个人被迫与他人接触的机会越少,他的境况就会越好”。叔本华认为,幸运的是,任何一个稍有理智的人在与他人工作和生活一段时间后,都会自然而然地&quot;不愿和他人有频繁的交往,就像一个小学校长决不会愿意和周围的一群吵吵嚷嚷、喧闹不休的孩子搅和在一起一样”。</p></li><li><p>这种观点说明,决心躲避他人并不意味着一个人在任何情况下都不愿和他人交往。这一想法只是反映了我们对所能够交往的对象的不满。愤世嫉俗的人都不过是理想主义者,他们对事物的要求标准很高,达到了常人所难以理解的程度。用尚福尔的话说:“我们往往把一个特立独行的人看作是不喜欢人际交往的人。这样的说法就像把一个不愿在深更半夜去邦迪森林散步的人看作是不喜欢散步的人一样。”</p></li><li><p>哲学家们在他们各自独立的研究中提出,我们应该遵循自己内心的良知,而不是遵循来自外部的赞扬或谴责。问题的关键不在于我们在一个随机形成的人群中看起来是什么形象,而在于我们自己知道自己是什么形象。用叔本华的话说:“只有击中目标的谴责才能使我们受到伤害。一个人如果真正知道他不应该受到某种谴责,那么他可以满怀把握地对此不屑一顾。”</p></li><li><p>如果我们接受这种遁世哲学的建议,那么我们就应该放弃在维护我们身份方面所采取的幼稚做法——这是一个我们永远都无法完成的工作,因为它在理论上要求我们跟任何一个对我们抱有负面评价的人进行决斗,将其杀死——只有接受了遁世哲学的建议并放弃了这种幼稚的做法,我们才能够在严密分析的基础上形成对自己价值的正确认识,并从中获得一种可靠而有根有据的满足感。</p></li><li><p>用约翰·德莱登的话说,“<font color="red">讽刺的真正目的是对缺陷的纠正</font>”。</p></li><li><p><font color="red">因为我们意识到,虽然我们以某种特定的方式生活,但很少理解导致这种生活方式的原因,我们对自己和他人知之甚少,我们行为的后果又是极为严重而悲惨,我们的社会对待我们的错误又是多么地冷酷和无情。</font></p></li><li><p>不要说一个凡人是幸福的,在他还没有跨过生命的界限,还没有得到痛苦的解脱之前。</p></li><li><p>俄狄浦斯的故事在揭示我们的性格与命运的密切关系方面,能起到振聋发聩的作用:小小的失误可以明显地导致非常严重后果的发生,我们往往对我们自己行为的后果认识不足,我们总喜欢认为我们深思熟虑地掌握着我们自己的命运;我们珍视的任何东西可以在非常短的时间内全部失去;我们理性思考和预见未来的微弱能力并不能跟索福克勒斯称为&quot;命运&quot;的难以捉摸的晦冥力量相抗衡。</p></li></ul><h2 id="第二章-v2">第二章</h2><ul><li><p>艺术到底有何用处？19世纪60年代的英国,人们普遍在问这同一个问题,根据好多评论家的观点,答案是:艺术没什么用处。并非是艺术建造了大型工业城市,修筑了铁路,挖掘了运河,扩张了帝国,或使英国在世界各国中遥遥领先。</p></li><li><p>在他所处的时代,正好是人们第一次能够用一个早晨从伦敦出发到达伯明翰,并且大不列颠已经为自己挣下了世界工厂的名声的时代。</p></li><li><p>阿诺德在他的《文化与无政府状态》一书的开始就列举了种种加诸于艺术的责难。他说在多数人看来,艺术微不足道,别无所长,仅仅是&quot;涂抹在人类伤痛上的加了香料的油膏,是为优雅的懒惰呆钝状态大做宣传的宗教,而且使它的信徒拒绝致力于消除罪恶。艺术的缺陷经常被概括为脱离实际,或者——如同很多批评家熟悉的说法一样——都是胡言乱语,不可理喻&quot;。</p><p>阿诺德认为,<font color="red">伟大的艺术作品绝对不是不可理喻的胡言乱语,而是一种途径,这种途径可以帮助我们解决生活中隐藏在心灵深处的紧张和焦虑。</font>不管艺术对&quot;《每日电讯报》的年轻名流&quot;来说是何等地脱离实际,它提供给我们的不是其他,而是对生存中的缺陷的解释和解决方法。</p></li><li><p>仔细研读伟大艺术家的作品,阿诺德认为,你就会发现它们（或直接或间接地）“致力于消除人类的错误,澄清人类的混乱,降低人类的痛苦”。阿诺德说,所有的伟大艺术家都心怀一种愿望,“使这个世界变得比它原有的状态更加美好,更加幸福”。他们很可能没有使用明确的政治语言来表达自己的这种愿望,他们或许根本没有意识到自己有此种愿望,但在他们的作品中,总有一个声音在谴责现有社会的种种弊端,总有一种努力在试图纠正我们的谬误,教育我们如何去发现美丽,帮助我们了解痛苦,重新点燃我们对事物的敏感,通过让我们忧伤或大笑,培养我们感同身受的能力或使我们的道德观念平衡发展。阿诺德的结论就是这一章的主题所在。阿诺德说,艺术是&quot;对生活的批判&quot;。</p></li><li><p>那么,我们应该如何理解这句话呢？或许首先所能想到的最明显的理由就是生活是一个需要批判的现象,我们犯有原罪,具有各种缺陷,每时每刻都有犯错误的危险,例如对错误的目标进行顶礼膜拜,对自己蒙昧无知,对他人一味误解,毫无必要地满怀焦虑或贪欲重重,以及让虚荣和错误蒙蔽了自己的本性。艺术作品——小说、诗歌、戏剧、绘画或电影——可庄可谐,能够在不知不觉当中,潜移默化地向我们揭示我们的生活状态。它们有助于引导我们更正确、更审慎、更理智地理解世界。</p></li><li><p>鉴于最需要批判（或洞察和分析）的莫过于我们对身份以及如何获得身份的态度,因此我们就会毫不奇怪地发现,古今中外有众多的艺术家通过各自的作品,对人们在社会中获得地位的方式提出质疑。艺术史充满了对身份体系的不满,这种不满可以是讥讽的、愤怒的、抒情的、沮丧的或幽默的。</p></li><li><p>一部艺术作品应该有助于我们理解和欣赏那些在无人凭吊的坟墓中安息的每一个平凡人生的价值。&quot;如果艺术不能够激发我们的同情心,那么它在道德方面将毫无作用,&quot;乔治·爱略特这样认为。</p></li><li><p>绘画也可以对这个世界用来衡量何人重要或何物重要的标准提出挑战。</p></li><li><p>让-巴蒂斯特·夏尔丹在1746年画了一幅画《病人的膳食》。一位衣着朴素的妇人站在一间家具简陋的屋子里,充满耐心地为一个我们在画面上看不见的病人剥鸡蛋。这是普通人生活中极为普通的一刻。为什么要选这些东西来作为绘画素材呢？就他的大多数作品而言,批评家一致认为很难就选材的原因进行回答。他是一位天才的画家,经常神秘莫测地投入很大的精力来画面包片、破碎的盘子、刀叉、苹果和梨,或劳动阶层和下层民众在简陋的厨房或客厅在做他们各自事情的情景。</p></li><li><p>根据法国美术学院所规定的艺术准则,这当然不是人们所公认的一个伟大的艺术家应该画的内容。自从法国美术学院于1648年由路易十四建立起,它就把各种类型的绘画按照重要性进行了等级排序。排在首位的是历史绘画:用来表达古希腊、罗马的高贵庄严或描绘圣经中的伦理故事。排在第二位的是肖像画,特别是国王和王后的肖像画。接下来排到第三位的是风景画,排到最后的才是被轻蔑地称为&quot;风俗情景画&quot;的作品,用来描绘非贵族阶层的家庭生活。艺术的等级序列直接对应于艺术家画室之外世界的社会等级序列,在艺术家的笔下,骑在马上巡视自己的大片土地的国王,人们自然而然地赋予他高尚的地位,而正在剥鸡蛋的衣着朴素的妇女根本不能望其项背。</p></li><li><p>人们趋向于认为一个妇女的家务劳动或一个沐浴在午后阳光中的破旧陶器没有多大的价值,但夏尔丹用他的艺术颠覆了这种看法（“夏尔丹教导我们,一只梨可以像女人一样富有活力,一个水壶可以像宝石一样美丽动人。”——马塞尔·普鲁斯特）。</p></li><li><p>在绘画史上,我们还可以找到为数不多的同夏尔丹具有相同创作原则的画家,发现为数不多的可以纠正我们对重要性的习惯看法的作品。</p></li><li><p><font color="red">在南方相互连接的墙壁上,强烈的光线照亮了因风吹雨打而变得斑斑驳驳的灰泥,光线勾勒出每一块凹陷的、残缺的地方,就像渔夫饱经风霜的粗糙的双手一样,可以唤起我们对时光流逝的感慨;四季流转,一刻不停,单调沉寂的夏季炎热让位于狂怒的冬季暴风雨,经过了一段似乎没完没了的时间,冬季的暴风雨也会被试探性的春季阳光所替代。</font>琼斯画笔下的石头和灰泥充分地体现出了黏土、石灰和地中海山坡上坑洼不平的石块的质地。纷繁复杂的建筑给我们留下了一个城市的印象,三教九流的人物在这个城市中生活——在每个窗户后面,生活着积极向上的人、无聊乏味的人、游戏人生的人以及走投无路的人,这些人物的复杂程度丝毫不亚于伟大小说所塑造的人物的复杂程度。<br>我们很少关注屋顶,我们的眼睛很容易被罗马寺庙和文艺复兴时期教堂的金碧辉煌所吸引。琼斯把被人遗忘的角落呈现出来供我们思考,把它潜在的美表达出来,使它能够被人看见,从而在我们对幸福的理解当中,再也不会认为南方的屋顶毫无价值。</p></li><li><p>如同夏尔丹和琼斯的作品一样,克布克的作品中包含着对价值判断方面占统治地位的物质标准的挑战。这三个艺术家似乎都认为,如果夏日黄昏的天空、阳光下凹凸不平的墙壁、或为病人剥鸡蛋的无名妇女属于那些我们真正想看到的美好景象,那么我们就不得不去怀疑那些传统教育教给我们应该去尊重或羡慕的东西的价值。</p></li><li><p>给餐具柜上的水壶或田野里的奶牛赋予这样一个准政治化的价值判断似乎有点牵强附会,但克布克,琼斯或夏尔丹的作品的道德涵义极为深远,远远超出了我们习惯性地赋予一幅在纸上或布上所作的绘画的涵义,令人心荡神驰。像简·奥斯丁或乔治·爱略特一样,这些描绘日常生活的伟大艺术家能够帮助我们纠正一系列势利观念,从而对人世间何者应该受到尊重,何者应该获得荣耀得到全新的认识。</p></li><li><p><font color="red">工作失败本身固然可怕,但如果我们没有意识到一旦失败,就会受到他人苛刻的品头论足,失败也不会变得如此恐怖。我们除了惧怕失败所导致的物质损失之外,还惧怕世人对待失败的毫不宽容的态度,即世人倾向于把那些在事业上没有取得成功的人称为&quot;输家&quot;——这个词语冷漠地指向两层含义,首先是指称一些人在某些方面受到损失,其次说明他们的所作所为使他们丧失了获得同情的权利。</font></p></li><li><p><font color="red">世人在讨论大多数境遇悲惨的人的时候,其语气总是苛刻而有欠宽恕</font>,因此如果把一些文学名著中的主人公——俄狄浦斯、安提戈涅、李尔王、奥赛罗、爱玛·包法利、安娜·卡列尼娜、海达·加布勒或苔丝——的悲惨命运交给一伙同事或一帮学校的朋友进行讨论,他们的形象将会在这个过程中大打折扣。但如果让报纸来评论他们,他们的形象则会更加糟糕:<br>奥赛罗:“因爱情而失去理智的移民杀死了参议院的女儿”<br>包法利夫人:“有购物狂倾向的女通奸犯在信用欺诈之后服毒自杀”<br>俄狄浦斯王:“因与母亲发生性关系致使双目失明”</p></li><li><p>如果这些新闻标题显得有点别扭,那是因为我们一直习惯地认为这些姓名所指代的人物具有内在的复杂性,应该受到严肃而尊敬的对待,而不应该像报纸对待它的受害者那样以色情和批判的语言描绘他们。<br><font color="red">但实际上,这些人物身上并没有任何东西能够使他们毫无争议地成为关注和尊敬的对象。这些文学作品中传奇式的失败人物之所以显得庄严高贵,并非由于他们自身的素质和品德,而是由我们看待文学作品的方式所决定的,而这些方式是由其作者和记录者教给我们的。</font></p></li><li><p>有一种与众不同的文学体裁,它从诞生之日起,就致力于讲述伟大人物的失败故事,而不带任何讥讽或评判的语言。这种文学体裁并没有免除人物对自己行为应该负有的责任,它的主要成就在于给予这些陷入灾难的人们——蒙羞的政治家、杀人犯、破产者、感情冲动者——一些合理的同情,而这些同情是普通民众永远无法得到的。</p></li><li><p><font color="red">悲剧艺术始于公元前6世纪的古希腊戏剧,用来讲述一位英雄——通常出身高贵的英雄,一位国王或一位著名勇士的故事,他们往往通过自己的错误,使他们丧失辉煌而受拥戴的地位,从而面临毁灭和耻辱。悲剧陈述故事的方式能够同时产生两种影响,其一是能够使观众不愿贸然批判这些英雄的所作所为,其二是观众变得更加谦卑,因为他们认识到如果有一天,他们也将面临这些英雄人物曾经面临的困境,他们也会很容易地遭受毁灭。悲剧在讲述幸福生活实属不易时,令观众悲伤;悲剧在讲述追求幸福生活时的失败事例时,令观众谦和。</font></p></li><li><p>报纸具备一套可以把别人定义为心理变态、怪物、失败者和输家的语言,它对人的理解处于一个极端的状态,而报纸的反面则是悲剧。<font color="red">悲剧力图在罪有应得和全然无辜之间架起一道桥梁,使我们对责任的惯常理解提出质疑,它是一种最为复杂的心理呈现模式,一种对他人最为尊重的表达方式,它认为人们在丧失尊严的同时,不应该被剥夺让别人听到他们心声的权利。</font></p></li><li><p><font color="red">亚里士多德在他的《诗学》（约公元前350年）中力图规定一部令人印象深刻的悲剧应该具备的核心要素。他认为,应该有一个中心人物,事件应该在相对集中的时间和空间中展开,而且不出所料地认为,“人物命运的改变&quot;不应该是&quot;从悲惨到幸福”,而是正好相反,“从幸福到悲惨”。</font></p></li><li><p>但一部好的悲剧还应该具备其他两个更能体现悲剧本质的要求。<font color="red">悲剧人物不能过好,也不能过坏,他在道德水平上应该处于日常的、普通人的层面,我们很容易就能够跟他联系到一起,他应该具有一些优良的品质,但也不乏一些缺点,比如过度的骄傲、愤怒或冲动。主人公然后可能会犯一个严重的错误,但绝对不是出于内心深处罪恶的目的</font>,而是出于亚里士多德用希腊语称为hamartia的东西,比如判断错误、一时的盲目、一个行动上的、或感情上的失误。主人公的悲剧性弱点将会导致最可怕的peripeteia,也就是命运的逆转,在此过程中,主人公可能会丧失掉自己珍爱的一切,而且几乎无一例外地赔上自己的性命。</p></li><li><p><font color="red">建立在与主人公认同的基础上,观众会产生对主人公的怜悯和对自己状况的恐惧,这是悲剧故事带给我们的感情的自然反应。悲剧作品能够让我们受到教育,使我们谦虚地看待自己应对灾难的能力,并同时引导我们同情那些已经遭受灾难的人们。当我们离开剧院的时候,我们再也不会轻易地以一种高高在上的态度对待那些犯了错的人们和失败的人们。</font></p></li><li><p><font color="red">亚里士多德显然认为,我们对他人惨败的同情几乎全都是因为我们强烈地意识到,一旦把我们置于特定的环境中,我们也会非常容易地遭遇与他们相同的悲惨经历;同样,一旦他人的行为看起来是那些我们永远也不可能有的行为的时候,我们对他们的同情就会大打折扣。</font>当我们听到一些在我们看来是不可思议的事情的时候,例如轻率地同他人结婚,与家人发生乱伦事件,妒火中烧的时候杀死了自己的恋人,向老板撒谎,盗窃金钱,或让贪婪的本性毁掉自己的前程,我们就会问:一个头脑清醒、心智健全的人怎么会做那样的事情？只要我们认为有一道生铁铸就的墙壁把我们的本性和境况同他人的本性和境况截然分开,只要我们认为我们可以很安全地一直保持一种傲慢自得的态度,我们的大度和容忍就会被冷酷和讥讽取而代之。</p></li><li><p>但悲剧作家让我们认识到一个几乎难以接受的事实:<font color="red">在人类历史的长河中,任何一个有罪的人所犯的每一个错误都可以追溯到我们自己的某一方面的本性;在我们内心囊括了人类所有的品质,包括最优秀的品质和最恶劣的品质,在合适的情形下,或不如说,在错误的情形下,我们能够干得出任何事情。一旦观众认识到这个事实,他们就有可能摆脱他们傲慢自得的态度,从而感觉到自己施与同情和保持谦虚的能力大有提高;他们会接受这样一个事实:他们个性中的一些不良品质虽然一直没有导致严重的事件发生,但一旦置于特定的情形之下,这些缺点就会毫无约束地、灾难性地占据整个心灵,从而轻易地把他们的生活破坏殆尽</font>——然后,他们的屈辱程度和悲惨程度将会毫不亚于那些报纸上的&quot;因与母亲发生性关系致使双目失明&quot;的新闻标题所指称的主人公的遭遇。</p></li><li><p><font color="red">生活就是用一种焦虑代替另一种焦虑,用一种欲望代替另一种欲望的过程——这样说,并非要我们永远都不要去努力克服焦虑,或不要努力去满足某种欲望,而是要求我们在努力追求的过程中要明白一个道理:我们的任何一个目标向我们提供的一劳永逸的保证,按照目标本身的意思,是不可能实现的。</font></p></li><li><p><font color="red">我们同样能够很容易地误解特定职业的魅力,因为这些工作需要付出的代价往往被人剪辑掉了,而只是剩下了那些人们无法抗拒的优点。我们总是在阅读结果,而不是整个过程。</font></p></li><li><p>一旦我们停止嫉妒他人,我们就会极端痛苦地发现我们居然花了我们生命中这么多的时间来羡慕那些错误的东西。</p></li><li><p><font color="red">小小的失误可以明显地导致非常严重后果的发生,我们往往对我们自己行为的后果认识不足,我们总喜欢认为我们深思熟虑地掌握着我们自己的命运;我们珍视的任何东西可以在非常短的时间内全部失去;我们理性思考和预见未来的微弱能力并不能跟索福克勒斯称为&quot;命运&quot;的难以捉摸的晦冥力量相抗衡。</font></p></li><li><p>不要说一个凡人是幸福的,在他还没有跨过生命的界限,还没有得到痛苦的解脱之前。</p></li><li><p><font color="red">如果说悲剧作品能让我们对他人的失败给予比平常更多的关注,那主要是因为悲剧艺术能够引导我们探究失败的根源。在这种情况下,对实际情况了解越多,我们就会更易于理解他人,原谅他人。一件悲剧作品可以巧妙地使我们了解各种细节,认识男女主人公的富贵与衰败之间微妙的关联,明白意图和结果之间荒谬乖张的关系。虽然在阅读报纸上仅有大致轮廓的失败故事的时候,我们很容易就会产生漠不关心,甚至幸灾乐祸的想法,但在欣赏悲剧的过程中,我们不可能长时间地保持这种心态。</font></p></li><li><p><font color="red">我们在恐惧和沮丧中结束对福楼拜的这部小说的阅读,因为我们意识到,虽然我们以某种特定的方式生活,但很少理解导致这种生活方式的原因,我们对自己和他人知之甚少,我们行为的后果又是极为严重而悲惨,我们的社会对待我们的错误又是多么地冷酷和无情。</font></p></li><li><p>作为悲剧作品的读者或观众,我们尽可能地远离报纸标题&quot;有购物狂倾向的女通奸犯在信用欺诈之后服毒自杀&quot;所体现的思维模式。悲剧促使我们摒弃日常生活中对失败与挫折的简单化的看法,使我们以宽容的心态对待我们人性中普遍存在的愚昧与过失。</p></li><li><p><font color="red">如果这个世界中的人们从悲剧艺术中汲取了经验教训,那么我们的失败可能导致的后果就不会如此沉重地压在我们的头上。</font></p></li><li><p><font color="red">用马克思的话说:“每个时代占统治地位的思想往往是统治阶级的思想。”</font></p></li><li><p>萧伯纳,《智慧妇女的社会主义和资本主义指南》:“你必须清除头脑中的幻象,这种幻象在我们孩提时代起就已经具有了,那就是我们坚信,我们生活于其中的任何机制都是同天气变化一样自然而然,无需争议。实际上并非如此。因为它们在我们生活的小小世界里到处存在,所以我们便理所当然地认为它们一直都是存在的,而且在将来也会一直存在。这是一个极为危险的错误。它们实际上一直处于变动不居、相互替换的状态中。在过去几代人中没有人能够相信的变化确确实实地发生了。孩子们现在认为在学校里读9年书,领取养老金和寡妇赡养费,在选举中投妇女的票,以及国会中有穿短裙的女士,都是自然秩序的一部分,以前一直是,将来也会一直都是;然而他们的曾祖母如果听到有人说这些事物即将发生,那么她们将会骂说话者是个疯子——而且认为任何想要这些事情发生的人都是邪恶缺德的。”</p></li><li><p>在《玩笑及其与无意识的关系》（1905）中,弗洛伊德写道:&quot;一个玩笑能够使我们披露我们敌人的一些荒唐的东西,而用直接的或公开的方式来披露它们则会困难重重、难以实现。&quot;弗洛伊德继续写道:“如果用非玩笑的方式提出批判,有些人就会拒绝接受;但转而通过玩笑的方式,则可以得到他们的理解和承认……［这就是为什么］对身居高位的人而言,要让他们采纳批评意见,采取玩笑的方式更为普遍。”</p></li><li><p>因此,在最优秀的漫画家手里,笑声获得了一种道德教育目的,玩笑成了引导他人改善品德和习惯的手段。玩笑可以表达一个政治理想,能够创造一个更加平等、更加理性的世界。如同塞缪尔·约翰逊指出的那样,讽刺是&quot;谴责邪恶和愚蠢&quot;的惟一一条另外途径,也是非常顶用的一条途径。用约翰·德莱登的话说,“讽刺的真正目的是对缺陷的纠正”。</p></li><li><p>历史上不乏那些针对上层阶级的玩笑,这些玩笑都试图纠正他们的缺陷,使这些有权有势的人摆脱骄傲与虚伪。</p></li><li><p>幽默不仅是攻击上层社会人士的有效工具,同时也能帮助我们认清自己的身份焦虑,并把它维持在一个缓和而适中的程度上。</p></li><li><p>我们所能够觉察到的好多有趣的事情都是关于在日常生活中我们可能为之沮丧或羞愧的情形或感情。最杰出的漫画家能够处理那些我们无法直接面对的弱点;我们总是隐藏着一些最令人尴尬的东西,而杰出的漫画家能够把我们从这些尴尬的东西身边拽开。忧虑越隐私、越强烈,引发的笑声就可能会越大,笑声成了把那些无法言说的缺陷拿来公开处理的有力武器。</p></li><li><p>因此不出所料,好多幽默都努力揭示一些对身份的焦虑,进而对此进行控制。它向我们揭示了在这个世界上还有其他比我们嫉妒心更盛,而在社会生活中更脆弱的人群;还有一些人在凌晨醒来时,为他们在经济方面的表现而痛苦万分;它还向我们说明,在一副副社会要求应该保持冷静的面孔之下,我们绝大多数人都有点精神恍惚、神志失常——这一切都给我们提供了充足的理由,要我们向相比而言比我们更惨的邻居伸出援助之手。</p></li><li><p><font color="red">最为和善的漫画不会就我们对身份的关注进行嘲笑,而是进行调侃:他们对我们提出批评,但同时认为我们依然相当不错。由于他们的才能,我们才能够以开放的心态,带着爽朗的笑声,承认自己身上的一些痛苦的事实,而这些事实如果以平常的、责备的语言传达给我们,我们就会因为惧怕危险和伤害而拒绝接受。</font></p></li><li><p>漫画家与其他艺术家相比毫不逊色,他们的作品符合马修·阿诺德对艺术的定义:<font color="red">艺术是为生活提供批判的学科。</font></p></li></ul><h2 id="第三章-v2">第三章</h2><ul><li><p><font color="red">在每一个社会里,总有一个特定的人群能够获得高度的尊崇——其他的人群则因为没有具备合适的技能、口音、气质、性别或肤色而受到贬抑或忽略。但这些对成功的定义远远不是一成不变或普遍适用的。一些素质和技能在一个地方能够带来较高的社会地位,而在另外一个地方则有可能变得无关紧要或为人不齿。</font></p></li><li><p>而对伊凡自己而言,现在只剩下几周好活了,他意识到自己浪费了在世上的光阴,意识到自己一直过的生活在表面上虽然显得春风得意,而内心里却是无聊苍白。</p></li><li><p>那些因所处社会的关于人的理想标准而狂躁不安或心怀怨恨的人,心里应该明白,身份的历史,即使是非常粗略地勾勒出的一个身份历史,都能揭示出一个根本的、振奋人心的结论:关于人的理想标准并非像石头一样一成不变。身份的理想标准长期以来都是,将来也一定会处于不断的变化当中。我们可以用一个词来形容这一个变化过程,这个词就是政治。</p><p>通过政治斗争,不同的群体都试图改变他们社会的尊严系统,摆脱在既有体系中利益既得者的统治,从而为自己获得尊严。这些不同的群体通过一个投票箱、一把枪、一次罢工,有时候通过一本书,来重新确立社会标准,决定什么样的人才有资格拥有上层身份的位置。</p></li><li><p>对上层地位的要求:不管男人和女人,不管属于任何种族,只要他们能够通过商业世界中的众多渠道之一（包括体育、艺术和科学研究）,通过个人的努力（而不是通过继承）积累一定的金钱、权力和名声,那么他们就是成功人士。因为在各个社会里都相信&quot;精英集团&quot;,因此,商业方面的成就被人们认为是&quot;理所应当的&quot;。积累财富的能力为人所重视,是因为这种能力能够证明一个人至少拥有四种基本品质:创造力、勇气、智力和毅力。至于其他的品质——诸如谦逊或正直——则很少引起人们的关注。同过去的社会不同,一切成就不再归因于&quot;运气&quot;、“天意&quot;或&quot;上帝”——反映了现代世俗社会对个人意志力的信任。经济上的失败被认为是罪有应得,失业所带来的耻辱,同战争年月的懦弱行为所导致的耻辱不相上下。金钱携带着一种道德品质。它的存在体现了拥有者的美德,就如同它体现了它所能够买的物质商品一样。正像库维奥人的美洲虎的牙齿,富裕的生活方式能够体现一个人的价值,如果一个人开着一辆破车,住着一间破屋,人们则会对他产生道德方面的怀疑。除了能够赋予一个人上层社会地位,财富还被提高到能够给人带来幸福的高度,这种幸福是通过购买一系列永远都在变化的消费品实现的——当我们想到以前的人们过着缺乏这些消费品的有局限的生活时,我们的心中充满了同情与困惑。</p></li><li><p>现代身份理想受到最大关注的莫过于它在财富与美德——以及贫穷与怀疑——之间建立起的一种联系。在《有闲阶级理论》（1899）一书中,托尔斯坦·凡勃伦指出,从19世纪早期开始,金钱成为商业社会衡量每个成员的核心标准:“［财富已经成为］获得尊敬的社会基础。要想在一个社会中占据一个受人尊敬的位置,占有财富成为必需。财富对于获得一个好名声来说必不可少……那些没有相对较多财富的社会成员,很难受到他们周围人的欣赏;其结果就是他们也很难受到他们自己的欣赏。”</p></li><li><p><font color="red">托尔斯坦·凡勃伦认为,在一个商业社会里,任何坚持一个人可以很有道德,同时仍很穷的观点都是没有市场的。即使是那些对财富最不在乎的人,也会感受到一种迫切的需要去积累财富,并向外界展示自己拥有财富,以期逃避责备,一旦没有积累足够的财富,就会感到焦虑不堪,感到自己应该受到责备。</font></p></li><li><p>因此,拥有大量的物质商品成为必需,其主要原因并非商品能够带来快乐（虽然它们也可能会带来快乐）,而是因为商品能够带来尊严。在古代,哲学家曾经热烈地讨论在物质方面什么对幸福来说必不可少,什么无关紧要。比如说,伊壁鸠鲁认为简单的饮食和住宿是生活的必需条件,但豪华的屋舍和奢侈的杯盘对那些有理智的、有哲学思想的人来说完全是多余之物。然而几个世纪以后,<font color="red">亚当·斯密在《国富论》中对此也作了讨论,他冷静地指出,在现代物质社会中,毫无疑问,有无数的物质产品对肉体的生存来说毫无意义,然而还是有更多的东西在实际的生活中被认为是&quot;必须的&quot;,因为如果一个人缺乏了这些东西,没有人会认为他值得尊敬,因此他也不会过上心理上舒舒坦坦的生活:“我所说的必需品,不但是维持生活上必不可少的商品,而且是按照一国习俗,少了它,体面人固不待说,就是最低阶级人民,亦觉得伤体面的那一切商品。例如,严格来说,麻衬衫并不算是生活上必要的。据我推想,希腊人罗马人虽然没有亚麻,他们还是生活得非常舒服。但是,到现在,欧洲大部分,哪怕一个日工,没有穿上麻衬衫,亦是羞于走到人面前去的。没有衬衫,在想象上,是表示他穷到了丢脸的程度,并且,一个人没有做极端的坏事,是不会那样穷的。同样的,习俗使皮鞋成为英格兰的生活必需品。哪怕最穷的体面男人和女人,没穿上皮鞋他或她是不肯出去献丑的。在苏格兰,对于最下层阶级男子,习俗虽亦以皮鞋为生活所必需,但对同阶级的女子却不然,她赤着脚,是没有什么不体面的。在法国,无论男、女,皮鞋都不是生活必需品。法国最下层阶级的男女,可穿着木屐或打着赤脚,走在人前,而无伤体面。所以,在必需品中,我的解释,不但包括那些大自然使其成为最低阶级人民所必需的物品,而且包括那些有关面子的习俗,使其成为最低阶级人民所必需的物品。”</font></p></li><li><p>自从斯密之后,经济学家几乎众口一词地认为,贫困的最根本特征,贫困最令人痛苦的地方,并不是它所导致的身体上的痛苦,而是他人对贫困状态的负面反应所导致的羞耻感,是贫困状态违反了斯密所称的&quot;既定的社会体面原则&quot;所产生的羞耻感。在《富裕社会》（1958）一书中,约翰·肯尼思·加尔布雷思的思想与斯密显然一脉相承,他写道:“只要一个人的收入明显低于周围人,即使对生存而言已经绰绰有余,但他依然为贫穷所困扰。他们缺乏社会所规定的最低的体面要求,因而他们不能完全逃脱被社会定义为不体面的命运。”</p></li><li><p>在这些东西中间,摆放着两种代表死亡和人生苦短的象征物:头骨和沙漏。</p></li><li><p>现代身份理想认为&quot;体面&quot;与财富直接相关,而&quot;不体面&quot;与贫苦直接相关,这一点构成了一些人对现代身份理想提出质疑的关键所在。为什么把挣钱上的失败看作一个人在绝对意义上有缺陷的证据,而不是将其看作在一个大范围、多层面的生活中个别的某一方面的失败？为什么要把财富和贫困看作一个人道德水平的主要依据？</p></li><li><p>其原因并不复杂。挣钱的过程往往需要个体具备某些优秀品质。坚持干好任何工作几乎都需要智力、体力、计划以及与他人进行合作的精神。事实上,挣钱越多的工作,对个体优秀品质的要求也越高。律师和医生不仅比扫大街的清洁工收入高,而且他们在工作中持续投入的精力和技巧也要多得多。</p></li><li><p>亚当·斯密写道,如果一个正常上班的人在公众场合出现时没有身穿麻衬衫,那么他会为此而深感羞耻,因为（我们再次引用他的语言,并用特别字体做出强调）没有麻衬衫将隐含一定程度的贫困,斯密的同时代人认为,“只有那些在工作中表现极度差劲的人才会沦落到这种田地”。除非一个人天生就喜欢酗酒、撒谎、偷窃或幼稚地不服从领导,那么他绝对会有机会获得一个购买一件麻衬衫所需的最差劲的工作——在这种情况下,我们就能理解完全可以把拥有一件麻衬衫作为良好人品的最低保证。</p></li><li><p>以此为出发点,我们不难推想,拥有挂满麻衬衫的衣柜、游艇、宅第和珠宝是&quot;在工作中表现极佳&quot;和多种美德的证据。昂贵的物品可以赋予拥有者尊敬,这一身份象征的观念可以演绎出一个为人广泛接受而且并非没有道理的推论:要拥有最昂贵的物品,无一例外地需要具备最完美的素质。</p></li><li><p>在罗斯金和萧伯纳之前300年,米歇尔·德·蒙田曾表达过相似的观点,他也强调偶然因素对一个人前途的决定性影响。他建议我们要牢记一点:“偶然性事件按照它难以捕捉的意愿决定着我们的身份和名誉:我经常看见机遇走在美德前面,而且占有绝对优势。”</p></li><li><p>很多人对此组观点提出反对,其中最具有启发意义而且易于理解的应属让雅克·卢梭和他的《论人类不平等的起源和基础》。卢梭在开篇之际就宣称,不管我们认为自己在思想上多么独立,我们实际上并不理解我们自己的需要,这是一个极为危险的现象。我们的灵魂很少直接说出自己需要具备什么,才能够使自己满足,或者即使它们有时嘟哝些什么,它们的指令也往往建立在谬误的基础之上,或干脆自相矛盾。卢梭认为,我们不能把心灵比作身体,因为身体知道需要吸收消化什么,才能保持自身的健康,而心灵则不然,心灵更像以下状态下的身体:在它需要喝水的时候大声呼喝上酒,在它需要平躺在床上休息的时候坚持继续跳舞。外界有各种声音在不停地告诉我们,应该获取什么,然后我们才能得到满足,我们的思维极易受到这些声音的左右,我们灵魂深处发出的一点点微弱的声音将会淹没在这些外界声音之中,而我们也会很容易地受到误导,从而使我们偏离了对我们生命中何者真正重要的谨慎而艰苦的求索。</p></li><li><p><font color="red">在第一批欧洲人到达美洲的短短几十年间,通过与欧洲工业社会的科技和奢侈品相接触,印第安社会的身份体系发生了急剧的变化。社会所重视的东西不再是一个人的智慧和理解自然的能力,而是对武器、珠宝和酒的占有。现在,印第安人渴望得到的是银耳环、铜手镯、锡戒指、用彩色装饰玻璃制作的项链、冰镐、枪支、酒类、水壶、珠子、锄头和镜子。</font></p></li><li><p><font color="red">这些新的爱好并非凭空产生。欧洲商人蓄意地培养印第安人的种种欲望,从而使他们为了满足这些欲望而去猎获大量欧洲市场所需要的动物毛皮。英国博物学家约翰·巴尼斯特牧师记载道,到1690年为止,欧洲商人已经成功地诱使哈得孙湾的印第安人需要&quot;那些他们以前从来都不需要的东西,因为他们此前从来没有拥有过它们,但贸易使这些东西成为必需品&quot;。20年以后,旅行家罗伯特·贝弗利作了这样的观察:“欧洲人把奢侈品引入到印第安人中,从而使他们的需求倍增,他们现在渴望得到他们以前从来都没有梦想过的成千上万的东西。”</font></p></li><li><p>理解发生了什么,即使如此,他们都非常同意他的观点。在印第安人内部产生了摆脱欧洲&quot;奢侈品&quot;的呼声。18世纪60年代,在宾夕法尼亚州西部的特拉华地区以及俄亥俄峡谷地区的印第安人试图恢复先人的生活方式。而且出现了一些预言,说如果人们不能从对贸易的依赖中解脱出来,那么他们的部落就会面临灭绝的危险。但一切都为时已晚。印第安人在心理构成上同其他民族并无二致,他们轻易地为现代文明创造的小小物什所吸引,从而拒绝听从那些平和冲淡的声音,这种声音讲述平平淡淡的部落生活的乐趣和傍晚时分空旷峡谷的美丽景色。</p></li><li><p>面对那些同情美洲印第安人的人和任何一个可能会抱怨发达的经济具有危害性的人,商业社会的维护者通常会这样回答针对经济危害性的责难:没有任何人强迫印第安人购买彩色玻璃制作的项链、冰镐、枪支、水壶、珠子、锄头和镜子。没有任何人阻止他们生活在帐篷里面,也没有任何人强迫他们渴望拥有带着院子和酒窖的木制房屋。印第安人自己放弃了一个安静而简单的生活——这一点很可能可以证明他们以前的生活并不像人们所想象的那样惬意。</p></li><li><p>这种辩护方式与现代广告代理商和报纸编辑经常使用的辩护方式有点相似,他们也认为他们不应该为以下的情况负责,即鼓励人们过分地关注名人的生活情况,过分地关注流行趋势的变化,以及过分地关注对一些新产品的拥有。他们认为,各种媒体仅仅将与这些题目相关的信息呈现出来,这样,感兴趣的人就可以从中获益——同时,他们还暗示,在看到这些信息后,会有更多的人自发地帮助弱者,反省自己的灵魂,去阅读爱德华·吉本的《罗马帝国衰亡史》,或对自己大限之前仅剩的一点短短的时光进行思考。</p></li><li><p>是当这些观点伴随着报纸的权威或者广告牌的美妙画面时。尽管卢梭的观点令人气馁,但却不乏深意。</p></li><li><p>对消费社会的批判不仅针对产品的缺点和不足（在这点上,人们总是容易夸大事实,因为只有脾气极为乖戾古怪的人才能拒绝接受,比如说,漂亮的山羊绒外套毛衣或在公路上夜间驱车时汽车的仪表板）,而且,也许更加公允地,针对由于产品的宣传手段而导致的我们扭曲变形的需求。由于我们既不了解这些产品的真正用途,也不了解我们自己的真正需求,所以这些产品从表面看来显得必不可少,显得能够为我们的生活带来莫大的幸福。</p></li><li><p>一个汽车广告,比方说,会小心谨慎地避免提及我们心理的某些方面,或拥有汽车的全部过程,因为知道了这些,可以破坏或至少降低我们因将要拥有一辆漂亮汽车而具有的快乐。<font color="red">广告绝对不会提及一件事,那就是一旦我们拥有了某个东西,用不了多久,我们就会停止喜欢它。要想停止注意某件事物,最快的方法就是将它购买到手——就如同要想停止欣赏某个人,最快的方法可能就是与其结婚。受各种观点的蛊惑,我们相信取得某种成就或购买某种商品,就可以保证我们长期享受满足感。外界观点总是引导我们,让我们想象自己在攀登幸福崖上的最陡峭的一边,一旦爬上去,就可以到达一个广阔的高台,在其上我们就可以一直享受幸福生活;从来不会有人告知我们,一旦到达顶点,我们又会被唤回谷底,重新处于焦虑和欲望的洼地中。</font></p></li><li><p>购买的汽车,就如同任何一件我们已经拥有的美妙的事物一样,很快就会消失在我们生活的物质背景之中,从此很难再被人注意到——直到有个晚上,有个窃贼做了一件具有自相矛盾的双重含意的事,砸破了车窗玻璃,偷走了收音机,但同时用一堆碎玻璃提醒我们,我们应该感谢生活为我们提供了这么多美好的东西。</p></li><li><p>广告很少提及,所有的物质产品与感情事件的巨大能量相比,在影响我们的幸福水平方面具有极为有限的能力。任何设计最为高雅、制作最为精良的汽车,并不能为我们带来丝毫人际关系所能够带来的满足感——如同在家庭争吵或遭人遗弃之后,它不会使我们产生任何欣慰的感受。在此时此刻,我们甚至都会憎恨汽车毫无感情的优质功效、显示屏一丝不苟的滴答声,以及车载电脑有条不紊的计算。</p></li><li><p>现代上层身份理想的反对者认为,现代上层身份理想的最大过错在于严重地歪曲了生活中何者最重要的问题,以及把物质积累过程抬高到人生最高成就的水平,然而在一个更加真实的、更加全面的对我们自己的概念之中,物质积累充其量只是决定我们生活方向的众多因素之一而已。</p></li><li><p>对生活中何者最重要的歪曲极大地激怒了约翰·罗斯金,他批评19世纪的英国人（他从未去过美国）是世界历史上曾经出现过的对财富最着迷的民族。无论在何时何地,他写道,英国人从未放弃过对两个问题的关注:他拥有什么,以及他来自哪个阶层（“惟一起作用的女神可以被更好地也更全面地概括为‘使劲挣钱的女神’”）。他们为自己没有足够的财富而深感耻辱,为他人拥有财富而深怀嫉妒。</p></li><li><p>在《给那后来的》一书中,他因此请求我们放弃日常把财富等同为金钱的观念,采取以&quot;生活&quot;为基础的思维观点,根据这种思维观点,世界上最富有的人将不再理所当然地是商人或地主,而是那些在凝视夜晚星空时深深感到惊奇的人,和那些能够理解和减轻他人痛苦的人。&quot;除却生活别无财富,&quot;他吟颂道,“而生活饱含着它全部的爱的能力、快乐的能力以及欣赏的能力。一个能够养育最大数量的高尚而幸福人群的国家是最富有的国家;一个能够把自己生活的价值发挥到极致,而且通过个人的努力,或通过自己拥有的财物,能够对他人施以最广泛的有利影响的人将是最富有的人……好多普遍被认为很富有的人,其富有程度实际上还比不上他们保险柜的锁子,他们是那些天生的、永远不可能变得富有的人。”</p></li><li><p>就阿诺德自己看来,幸福是一种&quot;内在的精神活动,其特征是人变得更加和蔼可亲、更加睿智通达、生活更加丰富,而对待他人则带有更多的同情（他的观点又一次引发了《每日电讯报》的批评家们的冷嘲热讽）&quot;。</p></li><li><p>托马斯·卡莱尔完全支持罗斯金和阿诺德的观点,只不过他更加生气而已。在《迈达斯王》（1843）中,他问道:“英国日益繁荣的工业,虽然创造了大量财富,但……还没使任何人发财致富……我们有奢侈豪华的物品供我们使用,但却已忘记如何在这些物品之中生活。好多人吃的是珍馐美味,喝的是醇醪名酒,但在他们的心中,这是不是就使他们更幸福了呢？难道他们就更善良、更漂亮、更健壮、更勇敢了吗？难道他们真的就像他们自己所说的更‘幸福’了吗？他们是否以满意的心态看待这个上帝创造的地球上的更多的事物和他人,或者是否有更多的事物和他人以满意的心态来看待他们？并非如此……我们已经彻底忘记了,在任何地方,现金交易并不是人际间的惟一关系。”</p></li><li><p>在历史长河中,有好多观点鲜明的思想曾一度被认为是理所应当的:&quot;理所应当的&quot;思想,1857-1911年</p><ul><li>&quot;确凿的事实是男人从一开始就受命统治女人:对这样一个永恒的天命,我们既无权利,也无能力去改变。&quot;珀西伯爵（1873）</li><li>&quot;在一个受过良好教育的欧洲男人和一个欧洲女人之间存在的身体和道德差异,要远甚于在一个欧洲人和中非野蛮部落的黑人之间存在的差异。&quot;克罗默勋爵（1911）</li><li>&quot;绝大多数的妇女对任何形式的性感觉毫不在意（这对她们而言是一件好事）。&quot;威廉·阿克顿爵士（1857）</li><li>&quot;作为一个种族,非洲人要比白人低劣;受制于白人是他们的正常状态。因此,我们的社会体系认为非洲人比我们低劣,是建立在伟大的自然法则之上的。&quot;亚历山大·斯蒂芬斯（1861）</li></ul></li><li><p>那些被社会重量级人物认为是颠扑不破的真理,实际上往往是相对的,是可以进一步商榷的。一旦认识到了这一层,一种政治上的觉悟就会随之产生。我们可以满怀信心地批判这些观点,即使这些观点看起来多么像树木、天空一样自然,但实际上它们都——<font color="red">一种政治观点坚持认为——为一些特定的人所维护,并用来服务于他们特定的使用目的或精神目的。</font></p></li><li><p><font color="red">如果这种相对性很难被人觉察,那是因为占支配地位的观点总是煞费苦心地证明,它们的真实性就如同太阳的轨道一样是无法更改的。它们总是宣称自己仅仅在陈述一件显而易见的事实而已。我们借用卡尔·马克思的一个非常有用的词汇——意识形态——来描绘这种情形:它们都是意识形态性的,而任何意识形态的思想总是打着客观公正的幌子,来巧妙地推行偏颇的论点。</font></p></li><li><p><font color="red">对马克思而言,在一个社会中主要由统治阶级来决定意识形态,我们可以用他的观点来解释以下的两个现象:在一个由地主阶级控制权力的社会里,土地带来的财富和由此产生的可继承的上层地位被绝大多数的人们认为是理所应当、毋庸置疑的（甚至包括在这一体系中被边缘化的那些人）;而在一个商业社会中,是那些企业家的成就占据着老百姓对成功的想象。用马克思的话说:“每个时代占统治地位的思想往往是统治阶级的思想。”</font></p></li><li><p><font color="red">然而这些意识形态的观点如果表现得过于咄咄逼人,那么它们就不会强有力地占据统治地位。意识形态观点的精髓就是,除非我们的政治素养得到了极大的发展,否则我们很难意识到它们的存在。意识形态就像无色无味的气体一样,被释放到社会中。它通过报纸、广告、电视节目和教科书得到体现——在这些领域,意识形态在宣传它对世界偏颇的、也许还是缺乏逻辑的、缺乏公正的理解;在这些领域,它羞羞答答地暗示,它只是在陈述一件自古就有的事实,而只有那些蠢才或疯子才会对此加以否认。</font></p></li><li><p>受压迫的状况很可能被解释为一种迹象,表明自然对一个人做出惩罚,让他永远受苦。但如果变换一种政治角度,重新进行解释,那么一个糟糕的处境可以归结于一些或许可变的社会力量。负疚和羞愧从而可以转化成为理解,以及对更加平等地分配身份的探求。</p></li><li><p>萧伯纳,《智慧妇女的社会主义和资本主义指南》:“你必须清除头脑中的幻象,这种幻象在我们孩提时代起就已经具有了,那就是我们坚信,我们生活于其中的任何机制都是同天气变化一样自然而然,无需争议。实际上并非如此。因为它们在我们生活的小小世界里到处存在,所以我们便理所当然地认为它们一直都是存在的,而且在将来也会一直存在。这是一个极为危险的错误。它们实际上一直处于变动不居、相互替换的状态中。在过去几代人中没有人能够相信的变化确确实实地发生了。孩子们现在认为在学校里读9年书,领取养老金和寡妇赡养费,在选举中投妇女的票,以及国会中有穿短裙的女士,都是自然秩序的一部分,以前一直是,将来也会一直都是;然而他们的曾祖母如果听到有人说这些事物即将发生,那么她们将会骂说话者是个疯子——而且认为任何想要这些事情发生的人都是邪恶缺德的。”</p></li><li><p><font color="red">报纸和电视节目所灌输的对物质至上主义、企业家精神和物质精英论（“每个时代占统治地位的思想往往是统治阶级的思想”）都反映了那些控制整个经济体系的人的利益,而普通大众则需要依赖这个经济体系来养家口。</font></p></li><li><p>理解了这一层道理,并不能奇迹般地消除身份理想所能导致的诸多忧虑。理解内情与政治上的困难之间的关系有点类似于气象卫星与气象灾害之间的关系。<font color="red">理解并不是总能防止问题的发生,但它在一个最小的范围内,能够教会我们很多有用的东西,让我们知道如何以最好的方式去面对问题,从而大幅度地降低受害的感觉、被动的感觉和困惑的感觉。或者我们可以更加野心勃勃地说,理解这一切将是我们迈出的第一步,以此开始我们可以改变或者挑战社会理想,从而建立一个更美好的社会。在这个社会里,把尊严和荣誉教条式地、不加质疑地赋予那些依然踩着高跷的人的可能性会有所降低,即使是非常微弱的降低也罢。</font></p></li></ul><h2 id="第四章-v2">第四章</h2><ul><li><p>他浪费了自己短暂的一生,这让他痛苦,然而更加令他难以释怀的是他意识到他周围的人所喜欢的仅仅是他的身份,而不是他真正的、脆弱的自我。他因为是一个法官、一个有钱的父亲、一家之长而受人尊敬,而现在这一切身份都即将消失,在痛苦和恐惧中,他知道他不能指望任何人能够爱他:“最折磨伊凡·伊里奇的是没有人能够给予他同情,而这是他最渴望得到的。在经过长时间的折磨之后,他最希望得到的是（虽然让他公开承认显得有失体面）有人能够像对待生病的小孩那样疼他。他希望有人抚摸着他、亲他、抱着他哭,就像生了病的小孩一样被人宠着,被人抚慰着。他清楚地知道自己是一个重要官员,而且胡须已经花白,因此这一切都是不可能实现的;然而,不管怎样,他都渴望得到这些。”</p></li><li><p>死亡的想法对我们的影响或许就是引领我们去追求任何对我们真正重要的东西,不管这些东西是在尼罗河畔饮酒,写一部书,还是发一笔财;同时还会鼓励我们漠视他人对我们的评价,因为他人的评价毕竟与我们的死亡没有丝毫的关系。对死亡的预见能够使我们追求我们内心中最渴望的生活方式。</p></li><li><p>对死亡的思考能够赋予我们以勇气,使我们能够摆脱社会对我们的期望中的那些毫无道理的成分。在一具骷髅之前,他人观点中那些令人压抑的东西将会习惯性地丧失赖以吓人的力量。</p></li><li><p>从死亡的角度来看待人的生命中什么事才算得上富有意义,基督教和世俗的看法各不相同,但不管两者之间有多大的差异,它们似乎都强调仁爱,强调真诚的社会交往,强调乐善好施;同时它们都反对过度关注权力、武力、财富欲的膨胀和它们所带来的荣誉。在人类的生活中有一些行为,一旦与死亡的思考联系到一起,不管在何时何地,都会显得无关紧要。</p></li><li><p>这些作品的目的并非要让拥有者因万物皆虚妄的事实而沮丧不堪,相反,这些画的目的是赋予人们以勇气,让他们能够以批判的眼光检查自己生活中的每个细节,同时给予他们以理由,让他们能够以更严肃的心态去关注关爱、善良、真诚、谦卑和友好等美德。</p></li><li><p>除了对我们自己必死的命运进行思考之外,我们还可以通过思考他人的死亡来摆脱身份的焦虑,特别是那些取得很高的成就使我们自卑和嫉妒的人的死亡。不管我们生活在如何遭人遗弃和忽略的境况中,也不管他人多么势力强大,多么受人尊敬,一旦想到每一个人都将最终化为世界上最平等的物质——尘土,我们便会顿感释然。</p></li><li><p>我们总是牺牲自己宁静的心情而去追求那些转瞬即逝的世间的荣华富贵,而遗迹能够揭示出我们这些行为的愚蠢本质。当我们看到这些古老的石头之时,我们对自己成就的焦虑——以及缺乏成就的焦虑——会随之减弱。如果我们在他人眼中是个失败者,如果没有人为我们树碑立传,如果没有人为我们列队致意,如果在最近一次聚会中没有人对我们以笑脸相迎,这一切又有什么关系呢？任何事物注定都要消失,新西兰人总会在一定的时候来为我们居住的大街和工作的办公室留下的遗迹做素描。与永恒相比较,扰乱我们心神的那些东西显得多么微不足道啊。</p></li><li><p>遗迹能够让我们放弃辛苦劳作,放弃我们自以为是的完美感和成就感。遗迹提醒我们,我们永远不可能抗拒时间,我们只是自然破坏力的玩物,而我们只能暂时压制自然破坏力,不能真正地克服它。我们可能会享受一时的成功,我们可能会在短短几年内赋予混乱以秩序,但任何事物都终将退回到以前原初的状态。如果这种想法能使我们心情宁静,那是因为我们的绝大部分焦虑来自于我们过高地估计了自己的目标和关注的重要性。由于我们对自己所做的事情评价过高,我们便因此受到惩罚,进而接受理想的折磨。</p></li><li><p><font color="red">基督教的伦理学家们长期以来都明白,要安抚焦虑者,最好的方式并不是像乐观的心态教我们的那样,告诉他一切事情都会好起来的——相反,我们应该告诉他一切事物最终都将变得非常糟糕:屋顶将会塌陷,银行将会变成废墟,我们将会死去,每一个我们所爱的人都将去世,我们所有的成就,甚至连同我们的名字都将深埋于地下。如果这样的想法能够安抚我们,那是因为在内心深处,我们本能地知道我们的痛苦与抱负之庞大密切相关。如果从1,000年的角度来看待我们那些渺小的身份焦虑,我们将会非常难得地认识到自己的微不足道,从而获得心情的宁静。</font></p></li><li><p><font color="red">宏大的自然景观与废墟一样,能够起到相同的减缓焦虑的作用,因为宏大的自然景观是无限空间的代表,就如同废墟是无限时间的代表一样,与无限的时间相比,我们虚弱的、短暂的生命与飞蛾或蜘蛛的生命一样微不足道。</font></p></li><li><p>不管人们之间存在着多大的差别,但一旦我们把世界上最强大的人同荒原大漠、崇山峻岭、巨大的冰河以及世界的大洋相提并论,人与人之间的差别就会变得非常微弱,几于消失。它们都是自然现象,其所占的空间如此之大,很容易就可以使任何两个人之间的差异显得可笑地微弱。身处宏大的自然景观,我们会感受到在广阔无垠的宇宙中人类的渺小,我们的心情会随之宁静,我们在社会等级结构中感受到的人微言轻的感觉也会随风消散。</p></li><li><p>要想克服认为自己微不足道的自卑感,我们无须努力使自己变得更加重要,而是要认识到所有的人相对而言都是微不足道的。一旦面对那些比我们要大上千亿倍的东西时,我们对他人比我们高几毫米的关注就会随之消失,取而代之的是对这些巨大的东西的敬畏之情,我们往往称这种力量为无限、永恒——或很简单地,同时也最顶用地,称之为上帝。</p></li><li><p><font color="red">对身份低下的焦虑进行治疗,最好的办法就是通过旅游——在现实中旅游或在艺术作品中旅游——去感受世界的广阔无垠。</font></p></li><li><p>根据现代世俗社会的一种很有影响力的观点,认为一个人最不体面的命运莫过于变得&quot;同每一个其他的人相像&quot;:因为&quot;每一个其他的人&quot;是包括平庸无能的人、墨守成规的人、无聊乏味的人以及土里土气的人在内的一类人的总称。任何一个思维正常的人的目标就是想方设法使自己区别于周围的人群,在他们能力许可的前提下使自己&quot;脱颖而出&quot;。</p></li><li><p>基督教要求我们透过人们之间表面的差异,去关注那些被公认为是普遍的真理,建立在这些普遍真理之上的是集体感和亲情感。我们中有一些人可能很残酷,有些人可能很焦躁,有些人可能会很愚笨,还有些人可能会很无聊,但把我们拉在一起,并在我们之间建立起相互联系的纽带的是我们对自身的脆弱的共识。在我们的缺点背后,总有两个基本要素在起作用:恐惧和对爱的渴望。</p></li><li><p><font color="red">为了鼓励人们之间的相互感情,耶稣力劝我们要像对待小孩那样对待成年人。一旦我们把他人想象成一个小孩,我们对他人品格的评价立刻就会产生180度的大转弯。从这个角度出发,我们能够更容易地对成年人表达同情和宽容,就像我们总是很自然地以同情和宽容的态度对待小孩,如我们总是说孩子很调皮,而不说他品质糟糕,我们说孩子很任性,而不说他很傲慢自大。</font>要讨厌一个小孩很难,要讨厌一个正在熟睡的人同样很难。熟睡者紧闭的眼睛,放松而毫无防备的表情,都能让旁观的人产生关怀和爱护的心理——这种情形非常明显,我们在火车上或飞机上对身旁睡着的人长时间地盯着看也会因此而显得尴尬不已。他们的脸让我们立即产生亲近感,日常人际关系赖以为基础的后天形成的漠不关心也随之受到质疑。基督徒认为,世界上并没有陌生人这回事,只可能因为没有意识到他人和我们具有相同的需求和弱点从而对他人产生一种陌生的印象。从本质上来说,从真正重要的东西来说,我们同他人实际上并无二致,认识到这点才是一个最高贵的人生和最完整的个人的基础。</p></li><li><p>在一个理想的基督教社会里,人们对自己不是获胜者的恐惧将会因为尊严和资源的最根本的平等而减弱,进而易于控制。成功意味着兴旺发达,而失败意味着衰退消亡的二分法,也会随之丧失其令人痛苦的清晰度。</p></li></ul><h2 id="第五章-v2">第五章</h2><ul><li><p>解决焦虑的成熟之途可以说始于一种认识,即身份的确立取决于听众的选择:听众可以是工业家或波希米亚人,可以是家庭成员或哲学家——而我们可以按照自己的意愿自由地选择听众。</p></li><li><p><font color="red">不管身份的焦虑如何令人不快,但我们还是很难想象一种完全摆脱身份焦虑的美好生活,因为一个人对失败和在他人面前丢脸的恐惧,实际上意味着他抱有一定的追求,期待某些结果的出现,以及对自己以外的其他人心怀尊敬。身份的焦虑是我们承认在成功生活和不成功生活之间存在公共差异的时候,必须付出的代价。</font></p></li><li><p>虽然我们对身份的需求是毋庸置疑的,但我们在满足对身份的需求时面临着诸多选择,我们有自由认识到我们对蒙羞的忧虑完全取决于一定的社会群体,我们充分理解和尊重这个社会群体的判断方法。身份的焦虑只有在一种情况下才是成问题的,那就是我们遵循这些导致焦虑的价值观念,仅仅是因为我们异常胆小怕事、循规蹈矩,或仅仅是因为我们的思维已经被完全麻痹,以至于我们认为这些价值观念是天经地义的,或来自神授,或因为我们周围的人对此心醉神迷,或因为我们的想象力变得过于局限,而想不到还有其他的选择。</p></li><li><p>哲学、艺术、政治、基督教和波希米亚的目的并非废除身份等级,他们只是尝试创立一些新的身份等级,而这些等级建立在那些为大众所忽略或批判的价值标准的基础之上。这五个不同领域的革新者们一方面都坚持严格区分成功与失败、好与坏、可耻与高尚,另一方面又试图重新塑造我们的判断标准,使我们重新思考何种行为才能归入这些重要的标题。</p></li><li><p>每一个时代都会有一些人无法或不愿温顺地服从关于上层身份的主流观念,但他们有资格拥有更好的称呼,而不是残酷地被人称为失败者或小角色,而这五个领域的革新者们通过上述的方式,赋予这些人以合理性。他们提供了好多富有说服力和抚慰能力的事例来提醒我们,世界上并不是只有一种方式——并不是只有法官或药剂师的方式——才能证明生活的成功。</p></li></ul>]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>身份的焦虑</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust 菜鸟笔记</title>
    <url>/rust-rookie-notes.html</url>
    <content><![CDATA[<blockquote><p>Rust 学习笔记</p></blockquote><a id="more"></a><h1>安装</h1><p>我的环境是Win 10,下载<a href="https://www.rust-lang.org/tools/install" target="_blank" rel="noopener">rustup-init.exe</a><br>按照提示进行安装，按照完成后，在CMD中输入</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rustc --version</span><br></pre></td></tr></table></figure><p><img data-src="/images/rust-rookie-notes/rust_version.png" alt></p><blockquote><p>安装官方文档<br><a href="https://doc.rust-lang.org/book/ch01-01-installation.html#installing-rustup-on-windows" target="_blank" rel="noopener">https://doc.rust-lang.org/book/ch01-01-installation.html#installing-rustup-on-windows</a></p></blockquote><h1>开发工具选择</h1><p><a href="https://www.rust-lang.org/tools" target="_blank" rel="noopener">https://www.rust-lang.org/tools</a></p><h1>Hello, World!</h1><p>创建文件夹及文件:projects/hello_world/main.rs<br>内容:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fn main() &#123;</span><br><span class="line">    println!(&quot;Hello, world!&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; rustc main.rs</span><br><span class="line">&gt; .\main.exe</span><br></pre></td></tr></table></figure><p>错误信息:<br><img data-src="/images/rust-rookie-notes/linker_link_exe_not_found.png" alt></p><p>解决:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rustup toolchain install stable-x86_64-pc-windows-gnu</span><br><span class="line">rustup default stable-x86_64-pc-windows-gnu</span><br></pre></td></tr></table></figure><p>再次运行:<br><img data-src="/images/rust-rookie-notes/hello_world.png" alt></p><p><a href="https://doc.rust-lang.org/book/ch01-02-hello-world.html" target="_blank" rel="noopener">https://doc.rust-lang.org/book/ch01-02-hello-world.html</a></p>]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Effective Elasticsearch Plugin Management with Docker</title>
    <url>/effective-elasticsearch-plugin-management-with-docker.html</url>
    <content><![CDATA[<blockquote><p>原文地址:<a href="https://www.elastic.co/cn/blog/elasticsearch-docker-plugin-management" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/elasticsearch-docker-plugin-management</a></p></blockquote><a id="more"></a><p>如果你正在用容器来运行elasticsearch,那么有一些事项需要注意。在管理有状态服务和守护进程时尤其如此——当将数据持久化在临时容器之外变得很重要时。</p><p>在容器中使用Elasticsearch插件就是一个例子，无论是以可重复、可跟踪的方式安装它们，还是管理插件配置和数据。</p><p>在这篇文章中，我们将探讨一些在Docker和Elasticsearch中实现合理插件管理的选项。</p><h1>Docker 持久性入门</h1><p>与版本控制系统中更改文档一样，更改正在运行的容器中的文档系统会在正在运行的镜像中引入差异。如果数据和更改需要在临时容器的范围之外永久保留，则需要采取措施。</p><p>尽管可以利用一些更复杂的存储方案来实现容器持久化，但绑定挂载的基本Docker机制最能说明问题。例如，通过将<code>-v /data:/usr/share/elasticsearch/data</code>之类的选项传递给<code>docker run</code>命令，将 Elasticsearch 索引长期保存在<code>/data</code>中来实现的，该命令有效地将Elasticsearch数据存储在主机的（不是容器的）<code>/data</code> 目录。</p><p><font color="red">如果更改是永久性的，也就是说，预计它们不会随着时间的推移而改变，那么将更改编入<code>Dockerfile</code>中可能更有意义。</font>这两种方法在不同情况下都有用。</p><h1>管理基础插件</h1><p>在以下示例中，我将“基础”插件称为不需要许可证或任何其他特殊组件的插件。 像cloud-aws这样简单的插件只需要在系统上放置一些文件就可以工作。</p><p>在这种情况下，管理插件的存在最简单，只需使用Dockerfile扩展镜像即可。 例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM elasticsearch:2</span><br><span class="line"></span><br><span class="line">RUN /usr/share/elasticsearch/bin/plugin install --batch cloud-aws</span><br></pre></td></tr></table></figure><p>这个<code>Dockerfile</code>从Docker Hub的维护者提供的Elasticsearch镜像开始，并运行一个简单的插件安装命令。然后可以通过标签构建和引用此镜像：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker build -t elasticsearch-aws .</span><br></pre></td></tr></table></figure><h1>更复杂的插件</h1><p>某些插件可能需要额外的文件（例如使用Shield时的证书）才能实现某些功能。上述构建自定义镜像的技术可以处理这些插件的安装，但管理配置是用其它方法处理更好。这有助于保持镜像的通用性以供部署重用，并保持对密钥的控制更严格。</p><p>注意：一些商业插件需要license。在以下示例中，我们仅依赖默认存在的临时试用license。在生产环境中部署时，license是通过Elasticsearch REST API执行的，它将license信息存储在Elasticsearch的数据路径中。只要您的数据通过卷装载或其他方式适当地持久化，您的license信息就会保存在您的集群中。</p><h2 id="Example-Shield">Example: Shield</h2><p>正如<a href="https://www.elastic.co/guide/en/shield/current/installing-shield.html" target="_blank" rel="noopener">Shield安装文档</a>中所述，安装license和shield插件是先决条件，我们可以使用之前的构建派生镜像的策略来实现：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM elasticsearch:2</span><br><span class="line"></span><br><span class="line">RUN /usr/share/elasticsearch/bin/plugin install --batch license</span><br><span class="line">RUN /usr/share/elasticsearch/bin/plugin install --batch shield</span><br></pre></td></tr></table></figure><p>构建镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker build -t elasticsearch-shield .</span><br></pre></td></tr></table></figure><p>此时，如果我们将配置目录卷挂载到容器中，Shield 将获取我们的设置。 作为示例配置，请考虑以下目录结构：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tree config</span><br><span class="line">config</span><br><span class="line">├── elasticsearch.yml</span><br><span class="line">├── logging.yml</span><br><span class="line">├── scripts</span><br><span class="line">└── shield</span><br><span class="line">    ├── roles.yml</span><br><span class="line">    ├── users</span><br><span class="line">    └── users_roles</span><br><span class="line"></span><br><span class="line">2 directories, 4 files</span><br></pre></td></tr></table></figure><p><code>logging.yml</code>包含默认日志记录配置。 在<code>elasticsearch.yml</code>中，绑定到通配符 0.0.0.0 确保我们可以访问到容器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat elasticsearch.yml</span><br><span class="line">network.host: 0.0.0.0</span><br></pre></td></tr></table></figure><p>对于 Shield 配置，我们定义了一个单独的角色admin，以及一个名为“example”且密码为“password”的用户，并将其添加到 admin 角色（您显然需要比这更安全的配置！） :</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat shield/roles.yml</span><br><span class="line">admin:</span><br><span class="line">  cluster: all</span><br><span class="line">  indices:</span><br><span class="line">    &apos;*&apos;:</span><br><span class="line">    privileges: all</span><br><span class="line">$ cat shield/users</span><br><span class="line">example:$2a$10$ppZqjFEXgVE3yT/yQPsp4etGMdF4.RFCS9OOGwZGAp0l3lPh4/ALC</span><br><span class="line">$ cat shield/users_roles</span><br><span class="line">admin:example</span><br></pre></td></tr></table></figure><p>注意：在此示例中，我们使用的是使用<code>esusers</code> Shield实用程序生成的密码哈希。</p><p>然后我们启动容器，为我们的配置指定挂载卷并公开REST端口：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -d -p 9200:9200 -v &quot;$PWD/config&quot;:/usr/share/elasticsearch/config elasticsearch-shield</span><br></pre></td></tr></table></figure><p>Elasticsearch 应拒绝未经身份验证的请求：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl -I -XGET -k https://localhost:9200/_cluster/health</span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">WWW-Authenticate: Basic realm=&quot;shield&quot;</span><br><span class="line">Content-Type: application/json; charset=UTF-8</span><br><span class="line">Content-Length: 389</span><br><span class="line">$ curl -I -XGET -k -u example:password https://localhost:9200/_cluster/health</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: application/json; charset=UTF-8</span><br><span class="line">Content-Length: 389</span><br></pre></td></tr></table></figure><h2 id="Adding-SSL-TLS">Adding SSL/TLS</h2><p>与挂载Shield配置文件一样，可以类似地管理SSL和TLS证书。可以遵循<a href="https://www.elastic.co/guide/en/shield/current/ssl-tls.html" target="_blank" rel="noopener">Shield SSL/TLS</a> 指南中概述的大部分步骤请记住<code>CONFIG_DIR</code>目录是我们将在运行时安装到容器中的路径。 CA和证书管理的全部内容不在本教程的讨论范围内，因此我们在此假设您使用的是正确配置的Javakeystore文件，此处称为 <code>node01.jks</code>。</p><p>公开keystore文件只是将其包含在安装到容器中的配置目录中的问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tree config</span><br><span class="line">config</span><br><span class="line">├── elasticsearch.yml</span><br><span class="line">├── logging.yml</span><br><span class="line">├── node01.jks</span><br><span class="line">├── scripts</span><br><span class="line">└── shield</span><br><span class="line">    ├── roles.yml</span><br><span class="line">    ├── users</span><br><span class="line">    └── users_roles</span><br><span class="line">$ file config/node01.jks</span><br><span class="line">config/node01.jks: Java KeyStore</span><br></pre></td></tr></table></figure><p>按照Shield用户指南，我们启用传输加密：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat config/elasticsearch.yml</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">shield.ssl.keystore.path: /usr/share/elasticsearch/config/node01.jks</span><br><span class="line">shield.ssl.keystore.password: password</span><br><span class="line">shield.transport.ssl: true</span><br><span class="line">shield.http.ssl: true</span><br></pre></td></tr></table></figure><p>注意：在生产中，您可能希望更严格地控制您的keystore - 在本例中，我们只使用通用密码锁定keystore。</p><p>有了keystore文件并启用了SSL，我们可以启动节点并通过HTTPS发出请求（在这种情况下，将 <code>-k</code> 传递给 curl 以绕过自签名证书）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -d -p 9200:9200 -v &quot;$PWD/config&quot;:/usr/share/elasticsearch/config elasticsearch-shield</span><br><span class="line">87e51d000cc11d63fbedb8a61d58ab1723f4a598b13614272a3b9d7f36a7b223</span><br><span class="line">$ curl -I -XGET -k -u example:password https://localhost:9200/_cluster/health</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: text/plain; charset=UTF-8</span><br><span class="line">Content-Length: 0</span><br></pre></td></tr></table></figure><p>当需要在集群中分发keystore文件时，它们可能会由<a href="https://forge.puppetlabs.com/puppetlabs/java_ks" target="_blank" rel="noopener">配置管理模块</a>或类似方法进行管理。</p><p>注意：在生成将在Docker内运行的节点的证书时，请密切注意将适当的选项传递到<code>-ext</code>选项。DNS名称和IP地址应正确反映节点将用于相互通信的主机名或IP地址。</p><h1>总结</h1><p>尽管我们在这篇博文中给出了几个具体示例，但每个部署都是不同的，您应该根据提高环境可靠性、可重复性和安全性的因素来定制您的设置。 一般来说，遵循这些准则应该有助于一个好的插件管理方案：</p><ul><li>在Docker镜像中定义最通用的步骤。通过尽早管理插件然后从这些镜像运行容器，您可以避免一遍又一遍地重新运行相同的安装命令。</li><li>在挂载卷中维护持久数据。将您的索引数据和插件配置与容器镜像分开存储可确保您的数据受到控制并且容器保持短暂。</li><li>测试！在部署任何生产基础设施之前，确保Elasticsearch在Docker中的行为符合预期，尤其是在网络通信（包括单播和IP地址绑定行为）、JVM资源分配和插件功能方面。</li></ul><h1>新版本示例</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM elasticsearch:7.13.4</span><br><span class="line"></span><br><span class="line"># RUN ./bin/elasticsearch-plugin install --batch https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.13.4/elasticsearch-analysis-ik-7.13.4.zip</span><br><span class="line">ADD elasticsearch-analysis-ik-7.13.4.zip /usr/share/elasticsearch</span><br><span class="line">RUN ./bin/elasticsearch-plugin install --batch file:///usr/share/elasticsearch/elasticsearch-analysis-ik-7.13.4.zip</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>翻译</tag>
        <tag>Plugin</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang PutUvarint Uvarint</title>
    <url>/golang-putuvarint-uvarint.html</url>
    <content><![CDATA[<blockquote><p>看<a href="https://github.com/allegro/bigcache" target="_blank" rel="noopener">bigcache</a>库的时候,注意到存放数据用的是PutUvarint、Uvarint,那这两个方法是做什么的呢？</p></blockquote><a id="more"></a><h1>PutUvarint</h1><h2 id="源码及注释">源码及注释</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// PutUvarint encodes a uint64 into buf and returns the number of bytes written.</span><br><span class="line">// If the buffer is too small, PutUvarint will panic.</span><br><span class="line">// PutVarint 将 int64 编码为 buf 并返回写入的字节数。如果缓冲区太小，PutVarint 会panic。</span><br><span class="line">func PutUvarint(buf []byte, x uint64) int &#123;</span><br><span class="line">	i := 0</span><br><span class="line">	// 0x80 128</span><br><span class="line">	for x &gt;= 0x80 &#123;</span><br><span class="line">		buf[i] = byte(x) | 0x80</span><br><span class="line">		// 右移7位,然后将右移后的值，赋值给x</span><br><span class="line">		x &gt;&gt;= 7</span><br><span class="line">		i++</span><br><span class="line">	&#125;</span><br><span class="line">	buf[i] = byte(x)</span><br><span class="line">	return i + 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="代码示例">代码示例</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;encoding/binary&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">	buf := make([]byte, binary.MaxVarintLen64)</span><br><span class="line"></span><br><span class="line">	for _, x := range []int64&#123;-65, -64, -2, -1, 0, 1, 2, 63, 64&#125; &#123;</span><br><span class="line">		n := binary.PutVarint(buf, x)</span><br><span class="line">		fmt.Printf(&quot;%x\n&quot;, buf[:n])</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">8101</span><br><span class="line">7f</span><br><span class="line">03</span><br><span class="line">01</span><br><span class="line">00</span><br><span class="line">02</span><br><span class="line">04</span><br><span class="line">7e</span><br><span class="line">8001</span><br><span class="line"></span><br><span class="line">Program exited.</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://go.dev/play/p/yRUoUooVrHm" target="_blank" rel="noopener">https://go.dev/play/p/yRUoUooVrHm</a></p></blockquote><h1>Uvarint</h1><h2 id="源码及注释-v2">源码及注释</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Uvarint decodes a uint64 from buf and returns that value and the</span><br><span class="line">// number of bytes read (&gt; 0). If an error occurred, the value is 0</span><br><span class="line">// and the number of bytes n is &lt;= 0 meaning:</span><br><span class="line">//</span><br><span class="line">//	n == 0: buf too small</span><br><span class="line">//	n  &lt; 0: value larger than 64 bits (overflow)</span><br><span class="line">//	        and -n is the number of bytes read</span><br><span class="line">// Uvarint 从 buf 解码 uint64 并返回该值和读取的字节数（&gt; 0）。如果发生错误，则该值为0，并且字节数n &lt;= 0意味着：</span><br><span class="line">// n == 0：buf太小了</span><br><span class="line">// n &lt;0：大于64位的值（溢出）</span><br><span class="line">//       和-n是读取的字节数</span><br><span class="line">func Uvarint(buf []byte) (uint64, int) &#123;</span><br><span class="line">	var x uint64</span><br><span class="line">	var s uint</span><br><span class="line">	for i, b := range buf &#123;</span><br><span class="line">		// MaxVarintLen64 10</span><br><span class="line">		if i == MaxVarintLen64 &#123;</span><br><span class="line">			// Catch byte reads past MaxVarintLen64.</span><br><span class="line">			// See issue https://golang.org/issues/41185</span><br><span class="line">			return 0, -(i + 1) // overflow</span><br><span class="line">		&#125;</span><br><span class="line">		// 0x80 128</span><br><span class="line">		if b &lt; 0x80 &#123;</span><br><span class="line">			if i == MaxVarintLen64-1 &amp;&amp; b &gt; 1 &#123;</span><br><span class="line">				return 0, -(i + 1) // overflow</span><br><span class="line">			&#125;</span><br><span class="line">			return x | uint64(b)&lt;&lt;s, i + 1</span><br><span class="line">		&#125;</span><br><span class="line">		// 0x7f 127</span><br><span class="line">		x |= uint64(b&amp;0x7f) &lt;&lt; s</span><br><span class="line">		s += 7</span><br><span class="line">	&#125;</span><br><span class="line">	return 0, 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="代码示例-v2">代码示例</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;encoding/binary&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">	inputs := [][]byte&#123;</span><br><span class="line">		[]byte&#123;0x01&#125;,       //1</span><br><span class="line">		[]byte&#123;0x02&#125;,       //2</span><br><span class="line">		[]byte&#123;0x7f&#125;,       //127</span><br><span class="line">		[]byte&#123;0x80, 0x01&#125;, //128,1</span><br><span class="line">		[]byte&#123;0xff, 0x01&#125;, //255,1</span><br><span class="line">		[]byte&#123;0x80, 0x02&#125;, //128,2</span><br><span class="line">		[]byte&#123;0x80, 0x03&#125;, //128,3</span><br><span class="line">	&#125;</span><br><span class="line">	for _, b := range inputs &#123;</span><br><span class="line">		x, n := binary.Uvarint(b)</span><br><span class="line">		if n != len(b) &#123;</span><br><span class="line">			fmt.Println(&quot;Uvarint did not consume all of in&quot;)</span><br><span class="line">		&#125;</span><br><span class="line">		fmt.Println(x)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">384</span><br><span class="line"></span><br><span class="line">Program exited.</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://go.dev/play/p/df572cFK6Im" target="_blank" rel="noopener">https://go.dev/play/p/df572cFK6Im</a></p></blockquote><p>在线16进制转10进制:<a href="https://jisuan5.com/hexadecimal-to-decimal/" target="_blank" rel="noopener">https://jisuan5.com/hexadecimal-to-decimal/</a><br>参考文章:<a href="https://cloud.tencent.com/developer/section/1141534" target="_blank" rel="noopener">https://cloud.tencent.com/developer/section/1141534</a></p>]]></content>
      <tags>
        <tag>Go</tag>
        <tag>PutUvarint</tag>
        <tag>Uvarint</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang net/http 请求处理流程分析</title>
    <url>/golang-net-http-request-processing-flow.html</url>
    <content><![CDATA[<blockquote><p>serverHandler{c.server}.ServeHTTP(w, w.req)</p></blockquote><a id="more"></a><p>先看一下Golang Web Server是如何监听请求的:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">srv := &amp;http.Server&#123;</span><br><span class="line">		Addr:    &quot;:8080&quot;,</span><br><span class="line">		Handler: obj.App,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">if err := srv.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed &#123;</span><br><span class="line">   log.Fatalf(&quot;listen: %s\n&quot;, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体的监听处理在<a href="https://github.com/golang/go/blob/master/src/net/http/server.go#L2987" target="_blank" rel="noopener">ListenAndServe()</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// ListenAndServe listens on the TCP network address srv.Addr and then</span><br><span class="line">// calls Serve to handle requests on incoming connections.</span><br><span class="line">// Accepted connections are configured to enable TCP keep-alives.</span><br><span class="line">//</span><br><span class="line">// If srv.Addr is blank, &quot;:http&quot; is used.</span><br><span class="line">//</span><br><span class="line">// ListenAndServe always returns a non-nil error. After Shutdown or Close,</span><br><span class="line">// the returned error is ErrServerClosed.</span><br><span class="line">func (srv *Server) ListenAndServe() error &#123;</span><br><span class="line">	if srv.shuttingDown() &#123;</span><br><span class="line">		return ErrServerClosed</span><br><span class="line">	&#125;</span><br><span class="line">	addr := srv.Addr</span><br><span class="line">	if addr == &quot;&quot; &#123;</span><br><span class="line">		addr = &quot;:http&quot;</span><br><span class="line">	&#125;</span><br><span class="line">	ln, err := net.Listen(&quot;tcp&quot;, addr)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return srv.Serve(ln)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面看一下<a href="https://github.com/golang/go/blob/master/src/net/http/server.go#L3040" target="_blank" rel="noopener">Serve(l net.Listener)</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Serve accepts incoming connections on the Listener l, creating a</span><br><span class="line">// new service goroutine for each. The service goroutines read requests and</span><br><span class="line">// then call srv.Handler to reply to them.</span><br><span class="line">//</span><br><span class="line">// HTTP/2 support is only enabled if the Listener returns *tls.Conn</span><br><span class="line">// connections and they were configured with &quot;h2&quot; in the TLS</span><br><span class="line">// Config.NextProtos.</span><br><span class="line">//</span><br><span class="line">// Serve always returns a non-nil error and closes l.</span><br><span class="line">// After Shutdown or Close, the returned error is ErrServerClosed.</span><br><span class="line">func (srv *Server) Serve(l net.Listener) error &#123;</span><br><span class="line">	if fn := testHookServerServe; fn != nil &#123;</span><br><span class="line">		fn(srv, l) // call hook with unwrapped listener</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	origListener := l</span><br><span class="line">	l = &amp;onceCloseListener&#123;Listener: l&#125;</span><br><span class="line">	defer l.Close()</span><br><span class="line"></span><br><span class="line">	if err := srv.setupHTTP2_Serve(); err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if !srv.trackListener(&amp;l, true) &#123;</span><br><span class="line">		return ErrServerClosed</span><br><span class="line">	&#125;</span><br><span class="line">	defer srv.trackListener(&amp;l, false)</span><br><span class="line"></span><br><span class="line">	baseCtx := context.Background()</span><br><span class="line">	if srv.BaseContext != nil &#123;</span><br><span class="line">		baseCtx = srv.BaseContext(origListener)</span><br><span class="line">		if baseCtx == nil &#123;</span><br><span class="line">			panic(&quot;BaseContext returned a nil context&quot;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	var tempDelay time.Duration // how long to sleep on accept failure</span><br><span class="line"></span><br><span class="line">	ctx := context.WithValue(baseCtx, ServerContextKey, srv)</span><br><span class="line">	for &#123;</span><br><span class="line">		rw, err := l.Accept()</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			select &#123;</span><br><span class="line">			case &lt;-srv.getDoneChan():</span><br><span class="line">				return ErrServerClosed</span><br><span class="line">			default:</span><br><span class="line">			&#125;</span><br><span class="line">			if ne, ok := err.(net.Error); ok &amp;&amp; ne.Temporary() &#123;</span><br><span class="line">				if tempDelay == 0 &#123;</span><br><span class="line">					tempDelay = 5 * time.Millisecond</span><br><span class="line">				&#125; else &#123;</span><br><span class="line">					tempDelay *= 2</span><br><span class="line">				&#125;</span><br><span class="line">				if max := 1 * time.Second; tempDelay &gt; max &#123;</span><br><span class="line">					tempDelay = max</span><br><span class="line">				&#125;</span><br><span class="line">				srv.logf(&quot;http: Accept error: %v; retrying in %v&quot;, err, tempDelay)</span><br><span class="line">				time.Sleep(tempDelay)</span><br><span class="line">				continue</span><br><span class="line">			&#125;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		connCtx := ctx</span><br><span class="line">		if cc := srv.ConnContext; cc != nil &#123;</span><br><span class="line">			connCtx = cc(connCtx, rw)</span><br><span class="line">			if connCtx == nil &#123;</span><br><span class="line">				panic(&quot;ConnContext returned nil&quot;)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		tempDelay = 0</span><br><span class="line">		c := srv.newConn(rw)</span><br><span class="line">		c.setState(c.rwc, StateNew, runHooks) // before Serve can return</span><br><span class="line">		go c.serve(connCtx)  // &lt;--- 注意这里</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意一下，在serve(l net.Listener)函数中，对于每一个请求都会开一个协程来处理。</p></blockquote><p>协程内部都做了啥呢？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Serve a new connection.</span><br><span class="line">func (c *conn) serve(ctx context.Context) &#123;</span><br><span class="line">	c.remoteAddr = c.rwc.RemoteAddr().String()</span><br><span class="line">	ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr())</span><br><span class="line">	var inFlightResponse *response</span><br><span class="line">	defer func() &#123;</span><br><span class="line">		if err := recover(); err != nil &amp;&amp; err != ErrAbortHandler &#123;</span><br><span class="line">			const size = 64 &lt;&lt; 10</span><br><span class="line">			buf := make([]byte, size)</span><br><span class="line">			buf = buf[:runtime.Stack(buf, false)]</span><br><span class="line">			c.server.logf(&quot;http: panic serving %v: %v\n%s&quot;, c.remoteAddr, err, buf)</span><br><span class="line">		&#125;</span><br><span class="line">		if inFlightResponse != nil &#123;</span><br><span class="line">			inFlightResponse.cancelCtx()</span><br><span class="line">		&#125;</span><br><span class="line">		if !c.hijacked() &#123;</span><br><span class="line">			if inFlightResponse != nil &#123;</span><br><span class="line">				inFlightResponse.conn.r.abortPendingRead()</span><br><span class="line">				inFlightResponse.reqBody.Close()</span><br><span class="line">			&#125;</span><br><span class="line">			c.close()</span><br><span class="line">			c.setState(c.rwc, StateClosed, runHooks)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	if tlsConn, ok := c.rwc.(*tls.Conn); ok &#123;</span><br><span class="line">		tlsTO := c.server.tlsHandshakeTimeout()</span><br><span class="line">		if tlsTO &gt; 0 &#123;</span><br><span class="line">			dl := time.Now().Add(tlsTO)</span><br><span class="line">			c.rwc.SetReadDeadline(dl)</span><br><span class="line">			c.rwc.SetWriteDeadline(dl)</span><br><span class="line">		&#125;</span><br><span class="line">		if err := tlsConn.HandshakeContext(ctx); err != nil &#123;</span><br><span class="line">			// If the handshake failed due to the client not speaking</span><br><span class="line">			// TLS, assume they&apos;re speaking plaintext HTTP and write a</span><br><span class="line">			// 400 response on the TLS conn&apos;s underlying net.Conn.</span><br><span class="line">			if re, ok := err.(tls.RecordHeaderError); ok &amp;&amp; re.Conn != nil &amp;&amp; tlsRecordHeaderLooksLikeHTTP(re.RecordHeader) &#123;</span><br><span class="line">				io.WriteString(re.Conn, &quot;HTTP/1.0 400 Bad Request\r\n\r\nClient sent an HTTP request to an HTTPS server.\n&quot;)</span><br><span class="line">				re.Conn.Close()</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">			c.server.logf(&quot;http: TLS handshake error from %s: %v&quot;, c.rwc.RemoteAddr(), err)</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">		// Restore Conn-level deadlines.</span><br><span class="line">		if tlsTO &gt; 0 &#123;</span><br><span class="line">			c.rwc.SetReadDeadline(time.Time&#123;&#125;)</span><br><span class="line">			c.rwc.SetWriteDeadline(time.Time&#123;&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">		c.tlsState = new(tls.ConnectionState)</span><br><span class="line">		*c.tlsState = tlsConn.ConnectionState()</span><br><span class="line">		if proto := c.tlsState.NegotiatedProtocol; validNextProto(proto) &#123;</span><br><span class="line">			if fn := c.server.TLSNextProto[proto]; fn != nil &#123;</span><br><span class="line">				h := initALPNRequest&#123;ctx, tlsConn, serverHandler&#123;c.server&#125;&#125;</span><br><span class="line">				// Mark freshly created HTTP/2 as active and prevent any server state hooks</span><br><span class="line">				// from being run on these connections. This prevents closeIdleConns from</span><br><span class="line">				// closing such connections. See issue https://golang.org/issue/39776.</span><br><span class="line">				c.setState(c.rwc, StateActive, skipHooks)</span><br><span class="line">				fn(c.server, tlsConn, h)</span><br><span class="line">			&#125;</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// HTTP/1.x from here on.</span><br><span class="line"></span><br><span class="line">	ctx, cancelCtx := context.WithCancel(ctx)</span><br><span class="line">	c.cancelCtx = cancelCtx</span><br><span class="line">	defer cancelCtx()</span><br><span class="line"></span><br><span class="line">	c.r = &amp;connReader&#123;conn: c&#125;</span><br><span class="line">	c.bufr = newBufioReader(c.r)</span><br><span class="line">	c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, 4&lt;&lt;10)</span><br><span class="line"></span><br><span class="line">	for &#123;</span><br><span class="line">		w, err := c.readRequest(ctx)</span><br><span class="line">		if c.r.remain != c.server.initialReadLimitSize() &#123;</span><br><span class="line">			// If we read any bytes off the wire, we&apos;re active.</span><br><span class="line">			c.setState(c.rwc, StateActive, runHooks)</span><br><span class="line">		&#125;</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			const errorHeaders = &quot;\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n&quot;</span><br><span class="line"></span><br><span class="line">			switch &#123;</span><br><span class="line">			case err == errTooLarge:</span><br><span class="line">				// Their HTTP client may or may not be</span><br><span class="line">				// able to read this if we&apos;re</span><br><span class="line">				// responding to them and hanging up</span><br><span class="line">				// while they&apos;re still writing their</span><br><span class="line">				// request. Undefined behavior.</span><br><span class="line">				const publicErr = &quot;431 Request Header Fields Too Large&quot;</span><br><span class="line">				fmt.Fprintf(c.rwc, &quot;HTTP/1.1 &quot;+publicErr+errorHeaders+publicErr)</span><br><span class="line">				c.closeWriteAndWait()</span><br><span class="line">				return</span><br><span class="line"></span><br><span class="line">			case isUnsupportedTEError(err):</span><br><span class="line">				// Respond as per RFC 7230 Section 3.3.1 which says,</span><br><span class="line">				//      A server that receives a request message with a</span><br><span class="line">				//      transfer coding it does not understand SHOULD</span><br><span class="line">				//      respond with 501 (Unimplemented).</span><br><span class="line">				code := StatusNotImplemented</span><br><span class="line"></span><br><span class="line">				// We purposefully aren&apos;t echoing back the transfer-encoding&apos;s value,</span><br><span class="line">				// so as to mitigate the risk of cross side scripting by an attacker.</span><br><span class="line">				fmt.Fprintf(c.rwc, &quot;HTTP/1.1 %d %s%sUnsupported transfer encoding&quot;, code, StatusText(code), errorHeaders)</span><br><span class="line">				return</span><br><span class="line"></span><br><span class="line">			case isCommonNetReadError(err):</span><br><span class="line">				return // don&apos;t reply</span><br><span class="line"></span><br><span class="line">			default:</span><br><span class="line">				if v, ok := err.(statusError); ok &#123;</span><br><span class="line">					fmt.Fprintf(c.rwc, &quot;HTTP/1.1 %d %s: %s%s%d %s: %s&quot;, v.code, StatusText(v.code), v.text, errorHeaders, v.code, StatusText(v.code), v.text)</span><br><span class="line">					return</span><br><span class="line">				&#125;</span><br><span class="line">				publicErr := &quot;400 Bad Request&quot;</span><br><span class="line">				fmt.Fprintf(c.rwc, &quot;HTTP/1.1 &quot;+publicErr+errorHeaders+publicErr)</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// Expect 100 Continue support</span><br><span class="line">		req := w.req</span><br><span class="line">		if req.expectsContinue() &#123;</span><br><span class="line">			if req.ProtoAtLeast(1, 1) &amp;&amp; req.ContentLength != 0 &#123;</span><br><span class="line">				// Wrap the Body reader with one that replies on the connection</span><br><span class="line">				req.Body = &amp;expectContinueReader&#123;readCloser: req.Body, resp: w&#125;</span><br><span class="line">				w.canWriteContinue.setTrue()</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else if req.Header.get(&quot;Expect&quot;) != &quot;&quot; &#123;</span><br><span class="line">			w.sendExpectationFailed()</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		c.curReq.Store(w)</span><br><span class="line"></span><br><span class="line">		if requestBodyRemains(req.Body) &#123;</span><br><span class="line">			registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead)</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			w.conn.r.startBackgroundRead()</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// HTTP cannot have multiple simultaneous active requests.[*]</span><br><span class="line">		// Until the server replies to this request, it can&apos;t read another,</span><br><span class="line">		// so we might as well run the handler in this goroutine.</span><br><span class="line">		// [*] Not strictly true: HTTP pipelining. We could let them all process</span><br><span class="line">		// in parallel even if their responses need to be serialized.</span><br><span class="line">		// But we&apos;re not going to implement HTTP pipelining because it</span><br><span class="line">		// was never deployed in the wild and the answer is HTTP/2.</span><br><span class="line">		inFlightResponse = w</span><br><span class="line">		serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req) // &lt;--- 注意这里</span><br><span class="line">		inFlightResponse = nil</span><br><span class="line">		w.cancelCtx()</span><br><span class="line">		if c.hijacked() &#123;</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">		w.finishRequest()</span><br><span class="line">		if !w.shouldReuseConnection() &#123;</span><br><span class="line">			if w.requestBodyLimitHit || w.closedRequestBodyEarly() &#123;</span><br><span class="line">				c.closeWriteAndWait()</span><br><span class="line">			&#125;</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">		c.setState(c.rwc, StateIdle, runHooks)</span><br><span class="line">		c.curReq.Store((*response)(nil))</span><br><span class="line"></span><br><span class="line">		if !w.conn.server.doKeepAlives() &#123;</span><br><span class="line">			// We&apos;re in shutdown mode. We might&apos;ve replied</span><br><span class="line">			// to the user without &quot;Connection: close&quot; and</span><br><span class="line">			// they might think they can send another</span><br><span class="line">			// request, but such is life with HTTP/1.1.</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if d := c.server.idleTimeout(); d != 0 &#123;</span><br><span class="line">			c.rwc.SetReadDeadline(time.Now().Add(d))</span><br><span class="line">			if _, err := c.bufr.Peek(4); err != nil &#123;</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		c.rwc.SetReadDeadline(time.Time&#123;&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这行代码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req)</span><br></pre></td></tr></table></figure><p>其中ServeHTTP是一个接口，绝大多数Web框架都是通过实现该接口，从而替换掉Golang默认的路由。</p><p>具体的接口定义:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// A Handler responds to an HTTP request.</span><br><span class="line">//</span><br><span class="line">// ServeHTTP should write reply headers and data to the ResponseWriter</span><br><span class="line">// and then return. Returning signals that the request is finished; it</span><br><span class="line">// is not valid to use the ResponseWriter or read from the</span><br><span class="line">// Request.Body after or concurrently with the completion of the</span><br><span class="line">// ServeHTTP call.</span><br><span class="line">//</span><br><span class="line">// Depending on the HTTP client software, HTTP protocol version, and</span><br><span class="line">// any intermediaries between the client and the Go server, it may not</span><br><span class="line">// be possible to read from the Request.Body after writing to the</span><br><span class="line">// ResponseWriter. Cautious handlers should read the Request.Body</span><br><span class="line">// first, and then reply.</span><br><span class="line">//</span><br><span class="line">// Except for reading the body, handlers should not modify the</span><br><span class="line">// provided Request.</span><br><span class="line">//</span><br><span class="line">// If ServeHTTP panics, the server (the caller of ServeHTTP) assumes</span><br><span class="line">// that the effect of the panic was isolated to the active request.</span><br><span class="line">// It recovers the panic, logs a stack trace to the server error log,</span><br><span class="line">// and either closes the network connection or sends an HTTP/2</span><br><span class="line">// RST_STREAM, depending on the HTTP protocol. To abort a handler so</span><br><span class="line">// the client sees an interrupted response but the server doesn&apos;t log</span><br><span class="line">// an error, panic with the value ErrAbortHandler.</span><br><span class="line">type Handler interface &#123;</span><br><span class="line">	ServeHTTP(ResponseWriter, *Request)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Golang默认实现:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// https://github.com/golang/go/blob/master/src/net/http/server.go#L2926</span><br><span class="line">func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) &#123;</span><br><span class="line">	handler := sh.srv.Handler</span><br><span class="line">	if handler == nil &#123;</span><br><span class="line">		handler = DefaultServeMux</span><br><span class="line">	&#125;</span><br><span class="line">	if req.RequestURI == &quot;*&quot; &amp;&amp; req.Method == &quot;OPTIONS&quot; &#123;</span><br><span class="line">		handler = globalOptionsHandler&#123;&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if req.URL != nil &amp;&amp; strings.Contains(req.URL.RawQuery, &quot;;&quot;) &#123;</span><br><span class="line">		var allowQuerySemicolonsInUse int32</span><br><span class="line">		req = req.WithContext(context.WithValue(req.Context(), silenceSemWarnContextKey, func() &#123;</span><br><span class="line">			atomic.StoreInt32(&amp;allowQuerySemicolonsInUse, 1)</span><br><span class="line">		&#125;))</span><br><span class="line">		defer func() &#123;</span><br><span class="line">			if atomic.LoadInt32(&amp;allowQuerySemicolonsInUse) == 0 &#123;</span><br><span class="line">				sh.srv.logf(&quot;http: URL query contains semicolon, which is no longer a supported separator; parts of the query may be stripped when parsed; see golang.org/issue/25192&quot;)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	handler.ServeHTTP(rw, req)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://github.com/golang/go/blob/master/src/net/http/server.go#L2478</span><br><span class="line">// ServeHTTP dispatches the request to the handler whose</span><br><span class="line">// pattern most closely matches the request URL.</span><br><span class="line">func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) &#123;</span><br><span class="line">	if r.RequestURI == &quot;*&quot; &#123;</span><br><span class="line">		if r.ProtoAtLeast(1, 1) &#123;</span><br><span class="line">			w.Header().Set(&quot;Connection&quot;, &quot;close&quot;)</span><br><span class="line">		&#125;</span><br><span class="line">		w.WriteHeader(StatusBadRequest)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	h, _ := mux.Handler(r) // &lt;--- 注意这里</span><br><span class="line">	h.ServeHTTP(w, r)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://github.com/golang/go/blob/master/src/net/http/server.go#L2423</span><br><span class="line">// consulting r.Method, r.Host, and r.URL.Path. It always returns</span><br><span class="line">// a non-nil handler. If the path is not in its canonical form, the</span><br><span class="line">// handler will be an internally-generated handler that redirects</span><br><span class="line">// to the canonical path. If the host contains a port, it is ignored</span><br><span class="line">// when matching handlers.</span><br><span class="line">//</span><br><span class="line">// The path and host are used unchanged for CONNECT requests.</span><br><span class="line">//</span><br><span class="line">// Handler also returns the registered pattern that matches the</span><br><span class="line">// request or, in the case of internally-generated redirects,</span><br><span class="line">// the pattern that will match after following the redirect.</span><br><span class="line">//</span><br><span class="line">// If there is no registered handler that applies to the request,</span><br><span class="line">// Handler returns a “page not found” handler and an empty pattern.</span><br><span class="line">func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) &#123;</span><br><span class="line"></span><br><span class="line">	// CONNECT requests are not canonicalized.</span><br><span class="line">	if r.Method == &quot;CONNECT&quot; &#123;</span><br><span class="line">		// If r.URL.Path is /tree and its handler is not registered,</span><br><span class="line">		// the /tree -&gt; /tree/ redirect applies to CONNECT requests</span><br><span class="line">		// but the path canonicalization does not.</span><br><span class="line">		if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok &#123;</span><br><span class="line">			return RedirectHandler(u.String(), StatusMovedPermanently), u.Path</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return mux.handler(r.Host, r.URL.Path)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// All other requests have any port stripped and path cleaned</span><br><span class="line">	// before passing to mux.handler.</span><br><span class="line">	host := stripHostPort(r.Host)</span><br><span class="line">	path := cleanPath(r.URL.Path)</span><br><span class="line"></span><br><span class="line">	// If the given path is /tree and its handler is not registered,</span><br><span class="line">	// redirect for /tree/.</span><br><span class="line">	if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok &#123;</span><br><span class="line">		return RedirectHandler(u.String(), StatusMovedPermanently), u.Path</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if path != r.URL.Path &#123;</span><br><span class="line">		_, pattern = mux.handler(host, path)</span><br><span class="line">		u := &amp;url.URL&#123;Path: path, RawQuery: r.URL.RawQuery&#125;</span><br><span class="line">		return RedirectHandler(u.String(), StatusMovedPermanently), pattern</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return mux.handler(host, r.URL.Path)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://github.com/golang/go/blob/master/src/net/http/server.go#L2459</span><br><span class="line">// handler is the main implementation of Handler.</span><br><span class="line">// The path is known to be in canonical form, except for CONNECT methods.</span><br><span class="line">func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) &#123;</span><br><span class="line">	mux.mu.RLock()</span><br><span class="line">	defer mux.mu.RUnlock()</span><br><span class="line"></span><br><span class="line">	// Host-specific pattern takes precedence over generic ones</span><br><span class="line">	if mux.hosts &#123;</span><br><span class="line">		h, pattern = mux.match(host + path)</span><br><span class="line">	&#125;</span><br><span class="line">	if h == nil &#123;</span><br><span class="line">		h, pattern = mux.match(path)</span><br><span class="line">	&#125;</span><br><span class="line">	if h == nil &#123;</span><br><span class="line">		h, pattern = NotFoundHandler(), &quot;&quot;</span><br><span class="line">	&#125;</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://github.com/golang/go/blob/master/src/net/http/server.go#L2350</span><br><span class="line">// 从代码中可以看出，匹配规则过于简单,导致基本所有的go框架</span><br><span class="line">// 最重要的一点就是:重写路由匹配这部分，比如gin</span><br><span class="line">// Find a handler on a handler map given a path string.</span><br><span class="line">// Most-specific (longest) pattern wins.</span><br><span class="line">func (mux *ServeMux) match(path string) (h Handler, pattern string) &#123;</span><br><span class="line">	// Check for exact match first.</span><br><span class="line">	v, ok := mux.m[path]</span><br><span class="line">	if ok &#123;</span><br><span class="line">		return v.h, v.pattern</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// Check for longest valid match.  mux.es contains all patterns</span><br><span class="line">	// that end in / sorted from longest to shortest.</span><br><span class="line">	for _, e := range mux.es &#123;</span><br><span class="line">		if strings.HasPrefix(path, e.pattern) &#123;</span><br><span class="line">			return e.h, e.pattern</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return nil, &quot;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// ServeHTTP calls f(w, r).</span><br><span class="line">func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) &#123;</span><br><span class="line">	f(w, r)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// The HandlerFunc type is an adapter to allow the use of</span><br><span class="line">// ordinary functions as HTTP handlers. If f is a function</span><br><span class="line">// with the appropriate signature, HandlerFunc(f) is a</span><br><span class="line">// Handler that calls f.</span><br><span class="line">type HandlerFunc func(ResponseWriter, *Request) // &lt;--- 接口型函数</span><br></pre></td></tr></table></figure><p>比如Gin就通过实现<a href="https://github.com/gin-gonic/gin/blob/master/gin.go#L566" target="_blank" rel="noopener">ServeHTTP(w http.ResponseWriter, req *http.Request)</a>接口，在这里重新实现路由匹配</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// ServeHTTP conforms to the http.Handler interface.</span><br><span class="line">func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123;</span><br><span class="line">	c := engine.pool.Get().(*Context)</span><br><span class="line">	c.writermem.reset(w)</span><br><span class="line">	c.Request = req</span><br><span class="line">	c.reset()</span><br><span class="line"></span><br><span class="line">	engine.handleHTTPRequest(c)</span><br><span class="line"></span><br><span class="line">	engine.pool.Put(c)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// https://github.com/gin-gonic/gin/blob/master/gin.go#L588</span><br><span class="line">func (engine *Engine) handleHTTPRequest(c *Context) &#123;</span><br><span class="line">	httpMethod := c.Request.Method</span><br><span class="line">	rPath := c.Request.URL.Path</span><br><span class="line">	unescape := false</span><br><span class="line">	if engine.UseRawPath &amp;&amp; len(c.Request.URL.RawPath) &gt; 0 &#123;</span><br><span class="line">		rPath = c.Request.URL.RawPath</span><br><span class="line">		unescape = engine.UnescapePathValues</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if engine.RemoveExtraSlash &#123;</span><br><span class="line">		rPath = cleanPath(rPath)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// Find root of the tree for the given HTTP method</span><br><span class="line">	t := engine.trees</span><br><span class="line">	for i, tl := 0, len(t); i &lt; tl; i++ &#123;</span><br><span class="line">		if t[i].method != httpMethod &#123;</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line">		root := t[i].root</span><br><span class="line">		// Find route in tree</span><br><span class="line">		value := root.getValue(rPath, c.params, c.skippedNodes, unescape)</span><br><span class="line">		if value.params != nil &#123;</span><br><span class="line">			c.Params = *value.params</span><br><span class="line">		&#125;</span><br><span class="line">		if value.handlers != nil &#123;</span><br><span class="line">			c.handlers = value.handlers</span><br><span class="line">			c.fullPath = value.fullPath</span><br><span class="line">			c.Next()</span><br><span class="line">			c.writermem.WriteHeaderNow()</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">		if httpMethod != http.MethodConnect &amp;&amp; rPath != &quot;/&quot; &#123;</span><br><span class="line">			if value.tsr &amp;&amp; engine.RedirectTrailingSlash &#123;</span><br><span class="line">				redirectTrailingSlash(c)</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">			if engine.RedirectFixedPath &amp;&amp; redirectFixedPath(c, root, engine.RedirectFixedPath) &#123;</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		break</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if engine.HandleMethodNotAllowed &#123;</span><br><span class="line">		for _, tree := range engine.trees &#123;</span><br><span class="line">			if tree.method == httpMethod &#123;</span><br><span class="line">				continue</span><br><span class="line">			&#125;</span><br><span class="line">			if value := tree.root.getValue(rPath, nil, c.skippedNodes, unescape); value.handlers != nil &#123;</span><br><span class="line">				c.handlers = engine.allNoMethod</span><br><span class="line">				serveError(c, http.StatusMethodNotAllowed, default405Body)</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	c.handlers = engine.allNoRoute</span><br><span class="line">	serveError(c, http.StatusNotFound, default404Body)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>原创</tag>
        <tag>Go</tag>
        <tag>net/http</tag>
        <tag>Request</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang写时复制是否是原子性的？</title>
    <url>/golang-copy-on-write-and-atomic.html</url>
    <content><![CDATA[<blockquote><p>Golang在生成汇编语句的时候,赋值是一句话,所以:COW Copy-On-Write是原子性的</p></blockquote><a id="more"></a><p>先说一下我这边的一个简化场景吧，有一个定时任务定时从数据库获取数据，也就是对应实例代码中的getNewProject()，获取完数据后，会直接赋给变量projectMap(projectMap其实就是作为一个缓存来用的)；还会有程序从projectMap获取对应的信息。</p><p>这个场景其实就是一个简单的写时复制。对于获取在赋值过程中，获取到旧值，也是允许的。</p><p>有个疑问点就是在赋值的这个操作是不是原子的呢？</p><p>比如示例代码中的第8行。</p><p>验证代码:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">var (</span><br><span class="line">        projectMap = make(map[string]*Project)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">        projectMap = getNewProject()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func getNewProject() map[string]*Project &#123;</span><br><span class="line">        items := make(map[string]*Project)</span><br><span class="line"></span><br><span class="line">        item := new(Project)</span><br><span class="line">        item.ID = &quot;project_id&quot;</span><br><span class="line">        item.Name = &quot;project_name&quot;</span><br><span class="line"></span><br><span class="line">        items[item.ID] = item</span><br><span class="line">        return items</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type Project struct &#123;</span><br><span class="line">        ID   string `json:&quot;id&quot;`</span><br><span class="line">        Name string `json:&quot;name&quot;`</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在网上也找到一些资料，说是原子性的：</p><ul><li>看看开源项目都是如何做的<ul><li><a href="https://github.com/fagongzi/manba/blob/master/pkg/proxy/dispatcher_meta.go#L174" target="_blank" rel="noopener">https://github.com/fagongzi/manba/blob/master/pkg/proxy/dispatcher_meta.go#L174</a></li></ul></li><li>看看一些对于Copy-On-Write的讨论<ul><li><a href="https://chunlife.top/2019/09/03/copy-on-write%E6%8A%80%E6%9C%AF/" target="_blank" rel="noopener">https://chunlife.top/2019/09/03/copy-on-write技术/</a></li><li><a href="https://github.com/Terry-Mao/gopush-cluster/issues/44" target="_blank" rel="noopener">https://github.com/Terry-Mao/gopush-cluster/issues/44</a></li></ul></li></ul><p>但终究还是自己探索一下的比较好对吧，哈哈。</p><p>要想看这个赋值操作是不是原子性的，那咱们看下汇编代码吧。<br>查看汇编，咱们分为两步：</p><ul><li>编译golang代码为.o文件</li><li>反编译.o文件</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PS D:\Code\Golang\github\jiankunking\cow-test&gt; go tool compile -N -l main\main.go    </span><br><span class="line">PS D:\Code\Golang\github\jiankunking\cow-test&gt; go tool objdump .\main.o              </span><br><span class="line">TEXT &quot;&quot;.main(SB) gofile..D:/Code/Golang/github/jiankunking/cow-test/main/main.go                                                    </span><br><span class="line">  main.go:7             0x22f1                  493b6610                CMPQ 0x10(R14), SP                                          </span><br><span class="line">  main.go:7             0x22f5                  763e                    JBE 0x2335                                                  </span><br><span class="line">  main.go:7             0x22f7                  4883ec08                SUBQ $0x8, SP                                               </span><br><span class="line">  main.go:7             0x22fb                  48892c24                MOVQ BP, 0(SP)                                              </span><br><span class="line">  main.go:7             0x22ff                  488d2c24                LEAQ 0(SP), BP                                              </span><br><span class="line">  main.go:8             0x2303                  e800000000              CALL 0x2308             [1:5]R_CALL:&quot;&quot;.getNewProject        </span><br><span class="line">  main.go:8             0x2308                  833d0000000000          CMPL $0x0, 0(IP)        [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">  main.go:8             0x230f                  6690                    NOPW                                                        </span><br><span class="line">  main.go:8             0x2311                  7402                    JE 0x2315                                                   </span><br><span class="line">  main.go:8             0x2313                  eb09                    JMP 0x231e                                                  </span><br><span class="line">  main.go:8             0x2315                  48890500000000          MOVQ AX, 0(IP)          [3:7]R_PCREL:&quot;&quot;.projectMap          </span><br><span class="line">  main.go:8             0x231c                  eb0e                    JMP 0x232c                                                  </span><br><span class="line">  main.go:8             0x231e                  488d3d00000000          LEAQ 0(IP), DI          [3:7]R_PCREL:&quot;&quot;.projectMap</span><br><span class="line">  main.go:8             0x2325                  e800000000              CALL 0x232a             [1:5]R_CALL:runtime.gcWriteBarrier&lt;1&gt;</span><br><span class="line">  main.go:8             0x232a                  eb00                    JMP 0x232c</span><br><span class="line">  main.go:9             0x232c                  488b2c24                MOVQ 0(SP), BP</span><br><span class="line">  main.go:9             0x2330                  4883c408                ADDQ $0x8, SP</span><br><span class="line">  main.go:9             0x2334                  c3                      RET</span><br><span class="line">  main.go:7             0x2335                  e800000000              CALL 0x233a             [1:5]R_CALL:runtime.morestack_noctxt</span><br><span class="line">  main.go:7             0x233a                  ebb5                    JMP &quot;&quot;.main(SB)</span><br><span class="line"></span><br><span class="line">TEXT &quot;&quot;.getNewProject(SB) gofile..D:/Code/Golang/github/jiankunking/cow-test/main/main.go</span><br><span class="line">  main.go:11            0x233c                  493b6610                CMPQ 0x10(R14), SP</span><br><span class="line">  main.go:11            0x2340                  0f8600010000            JBE 0x2446</span><br><span class="line">  main.go:11            0x2346                  4883ec58                SUBQ $0x58, SP</span><br><span class="line">  main.go:11            0x234a                  48896c2450              MOVQ BP, 0x50(SP)</span><br><span class="line">  main.go:11            0x234f                  488d6c2450              LEAQ 0x50(SP), BP</span><br><span class="line">  main.go:11            0x2354                  48c744242000000000      MOVQ $0x0, 0x20(SP)</span><br><span class="line">  main.go:12            0x235d                  e800000000              CALL 0x2362                     [1:5]R_CALL:runtime.makemap_small&lt;1&gt;</span><br><span class="line">  main.go:12            0x2362                  4889442428              MOVQ AX, 0x28(SP)</span><br><span class="line">  main.go:14            0x2367                  488d0500000000          LEAQ 0(IP), AX                  [3:7]R_PCREL:type.&quot;&quot;.Project</span><br><span class="line">  main.go:14            0x236e                  e800000000              CALL 0x2373                     [1:5]R_CALL:runtime.newobject&lt;1&gt;</span><br><span class="line">  main.go:14            0x2373                  4889442430              MOVQ AX, 0x30(SP)</span><br><span class="line">  main.go:15            0x2378                  48c740080a000000        MOVQ $0xa, 0x8(AX)</span><br><span class="line">  main.go:15            0x2380                  833d0000000000          CMPL $0x0, 0(IP)                [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">  main.go:15            0x2387                  7402                    JE 0x238b</span><br><span class="line">  main.go:15            0x2389                  eb0c                    JMP 0x2397</span><br><span class="line">  main.go:15            0x238b                  488d1500000000          LEAQ 0(IP), DX                  [3:7]R_PCREL:go.string.&quot;project_id&quot;</span><br><span class="line">  main.go:15            0x2392                  488910                  MOVQ DX, 0(AX)</span><br><span class="line">  main.go:15            0x2395                  eb11                    JMP 0x23a8</span><br><span class="line">  main.go:15            0x2397                  4889c7                  MOVQ AX, DI</span><br><span class="line">  main.go:15            0x239a                  488d1500000000          LEAQ 0(IP), DX                  [3:7]R_PCREL:go.string.&quot;project_id&quot;</span><br><span class="line">  main.go:15            0x23a1                  e800000000              CALL 0x23a6                     [1:5]R_CALL:runtime.gcWriteBarrierDX</span><br><span class="line">  main.go:15            0x23a6                  eb00                    JMP 0x23a8</span><br><span class="line">  main.go:16            0x23a8                  488b542430              MOVQ 0x30(SP), DX</span><br><span class="line">  main.go:16            0x23ad                  8402                    TESTB AL, 0(DX)</span><br><span class="line">  main.go:16            0x23af                  48c742180c000000        MOVQ $0xc, 0x18(DX)</span><br><span class="line">  main.go:16            0x23b7                  488d7a10                LEAQ 0x10(DX), DI</span><br><span class="line">  main.go:16            0x23bb                  833d0000000000          CMPL $0x0, 0(IP)                [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">  main.go:16            0x23c2                  7402                    JE 0x23c6</span><br><span class="line">  main.go:16            0x23c4                  eb0d                    JMP 0x23d3</span><br><span class="line">  main.go:16            0x23c6                  488d3500000000          LEAQ 0(IP), SI                  [3:7]R_PCREL:go.string.&quot;project_name&quot;</span><br><span class="line">  main.go:16            0x23cd                  48897210                MOVQ SI, 0x10(DX)</span><br><span class="line">  main.go:16            0x23d1                  eb10                    JMP 0x23e3</span><br><span class="line">  main.go:16            0x23d3                  488d1500000000          LEAQ 0(IP), DX                  [3:7]R_PCREL:go.string.&quot;project_name&quot;</span><br><span class="line">  main.go:16            0x23da                  6690                    NOPW</span><br><span class="line">  main.go:16            0x23dc                  e800000000              CALL 0x23e1                     [1:5]R_CALL:runtime.gcWriteBarrierDX</span><br><span class="line">  main.go:16            0x23e1                  eb00                    JMP 0x23e3</span><br><span class="line">  main.go:18            0x23e3                  488b542430              MOVQ 0x30(SP), DX</span><br><span class="line">  main.go:18            0x23e8                  8402                    TESTB AL, 0(DX)</span><br><span class="line">  main.go:18            0x23ea                  488b0a                  MOVQ 0(DX), CX</span><br><span class="line">  main.go:18            0x23ed                  488b7a08                MOVQ 0x8(DX), DI</span><br><span class="line">  main.go:18            0x23f1                  48894c2440              MOVQ CX, 0x40(SP)</span><br><span class="line">  main.go:18            0x23f6                  48897c2448              MOVQ DI, 0x48(SP)</span><br><span class="line">  main.go:18            0x23fb                  488b5c2428              MOVQ 0x28(SP), BX</span><br><span class="line">  main.go:18            0x2400                  488d0500000000          LEAQ 0(IP), AX                  [3:7]R_PCREL:type.map[string]*&quot;&quot;.Project        </span><br><span class="line">  main.go:18            0x2407                  e800000000              CALL 0x240c                     [1:5]R_CALL:runtime.mapassign_faststr&lt;1&gt;</span><br><span class="line">  main.go:18            0x240c                  4889442438              MOVQ AX, 0x38(SP)</span><br><span class="line">  main.go:18            0x2411                  8400                    TESTB AL, 0(AX)</span><br><span class="line">  main.go:18            0x2413                  488b542430              MOVQ 0x30(SP), DX</span><br><span class="line">  main.go:18            0x2418                  833d0000000000          CMPL $0x0, 0(IP)                [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">  main.go:18            0x241f                  7402                    JE 0x2423</span><br><span class="line">  main.go:18            0x2421                  eb05                    JMP 0x2428</span><br><span class="line">  main.go:18            0x2423                  488910                  MOVQ DX, 0(AX)</span><br><span class="line">  main.go:18            0x2426                  eb0a                    JMP 0x2432</span><br><span class="line">  main.go:18            0x2428                  4889c7                  MOVQ AX, DI</span><br><span class="line">  main.go:18            0x242b                  e800000000              CALL 0x2430                     [1:5]R_CALL:runtime.gcWriteBarrierDX</span><br><span class="line">  main.go:18            0x2430                  eb00                    JMP 0x2432</span><br><span class="line">  main.go:19            0x2432                  488b442428              MOVQ 0x28(SP), AX</span><br><span class="line">  main.go:19            0x2437                  4889442420              MOVQ AX, 0x20(SP)</span><br><span class="line">  main.go:19            0x243c                  488b6c2450              MOVQ 0x50(SP), BP</span><br><span class="line">  main.go:19            0x2441                  4883c458                ADDQ $0x58, SP</span><br><span class="line">  main.go:19            0x2445                  c3                      RET</span><br><span class="line">  main.go:11            0x2446                  e800000000              CALL 0x244b                     [1:5]R_CALL:runtime.morestack_noctxt</span><br><span class="line">  main.go:11            0x244b                  e9ecfeffff              JMP &quot;&quot;.getNewProject(SB)</span><br><span class="line"></span><br><span class="line">TEXT &quot;&quot;.init(SB) gofile..D:/Code/Golang/github/jiankunking/cow-test/main/main.go</span><br><span class="line">  main.go:4             0x2450                  493b6610                CMPQ 0x10(R14), SP</span><br><span class="line">  main.go:4             0x2454                  763e                    JBE 0x2494</span><br><span class="line">  main.go:4             0x2456                  4883ec08                SUBQ $0x8, SP</span><br><span class="line">  main.go:4             0x245a                  48892c24                MOVQ BP, 0(SP)</span><br><span class="line">  main.go:4             0x245e                  488d2c24                LEAQ 0(SP), BP</span><br><span class="line">  main.go:4             0x2462                  e800000000              CALL 0x2467             [1:5]R_CALL:runtime.makemap_small&lt;1&gt;</span><br><span class="line">  main.go:4             0x2467                  833d0000000000          CMPL $0x0, 0(IP)        [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">  main.go:4             0x246e                  6690                    NOPW</span><br><span class="line">  main.go:4             0x2470                  7402                    JE 0x2474</span><br><span class="line">  main.go:4             0x2472                  eb09                    JMP 0x247d</span><br><span class="line">  main.go:4             0x2474                  48890500000000          MOVQ AX, 0(IP)          [3:7]R_PCREL:&quot;&quot;.projectMap</span><br><span class="line">  main.go:4             0x247b                  eb0e                    JMP 0x248b</span><br><span class="line">  main.go:4             0x247d                  488d3d00000000          LEAQ 0(IP), DI          [3:7]R_PCREL:&quot;&quot;.projectMap</span><br><span class="line">  main.go:4             0x2484                  e800000000              CALL 0x2489             [1:5]R_CALL:runtime.gcWriteBarrier&lt;1&gt;</span><br><span class="line">  main.go:4             0x2489                  eb00                    JMP 0x248b</span><br><span class="line">  main.go:4             0x248b                  488b2c24                MOVQ 0(SP), BP</span><br><span class="line">  main.go:4             0x248f                  4883c408                ADDQ $0x8, SP</span><br><span class="line">  main.go:4             0x2493                  c3                      RET</span><br><span class="line">  main.go:4             0x2494                  e800000000              CALL 0x2499             [1:5]R_CALL:runtime.morestack_noctxt</span><br><span class="line">  main.go:4             0x2499                  ebb5                    JMP &quot;&quot;.init(SB)</span><br><span class="line"></span><br><span class="line">TEXT type..eq.&quot;&quot;.Project(SB) gofile..&lt;autogenerated&gt;</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2713                  493b6610                CMPQ 0x10(R14), SP</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2717                  0f8610010000            JBE 0x282d</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x271d                  4883ec58                SUBQ $0x58, SP</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2721                  48896c2450              MOVQ BP, 0x50(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2726                  488d6c2450              LEAQ 0x50(SP), BP</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x272b                  4889442460              MOVQ AX, 0x60(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2730                  48895c2468              MOVQ BX, 0x68(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2735                  c644241e00              MOVB $0x0, 0x1e(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x273a                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x273f                  488b5208                MOVQ 0x8(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2743                  4889542428              MOVQ DX, 0x28(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2748                  488b542468              MOVQ 0x68(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x274d                  488b5208                MOVQ 0x8(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2751                  4889542420              MOVQ DX, 0x20(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2756                  4839542428              CMPQ DX, 0x28(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x275b                  7405                    JE 0x2762</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x275d                  e9b3000000              JMP 0x2815</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2762                  eb00                    JMP 0x2764</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2764                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2769                  488b5218                MOVQ 0x18(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x276d                  4889542420              MOVQ DX, 0x20(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2772                  488b542468              MOVQ 0x68(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2777                  488b5218                MOVQ 0x18(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x277b                  4889542428              MOVQ DX, 0x28(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2780                  4839542420              CMPQ DX, 0x20(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2785                  7405                    JE 0x278c</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2787                  e987000000              JMP 0x2813</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x278c                  eb00                    JMP 0x278e</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x278e                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2793                  488b5208                MOVQ 0x8(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2797                  4889542428              MOVQ DX, 0x28(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x279c                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27a1                  488b12                  MOVQ 0(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27a4                  4889542448              MOVQ DX, 0x48(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27a9                  488b542468              MOVQ 0x68(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27ae                  488b1a                  MOVQ 0(DX), BX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27b1                  48895c2440              MOVQ BX, 0x40(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27b6                  488b4c2428              MOVQ 0x28(SP), CX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27bb                  488b442448              MOVQ 0x48(SP), AX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27c0                  e800000000              CALL 0x27c5                     [1:5]R_CALL:runtime.memequal&lt;1&gt;</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27c5                  8844241f                MOVB AL, 0x1f(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27c9                  84c0                    TESTL AL, AL</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27cb                  7502                    JNE 0x27cf</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27cd                  eb41                    JMP 0x2810</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27cf                  eb00                    JMP 0x27d1</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27d1                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27d6                  488b5218                MOVQ 0x18(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27da                  4889542428              MOVQ DX, 0x28(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27df                  488b542460              MOVQ 0x60(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27e4                  488b5210                MOVQ 0x10(DX), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27e8                  4889542438              MOVQ DX, 0x38(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27ed                  488b542468              MOVQ 0x68(SP), DX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27f2                  488b5a10                MOVQ 0x10(DX), BX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27f6                  48895c2430              MOVQ BX, 0x30(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x27fb                  488b4c2428              MOVQ 0x28(SP), CX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2800                  488b442438              MOVQ 0x38(SP), AX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2805                  e800000000              CALL 0x280a                     [1:5]R_CALL:runtime.memequal&lt;1&gt;</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x280a                  8844241e                MOVB AL, 0x1e(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x280e                  eb0e                    JMP 0x281e</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2810                  eb05                    JMP 0x2817</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2812                  90                      NOPL</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2813                  eb02                    JMP 0x2817</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2815                  eb00                    JMP 0x2817</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2817                  c644241e00              MOVB $0x0, 0x1e(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x281c                  eb00                    JMP 0x281e</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x281e                  0fb644241e              MOVZX 0x1e(SP), AX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2823                  488b6c2450              MOVQ 0x50(SP), BP</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2828                  4883c458                ADDQ $0x58, SP</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x282c                  c3                      RET</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x282d                  4889442408              MOVQ AX, 0x8(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2832                  48895c2410              MOVQ BX, 0x10(SP)</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2837                  e800000000              CALL 0x283c                     [1:5]R_CALL:runtime.morestack_noctxt    </span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x283c                  488b442408              MOVQ 0x8(SP), AX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2841                  488b5c2410              MOVQ 0x10(SP), BX</span><br><span class="line">  gofile..&lt;autogenerated&gt;:1     0x2846                  e9c8feffff              JMP type..eq.&quot;&quot;.Project(SB)</span><br><span class="line">PS D:\Code\Golang\github\jiankunking\cow-test&gt;</span><br></pre></td></tr></table></figure><p>先从汇编代码中摘取出，第8行代码对应的汇编</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">main.go:8             0x2303                  e800000000              CALL 0x2308             [1:5]R_CALL:&quot;&quot;.getNewProject        </span><br><span class="line">main.go:8             0x2308                  833d0000000000          CMPL $0x0, 0(IP)        [2:6]R_PCREL:runtime.writeBarrier+-1</span><br><span class="line">main.go:8             0x230f                  6690                    NOPW                                                        </span><br><span class="line">main.go:8             0x2311                  7402                    JE 0x2315                                                   </span><br><span class="line">main.go:8             0x2313                  eb09                    JMP 0x231e                                                  </span><br><span class="line">main.go:8             0x2315                  48890500000000          MOVQ AX, 0(IP)          [3:7]R_PCREL:&quot;&quot;.projectMap          </span><br><span class="line">main.go:8             0x231c                  eb0e                    JMP 0x232c                                                  </span><br><span class="line">main.go:8             0x231e                  488d3d00000000          LEAQ 0(IP), DI          [3:7]R_PCREL:&quot;&quot;.projectMap</span><br><span class="line">main.go:8             0x2325                  e800000000              CALL 0x232a             [1:5]R_CALL:runtime.gcWriteBarrier&lt;1&gt;</span><br><span class="line">main.go:8             0x232a                  eb00                    JMP 0x232c</span><br></pre></td></tr></table></figure><p>从汇编代码中可以看出，赋值的核心在下面这几句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 将AX寄存器中的值赋给0(IP)</span><br><span class="line">  main.go:8             0x2315                  48890500000000          MOVQ AX, 0(IP)          [3:7]R_PCREL:&quot;&quot;.projectMap          </span><br><span class="line">// 跳转</span><br><span class="line">  main.go:8             0x231c                  eb0e                    JMP 0x232c                                                  </span><br><span class="line">// 将0(IP)中值的地址赋给DI</span><br><span class="line">  main.go:8             0x231e                  488d3d00000000          LEAQ 0(IP), DI          [3:7]R_PCREL:&quot;&quot;.projectMap</span><br></pre></td></tr></table></figure><p>从汇编可以看到赋值是只有一步，但获取值及赋值是分开的，也就是说对于写时复制这种场景来说，直接赋值是没有问题的</p><h2 id="基础知识补充">基础知识补充:</h2><h3 id="MOVQ">MOVQ</h3><ul><li><p>movb(8位)、movw(16位)、movl(32位)、movq(64位)</p></li><li><p>寄存器寻址：</p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movl %eax, %edx</span><br><span class="line">eax -&gt; edx</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/luoyhang003/article/details/46786591/" target="_blank" rel="noopener">https://blog.csdn.net/luoyhang003/article/details/46786591/</a></p><h3 id="TESTB">TESTB</h3><p>TEST指令的行为与AND指令一样，除了不改变目的寄存器的值。例如，testq %rax, %rax 用来检查 %rax 是负数、零、还是正数。</p><h3 id="LEAQ-vs-MOVQ">LEAQ vs MOVQ</h3><p><a href="https://stackoverflow.com/questions/1699748/what-is-the-difference-between-mov-and-lea" target="_blank" rel="noopener">https://stackoverflow.com/questions/1699748/what-is-the-difference-between-mov-and-lea</a></p><h3 id="PCDATA">PCDATA</h3><p><a href="https://www.cnblogs.com/binHome/p/13034103.html" target="_blank" rel="noopener">https://www.cnblogs.com/binHome/p/13034103.html</a></p><h3 id="CMPL">CMPL</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CMPL %eax，%ebx</span><br><span class="line">==&gt; </span><br><span class="line">[ebx]-[eax],就是把第二个数减去第一个数</span><br></pre></td></tr></table></figure><h3 id="JMP">JMP</h3><p>无条件转移指令<br>JMP 389无条件转至0x0185地址处(十进制389转换成十六进制0x0185)</p><h3 id="CALL">CALL</h3><p>调用函数<br>CALL runtime.printnl(SB)表示通过printnl函数的内存地址发起调用</p><h3 id="伪计数器">伪计数器</h3><p>FP: Frame pointer: arguments and locals.(指向当前栈帧)<br>PC: Program counter: jumps and branches.(指向指令地址)<br>SB: Static base pointer: global symbols.(指向全局符号表)<br>SP: Stack pointer: top of stack.(指向当前栈顶部)<br>注意: 栈是向下整长 golang的汇编是调用者维护参数返回值跟返回地址。所以FP的值小于参数跟返回值</p><h1>本机环境</h1><p><img data-src="/images/golang-copy-on-write-and-atomic/cpu.png" alt></p><blockquote><p>x86-64（ 又称x64，即英文词64-bit extended，64位拓展 的简写）是x86架构的64位拓展，向后兼容于16位及32位的x86架构。x64于1999年由AMD设计，AMD首次公开64位集以扩展给x86，称为“AMD64”。</p></blockquote><h1>编译命令详解</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PS D:\Code\Golang\github\jiankunking\cow-test&gt; go tool compile -help</span><br><span class="line">usage: compile [options] file.go...</span><br><span class="line">  -% int</span><br><span class="line">        debug non-static initializers</span><br><span class="line">  -+    compiling runtime</span><br><span class="line">  -B    disable bounds checking</span><br><span class="line">  -C    disable printing of columns in error messages</span><br><span class="line">  -D path</span><br><span class="line">        set relative path for local imports</span><br><span class="line">  -E    debug symbol export</span><br><span class="line">  -G    accept generic code (default 3)</span><br><span class="line">  -I directory</span><br><span class="line">        add directory to import search path</span><br><span class="line">  -K    debug missing line numbers</span><br><span class="line">  -L    show full file names in error messages</span><br><span class="line">  -N    disable optimizations</span><br><span class="line">  -S    print assembly listing</span><br><span class="line">  -V    print version and exit</span><br><span class="line">  -W    debug parse tree after type checking</span><br><span class="line">  -asan</span><br><span class="line">        build code compatible with C/C++ address sanitizer</span><br><span class="line">  -asmhdr file</span><br><span class="line">        write assembly header to file</span><br><span class="line">  -bench file</span><br><span class="line">        append benchmark times to file</span><br><span class="line">  -blockprofile file</span><br><span class="line">        write block profile to file</span><br><span class="line">  -buildid id</span><br><span class="line">        record id as the build id in the export metadata</span><br><span class="line">  -c int</span><br><span class="line">        concurrency during compilation (1 means no concurrency) (default 1)</span><br><span class="line">  -clobberdead</span><br><span class="line">        clobber dead stack slots (for debugging)</span><br><span class="line">  -clobberdeadreg</span><br><span class="line">        clobber dead registers (for debugging)</span><br><span class="line">  -complete</span><br><span class="line">        compiling complete package (no C or assembly)</span><br><span class="line">  -cpuprofile file</span><br><span class="line">        write cpu profile to file</span><br><span class="line">  -d value</span><br><span class="line">        enable debugging settings; try -d help</span><br><span class="line">  -dwarf</span><br><span class="line">        generate DWARF symbols (default true)</span><br><span class="line">  -dwarfbasentries</span><br><span class="line">        use base address selection entries in DWARF (default true)</span><br><span class="line">  -dwarflocationlists</span><br><span class="line">        add location lists to DWARF in optimized mode (default true)</span><br><span class="line">  -dynlink</span><br><span class="line">        support references to Go symbols defined in other shared libraries</span><br><span class="line">  -e    no limit on number of errors reported</span><br><span class="line">  -embedcfg file</span><br><span class="line">        read go:embed configuration from file</span><br><span class="line">  -gendwarfinl int</span><br><span class="line">        generate DWARF inline info records (default 2)</span><br><span class="line">  -goversion string</span><br><span class="line">        required version of the runtime</span><br><span class="line">  -h    halt on error</span><br><span class="line">  -importcfg file</span><br><span class="line">        read import configuration from file</span><br><span class="line">  -importmap definition</span><br><span class="line">        add definition of the form source=actual to import map</span><br><span class="line">  -installsuffix suffix</span><br><span class="line">        set pkg directory suffix</span><br><span class="line">  -j    debug runtime-initialized variables</span><br><span class="line">  -json string</span><br><span class="line">        version,file for JSON compiler/optimizer detail output</span><br><span class="line">  -l    disable inlining</span><br><span class="line">  -lang string</span><br><span class="line">        Go language version source code expects</span><br><span class="line">  -linkobj file</span><br><span class="line">        write linker-specific object to file</span><br><span class="line">  -linkshared</span><br><span class="line">        generate code that will be linked against Go shared libraries</span><br><span class="line">  -live</span><br><span class="line">        debug liveness analysis</span><br><span class="line">  -m    print optimization decisions</span><br><span class="line">  -memprofile file</span><br><span class="line">        write memory profile to file</span><br><span class="line">  -memprofilerate rate</span><br><span class="line">        set runtime.MemProfileRate to rate</span><br><span class="line">  -msan</span><br><span class="line">        build code compatible with C/C++ memory sanitizer</span><br><span class="line">  -mutexprofile file</span><br><span class="line">        write mutex profile to file</span><br><span class="line">  -nolocalimports</span><br><span class="line">        reject local (relative) imports</span><br><span class="line">  -o file</span><br><span class="line">        write output to file</span><br><span class="line">  -p path</span><br><span class="line">        set expected package import path</span><br><span class="line">  -pack</span><br><span class="line">        write to file.a instead of file.o</span><br><span class="line">  -r    debug generated wrappers</span><br><span class="line">  -race</span><br><span class="line">        enable race detector</span><br><span class="line">  -shared</span><br><span class="line">        generate code that can be linked into a shared library</span><br><span class="line">  -smallframes</span><br><span class="line">        reduce the size limit for stack allocated objects</span><br><span class="line">  -spectre list</span><br><span class="line">        enable spectre mitigations in list (all, index, ret)</span><br><span class="line">  -std</span><br><span class="line">        compiling standard library</span><br><span class="line">  -symabis file</span><br><span class="line">        read symbol ABIs from file</span><br><span class="line">  -t    enable tracing for debugging the compiler</span><br><span class="line">  -traceprofile file</span><br><span class="line">        write an execution trace to file</span><br><span class="line">  -trimpath prefix</span><br><span class="line">        remove prefix from recorded source file paths</span><br><span class="line">  -v    increase debug verbosity</span><br><span class="line">  -w    debug type checking</span><br><span class="line">  -wb</span><br><span class="line">        enable write barrier (default true)</span><br></pre></td></tr></table></figure><h1>拓展阅读</h1><p><a href="https://stackoverflow.com/questions/70332316/whats-the-differenct-between-go-tool-compile-and-go-tool-objdump" target="_blank" rel="noopener">https://stackoverflow.com/questions/70332316/whats-the-differenct-between-go-tool-compile-and-go-tool-objdump</a></p><p><a href="https://xargin.com/plan9-assembly/" target="_blank" rel="noopener">https://xargin.com/plan9-assembly/</a></p><p><a href="https://github.com/cch123/golang-notes/blob/master/assembly.md" target="_blank" rel="noopener">https://github.com/cch123/golang-notes/blob/master/assembly.md</a></p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>atomic</tag>
        <tag>Copy-On-Write</tag>
        <tag>COW</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes集群中Pod间文件拷贝</title>
    <url>/kubernetes-copies-files-from-one-pod-to-another.html</url>
    <content><![CDATA[<p>如何在Pod间拷贝文件？</p><a id="more"></a><p>具体代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line"> copy file to pod</span><br><span class="line">*/</span><br><span class="line">package cp</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;archive/tar&quot;</span><br><span class="line">	&quot;context&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;io&quot;</span><br><span class="line">	&quot;io/ioutil&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;os&quot;</span><br><span class="line">	&quot;path&quot;</span><br><span class="line">	&quot;strings&quot;</span><br><span class="line"></span><br><span class="line">	corev1 &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class="line">	&quot;k8s.io/client-go/rest&quot;</span><br><span class="line">	&quot;k8s.io/client-go/tools/remotecommand&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type Pod struct &#123;</span><br><span class="line">	Name          string</span><br><span class="line">	Namespace     string</span><br><span class="line">	ContainerName string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (i *Pod) CopyToPod(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, srcPath string, destPath string) error &#123;</span><br><span class="line">	reader, writer := io.Pipe()</span><br><span class="line"></span><br><span class="line">	if destPath != &quot;/&quot; &amp;&amp; strings.HasSuffix(string(destPath[len(destPath)-1]), &quot;/&quot;) &#123;</span><br><span class="line">		destPath = destPath[:len(destPath)-1]</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if err := checkDestinationIsDir(ctx, client, config, i, destPath); err == nil &#123;</span><br><span class="line">		destPath = destPath + &quot;/&quot; + path.Base(srcPath)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	go func() &#123;</span><br><span class="line">		defer writer.Close()</span><br><span class="line">		err := makeTar(srcPath, destPath, writer)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			fmt.Println(err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	var cmdArr []string</span><br><span class="line"></span><br><span class="line">	cmdArr = []string&#123;&quot;tar&quot;, &quot;-xf&quot;, &quot;-&quot;&#125;</span><br><span class="line">	destDir := path.Dir(destPath)</span><br><span class="line">	if len(destDir) &gt; 0 &#123;</span><br><span class="line">		cmdArr = append(cmdArr, &quot;-C&quot;, destDir)</span><br><span class="line">	&#125;</span><br><span class="line">	//remote shell.</span><br><span class="line">	req := client.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Namespace(i.Namespace).</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(i.Name).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(&amp;corev1.PodExecOptions&#123;</span><br><span class="line">			Container: i.ContainerName,</span><br><span class="line">			Command:   cmdArr,</span><br><span class="line">			Stdin:     true,</span><br><span class="line">			Stdout:    true,</span><br><span class="line">			Stderr:    true,</span><br><span class="line">			TTY:       false,</span><br><span class="line">		&#125;, scheme.ParameterCodec)</span><br><span class="line"></span><br><span class="line">	exec, err := remotecommand.NewSPDYExecutor(config, &quot;POST&quot;, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = exec.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:  reader,</span><br><span class="line">		Stdout: os.Stdout,</span><br><span class="line">		Stderr: os.Stderr,</span><br><span class="line">		Tty:    false,</span><br><span class="line">	&#125;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func checkDestinationIsDir(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, i *Pod, destPath string) error &#123;</span><br><span class="line">	return i.Exec(ctx, client, config, []string&#123;&quot;test&quot;, &quot;-d&quot;, destPath&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func makeTar(srcPath, destPath string, writer io.Writer) error &#123;</span><br><span class="line">	// TODO: use compression here?</span><br><span class="line">	tarWriter := tar.NewWriter(writer)</span><br><span class="line">	defer tarWriter.Close()</span><br><span class="line"></span><br><span class="line">	srcPath = path.Clean(srcPath)</span><br><span class="line">	destPath = path.Clean(destPath)</span><br><span class="line">	return recursiveTar(path.Dir(srcPath), path.Base(srcPath), path.Dir(destPath), path.Base(destPath), tarWriter)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func recursiveTar(srcBase, srcFile, destBase, destFile string, tarWriter *tar.Writer) error &#123;</span><br><span class="line"></span><br><span class="line">	// defer func() &#123;</span><br><span class="line">	// 	fmt.Println(&quot;d&quot;)</span><br><span class="line">	// 	if err := recover(); err != nil &#123;</span><br><span class="line">	// 		fmt.Println(err) // 这里的err其实就是panic传入的内容</span><br><span class="line">	// 	&#125;</span><br><span class="line">	// 	fmt.Println(&quot;e&quot;)</span><br><span class="line">	// &#125;()</span><br><span class="line"></span><br><span class="line">	filepath := path.Join(srcBase, srcFile)</span><br><span class="line">	stat, err := os.Lstat(filepath)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	if stat.IsDir() &#123;</span><br><span class="line">		files, err := ioutil.ReadDir(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		if len(files) == 0 &#123;</span><br><span class="line">			//case empty directory</span><br><span class="line">			hdr, _ := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">			hdr.Name = destFile</span><br><span class="line">			if err := tarWriter.WriteHeader(hdr); err != nil &#123;</span><br><span class="line">				return err</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		for _, f := range files &#123;</span><br><span class="line">			if err := recursiveTar(srcBase, path.Join(srcFile, f.Name()), destBase, path.Join(destFile, f.Name()), tarWriter); err != nil &#123;</span><br><span class="line">				return err</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return nil</span><br><span class="line">	&#125; else if stat.Mode()&amp;os.ModeSymlink != 0 &#123;</span><br><span class="line">		//case soft link</span><br><span class="line">		hdr, _ := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">		target, err := os.Readlink(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		hdr.Linkname = target</span><br><span class="line">		hdr.Name = destFile</span><br><span class="line">		if err := tarWriter.WriteHeader(hdr); err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		//case regular file or other file type like pipe</span><br><span class="line">		hdr, err := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		hdr.Name = destFile</span><br><span class="line">		err = tarWriter.WriteHeader(hdr)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			log.Println(err)</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		f, err := os.Open(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		defer f.Close()</span><br><span class="line"></span><br><span class="line">		if _, err := io.Copy(tarWriter, f); err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		return f.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (i *Pod) Exec(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, cmd []string) error &#123;</span><br><span class="line"></span><br><span class="line">	req := client.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Namespace(i.Namespace).</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(i.Name).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(&amp;corev1.PodExecOptions&#123;</span><br><span class="line">			Container: i.ContainerName,</span><br><span class="line">			Command:   cmd,</span><br><span class="line">			Stdin:     true,</span><br><span class="line">			Stdout:    true,</span><br><span class="line">			Stderr:    true,</span><br><span class="line">			TTY:       false,</span><br><span class="line">		&#125;, scheme.ParameterCodec)</span><br><span class="line"></span><br><span class="line">	exec, err := remotecommand.NewSPDYExecutor(config, &quot;POST&quot;, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = exec.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:  strings.NewReader(&quot;&quot;),</span><br><span class="line">		Stdout: os.Stdout,</span><br><span class="line">		Stderr: os.Stderr,</span><br><span class="line">		Tty:    false,</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>client-go</tag>
        <tag>Copy</tag>
        <tag>File</tag>
        <tag>Pod</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 可重复读隔离级别与幻读(能很大程度上避免幻读,但不能完全避免)</title>
    <url>/mysql-isolation-level-repeatable-read-and-phantom-read.html</url>
    <content><![CDATA[<blockquote><p>在MySQL可重复读的隔离级别下，能很大程度上避免幻读，但不能完全避免。</p></blockquote><a id="more"></a><h1>场景复现</h1><p>环境信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MySQL版本：5.7.23-log</span><br><span class="line">隔离级别：REPEATABLE-READ</span><br></pre></td></tr></table></figure><p>测试数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET NAMES utf8mb4;</span><br><span class="line">SET FOREIGN_KEY_CHECKS = 0;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for app_record_lock_test</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `app_record_lock_test`;</span><br><span class="line">CREATE TABLE `app_record_lock_test`  (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `hash` bigint(20) NOT NULL DEFAULT 0,</span><br><span class="line">  `cluster` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,</span><br><span class="line">  `namespace` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">  `service` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">  `pod` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">  `created_at` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),</span><br><span class="line">  `updated_at` datetime(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  UNIQUE INDEX `cluster_hash`(`cluster`, `hash`) USING BTREE</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 120236026 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Records of app_record_lock_test</span><br><span class="line">-- ----------------------------</span><br><span class="line">INSERT INTO `app_record_lock_test` VALUES (120236012, 1, &apos;cluster&apos;, &apos;namespace&apos;, &apos;service&apos;, &apos;pod&apos;, &apos;2022-02-18 14:14:59&apos;, &apos;2022-02-09 10:00:00&apos;);</span><br><span class="line">INSERT INTO `app_record_lock_test` VALUES (120236013, 2, &apos;cluster&apos;, &apos;namespace&apos;, &apos;service&apos;, &apos;pod&apos;, &apos;2022-02-18 14:14:59&apos;, &apos;2022-02-09 10:00:00&apos;);</span><br><span class="line">INSERT INTO `app_record_lock_test` VALUES (120236014, 3, &apos;cluster&apos;, &apos;namespace&apos;, &apos;service&apos;, &apos;pod&apos;, &apos;2022-02-18 14:14:59&apos;, &apos;2022-02-09 10:00:00&apos;);</span><br><span class="line"></span><br><span class="line">SET FOREIGN_KEY_CHECKS = 1;</span><br></pre></td></tr></table></figure><p>复现流程：</p><table><thead><tr><th style="text-align:center">时间</th><th style="text-align:center">会话A(T1)</th><th style="text-align:center">会话B(T2)</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">START TRANSACTION;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">2</td><td style="text-align:center"></td><td style="text-align:center">START TRANSACTION;</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">SELECT * FROM app_record_lock_test WHERE cluster = ‘cluster1’;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center"></td><td style="text-align:center">INSERT INTO app_record_lock_test (HASH, cluster, namespace, service, pod, updated_at)VALUES(1, ‘cluster1’, ‘namespace’, ‘service’, ‘pod’, ‘2022-02-09 10:00:00’) ;</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center"></td><td style="text-align:center">COMMIT;</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">update app_record_lock_test set namespace= ‘namespace2’ where cluster = ‘cluster1’;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">SELECT * FROM app_record_lock_test WHERE cluster = ‘cluster1’;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">COMMIT;</td><td style="text-align:center"></td></tr></tbody></table><p>在第3步执行查询cluster = 'cluster1’时，查询到的结果是空。<br>但会话B执行完第4 5之后，再在会话A中执行第6步，就不会等待或者报错了，也就是可以正常执行，在第7步的查询中，也能查到该数据了。</p><blockquote><p>注意：会话A能正常更新、查询的前提是：会话B事务已提交。<br>注意：会话A如果不执行更新（也就是第6步），那么在查询的时候，还是查询不到记录的。</p></blockquote><h1>原因分析</h1><p>对于使用InnoDB存储引擎的表来说，<font color="red"> 它的聚簇索引记录中都包含下面这两个必要的隐藏列（row_id并不是必要的：在创建的表中有主键时，或者有不允许为NULL的UNIQUE键时，都不会包含row_id列）</font>.<br>• <code>trx_id</code>：一个事务每次对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列.<br>• <code>roll_pointer</code>：每次对某条聚族索引记录进行改动时，都会把旧的版本写入到undo日志中.这个隐藏列就相当于一个指针，可以通过它找到该记录修改前的信息.</p><p>在REPEATABLE READ隔离级别下，T1第一次执行普通的SELECT语句时生成了一个ReadView,之后T2向app_record_lock_test表中新插入一条记录并提交.ReadView并不能阻止T1执行UPDATE或者DELETE语句来改动这个新插入的记录（由于T2已经提交，因此改动该记录并不会造成阻塞），但是这样一来，这条新记录的trx_id隐藏列的值就变成了T1的事务id,之后T1再使用普通的SELECT语句去查询这条记录时就可以看到这条记录了，也就可以把这条记录返回给客户端.因为这个特殊现象的存在，我们也可以认为InnoDB中的MVCC并不能完全禁止幻读。</p><blockquote><p>也就是说，T1将新插入数据的事务号修改的小于等于ReadView对应的事务版本号了，相当于扩充了ReadView的范围，从而导致在下一次查询的时候能查询出该记录。</p></blockquote>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>编程高手必学的内存知识 笔记</title>
    <url>/memory-knowledge-that-programming-masters-must-learn.html</url>
    <content><![CDATA[<p>编程高手必学的内存知识 笔记<br>作者： 海纳</p><a id="more"></a><h1>为什么可用内存会远超物理内存？</h1><p>虚拟内存的出现，是为了解决直接操作物理内存的系统无法支持多进程的问题。这里的难点主要是进程的地址空间非常小，而且多个进程的地址很容易发生冲突。所以在局部性原理的基础上，CPU设计者提出虚拟内存的方案将多个进程的地址空间隔离开，并且提供了巨大的内存空间。</p><p>我们可以总结一下，虚拟内存主要有下面两个特点：<br>第一，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间地址冲突的问题。<br>第二，PTE中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</p><p>另外，虚拟内存可以充分使用CPU提供的机制来完成很多重要的任务。例如，fork借用写保护来实现写时复制，JVM中借用改变某一个页的读权限来实现safepoint查询等等。</p><p>由于CPU对内存提供了更多保护的能力，所以X86架构的CPU把这种工作模式称为保护模式，与可以直接访问物理内存的实模式形成了对比。</p><p><a href="/attachments/编程高手必学的内存知识/01为什么可用内存会远超物理内存？.pdf" target="_blank">为什么可用内存会远超物理内存？</a></p><h1>X86体系结构中的实模式和保护模式</h1><p>8086是16位的CPU，我们称8086的工作模式为实模式，它的特点是直接操作物理内存，内存管理容易出错，要十分小心，代码编写和调试都很困难。</p><p>之后出现的i386，则采用了和实模式不同的保护模式。相比实模式，i386中的保护模式，采用了页式管理，但它没有彻底放弃8086的段式管理，而是将段寄存器中的值由段基址变成了段选择子。段选择子本质是GDT表的下标值，段基址都转移到GDT中去了。</p><p>段式管理负责将逻辑地址转换为线性地址，或者称为虚拟地址，页式管理负责将线性地址映射到物理地址。i386的保护模式采用了段页式混合管理的模式，兼具了段式管理和页式管理的优点。</p><p>除了段页式内存管理这个不同之外，保护模式和实模式的区别还体现在中断描述符表（IDT）上。IDT是保护模式的一个重要组成部分，它保存着 i386 中断服务程序的入口地址。</p><p>8086和i386对X86架构的CPU影响巨大。直到今天，X86架构的CPU在上电以后，为了与8086保持兼容，还是运行在16位实模式下，也就是说所有访存指令访问的都是物理内存地址。在启动操作系统后，才会切换到保护模式下进行工作。</p><p><a href="/attachments/编程高手必学的内存知识/02X86体系结构中的实模式和保护模式.pdf.pdf" target="_blank">X86体系结构中的实模式和保护模式</a></p><h1>内存布局：应用程序是如何安排数据的？</h1><h2 id="IA-32机器上的Linux进程内存布局">IA-32机器上的Linux进程内存布局</h2><p>在32位机器上，每个进程都具有4GB的寻址能力。Linux系统会默认将高地址的1GB空间分配给内核，剩余的低3GB是用户可以使用的用户空间。下图是32位机器上Linux进程的一个典型的内存布局。在实践中，我们可以通过cat /proc/pid/maps来查看某个进程的实际虚拟内存布局。</p><p><img data-src="/images/memory-knowledge-that-programming-masters-must-learn/1.png" alt></p><blockquote><p>BSS 段这个缩写名字是Block Started by Symbol，但很多人可能更喜欢把它记作Better Save Space的缩写。</p></blockquote><blockquote><p>我们上述的布局分析都是基于Linux系统下关闭了进程地址随机化的选项。如果打开进程地址随机化的模式，其中的堆空间、栈空间和共享库映射的地址，在每次程序运行下都会不一样。这是因为内核在加载的过程中，会对这些区域的起始地址增加一些随机的偏移值，这能增加缓冲区溢出的难度。</p></blockquote><h2 id="Intel-64机器上的Linux进程内存布局">Intel 64机器上的Linux进程内存布局</h2><p><img data-src="/images/memory-knowledge-that-programming-masters-must-learn/2.png" alt></p><p>从图中你可以看到，在用户空间和内核空间之间有一个巨大的内存空洞。这块空间之所以用更深颜色来区分，是因为这块空间的不可访问是由CPU来保证的（这里的地址都不满足Intel 64的Canonical form）。</p><p><a href="/attachments/编程高手必学的内存知识/03内存布局：应用程序是如何安排数据的？.pdf" target="_blank">内存布局：应用程序是如何安排数据的？</a></p><h1>深入理解栈：从CPU和函数的视角看栈的管理</h1><p><a href="/attachments/编程高手必学的内存知识/04深入理解栈：从CPU和函数的视角看栈的管理.pdf" target="_blank">深入理解栈：从CPU和函数的视角看栈的管理</a></p><h1>栈的魔法：从栈切换的角度理解进程和协程</h1><p>栈切换的核心就是栈指针rsp寄存器的切换，只要我们想办法把rsp切换了就相当于换了执行单元的上下文环境。</p><p><a href="/attachments/编程高手必学的内存知识/05栈的魔法：从栈切换的角度理解进程和协程.pdf" target="_blank">栈的魔法：从栈切换的角度理解进程和协程</a></p><h1>静态链接：变量与内存地址是如何映射的？</h1><p>在GNU/linux 下，GNU的binutils提供了一系列编程语言的工具程序，用来查看不同格式下的目标文件。今天我要给你重点介绍两个工具：readelf和objdump，这两个工具可以用来解析和读取上一节编译阶段生成的目标文件信息。</p><p>一般情况下，我在对二进制文件进行反汇编时会使用objdump工具，因为readelf工具没有提供反汇编的能力，它更多是用来解析二进制文件信息。</p><p>从源文件生成二进制可执行文件，这一过程主要包含了编译和链接两个步骤。其中，编译的作用是生成性能优越的机器码。对于编译单元内部的静态函数，可以在编译时通过相对地址的办法，生成call指令，因为无论将来调用者和被调用者被安置到什么地方，它们之间的相对距离不会发生变化。</p><p>而其他类型的变量和函数在编译时，编译器并不知道它们的最终地址，所以只能使用占位符（比如 0）来临时代替目标地址。</p><p>而链接器的任务是为所有变量和函数分配地址，并把被分配到的地址回写到调用者处。链接的过程主要分为两步，第一步是多文件合并，同时为符号分配地址，第二步则是将符号的地址回写到引用它的地方。其中，地址回写有一个专门的名字叫做重定位。重定位的过程依赖目标文件中的重定位表。</p><p><a href="/attachments/编程高手必学的内存知识/06静态链接：变量与内存地址是如何映射的？.pdf" target="_blank">静态链接：变量与内存地址是如何映射的？</a></p><h1>动态链接（上）：地址无关代码是如何生成的？</h1><p><a href="/attachments/编程高手必学的内存知识/07动态链接（上）：地址无关代码是如何生成的？.pdf" target="_blank">动态链接（上）：地址无关代码是如何生成的？</a></p><h1>动态链接（下）：延迟绑定与动态链接器是什么？</h1><p><a href="/attachments/编程高手必学的内存知识/08动态链接（下）：延迟绑定与动态链接器是什么？.pdf" target="_blank">动态链接（下）：延迟绑定与动态链接器是什么？</a></p><h1>深入理解堆：malloc和内存池是怎么回事？</h1><p><a href="/attachments/编程高手必学的内存知识/09深入理解堆：malloc和内存池是怎么回事？.pdf" target="_blank">深入理解堆：malloc和内存池是怎么回事？？</a></p><h1>页中断：fork、mmap背后的保护神</h1><p><a href="/attachments/编程高手必学的内存知识/10页中断：fork、mmap背后的保护神.pdf" target="_blank">页中断：fork、mmap背后的保护神</a></p><h1>即时编译：高性能JVM的核心秘密</h1><p><a href="/attachments/编程高手必学的内存知识/11即时编译：高性能JVM的核心秘密.pdf" target="_blank">即时编译：高性能JVM的核心秘密</a></p><h1>内存虚拟化：云原生时代的奠基者</h1><p><a href="/attachments/编程高手必学的内存知识/12内存虚拟化：云原生时代的奠基者.pdf" target="_blank">内存虚拟化：云原生时代的奠基者</a></p><h1>存储电路：计算机存储芯片的电路结构是怎样的？</h1><p><a href="/attachments/编程高手必学的内存知识/13存储电路：计算机存储芯片的电路结构是怎样的？.pdf" target="_blank">存储电路：计算机存储芯片的电路结构是怎样的？</a></p><h1>CPUCache：访存速度是如何大幅提升的？</h1><p><a href="/attachments/编程高手必学的内存知识/14CPUCache：访存速度是如何大幅提升的？.pdf" target="_blank">CPUCache：访存速度是如何大幅提升的？</a></p><h1>MESI协议：多核CPU是如何同步高速缓存的？</h1><p><a href="/attachments/编程高手必学的内存知识/15MESI协议：多核CPU是如何同步高速缓存的？.pdf" target="_blank">MESI协议：多核CPU是如何同步高速缓存的？</a></p><h1>内存模型：有了MESI为什么还需要内存屏障？</h1><p><a href="/attachments/编程高手必学的内存知识/16内存模型：有了MESI为什么还需要内存屏障？.pdf" target="_blank">内存模型：有了MESI为什么还需要内存屏障？</a></p><h1>NUMA：非均匀访存带来了哪些提升与挑战？</h1><p><a href="/attachments/编程高手必学的内存知识/17NUMA：非均匀访存带来了哪些提升与挑战？.pdf" target="_blank">NUMA：非均匀访存带来了哪些提升与挑战？</a></p><h1>Java内存模型：Java中的volatile有什么用？</h1><p><a href="/attachments/编程高手必学的内存知识/18Java内存模型：Java中的volatile有什么用？.pdf" target="_blank">Java内存模型：Java中的volatile有什么用？</a></p><h1>Scavenge：基于copy的垃圾回收算法</h1><p><a href="/attachments/编程高手必学的内存知识/20Scavenge：基于copy的垃圾回收算法.pdf" target="_blank">Scavenge：基于copy的垃圾回收算法</a></p><h1>分代算法：基于生命周期的内存管理</h1><p><a href="/attachments/编程高手必学的内存知识/21分代算法：基于生命周期的内存管理.pdf" target="_blank">分代算法：基于生命周期的内存管理</a></p><h1>G1GC：分区回收算法说的是什么？</h1><p><a href="/attachments/编程高手必学的内存知识/22G1GC：分区回收算法说的是什么？.pdf" target="_blank">G1GC：分区回收算法说的是什么？</a></p><h1>PauselessGC：挑战无暂停的垃圾回收</h1><p><a href="/attachments/编程高手必学的内存知识/23PauselessGC：挑战无暂停的垃圾回收.pdf" target="_blank">PauselessGC：挑战无暂停的垃圾回收</a></p><h1>GC实例：Python和Go的内存管理机制是怎样的？</h1><p><a href="/attachments/编程高手必学的内存知识/24GC实例：Python和Go的内存管理机制是怎样的？.pdf" target="_blank">GC实例：Python和Go的内存管理机制是怎样的？</a></p>]]></content>
      <categories>
        <category>Memory</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>系统性能调优必知必会 笔记</title>
    <url>/system-performance-tuning-must-know-and-must-know.html</url>
    <content><![CDATA[<p>系统性能调优必知必会 笔记<br>作者： 陶辉</p><a id="more"></a><h1>CPU缓存</h1><h2 id="CPU-的多级缓存">CPU 的多级缓存</h2><p>比如，Linux系统上，离CPU最近的一级缓存是32KB，二级缓存是256KB，最大的三级缓存则是20MB。</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/2.png" alt></p><p>你可能注意到，三级缓存要比一、二级缓存大许多倍，这是因为当下的CPU都是多核心的，每个核心都有自己的一、二级缓存，但三级缓存却是一颗CPU上所有核心共享的。</p><p>程序执行时，会先将内存中的数据载入到共享的三级缓存中，再进入每颗核心独有的二级缓存，最后进入最快的一级缓存，之后才会被CPU使用，就像下面这张图。</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/1.png" alt></p><p>缓存要比内存快很多。CPU访问一次内存通常需要100个时钟周期以上，而访问一级缓存只需要4~5个时钟周期，二级缓存大约12个时钟周期，三级缓存大约30个时钟周期（对于2GHZ主频的CPU来说，一个时钟周期是0.5纳秒。</p><p>如果CPU所要操作的数据在缓存中，则直接读取，这称为缓存命中。命中缓存会带来很大的性能提升，因此，<strong>我们的代码优化目标是提升 CPU 缓存的命中率</strong>。</p><p>当然，缓存命中率是很笼统的，具体优化时还得一分为二。比如，你在查看CPU缓存时会发现有2个一级缓存（比如Linux上就是上图中的index0 和 index1），这是因为，CPU会区别对待指令与数据。比如，“1+1=2”这个运算，“+”就是指令，会放在一级指令缓存中，而“1”这个输入数字，则放在一级数据缓存中。虽然在冯诺依曼计算机体系结构中，代码指令与数据是放在一起的，但执行时却是分开进入指令缓存与数据缓存的，因此我们要分开来看二者的缓存命中率。</p><h2 id="提升数据缓存的命中率">提升数据缓存的命中率</h2><p>缓存一次性会载入多少元素呢？CPU Cache Line相关，它定义了缓存一次载入数据的大小，Linux上你可以通过coherency_line_size配置查看它，通常是64字节。</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/3.png" alt></p><p>遇到这种遍历访问数组的情况时，按照内存布局顺序访问将会带来很大的性能提升。</p><p>关于CPU Cache Line的应用其实非常广泛，如果你用 Nginx，会发现它是用哈希表来存放域名、HTTP头部等数据的，这样访问速度非常快，而哈希表里桶的大小如server_names_hash_bucket_size，它默认就等于 CPU Cache Line 的值。由于所存放的字符串长度不能大于桶的大小，所以当需要存放更长的字符串时，就需要修改桶大小，但<a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#server_names_hash_bucket_size" target="_blank" rel="noopener">Nginx 官网上明确建议它应该是CPU Cache Line的整数倍</a>。</p><p>为什么要做这样的要求呢？就是因为缓存是按照64字节的整数倍来访问内存的，哈希表的桶按此大小排列布局，就可以尽量减少访问内存的次数。比如，若桶大小为64字节，那么根据地址获取字符串时只需要访问一次内存，而桶大小为50字节，会导致最坏2次访问内存，而70字节最坏会有3次访问内存。</p><h2 id="提升指令缓存的命中率">提升指令缓存的命中率</h2><p>当代码中出现if、switch等语句时，意味着此时至少可以选择跳转到两段不同的指令去执行。如果分支预测器可以预测接下来要在哪段代码执行（比如 if 还是 else 中的指令），就可以提前把这些指令放在缓存中，CPU执行时就会很快。当数组中的元素完全随机时，分支预测器无法有效工作，而当array数组有序时，分支预测器会动态地根据历史命中数据对未来进行预测，命中率就会非常高。</p><h2 id="提升多核-CPU-下的缓存命中率">提升多核 CPU 下的缓存命中率</h2><p>操作系统提供了将进程或者线程绑定到某一颗CPU上运行的能力。如Linux上提供了sched_setaffinity方法实现这一功能。</p><p>Perf工具也提供了cpu-migrations事件，它可以显示进程从不同的CPU核心上迁移的次数。</p><p>如果你在用Linux操作系统，可以通过一个名叫Perf的工具直观地验证缓存命中的情况（可以用yum install perf或者apt-get install perf安装这个工具）。<br>执行perf stat可以统计出进程运行时的系统信息（通过-e选项指定要统计的事件，如果要查看三级缓存总的命中率，可以指定缓存未命中 cache-misses 事件，以及读取缓存次数cache-references事件，两者相除就是缓存的未命中率，用1相减就是命中率。类似的，通过L1-dcache-load-misses和L1-dcache-loads可以得到L1缓存的命中率）。</p><h1>内存池：如何提升内存分配的效率？</h1><p>在Linux系统中，用Xmx设置JVM的最大堆内存为8GB，但在近百个并发线程下，观察到Java进程占用了14GB的内存。为什么会这样呢？</p><p>这是因为，绝大部分高级语言都是用C语言编写的，包括Java，申请内存必须经过C库，而C库通过预分配更大的空间作为内存池，来加快后续申请内存的速度。这样，预分配的6GB的C库内存池就与JVM中预分配的8G内存池叠加在一起，造成了Java进程的内存占用超出了预期。</p><h2 id="隐藏的内存池">隐藏的内存池</h2><p>实际上，在你的业务代码与系统内核间，往往有两层内存池容易被忽略，尤其是其中的C库内存池。</p><p>当代码申请内存时，首先会到达应用层内存池，如果应用层内存池有足够的可用内存，就会直接返回给业务代码，否则，它会向更底层的C库内存池申请内存。比如，如果你在Apache、Nginx 等服务之上做模块开发，这些服务中就有独立的内存池。当然，Java中也有内存池，当通过启动参数Xmx指定JVM的堆内存为8GB时，就设定了JVM堆内存池的大小。</p><p>你可能听说过Google的TCMalloc和FaceBook的JEMalloc，它们也是C库内存池。当C库内存池无法满足内存申请时，才会向操作系统内核申请分配内存。如下图所示：</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/4.png" alt></p><p>回到文章开头的问题，Java已经有了应用层内存池，为什么还会受到C库内存池的影响呢？这是因为，除了JVM负责管理的堆内存外，Java还拥有一些堆外内存，由于它不使用JVM的垃圾回收机制，所以更稳定、持久，处理IO的速度也更快。这些堆外内存就会由C库内存池负责分配，这是Java受到C库内存池影响的原因。</p><h1>索引：如何用哈希表管理亿级对象?</h1><h2 id="内存结构与序列化方案">内存结构与序列化方案</h2><p>事实上对于动态（元素是变化的）哈希表，我们无法避免哈希冲突。有两种方法解决哈希冲突：</p><ol><li>链接法，落到数组同一个位置中的多个数据，通过链表串在一起。使用哈希函数查找到这个位置后，再使用链表遍历的方式查找数据。Java标准库中的哈希表就使用链接法解决冲突。</li><li>开放寻址法，插入时若发现对应的位置已经占用，或者查询时发现该位置上的数据与查询关键字不同，开放寻址法会按既定规则变换哈希函数（例如哈希函数设为 H(key,i)，顺序地把参数i加1），计算出下一个数组下标，继续在哈希表中探查正确的位置。</li></ol><p>我们该选择哪种方法呢？</p><p>链接法虽然实现简单，还允许存放元素个数大于数组的大小（也叫装载因子大于1），但链接法序列化数据的代价很大，因为使用了指针后，内存是不连续的。</p><p>开放寻址法确保所有对象都在数组里，就可以把数组用到的这段连续内存原地映射到文件中（参考Linux中的mmap，Java等语言都有类似的封装），再通过备份文件的方式备份哈希表。虽然操作系统会自动同步内存中变更的数据至文件，但备份前还是需要主动刷新内存<br>（参考Linux中的msync，它可以按地址及长度来分段刷新，以减少msync的耗时），以确定备份数据的精确时间点。而新的进程启动时，可以通过映射磁盘中的文件到内存，快速重建哈希表提供服务。</p><p>使用哈希表，你要注意几个关键问题。</p><ol><li>生产环境一定要考虑容灾，而把哈希表原地序列化为文件是一个解决方案，它能保证新进程快速恢复哈希表。解决哈希冲突有链接法和开放寻址法，而后者更擅长序列化数据，因此成为我们的首选。</li><li>亿级数据下，我们必须注重内存的节约使用。数亿条数据会放大节约下的点滴内存，再把它们用于提升哈希数组的大小，就可以通过降低装载因子来减少哈希冲突，提升速度。</li><li>优化哈希函数也是降低哈希冲突的重要手段，我们需要研究关键字的特征与分布，设计出快速、使关键字均匀分布的哈希函数。</li></ol><h1>零拷贝：如何高效地传输文件？</h1><p><a href="/attachments/系统性能调优必知必会/04零拷贝：如何高效地传输文件.pdf" target="_blank">零拷贝：如何高效地传输文件？</a></p><h1>协程：如何快速地实现高并发服务？</h1><p>事实上，无论基于多进程还是多线程，都难以实现高并发，这由两个原因所致。</p><p>首先，单个线程消耗的内存过多，比如，64位的Linux为每个线程的栈分配了8MB的内存，还预分配了64MB的内存作为堆内存池。所以，我们没有足够的内存去开启几万个线程实现并发。</p><p>其次，切换请求是内核通过切换线程实现的，什么时候会切换线程呢？不只时间片用尽，当调用阻塞方法时，内核为了让CPU充分工作，也会切换到其他线程执行。一次上下文切换的成本在几十纳秒到几微秒间，当线程繁忙且数量众多时，这些切换会消耗绝大部分的CPU运算能力。</p><p>实际上，用户态的代码切换协程，与内核切换线程的原理是一样的。内核通过管理CPU的寄存器来切换线程，我们以最重要的栈寄存器和指令寄存器为例，看看协程切换时如何切换程序指令与内存。</p><p>每个线程有独立的栈，而栈既保留了变量的值，也保留了函数的调用关系、参数和返回值，CPU中的栈寄存器SP指向了当前线程的栈，而指令寄存器IP保存着下一条要执行的指令地址。因此，从线程1切换到线程2时，首先要把SP、IP 寄存器的值为线程1保存下来，再从内存中找出线程2上一次切换前保存好的寄存器值，写入CPU的寄存器，这样就完成了线程切换。（其他寄存器也需要管理、替换，原理与此相同，不再赘述。）</p><p>协程的切换与此相同，只是把内核的工作转移到协程框架实现而已，下图是协程切换前的状态：</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/5.png" alt></p><p>从协程1切换到协程2后的状态如下图所示：<br><img data-src="/images/system-performance-tuning-must-know-and-must-know/6.png" alt></p><p>创建协程时，会从进程的堆中分配一段内存作为协程的栈。线程的栈有8MB，而协程栈的大小通常只有几十KB。而且，C库内存池也不会为协程预分配内存，它感知不到协程的存在。这样，更低的内存占用空间为高并发提供了保证，毕竟十万并发请求，就意味着10万个协程。当然，栈缩小后，就尽量不要使用递归函数，也不能在栈中申请过多的内存，这是实现高并发必须付出的代价。</p><p>由此可见，协程就是用户态的线程。然而，为了保证所有切换都在用户态进行，协程必须重新封装所有的阻塞系统调用，否则，一旦协程触发了线程切换，会导致这个线程进入休眠状态，进而其上的所有协程都得不到执行。比如，普通的sleep函数会让当前线程休眠，由内核来唤醒线程，而协程化改造后，sleep只会让当前协程休眠，由协程框架在指定时间后唤醒协程。再比如，线程间的互斥锁是使用信号量实现的，而信号量也会导致线程休眠，协程化改造互斥锁后，同样由框架来协调、同步各协程的执行。</p><p>所以，协程的高性能，建立在切换必须由用户态代码完成之上，这要求协程生态是完整的，要尽量覆盖常见的组件。</p><h1>锁：如何根据业务场景选择合适的锁？</h1><h2 id="互斥锁与自旋锁：休眠还是“忙等待”？">互斥锁与自旋锁：休眠还是“忙等待”？</h2><p>当你无法判断锁住的代码会执行多久时，应该首选互斥锁，互斥锁是一种独占锁。</p><p>如果你能确定被锁住的代码执行时间很短，就应该用自旋锁取代互斥锁。自旋锁比互斥锁快得多，因为它通过CPU提供的CAS函数（全称Compare And Swap），在用户态代码中完成加锁与解锁操作。</p><p>我们知道，加锁流程包括2个步骤：第1步查看锁的状态，如果锁是空闲的，第2步将锁设置为当前线程持有。</p><p>在没有CAS操作前，多个线程同时执行这2个步骤是会出错的。比如线程A执行第1步发现锁是空闲的，但它在执行第2步前，线程B也执行了第1步，B也发现锁是空闲的，于是线程A、B会同时认为它们获得了锁。</p><p>CAS函数把这2个步骤合并为一条硬件级指令。这样，第1步比较锁状态和第2步锁变量赋值，将变为不可分割的原子指令。于是，设锁为变量lock，整数0表示锁是空闲状态，整数pid表示线程ID，那么CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid,0)则表示解锁操作。</p><p>多线程竞争锁的时候，加锁失败的线程会“忙等待”，直到它拿到锁。什么叫“忙等待”呢？它并不意味着一直执行CAS函数，生产级的自旋锁在“忙等待”时，会与CPU紧密配合，它通过CPU提供的<a href="https://www.felixcloutier.com/x86/pause" target="_blank" rel="noopener">PAUSE</a>指令，减少循环等待时的耗电量；对于单核CPU，忙等待并没有意义，此时它会主动把线程休眠。</p><p>如果你对此感兴趣，可以阅读下面这段生产级的自旋锁，看看它是怎么执行“忙等待”的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while (true) &#123;</span><br><span class="line">	//因为判断lock变量的值比CAS操作更快，所以先判断lock再调用CAS效率更高</span><br><span class="line">	if (lock == 0 &amp;&amp; CAS(lock, 0, pid) == 1) return;</span><br><span class="line">	45 if (CPU_count &gt; 1 ) &#123;</span><br><span class="line">		//如果是多核CPU，“忙等待”才有意义</span><br><span class="line">		for (n = 1; n &lt; 2048; n &lt;&lt;= 1) &#123;</span><br><span class="line">			//pause的时间，应当越来越长</span><br><span class="line">			for (i = 0; i &lt; n; i++) pause();</span><br><span class="line">			//CPU专为自旋锁设计了pause指令</span><br><span class="line">			if (lock == 0 &amp;&amp; CAS(lock, 0, pid)) return;</span><br><span class="line">			//pause后再尝试获取锁</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	sched_yield();</span><br><span class="line">	//单核CPU，或者长时间不能获取到锁，应主动休眠，让出CPU 12</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果你能够明确区分出读和写两种场景，可以选择读写锁。</p><p>用队列把请求锁的线程排队，按照先来后到的顺序加锁即可，当然读线程仍然可以并发，只不过不能插队到写线程之前。Java中的ReentrantReadWriteLock读写锁，就支持这种排队的公平读写锁。</p><h1>如何提升TCP三次握手的性能？</h1><p>当客户端通过发送SYN发起握手时，可以通过tcp_syn_retries控制重发次数。当服务器的SYN半连接队列溢出后，SYN报文会丢失从而导致连接建立失败。我们可以通过netstat -s给出的统计结果判断队列长度是否合适，进而通过tcp_max_syn_backlog参数调整队列的长度。服务器回复SYN+ACK报文的重试次数由tcp_synack_retries参数控制，网络稳定时可以调小它。为了应对 SYN 泛洪攻击，应将 tcp_syncookies 参数设置为1，它仅在 SYN 队列满后开启 syncookie 功能，保证连接成功建立。</p><p>服务器收到客户端返回的ACK后，会把连接移入accept队列，等待进程调用accept函数取出连接。如果accept队列溢出，默认系统会丢弃 ACK，也可以通过tcp_abort_on_overflow参数用RST通知客户端连接建立失败。如果netstat统计信息显示，大量的ACK被丢弃后，可以通过listen函数的backlog参数和somaxconn系统参数提高队列上限。</p><p>TFO技术绕过三次握手，使得HTTP请求减少了1个RTT的时间。Linux下可以通过tcp_fastopen参数开启该功能。</p><p><a href="/attachments/系统性能调优必知必会/09如何提升TCP三次握手的性能？.pdf" target="_blank">如何提升TCP三次握手的性能？</a></p><h1>如何提升TCP四次挥手的性能？</h1><p>我们把先关闭连接的一方叫做主动方，后关闭连接的一方叫做被动方。</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/7.png" alt></p><p><a href="/attachments/系统性能调优必知必会/10如何提升TCP四次挥手的性能？.pdf" target="_blank">如何提升TCP四次挥手的性能？</a></p><h1>如何修改TCP缓冲区才能兼顾并发数量与传输速度？</h1><p>如果你在Linux系统中用free命令查看内存占用情况，会发现一栏叫做buff/cache，它是系统内存，似乎与应用进程无关。但每当进程新建一个TCP连接，buff/cache中的内存都会上升4K左右。而且，当连接传输数据时，就远不止增加4K内存了。</p><p>这是因为TCP连接是由内核维护的，内核为每个连接建立的内存缓冲区，既要为网络传输服务，也要充当进程与网络间的缓冲桥梁。如果连接的内存配置过小，就无法充分使用网络带宽，TCP传输速度就会很慢；如果连接的内存配置过大，那么服务器内存会很快用尽，新连接就无法建立成功。因此，只有深入理解Linux下TCP内存的用途，才能正确地配置内存大小。</p><p><img data-src="/images/system-performance-tuning-must-know-and-must-know/8.png" alt></p><p>实现高并发服务时，由于必须把大部分内存用在网络传输上，所以除了关注应用内存的使用，还必须关注TCP内核缓冲区的内存使用情况。</p><p>TCP使用ACK确认报文实现了可靠性，又依赖滑动窗口既提升了发送速度也兼顾了接收方的处理能力。然而，默认的滑动窗口最大只能到65KB，要想提升发送速度必须提升滑动窗口的上限，在Linux下是通过设置tcp_window_scaling为1做到的。</p><p>滑动窗口定义了飞行报文的最大字节数，当它超过带宽时延积时，就会发生丢包。而当它小于带宽时延积时，就无法让TCP的传输速度达到网络允许的最大值。因此，滑动窗口的设计，必须参考带宽时延积。</p><p>内核缓冲区决定了滑动窗口的上限，但我们不能通过socket的SO_SNFBUF等选项直接把缓冲区大小设置为带宽时延积，因为TCP不会一直维持在最高速上，过大的缓冲区会减少并发连接数。Linux带来的缓冲区自动调节功能非常有效，我们应当把缓冲区的上限设置为带宽时延积。其中，发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把tcp_moderate_rcvbuf设置为1来开启，其中调节的依据根据tcp_mem而定。</p><p><a href="/attachments/系统性能调优必知必会/11如何修改TCP缓冲区才能兼顾并发数量与传输速度？.pdf" target="_blank">如何修改TCP缓冲区才能兼顾并发数量与传输速度？</a></p><h1>如何调整TCP拥塞控制的性能？</h1><p>当TCP连接建立成功后，拥塞控制算法就会发生作用，首先进入慢启动阶段。决定连接此时网速的是初始拥塞窗口，Linux上可以通过route ip change命令修改它。通常，在带宽时延积较大的网络中，应当调高初始拥塞窗口。</p><p>丢包以及重复的ACK都是明确的拥塞信号，此时，发送方就会调低拥塞窗口减速，同时修正慢启动阈值。这样，将来再次到达这个速度时，就会自动进入拥塞避免阶段，用线性速度代替慢启动阶段的指数速度提升窗口大小。</p><p>当然，重复ACK意味着发送方可以提前重发丢失报文，快速重传算法定义了这一行为。同时，为了使得重发报文的过程中，发送速度不至于出现断崖式下降，TCP又定义了快速恢复算法，发送方在报文重新变得有序后，结束快速恢复进入拥塞避免阶段。但以丢包作为网络拥塞的信号往往为时已晚，于是以BBR算法为代表的测量型拥塞控制算法应运而生。当飞行中报文数量不变，而网络时延升高时，就说明网络中的缓冲队列出现了积压，这是进行拥塞控制的最好时机。Linux高版本支持BBR算法，你可以通过tcp_congestion_control配置更改拥塞控制算法。</p><p><a href="/attachments/系统性能调优必知必会/12如何调整TCP拥塞控制的性能？.pdf" target="_blank">如何调整TCP拥塞控制的性能？</a></p><h1>实战：单机如何实现管理百万主机的心跳服务？</h1><p><a href="/attachments/系统性能调优必知必会/13实战：单机如何实现管理百万主机的心跳服务？.pdf" target="_blank">实战：单机如何实现管理百万主机的心跳服务？</a></p><h1>优化TLS=SSL性能该从何下手？</h1><p><a href="/attachments/系统性能调优必知必会/14优化TLS=SSL性能该从何下手？.pdf" target="_blank">优化TLS=SSL性能该从何下手？</a></p><h1>如何提升HTTP-1.1性能？</h1><p><a href="/attachments/系统性能调优必知必会/15如何提升HTTP-1.1性能？.pdf" target="_blank">如何提升HTTP-1.1性能？</a></p><h1>HTTP-2是怎样提升性能的？</h1><p><a href="/attachments/系统性能调优必知必会/16HTTP-2是怎样提升性能的？.pdf" target="_blank">HTTP-2是怎样提升性能的？</a></p><h1>一致性哈希：如何高效地均衡负载？</h1><p><a href="/attachments/系统性能调优必知必会/24一致性哈希：如何高效地均衡负载？.pdf" target="_blank">一致性哈希：如何高效地均衡负载？</a></p><h1>与程序员相关的SSD性能知识</h1><p><a href="/attachments/系统性能调优必知必会/大咖助场｜庄振运：与程序员相关的SSD性能知识.pdf" target="_blank">与程序员相关的SSD性能知识</a></p><h1>加餐与分享</h1><h2 id="留言">留言</h2><p>鲤鲤鱼：我们集群有一个问题，某一台物理机的CPU会被Hadoop yarn的查询任务打满，并且占用最多的pid在不停的变化，我查看了TIME_WAIT的个数好像也不是很多，在顶峰的时候还没达到一万，能够持续一两个小时。这个问题您有没有什么思路呢？</p><p>作者：解决性能问题，一般有两种方法：经验派和“理论”派。前者就是基于自己的经验概率，将能想到的优化方法都试一遍，这种方式通常又有效又快速，但无法解决复杂的问题。而所谓理论派，就是沿着固定的思路，使用二分法，从高至低慢慢下沉到细节。具体到你的问题，我建议你先看看，CPU占用的是用户态还是系统态，用户态的话就要分析代码了，系统态还要进一步分析。火焰图通常是个很好的办法，虽然搭能画火焰图的环境很麻烦，但这种底层方法很有效。</p><p>杨文宇：链表的内存地址不连续是如何影响序列化的？老师能具体说一下吗？<br>作者：当数组外还有链表中的元素时，序列化就必须遍历所有元素，比如，至少要做1次循环，把每1个遍历到的元素的值，序列化写入至另一段内存中。而使用闭散列时，可以直接将这个数组占用的内存作为序列化后的数据。</p><p>helloworld：“第二，读取磁盘数据时，需要先找到数据所在的位置，对于机械磁盘来说，就是旋转磁头到数据所在的扇区，再开始顺序读取数据。其中，旋转磁头耗时很长，为了降低它的影响，PageCache使用了预读功能。”那是不是使用SSD这类固态硬盘（不用旋转磁头），PageCache就没有很大的影响？<br>作者：对的！其实，当下的操作系统对SSD磁盘的支持还不够，当SSD广泛应用时，文件系统还需要跟上，得获得很大的性能提升才可以。</p><p>Robust：“然而，共享地址空间虽然可以方便地共享对象，但这也导致一个问题，那就是任何一个线程出错时，进程中的所有线程会跟着一起崩溃。”这里的出错应该表示一些特殊的错误吧，或者是说和共享内存有关的错误，比如申请不到内存等。老师，我理解得没错吧？<br>作者：这里指无法恢复的错误，不仅是内存申请错误，比如访问已经释放的资源，且没有捕获异常或者无法捕获异常，进而操作系统只能杀死线程时，进程里的其它线程也会被杀死。</p><p>范闲：用户态的协程不能用互斥或者自旋，会进入内核态与其设计初衷相悖，Python里面用的yield。<br>作者：是的，用户态协程需要用户态的代码将锁重新实现一遍，其中实现时不能用到内核提供的系统调用。</p><p>Geek_007：看评论区，很多同学都说是长连接，普通的HTTP keep-alive会不会有坑，三大运营商或者中间网络设备都会将超过一定时间的链接drop掉。如果没有H2这种ping保活的机制，有可能客户端长链接莫名其妙的就被drop掉，客户端只能依赖超时来感知异常，反倒是影响性能了。<br>作者：是的，不只网络设备，一些代理服务器为了减轻自己的负担，也会把长连接断掉，比如Nginx默认关闭75秒没有数据交互的keep-alive长连接。</p><h2 id="大咖助场">大咖助场</h2><h3 id="场景1：失败引发轮询">场景1：失败引发轮询</h3><h4 id="案例">案例</h4><p>在使用Apache HttpClient发送HTTP请求时，稍有经验的程序员都知道去控制下超时时间，这样，在连接不上服务器或者服务器无响应时，响应延时都会得到有效的控制，例如我们会使用下面的代码来配置HttpClient：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RequestConfig requestConfig = RequestConfig.custom().</span><br><span class="line">setConnectTimeout(2 * 1000). //控制连接建立时间</span><br><span class="line">setConnectionRequestTimeout(1 * 1000). //控制获取连接时间</span><br><span class="line">setSocketTimeout(3 * 1000). //控制“读取”数据等待时间</span><br><span class="line">build();</span><br></pre></td></tr></table></figure><p>以上面的代码为例，你能估算出响应时间最大是多少么？上面的代码实际设置了三个参数，是否直接相加就能计算出最大延时时间？即所有请求100%控制在6秒。</p><p>先不说结论，通过实际的生产线观察，我们确实发现大多符合我们的预期：可以说99.9%的响应都控制在6秒以内，但是总有一些“某年某月某天”，发现有一些零星的请求甚至超过了10秒，这又是为什么？</p><h4 id="解析">解析</h4><p>经过问题跟踪，我们发现我们访问的URL是一个下游服务的域名（大多如此，并不稀奇），而这个域名本身有点特殊，由于负载均衡等因素的考虑，我们将它绑定到了多个IP地址。所以假设这些IP地址中，一些IP地址指向的服务临时不服务时，则会引发轮询，即轮询其它IP地址直到最终成功或失败，而每一次轮询中的失败都会额外增加一倍ConnectTimeout，所以我们发现超过6秒甚至10秒的请求也不稀奇了。我们可以通过HttpClient的源码来验证下这个逻辑（参考org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect方法）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void connect( final ManagedHttpClientConnection conn, final HttpHost host, final InetSocketAddress localAddress, final int connectTimeout, final SocketConfig socketConfig, final HttpContext context) throws IOException &#123;</span><br><span class="line">	final Lookup&lt;ConnectionSocketFactory&gt; registry = getSocketFactoryRegistry( final ConnectionSocketFactory sf = registry.lookup(host.getSchemeName());</span><br><span class="line">	//域名解析，可能解析出多个地址</span><br><span class="line">	final InetAddress[] addresses = host.getAddress() != null ? new InetAddress[] &#123; host.getAddress()</span><br><span class="line">&#125;</span><br><span class="line">: this.dnsResolver.resolve final int port = this.schemePortResolver.resolve(host);</span><br><span class="line">//对于解析出的地址，进行连接，如果中途有失败，尝试下一个</span><br><span class="line">for (int i = 0; i &lt; addresses.length; i++) &#123;</span><br><span class="line">	final InetAddress address = addresses[i];</span><br><span class="line">	final Boolean last = i == addresses.length - 1;</span><br><span class="line">	Socket sock = sf.createSocket(context);</span><br><span class="line">	conn.bind(sock);</span><br><span class="line">	final InetSocketAddress remoteAddress = new InetSocketAddress(address, if (this.log.isDebugEnabled()) &#123;</span><br><span class="line">		this.log.debug(&quot;Connecting to &quot; + remoteAddress);</span><br><span class="line">	&#125;</span><br><span class="line">	try &#123;</span><br><span class="line">		//使用解析出的地址执行连接</span><br><span class="line">		sock = sf.connectSocket( connectTimeout, sock, host, remoteAddress, localAddress, c conn.bind(sock);</span><br><span class="line">		if (this.log.isDebugEnabled()) &#123;</span><br><span class="line">			this.log.debug(&quot;Connection established &quot; + conn);</span><br><span class="line">		&#125;</span><br><span class="line">		//如果连接成功，则直接退出，不继续尝试其它地址</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (final SocketTimeoutException ex) &#123;</span><br><span class="line">		if (last) &#123;</span><br><span class="line">			throw new ConnectTimeoutException(ex, host, addresses);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (final ConnectException ex) &#123;</span><br><span class="line">		if (last) &#123;</span><br><span class="line">			//如果连接到最后一个地址，还是失败，则抛出异常。如果不是最后一个</span><br><span class="line">			final String msg = ex.getMessage();</span><br><span class="line">			if (&quot;Connection timed out&quot;.equals(msg)) &#123;</span><br><span class="line">				throw new ConnectTimeoutException(ex, host, addresses);</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				throw new HttpHostConnectException(ex, host, addresses);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	if (this.log.isDebugEnabled()) &#123;</span><br><span class="line">		this.log.debug(&quot;Connect to &quot; + remoteAddress + &quot; timed out. &quot; + &quot;Connection will be retried using another IP address&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过以上代码，我们可以清晰地看出：在一个域名能解析出多个IP地址的场景下，如果其中部分IP指向的服务不可达时，延时就可能会增加。这里不妨再举个例子，对于Redis集群，我们会在客户端配置多个连接节点（例如在SpringBoot中配置spring.redis.cluster.nodes=10.224.56.101:8001,10.224.56.102:8001），通过连接节点来获取整个集群的信息（其它所有节点）。正常情况下，我们都会连接成功，所以我们没有看到长延时情况，但是假设刚初始化时，连接的部分节点不服务了，那这个时候就会连接其它配置的节点，从而导致延时倍增。</p><h3 id="场景2：STW">场景2：STW</h3><p>假设某天我们看到零星请求有“掉队”，且没有什么规律，但是又持续发生，我们往往都会怀疑是网络抖动，但是假设我们的组件是部署在同一个网络内，实际上，不大可能是网络原因导致的，而更可能是GC的原因。当然，跟踪GC有N多方法，这里我只是额外贴上了组件B使用的跟踪代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;GarbageCollectorMXBean&gt; gcbeans = ManagementFactory.getGarbageCollectorMX;</span><br><span class="line">for (GarbageCollectorMXBean gcbean : gcbeans) &#123;</span><br><span class="line">	LOGGER.info(&quot;GC bean: &quot; + gcbean);</span><br><span class="line">	if (!(gcbean instanceof NotificationEmitter)) continue;</span><br><span class="line">	NotificationEmitter emitter = (NotificationEmitter) gcbean;</span><br><span class="line">	//注册一个GC(垃圾回收)的通知回调</span><br><span class="line">	emitter.addNotificationListener(new NotificationListenerImplementation(), n return GarbageCollectionNotificationInfo.GARBAGE_COLLECTION_NOTIFI .equals(notification.getType());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public final static class NotificationListenerImplementation implements Notifi &#123;</span><br><span class="line">	@Override public void handleNotification(Notification notification, Object handback) GarbageCollectionNotificationInfo info = GarbageCollectionNotificationIn .from((CompositeData) notification.getUserData());</span><br><span class="line">	String gctype = info.getGcAction().replace(&quot;end of &quot;, &quot;&quot;);</span><br><span class="line">	//此处只获取major gc的相关信息</span><br><span class="line">	if(gctype.toLowerCase().contains(&quot;major&quot;))&#123;</span><br><span class="line">		long id = info.getGcInfo().getId();</span><br><span class="line">		long startTime = info.getGcInfo().getStartTime();</span><br><span class="line">		long duration = info.getGcInfo().getDuration();</span><br><span class="line">		//省略非关键代码，记录GC相关信息，如耗费多久、开始时间点等。</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外同样是停顿，发生的时机不同，呈现的效果也不完全相同，具体问题还得具体分析。至于应对这个问题的策略，就是我们写Java程序一直努力的方向：减少GC引发的STW时间。</p><h3 id="场景3：网络抖动">场景3：网络抖动</h3><h4 id="解析-v2">解析</h4><p>那什么是网络抖动呢？网络抖动是衡量网络服务质量的一个指标。假设我们的网络最大延迟为100ms，最小延迟为10ms，那么网络抖动就是90ms，即网络延时的最大值与最小值的差值。差值越小，意味着抖动越小，网络越稳定。反之，当网络不稳定时，抖动就会越大，网络延时差距也就越大，反映到上层应用自然是响应速度的“掉队”。</p><p>为什么网络抖动如此难以避免？这是因为网络的延迟包括两个方面：传输延时和处理延时。忽略处理延时这个因素，假设我们的一个主机进行一次服务调用，需要跨越千山万水才能到达服务器，我们中间出“岔子”的情况就会越多。我们在Linux下面可以使用traceroute命令来查看我们跋山涉水的情况，例如从我的Linux机器到百度的情况是这样的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jiankunking@kube-node-1:~# traceroute www.baidu.com</span><br><span class="line">traceroute to www.baidu.com (39.156.66.14), 30 hops max, 60 byte packets</span><br><span class="line"> 1  11.247.18.30 (11.247.18.30)  1.079 ms  1.060 ms  1.055 ms</span><br><span class="line"> 2  11.73.0.113 (11.73.0.113)  7.325 ms 11.73.0.125 (11.73.0.125)  4.477 ms  4.349 ms</span><br><span class="line"> 3  10.54.189.126 (10.54.189.126)  0.978 ms 10.54.228.170 (10.54.228.170)  1.069 ms 11.94.56.169 (11.94.56.169)  1.335 ms</span><br><span class="line"> 4  11.94.131.61 (11.94.131.61)  2.207 ms 10.54.228.94 (10.54.228.94)  1.480 ms 10.54.228.122 (10.54.228.122)  1.826 ms</span><br><span class="line"> 5  103.41.143.46 (103.41.143.46)  1.493 ms 116.251.113.33 (116.251.113.33)  1.228 ms  1.674 ms</span><br><span class="line"> 6  120.221.68.37 (120.221.68.37)  2.755 ms 120.221.68.21 (120.221.68.21)  2.115 ms 120.221.68.25 (120.221.68.25)  2.077 ms</span><br><span class="line"> 7  211.137.177.81 (211.137.177.81)  7.275 ms  6.973 ms  7.158 ms</span><br><span class="line"> 8  221.183.48.73 (221.183.48.73)  6.994 ms 221.183.48.65 (221.183.48.65)  6.610 ms 221.183.48.73 (221.183.48.73)  6.847 ms</span><br><span class="line"> 9  221.183.40.1 (221.183.40.1)  15.203 ms  13.625 ms 221.183.37.173 (221.183.37.173)  20.658 ms</span><br><span class="line">10  221.183.49.122 (221.183.49.122)  20.774 ms 221.183.49.126 (221.183.49.126)  13.427 ms *</span><br><span class="line">11  111.13.188.38 (111.13.188.38)  17.717 ms 111.13.0.174 (111.13.0.174)  14.427 ms 39.156.27.1 (39.156.27.1)  17.497 ms</span><br><span class="line">12  * * 39.156.27.5 (39.156.27.5)  22.698 ms</span><br><span class="line">13  * * *</span><br><span class="line">14  * * *</span><br><span class="line">15  * * *</span><br><span class="line">16  * * *</span><br><span class="line">17  * * *</span><br><span class="line">18  * * *</span><br><span class="line">19  * * *</span><br><span class="line">20  * * *</span><br><span class="line">21  * * *</span><br><span class="line">22  * * *</span><br><span class="line">23  * * *</span><br><span class="line">24  * * *</span><br><span class="line">25  * * *</span><br><span class="line">26  * * *</span><br><span class="line">27  * * *</span><br><span class="line">28  * * *</span><br><span class="line">29  * * *</span><br><span class="line">30  * * *</span><br></pre></td></tr></table></figure><blockquote><p>*是指此次trace超时。一般会对每一个route连接3次。</p></blockquote><p>通过上面的命令结果我们可以看出，我的机器到百度需要很多“路”。当然大多数人并不喜欢使用traceroute来评估这段路的艰辛程度，而是直接使用ping来简单看看“路”的远近。例如通过以下结果，我们就可以看出，我们的网络延时达到了40ms，这时网络延时就可能是一个问题了。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jiankunking@kube-node-1:~# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (39.156.66.18) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=1 ttl=49 time=16.6 ms</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=2 ttl=49 time=16.5 ms</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=3 ttl=49 time=16.5 ms</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=4 ttl=49 time=16.5 ms</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=5 ttl=49 time=16.5 ms</span><br><span class="line">64 bytes from 39.156.66.18 (39.156.66.18): icmp_seq=6 ttl=49 time=16.5 ms</span><br></pre></td></tr></table></figure><p>其实上面这两个工具的使用只是直观反映网络延时，它们都默认了一个潜规则：网络延时越大，网络越抖动。且不说这个规则是否完全正确，至少从结果来看，评估网络抖动并不够直观。</p><p>所以我们可以再寻求一些其它的工具。例如可以使用MTR工具，它集合了tractroute和ping。我们可以看下执行结果：下图中的best和wrst字段，即为最好的情况与最坏的情况，两者的差值也能在一定程度上反映出抖动情况，其中不同的host相当于traceroute经过的“路”。</p><p>命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mtr www.baidu.com</span><br></pre></td></tr></table></figure><p>响应结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kube-node-1 (127.0.0.1)                                                                                                                                         2022-01-27T20:06:22+0800</span><br><span class="line">Keys:  Help   Display mode   Restart statistics   Order of fields   quit</span><br><span class="line">                                                                                                                                                                 s</span><br><span class="line"> Host                                                                                                                                                           Loss%   Snt   Last   Avg  Best  Wrst StDev</span><br><span class="line"> 1. 11.247.18.30                                                                                                                                                 0.0%    10    1.3   1.4   1.2   1.7   0.1</span><br><span class="line"> 2. 11.73.0.125                                                                                                                                                  0.0%    10    2.4   3.1   2.4   5.5   0.9</span><br><span class="line"> 3. 10.54.229.78                                                                                                                                                 0.0%    10    7.0   5.8   0.9  15.4   5.4</span><br><span class="line"> 4. 45.112.219.26                                                                                                                                                0.0%    10    1.5   1.2   1.1   1.5   0.1</span><br><span class="line"> 5. 103.41.143.46                                                                                                                                                0.0%    10    1.7   1.4   1.3   1.7   0.1</span><br><span class="line"> 6. 120.221.68.25                                                                                                                                                0.0%    10    2.0   1.9   1.8   2.0   0.1</span><br><span class="line"> 7. 211.137.177.81                                                                                                                                               0.0%    10    6.8   6.9   6.7   7.2   0.1</span><br><span class="line"> 8. 221.183.48.61                                                                                                                                                0.0%    10    6.8   7.0   6.5   8.7   0.6</span><br><span class="line"> 9. 221.183.37.173                                                                                                                                              37.5%     9   20.6  21.5  20.6  25.3   2.1</span><br><span class="line">10. (waiting for reply)</span><br><span class="line">11. 39.156.27.1                                                                                                                                                  0.0%     9   17.4  17.9  17.2  22.7   1.8</span><br><span class="line">12. (waiting for reply)</span><br><span class="line">13. (waiting for reply)</span><br><span class="line">14. (waiting for reply)</span><br><span class="line">15. (waiting for reply)</span><br><span class="line">16. 39.156.66.10                                                                                                                                                 0.0%     9   17.1  17.1  17.1  17.2   0.1</span><br></pre></td></tr></table></figure><h3 id="百万并发下Nginx的优化之道">百万并发下Nginx的优化之道</h3><p><a href="/attachments/系统性能调优必知必会/加餐3百万并发下Nginx的优化之道.pdf" target="_blank">百万并发下Nginx的优化之道</a></p>]]></content>
      <categories>
        <category>Performance</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>读书笔记</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch的一些限制及推荐配置</title>
    <url>/elasticsearch-limits-and-recommended-configurations.html</url>
    <content><![CDATA[<blockquote><p>ElasticSearch的一些限制及推荐配置</p></blockquote><a id="more"></a><h1>限制</h1><h2 id="数组字段，数组大小无限制。">数组字段，数组大小无限制。</h2><p><a href="https://discuss.elastic.co/t/what-are-the-limitations-of-array-size-in-elastic-search/108413" target="_blank" rel="noopener">There is no hard limit but it’s definitely recommended to keep those arrays “reasonable”. When performing an update, Elasticsearch needs to fetch the entire doc, apply the update, then index the updated document and replicate the entire updated document to the replica, so very large arrays would come with a performance penalty indeed.</a></p><h2 id="文档大小限制：2GB">文档大小限制：2GB</h2><p>Given that the default http.max_content_length is set to 100MB, Elasticsearch will refuse to index any document that is larger than that. You might decide to increase that particular setting, but Lucene still has a limit of about 2GB.</p><p><a href="https://stackoverflow.com/questions/28841221/what-is-the-maximum-elasticsearch-document-size/28841656#28841656" target="_blank" rel="noopener">https://stackoverflow.com/questions/28841221/what-is-the-maximum-elasticsearch-document-size/28841656#28841656</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/general-recommendations.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/general-recommendations.html</a></p><h2 id="单字段大小限制">单字段大小限制</h2><p>未找到资料，感觉整个文档不超就好</p><h1>推荐配置</h1><h2 id="模板参考配置">模板参考配置</h2><p>从ES 5.x开始，索引级设置需要写在模板中，或者在创建索引时指定，我们把各个索引通用的配置写到了模板中，这个模板匹配全部的索引，并且具有最低的优先级，让用户定义的模板有更高的优先级，以覆盖这个模板中的配置。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;template&quot;: &quot;*&quot;,</span><br><span class="line">  &quot;order&quot;: 0,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.merge.policy.max_merged_segment&quot;: &quot;2gb&quot;,</span><br><span class="line">    &quot;index.merge.policy.segments_per_tier&quot;: &quot;24&quot;,</span><br><span class="line">    &quot;index.number_of_replicas&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;index.number_of_shards&quot;: &quot;24&quot;,</span><br><span class="line">    &quot;index.optimize_auto_generated_id&quot;: &quot;true&quot;,</span><br><span class="line">    &quot;index.refresh_interval&quot;: &quot;120s&quot;,</span><br><span class="line">    &quot;index.translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">    &quot;index.translog.flush_threshold_size&quot;: &quot;1000mb&quot;,</span><br><span class="line">    &quot;index.translog.sync_interval&quot;: &quot;120s&quot;,</span><br><span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5d&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="避免热索引分片不均">避免热索引分片不均</h2><p>默认情况下，ES的分片均衡策略是尽量保持各个节点分片数量大致相同。但是当集群扩容时，新加入集群的节点没有分片，此时新创建的索引分片会集中在新节点上，这导致新节点拥有太多热点数据，该节点可能会面临巨大的写入压力。因此，对于一个索引的全部分片，我们需要控制单个节点上存储的该索引的分片总数，使索引分片在节点上分布得更均匀一些。</p><p>例如，10个节点的集群，索引主分片数为5，副本数量为1，那么平均下来每个节点应该有(5×2)/10=1个分片，考虑到节点故障、分片迁移的情况，可以设置节点分片总数为2：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl --location --request PUT &apos;http://127.0.0.1:9200/myindex/_settings&apos; \</span><br><span class="line">--header &apos;Content-Type: application/json&apos; \</span><br><span class="line">--data &apos;&#123;</span><br><span class="line">  &quot;index&quot;: &#123;</span><br><span class="line">    &quot;routing.allocation.total_shards_per_node&quot;: &quot;2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="延时分片分配策略-节点离开延迟分片分配">延时分片分配策略(节点离开延迟分片分配)</h2><p>当节点出于任何原因（人为原因或系统异常）离开集群时，主节点会做出以下反应（如下称为步骤 X 是方便后续的解读）：</p><ul><li>步骤1：将副本分片提升为主分片以替换节点上的任何主分片。</li><li>步骤2：分配副本分片以替换丢失的副本（在有足够的节点的前提下）。</li><li>步骤3：在其余节点之间均匀地重新平衡分片。</li></ul><p>以上操作的好处是：避免集群数据丢失，确保集群高可用。</p><p>但可能带来的副作用也非常明显：其一，会给集群带来额外的负载（分片分配非常耗费系统资源）；其二，若离开集群的节点很快返回，上述机制的必要性就有待商榷。</p><p>此时，延迟分片分配就显得非常必要，设置如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT _all/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>延时分片分配策略的本质：</p><p>当节点离开集群并确认几分钟（自己设定）可以快速上线的情况下，离开的过程中只触发步骤1的将离开节点上的对应的副本分片提升为主分片。此时集群至少不是red 状态，而是yellow状态。步骤2、步骤3不会发生，此时集群是可用的，待设定的几分钟内下线集群确保重新上线后，分片再重新转为副本分片，此时集群恢复绿色状态。</p><p>这个过程有效避免了步骤2、步骤3的分片分配，整体上以最短的时间确保了集群的高可用性。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html</a></p><h2 id="每个节点将被恢复的并发分片数">每个节点将被恢复的并发分片数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;transient&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.node_concurrent_recoveries&quot;: 3</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上配置:node_concurrent_incoming_recoveries和 node_concurrent_outgoing_recoveries同时生效。<br>incoming_recoverie:通常是其他节点上的副本 shard 恢复到该节点上outgoing_recoveries:通常是当前节点上的主分片 shard 恢复副本分片到其他节点上。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html</a></p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>限制</tag>
        <tag>推荐</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]寻找一种易于理解的一致性算法（扩展版）</title>
    <url>/raft-zh_cn.html</url>
    <content><![CDATA[<blockquote><p>原文地址：<a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="noopener">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></p></blockquote><a id="more"></a><h1>寻找一种易于理解的一致性算法（扩展版）</h1><ul><li><a href="#%E5%AF%BB%E6%89%BE%E4%B8%80%E7%A7%8D%E6%98%93%E4%BA%8E%E7%90%86%E8%A7%A3%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E6%89%A9%E5%B1%95%E7%89%88">寻找一种易于理解的一致性算法（扩展版）</a><ul><li><a href="#%E6%91%98%E8%A6%81">摘要</a></li><li><a href="#1-%E4%BB%8B%E7%BB%8D">1 介绍</a></li><li><a href="#2-%E5%A4%8D%E5%88%B6%E7%8A%B6%E6%80%81%E6%9C%BA">2 复制状态机</a></li><li><a href="#3-paxos-%E7%AE%97%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98">3 Paxos 算法的问题</a></li><li><a href="#4-%E4%B8%BA%E4%BA%86%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7%E7%9A%84%E8%AE%BE%E8%AE%A1">4 为了可理解性的设计</a></li><li><a href="#5-raft-%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95">5 Raft 一致性算法</a><ul><li><a href="#51-raft-%E5%9F%BA%E7%A1%80">5.1 Raft 基础</a></li><li><a href="#52-%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE">5.2 领导人选举</a></li><li><a href="#53-%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">5.3 日志复制</a></li><li><a href="#54-%E5%AE%89%E5%85%A8%E6%80%A7">5.4 安全性</a><ul><li><a href="#541-%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">5.4.1 选举限制</a></li><li><a href="#542-%E6%8F%90%E4%BA%A4%E4%B9%8B%E5%89%8D%E4%BB%BB%E6%9C%9F%E5%86%85%E7%9A%84%E6%97%A5%E5%BF%97%E6%9D%A1%E7%9B%AE">5.4.2 提交之前任期内的日志条目</a></li><li><a href="#543-%E5%AE%89%E5%85%A8%E6%80%A7%E8%AE%BA%E8%AF%81">5.4.3 安全性论证</a></li></ul></li><li><a href="#55-%E8%B7%9F%E9%9A%8F%E8%80%85%E5%92%8C%E5%80%99%E9%80%89%E4%BA%BA%E5%B4%A9%E6%BA%83">5.5 跟随者和候选人崩溃</a></li><li><a href="#56-%E6%97%B6%E9%97%B4%E5%92%8C%E5%8F%AF%E7%94%A8%E6%80%A7">5.6 时间和可用性</a></li></ul></li><li><a href="#6-%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E5%8C%96">6 集群成员变化</a></li><li><a href="#7-%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9">7 日志压缩</a></li><li><a href="#8-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%A4%E4%BA%92">8 客户端交互</a></li><li><a href="#9-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%92%8C%E8%AF%84%E4%BC%B0">9 算法实现和评估</a><ul><li><a href="#91-%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7">9.1 可理解性</a></li><li><a href="#92-%E6%AD%A3%E7%A1%AE%E6%80%A7">9.2 正确性</a></li><li><a href="#93-%E6%80%A7%E8%83%BD">9.3 性能</a></li></ul></li><li><a href="#10-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C">10 相关工作</a></li><li><a href="#11-%E7%BB%93%E8%AE%BA">11 结论</a></li><li><a href="#12-%E6%84%9F%E8%B0%A2">12 感谢</a></li><li><a href="#%E5%8F%82%E8%80%83">参考</a></li></ul></li></ul><h2 id="摘要">摘要</h2><p>Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。一项用户研究的结果表明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。</p><h2 id="1-介绍">1 介绍</h2><p>一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。</p><p>但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。因此工业界和学术界都对 Paxos 算法感到十分头疼。</p><p>努力研究过 Paxos 算法之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。与 Paxos 不同，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且比 Paxos 算法更容易学习。此外，我们希望该算法方便系统构建者的直觉的发展。重要的不仅仅是算法能够工作，更重要的是能够很清楚地知道它为什么能工作。</p><p>Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。</p><p>Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：</p><ul><li><strong>强领导人</strong>：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导人发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。</li><li><strong>领导选举</strong>：Raft 算法使用一个随机计时器来选举领导人。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。</li><li><strong>成员关系调整</strong>：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。</li></ul><p>我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全特性已经被正式定义和证明；它的效率和其他算法比起来也不相上下。</p><p>接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了可理解性而采取的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。</p><h2 id="2-复制状态机">2 复制状态机</h2><p>一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE1.png" alt="图 1 "></p><blockquote><p>图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p></blockquote><p>复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p><p>一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。</p><p>实际系统中使用的一致性算法通常含有以下特性：</p><ul><li>安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、重复和乱序等错误都可以保证正确。</li><li>可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。它们稍后可能会从可靠存储的状态中恢复并重新加入集群。</li><li>不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。</li><li>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</li></ul><h2 id="3-Paxos-算法的问题">3 Paxos 算法的问题</h2><p>在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。</p><p>不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。</p><p>我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。</p><p>Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。</p><p>而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。</p><p>因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：</p><blockquote><p>在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。</p></blockquote><p>由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft 算法就是这次实验的结果。</p><h2 id="4-为了可理解性的设计">4 为了可理解性的设计</h2><p>设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。</p><p>在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？</p><p>我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：我们尽可能地将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和成员变更几个部分。</p><p>我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化来简化 Raft 中领导人选举算法。</p><h2 id="5-Raft-一致性算法">5 Raft 一致性算法</h2><p>Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。</p><p>Raft 通过选举一个杰出的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目（log entries），把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导人会被选举出来。</p><p>通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：</p><ul><li><strong>领导选举</strong>：当现存的领导人发生故障的时候, 一个新的领导人需要被选举出来（章节 5.2）</li><li><strong>日志复制</strong>：领导人必须从客户端接收日志条目（log entries）然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。</li><li><strong>安全性</strong>：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到选举机制（5.2 节）上的一个额外限制。</li></ul><p>在展示一致性算法之后，这一章节会讨论一些可用性的问题和计时在系统中的作用。</p><p><strong>状态</strong>：</p><p>所有服务器上的持久性状态<br>(在响应 RPC 请求之前，已经更新到了稳定的存储设备)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>currentTerm</td><td>服务器已知最新的任期（在服务器首次启动时初始化为0，单调递增）</td></tr><tr><td>votedFor</td><td>当前任期内收到选票的 candidateId，如果没有投给任何候选人 则为空</td></tr><tr><td>log[]</td><td>日志条目；每个条目包含了用于状态机的命令，以及领导人接收到该条目时的任期（初始索引为1）</td></tr></tbody></table><p>所有服务器上的易失性状态</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>commitIndex</td><td>已知已提交的最高的日志条目的索引（初始值为0，单调递增）</td></tr><tr><td>lastApplied</td><td>已经被应用到状态机的最高的日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p>领导人（服务器）上的易失性状态<br>(选举后已经重新初始化)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>nextIndex[]</td><td>对于每一台服务器，发送到该服务器的下一个日志条目的索引（初始值为领导人最后的日志条目的索引+1）</td></tr><tr><td>matchIndex[]</td><td>对于每一台服务器，已知的已经复制到该服务器的最高日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p><strong>追加条目（AppendEntries）RPC</strong>：</p><p>由领导人调用，用于日志条目的复制，同时也被当做心跳使用</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期</td></tr><tr><td>leaderId</td><td>领导人 ID 因此跟随者可以对客户端进行重定向（译者注：跟随者根据领导人 ID 把客户端的请求重定向到领导人，比如有时客户端把请求发给了跟随者而不是领导人）</td></tr><tr><td>prevLogIndex</td><td>紧邻新日志条目之前的那个日志条目的索引</td></tr><tr><td>prevLogTerm</td><td>紧邻新日志条目之前的那个日志条目的任期</td></tr><tr><td>entries[]</td><td>需要被保存的日志条目（被当做心跳使用时，则日志条目内容为空；为了提高效率可能一次性发送多个）</td></tr><tr><td>leaderCommit</td><td>领导人的已知已提交的最高的日志条目的索引</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期，对于领导人而言 它会更新自己的任期</td></tr><tr><td>success</td><td>如果跟随者所含有的条目和 prevLogIndex 以及 prevLogTerm 匹配上了，则为 true</td></tr></tbody></table><p>接收者的实现：</p><ol><li>返回假 如果领导人的任期小于接收者的当前任期（译者注：这里的接收者是指跟随者或者候选人）（5.1 节）</li><li>返回假 如果接收者日志中没有包含这样一个条目 即该条目的任期在 prevLogIndex 上能和 prevLogTerm 匹配上<br>（译者注：在接收者日志中 如果能找到一个和 prevLogIndex 以及 prevLogTerm 一样的索引和任期的日志条目 则继续执行下面的步骤 否则返回假）（5.3 节）</li><li>如果一个已经存在的条目和新条目（译者注：即刚刚接收到的日志条目）发生了冲突（因为索引相同，任期不同），那么就删除这个已经存在的条目以及它之后的所有条目 （5.3 节）</li><li>追加日志中尚未存在的任何新条目</li><li>如果领导人的已知已提交的最高日志条目的索引大于接收者的已知已提交最高日志条目的索引（<code>leaderCommit &gt; commitIndex</code>），则把接收者的已知已经提交的最高的日志条目的索引commitIndex 重置为 领导人的已知已经提交的最高的日志条目的索引 leaderCommit 或者是 上一个新条目的索引 取两者的最小值</li></ol><p><strong>请求投票（RequestVote）RPC</strong>：</p><p>由候选人负责调用用来征集选票（5.2 节）</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>候选人的任期号</td></tr><tr><td>candidateId</td><td>请求选票的候选人的 ID</td></tr><tr><td>lastLogIndex</td><td>候选人的最后日志条目的索引值</td></tr><tr><td>lastLogTerm</td><td>候选人最后日志条目的任期号</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号，以便于候选人去更新自己的任期号</td></tr><tr><td>voteGranted</td><td>候选人赢得了此张选票时为真</td></tr></tbody></table><p>接收者实现：</p><ol><li>如果<code>term &lt; currentTerm</code>返回 false （5.2 节）</li><li>如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）</li></ol><p><strong>所有服务器需遵守的规则</strong>：</p><p>所有服务器：</p><ul><li>如果<code>commitIndex &gt; lastApplied</code>，则 lastApplied 递增，并将<code>log[lastApplied]</code>应用到状态机中（5.3 节）</li><li>如果接收到的 RPC 请求或响应中，任期号<code>T &gt; currentTerm</code>，则令 <code>currentTerm = T</code>，并切换为跟随者状态（5.1 节）</li></ul><p>跟随者（5.2 节）：</p><ul><li>响应来自候选人和领导人的请求</li><li>如果在超过选举超时时间的情况之前没有收到<strong>当前领导人</strong>（即该领导人的任期需与这个跟随者的当前任期相同）的心跳/附加日志，或者是给某个候选人投了票，就自己变成候选人</li></ul><p>候选人（5.2 节）：</p><ul><li>在转变成候选人后就立即开始选举过程<ul><li>自增当前的任期号（currentTerm）</li><li>给自己投票</li><li>重置选举超时计时器</li><li>发送请求投票的 RPC 给其他所有服务器</li></ul></li><li>如果接收到大多数服务器的选票，那么就变成领导人</li><li>如果接收到来自新的领导人的附加日志（AppendEntries）RPC，则转变成跟随者</li><li>如果选举过程超时，则再次发起一轮选举</li></ul><p>领导人：</p><ul><li>一旦成为领导人：发送空的附加日志（AppendEntries）RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以防止跟随者超时（5.2 节）</li><li>如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）</li><li>如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex（<code>lastLogIndex ≥ nextIndex</code>），则发送从 nextIndex 开始的所有日志条目：<ul><li>如果成功：更新相应跟随者的 nextIndex 和 matchIndex</li><li>如果因为日志不一致而失败，则 nextIndex 递减并重试</li></ul></li><li>假设存在 N 满足<code>N &gt; commitIndex</code>，使得大多数的 <code>matchIndex[i] ≥ N</code>以及<code>log[N].term == currentTerm</code> 成立，则令 <code>commitIndex = N</code>（5.3 和 5.4 节）</li></ul><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE2.png" alt="图 2"></p><blockquote><p>图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。</p></blockquote><table><thead><tr><th>特性</th><th>解释</th></tr></thead><tbody><tr><td>选举安全特性</td><td>对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）</td></tr><tr><td>领导人只附加原则</td><td>领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）</td></tr><tr><td>日志匹配原则</td><td>如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致（5.3 节）</td></tr><tr><td>领导人完全特性</td><td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）</td></tr><tr><td>状态机安全特性</td><td>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目（5.4.3 节）</td></tr></tbody></table><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE3.png" alt="图 3 "></p><blockquote><p>图 3：Raft 在任何时候都保证以上的各个特性。</p></blockquote><h3 id="5-1-Raft-基础">5.1 Raft 基础</h3><p>一个 Raft 集群包含若干个服务器节点；5 个服务器节点是一个典型的例子，这允许整个系统容忍 2 个节点失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导人或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE4.png" alt="图 4 "></p><blockquote><p>图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导人。在一个任期内，领导人一直都会是领导人，直到自己宕机了。</p></blockquote><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE5.png" alt="图 5"></p><blockquote><p>图 5：时间被划分成一个个的任期，每个任期开始都是一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。</p></blockquote><p>Raft 把时间分割成任意长度的<strong>任期</strong>，如图 5。任期用连续的整数标记。每一段任期从一次<strong>选举</strong>开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导人。</p><p>不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，任期使得服务器可以检测一些过期的信息：比如过期的领导人。每个节点存储一个当前任期号，这一编号在整个时期内单调递增。每当服务器之间通信的时候都会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导人发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</p><p>Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节 5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。</p><h3 id="5-2-领导人选举">5.2 领导人选举</h3><p>Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选人处接收到有效的 RPCs。领导人周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加条目（AppendEntries） RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是<strong>选举超时</strong>，那么他就会认为系统中没有可用的领导人,并且发起选举以选出新的领导人。</p><p>要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导人，© 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。</p><p>当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止发起新的选举。</p><p>在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加条目（AppendEntries）RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。</p><p>第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p><p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。</p><p>领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。</p><h3 id="5-3-日志复制">5.3 日志复制</h3><p>一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行的发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE6.png" alt="图 6"></p><blockquote><p>图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。</p></blockquote><p>日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。</p><p>领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为<strong>已提交</strong>。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。</p><p>我们设计了 Raft 的日志机制来维护不同服务器日志之间的高层次的一致性。这么做不仅简化了系统的行为也使其更具有可预测性，同时它也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些特性共同组成了图 3 中的<strong>日志匹配特性（Log Matching Property）</strong>：</p><ul><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。</li><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。</li></ul><p>第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目前紧挨着的条目的索引位置和任期号包含在日志内。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。</p><p>在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同。跟随者可能会丢失一些在新的领导人中存在的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE7.png" alt="图 7"></p><blockquote><p>图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。</p></blockquote><p>在 Raft 算法中，领导人是通过强制跟随者直接复制自己的日志来处理不一致问题的。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。</p><p>要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除跟随者从那个点之后的所有日志条目，并发送自己在那个点之后的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 <strong>nextIndex</strong>，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的 index 加 1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。</p><blockquote><p>如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以(返回)冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导人可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。</p></blockquote><p>通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。</p><p>日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。</p><h3 id="5-4-安全性">5.4 安全性</h3><p>前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。</p><p>这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于**领导人完整特性（Leader Completeness Property）**的简要证明，并且说明该特性是如何引导复制状态机做出正确行为的。</p><h4 id="5-4-1-选举限制">5.4.1 选举限制</h4><p>在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导人。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证在选举的时候新的领导人拥有所有之前任期中已经提交的日志条目，而不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。</p><p>Raft 使用投票的方式来阻止一个候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票（RequestVote） RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。</p><p>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</p><h4 id="5-4-2-提交之前任期内的日志条目">5.4.2 提交之前任期内的日志条目</h4><p>如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE8.png" alt="图 8"></p><blockquote><p>图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导人，部分的(跟随者)复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 ©，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为 S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。</p></blockquote><p>为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。</p><p>当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</p><h4 id="5-4-3-安全性论证">5.4.3 安全性论证</h4><p>在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE9.png" alt="图 9"></p><blockquote><p>图 9：如果 S1 （任期 T 的领导人）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。</p></blockquote><ol><li>在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。</li><li>领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人 T 的日志条目，并且给领导人 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。</li><li>这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。</li><li>投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。</li><li>投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。</li><li>首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。</li><li>除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。</li><li>这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。</li><li>日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。</li></ol><p>通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。</p><p>最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。</p><h3 id="5-5-跟随者和候选人崩溃">5.5 跟随者和候选人崩溃</h3><p>到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。</p><h3 id="5-6-时间和可用性">5.6 时间和可用性</h3><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p><p>领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：</p><blockquote><p>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p></blockquote><p>在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p><p>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p><h2 id="6-集群成员变化">6 集群成员变化</h2><p>到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。</p><p>为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人在同一个任期里同时被选举成功。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性原子地转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE10.png" alt="图 10"></p><blockquote><p>图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。</p></blockquote><p>为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致（<em>joint consensus</em>)；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：</p><ul><li>日志条目被复制给集群中新、老配置的所有服务器。</li><li>新、旧配置的服务器都可以成为领导人。</li><li>达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。</li></ul><p>共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应客户端的请求。</p><p>集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用 C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。</p><p>一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，如果不经过另一个配置的允许都不能单独做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE11.png" alt="图 11"></p><blockquote><p>图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的配置日志条目，实线表示最后被提交的配置日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。</p></blockquote><p>在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新之前使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。</p><p>第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。</p><p>第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。</p><p>为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。特别的，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。</p><h2 id="7-日志压缩">7 日志压缩</h2><p>Raft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。</p><p>快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。</p><p>增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE12.png" alt="图 12"></p><blockquote><p>图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。</p></blockquote><p>图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：<strong>最后被包含索引</strong>指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），<strong>最后被包含的任期</strong>指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。</p><p>尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。</p><p><strong>安装快照 RPC</strong>：</p><p>由领导人调用以将快照的分块发送给跟随者。领导人总是按顺序发送分块。</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期号</td></tr><tr><td>leaderId</td><td>领导人的 ID，以便于跟随者重定向请求</td></tr><tr><td>lastIncludedIndex</td><td>快照中包含的最后日志条目的索引值</td></tr><tr><td>lastIncludedTerm</td><td>快照中包含的最后日志条目的任期号</td></tr><tr><td>offset</td><td>分块在快照中的字节偏移量</td></tr><tr><td>data[]</td><td>从偏移量开始的快照分块的原始字节</td></tr><tr><td>done</td><td>如果这是最后一个分块则为 true</td></tr></tbody></table><table><thead><tr><th>结果</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号（currentTerm），便于领导人更新自己</td></tr></tbody></table><p><strong>接收者实现</strong>：</p><ol><li>如果<code>term &lt; currentTerm</code>就立即回复</li><li>如果是第一个分块（offset 为 0）就创建一个新的快照</li><li>在指定偏移量写入数据</li><li>如果 done 是 false，则继续等待更多的数据</li><li>保存快照文件，丢弃具有较小索引的任何现有或部分快照</li><li>如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号，则保留其后的日志条目并进行回复</li><li>丢弃整个日志</li><li>使用快照重置状态机（并加载快照的集群配置）</li></ol><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE13.png" alt="图 13 "></p><blockquote><p>图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。</p></blockquote><p>在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种 RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者丢弃其整个日志；它全部被快照取代，并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照后面的条目仍然有效，必须保留。</p><p>这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。</p><p>我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。</p><p>还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。</p><p>第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。</p><h2 id="8-客户端交互">8 客户端交互</h2><p>这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。</p><p>Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。</p><p>我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可能执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。</p><p>只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为响应客户端请求的领导人可能在他不知道的时候已经被新的领导人取代了。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道哪些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。</p><h2 id="9-算法实现和评估">9 算法实现和评估</h2><p>我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。</p><p>这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。</p><h3 id="9-1-可理解性">9.1 可理解性</h3><p>为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。</p><p>我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些 Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。</p><table><thead><tr><th>关心</th><th>缓和偏见采取的手段</th><th>可供查看的材料</th></tr></thead><tbody><tr><td>相同的讲课质量</td><td>两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。</td><td>视频</td></tr><tr><td>相同的测验难度</td><td>问题以难度分组，在两个测验里成对出现。</td><td>小测验</td></tr><tr><td>公平评分</td><td>使用评价量规。随机顺序打分，两个测验交替进行。</td><td>评价量规（rubric）</td></tr></tbody></table><blockquote><p>表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。</p></blockquote><p>参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明，在 95% 的可信度下，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE14.png" alt="图 14"></p><blockquote><p>图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。</p></blockquote><p>我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型预测，对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft的得分低了6.3分; 虽然我们不知道为什么，这似乎在统计上是有意义的。</p><p>我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE15.png" alt="图 15"></p><blockquote><p>图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。</p></blockquote><p>关于 Raft 用户学习有一个更加详细的讨论。</p><h3 id="9-2-正确性">9.2 正确性</h3><p>在第 5 节，我们已经制定了正式的规范，和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行，并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性是完备的，并且是相当清晰的（大约 3500 个词）。</p><h3 id="9-3-性能">9.3 性能</h3><p>Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。</p><p>我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？</p><p><img data-src="./images/raft-zh_cn/raft-%E5%9B%BE16.png" alt="图 16"></p><blockquote><p>图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。</p></blockquote><p>为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。</p><p>图 16 中上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。</p><p>图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。</p><h2 id="10-相关工作">10 相关工作</h2><p>已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：</p><ul><li>Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。</li><li>关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。</li><li>实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。</li><li>Paxos 可以应用的性能优化。</li><li>Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。</li></ul><p>Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。</p><p>像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。</p><p>和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型，相对的，Raft 只有 4 种消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。</p><p>Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。</p><p>一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。</p><h2 id="11-结论">11 结论</h2><p>算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。</p><p>在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。</p><h2 id="12-感谢">12 感谢</h2><p>这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。</p><h2 id="参考">参考</h2><p>略</p>]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]ElasticSearch中如何处理关联数据？</title>
    <url>/managing-relations-inside-elasticsearch.html</url>
    <content><![CDATA[<p>Inner Object、Nested、Parent/Child、Denormalization</p><a id="more"></a><p>现实世界中的数据很少是简单的–通常情况下，数据之间有着错综复杂的联系。</p><p>你如何在 Elasticsearch 中表示关系数据？ 有几种机制可用于提供关系支持。 每个都有其优点和缺点，使它们适用于不同的情况。</p><h1>Inner Objects</h1><p>最简单的机制被命名为“内部对象”。 它们是嵌入在父文档中的JSON对象：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;Zach&quot;,</span><br><span class="line">    &quot;car&quot;: &#123;</span><br><span class="line">        &quot;make&quot;: &quot;Saturn&quot;,</span><br><span class="line">        &quot;model&quot;: &quot;SL&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单吧?“car”字段是一个JSON对象，内部对象有两个属性(“make”和“model”)。只要根对象和内部对象之间有一对一的关系，这个内部对象映射就可以工作。每个人最多有一辆“车”。</p><p>但如果Zach有两辆车，而另一个人Bob只有一辆车呢?</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;Zach&quot;,</span><br><span class="line">    &quot;car&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;make&quot;: &quot;Saturn&quot;,</span><br><span class="line">            &quot;model&quot;: &quot;SL&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;make&quot;: &quot;Subaru&quot;,</span><br><span class="line">            &quot;model&quot;: &quot;Imprezza&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">	&quot;name&quot;: &quot;Bob&quot;,</span><br><span class="line">	&quot;car&quot;: [</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;make&quot;: &quot;Saturn&quot;,</span><br><span class="line">			&quot;model&quot;: &quot;Imprezza&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>忽略Saturn未制造过Imprezza汽车的事实，当我们搜索它时会发生什么?逻辑上，只有Bob有一个“Saturn Imprezza”，所以我们应该能够执行如下查询:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">query: car.make=Saturn AND car.model=Imprezza</span><br></pre></td></tr></table></figure><p>这样对吗？如果执行该查询，您将搜到两个文档。Elasticsearch在内部将inner objects打平成单个对象。所以Zach’s的实体实际上是这样的:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;Zach&quot;,</span><br><span class="line">    &quot;car.make&quot;: [</span><br><span class="line">        &quot;Saturn&quot;,</span><br><span class="line">        &quot;Subaru&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;car.model&quot;: [</span><br><span class="line">        &quot;SL&quot;,</span><br><span class="line">        &quot;Imprezza&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就解释了为什么会搜索到两条数据。Elasticsearch本质上是扁平的，因此在内部文档被表示为扁平化的字段。</p><h1>Nested</h1><p>作为内部对象的替代方案，Elasticsearch提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html" target="_blank" rel="noopener">“嵌套类型”</a>的概念。 嵌套文档在文档级别看起来与内部对象相同，但提供了我们上面缺少的功能（以及一些限制）。</p><p>嵌套文档示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;Zach&quot;,</span><br><span class="line">    &quot;car&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;make&quot;: &quot;Saturn&quot;,</span><br><span class="line">            &quot;model&quot;: &quot;SL&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;make&quot;: &quot;Subaru&quot;,</span><br><span class="line">            &quot;model&quot;: &quot;Imprezza&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在mapping级别，必须显式声明嵌套类型（与自动检测的内部对象不同）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;person&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;string&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;car&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;nested&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内部对象的问题是，每个嵌套的JSON对象没有被视为文档的独立部分。相反，它们将内部对象相同属性名对应的属性进行合并。</p><p>而嵌套文档则不是这样。每个嵌套的文档保持独立，您可以执行一个查询，比如:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">car.make=Saturn AND car.model=Imprezza</span><br></pre></td></tr></table></figure><p>这样就不会有问题了。</p><p>Elasticsearch 从根本上来说仍然是扁平的，但它在内部管理嵌套关系。当您创建嵌套文档时，Elasticsearch实际上索引两个单独的文档（根对象和嵌套对象），然后在内部将两者关联起来。 两个文档都存储在同一个Shard上的同一个Lucene块中，因此读取性能仍然非常快。</p><p>这种安排确实有一些缺点。 最明显的是，您只能使用特殊的“嵌套查询”访问这些嵌套文档。</p><p>由于所有的文档都存储在同一个Lucene块中，Lucene从不允许对它的段进行随机的写，更新嵌套文档中的一个字段将强制对整个文档进行重新索引。</p><p>这包括根对象和任何其他嵌套对象，即使它们没有被修改。在内部，ES将旧文档标记为已删除，更新字段，然后将所有内容重新索引到一个新的Lucene块中。如果您的数据经常更改，那么嵌套文档reindexing开销将不可忽略。</p><p>最后，不可能在嵌套文档之间“交叉引用”。一个嵌套文档不能“看到”另一个嵌套文档的属性。例如，您不能过滤“<a href="http://A.name" target="_blank" rel="noopener">A.name</a>”，但可以过滤“B.age”上的facet。你可以通过使用’include_in_root’来解决这个问题，它有效地将嵌套的文档复制到根目录中，但这让你回到了内部对象的问题。</p><h1>Parent/Child</h1><p>Elasticsearch 提供的最后一个方法是<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/parent-join.html" target="_blank" rel="noopener">父/子类型</a>。 该方案比嵌套的耦合更松散，并为您提供一组稍微强大的查询。 让我们看一个例子，其中一个人有多个家（在不同的州）。 parent的映射，比如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;person&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;string&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>children拥有自己的映射，但具有特殊的<code>_parent</code>属性：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;homes&quot;: &#123;</span><br><span class="line">        &quot;_parent&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;person&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;state&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>_parent</code>字段告诉 Elasticsearch “homes”类型是“人员”person的子代。 向该方案添加文档非常容易。 父文档正常索引：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl -XPUT localhost:9200/test/person/zach/ -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;Zach&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并且索引子文档几乎和正常一样，除了您需要在查询参数中指定这个子文档属于哪个父文档（在本例中为“zach”，这是我们在上述文档中使用的 ID）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl -XPOST localhost:9200/test/homes?parent=zach -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;state&quot;: &quot;Ohio&quot;</span><br><span class="line">&#125;</span><br><span class="line">$ curl -XPOST localhost:9200/test/homes?parent=zach -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;state&quot;: &quot;South Carolina&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这两个文档现在都与“zach”父文档相关联，这允许您使用特殊查询，例如：</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-has-parent-query.html" target="_blank" rel="noopener">Has Parent Filter/Has Parent Query</a>, 它适用于父文档并返回子文档。</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-has-child-query.html" target="_blank" rel="noopener">Has Child Filter/Has Child Query</a>, 适用于子文档并返回父文档。</li></ul><p>您可以单独查询父类型或子类型，因为它们是一级类型并且会像普通查询一样响应（只是不能使用关系值）。</p><p>Nested的一个大问题是它们的存储：所有东西都存储在同一个Lucene块中。父/子通过分离两个文档并仅将它们松散耦合来消除此限制。这有一些优点和缺点。松散耦合意味着您可以更自由地更新/删除子文档，因为它们对父文档或其他子文档没有影响。</p><p>Nested的一个大问题是它们的存储:所有内容都存储在同一个Lucene块中。Parent/Child通过分离两个文档并松散耦合它们来消除这种限制。这样做有利有弊。松散耦合意味着你可以更自由地更新/删除子文档，因为它们对父文档或其他子文档没有影响。</p><p>缺点是Parent/Child的性能略低于嵌套。子文档被路由到与父文档相同的shard，所以它们仍然受益于shard级别的缓存和内存过滤。但是它们没有嵌套的那么快，因为它们不在同一个Lucene块中。还有一点内存开销，因为ElasticSearch需要在内存中保留一个“连接表”，用于管理关系。</p><p>最后，坦率地说，您将遇到排序或评分非常困难的情况。例如，不可能知道哪个子文档匹配您的’Has_Child’过滤器，只知道返回的父文档中的一个文档匹配了条件。这可能会令人沮丧，这取决于您的用例。</p><h1>Denormalization</h1><p>有时最好的选择是在适当的地方简单地对数据进行反规范化。Elasticsearch提供的关系工具非常适合某些场景……但从来没有打算提供您期望从RDBM中得到的健壮关系特性。</p><p>从本质上讲，Elasticsearch是一个扁平的层次结构，试图将关系数据强制放入其中可能非常具有挑战性。有时，最好的解决方案是明智地选择要反规范化的数据，以及可以接受第二个查询来检索子查询的位置。非规范化可以为您提供最大的权力和灵活性。</p><p>当然，这也带来了管理开销的负担。您可以管理关系，并执行所需的查询/过滤器来关联各种类型。</p><h1>Conclusion and Recap</h1><p>简单概括一下：</p><h2 id="Inner-Object">Inner Object</h2><ul><li>简单,快速,性能</li><li>仅适用于保持一对一关系时</li><li>不需要特殊查询</li></ul><h2 id="Nested">Nested</h2><ul><li>嵌套文档存储在同一个Lucene块中，这有助于提高读取/查询性能。读取嵌套文档比读取等效的父/子文档要快。</li><li>更新嵌套文档(父文档或子文档)中的单个字段将迫使ES重新索引整个嵌套文档。对于大型嵌套文档来说，这可能是非常昂贵的</li><li>“交叉引用”嵌套文档是不可能的</li><li>最适合不经常更改的数据</li></ul><h2 id="Parent-Child">Parent/Child</h2><ul><li>子节点与父节点分开存储，但是被路由到相同的碎片。因此，parent/children在读/查询方面的性能略低于嵌套</li><li>父/子映射有一点额外的内存开销，因为ES在内存中维护一个“连接”列表</li><li>更新子文档不会影响父文档或任何其他子文档，这可能会节省大量大型文档的索引</li><li>Parent/Child的排序/评分可能很困难，因为Has Child/Has Parent操作有时是不透明的</li></ul><h2 id="Denormalization">Denormalization</h2><ul><li>你可以自己管理所有的关系!</li><li>最灵活、管理开销最大</li><li>可能是更多或更少的性能取决于您的设置</li></ul><p>原文地址：<a href="https://www.elastic.co/cn/blog/managing-relations-inside-elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/managing-relations-inside-elasticsearch</a></p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>翻译</tag>
        <tag>Nested</tag>
        <tag>Parent/Child</tag>
        <tag>Denormalization</tag>
      </tags>
  </entry>
  <entry>
    <title>友爱的Sentry</title>
    <url>/fraternity-sentry.html</url>
    <content><![CDATA[<p>What do you want Sentry to do in this case? Turn itself off?</p><a id="more"></a><p>最近Sentry的Redis一直报内存占用高，看Sentry日志能看到:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">OOM command not allowed when used memory &gt; &apos;maxmemory&apos;</span><br></pre></td></tr></table></figure><p>然后上网看了一下，发现了几个有意思的回复:</p><p><img data-src="/images/fraternity-sentry/1.png" alt><br><img data-src="/images/fraternity-sentry/2.png" alt></p><p>感觉Sentry社区很“友爱”，就是硬钢。</p><p>那么，Sentry Redis中存储的都是什么内容呢？<br><img data-src="/images/fraternity-sentry/3.png" alt></p><p>截图来源：<br><a href="https://github.com/getsentry/sentry/issues/1183" target="_blank" rel="noopener">https://github.com/getsentry/sentry/issues/1183</a><br><a href="https://github.com/getsentry/sentry/issues/13785" target="_blank" rel="noopener">https://github.com/getsentry/sentry/issues/13785</a><br><a href="https://forum.sentry.io/t/redis-hitting-oom/2810" target="_blank" rel="noopener">https://forum.sentry.io/t/redis-hitting-oom/2810</a></p>]]></content>
      <categories>
        <category>Sentry</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Redis</tag>
        <tag>Sentry</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title>杂书推荐</title>
    <url>/recommended-leisure-books.html</url>
    <content><![CDATA[<p>对个人影响比较大的几本书。</p><a id="more"></a><p>1、《身份的焦虑》–阿兰·德波顿<br>2、《工作漂流》–稻泉连</p>]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]7.7 版本中的新改进：显著降低 Elasticsearch 堆内存使用量</title>
    <url>/significantly-decrease-your-elasticsearch-heap-memory-usage.html</url>
    <content><![CDATA[<blockquote><p>原文地址：<br><a href="https://www.elastic.co/cn/blog/significantly-decrease-your-elasticsearch-heap-memory-usage" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/significantly-decrease-your-elasticsearch-heap-memory-usage</a></p></blockquote><a id="more"></a><p>由于 Elasticsearch 用户不断突破在 Elasticsearch 节点上存储的数据量的极限，所以他们有时会在耗尽磁盘空间之前就将堆内存用完了。对于这些用户来说，这个问题难免让他们沮丧，因为每个节点拟合尽可能多的数据通常是降低成本的重要手段。</p><p>但为什么 Elasticsearch 需要堆内存来存储数据呢？为什么它不能只用磁盘空间呢？这其中有几个原因，但最主要的一个是，Lucene 需要在内存中存储一些信息，以便知道在磁盘的什么位置进行查找。例如，Lucene 的倒排索引由术语字典和术语索引组成，术语字典将术语按排序顺序归入磁盘上的区块，术语索引用于快速查找术语字典。该术语索引将术语前缀与磁盘上区块（包含具有该前缀的术语）起始位置的偏移量建立映射。术语字典在磁盘上，但是术语索引直到最近还在堆上。</p><p>索引需要多少内存？通常情况下，每 GB 索引需要几 MB 内存。这并不算多，但随着用户在节点上安装 TB 数越来越大的磁盘，索引很快就需要 10-20 GB 的堆内存来存储这些 TB 量级的索引。鉴于 Elastic 的建议，不要超过 30 GB，不然就没有给聚合等其他堆内存消耗者留下太多空间，而且，如果 JVM 没有为集群管理操作留出足够的空间，就会导致稳定性问题。</p><p>我们来看一些实实在在的数字。Elastic 在多个数据集上运行了夜间基准测试，并跟踪了不同时间的各种指标，特别是段的内存使用情况。Geonames 数据集很有趣，它清晰地显示了在 Elasticsearch 7.x 上发生的各种变化的影响：</p><p><img data-src="/images/significantly-decrease-your-elasticsearch-heap-memory-usage/heap-reduction-7-7-nightly-geonames-blog.png" alt></p><p><font color="DeepPink"><strong>6 个月前，此索引在磁盘上占用大约 3 GB 空间，需要大约 5.2 MB 的内存，堆:存储比约为 1:600。按此比例，如果每个节点有 10 TB 数据，那么就需要 10 TB / 600 = 17 GB 的堆量，这还是仅够保持存储类似 geonames 数据的索引处于打开状态。但正如您所看到的，随着时间的推移，情况正在向好的方向发展：点（深蓝色）开始需要较少的内存，接着是术语（粉色），之后是存储字段（绿色），最后还是术语占比很大。堆:存储比现在约为 1:4000，与 6.x 和早期 7.x 版本相比，几乎提升了 7 倍。现在只需要 2.5 GB 堆内存就可以使 10 TB 索引保持打开状态。</strong></font></p><p>这些数字在不同数据集间会有很大差异，不过让人欣慰的是，Geonames 是堆使用量减少程度最低的数据集之一：虽然在 Geonames 上，堆使用量减少了约 7 倍，但在 NYC taxis 和 HTTP logs 数据集上，减少量超过了 100 倍。同样，这一变化将有助于降低成本，因为在每个节点上存储的数据比以前版本的 Elasticsearch 要多得多。</p><p><img data-src="/images/significantly-decrease-your-elasticsearch-heap-memory-usage/heap-reduction-7-7-nightly-taxis-blog.png" alt></p><p><img data-src="/images/significantly-decrease-your-elasticsearch-heap-memory-usage/heap-reduction-7-7-nightly-http-logs-blog.png" alt></p><p>它是如何工作的，有什么缺陷？随着时间的推移，同样的方法已经应用到 Lucene 索引的多个组件中：将数据结构从 JVM 堆移动到磁盘，并依赖文件系统缓存（通常称为页面缓存或 OS 缓存）将热数据保存在内存中。这可能会被误以为这些内存仍然在使用，只不过是分配到了其他地方，但实际情况是，根据您的用例，很大一部分内存根本没有使用。例如，Terms 的最后一次删除操作是因为移动了磁盘上 _id 字段的术语索引，这只在使用 GET API 或使用显式 ID 索引文档时有用。那些绝大多数将日志和指标索引到 Elasticsearch 中的用户从来都不会执行此类操作，所以这只会让他们的资源出现净增长。</p><blockquote><p>这个内存降低主要是Elasticsearch 7.7.0的lucene更新到8.5.0 release，将FST等移到了堆外,具体可以看下lucene 8.5.0 的变更。<br>拓展阅读 <a href="https://zhuanlan.zhihu.com/p/146083622" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/146083622</a><br>拓展阅读 <a href="https://www.easyice.cn/archives/346" target="_blank" rel="noopener">https://www.easyice.cn/archives/346</a></p></blockquote><p>在线：<a href="/attachments/lucene-8.5.0-CHANGES.txt" target="_blank">lucene 8.5.0 CHANGES</a></p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ElasticSearch</tag>
        <tag>Heap</tag>
        <tag>Index</tag>
      </tags>
  </entry>
  <entry>
    <title>怎样在焦虑的情况下表现更好</title>
    <url>/how-to-perform-better-in-anxious-situations.html</url>
    <content><![CDATA[<p>每个人都想在生活中做到最好。但是，一个人越是想表现好，压力就会越大，焦虑情绪也越严重。如果处理好压力和焦虑，它们就可以成为帮助我们实现最佳自我的有效工具。《今日心理学》网站的一篇文章介绍了一些策略，可以帮人们借助焦虑来提高自己的表现。微信公众号“心之洲”翻译了这篇文章。</p><p><font color="DeepPink"><strong>第一，改变对焦虑的态度，并且把焦虑当成一种资源。</strong></font>很多研究表明，只有在人们将“压力”看做压力时，压力才会影响健康。也就是说，如果我们不把它看作“压力”的话，就不会影响健康，即使压力真的很严重。</p><p><font color="DeepPink"><strong>第二，优化焦点。</strong></font>研究表明，焦虑最大的影响之一，就是利用焦点，并且将注意力转移到最需要的地方。日常生活中，焦虑可以让人在众多干扰情况下，将注意力集中到需要关注的地方，从而提升自我的表现力。</p><p><font color="DeepPink"><strong>第三，焦虑会让人保持警觉和警惕，并且为最佳表现做好准备。</strong></font>有研究表明，人们在有压力的情况下，更容易发现威胁，同时迅速采取行动。而且在焦虑的情况下，感觉运动系统的神经传导过程更快，处理和响应刺激的效率也最高。</p><p><font color="DeepPink"><strong>第四，焦虑能提醒人们想起某些需要注意、但可能已经忘了的事情。</strong></font>焦虑时，人们会很谨慎，甚至可能会过度夸大潜在风险。焦虑会让我们想到最坏的结果，万一这种结果真的出现了，至少我们不会措手不及。</p><p><font color="DeepPink"><strong>第五，尽可能保证睡眠。</strong></font>不少研究表明，充足的睡眠能让人表现更好，我们的大脑需要睡眠来清理毒素并吸收新的信息，睡眠不足则会加重焦虑。</p><p>以上就是正确应对焦虑、提高个人表现的几个策略，希望对你有帮助。</p>]]></content>
      <categories>
        <category>自我</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>焦虑</tag>
      </tags>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 节点关闭分析</title>
    <url>/elasticsearch-node-stop-source-code-analysis.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第六篇：Elasticsearch 节点关闭分析<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><h1>目的</h1><p>在看源码之前先梳理一下，自己对于节点关闭流程疑惑的点：</p><ul><li>节点关闭都做了哪些检查？</li><li>kill ES进程来关闭节点是否安全？</li><li>普通节点关闭与Master节点关闭有什么区别？</li><li>正在写入数据的节点，在关闭的时候，会发生什么？</li></ul><h1>源码分析</h1><p>在节点启动过程中，Bootstrap#setup方法中添加了shutdown hook，当进程收到系统SIGTERM（kill命令默认信号 15）或SIGINT(2)信号时，调用<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/node/Node.javas" target="_blank" rel="noopener">Node</a>#<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/node/Node.java#L971" target="_blank" rel="noopener">close</a>方法，执行节点关闭流程。</p><blockquote><p><a href="https://stackoverflow.com/questions/4042201/how-does-sigint-relate-to-the-other-termination-signals-such-as-sigterm-sigquit" target="_blank" rel="noopener">https://stackoverflow.com/questions/4042201/how-does-sigint-relate-to-the-other-termination-signals-such-as-sigterm-sigquit</a></p></blockquote><p>每个模块的Service中都实现了doStop和doClose，用于处理这个模块的正常关闭流程。节点总的关闭流程位于Node#close，在close方法的实现中，先调用一遍各个模块的doStop，然后再次遍历各个模块执行doClose。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// During concurrent close() calls we want to make sure that all of them return after the node has completed it&apos;s shutdown cycle.</span><br><span class="line">// If not, the hook that is added in Bootstrap#setup() will be useless:</span><br><span class="line">// close() might not be executed, in case another (for example api) call to close() has already set some lifecycles to stopped.</span><br><span class="line">// In this case the process will be terminated even if the first call to close() has not finished yet.</span><br><span class="line">@Override</span><br><span class="line">public synchronized void close() throws IOException &#123;</span><br><span class="line">    synchronized (lifecycle) &#123;</span><br><span class="line">        if (lifecycle.started()) &#123;</span><br><span class="line">            stop();</span><br><span class="line">        &#125;</span><br><span class="line">        if (!lifecycle.moveToClosed()) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    logger.info(&quot;closing ...&quot;);</span><br><span class="line"></span><br><span class="line">    // 关闭各种服务</span><br><span class="line">    List&lt;Closeable&gt; toClose = new ArrayList&lt;&gt;();</span><br><span class="line">    StopWatch stopWatch = new StopWatch(&quot;node_close&quot;);</span><br><span class="line">    toClose.add(() -&gt; stopWatch.start(&quot;node_service&quot;));</span><br><span class="line">    toClose.add(nodeService);</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;http&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(HttpServerTransport.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;snapshot_service&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(SnapshotsService.class));</span><br><span class="line">    toClose.add(injector.getInstance(SnapshotShardsService.class));</span><br><span class="line">    toClose.add(injector.getInstance(RepositoriesService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;client&quot;));</span><br><span class="line">    Releasables.close(injector.getInstance(Client.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;indices_cluster&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(IndicesClusterStateService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;indices&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(IndicesService.class));</span><br><span class="line">    // close filter/fielddata caches after indices</span><br><span class="line">    toClose.add(injector.getInstance(IndicesStore.class));</span><br><span class="line">    toClose.add(injector.getInstance(PeerRecoverySourceService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;cluster&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(ClusterService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;node_connections_service&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(NodeConnectionsService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;discovery&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(Discovery.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;monitor&quot;));</span><br><span class="line">    toClose.add(nodeService.getMonitorService());</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;fsHealth&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(FsHealthService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;gateway&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(GatewayService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;search&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(SearchService.class));</span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;transport&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(TransportService.class));</span><br><span class="line"></span><br><span class="line">    for (LifecycleComponent plugin : pluginLifecycleComponents) &#123;</span><br><span class="line">        toClose.add(() -&gt; stopWatch.stop().start(&quot;plugin(&quot; + plugin.getClass().getName() + &quot;)&quot;));</span><br><span class="line">        toClose.add(plugin);</span><br><span class="line">    &#125;</span><br><span class="line">    toClose.addAll(pluginsService.filterPlugins(Plugin.class));</span><br><span class="line"></span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;script&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(ScriptService.class));</span><br><span class="line"></span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;thread_pool&quot;));</span><br><span class="line">    toClose.add(() -&gt; injector.getInstance(ThreadPool.class).shutdown());</span><br><span class="line">    // Don&apos;t call shutdownNow here, it might break ongoing operations on Lucene indices.</span><br><span class="line">    // See https://issues.apache.org/jira/browse/LUCENE-7248. We call shutdownNow in</span><br><span class="line">    // awaitClose if the node doesn&apos;t finish closing within the specified time.</span><br><span class="line"></span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;gateway_meta_state&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(GatewayMetaState.class));</span><br><span class="line"></span><br><span class="line">    toClose.add(() -&gt; stopWatch.stop().start(&quot;node_environment&quot;));</span><br><span class="line">    toClose.add(injector.getInstance(NodeEnvironment.class));</span><br><span class="line">    toClose.add(stopWatch::stop);</span><br><span class="line"></span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        toClose.add(() -&gt; logger.trace(&quot;Close times for each service:\n&#123;&#125;&quot;, stopWatch.prettyPrint()));</span><br><span class="line">    &#125;</span><br><span class="line">    IOUtils.close(toClose);</span><br><span class="line">    logger.info(&quot;closed&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private Node stop() &#123;</span><br><span class="line">    if (!lifecycle.moveToStopped()) &#123;</span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line">    logger.info(&quot;stopping ...&quot;);</span><br><span class="line"></span><br><span class="line">    injector.getInstance(ResourceWatcherService.class).close();</span><br><span class="line">    injector.getInstance(HttpServerTransport.class).stop();</span><br><span class="line"></span><br><span class="line">    injector.getInstance(SnapshotsService.class).stop();</span><br><span class="line">    injector.getInstance(SnapshotShardsService.class).stop();</span><br><span class="line">    injector.getInstance(RepositoriesService.class).stop();</span><br><span class="line">    // stop any changes happening as a result of cluster state changes</span><br><span class="line">    injector.getInstance(IndicesClusterStateService.class).stop();</span><br><span class="line">    // close discovery early to not react to pings anymore.</span><br><span class="line">    // This can confuse other nodes and delay things - mostly if we&apos;re the master and we&apos;re running tests.</span><br><span class="line">    injector.getInstance(Discovery.class).stop();</span><br><span class="line">    // we close indices first, so operations won&apos;t be allowed on it</span><br><span class="line">    injector.getInstance(ClusterService.class).stop();</span><br><span class="line">    injector.getInstance(NodeConnectionsService.class).stop();</span><br><span class="line">    injector.getInstance(FsHealthService.class).stop();</span><br><span class="line">    nodeService.getMonitorService().stop();</span><br><span class="line">    injector.getInstance(GatewayService.class).stop();</span><br><span class="line">    injector.getInstance(SearchService.class).stop();</span><br><span class="line">    injector.getInstance(TransportService.class).stop();</span><br><span class="line"></span><br><span class="line">    pluginLifecycleComponents.forEach(LifecycleComponent::stop);</span><br><span class="line">    // we should stop this last since it waits for resources to get released</span><br><span class="line">    // if we had scroll searchers etc or recovery going on we wait for to finish.</span><br><span class="line">    injector.getInstance(IndicesService.class).stop();</span><br><span class="line">    logger.info(&quot;stopped&quot;);</span><br><span class="line"></span><br><span class="line">    return this;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>各模块的关闭有一定的顺序关系，以 doStop 为例，按下表所示的 顺序调用各模块 doStop方法。</p><table><thead><tr><th>服务</th><th>简介</th></tr></thead><tbody><tr><td>ResourceWatcherService</td><td>通用资源监视服务</td></tr><tr><td>HttpServerTransport</td><td>HTTP 传输服务，提供REST接口服务</td></tr><tr><td>SnapshotsService</td><td>快照服务</td></tr><tr><td>SnapshotShardsService</td><td>负责启动和停止shard级快照</td></tr><tr><td>RepositoriesService</td><td>Service responsible for maintaining and providing access to snapshot repositories on nodes</td></tr><tr><td>IndicesClusterStateService</td><td>收到集群状态信息后，处理其中索引相关操作</td></tr><tr><td>Discovery</td><td>集群拓扑管理</td></tr><tr><td>ClusterService</td><td>集群管理服务，主要处理集群任务，发布集群状态</td></tr><tr><td>NodeConnectionsService</td><td>节点连接管理服务</td></tr><tr><td>FsHealthService</td><td>Runs periodically and attempts to create a temp file to see if the filesystem is writable. If not then it marks the path as unhealthy</td></tr><tr><td>MonitorService</td><td>提供进程级、系统级、文件系统和 JVM 的监控服务</td></tr><tr><td>GatewayService</td><td>负责集群元数据持久化与恢复</td></tr><tr><td>SearchService</td><td>处理搜索请求</td></tr><tr><td>TransportService</td><td>底层传输服务</td></tr><tr><td>plugins</td><td>当前的所有插件</td></tr><tr><td>IndicesService</td><td>负责创建、删除索引等索引操作</td></tr></tbody></table><p>综合来看，关闭顺序大致如下∶</p><ul><li>关闭快照和HTTPServer，不再响应用户REST请求。</li><li>关闭集群拓扑管理，不再响应ping请求。</li><li>关闭网络模块，让节点离线。</li><li>执行各个插件的关闭流程。</li><li>关闭IndicesService。<br>最后才关闭IndicesService，是因为这期间需要等待释放的资源最多，时间最长。</li></ul><p>下面着重看一下IndicesService的doStop：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void doStop() &#123;</span><br><span class="line">    clusterService.removeApplier(timestampFieldMapperService);</span><br><span class="line">    timestampFieldMapperService.doStop();</span><br><span class="line"></span><br><span class="line">    ThreadPool.terminate(danglingIndicesThreadPoolExecutor, 10, TimeUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">    ExecutorService indicesStopExecutor =</span><br><span class="line">        Executors.newFixedThreadPool(5, daemonThreadFactory(settings, &quot;indices_shutdown&quot;));</span><br><span class="line"></span><br><span class="line">    // Copy indices because we modify it asynchronously in the body of the loop</span><br><span class="line">    final Set&lt;Index&gt; indices = this.indices.values().stream().map(s -&gt; s.index()).collect(Collectors.toSet());</span><br><span class="line">    final CountDownLatch latch = new CountDownLatch(indices.size());</span><br><span class="line">    for (final Index index : indices) &#123;</span><br><span class="line">        indicesStopExecutor.execute(() -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                removeIndex(index, IndexRemovalReason.SHUTDOWN, &quot;shutdown&quot;);</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    try &#123;</span><br><span class="line">    	// 注意shardsClosedTimeout 这个值是在IndicesService的构造函数中初始化的</span><br><span class="line">    	// this.shardsClosedTimeout = settings.getAsTime(INDICES_SHARDS_CLOSED_TIMEOUT, new TimeValue(1, TimeUnit.DAYS));</span><br><span class="line">    	// 也就是说 CountDownLatch.await默认1天才会继续后面的流程</span><br><span class="line">        if (latch.await(shardsClosedTimeout.seconds(), TimeUnit.SECONDS) == false) &#123;</span><br><span class="line">          logger.warn(&quot;Not all shards are closed yet, waited &#123;&#125;sec - stopping service&quot;, shardsClosedTimeout.seconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        // ignore</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        indicesStopExecutor.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那什么时候会导致removeIndex执行一直无法返回呢？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IndicesService removeIndex(final Index index, final IndexRemovalReason reason, final String extraInfo)=&gt;</span><br><span class="line">IndexService close(final String reason, boolean delete)=&gt;</span><br><span class="line">IndexService removeShard(int shardId, String reason)=&gt;</span><br><span class="line">IndexService removeShard(String reason, ShardId sId, IndexShard indexShard, Store store, IndexEventListener listener)=&gt;</span><br><span class="line">IndexShard close(String reason, boolean flushEngine)=&gt;</span><br><span class="line">Engine flushAndClose()=&gt;</span><br></pre></td></tr></table></figure><p>下面具体看一下flushAndClose()：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Flush the engine (committing segments to disk and truncating the</span><br><span class="line"> * translog) and close it.</span><br><span class="line"> */</span><br><span class="line">public void flushAndClose() throws IOException &#123;</span><br><span class="line">    if (isClosed.get() == false) &#123;</span><br><span class="line">        logger.trace(&quot;flushAndClose now acquire writeLock&quot;);</span><br><span class="line">        // 可以看一下：</span><br><span class="line">        // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java#L857</span><br><span class="line">        // 由于写入操作已经加了读锁，此时写锁会等待，直到写入执行完毕。</span><br><span class="line">        // 因此数据写入过程不会被中断。但是由于网络模块被关闭，客户端的连接会被断开。</span><br><span class="line">        // 客户端应当作为失败处理，虽然ES服务端的写流程还在继续。</span><br><span class="line">        try (ReleasableLock lock = writeLock.acquire()) &#123;</span><br><span class="line">            logger.trace(&quot;flushAndClose now acquired writeLock&quot;);</span><br><span class="line">            try &#123;</span><br><span class="line">                logger.debug(&quot;flushing shard on close - this might take some time to sync files to disk&quot;);</span><br><span class="line">                try &#123;</span><br><span class="line">                    // TODO we might force a flush in the future since we have the write lock already even though recoveries</span><br><span class="line">                    // are running.</span><br><span class="line">                    flush();</span><br><span class="line">                &#125; catch (AlreadyClosedException ex) &#123;</span><br><span class="line">                    logger.debug(&quot;engine already closed - skipping flushAndClose&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                close(); // double close is not a problem</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    awaitPendingClose();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1>总结</h1><p>kill -15/-2 ElasticSearch是可以正常退出的。</p><p>正在写入数据的节点，在关闭的时候，需要等待数据写入完成或者超时。</p><p>主节点被关闭时，没有想象中的特殊处理，节点正常执行关闭流程，当TransportService模块被关闭后，集群重新选举新Master。因此，滚动重启期间会有一段时间处于无主状态。</p><blockquote><p>该部分等看集群选举部分的时候，再细看一下。</p></blockquote>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Node</tag>
      </tags>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 节点启动分析</title>
    <url>/elasticsearch-node-start-source-code-analysis.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第五篇：Elasticsearch 节点启动分析<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><h1>目的</h1><p>在看源码之前先梳理一下，自己对于节点启动流程疑惑的点：</p><ul><li>节点启动都做了哪些检查？</li><li>节点启动都初始化了哪些内容？</li><li>当节点启动后，数据迁移是在哪里处理？</li></ul><h1>源码分析</h1><p>先从<a href="https://github.com/jiankunking/elasticsearch/blob/master/distribution/src/bin/elasticsearch" target="_blank" rel="noopener">启动脚本</a>中找到启动类的入口:org.elasticsearch.bootstrap.Elasticsearch。</p><p>下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java" target="_blank" rel="noopener">org.elasticsearch.bootstrap.Elasticsearch</a>,先看一下主入口函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Main entry point for starting elasticsearch</span><br><span class="line"> */</span><br><span class="line">public static void main(final String[] args) throws Exception &#123;</span><br><span class="line">    // 根据jvm.options中读取：es.networkaddress.cache.ttl和es.networkaddress.cache.negative.ttl</span><br><span class="line">    // 并覆盖JVM Security中的networkaddress.cache.ttl与networkaddress.cache.negative.ttl</span><br><span class="line">    overrideDnsCachePolicyProperties();</span><br><span class="line">    /*</span><br><span class="line">     * We want the JVM to think there is a security manager installed so that if internal policy decisions that would be based on the</span><br><span class="line">     * presence of a security manager or lack thereof act as if there is a security manager present (e.g., DNS cache policy). This</span><br><span class="line">     * forces such policies to take effect immediately.</span><br><span class="line">     */</span><br><span class="line">    System.setSecurityManager(new SecurityManager() &#123;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void checkPermission(Permission perm) &#123;</span><br><span class="line">            // grant all permissions so that we can later set the security manager to the one that we want</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;);</span><br><span class="line">    LogConfigurator.registerErrorListener();</span><br><span class="line">    final Elasticsearch elasticsearch = new Elasticsearch();</span><br><span class="line">    // 核心检查处理都在main(final String[] args, final Elasticsearch elasticsearch, final Terminal terminal)方法中</span><br><span class="line">    int status = main(args, elasticsearch, Terminal.DEFAULT);</span><br><span class="line">    if (status != ExitCodes.OK) &#123;</span><br><span class="line">        final String basePath = System.getProperty(&quot;es.logs.base_path&quot;);</span><br><span class="line">        // It&apos;s possible to fail before logging has been configured, in which case there&apos;s no point</span><br><span class="line">        // suggesting that the user look in the log file.</span><br><span class="line">        if (basePath != null) &#123;</span><br><span class="line">            Terminal.DEFAULT.errorPrintln(</span><br><span class="line">                &quot;ERROR: Elasticsearch did not exit normally - check the logs at &quot;</span><br><span class="line">                    + basePath</span><br><span class="line">                    + System.getProperty(&quot;file.separator&quot;)</span><br><span class="line">                    + System.getProperty(&quot;es.logs.cluster_name&quot;) + &quot;.log&quot;</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        exit(status);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>main的处理逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Elasticsearch main(final String[] args)=&gt;</span><br><span class="line">Elasticsearch main(final String[] args, final Elasticsearch elasticsearch, final Terminal terminal)=&gt;</span><br><span class="line">Command main(String[] args, Terminal terminal)=&gt;</span><br><span class="line">EnvironmentAwareCommand execute(Terminal terminal, OptionSet options)=&gt;</span><br><span class="line">Elasticsearch execute(Terminal terminal, OptionSet options, Environment env)=&gt;</span><br><span class="line">Bootstrap static void init(</span><br><span class="line">            final boolean foreground,</span><br><span class="line">            final Path pidFile,</span><br><span class="line">            final boolean quiet,</span><br><span class="line">            final Environment initialEnv)=&gt;</span><br></pre></td></tr></table></figure><p>下面看一下Bootstrap.init</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * This method is invoked by &#123;@link Elasticsearch#main(String[])&#125; to startup elasticsearch.</span><br><span class="line"> */</span><br><span class="line">static void init(</span><br><span class="line">        final boolean foreground,</span><br><span class="line">        final Path pidFile,</span><br><span class="line">        final boolean quiet,</span><br><span class="line">        final Environment initialEnv) throws BootstrapException, NodeValidationException, UserException &#123;</span><br><span class="line">    // force the class initializer for BootstrapInfo to run before</span><br><span class="line">    // the security manager is installed</span><br><span class="line">    BootstrapInfo.init();</span><br><span class="line"></span><br><span class="line">    INSTANCE = new Bootstrap();</span><br><span class="line"></span><br><span class="line">    final SecureSettings keystore = loadSecureSettings(initialEnv);</span><br><span class="line">    final Environment environment = createEnvironment(pidFile, keystore, initialEnv.settings(), initialEnv.configFile());</span><br><span class="line"></span><br><span class="line">    // the LogConfigurator will replace System.out and System.err with redirects to our logfile, so we need to capture</span><br><span class="line">    // the stream objects before calling LogConfigurator to be able to close them when appropriate</span><br><span class="line">    final Runnable sysOutCloser = getSysOutCloser();</span><br><span class="line">    final Runnable sysErrorCloser = getSysErrorCloser();</span><br><span class="line"></span><br><span class="line">    LogConfigurator.setNodeName(Node.NODE_NAME_SETTING.get(environment.settings()));</span><br><span class="line">    try &#123;</span><br><span class="line">        LogConfigurator.configure(environment);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        throw new BootstrapException(e);</span><br><span class="line">    &#125;</span><br><span class="line">    if (environment.pidFile() != null) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            PidFile.create(environment.pidFile(), true);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            throw new BootstrapException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        final boolean closeStandardStreams = (foreground == false) || quiet;</span><br><span class="line">        if (closeStandardStreams) &#123;</span><br><span class="line">            final Logger rootLogger = LogManager.getRootLogger();</span><br><span class="line">            final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class);</span><br><span class="line">            if (maybeConsoleAppender != null) &#123;</span><br><span class="line">                Loggers.removeAppender(rootLogger, maybeConsoleAppender);</span><br><span class="line">            &#125;</span><br><span class="line">            sysOutCloser.run();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // fail if somebody replaced the lucene jars</span><br><span class="line">        // 检查 Lucene 版本，ES 各个版本对使用的 Lucene 版本是有要求的</span><br><span class="line">        // 在这里检查Lucene版本以防止有人替换不兼容的jar包。</span><br><span class="line">        checkLucene();</span><br><span class="line"></span><br><span class="line">        // install the default uncaught exception handler; must be done before security is</span><br><span class="line">        // initialized as we do not want to grant the runtime permission</span><br><span class="line">        // setDefaultUncaughtExceptionHandler</span><br><span class="line">        // 会根据不同的异常，设置不同的exit code</span><br><span class="line">        // InternalError 128</span><br><span class="line">        // OutOfMemoryError 127</span><br><span class="line">        // StackOverflowError 126</span><br><span class="line">        // UnknownError 125</span><br><span class="line">        // IOError 124</span><br><span class="line">        // 其它 1</span><br><span class="line">        Thread.setDefaultUncaughtExceptionHandler(new ElasticsearchUncaughtExceptionHandler());</span><br><span class="line"></span><br><span class="line">        // 检查启动es的用户</span><br><span class="line">        // 检查JNA(系统调用)</span><br><span class="line">        // 检查MEMORY_LOCK</span><br><span class="line">        // 检查MaxNumberOfThreads</span><br><span class="line">        // 检查MaxSizeVirtualMemory</span><br><span class="line">        // 检查MaxFileSize</span><br><span class="line">        // init lucene random seed</span><br><span class="line">        // 注册JVM addShutdownHook(Node退出的时候，会用到)</span><br><span class="line">        // 检查jar冲突</span><br><span class="line">        // 初始化JVM Security</span><br><span class="line">        // Node实例添加validateNodeBeforeAcceptingRequests，并初始化Node实例。</span><br><span class="line">        INSTANCE.setup(true, environment);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            // any secure settings must be read during node construction</span><br><span class="line">            IOUtils.close(keystore);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            throw new BootstrapException(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 1、开始启动各子模块。</span><br><span class="line">        // 子模块在Node类中创建、启动</span><br><span class="line">        // 子模块的start方法基本就是初始化内部数据、创建线程池、启动线程池等操作。</span><br><span class="line">        // 2、调用keepAliveThread.start()方法启动keepalive线程，线程本身不做具体的工作。</span><br><span class="line">        // 主线程执行完启动流程后会退出，keepalive线程是唯一的用户线程，</span><br><span class="line">        // 作用是保持进程运行。在Java程序中，至少要有一个用户线程。当用户线程数为零时退出进程。</span><br><span class="line">        INSTANCE.start();</span><br><span class="line"></span><br><span class="line">        // We don&apos;t close stderr if `--quiet` is passed, because that</span><br><span class="line">        // hides fatal startup errors. For example, if Elasticsearch is</span><br><span class="line">        // running via systemd, the init script only specifies</span><br><span class="line">        // `--quiet`, not `-d`, so we want users to be able to see</span><br><span class="line">        // startup errors via journalctl.</span><br><span class="line">        if (foreground == false) &#123;</span><br><span class="line">            sysErrorCloser.run();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; catch (NodeValidationException | RuntimeException e) &#123;</span><br><span class="line">        // disable console logging, so user does not see the exception twice (jvm will show it already)</span><br><span class="line">        final Logger rootLogger = LogManager.getRootLogger();</span><br><span class="line">        final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class);</span><br><span class="line">        if (foreground &amp;&amp; maybeConsoleAppender != null) &#123;</span><br><span class="line">            Loggers.removeAppender(rootLogger, maybeConsoleAppender);</span><br><span class="line">        &#125;</span><br><span class="line">        Logger logger = LogManager.getLogger(Bootstrap.class);</span><br><span class="line">        // HACK, it sucks to do this, but we will run users out of disk space otherwise</span><br><span class="line">        if (e instanceof CreationException) &#123;</span><br><span class="line">            // guice: log the shortened exc to the log file</span><br><span class="line">            ByteArrayOutputStream os = new ByteArrayOutputStream();</span><br><span class="line">            PrintStream ps = null;</span><br><span class="line">            try &#123;</span><br><span class="line">                ps = new PrintStream(os, false, &quot;UTF-8&quot;);</span><br><span class="line">            &#125; catch (UnsupportedEncodingException uee) &#123;</span><br><span class="line">                assert false;</span><br><span class="line">                e.addSuppressed(uee);</span><br><span class="line">            &#125;</span><br><span class="line">            new StartupException(e).printStackTrace(ps);</span><br><span class="line">            ps.flush();</span><br><span class="line">            try &#123;</span><br><span class="line">                logger.error(&quot;Guice Exception: &#123;&#125;&quot;, os.toString(&quot;UTF-8&quot;));</span><br><span class="line">            &#125; catch (UnsupportedEncodingException uee) &#123;</span><br><span class="line">                assert false;</span><br><span class="line">                e.addSuppressed(uee);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else if (e instanceof NodeValidationException) &#123;</span><br><span class="line">            logger.error(&quot;node validation exception\n&#123;&#125;&quot;, e.getMessage());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // full exception</span><br><span class="line">            logger.error(&quot;Exception&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">        // re-enable it if appropriate, so they can see any logging during the shutdown process</span><br><span class="line">        if (foreground &amp;&amp; maybeConsoleAppender != null) &#123;</span><br><span class="line">            Loggers.addAppender(rootLogger, maybeConsoleAppender);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面看一下Node实例初始化及启动部分：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 环境变量中携带的信息主要节点的配置信息：</span><br><span class="line">  // dataFiles、configFile、pluginsFile、modulesFile等等</span><br><span class="line">  // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/env/Environment.java</span><br><span class="line">  public Node(Environment environment) &#123;</span><br><span class="line">    this(environment, Collections.emptyList(), true);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  /**</span><br><span class="line">   * Constructs a node</span><br><span class="line">   *</span><br><span class="line">   * @param initialEnvironment         the initial environment for this node, which will be added to by plugins</span><br><span class="line">   * @param classpathPlugins           the plugins to be loaded from the classpath</span><br><span class="line">   * @param forbidPrivateIndexSettings whether or not private index settings are forbidden when creating an index; this is used in the</span><br><span class="line">   *                                   test framework for tests that rely on being able to set private settings</span><br><span class="line">   */</span><br><span class="line">  protected Node(</span><br><span class="line">    final Environment initialEnvironment,</span><br><span class="line">    Collection&lt;Class&lt;? extends Plugin&gt;&gt; classpathPlugins,</span><br><span class="line">    boolean forbidPrivateIndexSettings</span><br><span class="line">  ) &#123;</span><br><span class="line">    final List&lt;Closeable&gt; resourcesToClose = new ArrayList&lt;&gt;(); // register everything we need to release in the case of an error</span><br><span class="line">    boolean success = false;</span><br><span class="line">    try &#123;</span><br><span class="line">      Settings tmpSettings = Settings</span><br><span class="line">        .builder()</span><br><span class="line">        .put(initialEnvironment.settings())</span><br><span class="line">        .put(Client.CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">      final JvmInfo jvmInfo = JvmInfo.jvmInfo();</span><br><span class="line">      logger.info(</span><br><span class="line">        &quot;version[&#123;&#125;], pid[&#123;&#125;], build[&#123;&#125;/&#123;&#125;/&#123;&#125;/&#123;&#125;], OS[&#123;&#125;/&#123;&#125;/&#123;&#125;], JVM[&#123;&#125;/&#123;&#125;/&#123;&#125;/&#123;&#125;]&quot;,</span><br><span class="line">        Build.CURRENT.getQualifiedVersion(),</span><br><span class="line">        jvmInfo.pid(),</span><br><span class="line">        Build.CURRENT.flavor().displayName(),</span><br><span class="line">        Build.CURRENT.type().displayName(),</span><br><span class="line">        Build.CURRENT.hash(),</span><br><span class="line">        Build.CURRENT.date(),</span><br><span class="line">        Constants.OS_NAME,</span><br><span class="line">        Constants.OS_VERSION,</span><br><span class="line">        Constants.OS_ARCH,</span><br><span class="line">        Constants.JVM_VENDOR,</span><br><span class="line">        Constants.JVM_NAME,</span><br><span class="line">        Constants.JAVA_VERSION,</span><br><span class="line">        Constants.JVM_VERSION</span><br><span class="line">      );</span><br><span class="line">      if (jvmInfo.getBundledJdk()) &#123;</span><br><span class="line">        logger.info(</span><br><span class="line">          &quot;JVM home [&#123;&#125;], using bundled JDK [&#123;&#125;]&quot;,</span><br><span class="line">          System.getProperty(&quot;java.home&quot;),</span><br><span class="line">          jvmInfo.getUsingBundledJdk()</span><br><span class="line">        );</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        logger.info(&quot;JVM home [&#123;&#125;]&quot;, System.getProperty(&quot;java.home&quot;));</span><br><span class="line">        deprecationLogger.deprecate(</span><br><span class="line">          &quot;no-jdk&quot;,</span><br><span class="line">          &quot;no-jdk distributions that do not bundle a JDK are deprecated and will be removed in a future release&quot;</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line">      logger.info(</span><br><span class="line">        &quot;JVM arguments &#123;&#125;&quot;,</span><br><span class="line">        Arrays.toString(jvmInfo.getInputArguments())</span><br><span class="line">      );</span><br><span class="line">      if (Build.CURRENT.isProductionRelease() == false) &#123;</span><br><span class="line">        logger.warn(</span><br><span class="line">          &quot;version [&#123;&#125;] is a pre-release version of Elasticsearch and is not suitable for production&quot;,</span><br><span class="line">          Build.CURRENT.getQualifiedVersion()</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if (logger.isDebugEnabled()) &#123;</span><br><span class="line">        logger.debug(</span><br><span class="line">          &quot;using config [&#123;&#125;], data [&#123;&#125;], logs [&#123;&#125;], plugins [&#123;&#125;]&quot;,</span><br><span class="line">          initialEnvironment.configFile(),</span><br><span class="line">          Arrays.toString(initialEnvironment.dataFiles()),</span><br><span class="line">          initialEnvironment.logsFile(),</span><br><span class="line">          initialEnvironment.pluginsFile()</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      // 创建PluginsService，加载modules目录下的所有模块和plugins目录下的所有插件</span><br><span class="line">      // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/plugins/PluginsService.java</span><br><span class="line">      this.pluginsService =</span><br><span class="line">        new PluginsService(</span><br><span class="line">          tmpSettings,</span><br><span class="line">          initialEnvironment.configFile(),</span><br><span class="line">          initialEnvironment.modulesFile(),</span><br><span class="line">          initialEnvironment.pluginsFile(),</span><br><span class="line">          classpathPlugins</span><br><span class="line">        );</span><br><span class="line">      final Settings settings = pluginsService.updatedSettings();</span><br><span class="line"></span><br><span class="line">      final Set&lt;DiscoveryNodeRole&gt; additionalRoles = pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(Plugin::getRoles)</span><br><span class="line">        .flatMap(Set::stream)</span><br><span class="line">        .collect(Collectors.toSet());</span><br><span class="line">      DiscoveryNode.setAdditionalRoles(additionalRoles);</span><br><span class="line"></span><br><span class="line">      /*</span><br><span class="line">       * Create the environment based on the finalized view of the settings. This is to ensure that components get the same setting</span><br><span class="line">       * values, no matter they ask for them from.</span><br><span class="line">       */</span><br><span class="line">      this.environment =</span><br><span class="line">        new Environment(settings, initialEnvironment.configFile());</span><br><span class="line">      Environment.assertEquivalent(initialEnvironment, this.environment);</span><br><span class="line">      nodeEnvironment = new NodeEnvironment(tmpSettings, environment);</span><br><span class="line">      logger.info(</span><br><span class="line">        &quot;node name [&#123;&#125;], node ID [&#123;&#125;], cluster name [&#123;&#125;], roles &#123;&#125;&quot;,</span><br><span class="line">        NODE_NAME_SETTING.get(tmpSettings),</span><br><span class="line">        nodeEnvironment.nodeId(),</span><br><span class="line">        ClusterName.CLUSTER_NAME_SETTING.get(tmpSettings).value(),</span><br><span class="line">        DiscoveryNode</span><br><span class="line">          .getRolesFromSettings(settings)</span><br><span class="line">          .stream()</span><br><span class="line">          .map(DiscoveryNodeRole::roleName)</span><br><span class="line">          .collect(Collectors.toCollection(LinkedHashSet::new))</span><br><span class="line">      );</span><br><span class="line">      resourcesToClose.add(nodeEnvironment);</span><br><span class="line">      localNodeFactory =</span><br><span class="line">        new LocalNodeFactory(settings, nodeEnvironment.nodeId());</span><br><span class="line"></span><br><span class="line">      // 调用各插件的getExecutorBuilders，获取ExecutorBuilder</span><br><span class="line">      final List&lt;ExecutorBuilder&lt;?&gt;&gt; executorBuilders = pluginsService.getExecutorBuilders(</span><br><span class="line">        settings</span><br><span class="line">      );</span><br><span class="line">      // 创建线程池</span><br><span class="line">      final ThreadPool threadPool = new ThreadPool(</span><br><span class="line">        settings,</span><br><span class="line">        executorBuilders.toArray(new ExecutorBuilder[0])</span><br><span class="line">      );</span><br><span class="line">      resourcesToClose.add(</span><br><span class="line">        () -&gt; ThreadPool.terminate(threadPool, 10, TimeUnit.SECONDS)</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final ResourceWatcherService resourceWatcherService = new ResourceWatcherService(</span><br><span class="line">        settings,</span><br><span class="line">        threadPool</span><br><span class="line">      );</span><br><span class="line">      resourcesToClose.add(resourceWatcherService);</span><br><span class="line">      // adds the context to the DeprecationLogger so that it does not need to be injected everywhere</span><br><span class="line">      HeaderWarning.setThreadContext(threadPool.getThreadContext());</span><br><span class="line">      resourcesToClose.add(</span><br><span class="line">        () -&gt; HeaderWarning.removeThreadContext(threadPool.getThreadContext())</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final List&lt;Setting&lt;?&gt;&gt; additionalSettings = new ArrayList&lt;&gt;();</span><br><span class="line">      // register the node.data, node.ingest, node.master, node.remote_cluster_client settings here so we can mark them private</span><br><span class="line">      additionalSettings.add(NODE_DATA_SETTING);</span><br><span class="line">      additionalSettings.add(NODE_INGEST_SETTING);</span><br><span class="line">      additionalSettings.add(NODE_MASTER_SETTING);</span><br><span class="line">      additionalSettings.add(NODE_REMOTE_CLUSTER_CLIENT);</span><br><span class="line">      additionalSettings.addAll(pluginsService.getPluginSettings());</span><br><span class="line">      final List&lt;String&gt; additionalSettingsFilter = new ArrayList&lt;&gt;(</span><br><span class="line">        pluginsService.getPluginSettingsFilter()</span><br><span class="line">      );</span><br><span class="line">      for (final ExecutorBuilder&lt;?&gt; builder : threadPool.builders()) &#123;</span><br><span class="line">        additionalSettings.addAll(builder.getRegisteredSettings());</span><br><span class="line">      &#125;</span><br><span class="line">      // 创建NodeClient</span><br><span class="line">      client = new NodeClient(settings, threadPool);</span><br><span class="line"></span><br><span class="line">      // 创建各种***Service对象和各种模***Module对象</span><br><span class="line">      final ScriptModule scriptModule = new ScriptModule(</span><br><span class="line">        settings,</span><br><span class="line">        pluginsService.filterPlugins(ScriptPlugin.class)</span><br><span class="line">      );</span><br><span class="line">      final ScriptService scriptService = newScriptService(</span><br><span class="line">        settings,</span><br><span class="line">        scriptModule.engines,</span><br><span class="line">        scriptModule.contexts</span><br><span class="line">      );</span><br><span class="line">      AnalysisModule analysisModule = new AnalysisModule(</span><br><span class="line">        this.environment,</span><br><span class="line">        pluginsService.filterPlugins(AnalysisPlugin.class)</span><br><span class="line">      );</span><br><span class="line">      // this is as early as we can validate settings at this point. we already pass them to ScriptModule as well as ThreadPool</span><br><span class="line">      // so we might be late here already</span><br><span class="line"></span><br><span class="line">      final Set&lt;SettingUpgrader&lt;?&gt;&gt; settingsUpgraders = pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(Plugin::getSettingUpgraders)</span><br><span class="line">        .flatMap(List::stream)</span><br><span class="line">        .collect(Collectors.toSet());</span><br><span class="line"></span><br><span class="line">      final SettingsModule settingsModule = new SettingsModule(</span><br><span class="line">        settings,</span><br><span class="line">        additionalSettings,</span><br><span class="line">        additionalSettingsFilter,</span><br><span class="line">        settingsUpgraders</span><br><span class="line">      );</span><br><span class="line">      scriptModule.registerClusterSettingsListeners(</span><br><span class="line">        scriptService,</span><br><span class="line">        settingsModule.getClusterSettings()</span><br><span class="line">      );</span><br><span class="line">      final NetworkService networkService = new NetworkService(</span><br><span class="line">        getCustomNameResolvers(</span><br><span class="line">          pluginsService.filterPlugins(DiscoveryPlugin.class)</span><br><span class="line">        )</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      List&lt;ClusterPlugin&gt; clusterPlugins = pluginsService.filterPlugins(</span><br><span class="line">        ClusterPlugin.class</span><br><span class="line">      );</span><br><span class="line">      final ClusterService clusterService = new ClusterService(</span><br><span class="line">        settings,</span><br><span class="line">        settingsModule.getClusterSettings(),</span><br><span class="line">        threadPool</span><br><span class="line">      );</span><br><span class="line">      clusterService.addStateApplier(scriptService);</span><br><span class="line">      resourcesToClose.add(clusterService);</span><br><span class="line">      final Set&lt;Setting&lt;?&gt;&gt; consistentSettings = settingsModule.getConsistentSettings();</span><br><span class="line">      if (consistentSettings.isEmpty() == false) &#123;</span><br><span class="line">        clusterService.addLocalNodeMasterListener(</span><br><span class="line">          new ConsistentSettingsService(</span><br><span class="line">            settings,</span><br><span class="line">            clusterService,</span><br><span class="line">            consistentSettings</span><br><span class="line">          )</span><br><span class="line">            .newHashPublisher()</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line">      final IngestService ingestService = new IngestService(</span><br><span class="line">        clusterService,</span><br><span class="line">        threadPool,</span><br><span class="line">        this.environment,</span><br><span class="line">        scriptService,</span><br><span class="line">        analysisModule.getAnalysisRegistry(),</span><br><span class="line">        pluginsService.filterPlugins(IngestPlugin.class),</span><br><span class="line">        client</span><br><span class="line">      );</span><br><span class="line">      final SetOnce&lt;RepositoriesService&gt; repositoriesServiceReference = new SetOnce&lt;&gt;();</span><br><span class="line">      final ClusterInfoService clusterInfoService = newClusterInfoService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        threadPool,</span><br><span class="line">        client</span><br><span class="line">      );</span><br><span class="line">      final UsageService usageService = new UsageService();</span><br><span class="line"></span><br><span class="line">      ModulesBuilder modules = new ModulesBuilder();</span><br><span class="line">      final MonitorService monitorService = new MonitorService(</span><br><span class="line">        settings,</span><br><span class="line">        nodeEnvironment,</span><br><span class="line">        threadPool</span><br><span class="line">      );</span><br><span class="line">      final FsHealthService fsHealthService = new FsHealthService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService.getClusterSettings(),</span><br><span class="line">        threadPool,</span><br><span class="line">        nodeEnvironment</span><br><span class="line">      );</span><br><span class="line">      final SetOnce&lt;RerouteService&gt; rerouteServiceReference = new SetOnce&lt;&gt;();</span><br><span class="line">      final InternalSnapshotsInfoService snapshotsInfoService = new InternalSnapshotsInfoService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        repositoriesServiceReference::get,</span><br><span class="line">        rerouteServiceReference::get</span><br><span class="line">      );</span><br><span class="line">      final ClusterModule clusterModule = new ClusterModule(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        clusterPlugins,</span><br><span class="line">        clusterInfoService,</span><br><span class="line">        snapshotsInfoService,</span><br><span class="line">        threadPool.getThreadContext()</span><br><span class="line">      );</span><br><span class="line">      modules.add(clusterModule);</span><br><span class="line">      IndicesModule indicesModule = new IndicesModule(</span><br><span class="line">        pluginsService.filterPlugins(MapperPlugin.class)</span><br><span class="line">      );</span><br><span class="line">      modules.add(indicesModule);</span><br><span class="line"></span><br><span class="line">      SearchModule searchModule = new SearchModule(</span><br><span class="line">        settings,</span><br><span class="line">        pluginsService.filterPlugins(SearchPlugin.class)</span><br><span class="line">      );</span><br><span class="line">      List&lt;BreakerSettings&gt; pluginCircuitBreakers = pluginsService</span><br><span class="line">        .filterPlugins(CircuitBreakerPlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(plugin -&gt; plugin.getCircuitBreaker(settings))</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line">      final CircuitBreakerService circuitBreakerService = createCircuitBreakerService(</span><br><span class="line">        settingsModule.getSettings(),</span><br><span class="line">        pluginCircuitBreakers,</span><br><span class="line">        settingsModule.getClusterSettings()</span><br><span class="line">      );</span><br><span class="line">      pluginsService</span><br><span class="line">        .filterPlugins(CircuitBreakerPlugin.class)</span><br><span class="line">        .forEach(</span><br><span class="line">          plugin -&gt; &#123;</span><br><span class="line">            CircuitBreaker breaker = circuitBreakerService.getBreaker(</span><br><span class="line">              plugin.getCircuitBreaker(settings).getName()</span><br><span class="line">            );</span><br><span class="line">            plugin.setCircuitBreaker(breaker);</span><br><span class="line">          &#125;</span><br><span class="line">        );</span><br><span class="line">      resourcesToClose.add(circuitBreakerService);</span><br><span class="line">      modules.add(new GatewayModule());</span><br><span class="line"></span><br><span class="line">      PageCacheRecycler pageCacheRecycler = createPageCacheRecycler(settings);</span><br><span class="line">      BigArrays bigArrays = createBigArrays(</span><br><span class="line">        pageCacheRecycler,</span><br><span class="line">        circuitBreakerService</span><br><span class="line">      );</span><br><span class="line">      modules.add(settingsModule);</span><br><span class="line">      List&lt;NamedWriteableRegistry.Entry&gt; namedWriteables = Stream</span><br><span class="line">        .of(</span><br><span class="line">          NetworkModule.getNamedWriteables().stream(),</span><br><span class="line">          IndicesModule.getNamedWriteables().stream(),</span><br><span class="line">          searchModule.getNamedWriteables().stream(),</span><br><span class="line">          pluginsService</span><br><span class="line">            .filterPlugins(Plugin.class)</span><br><span class="line">            .stream()</span><br><span class="line">            .flatMap(p -&gt; p.getNamedWriteables().stream()),</span><br><span class="line">          ClusterModule.getNamedWriteables().stream()</span><br><span class="line">        )</span><br><span class="line">        .flatMap(Function.identity())</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line">      final NamedWriteableRegistry namedWriteableRegistry = new NamedWriteableRegistry(</span><br><span class="line">        namedWriteables</span><br><span class="line">      );</span><br><span class="line">      NamedXContentRegistry xContentRegistry = new NamedXContentRegistry(</span><br><span class="line">        Stream</span><br><span class="line">          .of(</span><br><span class="line">            NetworkModule.getNamedXContents().stream(),</span><br><span class="line">            IndicesModule.getNamedXContents().stream(),</span><br><span class="line">            searchModule.getNamedXContents().stream(),</span><br><span class="line">            pluginsService</span><br><span class="line">              .filterPlugins(Plugin.class)</span><br><span class="line">              .stream()</span><br><span class="line">              .flatMap(p -&gt; p.getNamedXContent().stream()),</span><br><span class="line">            ClusterModule.getNamedXWriteables().stream()</span><br><span class="line">          )</span><br><span class="line">          .flatMap(Function.identity())</span><br><span class="line">          .collect(toList())</span><br><span class="line">      );</span><br><span class="line">      final MetaStateService metaStateService = new MetaStateService(</span><br><span class="line">        nodeEnvironment,</span><br><span class="line">        xContentRegistry</span><br><span class="line">      );</span><br><span class="line">      final PersistedClusterStateService lucenePersistedStateFactory = new PersistedClusterStateService(</span><br><span class="line">        nodeEnvironment,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        bigArrays,</span><br><span class="line">        clusterService.getClusterSettings(),</span><br><span class="line">        threadPool::relativeTimeInMillis</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      // collect engine factory providers from plugins</span><br><span class="line">      final Collection&lt;EnginePlugin&gt; enginePlugins = pluginsService.filterPlugins(</span><br><span class="line">        EnginePlugin.class</span><br><span class="line">      );</span><br><span class="line">      final Collection&lt;Function&lt;IndexSettings, Optional&lt;EngineFactory&gt;&gt;&gt; engineFactoryProviders = enginePlugins</span><br><span class="line">        .stream()</span><br><span class="line">        .map(</span><br><span class="line">          plugin -&gt;</span><br><span class="line">            (Function&lt;IndexSettings, Optional&lt;EngineFactory&gt;&gt;) plugin::getEngineFactory</span><br><span class="line">        )</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line">      final Map&lt;String, IndexStorePlugin.DirectoryFactory&gt; indexStoreFactories = pluginsService</span><br><span class="line">        .filterPlugins(IndexStorePlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(IndexStorePlugin::getDirectoryFactories)</span><br><span class="line">        .flatMap(m -&gt; m.entrySet().stream())</span><br><span class="line">        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));</span><br><span class="line"></span><br><span class="line">      final Map&lt;String, IndexStorePlugin.RecoveryStateFactory&gt; recoveryStateFactories = pluginsService</span><br><span class="line">        .filterPlugins(IndexStorePlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(IndexStorePlugin::getRecoveryStateFactories)</span><br><span class="line">        .flatMap(m -&gt; m.entrySet().stream())</span><br><span class="line">        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));</span><br><span class="line"></span><br><span class="line">      final List&lt;IndexStorePlugin.IndexFoldersDeletionListener&gt; indexFoldersDeletionListeners = pluginsService</span><br><span class="line">        .filterPlugins(IndexStorePlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(IndexStorePlugin::getIndexFoldersDeletionListeners)</span><br><span class="line">        .flatMap(List::stream)</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line">      final Map&lt;String, IndexStorePlugin.SnapshotCommitSupplier&gt; snapshotCommitSuppliers = pluginsService</span><br><span class="line">        .filterPlugins(IndexStorePlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(IndexStorePlugin::getSnapshotCommitSuppliers)</span><br><span class="line">        .flatMap(m -&gt; m.entrySet().stream())</span><br><span class="line">        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));</span><br><span class="line"></span><br><span class="line">      final Map&lt;String, Collection&lt;SystemIndexDescriptor&gt;&gt; systemIndexDescriptorMap = pluginsService</span><br><span class="line">        .filterPlugins(SystemIndexPlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .collect(</span><br><span class="line">          Collectors.toUnmodifiableMap(</span><br><span class="line">            plugin -&gt; plugin.getClass().getSimpleName(),</span><br><span class="line">            plugin -&gt; plugin.getSystemIndexDescriptors(settings)</span><br><span class="line">          )</span><br><span class="line">        );</span><br><span class="line">      final SystemIndices systemIndices = new SystemIndices(</span><br><span class="line">        systemIndexDescriptorMap</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final SystemIndexManager systemIndexManager = new SystemIndexManager(</span><br><span class="line">        systemIndices,</span><br><span class="line">        client</span><br><span class="line">      );</span><br><span class="line">      clusterService.addListener(systemIndexManager);</span><br><span class="line"></span><br><span class="line">      final RerouteService rerouteService = new BatchedRerouteService(</span><br><span class="line">        clusterService,</span><br><span class="line">        clusterModule.getAllocationService()::reroute</span><br><span class="line">      );</span><br><span class="line">      rerouteServiceReference.set(rerouteService);</span><br><span class="line">      clusterService.setRerouteService(rerouteService);</span><br><span class="line"></span><br><span class="line">      final IndicesService indicesService = new IndicesService(</span><br><span class="line">        settings,</span><br><span class="line">        pluginsService,</span><br><span class="line">        nodeEnvironment,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        analysisModule.getAnalysisRegistry(),</span><br><span class="line">        clusterModule.getIndexNameExpressionResolver(),</span><br><span class="line">        indicesModule.getMapperRegistry(),</span><br><span class="line">        namedWriteableRegistry,</span><br><span class="line">        threadPool,</span><br><span class="line">        settingsModule.getIndexScopedSettings(),</span><br><span class="line">        circuitBreakerService,</span><br><span class="line">        bigArrays,</span><br><span class="line">        scriptService,</span><br><span class="line">        clusterService,</span><br><span class="line">        client,</span><br><span class="line">        metaStateService,</span><br><span class="line">        engineFactoryProviders,</span><br><span class="line">        indexStoreFactories,</span><br><span class="line">        searchModule.getValuesSourceRegistry(),</span><br><span class="line">        recoveryStateFactories,</span><br><span class="line">        indexFoldersDeletionListeners,</span><br><span class="line">        snapshotCommitSuppliers</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final AliasValidator aliasValidator = new AliasValidator();</span><br><span class="line"></span><br><span class="line">      final ShardLimitValidator shardLimitValidator = new ShardLimitValidator(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService</span><br><span class="line">      );</span><br><span class="line">      final MetadataCreateIndexService metadataCreateIndexService = new MetadataCreateIndexService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        indicesService,</span><br><span class="line">        clusterModule.getAllocationService(),</span><br><span class="line">        aliasValidator,</span><br><span class="line">        shardLimitValidator,</span><br><span class="line">        environment,</span><br><span class="line">        settingsModule.getIndexScopedSettings(),</span><br><span class="line">        threadPool,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        systemIndices,</span><br><span class="line">        forbidPrivateIndexSettings</span><br><span class="line">      );</span><br><span class="line">      pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .forEach(</span><br><span class="line">          p -&gt;</span><br><span class="line">            p</span><br><span class="line">              .getAdditionalIndexSettingProviders()</span><br><span class="line">              .forEach(</span><br><span class="line">                metadataCreateIndexService::addAdditionalIndexSettingProvider</span><br><span class="line">              )</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">      final MetadataCreateDataStreamService metadataCreateDataStreamService = new MetadataCreateDataStreamService(</span><br><span class="line">        threadPool,</span><br><span class="line">        clusterService,</span><br><span class="line">        metadataCreateIndexService</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      Collection&lt;Object&gt; pluginComponents = pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .flatMap(</span><br><span class="line">          p -&gt;</span><br><span class="line">            p</span><br><span class="line">              .createComponents(</span><br><span class="line">                client,</span><br><span class="line">                clusterService,</span><br><span class="line">                threadPool,</span><br><span class="line">                resourceWatcherService,</span><br><span class="line">                scriptService,</span><br><span class="line">                xContentRegistry,</span><br><span class="line">                environment,</span><br><span class="line">                nodeEnvironment,</span><br><span class="line">                namedWriteableRegistry,</span><br><span class="line">                clusterModule.getIndexNameExpressionResolver(),</span><br><span class="line">                repositoriesServiceReference::get</span><br><span class="line">              )</span><br><span class="line">              .stream()</span><br><span class="line">        )</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line">      ActionModule actionModule = new ActionModule(</span><br><span class="line">        settings,</span><br><span class="line">        clusterModule.getIndexNameExpressionResolver(),</span><br><span class="line">        settingsModule.getIndexScopedSettings(),</span><br><span class="line">        settingsModule.getClusterSettings(),</span><br><span class="line">        settingsModule.getSettingsFilter(),</span><br><span class="line">        threadPool,</span><br><span class="line">        pluginsService.filterPlugins(ActionPlugin.class),</span><br><span class="line">        client,</span><br><span class="line">        circuitBreakerService,</span><br><span class="line">        usageService,</span><br><span class="line">        systemIndices,</span><br><span class="line">        getRestCompatibleFunction()</span><br><span class="line">      );</span><br><span class="line">      modules.add(actionModule);</span><br><span class="line"></span><br><span class="line">      final RestController restController = actionModule.getRestController();</span><br><span class="line">      final NetworkModule networkModule = new NetworkModule(</span><br><span class="line">        settings,</span><br><span class="line">        pluginsService.filterPlugins(NetworkPlugin.class),</span><br><span class="line">        threadPool,</span><br><span class="line">        bigArrays,</span><br><span class="line">        pageCacheRecycler,</span><br><span class="line">        circuitBreakerService,</span><br><span class="line">        namedWriteableRegistry,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        networkService,</span><br><span class="line">        restController,</span><br><span class="line">        clusterService.getClusterSettings()</span><br><span class="line">      );</span><br><span class="line">      Collection&lt;UnaryOperator&lt;Map&lt;String, IndexTemplateMetadata&gt;&gt;&gt; indexTemplateMetadataUpgraders = pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(Plugin::getIndexTemplateMetadataUpgrader)</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line">      final MetadataUpgrader metadataUpgrader = new MetadataUpgrader(</span><br><span class="line">        indexTemplateMetadataUpgraders</span><br><span class="line">      );</span><br><span class="line">      final MetadataIndexUpgradeService metadataIndexUpgradeService = new MetadataIndexUpgradeService(</span><br><span class="line">        settings,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        indicesModule.getMapperRegistry(),</span><br><span class="line">        settingsModule.getIndexScopedSettings(),</span><br><span class="line">        systemIndices,</span><br><span class="line">        scriptService</span><br><span class="line">      );</span><br><span class="line">      if (DiscoveryNode.isMasterNode(settings)) &#123;</span><br><span class="line">        clusterService.addListener(</span><br><span class="line">          new SystemIndexMetadataUpgradeService(systemIndices, clusterService)</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line">      new TemplateUpgradeService(</span><br><span class="line">        client,</span><br><span class="line">        clusterService,</span><br><span class="line">        threadPool,</span><br><span class="line">        indexTemplateMetadataUpgraders</span><br><span class="line">      );</span><br><span class="line">      final Transport transport = networkModule.getTransportSupplier().get();</span><br><span class="line">      Set&lt;String&gt; taskHeaders = Stream</span><br><span class="line">        .concat(</span><br><span class="line">          pluginsService</span><br><span class="line">            .filterPlugins(ActionPlugin.class)</span><br><span class="line">            .stream()</span><br><span class="line">            .flatMap(p -&gt; p.getTaskHeaders().stream()),</span><br><span class="line">          Stream.of(Task.X_OPAQUE_ID)</span><br><span class="line">        )</span><br><span class="line">        .collect(Collectors.toSet());</span><br><span class="line">      final TransportService transportService = newTransportService(</span><br><span class="line">        settings,</span><br><span class="line">        transport,</span><br><span class="line">        threadPool,</span><br><span class="line">        networkModule.getTransportInterceptor(),</span><br><span class="line">        localNodeFactory,</span><br><span class="line">        settingsModule.getClusterSettings(),</span><br><span class="line">        taskHeaders</span><br><span class="line">      );</span><br><span class="line">      final GatewayMetaState gatewayMetaState = new GatewayMetaState();</span><br><span class="line">      final ResponseCollectorService responseCollectorService = new ResponseCollectorService(</span><br><span class="line">        clusterService</span><br><span class="line">      );</span><br><span class="line">      final SearchTransportService searchTransportService = new SearchTransportService(</span><br><span class="line">        transportService,</span><br><span class="line">        client,</span><br><span class="line">        SearchExecutionStatsCollector.makeWrapper(responseCollectorService)</span><br><span class="line">      );</span><br><span class="line">      final HttpServerTransport httpServerTransport = newHttpTransport(</span><br><span class="line">        networkModule</span><br><span class="line">      );</span><br><span class="line">      final IndexingPressure indexingLimits = new IndexingPressure(settings);</span><br><span class="line"></span><br><span class="line">      final RecoverySettings recoverySettings = new RecoverySettings(</span><br><span class="line">        settings,</span><br><span class="line">        settingsModule.getClusterSettings()</span><br><span class="line">      );</span><br><span class="line">      RepositoriesModule repositoriesModule = new RepositoriesModule(</span><br><span class="line">        this.environment,</span><br><span class="line">        pluginsService.filterPlugins(RepositoryPlugin.class),</span><br><span class="line">        transportService,</span><br><span class="line">        clusterService,</span><br><span class="line">        bigArrays,</span><br><span class="line">        xContentRegistry,</span><br><span class="line">        recoverySettings</span><br><span class="line">      );</span><br><span class="line">      RepositoriesService repositoryService = repositoriesModule.getRepositoryService();</span><br><span class="line">      repositoriesServiceReference.set(repositoryService);</span><br><span class="line">      SnapshotsService snapshotsService = new SnapshotsService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        clusterModule.getIndexNameExpressionResolver(),</span><br><span class="line">        repositoryService,</span><br><span class="line">        transportService,</span><br><span class="line">        actionModule.getActionFilters()</span><br><span class="line">      );</span><br><span class="line">      SnapshotShardsService snapshotShardsService = new SnapshotShardsService(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService,</span><br><span class="line">        repositoryService,</span><br><span class="line">        transportService,</span><br><span class="line">        indicesService</span><br><span class="line">      );</span><br><span class="line">      RestoreService restoreService = new RestoreService(</span><br><span class="line">        clusterService,</span><br><span class="line">        repositoryService,</span><br><span class="line">        clusterModule.getAllocationService(),</span><br><span class="line">        metadataCreateIndexService,</span><br><span class="line">        metadataIndexUpgradeService,</span><br><span class="line">        clusterService.getClusterSettings(),</span><br><span class="line">        shardLimitValidator</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final DiskThresholdMonitor diskThresholdMonitor = new DiskThresholdMonitor(</span><br><span class="line">        settings,</span><br><span class="line">        clusterService::state,</span><br><span class="line">        clusterService.getClusterSettings(),</span><br><span class="line">        client,</span><br><span class="line">        threadPool::relativeTimeInMillis,</span><br><span class="line">        rerouteService</span><br><span class="line">      );</span><br><span class="line">      clusterInfoService.addListener(diskThresholdMonitor::onNewInfo);</span><br><span class="line"></span><br><span class="line">      final DiscoveryModule discoveryModule = new DiscoveryModule(</span><br><span class="line">        settings,</span><br><span class="line">        transportService,</span><br><span class="line">        namedWriteableRegistry,</span><br><span class="line">        networkService,</span><br><span class="line">        clusterService.getMasterService(),</span><br><span class="line">        clusterService.getClusterApplierService(),</span><br><span class="line">        clusterService.getClusterSettings(),</span><br><span class="line">        pluginsService.filterPlugins(DiscoveryPlugin.class),</span><br><span class="line">        clusterModule.getAllocationService(),</span><br><span class="line">        environment.configFile(),</span><br><span class="line">        gatewayMetaState,</span><br><span class="line">        rerouteService,</span><br><span class="line">        fsHealthService</span><br><span class="line">      );</span><br><span class="line">      this.nodeService =</span><br><span class="line">        new NodeService(</span><br><span class="line">          settings,</span><br><span class="line">          threadPool,</span><br><span class="line">          monitorService,</span><br><span class="line">          discoveryModule.getDiscovery(),</span><br><span class="line">          transportService,</span><br><span class="line">          indicesService,</span><br><span class="line">          pluginsService,</span><br><span class="line">          circuitBreakerService,</span><br><span class="line">          scriptService,</span><br><span class="line">          httpServerTransport,</span><br><span class="line">          ingestService,</span><br><span class="line">          clusterService,</span><br><span class="line">          settingsModule.getSettingsFilter(),</span><br><span class="line">          responseCollectorService,</span><br><span class="line">          searchTransportService,</span><br><span class="line">          indexingLimits,</span><br><span class="line">          searchModule.getValuesSourceRegistry().getUsageService()</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">      final SearchService searchService = newSearchService(</span><br><span class="line">        clusterService,</span><br><span class="line">        indicesService,</span><br><span class="line">        threadPool,</span><br><span class="line">        scriptService,</span><br><span class="line">        bigArrays,</span><br><span class="line">        searchModule.getFetchPhase(),</span><br><span class="line">        responseCollectorService,</span><br><span class="line">        circuitBreakerService</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      final List&lt;PersistentTasksExecutor&lt;?&gt;&gt; tasksExecutors = pluginsService</span><br><span class="line">        .filterPlugins(PersistentTaskPlugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .map(</span><br><span class="line">          p -&gt;</span><br><span class="line">            p.getPersistentTasksExecutor(</span><br><span class="line">              clusterService,</span><br><span class="line">              threadPool,</span><br><span class="line">              client,</span><br><span class="line">              settingsModule,</span><br><span class="line">              clusterModule.getIndexNameExpressionResolver()</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        .flatMap(List::stream)</span><br><span class="line">        .collect(toList());</span><br><span class="line"></span><br><span class="line">      final PersistentTasksExecutorRegistry registry = new PersistentTasksExecutorRegistry(</span><br><span class="line">        tasksExecutors</span><br><span class="line">      );</span><br><span class="line">      final PersistentTasksClusterService persistentTasksClusterService = new PersistentTasksClusterService(</span><br><span class="line">        settings,</span><br><span class="line">        registry,</span><br><span class="line">        clusterService,</span><br><span class="line">        threadPool</span><br><span class="line">      );</span><br><span class="line">      resourcesToClose.add(persistentTasksClusterService);</span><br><span class="line">      final PersistentTasksService persistentTasksService = new PersistentTasksService(</span><br><span class="line">        clusterService,</span><br><span class="line">        threadPool,</span><br><span class="line">        client</span><br><span class="line">      );</span><br><span class="line">      // 绑定各种服务模块的实例</span><br><span class="line">      modules.add(</span><br><span class="line">        b -&gt; &#123;</span><br><span class="line">          b.bind(Node.class).toInstance(this);</span><br><span class="line">          b.bind(NodeService.class).toInstance(nodeService);</span><br><span class="line">          b.bind(NamedXContentRegistry.class).toInstance(xContentRegistry);</span><br><span class="line">          b.bind(PluginsService.class).toInstance(pluginsService);</span><br><span class="line">          b.bind(Client.class).toInstance(client);</span><br><span class="line">          b.bind(NodeClient.class).toInstance(client);</span><br><span class="line">          b.bind(Environment.class).toInstance(this.environment);</span><br><span class="line">          b.bind(ThreadPool.class).toInstance(threadPool);</span><br><span class="line">          b.bind(NodeEnvironment.class).toInstance(nodeEnvironment);</span><br><span class="line">          b</span><br><span class="line">            .bind(ResourceWatcherService.class)</span><br><span class="line">            .toInstance(resourceWatcherService);</span><br><span class="line">          b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);</span><br><span class="line">          b.bind(BigArrays.class).toInstance(bigArrays);</span><br><span class="line">          b.bind(PageCacheRecycler.class).toInstance(pageCacheRecycler);</span><br><span class="line">          b.bind(ScriptService.class).toInstance(scriptService);</span><br><span class="line">          b</span><br><span class="line">            .bind(AnalysisRegistry.class)</span><br><span class="line">            .toInstance(analysisModule.getAnalysisRegistry());</span><br><span class="line">          b.bind(IngestService.class).toInstance(ingestService);</span><br><span class="line">          b.bind(IndexingPressure.class).toInstance(indexingLimits);</span><br><span class="line">          b.bind(UsageService.class).toInstance(usageService);</span><br><span class="line">          b</span><br><span class="line">            .bind(AggregationUsageService.class)</span><br><span class="line">            .toInstance(</span><br><span class="line">              searchModule.getValuesSourceRegistry().getUsageService()</span><br><span class="line">            );</span><br><span class="line">          b</span><br><span class="line">            .bind(NamedWriteableRegistry.class)</span><br><span class="line">            .toInstance(namedWriteableRegistry);</span><br><span class="line">          b.bind(MetadataUpgrader.class).toInstance(metadataUpgrader);</span><br><span class="line">          b.bind(MetaStateService.class).toInstance(metaStateService);</span><br><span class="line">          b</span><br><span class="line">            .bind(PersistedClusterStateService.class)</span><br><span class="line">            .toInstance(lucenePersistedStateFactory);</span><br><span class="line">          b.bind(IndicesService.class).toInstance(indicesService);</span><br><span class="line">          b.bind(AliasValidator.class).toInstance(aliasValidator);</span><br><span class="line">          b</span><br><span class="line">            .bind(MetadataCreateIndexService.class)</span><br><span class="line">            .toInstance(metadataCreateIndexService);</span><br><span class="line">          b</span><br><span class="line">            .bind(MetadataCreateDataStreamService.class)</span><br><span class="line">            .toInstance(metadataCreateDataStreamService);</span><br><span class="line">          b.bind(SearchService.class).toInstance(searchService);</span><br><span class="line">          b</span><br><span class="line">            .bind(SearchTransportService.class)</span><br><span class="line">            .toInstance(searchTransportService);</span><br><span class="line">          b</span><br><span class="line">            .bind(SearchPhaseController.class)</span><br><span class="line">            .toInstance(</span><br><span class="line">              new SearchPhaseController(</span><br><span class="line">                namedWriteableRegistry,</span><br><span class="line">                searchService::aggReduceContextBuilder</span><br><span class="line">              )</span><br><span class="line">            );</span><br><span class="line">          b.bind(Transport.class).toInstance(transport);</span><br><span class="line">          b.bind(TransportService.class).toInstance(transportService);</span><br><span class="line">          b.bind(NetworkService.class).toInstance(networkService);</span><br><span class="line">          b</span><br><span class="line">            .bind(UpdateHelper.class)</span><br><span class="line">            .toInstance(new UpdateHelper(scriptService));</span><br><span class="line">          b</span><br><span class="line">            .bind(MetadataIndexUpgradeService.class)</span><br><span class="line">            .toInstance(metadataIndexUpgradeService);</span><br><span class="line">          b.bind(ClusterInfoService.class).toInstance(clusterInfoService);</span><br><span class="line">          b.bind(SnapshotsInfoService.class).toInstance(snapshotsInfoService);</span><br><span class="line">          b.bind(GatewayMetaState.class).toInstance(gatewayMetaState);</span><br><span class="line">          b.bind(Discovery.class).toInstance(discoveryModule.getDiscovery());</span><br><span class="line">          &#123;</span><br><span class="line">            processRecoverySettings(</span><br><span class="line">              settingsModule.getClusterSettings(),</span><br><span class="line">              recoverySettings</span><br><span class="line">            );</span><br><span class="line">            b</span><br><span class="line">              .bind(PeerRecoverySourceService.class)</span><br><span class="line">              .toInstance(</span><br><span class="line">                new PeerRecoverySourceService(</span><br><span class="line">                  transportService,</span><br><span class="line">                  indicesService,</span><br><span class="line">                  recoverySettings</span><br><span class="line">                )</span><br><span class="line">              );</span><br><span class="line">            b</span><br><span class="line">              .bind(PeerRecoveryTargetService.class)</span><br><span class="line">              .toInstance(</span><br><span class="line">                new PeerRecoveryTargetService(</span><br><span class="line">                  threadPool,</span><br><span class="line">                  transportService,</span><br><span class="line">                  recoverySettings,</span><br><span class="line">                  clusterService</span><br><span class="line">                )</span><br><span class="line">              );</span><br><span class="line">          &#125;</span><br><span class="line">          b.bind(HttpServerTransport.class).toInstance(httpServerTransport);</span><br><span class="line">          pluginComponents</span><br><span class="line">            .stream()</span><br><span class="line">            .forEach(p -&gt; b.bind((Class) p.getClass()).toInstance(p));</span><br><span class="line">          b</span><br><span class="line">            .bind(PersistentTasksService.class)</span><br><span class="line">            .toInstance(persistentTasksService);</span><br><span class="line">          b</span><br><span class="line">            .bind(PersistentTasksClusterService.class)</span><br><span class="line">            .toInstance(persistentTasksClusterService);</span><br><span class="line">          b.bind(PersistentTasksExecutorRegistry.class).toInstance(registry);</span><br><span class="line">          b.bind(RepositoriesService.class).toInstance(repositoryService);</span><br><span class="line">          b.bind(SnapshotsService.class).toInstance(snapshotsService);</span><br><span class="line">          b.bind(SnapshotShardsService.class).toInstance(snapshotShardsService);</span><br><span class="line">          b.bind(RestoreService.class).toInstance(restoreService);</span><br><span class="line">          b.bind(RerouteService.class).toInstance(rerouteService);</span><br><span class="line">          b.bind(ShardLimitValidator.class).toInstance(shardLimitValidator);</span><br><span class="line">          b.bind(FsHealthService.class).toInstance(fsHealthService);</span><br><span class="line">          b.bind(SystemIndices.class).toInstance(systemIndices);</span><br><span class="line">        &#125;</span><br><span class="line">      );</span><br><span class="line">      injector = modules.createInjector();</span><br><span class="line"></span><br><span class="line">      // We allocate copies of existing shards by looking for a viable copy of the shard in the cluster and assigning the shard there.</span><br><span class="line">      // The search for viable copies is triggered by an allocation attempt (i.e. a reroute) and is performed asynchronously. When it</span><br><span class="line">      // completes we trigger another reroute to try the allocation again. This means there is a circular dependency: the allocation</span><br><span class="line">      // service needs access to the existing shards allocators (e.g. the GatewayAllocator) which need to be able to trigger a</span><br><span class="line">      // reroute, which needs to call into the allocation service. We close the loop here:</span><br><span class="line">      clusterModule.setExistingShardsAllocators(</span><br><span class="line">        injector.getInstance(GatewayAllocator.class)</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      List&lt;LifecycleComponent&gt; pluginLifecycleComponents = pluginComponents</span><br><span class="line">        .stream()</span><br><span class="line">        .filter(p -&gt; p instanceof LifecycleComponent)</span><br><span class="line">        .map(p -&gt; (LifecycleComponent) p)</span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line">      resourcesToClose.addAll(pluginLifecycleComponents);</span><br><span class="line">      resourcesToClose.add(</span><br><span class="line">        injector.getInstance(PeerRecoverySourceService.class)</span><br><span class="line">      );</span><br><span class="line">      this.pluginLifecycleComponents =</span><br><span class="line">        Collections.unmodifiableList(pluginLifecycleComponents);</span><br><span class="line">      client.initialize(</span><br><span class="line">        injector.getInstance(new Key&lt;Map&lt;ActionType, TransportAction&gt;&gt;() &#123;&#125;),</span><br><span class="line">        transportService.getTaskManager(),</span><br><span class="line">        () -&gt; clusterService.localNode().getId(),</span><br><span class="line">        transportService.getLocalNodeConnection(),</span><br><span class="line">        transportService.getRemoteClusterService(),</span><br><span class="line">        namedWriteableRegistry</span><br><span class="line">      );</span><br><span class="line">      this.namedWriteableRegistry = namedWriteableRegistry;</span><br><span class="line"></span><br><span class="line">      logger.debug(&quot;initializing HTTP handlers ...&quot;);</span><br><span class="line">      actionModule.initRestHandlers(() -&gt; clusterService.state().nodes());</span><br><span class="line">      logger.info(&quot;initialized&quot;);</span><br><span class="line"></span><br><span class="line">      success = true;</span><br><span class="line">    &#125; catch (IOException ex) &#123;</span><br><span class="line">      throw new ElasticsearchException(&quot;failed to bind service&quot;, ex);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      if (!success) &#123;</span><br><span class="line">        IOUtils.closeWhileHandlingException(resourcesToClose);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  /**</span><br><span class="line">   * Start the node. If the node is already started, this method is no-op.</span><br><span class="line">   */</span><br><span class="line">  public Node start() throws NodeValidationException &#123;</span><br><span class="line">    // 将local node的state设为STARTED状态</span><br><span class="line">    if (!lifecycle.moveToStarted()) &#123;</span><br><span class="line">      return this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    logger.info(&quot;starting ...&quot;);</span><br><span class="line">    // plugins start</span><br><span class="line">    pluginLifecycleComponents.forEach(LifecycleComponent::start);</span><br><span class="line"></span><br><span class="line">    injector.getInstance(MappingUpdatedAction.class).setClient(client);</span><br><span class="line">    injector.getInstance(IndicesService.class).start();</span><br><span class="line">    injector.getInstance(IndicesClusterStateService.class).start();</span><br><span class="line">    injector.getInstance(SnapshotsService.class).start();</span><br><span class="line">    injector.getInstance(SnapshotShardsService.class).start();</span><br><span class="line">    injector.getInstance(RepositoriesService.class).start();</span><br><span class="line">    injector.getInstance(SearchService.class).start();</span><br><span class="line">    injector.getInstance(FsHealthService.class).start();</span><br><span class="line">    nodeService.getMonitorService().start();</span><br><span class="line"></span><br><span class="line">    final ClusterService clusterService = injector.getInstance(</span><br><span class="line">      ClusterService.class</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    final NodeConnectionsService nodeConnectionsService = injector.getInstance(</span><br><span class="line">      NodeConnectionsService.class</span><br><span class="line">    );</span><br><span class="line">    nodeConnectionsService.start();</span><br><span class="line">    clusterService.setNodeConnectionsService(nodeConnectionsService);</span><br><span class="line"></span><br><span class="line">    injector.getInstance(GatewayService.class).start();</span><br><span class="line">    Discovery discovery = injector.getInstance(Discovery.class);</span><br><span class="line">    clusterService</span><br><span class="line">      .getMasterService()</span><br><span class="line">      .setClusterStatePublisher(discovery::publish);</span><br><span class="line"></span><br><span class="line">    // Start the transport service now so the publish address will be added to the local disco node in ClusterService</span><br><span class="line">    TransportService transportService = injector.getInstance(</span><br><span class="line">      TransportService.class</span><br><span class="line">    );</span><br><span class="line">    transportService</span><br><span class="line">      .getTaskManager()</span><br><span class="line">      .setTaskResultsService(injector.getInstance(TaskResultsService.class));</span><br><span class="line">    transportService</span><br><span class="line">      .getTaskManager()</span><br><span class="line">      .setTaskCancellationService(</span><br><span class="line">        new TaskCancellationService(transportService)</span><br><span class="line">      );</span><br><span class="line">    transportService.start();</span><br><span class="line">    assert localNodeFactory.getNode() != null;</span><br><span class="line">    assert transportService</span><br><span class="line">      .getLocalNode()</span><br><span class="line">      .equals(</span><br><span class="line">        localNodeFactory.getNode()</span><br><span class="line">      ) : &quot;transportService has a different local node than the factory provided&quot;;</span><br><span class="line">    injector.getInstance(PeerRecoverySourceService.class).start();</span><br><span class="line"></span><br><span class="line">    // Load (and maybe upgrade) the metadata stored on disk</span><br><span class="line">    final GatewayMetaState gatewayMetaState = injector.getInstance(</span><br><span class="line">      GatewayMetaState.class</span><br><span class="line">    );</span><br><span class="line">    gatewayMetaState.start(</span><br><span class="line">      settings(),</span><br><span class="line">      transportService,</span><br><span class="line">      clusterService,</span><br><span class="line">      injector.getInstance(MetaStateService.class),</span><br><span class="line">      injector.getInstance(MetadataIndexUpgradeService.class),</span><br><span class="line">      injector.getInstance(MetadataUpgrader.class),</span><br><span class="line">      injector.getInstance(PersistedClusterStateService.class)</span><br><span class="line">    );</span><br><span class="line">    if (Assertions.ENABLED) &#123;</span><br><span class="line">      try &#123;</span><br><span class="line">        assert injector</span><br><span class="line">          .getInstance(MetaStateService.class)</span><br><span class="line">          .loadFullState()</span><br><span class="line">          .v1()</span><br><span class="line">          .isEmpty();</span><br><span class="line">        final NodeMetadata nodeMetadata = NodeMetadata.FORMAT.loadLatestState(</span><br><span class="line">          logger,</span><br><span class="line">          NamedXContentRegistry.EMPTY,</span><br><span class="line">          nodeEnvironment.nodeDataPaths()</span><br><span class="line">        );</span><br><span class="line">        assert nodeMetadata != null;</span><br><span class="line">        assert nodeMetadata.nodeVersion().equals(Version.CURRENT);</span><br><span class="line">        assert nodeMetadata.nodeId().equals(localNodeFactory.getNode().getId());</span><br><span class="line">      &#125; catch (IOException e) &#123;</span><br><span class="line">        assert false : e;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // we load the global state here (the persistent part of the cluster state stored on disk) to</span><br><span class="line">    // pass it to the bootstrap checks to allow plugins to enforce certain preconditions based on the recovered state.</span><br><span class="line">    final Metadata onDiskMetadata = gatewayMetaState</span><br><span class="line">      .getPersistedState()</span><br><span class="line">      .getLastAcceptedState()</span><br><span class="line">      .metadata();</span><br><span class="line">    assert onDiskMetadata != null : &quot;metadata is null but shouldn&apos;t&quot;; // this is never null</span><br><span class="line">    validateNodeBeforeAcceptingRequests(</span><br><span class="line">      new BootstrapContext(environment, onDiskMetadata),</span><br><span class="line">      transportService.boundAddress(),</span><br><span class="line">      pluginsService</span><br><span class="line">        .filterPlugins(Plugin.class)</span><br><span class="line">        .stream()</span><br><span class="line">        .flatMap(p -&gt; p.getBootstrapChecks().stream())</span><br><span class="line">        .collect(Collectors.toList())</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    clusterService.addStateApplier(transportService.getTaskManager());</span><br><span class="line">    // start after transport service so the local disco is known</span><br><span class="line">    discovery.start(); // start before cluster service so that it can set initial state on ClusterApplierService</span><br><span class="line">    clusterService.start();</span><br><span class="line">    assert clusterService</span><br><span class="line">      .localNode()</span><br><span class="line">      .equals(</span><br><span class="line">        localNodeFactory.getNode()</span><br><span class="line">      ) : &quot;clusterService has a different local node than the factory provided&quot;;</span><br><span class="line">    // start accepting incoming requests.</span><br><span class="line">    // when the transport layer starts up it will block any incoming requests until this method is called.</span><br><span class="line">    transportService.acceptIncomingRequests();</span><br><span class="line">    // 一会着重看一下选举部分</span><br><span class="line">    discovery.startInitialJoin();</span><br><span class="line">    final TimeValue initialStateTimeout = INITIAL_STATE_TIMEOUT_SETTING.get(</span><br><span class="line">      settings()</span><br><span class="line">    );</span><br><span class="line">    configureNodeAndClusterIdStateListener(clusterService);</span><br><span class="line"></span><br><span class="line">    if (initialStateTimeout.millis() &gt; 0) &#123;</span><br><span class="line">      final ThreadPool thread = injector.getInstance(ThreadPool.class);</span><br><span class="line">      ClusterState clusterState = clusterService.state();</span><br><span class="line">      ClusterStateObserver observer = new ClusterStateObserver(</span><br><span class="line">        clusterState,</span><br><span class="line">        clusterService,</span><br><span class="line">        null,</span><br><span class="line">        logger,</span><br><span class="line">        thread.getThreadContext()</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      if (clusterState.nodes().getMasterNodeId() == null) &#123;</span><br><span class="line">        logger.debug(</span><br><span class="line">          &quot;waiting to join the cluster. timeout [&#123;&#125;]&quot;,</span><br><span class="line">          initialStateTimeout</span><br><span class="line">        );</span><br><span class="line">        final CountDownLatch latch = new CountDownLatch(1);</span><br><span class="line">        // Wait for the next cluster state which satisfies statePredicate</span><br><span class="line">        observer.waitForNextChange(</span><br><span class="line">          new ClusterStateObserver.Listener() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void onNewClusterState(ClusterState state) &#123;</span><br><span class="line">              latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onClusterServiceClose() &#123;</span><br><span class="line">              latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onTimeout(TimeValue timeout) &#123;</span><br><span class="line">              logger.warn(</span><br><span class="line">                &quot;timed out while waiting for initial discovery state - timeout: &#123;&#125;&quot;,</span><br><span class="line">                initialStateTimeout</span><br><span class="line">              );</span><br><span class="line">              latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          state -&gt; state.nodes().getMasterNodeId() != null,</span><br><span class="line">          initialStateTimeout</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">          latch.await();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">          throw new ElasticsearchTimeoutException(</span><br><span class="line">            &quot;Interrupted while waiting for initial discovery state&quot;</span><br><span class="line">          );</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    injector.getInstance(HttpServerTransport.class).start();</span><br><span class="line"></span><br><span class="line">    if (WRITE_PORTS_FILE_SETTING.get(settings())) &#123;</span><br><span class="line">      TransportService transport = injector.getInstance(TransportService.class);</span><br><span class="line">      writePortsFile(&quot;transport&quot;, transport.boundAddress());</span><br><span class="line">      HttpServerTransport http = injector.getInstance(</span><br><span class="line">        HttpServerTransport.class</span><br><span class="line">      );</span><br><span class="line">      writePortsFile(&quot;http&quot;, http.boundAddress());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    logger.info(&quot;started&quot;);</span><br><span class="line"></span><br><span class="line">    pluginsService</span><br><span class="line">      .filterPlugins(ClusterPlugin.class)</span><br><span class="line">      .forEach(ClusterPlugin::onNodeStarted);</span><br><span class="line"></span><br><span class="line">    return this;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h1>总结</h1><p>Node启动过程这种做的检查、初始化、加入集群都梳理清楚了，但节点加入集群后同步数据，在该部分没有找到。</p><p>这个后续在看集群管理的时候，再找一下这个问题的答案。</p><h1>参考</h1><p><a href="https://www.modb.pro/db/33681" target="_blank" rel="noopener">https://www.modb.pro/db/33681</a><br><a href="https://easyice.cn/archives/332" target="_blank" rel="noopener">https://easyice.cn/archives/332</a></p><!-- ## 选举 [discovery.startInitialJoin()](https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/cluster/coordination/Coordinator.java#L700)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/cluster/coordination/Coordinator.java#L700</span><br><span class="line">  @Override</span><br><span class="line">  public void startInitialJoin() &#123;</span><br><span class="line">    synchronized (mutex) &#123;</span><br><span class="line">      becomeCandidate(&quot;startInitialJoin&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    clusterBootstrapService.scheduleUnconfiguredBootstrap();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/cluster/coordination/Coordinator.java#L517</span><br><span class="line">  void becomeCandidate(String method) &#123;</span><br><span class="line">    assert Thread.holdsLock(mutex) : &quot;Coordinator mutex not held&quot;;</span><br><span class="line">    logger.debug(</span><br><span class="line">      &quot;&#123;&#125;: coordinator becoming CANDIDATE in term &#123;&#125; (was &#123;&#125;, lastKnownLeader was [&#123;&#125;])&quot;,</span><br><span class="line">      method,</span><br><span class="line">      getCurrentTerm(),</span><br><span class="line">      mode,</span><br><span class="line">      lastKnownLeader</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    if (mode != Mode.CANDIDATE) &#123;</span><br><span class="line">      final Mode prevMode = mode;</span><br><span class="line">      mode = Mode.CANDIDATE;</span><br><span class="line">      cancelActivePublication(&quot;become candidate: &quot; + method);</span><br><span class="line">      joinAccumulator.close(mode);</span><br><span class="line">      joinAccumulator = joinHelper.new CandidateJoinAccumulator();</span><br><span class="line"></span><br><span class="line">      // 在activate()方法中调用onFoundPeersUpdated()方法检查集群中的节点是否达到多数</span><br><span class="line">      // 如果达到多数则会发起选举流程startElectionScheduler()</span><br><span class="line">      peerFinder.activate(</span><br><span class="line">        coordinationState.get().getLastAcceptedState().nodes()</span><br><span class="line">      );</span><br><span class="line">      clusterFormationFailureHelper.start();</span><br><span class="line"></span><br><span class="line">      leaderChecker.setCurrentNodes(DiscoveryNodes.EMPTY_NODES);</span><br><span class="line">      leaderChecker.updateLeader(null);</span><br><span class="line"></span><br><span class="line">      followersChecker.clearCurrentNodes();</span><br><span class="line">      followersChecker.updateFastResponseState(getCurrentTerm(), mode);</span><br><span class="line">      lagDetector.clearTrackedNodes();</span><br><span class="line"></span><br><span class="line">      if (prevMode == Mode.LEADER) &#123;</span><br><span class="line">        cleanMasterService();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if (applierState.nodes().getMasterNodeId() != null) &#123;</span><br><span class="line">        applierState = clusterStateWithNoMasterBlock(applierState);</span><br><span class="line">        clusterApplier.onNewClusterState(</span><br><span class="line">          &quot;becoming candidate: &quot; + method,</span><br><span class="line">          () -&gt; applierState,</span><br><span class="line">          (source, e) -&gt; &#123;&#125;</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    preVoteCollector.update(getPreVoteResponse(), null);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // CoordinatorPeerFinder</span><br><span class="line">  /**</span><br><span class="line">   * Invoked when the set of found peers changes. Note that invocations of this method are not fully synchronised, so we only guarantee</span><br><span class="line">   * that the change to the set of found peers happens before this method is invoked. If there are multiple concurrent changes then there</span><br><span class="line">   * will be multiple concurrent invocations of this method, with no guarantee as to their order. For this reason we do not pass the</span><br><span class="line">   * updated set of peers as an argument to this method, leaving it to the implementation to call getFoundPeers() with appropriate</span><br><span class="line">   * synchronisation to avoid lost updates. Also, by the time this method is invoked we may have been deactivated.</span><br><span class="line">   */</span><br><span class="line">  @Override</span><br><span class="line">  protected void onFoundPeersUpdated() &#123;</span><br><span class="line">    synchronized (mutex) &#123;</span><br><span class="line">      final Iterable&lt;DiscoveryNode&gt; foundPeers = getFoundPeers();</span><br><span class="line">      if (mode == Mode.CANDIDATE) &#123;</span><br><span class="line">        final VoteCollection expectedVotes = new VoteCollection();</span><br><span class="line">        foundPeers.forEach(expectedVotes::addVote);</span><br><span class="line">        expectedVotes.addVote(Coordinator.this.getLocalNode());</span><br><span class="line">        final boolean foundQuorum = coordinationState</span><br><span class="line">          .get()</span><br><span class="line">          .isElectionQuorum(expectedVotes);</span><br><span class="line"></span><br><span class="line">        if (foundQuorum) &#123;</span><br><span class="line">          if (electionScheduler == null) &#123;</span><br><span class="line">            startElectionScheduler();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          closePrevotingAndElectionScheduler();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    clusterBootstrapService.onFoundPeersUpdated();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  private void startElectionScheduler() &#123;</span><br><span class="line">    assert electionScheduler == null : electionScheduler;</span><br><span class="line"></span><br><span class="line">    if (getLocalNode().isMasterNode() == false) &#123;</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final TimeValue gracePeriod = TimeValue.ZERO;</span><br><span class="line">    electionScheduler =</span><br><span class="line">      electionSchedulerFactory.startElectionScheduler(</span><br><span class="line">        gracePeriod,</span><br><span class="line">        new Runnable() &#123;</span><br><span class="line">          @Override</span><br><span class="line">          public void run() &#123;</span><br><span class="line">            synchronized (mutex) &#123;</span><br><span class="line">              if (mode == Mode.CANDIDATE) &#123;</span><br><span class="line">                final ClusterState lastAcceptedState = coordinationState</span><br><span class="line">                  .get()</span><br><span class="line">                  .getLastAcceptedState();</span><br><span class="line"></span><br><span class="line">                // https://github.com/elastic/elasticsearch/commit/d95b53d87bbfd082d949ab9610a21a805b3bdef2</span><br><span class="line">                if (localNodeMayWinElection(lastAcceptedState) == false) &#123;</span><br><span class="line">                  logger.trace(</span><br><span class="line">                    &quot;skip prevoting as local node may not win election: &#123;&#125;&quot;,</span><br><span class="line">                    lastAcceptedState.coordinationMetadata()</span><br><span class="line">                  );</span><br><span class="line">                  return;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                final StatusInfo statusInfo = nodeHealthService.getHealth();</span><br><span class="line">                if (statusInfo.getStatus() == UNHEALTHY) &#123;</span><br><span class="line">                  logger.debug(</span><br><span class="line">                    &quot;skip prevoting as local node is unhealthy: [&#123;&#125;]&quot;,</span><br><span class="line">                    statusInfo.getInfo()</span><br><span class="line">                  );</span><br><span class="line">                  return;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                if (prevotingRound != null) &#123;</span><br><span class="line">                  prevotingRound.close();</span><br><span class="line">                &#125;</span><br><span class="line">                // PreVoteCollector start</span><br><span class="line">                prevotingRound =</span><br><span class="line">                  preVoteCollector.start(</span><br><span class="line">                    lastAcceptedState,</span><br><span class="line">                    getDiscoveredNodes()</span><br><span class="line">                  );</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          @Override</span><br><span class="line">          public String toString() &#123;</span><br><span class="line">            return &quot;scheduling of new prevoting round&quot;;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  /**</span><br><span class="line">   * Start a new pre-voting round.</span><br><span class="line">   *</span><br><span class="line">   * @param clusterState   the last-accepted cluster state</span><br><span class="line">   * @param broadcastNodes the nodes from whom to request pre-votes</span><br><span class="line">   * @return the pre-voting round, which can be closed to end the round early.</span><br><span class="line">   */</span><br><span class="line">  public Releasable start(</span><br><span class="line">    final ClusterState clusterState,</span><br><span class="line">    final Iterable&lt;DiscoveryNode&gt; broadcastNodes</span><br><span class="line">  ) &#123;</span><br><span class="line">    PreVotingRound preVotingRound = new PreVotingRound(</span><br><span class="line">      clusterState,</span><br><span class="line">      state.v2().getCurrentTerm()</span><br><span class="line">    );</span><br><span class="line">    preVotingRound.start(broadcastNodes);</span><br><span class="line">    return preVotingRound;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // PreVotingRound start</span><br><span class="line">  void start(final Iterable&lt;DiscoveryNode&gt; broadcastNodes) &#123;</span><br><span class="line">    logger.debug(&quot;&#123;&#125; requesting pre-votes from &#123;&#125;&quot;, this, broadcastNodes);</span><br><span class="line">    // https://github.com/elastic/elasticsearch/pull/32847</span><br><span class="line">    // String REQUEST_PRE_VOTE_ACTION_NAME = &quot;internal:cluster/request_pre_vote&quot;;</span><br><span class="line">    broadcastNodes.forEach(</span><br><span class="line">      n -&gt;</span><br><span class="line">        transportService.sendRequest(</span><br><span class="line">          n,</span><br><span class="line">          REQUEST_PRE_VOTE_ACTION_NAME,</span><br><span class="line">          preVoteRequest,</span><br><span class="line">          new TransportResponseHandler&lt;PreVoteResponse&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public PreVoteResponse read(StreamInput in) throws IOException &#123;</span><br><span class="line">              return new PreVoteResponse(in);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void handleResponse(PreVoteResponse response) &#123;</span><br><span class="line">              handlePreVoteResponse(response, n);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void handleException(TransportException exp) &#123;</span><br><span class="line">              logger.debug(new ParameterizedMessage(&quot;&#123;&#125; failed&quot;, this), exp);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public String executor() &#123;</span><br><span class="line">              return Names.GENERIC;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public String toString() &#123;</span><br><span class="line">              return (</span><br><span class="line">                &quot;TransportResponseHandler&#123;&quot; +</span><br><span class="line">                PreVoteCollector.this +</span><br><span class="line">                &quot;, node=&quot; +</span><br><span class="line">                n +</span><br><span class="line">                &apos;&#125;&apos;</span><br><span class="line">              );</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>request(REQUEST_PRE_VOTE_ACTION_NAME)发出去之后，谁来处理呢？看下PreVoteCollector的构造函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PreVoteCollector(</span><br><span class="line">    final TransportService transportService,</span><br><span class="line">    final Runnable startElection,</span><br><span class="line">    final LongConsumer updateMaxTermSeen,</span><br><span class="line">    final ElectionStrategy electionStrategy,</span><br><span class="line">    NodeHealthService nodeHealthService</span><br><span class="line">  ) &#123;</span><br><span class="line">    this.transportService = transportService;</span><br><span class="line">    this.startElection = startElection;</span><br><span class="line">    this.updateMaxTermSeen = updateMaxTermSeen;</span><br><span class="line">    this.electionStrategy = electionStrategy;</span><br><span class="line">    this.nodeHealthService = nodeHealthService;</span><br><span class="line"></span><br><span class="line">    transportService.registerRequestHandler(</span><br><span class="line">      REQUEST_PRE_VOTE_ACTION_NAME,</span><br><span class="line">      Names.GENERIC,</span><br><span class="line">      false,</span><br><span class="line">      false,</span><br><span class="line">      PreVoteRequest::new,</span><br><span class="line">      (request, channel, task) -&gt;</span><br><span class="line">        channel.sendResponse(handlePreVoteRequest(request))</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>可以看出处理request(REQUEST_PRE_VOTE_ACTION_NAME)的是：</p><ul><li>更新MaxTermSeen</li><li>判断leader是否为空，如果为空则直接返回response</li><li>判断发起PreVoteRequest的节点是否是leader，如果是则直接返回response</li><li>如果集群存在leader，并且这个leader不是发起PreVoteRequest的节点，则抛出异常：拒绝PreVoteRequest请求，因为集群中已存在leader</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private PreVoteResponse handlePreVoteRequest(final PreVoteRequest request) &#123;</span><br><span class="line">    updateMaxTermSeen.accept(request.getCurrentTerm());</span><br><span class="line"></span><br><span class="line">    Tuple&lt;DiscoveryNode, PreVoteResponse&gt; state = this.state;</span><br><span class="line">    assert state != null : &quot;received pre-vote request before fully initialised&quot;;</span><br><span class="line"></span><br><span class="line">    final DiscoveryNode leader = state.v1();</span><br><span class="line">    final PreVoteResponse response = state.v2();</span><br><span class="line"></span><br><span class="line">    final StatusInfo statusInfo = nodeHealthService.getHealth();</span><br><span class="line">    if (statusInfo.getStatus() == UNHEALTHY) &#123;</span><br><span class="line">      String message =</span><br><span class="line">        &quot;rejecting &quot; +</span><br><span class="line">        request +</span><br><span class="line">        &quot; on unhealthy node: [&quot; +</span><br><span class="line">        statusInfo.getInfo() +</span><br><span class="line">        &quot;]&quot;;</span><br><span class="line">      logger.debug(message);</span><br><span class="line">      throw new NodeHealthCheckFailureException(message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (leader == null) &#123;</span><br><span class="line">      return response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (leader.equals(request.getSourceNode())) &#123;</span><br><span class="line">      // This is a _rare_ case where our leader has detected a failure and stepped down, but we are still a follower. It&apos;s possible</span><br><span class="line">      // that the leader lost its quorum, but while we&apos;re still a follower we will not offer joins to any other node so there is no</span><br><span class="line">      // major drawback in offering a join to our old leader. The advantage of this is that it makes it slightly more likely that the</span><br><span class="line">      // leader won&apos;t change, and also that its re-election will happen more quickly than if it had to wait for a quorum of followers</span><br><span class="line">      // to also detect its failure.</span><br><span class="line">      return response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    throw new CoordinationStateRejectedException(</span><br><span class="line">      &quot;rejecting &quot; + request + &quot; as there is already a leader&quot;</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>request处理完了，再看一下response是如何处理？</p><ul><li>更新MaxTermSeen</li><li>如果满足以下两种情况之一，则忽略该response：<ul><li>response中lastAcceptedTerm大于clusterState中的term</li><li>response中lastAcceptedTerm等于clusterState中的term并且response中lastAcceptedVersion大于clusterState中的version</li></ul></li><li>节点接收所有没有被忽略的response</li><li>节点根据接收到的response来构造Join(选票)</li><li>调用electionStrategy.isElectionQuorum()判断选票是否达到大多数，如果没有则直接返回</li><li>根据electionStarted来判断选举是否已经开始，如果已经开始则直接返回</li><li>调用startElection.run()来发起选举</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void handlePreVoteResponse(</span><br><span class="line">    final PreVoteResponse response,</span><br><span class="line">    final DiscoveryNode sender</span><br><span class="line">  ) &#123;</span><br><span class="line">    if (isClosed.get()) &#123;</span><br><span class="line">      logger.debug(&quot;&#123;&#125; is closed, ignoring &#123;&#125; from &#123;&#125;&quot;, this, response, sender);</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    updateMaxTermSeen.accept(response.getCurrentTerm());</span><br><span class="line"></span><br><span class="line">    if (</span><br><span class="line">      response.getLastAcceptedTerm() &gt; clusterState.term() ||</span><br><span class="line">      (</span><br><span class="line">        response.getLastAcceptedTerm() == clusterState.term() &amp;&amp;</span><br><span class="line">        response.getLastAcceptedVersion() &gt; clusterState.version()</span><br><span class="line">      )</span><br><span class="line">    ) &#123;</span><br><span class="line">      logger.debug(</span><br><span class="line">        &quot;&#123;&#125; ignoring &#123;&#125; from &#123;&#125; as it is fresher&quot;,</span><br><span class="line">        this,</span><br><span class="line">        response,</span><br><span class="line">        sender</span><br><span class="line">      );</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    preVotesReceived.put(sender, response);</span><br><span class="line"></span><br><span class="line">    // create a fake VoteCollection based on the pre-votes and check if there is an election quorum</span><br><span class="line">    final VoteCollection voteCollection = new VoteCollection();</span><br><span class="line">    final DiscoveryNode localNode = clusterState.nodes().getLocalNode();</span><br><span class="line">    final PreVoteResponse localPreVoteResponse = getPreVoteResponse();</span><br><span class="line"></span><br><span class="line">    preVotesReceived.forEach(</span><br><span class="line">      (node, preVoteResponse) -&gt;</span><br><span class="line">        voteCollection.addJoinVote(</span><br><span class="line">          new Join(</span><br><span class="line">            node,</span><br><span class="line">            localNode,</span><br><span class="line">            preVoteResponse.getCurrentTerm(),</span><br><span class="line">            preVoteResponse.getLastAcceptedTerm(),</span><br><span class="line">            preVoteResponse.getLastAcceptedVersion()</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    if (</span><br><span class="line">      electionStrategy.isElectionQuorum(</span><br><span class="line">        clusterState.nodes().getLocalNode(),</span><br><span class="line">        localPreVoteResponse.getCurrentTerm(),</span><br><span class="line">        localPreVoteResponse.getLastAcceptedTerm(),</span><br><span class="line">        localPreVoteResponse.getLastAcceptedVersion(),</span><br><span class="line">        clusterState.getLastCommittedConfiguration(),</span><br><span class="line">        clusterState.getLastAcceptedConfiguration(),</span><br><span class="line">        voteCollection</span><br><span class="line">      ) ==</span><br><span class="line">      false</span><br><span class="line">    ) &#123;</span><br><span class="line">      logger.debug(</span><br><span class="line">        &quot;&#123;&#125; added &#123;&#125; from &#123;&#125;, no quorum yet&quot;,</span><br><span class="line">        this,</span><br><span class="line">        response,</span><br><span class="line">        sender</span><br><span class="line">      );</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (electionStarted.compareAndSet(false, true) == false) &#123;</span><br><span class="line">      logger.debug(</span><br><span class="line">        &quot;&#123;&#125; added &#123;&#125; from &#123;&#125; but election has already started&quot;,</span><br><span class="line">        this,</span><br><span class="line">        response,</span><br><span class="line">        sender</span><br><span class="line">      );</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    logger.debug(</span><br><span class="line">      &quot;&#123;&#125; added &#123;&#125; from &#123;&#125;, starting election&quot;,</span><br><span class="line">      this,</span><br><span class="line">      response,</span><br><span class="line">      sender</span><br><span class="line">    );</span><br><span class="line">    startElection.run();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>从Coordinator的构造函数中可以看出：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">this.preVoteCollector = new PreVoteCollector(transportService, </span><br><span class="line">this::startElection, </span><br><span class="line">this::updateMaxTermSeen, </span><br><span class="line">electionStrategy,</span><br><span class="line">nodeHealthService);</span><br></pre></td></tr></table></figure><p>–&gt;</p><!-- startElection.run()其实调用的就是Coordinator中的startElection： * 节点会构造StartJoinRequest,StartJoinRequest中的term的值取节点当前term与maxTermSeen的最大值并加1。 * 并将该请求发送给discoveredNodes * 该节点的discoveredNodes在接收到StartJoinRequest后会使用handleStartJoin(StartJoinRequest startJoinRequest)方法来处理该请求：如果StartJoinRequest中的term大于discoveredNodes的currentTerm，就会构造Join来为节点投票。 > 暂未找到transportService.registerRequestHandler接受StartJoinRequest的方法入口 > 该部分以下，都是整理自：[https://www.modb.pro/db/33681](https://www.modb.pro/db/33681)，后续自己再梳理一下。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void startElection() &#123;</span><br><span class="line">    synchronized (mutex) &#123;</span><br><span class="line">      // The preVoteCollector is only active while we are candidate, but it does not call this method with synchronisation, so we have</span><br><span class="line">      // to check our mode again here.</span><br><span class="line">      if (mode == Mode.CANDIDATE) &#123;</span><br><span class="line">        if (localNodeMayWinElection(getLastAcceptedState()) == false) &#123;</span><br><span class="line">          logger.trace(</span><br><span class="line">            &quot;skip election as local node may not win it: &#123;&#125;&quot;,</span><br><span class="line">            getLastAcceptedState().coordinationMetadata()</span><br><span class="line">          );</span><br><span class="line">          return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        final StartJoinRequest startJoinRequest = new StartJoinRequest(</span><br><span class="line">          getLocalNode(),</span><br><span class="line">          Math.max(getCurrentTerm(), maxTermSeen) + 1</span><br><span class="line">        );</span><br><span class="line">        logger.debug(&quot;starting election with &#123;&#125;&quot;, startJoinRequest);</span><br><span class="line">        getDiscoveredNodes()</span><br><span class="line">          .forEach(</span><br><span class="line">            node -&gt; joinHelper.sendStartJoinRequest(startJoinRequest, node)</span><br><span class="line">          );</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //  CoordinationState::handleStartJoin</span><br><span class="line">  /**</span><br><span class="line">   * May be safely called at any time to move this instance to a new term.</span><br><span class="line">   *</span><br><span class="line">   * @param startJoinRequest The startJoinRequest, specifying the node requesting the join.</span><br><span class="line">   * @return A Join that should be sent to the target node of the join.</span><br><span class="line">   * @throws CoordinationStateRejectedException if the arguments were incompatible with the current state of this object.</span><br><span class="line">   */</span><br><span class="line">  public Join handleStartJoin(StartJoinRequest startJoinRequest) &#123;</span><br><span class="line">    // 选民处理要求投票的请求。</span><br><span class="line">    // 由于候选人在发起StartJoinRequest的时候将 term+1了，因此请求中的term应该大于本节点term</span><br><span class="line">    if (startJoinRequest.getTerm() &lt;= getCurrentTerm()) &#123;</span><br><span class="line">      logger.debug(</span><br><span class="line">        &quot;handleStartJoin: ignoring [&#123;&#125;] as term provided is not greater than current term [&#123;&#125;]&quot;,</span><br><span class="line">        startJoinRequest,</span><br><span class="line">        getCurrentTerm()</span><br><span class="line">      );</span><br><span class="line">      throw new CoordinationStateRejectedException(</span><br><span class="line">        &quot;incoming term &quot; +</span><br><span class="line">        startJoinRequest.getTerm() +</span><br><span class="line">        &quot; not greater than current term &quot; +</span><br><span class="line">        getCurrentTerm()</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    logger.debug(</span><br><span class="line">      &quot;handleStartJoin: leaving term [&#123;&#125;] due to &#123;&#125;&quot;,</span><br><span class="line">      getCurrentTerm(),</span><br><span class="line">      startJoinRequest</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    if (joinVotes.isEmpty() == false) &#123;</span><br><span class="line">      final String reason;</span><br><span class="line">      if (electionWon == false) &#123;</span><br><span class="line">        reason = &quot;failed election&quot;;</span><br><span class="line">      &#125; else if (startJoinRequest.getSourceNode().equals(localNode)) &#123;</span><br><span class="line">        reason = &quot;bumping term&quot;;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        reason = &quot;standing down as leader&quot;;</span><br><span class="line">      &#125;</span><br><span class="line">      logger.debug(&quot;handleStartJoin: discarding &#123;&#125;: &#123;&#125;&quot;, joinVotes, reason);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    persistedState.setCurrentTerm(startJoinRequest.getTerm());</span><br><span class="line">    assert getCurrentTerm() == startJoinRequest.getTerm();</span><br><span class="line">    lastPublishedVersion = 0;</span><br><span class="line">    lastPublishedConfiguration = getLastAcceptedConfiguration();</span><br><span class="line">    startedJoinSinceLastReboot = true;</span><br><span class="line">    electionWon = false;</span><br><span class="line">    joinVotes = new VoteCollection();</span><br><span class="line">    publishVotes = new VoteCollection();</span><br><span class="line"></span><br><span class="line">    return new Join(</span><br><span class="line">      localNode,</span><br><span class="line">      startJoinRequest.getSourceNode(),</span><br><span class="line">      getCurrentTerm(),</span><br><span class="line">      getLastAcceptedTerm(),</span><br><span class="line">      getLastAcceptedVersion()</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>当节点收到选票后会使用handleJoin()方法来处理，具体处理逻辑如下：</p><ul><li>判断选民返回的投票(Join)中的term与当前节点的term的是否相等，如果不相等则会抛出CoordinationStateRejectedException(“incoming term does not match current term”)，拒绝将选票添加</li><li>判断startedJoinSinceLastReboot是否为false，这个场景是指在节点reboot后term没有增加，当startedJoinSinceLastReboot为false时，抛出CoordinationStateRejectedException(&quot;ignored join as term has not been incremented yet after reboot”)，拒绝将选票添加</li><li>判断选民返回的投票(Join)中的lastAcceptedTerm与当前节点的lastAcceptedTerm的关系，如果前者大于后者，则抛出异常CoordinationStateRejectedException，拒绝将选票添加</li><li>如果选民返回的投票(Join)中的lastAcceptedTerm与当前节点的lastAcceptedTerm相等，但是Join中的lastAcceptedVersion大于当前节点的lastAcceptedVersion，则抛出CoordinationStateRejectedException并拒绝将选票添加</li><li>判断节点的lastAcceptedConfiguration是否为空，如果为空则抛出CoordinationStateRejectedException</li><li>将该选票添加到joinVotes中</li><li>判断是否到达法定人数</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> // CoordinationState::handleJoin</span><br><span class="line">/**</span><br><span class="line">  * May be safely called at any time to move this instance to a new term.</span><br><span class="line">  *</span><br><span class="line">  * @param startJoinRequest The startJoinRequest, specifying the node requesting the join.</span><br><span class="line">  * @return A Join that should be sent to the target node of the join.</span><br><span class="line">  * @throws CoordinationStateRejectedException if the arguments were incompatible with the current state of this object.</span><br><span class="line">  */</span><br><span class="line"> public Join handleStartJoin(StartJoinRequest startJoinRequest) &#123;</span><br><span class="line">   if (startJoinRequest.getTerm() &lt;= getCurrentTerm()) &#123;</span><br><span class="line">     logger.debug(</span><br><span class="line">       &quot;handleStartJoin: ignoring [&#123;&#125;] as term provided is not greater than current term [&#123;&#125;]&quot;,</span><br><span class="line">       startJoinRequest,</span><br><span class="line">       getCurrentTerm()</span><br><span class="line">     );</span><br><span class="line">     throw new CoordinationStateRejectedException(</span><br><span class="line">       &quot;incoming term &quot; +</span><br><span class="line">       startJoinRequest.getTerm() +</span><br><span class="line">       &quot; not greater than current term &quot; +</span><br><span class="line">       getCurrentTerm()</span><br><span class="line">     );</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   logger.debug(</span><br><span class="line">     &quot;handleStartJoin: leaving term [&#123;&#125;] due to &#123;&#125;&quot;,</span><br><span class="line">     getCurrentTerm(),</span><br><span class="line">     startJoinRequest</span><br><span class="line">   );</span><br><span class="line"></span><br><span class="line">   if (joinVotes.isEmpty() == false) &#123;</span><br><span class="line">     final String reason;</span><br><span class="line">     if (electionWon == false) &#123;</span><br><span class="line">       reason = &quot;failed election&quot;;</span><br><span class="line">     &#125; else if (startJoinRequest.getSourceNode().equals(localNode)) &#123;</span><br><span class="line">       reason = &quot;bumping term&quot;;</span><br><span class="line">     &#125; else &#123;</span><br><span class="line">       reason = &quot;standing down as leader&quot;;</span><br><span class="line">     &#125;</span><br><span class="line">     logger.debug(&quot;handleStartJoin: discarding &#123;&#125;: &#123;&#125;&quot;, joinVotes, reason);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   persistedState.setCurrentTerm(startJoinRequest.getTerm());</span><br><span class="line">   assert getCurrentTerm() == startJoinRequest.getTerm();</span><br><span class="line">   lastPublishedVersion = 0;</span><br><span class="line">   lastPublishedConfiguration = getLastAcceptedConfiguration();</span><br><span class="line">   startedJoinSinceLastReboot = true;</span><br><span class="line">   electionWon = false;</span><br><span class="line">   joinVotes = new VoteCollection();</span><br><span class="line">   publishVotes = new VoteCollection();</span><br><span class="line"></span><br><span class="line">   return new Join(</span><br><span class="line">     localNode,</span><br><span class="line">     startJoinRequest.getSourceNode(),</span><br><span class="line">     getCurrentTerm(),</span><br><span class="line">     getLastAcceptedTerm(),</span><br><span class="line">     getLastAcceptedVersion()</span><br><span class="line">   );</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>最后processJoinRequest(JoinRequest joinRequest, JoinHelper.JoinCallback joinCallback)方法中当该节点收到多数的投票后会调用becomeLeader(“handleJoinRequest”)方法使得该节点的状态由candidate转换为leader。至此集群的master节点就选出来了。</p><pre><code>private void processJoinRequest(
    JoinRequest joinRequest,
    JoinHelper.JoinCallback joinCallback
  ) {
    final Optional&lt;Join&gt; optionalJoin = joinRequest.getOptionalJoin();
    synchronized (mutex) {
      updateMaxTermSeen(joinRequest.getTerm());

      final CoordinationState coordState = coordinationState.get();
      final boolean prevElectionWon = coordState.electionWon();

      optionalJoin.ifPresent(this::handleJoin);
      joinAccumulator.handleJoinRequest(
        joinRequest.getSourceNode(),
        joinCallback
      );

      if (prevElectionWon == false &amp;&amp; coordState.electionWon()) {
        becomeLeader(&quot;handleJoinRequest&quot;);
      }
    }
  }
``` --&gt;

</code></pre>-->]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Node</tag>
      </tags>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 GET分析</title>
    <url>/elasticsearch-get-source-code-analysis.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第四篇：Elasticsearch GET<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><p>通过前3篇的学习，可以稍微总结一下Elasticsearch：</p><ul><li>ES是一个集群，所以每个Node都需要和其他的Nodes 进行交互，这些交互是通过NodeClient来完成。</li><li>ES中RPC、HTTP请求都是基于Netty自行封装的：<ul><li><a href="https://github.com/jiankunking/elasticsearch/tree/master/modules/transport-netty4/src/main/java/org/elasticsearch/transport" target="_blank" rel="noopener">NettyTransport 对应RPC协议支持</a></li><li><a href="https://github.com/jiankunking/elasticsearch/tree/master/modules/transport-netty4/src/main/java/org/elasticsearch/http" target="_blank" rel="noopener">NettyHttpServerTransport 则对应HTTP协议支持</a></li></ul></li><li>Transport*Action 是比较核心的类集合:<ul><li>Action -&gt; Transport*Action</li><li>TransportAction -&gt; TransportHandler（即使是本地Node也会通过发请求的方式，将处理转发到TransportHandler处理）</li><li>真实干活的Transport*Action类(或者其父类)中<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/TransportAction.java#L67" target="_blank" rel="noopener">doExecute(…)</a></li></ul></li></ul><h1>目的</h1><p>在看源码之前先梳理一下，自己对于GET流程疑惑的点：</p><ul><li>是不是根据Document _id通过hash找到对应的Shard？</li><li>根据Document _id查询如何做到实时可见的？</li><li>单个shard查询失败会不会查询副本？</li></ul><h1>源码分析</h1><p><font color="DeepPink"><strong>第二部分是代码分析的过程，不想看的朋友可以跳过直接看第三部分总结。</strong></font></p><p>通过搜索/{index}/_doc/{id}可以找到<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/get/GetAction.java" target="_blank" rel="noopener">RestGetAction</a>,找到RestGetAction再加上前面的总结，其实就知道真实干活的是<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/get/TransportGetAction.java" target="_blank" rel="noopener">TransportGetAction</a>。</p><p><img data-src="/images/elasticsearch-get-source-code-analysis/TransportGetAction.png" alt></p><p>在TransportGetAction的父类<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java" target="_blank" rel="noopener">TransportSingleShardAction</a>中找到了doExecute：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void doExecute(Task task, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    new AsyncSingleAction(request, listener).start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// TransportSingleShardAction的AsyncSingleAction中</span><br><span class="line">private AsyncSingleAction(Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">        this.listener = listener;</span><br><span class="line"></span><br><span class="line">        ClusterState clusterState = clusterService.state();</span><br><span class="line">        if (logger.isTraceEnabled()) &#123;</span><br><span class="line">            logger.trace(&quot;executing [&#123;&#125;] based on cluster state version [&#123;&#125;]&quot;, request, clusterState.version());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 集群nodes列表</span><br><span class="line">        nodes = clusterState.nodes();</span><br><span class="line">        ClusterBlockException blockException = checkGlobalBlock(clusterState);</span><br><span class="line">        if (blockException != null) &#123;</span><br><span class="line">            throw blockException;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String concreteSingleIndex;</span><br><span class="line">        if (resolveIndex(request)) &#123;</span><br><span class="line">            concreteSingleIndex = indexNameExpressionResolver.concreteSingleIndex(clusterState, request).getName();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            concreteSingleIndex = request.index();</span><br><span class="line">        &#125;</span><br><span class="line">        this.internalRequest = new InternalRequest(request, concreteSingleIndex);</span><br><span class="line"></span><br><span class="line">        // TransportGetAction中resolveRequest</span><br><span class="line">        // 解析请求，更新指定routing</span><br><span class="line">        resolveRequest(clusterState, internalRequest);</span><br><span class="line"></span><br><span class="line">        blockException = checkRequestBlock(clusterState, internalRequest);</span><br><span class="line">        if (blockException != null) &#123;</span><br><span class="line">            throw blockException;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 根据路由算法获取目标shard的迭代器或者根据优先级获选择目标节点</span><br><span class="line">        this.shardIt = shards(clusterState, internalRequest);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// TransportGetAction中</span><br><span class="line">@Override</span><br><span class="line">protected ShardIterator shards(ClusterState state, InternalRequest request) &#123;</span><br><span class="line">    return clusterService.operationRouting()</span><br><span class="line">            .getShards(clusterService.state(), request.concreteIndex(), request.request().id(), request.request().routing(),</span><br><span class="line">                request.request().preference());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java" target="_blank" rel="noopener">OperationRouting</a>中的getShards(…)看一下是如何获取到具体的shardId的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> public ShardIterator getShards(ClusterState clusterState, String index, String id, @Nullable String routing,</span><br><span class="line">                                   @Nullable String preference) &#123;</span><br><span class="line">        return preferenceActiveShardIterator(shards(clusterState, index, id, routing), clusterState.nodes().getLocalNodeId(),</span><br><span class="line">            clusterState.nodes(), preference, null, null);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">protected IndexShardRoutingTable shards(ClusterState clusterState, String index, String id, String routing) &#123;</span><br><span class="line">        int shardId = generateShardId(indexMetadata(clusterState, index), id, routing);</span><br><span class="line">        return clusterState.getRoutingTable().shardRoutingTable(index, shardId);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">public static int generateShardId(IndexMetadata indexMetadata, @Nullable String id, @Nullable String routing) &#123;</span><br><span class="line">        final String effectiveRouting;</span><br><span class="line">        final int partitionOffset;</span><br><span class="line"></span><br><span class="line">        // routing参数解析可以参考具体的文档</span><br><span class="line">        // https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html</span><br><span class="line">        if (routing == null) &#123;</span><br><span class="line">            assert(indexMetadata.isRoutingPartitionedIndex() == false) : &quot;A routing value is required for gets from a partitioned index&quot;;</span><br><span class="line">            effectiveRouting = id;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            effectiveRouting = routing;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (indexMetadata.isRoutingPartitionedIndex()) &#123;</span><br><span class="line">            partitionOffset = Math.floorMod(Murmur3HashFunction.hash(id), indexMetadata.getRoutingPartitionSize());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // we would have still got 0 above but this check just saves us an unnecessary hash calculation</span><br><span class="line">            partitionOffset = 0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return calculateScaledShardId(indexMetadata, effectiveRouting, partitionOffset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private static int calculateScaledShardId(IndexMetadata indexMetadata, String effectiveRouting, int partitionOffset) &#123;</span><br><span class="line">        final int hash = Murmur3HashFunction.hash(effectiveRouting) + partitionOffset;</span><br><span class="line"></span><br><span class="line">        // we don&apos;t use IMD#getNumberOfShards since the index might have been shrunk such that we need to use the size</span><br><span class="line">        // of original index to hash documents</span><br><span class="line">        return Math.floorMod(hash, indexMetadata.getRoutingNumShards()) / indexMetadata.getRoutingFactor();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>到这里可以知道ES就是通过Document _id hash找到对应的shard。</p><p>下面看一下是如何做到实时可见的？</p><p>数据节点接收协调节点请求的入口为:TransportSingleShardAction.ShardTransportHandler# messageReceived：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void messageReceived(final Request request, final TransportChannel channel, Task task) throws Exception &#123;</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;executing [&#123;&#125;] on shard [&#123;&#125;]&quot;, request, request.internalShardId);</span><br><span class="line">    &#125;</span><br><span class="line">    asyncShardOperation(request, request.internalShardId, new ChannelActionListener&lt;&gt;(channel, transportShardAction, request));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体执行是在子类TransportGetAction#asyncShardOperation中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void asyncShardOperation(GetRequest request, ShardId shardId, ActionListener&lt;GetResponse&gt; listener) throws IOException &#123;</span><br><span class="line">    IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());</span><br><span class="line">    IndexShard indexShard = indexService.getShard(shardId.id());</span><br><span class="line">    // 关于realtime可以看一下官方文档</span><br><span class="line">    // https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html</span><br><span class="line">    if (request.realtime()) &#123; // we are not tied to a refresh cycle here anyway</span><br><span class="line">        super.asyncShardOperation(request, shardId, listener);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        indexShard.awaitShardSearchActive(b -&gt; &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                super.asyncShardOperation(request, shardId, listener);</span><br><span class="line">            &#125; catch (Exception ex) &#123;</span><br><span class="line">                listener.onFailure(ex);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TransportGetAction#asyncShardOperation获取文档最终调用的是：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected GetResponse shardOperation(GetRequest request, ShardId shardId) &#123;</span><br><span class="line">    IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());</span><br><span class="line">    IndexShard indexShard = indexService.getShard(shardId.id());</span><br><span class="line"></span><br><span class="line">    // 关于realtime、refresh可以看一下官方文档</span><br><span class="line">    // https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html</span><br><span class="line">    if (request.refresh() &amp;&amp; !request.realtime()) &#123;</span><br><span class="line">        indexShard.refresh(&quot;refresh_flag_get&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GetResult result = indexShard.getService().get(request.id(), request.storedFields(),</span><br><span class="line">            request.realtime(), request.version(), request.versionType(), request.fetchSourceContext());</span><br><span class="line">    return new GetResponse(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>shardOperation先检查是否需要refresh，然后调用indexShard.getService().get()读取数据并存储到GetResult中。读取及过滤 在ShardGetService#get()函数中，调用:<br>GetResult getResult = innerGet(…)；<br>获取结果。GetResult类用于存储读取的真实数据内容。核心的数据读取实现在ShardGetService#innerGet(…)函数中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private GetResult innerGet(String id, String[] gFields, boolean realtime, long version, VersionType versionType,</span><br><span class="line">                               long ifSeqNo, long ifPrimaryTerm, FetchSourceContext fetchSourceContext) &#123;</span><br><span class="line">        fetchSourceContext = normalizeFetchSourceContent(fetchSourceContext, gFields);</span><br><span class="line"></span><br><span class="line">        // 调用Engine获取数据</span><br><span class="line">        Engine.GetResult get = indexShard.get(new Engine.Get(realtime, realtime, id)</span><br><span class="line">            .version(version).versionType(versionType).setIfSeqNo(ifSeqNo).setIfPrimaryTerm(ifPrimaryTerm));</span><br><span class="line">        assert get.isFromTranslog() == false || realtime : &quot;should only read from translog if realtime enabled&quot;;</span><br><span class="line">        if (get.exists() == false) &#123;</span><br><span class="line">            get.close();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (get == null || get.exists() == false) &#123;</span><br><span class="line">            return new GetResult(shardId.getIndexName(), id, UNASSIGNED_SEQ_NO, UNASSIGNED_PRIMARY_TERM, -1, false, null, null, null);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            // 获取返回结果</span><br><span class="line">            // break between having loaded it from translog (so we only have _source), and having a document to load</span><br><span class="line">            return innerGetLoadFromStoredFields(id, gFields, fetchSourceContext, get, mapperService);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            get.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    //对指定的field、source进行过滤(source过滤只支持对字段)，</span><br><span class="line">    //把结果存于GetResult对象中</span><br><span class="line">    private GetResult innerGetLoadFromStoredFields(String id, String[] storedFields, FetchSourceContext fetchSourceContext,</span><br><span class="line">                                                   Engine.GetResult get, MapperService mapperService) &#123;</span><br><span class="line">        assert get.exists() : &quot;method should only be called if document could be retrieved&quot;;</span><br><span class="line"></span><br><span class="line">        // check first if stored fields to be loaded don&apos;t contain an object field</span><br><span class="line">        DocumentMapper docMapper = mapperService.documentMapper();</span><br><span class="line">        if (storedFields != null) &#123;</span><br><span class="line">            for (String field : storedFields) &#123;</span><br><span class="line">                Mapper fieldMapper = docMapper.mappers().getMapper(field);</span><br><span class="line">                if (fieldMapper == null) &#123;</span><br><span class="line">                    if (docMapper.mappers().objectMappers().get(field) != null) &#123;</span><br><span class="line">                        // Only fail if we know it is a object field, missing paths / fields shouldn&apos;t fail.</span><br><span class="line">                        throw new IllegalArgumentException(&quot;field [&quot; + field + &quot;] isn&apos;t a leaf field&quot;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, DocumentField&gt; documentFields = null;</span><br><span class="line">        Map&lt;String, DocumentField&gt; metadataFields = null;</span><br><span class="line">        BytesReference source = null;</span><br><span class="line">        DocIdAndVersion docIdAndVersion = get.docIdAndVersion();</span><br><span class="line">        // force fetching source if we read from translog and need to recreate stored fields</span><br><span class="line">        boolean forceSourceForComputingTranslogStoredFields = get.isFromTranslog() &amp;&amp; storedFields != null &amp;&amp;</span><br><span class="line">                Stream.of(storedFields).anyMatch(f -&gt; TranslogLeafReader.ALL_FIELD_NAMES.contains(f) == false);</span><br><span class="line">        FieldsVisitor fieldVisitor = buildFieldsVisitors(storedFields,</span><br><span class="line">            forceSourceForComputingTranslogStoredFields ? FetchSourceContext.FETCH_SOURCE : fetchSourceContext);</span><br><span class="line">        if (fieldVisitor != null) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                docIdAndVersion.reader.document(docIdAndVersion.docId, fieldVisitor);</span><br><span class="line">            &#125; catch (IOException e) &#123;</span><br><span class="line">                throw new ElasticsearchException(&quot;Failed to get id [&quot; + id + &quot;]&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line">            source = fieldVisitor.source();</span><br><span class="line"></span><br><span class="line">            // in case we read from translog, some extra steps are needed to make _source consistent and to load stored fields</span><br><span class="line">            if (get.isFromTranslog()) &#123;</span><br><span class="line">                // Fast path: if only asked for the source or stored fields that have been already provided by TranslogLeafReader,</span><br><span class="line">                // just make source consistent by reapplying source filters from mapping (possibly also nulling the source)</span><br><span class="line">                if (forceSourceForComputingTranslogStoredFields == false) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        source = indexShard.mapperService().documentMapper().sourceMapper().applyFilters(source, null);</span><br><span class="line">                    &#125; catch (IOException e) &#123;</span><br><span class="line">                        throw new ElasticsearchException(&quot;Failed to reapply filters for [&quot; + id + &quot;] after reading from translog&quot;, e);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    // Slow path: recreate stored fields from original source</span><br><span class="line">                    assert source != null : &quot;original source in translog must exist&quot;;</span><br><span class="line">                    SourceToParse sourceToParse = new SourceToParse(shardId.getIndexName(), id, source, XContentHelper.xContentType(source),</span><br><span class="line">                        fieldVisitor.routing());</span><br><span class="line">                    ParsedDocument doc = indexShard.mapperService().documentMapper().parse(sourceToParse);</span><br><span class="line">                    assert doc.dynamicMappingsUpdate() == null : &quot;mapping updates should not be required on already-indexed doc&quot;;</span><br><span class="line">                    // update special fields</span><br><span class="line">                    doc.updateSeqID(docIdAndVersion.seqNo, docIdAndVersion.primaryTerm);</span><br><span class="line">                    doc.version().setLongValue(docIdAndVersion.version);</span><br><span class="line"></span><br><span class="line">                    // retrieve stored fields from parsed doc</span><br><span class="line">                    fieldVisitor = buildFieldsVisitors(storedFields, fetchSourceContext);</span><br><span class="line">                    for (IndexableField indexableField : doc.rootDoc().getFields()) &#123;</span><br><span class="line">                        IndexableFieldType fieldType = indexableField.fieldType();</span><br><span class="line">                        if (fieldType.stored()) &#123;</span><br><span class="line">                            FieldInfo fieldInfo = new FieldInfo(indexableField.name(), 0, false, false, false, IndexOptions.NONE,</span><br><span class="line">                                DocValuesType.NONE, -1, Collections.emptyMap(), 0, 0, 0, false);</span><br><span class="line">                            StoredFieldVisitor.Status status = fieldVisitor.needsField(fieldInfo);</span><br><span class="line">                            if (status == StoredFieldVisitor.Status.YES) &#123;</span><br><span class="line">                                if (indexableField.numericValue() != null) &#123;</span><br><span class="line">                                    fieldVisitor.objectField(fieldInfo, indexableField.numericValue());</span><br><span class="line">                                &#125; else if (indexableField.binaryValue() != null) &#123;</span><br><span class="line">                                    fieldVisitor.binaryField(fieldInfo, indexableField.binaryValue());</span><br><span class="line">                                &#125; else if (indexableField.stringValue() != null) &#123;</span><br><span class="line">                                    fieldVisitor.objectField(fieldInfo, indexableField.stringValue());</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125; else if (status == StoredFieldVisitor.Status.STOP) &#123;</span><br><span class="line">                                break;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    // retrieve source (with possible transformations, e.g. source filters</span><br><span class="line">                    source = fieldVisitor.source();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            // put stored fields into result objects</span><br><span class="line">            if (!fieldVisitor.fields().isEmpty()) &#123;</span><br><span class="line">                fieldVisitor.postProcess(mapperService::fieldType);</span><br><span class="line">                documentFields = new HashMap&lt;&gt;();</span><br><span class="line">                metadataFields = new HashMap&lt;&gt;();</span><br><span class="line">                for (Map.Entry&lt;String, List&lt;Object&gt;&gt; entry : fieldVisitor.fields().entrySet()) &#123;</span><br><span class="line">                    if (mapperService.isMetadataField(entry.getKey())) &#123;</span><br><span class="line">                        metadataFields.put(entry.getKey(), new DocumentField(entry.getKey(), entry.getValue()));</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        documentFields.put(entry.getKey(), new DocumentField(entry.getKey(), entry.getValue()));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (source != null) &#123;</span><br><span class="line">            // apply request-level source filtering</span><br><span class="line">            if (fetchSourceContext.fetchSource() == false) &#123;</span><br><span class="line">                source = null;</span><br><span class="line">            &#125; else if (fetchSourceContext.includes().length &gt; 0 || fetchSourceContext.excludes().length &gt; 0) &#123;</span><br><span class="line">                Map&lt;String, Object&gt; sourceAsMap;</span><br><span class="line">                // TODO: The source might be parsed and available in the sourceLookup but that one uses unordered maps so different.</span><br><span class="line">                //  Do we care?</span><br><span class="line">                Tuple&lt;XContentType, Map&lt;String, Object&gt;&gt; typeMapTuple = XContentHelper.convertToMap(source, true);</span><br><span class="line">                XContentType sourceContentType = typeMapTuple.v1();</span><br><span class="line">                sourceAsMap = typeMapTuple.v2();</span><br><span class="line">                sourceAsMap = XContentMapValues.filter(sourceAsMap, fetchSourceContext.includes(), fetchSourceContext.excludes());</span><br><span class="line">                try &#123;</span><br><span class="line">                    source = BytesReference.bytes(XContentFactory.contentBuilder(sourceContentType).map(sourceAsMap));</span><br><span class="line">                &#125; catch (IOException e) &#123;</span><br><span class="line">                    throw new ElasticsearchException(&quot;Failed to get id [&quot; + id + &quot;] with includes/excludes set&quot;, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return new GetResult(shardId.getIndexName(), id, get.docIdAndVersion().seqNo, get.docIdAndVersion().primaryTerm,</span><br><span class="line">            get.version(), get.exists(), source, documentFields, metadataFields);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>下面看一下InternalEngine的读取过程：</p><p>InternalEngine#get过程会加读锁。处理realtime选项，如果为true，则先判断是否有数据可以刷盘，然后调用Searcher进行读取。Searcher是对IndexSearcher的封装。</p><p>从ES 5.x开始不会从translog中读取，只从Lucene中读。realtime的实现机制变成依靠refresh实现。参考官方链接：<a href="https://github.com/elastic/elasticsearch/pull/20102" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch/pull/20102</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">   public GetResult get(Get get, DocumentMapper mapper, Function&lt;Engine.Searcher, Engine.Searcher&gt; searcherWrapper) &#123;</span><br><span class="line">       assert Objects.equals(get.uid().field(), IdFieldMapper.NAME) : get.uid().field();</span><br><span class="line">       try (ReleasableLock ignored = readLock.acquire()) &#123;</span><br><span class="line">           ensureOpen();</span><br><span class="line">           // 处理realtime选项，判断是否需要刷盘</span><br><span class="line">           if (get.realtime()) &#123;</span><br><span class="line">               final VersionValue versionValue;</span><br><span class="line">               // versionMap中的值是写入索引的时候添加的，不会写到磁盘中</span><br><span class="line">               try (Releasable ignore = versionMap.acquireLock(get.uid().bytes())) &#123;</span><br><span class="line">                   // we need to lock here to access the version map to do this truly in RT</span><br><span class="line">                   versionValue = getVersionFromMap(get.uid().bytes());</span><br><span class="line">               &#125;</span><br><span class="line">               if (versionValue != null) &#123;</span><br><span class="line">                   if (versionValue.isDelete()) &#123;</span><br><span class="line">                       return GetResult.NOT_EXISTS;</span><br><span class="line">                   &#125;</span><br><span class="line">                   if (get.versionType().isVersionConflictForReads(versionValue.version, get.version())) &#123;</span><br><span class="line">                       throw new VersionConflictEngineException(shardId, get.id(),</span><br><span class="line">                           get.versionType().explainConflictForReads(versionValue.version, get.version()));</span><br><span class="line">                   &#125;</span><br><span class="line">                   if (get.getIfSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO &amp;&amp; (</span><br><span class="line">                       get.getIfSeqNo() != versionValue.seqNo || get.getIfPrimaryTerm() != versionValue.term</span><br><span class="line">                       )) &#123;</span><br><span class="line">                       throw new VersionConflictEngineException(shardId, get.id(),</span><br><span class="line">                           get.getIfSeqNo(), get.getIfPrimaryTerm(), versionValue.seqNo, versionValue.term);</span><br><span class="line">                   &#125;</span><br><span class="line">                   if (get.isReadFromTranslog()) &#123;</span><br><span class="line">                       // this is only used for updates - API _GET calls will always read form a reader for consistency</span><br><span class="line">                       // the update call doesn&apos;t need the consistency since it&apos;s source only + _parent but parent can go away in 7.0</span><br><span class="line">                       if (versionValue.getLocation() != null) &#123;</span><br><span class="line">                           try &#123;</span><br><span class="line">                               final Translog.Operation operation = translog.readOperation(versionValue.getLocation());</span><br><span class="line">                               if (operation != null) &#123;</span><br><span class="line">                                   return getFromTranslog(get, (Translog.Index) operation, mapper, searcherWrapper);</span><br><span class="line">                               &#125;</span><br><span class="line">                           &#125; catch (IOException e) &#123;</span><br><span class="line">                               maybeFailEngine(&quot;realtime_get&quot;, e); // lets check if the translog has failed with a tragic event</span><br><span class="line">                               throw new EngineException(shardId, &quot;failed to read operation from translog&quot;, e);</span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125; else &#123;</span><br><span class="line">                           trackTranslogLocation.set(true);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">                   assert versionValue.seqNo &gt;= 0 : versionValue;</span><br><span class="line">                   //执行刷盘操作</span><br><span class="line">                   refreshIfNeeded(&quot;realtime_get&quot;, versionValue.seqNo);</span><br><span class="line">               &#125;</span><br><span class="line">               // 调用Searcher读取数据</span><br><span class="line">               return getFromSearcher(get, acquireSearcher(&quot;realtime_get&quot;, SearcherScope.INTERNAL, searcherWrapper));</span><br><span class="line">           &#125; else &#123;</span><br><span class="line">               // we expose what has been externally expose in a point in time snapshot via an explicit refresh</span><br><span class="line">               return getFromSearcher(get, acquireSearcher(&quot;get&quot;, SearcherScope.EXTERNAL, searcherWrapper));</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h1>小结</h1><ul><li>GET是根据Document _id 哈希找到对应的shard的。</li><li>根据Document _id查询的实时可见是通过依靠refresh实现的。</li><li>从代码来看只会查询一次，不会多次查询<ul><li>其实换个角度来看，如果查询落到单个shard查询失败后，如果es自动查询其它副本，会引入以下两个问题：<ul><li>雪崩</li><li>代码逻辑变复杂</li><li>所以大概率也是不会默认支持的，通过在SDK上支持retry参数反而更好</li></ul></li></ul></li></ul><p>参考资料：<br>《Elasticsearch源码解析与优化实战》</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>GET</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 更新性能分析</title>
    <url>/why-does-elasticsearch-have-poor-update-performance.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第三篇：Elasticsearch 更新性能<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><h1>目的</h1><p>在看源码之前先梳理一下，自己对于更新疑惑的点：<br>为什么Elasticsearch更新与写入的性能会有比较大的差异？</p><h1>源码分析</h1><p>建议先看一下：<a href="https://jiankunking.com/elasticsearch-write-source-code-analysis.html">【Elasticsearch源码】 写入分析</a></p><p>在<a href="https://jiankunking.com/elasticsearch-write-source-code-analysis.html">【Elasticsearch源码】 写入分析</a>中可以看到bulk请求最终在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java" target="_blank" rel="noopener">TransportShardBulkAction</a> <a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java#L182" target="_blank" rel="noopener">doRun()</a>中执行的时候，还是通过一个循环，一个一个处理的，并没有什么神奇之处。</p><p>下面看一下具体执行的代码<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java" target="_blank" rel="noopener">executeBulkItemRequest</a> <a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java#L238" target="_blank" rel="noopener">doRun()</a>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Executes bulk item requests and handles request execution exceptions.</span><br><span class="line"> * @return &#123;@code true&#125; if request completed on this thread and the listener was invoked, &#123;@code false&#125; if the request triggered</span><br><span class="line"> *                      a mapping update that will finish and invoke the listener on a different thread</span><br><span class="line"> */</span><br><span class="line">static boolean executeBulkItemRequest(BulkPrimaryExecutionContext context, UpdateHelper updateHelper, LongSupplier nowInMillisSupplier,</span><br><span class="line">                                   MappingUpdatePerformer mappingUpdater, Consumer&lt;ActionListener&lt;Void&gt;&gt; waitForMappingUpdate,</span><br><span class="line">                                   ActionListener&lt;Void&gt; itemDoneListener) throws Exception &#123;</span><br><span class="line">    final DocWriteRequest.OpType opType = context.getCurrent().opType();</span><br><span class="line"></span><br><span class="line">    final UpdateHelper.Result updateResult;</span><br><span class="line">    if (opType == DocWriteRequest.OpType.UPDATE) &#123;</span><br><span class="line">        final UpdateRequest updateRequest = (UpdateRequest) context.getCurrent();</span><br><span class="line">        try &#123;</span><br><span class="line">            // </span><br><span class="line">            updateResult = updateHelper.prepare(updateRequest, context.getPrimary(), nowInMillisSupplier);</span><br><span class="line">        &#125; catch (Exception failure) &#123;</span><br><span class="line">            // we may fail translating a update to index or delete operation</span><br><span class="line">            // we use index result to communicate failure while translating update request</span><br><span class="line">            final Engine.Result result =</span><br><span class="line">                new Engine.IndexResult(failure, updateRequest.version());</span><br><span class="line">            context.setRequestToExecute(updateRequest);</span><br><span class="line">            context.markOperationAsExecuted(result);</span><br><span class="line">            context.markAsCompleted(context.getExecutionResult());</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        // execute translated update request</span><br><span class="line">        switch (updateResult.getResponseResult()) &#123;</span><br><span class="line">            case CREATED:</span><br><span class="line">            case UPDATED:</span><br><span class="line">                IndexRequest indexRequest = updateResult.action();</span><br><span class="line">                IndexMetadata metadata = context.getPrimary().indexSettings().getIndexMetadata();</span><br><span class="line">                MappingMetadata mappingMd = metadata.mapping();</span><br><span class="line">                indexRequest.process(metadata.getCreationVersion(), mappingMd, updateRequest.concreteIndex());</span><br><span class="line">                context.setRequestToExecute(indexRequest);</span><br><span class="line">                break;</span><br><span class="line">            case DELETED:</span><br><span class="line">                context.setRequestToExecute(updateResult.action());</span><br><span class="line">                break;</span><br><span class="line">            case NOOP:</span><br><span class="line">                context.markOperationAsNoOp(updateResult.action());</span><br><span class="line">                context.markAsCompleted(context.getExecutionResult());</span><br><span class="line">                return true;</span><br><span class="line">            default:</span><br><span class="line">                throw new IllegalStateException(&quot;Illegal update operation &quot; + updateResult.getResponseResult());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        context.setRequestToExecute(context.getCurrent());</span><br><span class="line">        updateResult = null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    assert context.getRequestToExecute() != null; // also checks that we&apos;re in TRANSLATED state</span><br><span class="line"></span><br><span class="line">    final IndexShard primary = context.getPrimary();</span><br><span class="line">    final long version = context.getRequestToExecute().version();</span><br><span class="line">    final boolean isDelete = context.getRequestToExecute().opType() == DocWriteRequest.OpType.DELETE;</span><br><span class="line">    final Engine.Result result;</span><br><span class="line">    if (isDelete) &#123;</span><br><span class="line">        final DeleteRequest request = context.getRequestToExecute();</span><br><span class="line">        result = primary.applyDeleteOperationOnPrimary(version, request.id(), request.versionType(),</span><br><span class="line">            request.ifSeqNo(), request.ifPrimaryTerm());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final IndexRequest request = context.getRequestToExecute();</span><br><span class="line">        result = primary.applyIndexOperationOnPrimary(version, request.versionType(), new SourceToParse(</span><br><span class="line">                request.index(), request.id(), request.source(), request.getContentType(), request.routing()),</span><br><span class="line">                request.ifSeqNo(), request.ifPrimaryTerm(), request.getAutoGeneratedTimestamp(), request.isRetry());</span><br><span class="line">    &#125;</span><br><span class="line">    if (result.getResultType() == Engine.Result.Type.MAPPING_UPDATE_REQUIRED) &#123;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            primary.mapperService().merge(MapperService.SINGLE_MAPPING_NAME,</span><br><span class="line">                new CompressedXContent(result.getRequiredMappingUpdate(), XContentType.JSON, ToXContent.EMPTY_PARAMS),</span><br><span class="line">                MapperService.MergeReason.MAPPING_UPDATE_PREFLIGHT);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            logger.info(() -&gt; new ParameterizedMessage(&quot;&#123;&#125; mapping update rejected by primary&quot;, primary.shardId()), e);</span><br><span class="line">            onComplete(exceptionToResult(e, primary, isDelete, version), context, updateResult);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        mappingUpdater.updateMappings(result.getRequiredMappingUpdate(), primary.shardId(),</span><br><span class="line">            new ActionListener&lt;&gt;() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onResponse(Void v) &#123;</span><br><span class="line">                    context.markAsRequiringMappingUpdate();</span><br><span class="line">                    waitForMappingUpdate.accept(</span><br><span class="line">                        ActionListener.runAfter(new ActionListener&lt;&gt;() &#123;</span><br><span class="line">                            @Override</span><br><span class="line">                            public void onResponse(Void v) &#123;</span><br><span class="line">                                assert context.requiresWaitingForMappingUpdate();</span><br><span class="line">                                context.resetForExecutionForRetry();</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            @Override</span><br><span class="line">                            public void onFailure(Exception e) &#123;</span><br><span class="line">                                context.failOnMappingUpdate(e);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;, () -&gt; itemDoneListener.onResponse(null))</span><br><span class="line">                    );</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onFailure(Exception e) &#123;</span><br><span class="line">                    onComplete(exceptionToResult(e, primary, isDelete, version), context, updateResult);</span><br><span class="line">                    // Requesting mapping update failed, so we don&apos;t have to wait for a cluster state update</span><br><span class="line">                    assert context.isInitial();</span><br><span class="line">                    itemDoneListener.onResponse(null);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        return false;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        onComplete(result, context, updateResult);</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Prepares an update request by converting it into an index or delete request or an update response (no action).</span><br><span class="line"> */</span><br><span class="line">public Result prepare(UpdateRequest request, IndexShard indexShard, LongSupplier nowInMillis) &#123;</span><br><span class="line">    // 这里是实时获取</span><br><span class="line">    // 获取结果最终会到InternalEngine </span><br><span class="line">    // get(Get get, DocumentMapper mapper, Function&lt;Engine.Searcher, Engine.Searcher&gt; searcherWrapper)</span><br><span class="line">    // 后面会附上 代码</span><br><span class="line">    final GetResult getResult = indexShard.getService().getForUpdate(</span><br><span class="line">        request.id(), request.ifSeqNo(), request.ifPrimaryTerm());</span><br><span class="line">    return prepare(indexShard.shardId(), request, getResult, nowInMillis);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public GetResult getForUpdate(String id, long ifSeqNo, long ifPrimaryTerm) &#123;</span><br><span class="line">    // realtime是true</span><br><span class="line">    return get(id, new String[]&#123;RoutingFieldMapper.NAME&#125;, true,</span><br><span class="line">        Versions.MATCH_ANY, VersionType.INTERNAL, ifSeqNo, ifPrimaryTerm, FetchSourceContext.FETCH_SOURCE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private GetResult get(String id, String[] gFields, boolean realtime, long version, VersionType versionType,</span><br><span class="line">                      long ifSeqNo, long ifPrimaryTerm, FetchSourceContext fetchSourceContext) &#123;</span><br><span class="line">    currentMetric.inc();</span><br><span class="line">    try &#123;</span><br><span class="line">        long now = System.nanoTime();</span><br><span class="line">        GetResult getResult =</span><br><span class="line">            innerGet(id, gFields, realtime, version, versionType, ifSeqNo, ifPrimaryTerm, fetchSourceContext);</span><br><span class="line"></span><br><span class="line">        if (getResult.isExists()) &#123;</span><br><span class="line">            existsMetric.inc(System.nanoTime() - now);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            missingMetric.inc(System.nanoTime() - now);</span><br><span class="line">        &#125;</span><br><span class="line">        return getResult;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        currentMetric.dec();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private GetResult innerGet(String id, String[] gFields, boolean realtime, long version, VersionType versionType,</span><br><span class="line">                           long ifSeqNo, long ifPrimaryTerm, FetchSourceContext fetchSourceContext) &#123;</span><br><span class="line">    fetchSourceContext = normalizeFetchSourceContent(fetchSourceContext, gFields);</span><br><span class="line"></span><br><span class="line">    Engine.GetResult get = indexShard.get(new Engine.Get(realtime, realtime, id)</span><br><span class="line">        .version(version).versionType(versionType).setIfSeqNo(ifSeqNo).setIfPrimaryTerm(ifPrimaryTerm));</span><br><span class="line">    assert get.isFromTranslog() == false || realtime : &quot;should only read from translog if realtime enabled&quot;;</span><br><span class="line">    if (get.exists() == false) &#123;</span><br><span class="line">        get.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (get == null || get.exists() == false) &#123;</span><br><span class="line">        return new GetResult(shardId.getIndexName(), id, UNASSIGNED_SEQ_NO, UNASSIGNED_PRIMARY_TERM, -1, false, null, null, null);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        // break between having loaded it from translog (so we only have _source), and having a document to load</span><br><span class="line">        return innerGetLoadFromStoredFields(id, gFields, fetchSourceContext, get, mapperService);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        get.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public Engine.GetResult get(Engine.Get get) &#123;</span><br><span class="line">    readAllowed();</span><br><span class="line">    DocumentMapper mapper = mapperService.documentMapper();</span><br><span class="line">    if (mapper == null) &#123;</span><br><span class="line">        return GetResult.NOT_EXISTS;</span><br><span class="line">    &#125;</span><br><span class="line">    return getEngine().get(get, mapper, this::wrapSearcher);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line"> * Prepares an update request by converting it into an index or delete request or an update response (no action, in the event of a</span><br><span class="line"> * noop).</span><br><span class="line"> */</span><br><span class="line">protected Result prepare(ShardId shardId, UpdateRequest request, final GetResult getResult, LongSupplier nowInMillis) &#123;</span><br><span class="line">    if (getResult.isExists() == false) &#123;</span><br><span class="line">        // If the document didn&apos;t exist, execute the update request as an upsert</span><br><span class="line">        return prepareUpsert(shardId, request, getResult, nowInMillis);</span><br><span class="line">    &#125; else if (getResult.internalSourceRef() == null) &#123;</span><br><span class="line">        // no source, we can&apos;t do anything, throw a failure...</span><br><span class="line">        throw new DocumentSourceMissingException(shardId, request.id());</span><br><span class="line">    &#125; else if (request.script() == null &amp;&amp; request.doc() != null) &#123;</span><br><span class="line">        // The request has no script, it is a new doc that should be merged with the old document</span><br><span class="line">        return prepareUpdateIndexRequest(shardId, request, getResult, request.detectNoop());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // The request has a script (or empty script), execute the script and prepare a new index request</span><br><span class="line">        return prepareUpdateScriptRequest(shardId, request, getResult, nowInMillis);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，prepare在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/update/UpdateHelper.java" target="_blank" rel="noopener">org/elasticsearch/action/update/UpdateHelper.java</a> 中。</p><p>从代码中可以看到更新逻辑分两步：</p><ul><li>获取待更新文档的数据</li><li>执行更新文档的操作</li></ul><p>第1步最终会调用<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java" target="_blank" rel="noopener">InternalEngine</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java#L643" target="_blank" rel="noopener">get</a>方法。代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public GetResult get(Get get, DocumentMapper mapper, Function&lt;Engine.Searcher, Engine.Searcher&gt; searcherWrapper) &#123;</span><br><span class="line">    assert Objects.equals(get.uid().field(), IdFieldMapper.NAME) : get.uid().field();</span><br><span class="line">    try (ReleasableLock ignored = readLock.acquire()) &#123;</span><br><span class="line">        ensureOpen();</span><br><span class="line">        // 是否实时获取</span><br><span class="line">        if (get.realtime()) &#123;</span><br><span class="line">            final VersionValue versionValue;</span><br><span class="line">            try (Releasable ignore = versionMap.acquireLock(get.uid().bytes())) &#123;</span><br><span class="line">                // we need to lock here to access the version map to do this truly in RT</span><br><span class="line">                versionValue = getVersionFromMap(get.uid().bytes());</span><br><span class="line">            &#125;</span><br><span class="line">            if (versionValue != null) &#123;</span><br><span class="line">                if (versionValue.isDelete()) &#123;</span><br><span class="line">                    return GetResult.NOT_EXISTS;</span><br><span class="line">                &#125;</span><br><span class="line">                if (get.versionType().isVersionConflictForReads(versionValue.version, get.version())) &#123;</span><br><span class="line">                    throw new VersionConflictEngineException(shardId, get.id(),</span><br><span class="line">                        get.versionType().explainConflictForReads(versionValue.version, get.version()));</span><br><span class="line">                &#125;</span><br><span class="line">                if (get.getIfSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO &amp;&amp; (</span><br><span class="line">                    get.getIfSeqNo() != versionValue.seqNo || get.getIfPrimaryTerm() != versionValue.term</span><br><span class="line">                    )) &#123;</span><br><span class="line">                    throw new VersionConflictEngineException(shardId, get.id(),</span><br><span class="line">                        get.getIfSeqNo(), get.getIfPrimaryTerm(), versionValue.seqNo, versionValue.term);</span><br><span class="line">                &#125;</span><br><span class="line">                // 是否从Translog获取</span><br><span class="line">                if (get.isReadFromTranslog()) &#123;</span><br><span class="line">                    // this is only used for updates - API _GET calls will always read form a reader for consistency</span><br><span class="line">                    // the update call doesn&apos;t need the consistency since it&apos;s source only + _parent but parent can go away in 7.0</span><br><span class="line">                    if (versionValue.getLocation() != null) &#123;</span><br><span class="line">                        try &#123;</span><br><span class="line">                            final Translog.Operation operation = translog.readOperation(versionValue.getLocation());</span><br><span class="line">                            if (operation != null) &#123;</span><br><span class="line">                                return getFromTranslog(get, (Translog.Index) operation, mapper, searcherWrapper);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (IOException e) &#123;</span><br><span class="line">                            maybeFailEngine(&quot;realtime_get&quot;, e); // lets check if the translog has failed with a tragic event</span><br><span class="line">                            throw new EngineException(shardId, &quot;failed to read operation from translog&quot;, e);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        trackTranslogLocation.set(true);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                assert versionValue.seqNo &gt;= 0 : versionValue;</span><br><span class="line">                refreshIfNeeded(&quot;realtime_get&quot;, versionValue.seqNo);</span><br><span class="line">            &#125;</span><br><span class="line">            return getFromSearcher(get, acquireSearcher(&quot;realtime_get&quot;, SearcherScope.INTERNAL, searcherWrapper));</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // we expose what has been externally expose in a point in time snapshot via an explicit refresh</span><br><span class="line">            return getFromSearcher(get, acquireSearcher(&quot;get&quot;, SearcherScope.EXTERNAL, searcherWrapper));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1>总结</h1><p>update操作需要先获取原始文档，如果查询不到，会新增；如果存在，会根据原始文档更新。</p><p>虽然更新操作最终调用的方法也是<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java" target="_blank" rel="noopener">InternalEngine</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java#L854" target="_blank" rel="noopener">index</a>，但在更新时调用<a href="https://github.com/jiankunking/lucene" target="_blank" rel="noopener">lucene</a> <a href="https://github.com/jiankunking/lucene/blob/master/core/src/java/org/apache/lucene/index/IndexWriter.java#L1519" target="_blank" rel="noopener">softUpdateDocuments</a>，会包含两个操作：标记删除、新增。</p><p>相对于新增而言:</p><ul><li>多了一次完整的查询(为了保证一致性，update调用GET时将realtime选项设置为true，并且不可配置。因此update操作可能会导致refresh生成新的Lucene分段。)</li><li>多了一个标记删除</li></ul><p>如果数据量比较大，操作又比较频繁的情况下，update这种操作还是要慎重。</p>]]></content>
      <tags>
        <tag>Performance</tag>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Update</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]eBay Elasticsearch性能调优实践</title>
    <url>/elasticsearch-performance-tuning-practice-at-ebay.html</url>
    <content><![CDATA[<blockquote><p>翻译自：Elasticsearch Performance Tuning Practice at eBay<br>地址：<br><a href="https://tech.ebayinc.com/engineering/elasticsearch-performance-tuning-practice-at-ebay" target="_blank" rel="noopener">https://tech.ebayinc.com/engineering/elasticsearch-performance-tuning-practice-at-ebay</a></p></blockquote><a id="more"></a><p>Elasticsearch是一个基于Apache Lucene的开源搜索和分析引擎，允许用户近实时地存储、搜索和分析数据。在eBay上承载Elasticsearch集群的平台Pronto，使eBay内部客户可以轻松地部署、操作和扩展Elasticsearch，以实现全文搜索、实时分析和日志/事件监控。现在有60多个Elasticsearch集群和2000多个节点由Pronto管理。每天提取的文档达到180亿，每天的搜索请求达到35亿次。该平台提供了从供应、补救、安全性到监控、警报和诊断的全方位服务。</p><p>虽然Elasticsearch是为快速查询而设计的，但性能很大程度上取决于应用于应用程序的场景、要索引的数据量以及应用程序和用户查询数据的频率。本文总结了这些挑战，以及Pronto团队为解决这些挑战而构建的过程和工具。本文还展示了对各种配置进行基准测试的某些结果，以作说明。</p><h1>挑战</h1><p>迄今为止观察到的Pronto/Elasticsearch面临的挑战包括:</p><ul><li>高吞吐量:某些集群每天最多提取5TB数据，而某些集群每天要接收超过4亿个搜索请求。如果Elasticsearch无法及时处理请求，则请求将在上游累积。</li><li>低搜索等待时间:对于性能至关重要的群集，尤其是对于面向站点(site-facing)的系统，低搜索等待时间是强制性的，否则会影响用户体验。</li><li>由于数据或查询是可变的，因此最佳设置始终会更改。没有适用于所有方案的最佳设置。例如，将索引拆分为更多的分片将有助于耗时的查询，但它可能会损害其他查询的性能。</li></ul><h1>解决方案</h1><p>为了帮助我们的客户应对这些挑战，Pronto团队建立了性能测试、调优和监控的方式，从用户案例入手开始，一直持续到整个集群生命周期。</p><ul><li>大小调整:在开始使用新用例之前，先收集客户提供的信息，例如吞吐量，文档大小，文档数和搜索类型，以估计Elasticsearch集群的初始大小。</li><li>优化索引设计:与客户一起审查索引设计。</li><li>调整索引性能:根据用户方案调整索引性能和搜索性能。</li><li>调整搜索性能:使用用户实际数据/查询运行性能测试，并结合使用Elasticsearch配置参数来比较和分析测试结果。</li><li>运行性能测试:案例启动后，将监控群集，并且只要数据更改，查询更改或流量增加，用户就可以自由地重新运行性能测试。</li></ul><h2 id="大小">大小</h2><p>Pronto团队针对每种机器和每种受支持的Elasticsearch版本运行基准测试以收集性能数据，然后将其与客户提供的信息一起用于估计集群的初始大小，包括:</p><ul><li>索引吞吐量</li><li>文档大小</li><li>搜索量</li><li>查询类型</li><li>热索引文档数量</li><li>保留策略</li><li>响应时间要求</li><li>SLA级别</li></ul><h2 id="优化索引设计">优化索引设计</h2><p>在开始提取数据并运行查询之前，请三思而后行。索引代表什么？ Elastic官方的回答是&quot;具有一些相似特征的文档集合。&quot; 因此，下一个问题是&quot;我应该使用哪些特征对数据进行分组？ 我应该将所有文档放入一个索引还是多个索引？&quot; 答案是，这取决于您使用的查询。以下是有关如何根据最常用的查询来组织索引的一些建议。</p><ul><li>例如，Elasticsearch接收了大量全局产品信息，大多数查询都有一个过滤子句&quot;region&quot;，并且很少有机会运行跨区域的查询。可以优化查询主体:</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;must&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;title&quot;: &quot;$&#123;title&#125;&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;term&quot;: &#123;</span><br><span class="line">                    &quot;region&quot;: &quot;US&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>&gt; 在这种情况下，如果将该索引按地区划分为几个较小的索引，如美国、欧洲和其他国家，我们可以获得更好的性能。然后可以从查询中删除filter子句。如果需要运行跨区域查询，可以将多个索引或通配符传递给Elasticsearch。
</code></pre><ul><li><p>如果查询具有过滤器字段且其值不可枚举，请使用路由。通过使用过滤器字段值作为路由键并删除过滤器，我们可以将索引分为多个分片。</p><blockquote><p>例如，Elasticsearch接收了数百万个订单，并且大多数查询都需要按买家ID查询订单。无法为每个买家创建索引，因此我们无法通过买家ID将数据分成多个索引。一个合适的解决方案是通过路由将相同买家ID的所有订单路由到同一个分片。这样，几乎所有的查询都可以在匹配routing key的分片中完成。</p></blockquote></li><li><p>如果查询具有日期范围过滤器，则按日期组织数据。这适用于大多数日志记录或监控方案。我们可以按每天，每周或每月组织索引，然后可以按指定的日期范围获取索引列表。Elasticsearch仅需要查询较小的数据集，而不是整个数据集。另外，当数据过期时，很容易收缩/删除旧索引。</p></li><li><p>显式设置映射。Elasticsearch可以动态创建映射，但是可能并不适合所有情况。例如，Elasticsearch 5.x中的默认字符串字段映射都是&quot;keyword&quot;和&quot;text&quot;类型。在许多情况下都是不必要的。</p></li><li><p>如果使用用户定义的ID或路由为文档建立索引，要注意避免分片不平衡。Elasticsearch使用随机ID生成器和哈希算法来确保将文档平均分配给分片。当使用用户定义的ID或路由时，ID或路由key可能不够随机，会导致某些分片可能明显大于其他分片。在这种情况下，对该分片的读/写操作将比其他分片慢得多。我们可以优化ID/路由键或使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html#routing-index-partition" target="_blank" rel="noopener">index.routing_partition_size</a>（在5.3及更高版本中可用）。</p></li><li><p>使分片均匀分布在节点上。如果一个节点的分片比其他节点多，那么它将比其他节点承担更多的负载，可能成为整个系统的瓶颈。</p></li></ul><h2 id="调优索引性能">调优索引性能</h2><p>对于日志和监控等需要大量索引的场景，索引性能是关键指标。以下是一些建议。</p><ul><li>使用批量(bulk)请求。</li><li>使用多个线程发送请求。</li><li>增加刷新(refresh)间隔。每次刷新事件发生时，Elasticsearch都会创建一个新的Lucene段，然后合并它们。增加刷新间隔可以降低创建/合并的成本。请注意，只有在刷新后才可以搜索文档。</li></ul><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture23.png" alt="Relationship between performance and refresh interval"></p><p>从上图中可以看出，随着刷新间隔的增加，吞吐量增加，响应时间减少。我们可以使用下面的请求来检查我们有多少段，以及在刷新和合并上花费了多少时间。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET index_name/_stats?filter_path= indices.**.refresh,indices.**.segments,indices.**.merges</span><br></pre></td></tr></table></figure><ul><li>减少副本数量。Elasticsearch需要为每个索引请求将文档写入主分片和所有副本分片。显然，大的副本数会降低索引速度，但另一方面，它会提高搜索性能。我们将在本文后面讨论它。</li></ul><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture22.png" alt="Relationship between performance and replica number"></p><p>从上图中，我们可以看到随着副本数的增加，吞吐量降低，响应时间增加。</p><ul><li>尽可能使用自动生成的ID。Elasticsearch可以确保自动生成的ID是唯一的，以避免版本查找。如果客户确实需要使用自定义ID，我们的建议是选择一个对Lucene友好的ID，例如零填充顺序ID，UUID-1或Nano time。这些ID具有一致的顺序模式，可以很好地压缩。相比之下，诸如UUID-4之类的ID本质上是随机的，这提供了较差的压缩并降低了Lucene的运行速度。</li></ul><h2 id="调优搜索性能">调优搜索性能</h2><p>使用Elasticsearch的主要原因是为了支持对数据的搜索。用户应该能够快速找到所需的信息。搜索性能取决于很多因素。</p><ul><li>如果可能，请使用过滤(filter)器上下文而不是查询(query)上下文。query子句用于回答&quot;此文档与该子句的匹配程度如何？“filter子句用于回答&quot;此文档是否与此子句匹配？” Elasticsearch只需回答&quot;是&quot;或&quot;否&quot;。它不需要为过滤器子句计算相关性得分，并且可以缓存过滤器结果。有关详细信息，请参见<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html" target="_blank" rel="noopener">查询和过滤上下文</a>。</li></ul><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture24.png" alt="Compare between query and filter"></p><ul><li><p>增加刷新(refresh)间隔。正如我们在调优索引性能部分中提到的那样，每次刷新时，Elasticsearch都会创建新的segment。增加刷新间隔将有助于减少段数并减少搜索的IO成本。并且，一旦刷新发生并更改了数据，缓存将无效。增加刷新间隔可以使Elasticsearch更有效地利用缓存。</p></li><li><p>增加副本数。Elasticsearch可以对主分片或副本分片执行搜索。您拥有的副本越多，搜索中可以用到的节点越多。</p></li></ul><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture25.png" alt="Relationship between performance and replica number"></p><p>从上图可以看到，搜索吞吐量几乎与副本数成线性关系。请注意，在此测试中，测试群集具有足够的数据节点，以确保每个分片都具有排他节点。如果不能满足此条件，则搜索吞吐量将不那么理想。</p><ul><li><p>尝试不同的分片数。&quot;我应该为索引设置多少个碎片？&quot;这可能是我们最常看到的问题。不幸的是，没有适用于所有情况的正确数字。这完全取决于您的情况。</p><p>分片数太小将使搜索无法扩展。例如，如果分片数设置为1，则索引中的所有文档都将存储在一个分片中。对于每次搜索，只能涉及一个节点。如果您有很多文档，那会很费时间。从另一方面说，创建具有太多分片的索引也对性能有害，因为Elasticsearch需要对所有分片运行查询，除非在请求中指定了路由key，然后才将所有返回的结果提取并合并在一起。</p><p>根据我们的经验，如果索引小于1G，可以将分片数设置为1。对于大多数情况，我们可以将分片数保留为默认值5，但是如果分片大小超过30GB，则应增加分片数以将索引拆分为更多分片。创建索引后就无法更改分片数，但是我们可以创建一个新索引并使用reindex API来移动数据。</p><p>我们测试了一个索引，该索引包含1亿个文档，约为150GB。我们使用了100个线程来发送搜索请求。</p></li></ul><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture26.png" alt="Relationship between performance and 分片 number"></p><p>从上图可以看出，最优的分片数量为11。搜索吞吐量在开始时增加（响应时间减少），但随着分片数量的增加而减少（响应时间增加）。</p><p>请注意，在此测试中，就像在副本数测试中一样，每个分片都有一个独占节点。如果不能满足此条件，则搜索吞吐量将不如该图所示。</p><p>在这种情况下，我们建议您尝试使用小于最优值的分片数，因为如果使用大的分片数，它将需要很多节点，并且使每个分片都具有专用的数据节点。</p><ul><li><p>节点查询缓存。<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-cache.html" target="_blank" rel="noopener">节点查询缓存</a>仅缓存在过滤器(filter)上下文中使用的查询。与查询(query)子句不同，过滤器子句是&quot;是&quot;或&quot;否&quot;的问题。Elasticsearch使用位集(bit set)机制来缓存过滤器结果，以便以后使用相同过滤器的查询将得到加速。请注意，只有包含超过10,000个文档（或总文档的3％，以较大者为准）的段(segments)将启用查询缓存。有关更多详细信息，请参阅<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/filter-caching.html#_independent_query_caching" target="_blank" rel="noopener">缓存</a>。</p><p>我们可以使用以下请求来检查节点查询缓存是否有效。</p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET index_name/_stats?filter_path=indices.**.query_cache</span><br><span class="line">&#123;</span><br><span class="line">  &quot;indices&quot;: &#123;</span><br><span class="line">    &quot;index_name&quot;: &#123;</span><br><span class="line">      &quot;primaries&quot;: &#123;</span><br><span class="line">        &quot;query_cache&quot;: &#123;</span><br><span class="line">          &quot;memory_size_in_bytes&quot;: 46004616,</span><br><span class="line">          &quot;total_count&quot;: 1588886,</span><br><span class="line">          &quot;hit_count&quot;: 515001,</span><br><span class="line">          &quot;miss_count&quot;: 1073885,</span><br><span class="line">          &quot;cache_size&quot;: 630,</span><br><span class="line">          &quot;cache_count&quot;: 630,</span><br><span class="line">          &quot;evictions&quot;: 0</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;total&quot;: &#123;</span><br><span class="line">        &quot;query_cache&quot;: &#123;</span><br><span class="line">          &quot;memory_size_in_bytes&quot;: 46004616,</span><br><span class="line">          &quot;total_count&quot;: 1588886,</span><br><span class="line">          &quot;hit_count&quot;: 515001,</span><br><span class="line">          &quot;miss_count&quot;: 1073885,</span><br><span class="line">          &quot;cache_size&quot;: 630,</span><br><span class="line">          &quot;cache_count&quot;: 630,</span><br><span class="line">          &quot;evictions&quot;: 0</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>分片查询缓存。如果大多数查询是聚合查询，则应查看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/%E5%88%86%E7%89%87-request-cache.html#_cache_invalidation" target="_blank" rel="noopener">分片查询缓存</a>，该缓存可以缓存聚合结果，以便Elasticsearch以很少的成本直接为请求提供服务。有几件事要注意:</p><ul><li>设置&quot;size&quot;:0。分片查询缓存仅缓存汇总结果和建议(suggestion)。它不会缓存命中，因此如果将size设置为非零，就不能从缓存中受益。</li><li>有效负载JSON必须相同。分片查询缓存使用JSON主体作为缓存键，因此您需要确保JSON主体不变，并确保JSON主体中的键顺序相同。</li><li>四舍五入查询时间。不要在查询中直接使用Date.now之类的变量。四舍五入。否则，每个请求都将具有不同的有效负载主体，这将使缓存始终无效。我们建议您将日期时间舍入为小时或天，以更有效地利用缓存。</li></ul><p>我们可以使用下面的请求来检查分片查询缓存是否有效。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET index_name/_stats?filter_path=indices.**.request_cache</span><br><span class="line">&#123;</span><br><span class="line">  &quot;indices&quot;: &#123;</span><br><span class="line">    &quot;index_name&quot;: &#123;</span><br><span class="line">      &quot;primaries&quot;: &#123;</span><br><span class="line">        &quot;request_cache&quot;: &#123;</span><br><span class="line">          &quot;memory_size_in_bytes&quot;: 0,</span><br><span class="line">          &quot;evictions&quot;: 0,</span><br><span class="line">          &quot;hit_count&quot;: 541,</span><br><span class="line">          &quot;miss_count&quot;: 514098</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;total&quot;: &#123;</span><br><span class="line">        &quot;request_cache&quot;: &#123;</span><br><span class="line">          &quot;memory_size_in_bytes&quot;: 0,</span><br><span class="line">          &quot;evictions&quot;: 0,</span><br><span class="line">          &quot;hit_count&quot;: 982,</span><br><span class="line">          &quot;miss_count&quot;: 947321</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>仅检索必须字段。如果文档很大，并且只需要几个字段，请使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-fields.html#stored-fields" target="_blank" rel="noopener">stored_fields</a>检索需要的字段，而不是所有字段。</li><li>避免搜索停用词。诸如&quot;a&quot;和&quot;the&quot;之类的停用词可能会导致查询匹配结果数量激增。想象一下您有一百万个文档。搜索&quot;fox&quot;可能会返回数十次匹配，但是搜索&quot;the fox&quot;可能会返回索引中的所有文档，因为&quot;the&quot;几乎出现在所有文档中。Elasticsearch需要对所有命中结果进行评分和排序，以使诸如&quot;the fox&quot;之类的查询减慢整个系统的速度。您可以使用停止令牌过滤器(stop token filter)删除停用词，或使用&quot;and&quot;运算符将查询从&quot;the fox&quot;更改为&quot;the AND fox&quot;，以获得更精确的匹配结果。</li></ul><p>如果索引中经常使用某些单词，但默认停用词列表中没有这些单词，则可以使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html#query-dsl-match-query-cutoff" target="_blank" rel="noopener">截止频率(cutoff-frequency)</a>来动态处理它们。</p><ul><li><p>如果您不关心文档的返回顺序，请按_doc排序。默认情况下，Elasticsearch使用&quot;_score&quot;字段按分数排序。如果您不关心顺序，则可以使用&quot;sort&quot;:&quot;_ doc&quot;让Elasticsearch按索引顺序返回匹配。</p></li><li><p>避免使用脚本查询实时计算(Avoid using a script query to calculate hits in flight)。索引时存储计算出的字段。例如，我们有一个包含大量用户信息的索引，并且我们需要查询所有以&quot;1234&quot;开头的用户。您可能想运行脚本查询，例如&quot;source&quot;:“doc[‘num’].value.startsWith(‘1234’).”。这种查询真很耗资源，并且会降低整个系统的速度。在建立索引时，请考虑添加一个名为&quot;num_prefix&quot;的字段。然后我们可以查询&quot;name_prefix&quot;:“1234”。</p></li><li><p>避免使用通配符查询。</p></li></ul></li></ul><h1>性能测试</h1><p>对于每项更改，都必须运行性能测试以验证更改是否合适。由于Elasticsearch是restful的服务，因此您可以使用Rally，Apache Jmeter和Gatling等工具来运行性能测试。因为Pronto团队需要在每种类型的机器和Elasticsearch版本上运行大量基准测试，并且我们需要在许多Elasticsearch集群上针对Elasticsearch配置参数组合运行性能测试，所以这些工具无法满足我们的要求。</p><p>Pronto团队基于Gatling构建了在线绩效分析服务，以帮助客户和我们进行绩效测试并进行回归分析。服务提供的功能使我们能够:</p><ul><li>轻松添加/编辑测试。用户可以根据自己输入的查询或文档结构生成测试，而无需Gatling或Scala知识。</li><li>按顺序运行多个测试，无需人工干预。它可以在每次测试之前/之后检查状态并更改Elasticsearch设置。</li><li>帮助用户比较和分析测试结果分析。测试期间的测试结果和群集统计信息将保留并可以通过预定义的Kibana可视化文件进行分析。</li><li>从命令行或Web UI运行测试。还为与其他系统的每次集成提供了Rest API。</li></ul><p>下面是它的架构：</p><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture27.png" alt="Performance test service architecture (click to enlarge diagram)"></p><p>用户可以查看每项测试的Gatling报告，并查看Kibana预定义的可视化效果，以进行进一步的分析和比较，如下所示。</p><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture28.png" alt="Gatling report"></p><p><img data-src="/images/elasticsearch-performance-tuning-practice-at-ebay/Picture29.png" alt="Gatling report"></p><h1>总结</h1><p>本文总结了索引/分片/副本设计以及在设计Elasticsearch集群时应考虑的其他一些配置，以满足对提取和搜索性能的高期望。它还说明了Pronto如何帮助客户进行索引初始大小确定，索引设计和调优以及性能测试。截至目前，Pronto团队已帮助包括订单管理系统（OMS）和搜索引擎优化（SEO）在内的许多客户实现了苛刻的性能目标，从而为eBay的关键业务做出了贡献。</p><p>Elasticsearch的性能取决于许多因素，包括文档结构，文档大小，索引设置/映射，请求率，数据集大小，查询命中数等。针对一种情况的建议不一定适用于另一种情况。全面测试性能，收集遥测数据，根据您的工作负载调整配置并优化群集以满足性能要求非常重要。</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Cluster</tag>
        <tag>Tuning</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>404</title>
    <url>/404.html</url>
    <content><![CDATA[<p><a href="https://jiankunking.com">如果你来访我，我不在，</a><br><a href="https://jiankunking.com">请和我门外的花坐一会儿，</a><br><a href="https://jiankunking.com">它们很温暖，我注视它们很多很多日子了。</a></p>]]></content>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 检索分析</title>
    <url>/elasticsearch-search-source-code-analysis.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第二篇：Elasticsearch 搜索<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><h1>目的</h1><p>在看源码之前先梳理一下，自己对于检索流程疑惑的点：<br>当索引是按照日期拆分之后，在使用-* 检索，会不会通过索引层面的时间配置直接跳过无关索引？使用*会对性能造成多大的影响？</p><h1>源码分析</h1><p><font color="DeepPink"><strong>第二部分是代码分析的过程，不想看的朋友可以跳过直接看第三部分总结。</strong></font></p><p>分析的话，咱们就以_search操作为主线。</p><p>在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java" target="_blank" rel="noopener">RestSearchAction</a>可以看到：</p><ul><li>路由注册</li><li>请求参数转换</li></ul><p>真正执行的是<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/TransportSearchAction.java" target="_blank" rel="noopener">TransportSearchAction</a>，类图如下：</p><p><img data-src="/images/elasticsearch-search-source-code-analysis/TransportSearchAction.png" alt></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TransportSearchAction doExecute =&gt;</span><br><span class="line">// executeRequest中会判断是local请求还是remote请求</span><br><span class="line">// local请求会执行executeLocalSearch，在executeLocalSearch中会将remote相关参数置空，然后在调用executeSearch</span><br><span class="line">// remote请求会执行executeSearch</span><br><span class="line">TransportSearchAction executeRequest =&gt;</span><br><span class="line">TransportSearchAction executeLocalSearch|executeSearch =&gt;</span><br><span class="line">// executeSearch会合并remoteShardIterators（跨集群访问）与localShardIterators得到shardIterators</span><br><span class="line">// 校验shard数是否超限</span><br><span class="line">TransportSearchAction executeSearch =&gt;</span><br></pre></td></tr></table></figure><p>下面先看一下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void executeRequest(Task task, SearchRequest searchRequest,</span><br><span class="line">                            SearchAsyncActionProvider searchAsyncActionProvider, ActionListener&lt;SearchResponse&gt; listener) &#123;</span><br><span class="line">    final long relativeStartNanos = System.nanoTime();</span><br><span class="line">    final SearchTimeProvider timeProvider =</span><br><span class="line">        new SearchTimeProvider(searchRequest.getOrCreateAbsoluteStartMillis(), relativeStartNanos, System::nanoTime);</span><br><span class="line">    ActionListener&lt;SearchSourceBuilder&gt; rewriteListener = ActionListener.wrap(source -&gt; &#123;</span><br><span class="line">        if (source != searchRequest.source()) &#123;</span><br><span class="line">            // only set it if it changed - we don&apos;t allow null values to be set but it might be already null. this way we catch</span><br><span class="line">            // situations when source is rewritten to null due to a bug</span><br><span class="line">            searchRequest.source(source);</span><br><span class="line">        &#125;</span><br><span class="line">        final SearchContextId searchContext;</span><br><span class="line">        final Map&lt;String, OriginalIndices&gt; remoteClusterIndices;</span><br><span class="line">        if (searchRequest.pointInTimeBuilder() != null) &#123;</span><br><span class="line">            searchContext = searchRequest.pointInTimeBuilder().getSearchContextId(namedWriteableRegistry);</span><br><span class="line">            remoteClusterIndices = getIndicesFromSearchContexts(searchContext, searchRequest.indicesOptions());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            searchContext = null;</span><br><span class="line">            remoteClusterIndices = remoteClusterService.groupIndices(searchRequest.indicesOptions(), searchRequest.indices());</span><br><span class="line">        &#125;</span><br><span class="line">        OriginalIndices localIndices = remoteClusterIndices.remove(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);</span><br><span class="line">        final ClusterState clusterState = clusterService.state();</span><br><span class="line">        if (remoteClusterIndices.isEmpty()) &#123;</span><br><span class="line">            executeLocalSearch(</span><br><span class="line">                task, timeProvider, searchRequest, localIndices, clusterState, listener, searchContext, searchAsyncActionProvider);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // 对应 ccs_minimize_roundtrips</span><br><span class="line">            // https://www.elastic.co/guide/en/elasticsearch/reference/7.9/modules-cross-cluster-search.html</span><br><span class="line">            if (shouldMinimizeRoundtrips(searchRequest)) &#123;</span><br><span class="line">                final TaskId parentTaskId = task.taskInfo(clusterService.localNode().getId(), false).getTaskId();</span><br><span class="line">                ccsRemoteReduce(parentTaskId, searchRequest, localIndices, remoteClusterIndices, timeProvider,</span><br><span class="line">                    searchService.aggReduceContextBuilder(searchRequest),</span><br><span class="line">                    remoteClusterService, threadPool, listener,</span><br><span class="line">                    (r, l) -&gt; executeLocalSearch(</span><br><span class="line">                        task, timeProvider, r, localIndices, clusterState, l, searchContext, searchAsyncActionProvider));</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                AtomicInteger skippedClusters = new AtomicInteger(0);</span><br><span class="line">                // 针对每个集群将搜索请求发送出去，</span><br><span class="line">                // 目标集群TransportSearchAction收到请求调用doExecute方法处理</span><br><span class="line">                collectSearchShards(searchRequest.indicesOptions(), searchRequest.preference(), searchRequest.routing(),</span><br><span class="line">                    skippedClusters, remoteClusterIndices, remoteClusterService, threadPool,</span><br><span class="line">                    ActionListener.wrap(</span><br><span class="line">                        searchShardsResponses -&gt; &#123;</span><br><span class="line">                            final BiFunction&lt;String, String, DiscoveryNode&gt; clusterNodeLookup =</span><br><span class="line">                                getRemoteClusterNodeLookup(searchShardsResponses);</span><br><span class="line">                            final Map&lt;String, AliasFilter&gt; remoteAliasFilters;</span><br><span class="line">                            final List&lt;SearchShardIterator&gt; remoteShardIterators;</span><br><span class="line">                            if (searchContext != null) &#123;</span><br><span class="line">                                remoteAliasFilters = searchContext.aliasFilter();</span><br><span class="line">                                remoteShardIterators = getRemoteShardsIteratorFromPointInTime(searchShardsResponses,</span><br><span class="line">                                    searchContext, searchRequest.pointInTimeBuilder().getKeepAlive(), remoteClusterIndices);</span><br><span class="line">                            &#125; else &#123;</span><br><span class="line">                                remoteAliasFilters = getRemoteAliasFilters(searchShardsResponses);</span><br><span class="line">                                remoteShardIterators = getRemoteShardsIterator(searchShardsResponses, remoteClusterIndices,</span><br><span class="line">                                    remoteAliasFilters);</span><br><span class="line">                            &#125;</span><br><span class="line">                            int localClusters = localIndices == null ? 0 : 1;</span><br><span class="line">                            int totalClusters = remoteClusterIndices.size() + localClusters;</span><br><span class="line">                            int successfulClusters = searchShardsResponses.size() + localClusters;</span><br><span class="line">                            executeSearch((SearchTask) task, timeProvider, searchRequest, localIndices, remoteShardIterators,</span><br><span class="line">                                clusterNodeLookup, clusterState, remoteAliasFilters, listener,</span><br><span class="line">                                new SearchResponse.Clusters(totalClusters, successfulClusters, skippedClusters.get()),</span><br><span class="line">                                searchContext, searchAsyncActionProvider);</span><br><span class="line">                        &#125;,</span><br><span class="line">                        listener::onFailure));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, listener::onFailure);</span><br><span class="line">    if (searchRequest.source() == null) &#123;</span><br><span class="line">        rewriteListener.onResponse(searchRequest.source());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        Rewriteable.rewriteAndFetch(searchRequest.source(), searchService.getRewriteContext(timeProvider::getAbsoluteStartMillis),</span><br><span class="line">            rewriteListener);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面再看一下executeSearch：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void executeSearch(SearchTask task, SearchTimeProvider timeProvider, SearchRequest searchRequest,</span><br><span class="line">                              OriginalIndices localIndices, List&lt;SearchShardIterator&gt; remoteShardIterators,</span><br><span class="line">                              BiFunction&lt;String, String, DiscoveryNode&gt; remoteConnections, ClusterState clusterState,</span><br><span class="line">                              Map&lt;String, AliasFilter&gt; remoteAliasMap, ActionListener&lt;SearchResponse&gt; listener,</span><br><span class="line">                              SearchResponse.Clusters clusters, @Nullable SearchContextId searchContext,</span><br><span class="line">                              SearchAsyncActionProvider searchAsyncActionProvider) &#123;</span><br><span class="line">       // red状态也可以查询</span><br><span class="line">       clusterState.blocks().globalBlockedRaiseException(ClusterBlockLevel.READ);</span><br><span class="line"></span><br><span class="line">       // TODO: I think startTime() should become part of ActionRequest and that should be used both for index name</span><br><span class="line">       // date math expressions and $now in scripts. This way all apis will deal with now in the same way instead</span><br><span class="line">       // of just for the _search api</span><br><span class="line">       final List&lt;SearchShardIterator&gt; localShardIterators;</span><br><span class="line">       final Map&lt;String, AliasFilter&gt; aliasFilter;</span><br><span class="line"></span><br><span class="line">       final String[] concreteLocalIndices;</span><br><span class="line">       if (searchContext != null) &#123;</span><br><span class="line">           assert searchRequest.pointInTimeBuilder() != null;</span><br><span class="line">           aliasFilter = searchContext.aliasFilter();</span><br><span class="line">           concreteLocalIndices = localIndices == null ? new String[0] : localIndices.indices();</span><br><span class="line">           localShardIterators = getLocalLocalShardsIteratorFromPointInTime(clusterState, localIndices,</span><br><span class="line">               searchRequest.getLocalClusterAlias(), searchContext, searchRequest.pointInTimeBuilder().getKeepAlive());</span><br><span class="line">       &#125; else &#123;</span><br><span class="line">           final Index[] indices = resolveLocalIndices(localIndices, clusterState, timeProvider);</span><br><span class="line">           Map&lt;String, Set&lt;String&gt;&gt; routingMap = indexNameExpressionResolver.resolveSearchRouting(clusterState, searchRequest.routing(),</span><br><span class="line">               searchRequest.indices());</span><br><span class="line">           routingMap = routingMap == null ? Collections.emptyMap() : Collections.unmodifiableMap(routingMap);</span><br><span class="line">           concreteLocalIndices = new String[indices.length];</span><br><span class="line">           for (int i = 0; i &lt; indices.length; i++) &#123;</span><br><span class="line">               concreteLocalIndices[i] = indices[i].getName();</span><br><span class="line">           &#125;</span><br><span class="line">           Map&lt;String, Long&gt; nodeSearchCounts = searchTransportService.getPendingSearchRequests();</span><br><span class="line">           GroupShardsIterator&lt;ShardIterator&gt; localShardRoutings = clusterService.operationRouting().searchShards(clusterState,</span><br><span class="line">               concreteLocalIndices, routingMap, searchRequest.preference(),</span><br><span class="line">               searchService.getResponseCollectorService(), nodeSearchCounts);</span><br><span class="line">           localShardIterators = StreamSupport.stream(localShardRoutings.spliterator(), false)</span><br><span class="line">               .map(it -&gt; new SearchShardIterator(</span><br><span class="line">                   searchRequest.getLocalClusterAlias(), it.shardId(), it.getShardRoutings(), localIndices))</span><br><span class="line">               .collect(Collectors.toList());</span><br><span class="line">           aliasFilter = buildPerIndexAliasFilter(searchRequest, clusterState, indices, remoteAliasMap);</span><br><span class="line">       &#125;</span><br><span class="line">       final GroupShardsIterator&lt;SearchShardIterator&gt; shardIterators = mergeShardsIterators(localShardIterators, remoteShardIterators);</span><br><span class="line"></span><br><span class="line">       failIfOverShardCountLimit(clusterService, shardIterators.size());</span><br><span class="line"></span><br><span class="line">       Map&lt;String, Float&gt; concreteIndexBoosts = resolveIndexBoosts(searchRequest, clusterState);</span><br><span class="line"></span><br><span class="line">       // optimize search type for cases where there is only one shard group to search on</span><br><span class="line">       if (shardIterators.size() == 1) &#123;</span><br><span class="line">           // if we only have one group, then we always want Q_T_F, no need for DFS, and no need to do THEN since we hit one shard</span><br><span class="line">           searchRequest.searchType(QUERY_THEN_FETCH);</span><br><span class="line">       &#125;</span><br><span class="line">       if (searchRequest.allowPartialSearchResults() == null) &#123;</span><br><span class="line">           // No user preference defined in search request - apply cluster service default</span><br><span class="line">           searchRequest.allowPartialSearchResults(searchService.defaultAllowPartialSearchResults());</span><br><span class="line">       &#125;</span><br><span class="line">       if (searchRequest.isSuggestOnly()) &#123;</span><br><span class="line">           // disable request cache if we have only suggest</span><br><span class="line">           searchRequest.requestCache(false);</span><br><span class="line">           switch (searchRequest.searchType()) &#123;</span><br><span class="line">               case DFS_QUERY_THEN_FETCH:</span><br><span class="line">                   // convert to Q_T_F if we have only suggest</span><br><span class="line">                   searchRequest.searchType(QUERY_THEN_FETCH);</span><br><span class="line">                   break;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       final DiscoveryNodes nodes = clusterState.nodes();</span><br><span class="line">       BiFunction&lt;String, String, Transport.Connection&gt; connectionLookup = buildConnectionLookup(searchRequest.getLocalClusterAlias(),</span><br><span class="line">           nodes::get, remoteConnections, searchTransportService::getConnection);</span><br><span class="line">       final Executor asyncSearchExecutor = asyncSearchExecutor(concreteLocalIndices, clusterState);</span><br><span class="line">       // 判断是否需要在查询前做目标分片过滤</span><br><span class="line">       // pre_filter_shard_size</span><br><span class="line">       // https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html</span><br><span class="line">       // shouldPreFilterSearchShards,判断为true需要同时满足3个条件：</span><br><span class="line">	// 1、查询类型为QUERY_THEN_FETCH</span><br><span class="line">       // 2、是否能通过查询重写预判出查询结果为空或者有字段排序</span><br><span class="line">       // 3、实际的查询分片数量&gt; preFilterShardSize(默认128)</span><br><span class="line">       // 需要注意的是：</span><br><span class="line">       // pre-filter 最主要的作用不是降低查询延迟，而是 pre-filter 阶段可以不占用search theadpool，减少了这个线程池的占用情况。</span><br><span class="line">       final boolean preFilterSearchShards = shouldPreFilterSearchShards(clusterState, searchRequest, concreteLocalIndices,</span><br><span class="line">           localShardIterators.size() + remoteShardIterators.size());</span><br><span class="line">       // 调用searchAsyncAction进行异步搜索，search操作是由action的start方法来处理的。</span><br><span class="line">       searchAsyncActionProvider.asyncSearchAction(</span><br><span class="line">           task, searchRequest, asyncSearchExecutor, shardIterators, timeProvider, connectionLookup, clusterState,</span><br><span class="line">           Collections.unmodifiableMap(aliasFilter), concreteIndexBoosts, listener,</span><br><span class="line">           preFilterSearchShards, threadPool, clusters).start();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>在看searchAsyncAction之前先看一下AbstractSearchAsyncAction的继承及实现类：<br><img data-src="/images/elasticsearch-search-source-code-analysis/AbstractSearchAsyncAction.png" alt></p><p>searchAsyncAction主要是生成查询的请求，也就是AbstractSearchAsyncAction的实例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private AbstractSearchAsyncAction&lt;? extends SearchPhaseResult&gt; searchAsyncAction(</span><br><span class="line">        SearchTask task,</span><br><span class="line">        SearchRequest searchRequest,</span><br><span class="line">        Executor executor,</span><br><span class="line">        GroupShardsIterator&lt;SearchShardIterator&gt; shardIterators,</span><br><span class="line">        SearchTimeProvider timeProvider,</span><br><span class="line">        BiFunction&lt;String, String, Transport.Connection&gt; connectionLookup,</span><br><span class="line">        ClusterState clusterState,</span><br><span class="line">        Map&lt;String, AliasFilter&gt; aliasFilter,</span><br><span class="line">        Map&lt;String, Float&gt; concreteIndexBoosts,</span><br><span class="line">        ActionListener&lt;SearchResponse&gt; listener,</span><br><span class="line">        boolean preFilter,</span><br><span class="line">        ThreadPool threadPool,</span><br><span class="line">        SearchResponse.Clusters clusters) &#123;</span><br><span class="line">        if (preFilter) &#123;</span><br><span class="line">            return new CanMatchPreFilterSearchPhase(logger, searchTransportService, connectionLookup,</span><br><span class="line">                aliasFilter, concreteIndexBoosts, executor, searchRequest, listener, shardIterators,</span><br><span class="line">                timeProvider, clusterState, task, (iter) -&gt; &#123;</span><br><span class="line">                AbstractSearchAsyncAction&lt;? extends SearchPhaseResult&gt; action = searchAsyncAction(</span><br><span class="line">                    task,</span><br><span class="line">                    searchRequest,</span><br><span class="line">                    executor,</span><br><span class="line">                    iter,</span><br><span class="line">                    timeProvider,</span><br><span class="line">                    connectionLookup,</span><br><span class="line">                    clusterState,</span><br><span class="line">                    aliasFilter,</span><br><span class="line">                    concreteIndexBoosts,</span><br><span class="line">                    listener,</span><br><span class="line">                    false,</span><br><span class="line">                    threadPool,</span><br><span class="line">                    clusters);</span><br><span class="line">                return new SearchPhase(action.getName()) &#123;</span><br><span class="line">                    @Override</span><br><span class="line">                    public void run() &#123;</span><br><span class="line">                        action.start();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;;</span><br><span class="line">            &#125;, clusters, searchService.getCoordinatorRewriteContextProvider(timeProvider::getAbsoluteStartMillis));</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            final QueryPhaseResultConsumer queryResultConsumer = searchPhaseController.newSearchPhaseResults(executor,</span><br><span class="line">                circuitBreaker, task.getProgressListener(), searchRequest, shardIterators.size(),</span><br><span class="line">                exc -&gt; searchTransportService.cancelSearchTask(task, &quot;failed to merge result [&quot; + exc.getMessage() + &quot;]&quot;));</span><br><span class="line">            AbstractSearchAsyncAction&lt;? extends SearchPhaseResult&gt; searchAsyncAction;</span><br><span class="line">            switch (searchRequest.searchType()) &#123;</span><br><span class="line">                // 与 “Query Then Fetch” 相同，除了初始分散阶段，该阶段计算分布式term频率以获得更准确的评分。</span><br><span class="line">                case DFS_QUERY_THEN_FETCH:</span><br><span class="line">                    searchAsyncAction = new SearchDfsQueryThenFetchAsyncAction(logger, searchTransportService, connectionLookup,</span><br><span class="line">                        aliasFilter, concreteIndexBoosts, searchPhaseController,</span><br><span class="line">                        executor, queryResultConsumer, searchRequest, listener, shardIterators, timeProvider, clusterState, task, clusters);</span><br><span class="line">                    break;</span><br><span class="line">                // 请求分两个阶段处理。 在第一阶段，查询被转发到所有涉及的分片。 每个分片执行搜索并生成对该分片本地的结果的排序列表。 </span><br><span class="line">                // 每个分片只向协调节点返回足够的信息，以允许其合并并将分片级结果重新排序为全局排序的最大长度大小的结果集。</span><br><span class="line">                // 在第二阶段期间，协调节点仅从相关分片请求文档内容（以及高亮显示的片段，如果有的话）。</span><br><span class="line">                // 如果您未在请求中指定 search_type，那么这是默认设置。</span><br><span class="line">                case QUERY_THEN_FETCH:</span><br><span class="line">                    searchAsyncAction = new SearchQueryThenFetchAsyncAction(logger, searchTransportService, connectionLookup,</span><br><span class="line">                        aliasFilter, concreteIndexBoosts, searchPhaseController, executor, queryResultConsumer,</span><br><span class="line">                        searchRequest, listener, shardIterators, timeProvider, clusterState, task, clusters);</span><br><span class="line">                    break;</span><br><span class="line">                default:</span><br><span class="line">                    throw new IllegalStateException(&quot;Unknown search type: [&quot; + searchRequest.searchType() + &quot;]&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return searchAsyncAction;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>获取到具体的SearchAsyncAction之后具体的执行是通过run()来调用各个实现类具体的执行了：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * This is the main entry point for a search. This method starts the search execution of the initial phase.</span><br><span class="line"> */</span><br><span class="line">public final void start() &#123;</span><br><span class="line">    if (getNumShards() == 0) &#123;</span><br><span class="line">        //no search shards to search on, bail with empty response</span><br><span class="line">        //(it happens with search across _all with no indices around and consistent with broadcast operations)</span><br><span class="line">        int trackTotalHitsUpTo = request.source() == null ? SearchContext.DEFAULT_TRACK_TOTAL_HITS_UP_TO :</span><br><span class="line">            request.source().trackTotalHitsUpTo() == null ? SearchContext.DEFAULT_TRACK_TOTAL_HITS_UP_TO :</span><br><span class="line">                request.source().trackTotalHitsUpTo();</span><br><span class="line">        // total hits is null in the response if the tracking of total hits is disabled</span><br><span class="line">        boolean withTotalHits = trackTotalHitsUpTo != SearchContext.TRACK_TOTAL_HITS_DISABLED;</span><br><span class="line">        listener.onResponse(new SearchResponse(InternalSearchResponse.empty(withTotalHits), null, 0, 0, 0, buildTookInMillis(),</span><br><span class="line">            ShardSearchFailure.EMPTY_ARRAY, clusters, null));</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    executePhase(this);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void executePhase(SearchPhase phase) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        phase.run();</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        if (logger.isDebugEnabled()) &#123;</span><br><span class="line">            logger.debug(new ParameterizedMessage(&quot;Failed to execute [&#123;&#125;] while moving to [&#123;&#125;] phase&quot;, request, phase.getName()), e);</span><br><span class="line">        &#125;</span><br><span class="line">        onPhaseFailure(phase, &quot;&quot;, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为默认的搜索类型是QUERY_THEN_FETCH，那么下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/SearchQueryThenFetchAsyncAction.java" target="_blank" rel="noopener">SearchQueryThenFetchAsyncAction</a>,在SearchQueryThenFetchAsyncAction中没有重写run()，所以真正执行的还是父类AbstractSearchAsyncAction中的run(),下面看下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public final void run() &#123;</span><br><span class="line">    for (final SearchShardIterator iterator : toSkipShardsIts) &#123;</span><br><span class="line">        assert iterator.skip();</span><br><span class="line">        skipShard(iterator);</span><br><span class="line">    &#125;</span><br><span class="line">    if (shardsIts.size() &gt; 0) &#123;</span><br><span class="line">        assert request.allowPartialSearchResults() != null : &quot;SearchRequest missing setting for allowPartialSearchResults&quot;;</span><br><span class="line">        if (request.allowPartialSearchResults() == false) &#123;</span><br><span class="line">            final StringBuilder missingShards = new StringBuilder();</span><br><span class="line">            // Fail-fast verification of all shards being available</span><br><span class="line">            for (int index = 0; index &lt; shardsIts.size(); index++) &#123;</span><br><span class="line">                final SearchShardIterator shardRoutings = shardsIts.get(index);</span><br><span class="line">                if (shardRoutings.size() == 0) &#123;</span><br><span class="line">                    if(missingShards.length() &gt; 0)&#123;</span><br><span class="line">                        missingShards.append(&quot;, &quot;);</span><br><span class="line">                    &#125;</span><br><span class="line">                    missingShards.append(shardRoutings.shardId());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (missingShards.length() &gt; 0) &#123;</span><br><span class="line">                //Status red - shard is missing all copies and would produce partial results for an index search</span><br><span class="line">                final String msg = &quot;Search rejected due to missing shards [&quot;+ missingShards +</span><br><span class="line">                    &quot;]. Consider using `allow_partial_search_results` setting to bypass this error.&quot;;</span><br><span class="line">                throw new SearchPhaseExecutionException(getName(), msg, null, ShardSearchFailure.EMPTY_ARRAY);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Version version = request.minCompatibleShardNode();</span><br><span class="line">        if (version != null &amp;&amp; Version.CURRENT.minimumCompatibilityVersion().equals(version) == false) &#123;</span><br><span class="line">            if (checkMinimumVersion(shardsIts) == false) &#123;</span><br><span class="line">                throw new VersionMismatchException(&quot;One of the shards is incompatible with the required minimum version [&#123;&#125;]&quot;,</span><br><span class="line">                    request.minCompatibleShardNode());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 遍历所有的分片，然后执行:</span><br><span class="line">        // 如果列表中有N个shard位于同一个节点，则向其发送N个请求，并不会把请求合并成一个。</span><br><span class="line">        for (int i = 0; i &lt; shardsIts.size(); i++) &#123;</span><br><span class="line">            final SearchShardIterator shardRoutings = shardsIts.get(i);</span><br><span class="line">            assert shardRoutings.skip() == false;</span><br><span class="line">            assert shardItIndexMap.containsKey(shardRoutings);</span><br><span class="line">            int shardIndex = shardItIndexMap.get(shardRoutings);</span><br><span class="line">            performPhaseOnShard(shardIndex, shardRoutings, shardRoutings.nextOrNull());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过performPhaseOnShard，来进行具体某个shard的搜索：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected void performPhaseOnShard(final int shardIndex, final SearchShardIterator shardIt, final SearchShardTarget shard) &#123;</span><br><span class="line">    /*</span><br><span class="line">     * We capture the thread that this phase is starting on. When we are called back after executing the phase, we are either on the</span><br><span class="line">     * same thread (because we never went async, or the same thread was selected from the thread pool) or a different thread. If we</span><br><span class="line">     * continue on the same thread in the case that we never went async and this happens repeatedly we will end up recursing deeply and</span><br><span class="line">     * could stack overflow. To prevent this, we fork if we are called back on the same thread that execution started on and otherwise</span><br><span class="line">     * we can continue (cf. InitialSearchPhase#maybeFork).</span><br><span class="line">     */</span><br><span class="line">    if (shard == null) &#123;</span><br><span class="line">        SearchShardTarget unassignedShard = new SearchShardTarget(null, shardIt.shardId(),</span><br><span class="line">            shardIt.getClusterAlias(), shardIt.getOriginalIndices());</span><br><span class="line">        fork(() -&gt; onShardFailure(shardIndex, unassignedShard, shardIt, new NoShardAvailableActionException(shardIt.shardId())));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final PendingExecutions pendingExecutions = throttleConcurrentRequests ?</span><br><span class="line">            pendingExecutionsPerNode.computeIfAbsent(shard.getNodeId(), n -&gt; new PendingExecutions(maxConcurrentRequestsPerNode))</span><br><span class="line">            : null;</span><br><span class="line">        Runnable r = () -&gt; &#123;</span><br><span class="line">            final Thread thread = Thread.currentThread();</span><br><span class="line">            try &#123;</span><br><span class="line">                // 定义Listener，用来处理搜索结果Response</span><br><span class="line">                executePhaseOnShard(shardIt, shard,</span><br><span class="line">                    new SearchActionListener&lt;Result&gt;(shard, shardIndex) &#123;</span><br><span class="line">                        @Override</span><br><span class="line">                        public void innerOnResponse(Result result) &#123;</span><br><span class="line">                            try &#123;</span><br><span class="line">                                onShardResult(result, shardIt);</span><br><span class="line">                            &#125; catch (Exception exc) &#123;</span><br><span class="line">                                onShardFailure(shardIndex, shard, shardIt, exc);</span><br><span class="line">                            &#125; finally &#123;</span><br><span class="line">                                executeNext(pendingExecutions, thread);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        @Override</span><br><span class="line">                        public void onFailure(Exception t) &#123;</span><br><span class="line">                            try &#123;</span><br><span class="line">                                onShardFailure(shardIndex, shard, shardIt, t);</span><br><span class="line">                            &#125; finally &#123;</span><br><span class="line">                                executeNext(pendingExecutions, thread);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line">            &#125; catch (final Exception e) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    /*</span><br><span class="line">                     * It is possible to run into connection exceptions here because we are getting the connection early and might</span><br><span class="line">                     * run into nodes that are not connected. In this case, on shard failure will move us to the next shard copy.</span><br><span class="line">                     */</span><br><span class="line">                    fork(() -&gt; onShardFailure(shardIndex, shard, shardIt, e));</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    executeNext(pendingExecutions, thread);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        if (throttleConcurrentRequests) &#123;</span><br><span class="line">            pendingExecutions.tryRun(r);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            r.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Sends the request to the actual shard.</span><br><span class="line"> * 摘自父类 AbstractSearchAsyncAction</span><br><span class="line"> * @param shardIt the shards iterator</span><br><span class="line"> * @param shard the shard routing to send the request for</span><br><span class="line"> * @param listener the listener to notify on response</span><br><span class="line"> */</span><br><span class="line">protected void executePhaseOnShard(final SearchShardIterator shardIt,</span><br><span class="line">                                   final SearchShardTarget shard,</span><br><span class="line">                                   final SearchActionListener&lt;SearchPhaseResult&gt; listener) &#123;</span><br><span class="line">    ShardSearchRequest request = rewriteShardSearchRequest(super.buildShardSearchRequest(shardIt, listener.requestIndex));</span><br><span class="line">    //通过SearchTransportService的sendChildRequest方法向具体的分片发送Query阶段的子任务进行异步处理。</span><br><span class="line">    getSearchTransport().sendExecuteQuery(getConnection(shard.getClusterAlias(), shard.getNodeId()), request, getTask(), listener);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个分片在执行完毕Query子任务后，通过节点间通信，回调AbstractSearchAsyncAction类中的onShardResult方法，把查询结果记录在协调节点保存的数组结构results中，并增加计数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  /**</span><br><span class="line"> * Executed once for every successful shard level request.</span><br><span class="line"> * @param result the result returned form the shard</span><br><span class="line"> * @param shardIt the shard iterator</span><br><span class="line"> */</span><br><span class="line">protected void onShardResult(Result result, SearchShardIterator shardIt) &#123;</span><br><span class="line">    assert result.getShardIndex() != -1 : &quot;shard index is not set&quot;;</span><br><span class="line">    assert result.getSearchShardTarget() != null : &quot;search shard target must not be null&quot;;</span><br><span class="line">    hasShardResponse.set(true);</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;got first-phase result from &#123;&#125;&quot;, result != null ? result.getSearchShardTarget() : null);</span><br><span class="line">    &#125;</span><br><span class="line">    results.consumeResult(result, () -&gt; onShardResultConsumed(result, shardIt));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void onShardResultConsumed(Result result, SearchShardIterator shardIt) &#123;</span><br><span class="line">    successfulOps.incrementAndGet();</span><br><span class="line">    // clean a previous error on this shard group (note, this code will be serialized on the same shardIndex value level</span><br><span class="line">    // so its ok concurrency wise to miss potentially the shard failures being created because of another failure</span><br><span class="line">    // in the #addShardFailure, because by definition, it will happen on *another* shardIndex</span><br><span class="line">    AtomicArray&lt;ShardSearchFailure&gt; shardFailures = this.shardFailures.get();</span><br><span class="line">    if (shardFailures != null) &#123;</span><br><span class="line">        shardFailures.set(result.getShardIndex(), null);</span><br><span class="line">    &#125;</span><br><span class="line">    // we need to increment successful ops first before we compare the exit condition otherwise if we</span><br><span class="line">    // are fast we could concurrently update totalOps but then preempt one of the threads which can</span><br><span class="line">    // cause the successor to read a wrong value from successfulOps if second phase is very fast ie. count etc.</span><br><span class="line">    // increment all the &quot;future&quot; shards to update the total ops since we some may work and some may not...</span><br><span class="line">    // and when that happens, we break on total ops, so we must maintain them</span><br><span class="line">    successfulShardExecution(shardIt);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void successfulShardExecution(SearchShardIterator shardsIt) &#123;</span><br><span class="line">    final int remainingOpsOnIterator;</span><br><span class="line">    if (shardsIt.skip()) &#123;</span><br><span class="line">        // It&apos;s possible that we&apos;re skipping a shard that&apos;s unavailable</span><br><span class="line">        // but its range was available in the IndexMetadata, in that</span><br><span class="line">        // case the shardsIt.remaining() would be 0, expectedTotalOps</span><br><span class="line">        // accounts for unavailable shards too.</span><br><span class="line">        remainingOpsOnIterator = Math.max(shardsIt.remaining(), 1);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        remainingOpsOnIterator = shardsIt.remaining() + 1;</span><br><span class="line">    &#125;</span><br><span class="line">    final int xTotalOps = totalOps.addAndGet(remainingOpsOnIterator);</span><br><span class="line">    // 检查是否收到全部回复</span><br><span class="line">    if (xTotalOps == expectedTotalOps) &#123;</span><br><span class="line">        onPhaseDone();</span><br><span class="line">    &#125; else if (xTotalOps &gt; expectedTotalOps) &#123;</span><br><span class="line">        throw new AssertionError(&quot;unexpected higher total ops [&quot; + xTotalOps + &quot;] compared to expected [&quot; + expectedTotalOps + &quot;]&quot;,</span><br><span class="line">            new SearchPhaseExecutionException(getName(), &quot;Shard failures&quot;, null, buildShardFailures()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当返回结果的分片数等于预期的总分片数时，协调节点会进入当前Phase的结束处理，启动下一个阶段Fetch Phase的执行。注意，ES中只需要一个分片执行成功，就会进行后续Phase处理得到部分结果，当然它会在结果中提示用户实际有多少分片执行成功。</p><p>onPhaseDone会调用executeNextPhase方法进入下一个阶段，从而开始进入Fetch 阶段。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Executed once all shard results have been received and processed</span><br><span class="line"> * @see #onShardFailure(int, SearchShardTarget, Exception)</span><br><span class="line"> * @see #onShardResult(SearchPhaseResult, SearchShardIterator)</span><br><span class="line"> */</span><br><span class="line">final void onPhaseDone() &#123;  // as a tribute to @kimchy aka. finishHim()</span><br><span class="line">    // SearchQueryThenFetchAsyncAction中getNextPhase会返回：FetchSearchPhase</span><br><span class="line">    executeNextPhase(this, getNextPhase(results, this));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public final void executeNextPhase(SearchPhase currentPhase, SearchPhase nextPhase) &#123;</span><br><span class="line">    /* This is the main search phase transition where we move to the next phase. If all shards</span><br><span class="line">     * failed or if there was a failure and partial results are not allowed, then we immediately</span><br><span class="line">     * fail. Otherwise we continue to the next phase.</span><br><span class="line">     */</span><br><span class="line">    ShardOperationFailedException[] shardSearchFailures = buildShardFailures();</span><br><span class="line">    if (shardSearchFailures.length == getNumShards()) &#123;</span><br><span class="line">        shardSearchFailures = ExceptionsHelper.groupBy(shardSearchFailures);</span><br><span class="line">        Throwable cause = shardSearchFailures.length == 0 ? null :</span><br><span class="line">            ElasticsearchException.guessRootCauses(shardSearchFailures[0].getCause())[0];</span><br><span class="line">        logger.debug(() -&gt; new ParameterizedMessage(&quot;All shards failed for phase: [&#123;&#125;]&quot;, getName()), cause);</span><br><span class="line">        onPhaseFailure(currentPhase, &quot;all shards failed&quot;, cause);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        Boolean allowPartialResults = request.allowPartialSearchResults();</span><br><span class="line">        assert allowPartialResults != null : &quot;SearchRequest missing setting for allowPartialSearchResults&quot;;</span><br><span class="line">        if (allowPartialResults == false &amp;&amp; successfulOps.get() != getNumShards()) &#123;</span><br><span class="line">            // check if there are actual failures in the atomic array since</span><br><span class="line">            // successful retries can reset the failures to null</span><br><span class="line">            if (shardSearchFailures.length &gt; 0) &#123;</span><br><span class="line">                if (logger.isDebugEnabled()) &#123;</span><br><span class="line">                    int numShardFailures = shardSearchFailures.length;</span><br><span class="line">                    shardSearchFailures = ExceptionsHelper.groupBy(shardSearchFailures);</span><br><span class="line">                    Throwable cause = ElasticsearchException.guessRootCauses(shardSearchFailures[0].getCause())[0];</span><br><span class="line">                    logger.debug(() -&gt; new ParameterizedMessage(&quot;&#123;&#125; shards failed for phase: [&#123;&#125;]&quot;,</span><br><span class="line">                        numShardFailures, getName()), cause);</span><br><span class="line">                &#125;</span><br><span class="line">                onPhaseFailure(currentPhase, &quot;Partial shards failure&quot;, null);</span><br><span class="line">                return;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                int discrepancy = getNumShards() - successfulOps.get();</span><br><span class="line">                assert discrepancy &gt; 0 : &quot;discrepancy: &quot; + discrepancy;</span><br><span class="line">                if (logger.isDebugEnabled()) &#123;</span><br><span class="line">                    logger.debug(&quot;Partial shards failure (unavailable: &#123;&#125;, successful: &#123;&#125;, skipped: &#123;&#125;, num-shards: &#123;&#125;, phase: &#123;&#125;)&quot;,</span><br><span class="line">                        discrepancy, successfulOps.get(), skippedOps.get(), getNumShards(), currentPhase.getName());</span><br><span class="line">                &#125;</span><br><span class="line">                onPhaseFailure(currentPhase, &quot;Partial shards failure (&quot; + discrepancy + &quot; shards unavailable)&quot;, null);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if (logger.isTraceEnabled()) &#123;</span><br><span class="line">            final String resultsFrom = results.getSuccessfulResults()</span><br><span class="line">                .map(r -&gt; r.getSearchShardTarget().toString()).collect(Collectors.joining(&quot;,&quot;));</span><br><span class="line">            logger.trace(&quot;[&#123;&#125;] Moving to next phase: [&#123;&#125;], based on results from: &#123;&#125; (cluster state version: &#123;&#125;)&quot;,</span><br><span class="line">                currentPhase.getName(), nextPhase.getName(), resultsFrom, clusterState.version());</span><br><span class="line">        &#125;</span><br><span class="line">        executePhase(nextPhase);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void executePhase(SearchPhase phase) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        phase.run();</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        if (logger.isDebugEnabled()) &#123;</span><br><span class="line">            logger.debug(new ParameterizedMessage(&quot;Failed to execute [&#123;&#125;] while moving to [&#123;&#125;] phase&quot;, request, phase.getName()), e);</span><br><span class="line">        &#125;</span><br><span class="line">        onPhaseFailure(phase, &quot;&quot;, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/FetchSearchPhase.java" target="_blank" rel="noopener">FetchSearchPhase</a>中的run()：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">       context.execute(new AbstractRunnable() &#123;</span><br><span class="line">           @Override</span><br><span class="line">           protected void doRun() throws Exception &#123;</span><br><span class="line">               // we do the heavy lifting in this inner run method where we reduce aggs etc. that&apos;s why we fork this phase</span><br><span class="line">               // off immediately instead of forking when we send back the response to the user since there we only need</span><br><span class="line">               // to merge together the fetched results which is a linear operation.</span><br><span class="line">               innerRun();</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           @Override</span><br><span class="line">           public void onFailure(Exception e) &#123;</span><br><span class="line">               context.onPhaseFailure(FetchSearchPhase.this, &quot;&quot;, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   private void innerRun() throws Exception &#123;</span><br><span class="line">       final int numShards = context.getNumShards();</span><br><span class="line">       final boolean isScrollSearch = context.getRequest().scroll() != null;</span><br><span class="line">       final List&lt;SearchPhaseResult&gt; phaseResults = queryResults.asList();</span><br><span class="line">       final SearchPhaseController.ReducedQueryPhase reducedQueryPhase = resultConsumer.reduce();</span><br><span class="line">       final boolean queryAndFetchOptimization = queryResults.length() == 1;</span><br><span class="line">       final Runnable finishPhase = ()</span><br><span class="line">           -&gt; moveToNextPhase(searchPhaseController, queryResults, reducedQueryPhase, queryAndFetchOptimization ?</span><br><span class="line">           queryResults : fetchResults.getAtomicArray());</span><br><span class="line">       if (queryAndFetchOptimization) &#123;</span><br><span class="line">           assert phaseResults.isEmpty() || phaseResults.get(0).fetchResult() != null : &quot;phaseResults empty [&quot; + phaseResults.isEmpty()</span><br><span class="line">               + &quot;], single result: &quot; +  phaseResults.get(0).fetchResult();</span><br><span class="line">           // query AND fetch optimization</span><br><span class="line">           finishPhase.run();</span><br><span class="line">       &#125; else &#123;</span><br><span class="line">           ScoreDoc[] scoreDocs = reducedQueryPhase.sortedTopDocs.scoreDocs;</span><br><span class="line">           final IntArrayList[] docIdsToLoad = searchPhaseController.fillDocIdsToLoad(numShards, scoreDocs);</span><br><span class="line">           // no docs to fetch -- sidestep everything and return</span><br><span class="line">           if (scoreDocs.length == 0) &#123;</span><br><span class="line">               // we have to release contexts here to free up resources</span><br><span class="line">               phaseResults.stream()</span><br><span class="line">                   .map(SearchPhaseResult::queryResult)</span><br><span class="line">                   .forEach(this::releaseIrrelevantSearchContext);</span><br><span class="line">               finishPhase.run();</span><br><span class="line">           &#125; else &#123;</span><br><span class="line">               final ScoreDoc[] lastEmittedDocPerShard = isScrollSearch ?</span><br><span class="line">                   searchPhaseController.getLastEmittedDocPerShard(reducedQueryPhase, numShards)</span><br><span class="line">                   : null;</span><br><span class="line">               final CountedCollector&lt;FetchSearchResult&gt; counter = new CountedCollector&lt;&gt;(fetchResults,</span><br><span class="line">                   docIdsToLoad.length, // we count down every shard in the result no matter if we got any results or not</span><br><span class="line">                   finishPhase, context);</span><br><span class="line">               // 从查询阶段的shard列表中遍历，跳过查询结果为空的shard，</span><br><span class="line">               // 对特定目标shard执行executeFetch方法来获取数据，其中包括分页信息。</span><br><span class="line">               for (int i = 0; i &lt; docIdsToLoad.length; i++) &#123;</span><br><span class="line">                   IntArrayList entry = docIdsToLoad[i];</span><br><span class="line">                   SearchPhaseResult queryResult = queryResults.get(i);</span><br><span class="line">                   if (entry == null) &#123; // no results for this shard ID</span><br><span class="line">                       if (queryResult != null) &#123;</span><br><span class="line">                           // if we got some hits from this shard we have to release the context there</span><br><span class="line">                           // we do this as we go since it will free up resources and passing on the request on the</span><br><span class="line">                           // transport layer is cheap.</span><br><span class="line">                           releaseIrrelevantSearchContext(queryResult.queryResult());</span><br><span class="line">                           progressListener.notifyFetchResult(i);</span><br><span class="line">                       &#125;</span><br><span class="line">                       // in any case we count down this result since we don&apos;t talk to this shard anymore</span><br><span class="line">                       counter.countDown();</span><br><span class="line">                   &#125; else &#123;</span><br><span class="line">                       SearchShardTarget searchShardTarget = queryResult.getSearchShardTarget();</span><br><span class="line">                       Transport.Connection connection = context.getConnection(searchShardTarget.getClusterAlias(),</span><br><span class="line">                           searchShardTarget.getNodeId());</span><br><span class="line">                       ShardFetchSearchRequest fetchSearchRequest = createFetchRequest(queryResult.queryResult().getContextId(), i, entry,</span><br><span class="line">                           lastEmittedDocPerShard, searchShardTarget.getOriginalIndices(), queryResult.getShardSearchRequest(),</span><br><span class="line">                           queryResult.getRescoreDocIds());</span><br><span class="line">                       executeFetch(queryResult.getShardIndex(), searchShardTarget, counter, fetchSearchRequest, queryResult.queryResult(),</span><br><span class="line">                           connection);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // executeFetch的参数querySearchResult包含分页信息，</span><br><span class="line">   // 同时定义了Listener，每成功获取一个shard数据之后就执行counter.onResult，</span><br><span class="line">   // 其中调用对结果的处理回调(final CountedCollector&lt;FetchSearchResult&gt; counter)，把结果保存到数组中，然后执行countDown。</span><br><span class="line">   private void executeFetch(final int shardIndex, final SearchShardTarget shardTarget,</span><br><span class="line">                             final CountedCollector&lt;FetchSearchResult&gt; counter,</span><br><span class="line">                             final ShardFetchSearchRequest fetchSearchRequest, final QuerySearchResult querySearchResult,</span><br><span class="line">                             final Transport.Connection connection) &#123;</span><br><span class="line">       context.getSearchTransport().sendExecuteFetch(connection, fetchSearchRequest, context.getTask(),</span><br><span class="line">           new SearchActionListener&lt;FetchSearchResult&gt;(shardTarget, shardIndex) &#123;</span><br><span class="line">               @Override</span><br><span class="line">               public void innerOnResponse(FetchSearchResult result) &#123;</span><br><span class="line">                   try &#123;</span><br><span class="line">                       progressListener.notifyFetchResult(shardIndex);</span><br><span class="line">                       counter.onResult(result);</span><br><span class="line">                   &#125; catch (Exception e) &#123;</span><br><span class="line">                       context.onPhaseFailure(FetchSearchPhase.this, &quot;&quot;, e);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">               @Override</span><br><span class="line">               public void onFailure(Exception e) &#123;</span><br><span class="line">                   try &#123;</span><br><span class="line">                       logger.debug(</span><br><span class="line">                           () -&gt; new ParameterizedMessage(&quot;[&#123;&#125;] Failed to execute fetch phase&quot;, fetchSearchRequest.contextId()), e);</span><br><span class="line">                       progressListener.notifyFetchFailure(shardIndex, shardTarget, e);</span><br><span class="line">                       counter.onFailure(shardIndex, shardTarget, e);</span><br><span class="line">                   &#125; finally &#123;</span><br><span class="line">                       // the search context might not be cleared on the node where the fetch was executed for example</span><br><span class="line">                       // because the action was rejected by the thread pool. in this case we need to send a dedicated</span><br><span class="line">                       // request to clear the search context.</span><br><span class="line">                       releaseIrrelevantSearchContext(querySearchResult);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Sets the result to the given array index and then runs &#123;@link #countDown()&#125;</span><br><span class="line">    */</span><br><span class="line">   void onResult(R result) &#123;</span><br><span class="line">       resultConsumer.consumeResult(result,  this::countDown);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Forcefully counts down an operation and executes the provided runnable</span><br><span class="line">    * if all expected operations where executed</span><br><span class="line">    */</span><br><span class="line">   void countDown() &#123;</span><br><span class="line">       assert counter.isCountedDown() == false : &quot;more operations executed than specified&quot;;</span><br><span class="line">       if (counter.countDown()) &#123;</span><br><span class="line">           onFinish.run();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   @Override</span><br><span class="line">   void consumeResult(Result result, Runnable next) &#123;</span><br><span class="line">       assert results.get(result.getShardIndex()) == null : &quot;shardIndex: &quot; + result.getShardIndex() + &quot; is already set&quot;;</span><br><span class="line">       results.set(result.getShardIndex(), result);</span><br><span class="line">       next.run();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>从代码在哪个可以看到Fetch后的结果保存到了counter中，而counter是定义在innerRun内：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final CountedCollector&lt;FetchSearchResult&gt; counter = new CountedCollector&lt;&gt;(fetchResults,</span><br><span class="line">                    docIdsToLoad.length, // we count down every shard in the result no matter if we got any results or not</span><br><span class="line">                    finishPhase, context);</span><br></pre></td></tr></table></figure><p>fetchResults用于存储从某个shard收集的结果，每收到一个shard数据就执行一次counter.countDown()。当所有shard收集完成之后，countDown会触发执行finishPhase：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// FetchSearchPhase类中</span><br><span class="line">final Runnable finishPhase = ()</span><br><span class="line">            -&gt; moveToNextPhase(searchPhaseController, queryResults, reducedQueryPhase, queryAndFetchOptimization ?</span><br><span class="line">            queryResults : fetchResults.getAtomicArray());</span><br><span class="line"></span><br><span class="line">// FetchSearchPhase类中</span><br><span class="line">private final SearchPhaseContext context;</span><br><span class="line">private void moveToNextPhase(SearchPhaseController searchPhaseController,</span><br><span class="line">                                 AtomicArray&lt;SearchPhaseResult&gt; queryPhaseResults,</span><br><span class="line">                                 SearchPhaseController.ReducedQueryPhase reducedQueryPhase,</span><br><span class="line">                                 AtomicArray&lt;? extends SearchPhaseResult&gt; fetchResultsArr) &#123;</span><br><span class="line">        final InternalSearchResponse internalResponse = searchPhaseController.merge(context.getRequest().scroll() != null,</span><br><span class="line">            reducedQueryPhase, fetchResultsArr.asList(), fetchResultsArr::get);</span><br><span class="line">        context.executeNextPhase(this, nextPhaseFactory.apply(internalResponse, queryPhaseResults));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">// FetchSearchPhase 构造函数</span><br><span class="line">FetchSearchPhase(SearchPhaseResults&lt;SearchPhaseResult&gt; resultConsumer,</span><br><span class="line">                     SearchPhaseController searchPhaseController,</span><br><span class="line">                     AggregatedDfs aggregatedDfs,</span><br><span class="line">                     SearchPhaseContext context) &#123;</span><br><span class="line">        this(resultConsumer, searchPhaseController, aggregatedDfs, context,</span><br><span class="line">            (response, queryPhaseResults) -&gt; new ExpandSearchPhase(context, response, queryPhaseResults));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>获取查询结果之后，进入<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/ExpandSearchPhase.java" target="_blank" rel="noopener">ExpandSearchPhase</a>类中的run():</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 主要判断是否启用字段折叠（field collapsing），根据需要实现字段折叠，</span><br><span class="line">// 如果没有实现，直接返回给客户端。</span><br><span class="line">   @Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">       if (isCollapseRequest() &amp;&amp; searchResponse.hits().getHits().length &gt; 0) &#123;</span><br><span class="line">           SearchRequest searchRequest = context.getRequest();</span><br><span class="line">           CollapseBuilder collapseBuilder = searchRequest.source().collapse();</span><br><span class="line">           final List&lt;InnerHitBuilder&gt; innerHitBuilders = collapseBuilder.getInnerHits();</span><br><span class="line">           MultiSearchRequest multiRequest = new MultiSearchRequest();</span><br><span class="line">           if (collapseBuilder.getMaxConcurrentGroupRequests() &gt; 0) &#123;</span><br><span class="line">               multiRequest.maxConcurrentSearchRequests(collapseBuilder.getMaxConcurrentGroupRequests());</span><br><span class="line">           &#125;</span><br><span class="line">           for (SearchHit hit : searchResponse.hits().getHits()) &#123;</span><br><span class="line">               BoolQueryBuilder groupQuery = new BoolQueryBuilder();</span><br><span class="line">               Object collapseValue = hit.field(collapseBuilder.getField()).getValue();</span><br><span class="line">               if (collapseValue != null) &#123;</span><br><span class="line">                   groupQuery.filter(QueryBuilders.matchQuery(collapseBuilder.getField(), collapseValue));</span><br><span class="line">               &#125; else &#123;</span><br><span class="line">                   groupQuery.mustNot(QueryBuilders.existsQuery(collapseBuilder.getField()));</span><br><span class="line">               &#125;</span><br><span class="line">               QueryBuilder origQuery = searchRequest.source().query();</span><br><span class="line">               if (origQuery != null) &#123;</span><br><span class="line">                   groupQuery.must(origQuery);</span><br><span class="line">               &#125;</span><br><span class="line">               for (InnerHitBuilder innerHitBuilder : innerHitBuilders) &#123;</span><br><span class="line">                   CollapseBuilder innerCollapseBuilder = innerHitBuilder.getInnerCollapseBuilder();</span><br><span class="line">                   SearchSourceBuilder sourceBuilder = buildExpandSearchSourceBuilder(innerHitBuilder, innerCollapseBuilder)</span><br><span class="line">                       .query(groupQuery)</span><br><span class="line">                       .postFilter(searchRequest.source().postFilter())</span><br><span class="line">                       .runtimeMappings(searchRequest.source().runtimeMappings());</span><br><span class="line">                   SearchRequest groupRequest = new SearchRequest(searchRequest);</span><br><span class="line">                   groupRequest.source(sourceBuilder);</span><br><span class="line">                   multiRequest.add(groupRequest);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           context.getSearchTransport().sendExecuteMultiSearch(multiRequest, context.getTask(),</span><br><span class="line">               ActionListener.wrap(response -&gt; &#123;</span><br><span class="line">                   Iterator&lt;MultiSearchResponse.Item&gt; it = response.iterator();</span><br><span class="line">                   for (SearchHit hit : searchResponse.hits.getHits()) &#123;</span><br><span class="line">                       for (InnerHitBuilder innerHitBuilder : innerHitBuilders) &#123;</span><br><span class="line">                           MultiSearchResponse.Item item = it.next();</span><br><span class="line">                           if (item.isFailure()) &#123;</span><br><span class="line">                               context.onPhaseFailure(this, &quot;failed to expand hits&quot;, item.getFailure());</span><br><span class="line">                               return;</span><br><span class="line">                           &#125;</span><br><span class="line">                           SearchHits innerHits = item.getResponse().getHits();</span><br><span class="line">                           if (hit.getInnerHits() == null) &#123;</span><br><span class="line">                               hit.setInnerHits(new HashMap&lt;&gt;(innerHitBuilders.size()));</span><br><span class="line">                           &#125;</span><br><span class="line">                           hit.getInnerHits().put(innerHitBuilder.getName(), innerHits);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">                   context.sendSearchResponse(searchResponse, queryResults);</span><br><span class="line">               &#125;, context::onFailure)</span><br><span class="line">           );</span><br><span class="line">       &#125; else &#123;</span><br><span class="line">           context.sendSearchResponse(searchResponse, queryResults);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>看到这里还是没有发现针对-*有什么特殊的优化，还是会根据检索条件遍历符合条件的所有索引及其shard。那下面看那一下具体获取数据的时候有没有什么特殊处理，也就是data node 在Query、Fetch阶段有没有什么特殊的优化？</p><p>下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/SearchTransportService.java" target="_blank" rel="noopener">SearchTransportService</a>下的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/search/SearchTransportService.java#L139" target="_blank" rel="noopener">sendExecuteQuery</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void sendExecuteQuery(Transport.Connection connection, final ShardSearchRequest request, SearchTask task,</span><br><span class="line">                                 final SearchActionListener&lt;SearchPhaseResult&gt; listener) &#123;</span><br><span class="line">        // we optimize this and expect a QueryFetchSearchResult if we only have a single shard in the search request</span><br><span class="line">        // this used to be the QUERY_AND_FETCH which doesn&apos;t exist anymore.</span><br><span class="line">        final boolean fetchDocuments = request.numberOfShards() == 1;</span><br><span class="line">        Writeable.Reader&lt;SearchPhaseResult&gt; reader = fetchDocuments ? QueryFetchSearchResult::new : QuerySearchResult::new;</span><br><span class="line"></span><br><span class="line">        final ActionListener handler = responseWrapper.apply(connection, listener);</span><br><span class="line">        transportService.sendChildRequest(connection, QUERY_ACTION_NAME, request, task,</span><br><span class="line">                new ConnectionCountingHandler&lt;&gt;(handler, reader, clientConnections, connection.getNode().getId()));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>通过请求路径QUERY_ACTION_NAME可以在SearchTransportService中找到对应的处理函数searchService.executeQueryPhase：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transportService.registerRequestHandler(QUERY_ACTION_NAME, ThreadPool.Names.SAME, ShardSearchRequest::new,</span><br><span class="line">           (request, channel, task) -&gt; &#123;</span><br><span class="line">               searchService.executeQueryPhase(request, keepStatesInContext(channel.getVersion()), (SearchShardTask) task,</span><br><span class="line">                   new ChannelActionListener&lt;&gt;(channel, QUERY_ACTION_NAME, request));</span><br><span class="line">           &#125;);</span><br></pre></td></tr></table></figure><p>下面具体看一下执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void executeQueryPhase(ShardSearchRequest request, boolean keepStatesInContext,</span><br><span class="line">                                  SearchShardTask task, ActionListener&lt;SearchPhaseResult&gt; listener) &#123;</span><br><span class="line">        assert request.canReturnNullResponseIfMatchNoDocs() == false || request.numberOfShards() &gt; 1</span><br><span class="line">            : &quot;empty responses require more than one shard&quot;;</span><br><span class="line">        final IndexShard shard = getShard(request);</span><br><span class="line">        rewriteAndFetchShardRequest(shard, request, new ActionListener&lt;ShardSearchRequest&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void onResponse(ShardSearchRequest orig) &#123;</span><br><span class="line">                // check if we can shortcut the query phase entirely.</span><br><span class="line">                if (orig.canReturnNullResponseIfMatchNoDocs()) &#123;</span><br><span class="line">                    assert orig.scroll() == null;</span><br><span class="line">                    final CanMatchResponse canMatchResp;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        ShardSearchRequest clone = new ShardSearchRequest(orig);</span><br><span class="line">                        canMatchResp = canMatch(clone, false);</span><br><span class="line">                    &#125; catch (Exception exc) &#123;</span><br><span class="line">                        listener.onFailure(exc);</span><br><span class="line">                        return;</span><br><span class="line">                    &#125;</span><br><span class="line">                    if (canMatchResp.canMatch == false) &#123;</span><br><span class="line">                        listener.onResponse(QuerySearchResult.nullInstance());</span><br><span class="line">                        return;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                // fork the execution in the search thread pool</span><br><span class="line">                runAsync(getExecutor(shard), () -&gt; executeQueryPhase(orig, task, keepStatesInContext), listener);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onFailure(Exception exc) &#123;</span><br><span class="line">                listener.onFailure(exc);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private SearchPhaseResult executeQueryPhase(ShardSearchRequest request,</span><br><span class="line">                                                SearchShardTask task,</span><br><span class="line">                                                boolean keepStatesInContext) throws Exception &#123;</span><br><span class="line">        final ReaderContext readerContext = createOrGetReaderContext(request, keepStatesInContext);</span><br><span class="line">        try (Releasable ignored = readerContext.markAsUsed(getKeepAlive(request));</span><br><span class="line">                SearchContext context = createContext(readerContext, request, task, true)) &#123;</span><br><span class="line">            final long afterQueryTime;</span><br><span class="line">            try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context)) &#123;</span><br><span class="line">                loadOrExecuteQueryPhase(request, context);</span><br><span class="line">                if (context.queryResult().hasSearchContext() == false &amp;&amp; readerContext.singleSession()) &#123;</span><br><span class="line">                    freeReaderContext(readerContext.id());</span><br><span class="line">                &#125;</span><br><span class="line">                afterQueryTime = executor.success();</span><br><span class="line">            &#125;</span><br><span class="line">            if (request.numberOfShards() == 1) &#123;</span><br><span class="line">                return executeFetchPhase(readerContext, context, afterQueryTime);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // Pass the rescoreDocIds to the queryResult to send them the coordinating node and receive them back in the fetch phase.</span><br><span class="line">                // We also pass the rescoreDocIds to the LegacyReaderContext in case the search state needs to stay in the data node.</span><br><span class="line">                final RescoreDocIds rescoreDocIds = context.rescoreDocIds();</span><br><span class="line">                context.queryResult().setRescoreDocIds(rescoreDocIds);</span><br><span class="line">                readerContext.setRescoreDocIds(rescoreDocIds);</span><br><span class="line">                return context.queryResult();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            // execution exception can happen while loading the cache, strip it</span><br><span class="line">            if (e instanceof ExecutionException) &#123;</span><br><span class="line">                e = (e.getCause() == null || e.getCause() instanceof Exception) ?</span><br><span class="line">                    (Exception) e.getCause() : new ElasticsearchException(e.getCause());</span><br><span class="line">            &#125;</span><br><span class="line">            logger.trace(&quot;Query phase failed&quot;, e);</span><br><span class="line">            processFailure(readerContext, e);</span><br><span class="line">            throw e;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Try to load the query results from the cache or execute the query phase directly if the cache cannot be used.</span><br><span class="line">     */</span><br><span class="line">    private void loadOrExecuteQueryPhase(final ShardSearchRequest request, final SearchContext context) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">        // 关于cache更多的介绍参见：</span><br><span class="line">        // https://www.elastic.co/guide/en/elasticsearch/reference/current/shard-request-cache.html</span><br><span class="line">        final boolean canCache = indicesService.canCache(request, context);</span><br><span class="line">        context.getSearchExecutionContext().freezeContext();</span><br><span class="line">        if (canCache) &#123;</span><br><span class="line">            indicesService.loadIntoContext(request, context, queryPhase);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            queryPhase.execute(context);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Can the shard request be cached at all?</span><br><span class="line">     */</span><br><span class="line">    public boolean canCache(ShardSearchRequest request, SearchContext context) &#123;</span><br><span class="line">        // Queries that create a scroll context cannot use the cache.</span><br><span class="line">        // They modify the search context during their execution so using the cache</span><br><span class="line">        // may invalidate the scroll for the next query.</span><br><span class="line">        if (request.scroll() != null) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // We cannot cache with DFS because results depend not only on the content of the index but also</span><br><span class="line">        // on the overridden statistics. So if you ran two queries on the same index with different stats</span><br><span class="line">        // (because an other shard was updated) you would get wrong results because of the scores</span><br><span class="line">        // (think about top_hits aggs or scripts using the score)</span><br><span class="line">        if (SearchType.QUERY_THEN_FETCH != context.searchType()) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // Profiled queries should not use the cache</span><br><span class="line">        if (request.source() != null &amp;&amp; request.source().profile()) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        IndexSettings settings = context.indexShard().indexSettings();</span><br><span class="line">        // if not explicitly set in the request, use the index setting, if not, use the request</span><br><span class="line">        if (request.requestCache() == null) &#123;</span><br><span class="line">            if (settings.getValue(IndicesRequestCache.INDEX_CACHE_REQUEST_ENABLED_SETTING) == false) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125; else if (context.size() != 0) &#123;</span><br><span class="line">                // If no request cache query parameter and shard request cache</span><br><span class="line">                // is enabled in settings don&apos;t cache for requests with size &gt; 0</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else if (request.requestCache() == false) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        // We use the cacheKey of the index reader as a part of a key of the IndicesRequestCache.</span><br><span class="line">        assert context.searcher().getIndexReader().getReaderCacheHelper() != null;</span><br><span class="line"></span><br><span class="line">        // if now in millis is used (or in the future, a more generic &quot;isDeterministic&quot; flag</span><br><span class="line">        // then we can&apos;t cache based on &quot;now&quot; key within the search request, as it is not deterministic</span><br><span class="line">        if (context.getSearchExecutionContext().isCacheable() == false) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>先略过cache部分，重点看一下QueryPhase类中的execute：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void execute(SearchContext searchContext) throws QueryPhaseExecutionException &#123;</span><br><span class="line">        if (searchContext.hasOnlySuggest()) &#123;</span><br><span class="line">            suggestPhase.execute(searchContext);</span><br><span class="line">            searchContext.queryResult().topDocs(new TopDocsAndMaxScore(</span><br><span class="line">                    new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), Lucene.EMPTY_SCORE_DOCS), Float.NaN),</span><br><span class="line">                new DocValueFormat[0]);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (LOGGER.isTraceEnabled()) &#123;</span><br><span class="line">            LOGGER.trace(&quot;&#123;&#125;&quot;, new SearchContextSourcePrinter(searchContext));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // Pre-process aggregations as late as possible. In the case of a DFS_Q_T_F</span><br><span class="line">        // request, preProcess is called on the DFS phase phase, this is why we pre-process them</span><br><span class="line">        // here to make sure it happens during the QUERY phase</span><br><span class="line">        aggregationPhase.preProcess(searchContext);</span><br><span class="line">        boolean rescore = executeInternal(searchContext);</span><br><span class="line"></span><br><span class="line">        if (rescore) &#123; // only if we do a regular search</span><br><span class="line">            rescorePhase.execute(searchContext);</span><br><span class="line">        &#125;</span><br><span class="line">        suggestPhase.execute(searchContext);</span><br><span class="line">        aggregationPhase.execute(searchContext);</span><br><span class="line"></span><br><span class="line">        if (searchContext.getProfilers() != null) &#123;</span><br><span class="line">            ProfileShardResult shardResults = SearchProfileShardResults</span><br><span class="line">                .buildShardResults(searchContext.getProfilers());</span><br><span class="line">            searchContext.queryResult().profileResults(shardResults);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">     /**</span><br><span class="line">     * In a package-private method so that it can be tested without having to</span><br><span class="line">     * wire everything (mapperService, etc.)</span><br><span class="line">     * @return whether the rescoring phase should be executed</span><br><span class="line">     */</span><br><span class="line">    static boolean executeInternal(SearchContext searchContext) throws QueryPhaseExecutionException &#123;</span><br><span class="line">        final ContextIndexSearcher searcher = searchContext.searcher();</span><br><span class="line">        SortAndFormats sortAndFormatsForRewrittenNumericSort = null;</span><br><span class="line">        final IndexReader reader = searcher.getIndexReader();</span><br><span class="line">        QuerySearchResult queryResult = searchContext.queryResult();</span><br><span class="line">        queryResult.searchTimedOut(false);</span><br><span class="line">        try &#123;</span><br><span class="line">            queryResult.from(searchContext.from());</span><br><span class="line">            queryResult.size(searchContext.size());</span><br><span class="line">            Query query = searchContext.query();</span><br><span class="line">            assert query == searcher.rewrite(query); // already rewritten</span><br><span class="line"></span><br><span class="line">            final ScrollContext scrollContext = searchContext.scrollContext();</span><br><span class="line">            if (scrollContext != null) &#123;</span><br><span class="line">                if (scrollContext.totalHits == null) &#123;</span><br><span class="line">                    // first round</span><br><span class="line">                    assert scrollContext.lastEmittedDoc == null;</span><br><span class="line">                    // there is not much that we can optimize here since we want to collect all</span><br><span class="line">                    // documents in order to get the total number of hits</span><br><span class="line"></span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    final ScoreDoc after = scrollContext.lastEmittedDoc;</span><br><span class="line">                    if (returnsDocsInOrder(query, searchContext.sort())) &#123;</span><br><span class="line">                        // now this gets interesting: since we sort in index-order, we can directly</span><br><span class="line">                        // skip to the desired doc</span><br><span class="line">                        if (after != null) &#123;</span><br><span class="line">                            query = new BooleanQuery.Builder()</span><br><span class="line">                                .add(query, BooleanClause.Occur.MUST)</span><br><span class="line">                                .add(new MinDocQuery(after.doc + 1), BooleanClause.Occur.FILTER)</span><br><span class="line">                                .build();</span><br><span class="line">                        &#125;</span><br><span class="line">                        // ... and stop collecting after $&#123;size&#125; matches</span><br><span class="line">                        searchContext.terminateAfter(searchContext.size());</span><br><span class="line">                    &#125; else if (canEarlyTerminate(reader, searchContext.sort())) &#123;</span><br><span class="line">                        // now this gets interesting: since the search sort is a prefix of the index sort, we can directly</span><br><span class="line">                        // skip to the desired doc</span><br><span class="line">                        if (after != null) &#123;</span><br><span class="line">                            query = new BooleanQuery.Builder()</span><br><span class="line">                                .add(query, BooleanClause.Occur.MUST)</span><br><span class="line">                                .add(new SearchAfterSortedDocQuery(searchContext.sort().sort, (FieldDoc) after), BooleanClause.Occur.FILTER)</span><br><span class="line">                                .build();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            final LinkedList&lt;QueryCollectorContext&gt; collectors = new LinkedList&lt;&gt;();</span><br><span class="line">            // whether the chain contains a collector that filters documents</span><br><span class="line">            boolean hasFilterCollector = false;</span><br><span class="line">            if (searchContext.terminateAfter() != SearchContext.DEFAULT_TERMINATE_AFTER) &#123;</span><br><span class="line">                // add terminate_after before the filter collectors</span><br><span class="line">                // it will only be applied on documents accepted by these filter collectors</span><br><span class="line">                collectors.add(createEarlyTerminationCollectorContext(searchContext.terminateAfter()));</span><br><span class="line">                // this collector can filter documents during the collection</span><br><span class="line">                hasFilterCollector = true;</span><br><span class="line">            &#125;</span><br><span class="line">            if (searchContext.parsedPostFilter() != null) &#123;</span><br><span class="line">                // add post filters before aggregations</span><br><span class="line">                // it will only be applied to top hits</span><br><span class="line">                collectors.add(createFilteredCollectorContext(searcher, searchContext.parsedPostFilter().query()));</span><br><span class="line">                // this collector can filter documents during the collection</span><br><span class="line">                hasFilterCollector = true;</span><br><span class="line">            &#125;</span><br><span class="line">            if (searchContext.queryCollectors().isEmpty() == false) &#123;</span><br><span class="line">                // plug in additional collectors, like aggregations</span><br><span class="line">                collectors.add(createMultiCollectorContext(searchContext.queryCollectors().values()));</span><br><span class="line">            &#125;</span><br><span class="line">            if (searchContext.minimumScore() != null) &#123;</span><br><span class="line">                // apply the minimum score after multi collector so we filter aggs as well</span><br><span class="line">                collectors.add(createMinScoreCollectorContext(searchContext.minimumScore()));</span><br><span class="line">                // this collector can filter documents during the collection</span><br><span class="line">                hasFilterCollector = true;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            CheckedConsumer&lt;List&lt;LeafReaderContext&gt;, IOException&gt; leafSorter = l -&gt; &#123;&#125;;</span><br><span class="line">            // try to rewrite numeric or date sort to the optimized distanceFeatureQuery</span><br><span class="line">            // 更详细的参见：https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-distance-feature-query.html</span><br><span class="line">            if ((searchContext.sort() != null) &amp;&amp; SYS_PROP_REWRITE_SORT) &#123;</span><br><span class="line">                Query rewrittenQuery = tryRewriteLongSort(searchContext, searcher.getIndexReader(), query, hasFilterCollector);</span><br><span class="line">                if (rewrittenQuery != null) &#123;</span><br><span class="line">                    query = rewrittenQuery;</span><br><span class="line">                    // modify sorts: add sort on _score as 1st sort, and move the sort on the original field as the 2nd sort</span><br><span class="line">                    SortField[] oldSortFields = searchContext.sort().sort.getSort();</span><br><span class="line">                    DocValueFormat[] oldFormats = searchContext.sort().formats;</span><br><span class="line">                    SortField[] newSortFields = new SortField[oldSortFields.length + 1];</span><br><span class="line">                    DocValueFormat[] newFormats = new DocValueFormat[oldSortFields.length + 1];</span><br><span class="line">                    newSortFields[0] = SortField.FIELD_SCORE;</span><br><span class="line">                    newFormats[0] = DocValueFormat.RAW;</span><br><span class="line">                    System.arraycopy(oldSortFields, 0, newSortFields, 1, oldSortFields.length);</span><br><span class="line">                    System.arraycopy(oldFormats, 0, newFormats, 1, oldFormats.length);</span><br><span class="line">                    sortAndFormatsForRewrittenNumericSort = searchContext.sort(); // stash SortAndFormats to restore it later</span><br><span class="line">                    searchContext.sort(new SortAndFormats(new Sort(newSortFields), newFormats));</span><br><span class="line">                    leafSorter = createLeafSorter(oldSortFields[0]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            boolean timeoutSet = scrollContext == null &amp;&amp; searchContext.timeout() != null &amp;&amp;</span><br><span class="line">                searchContext.timeout().equals(SearchService.NO_TIMEOUT) == false;</span><br><span class="line"></span><br><span class="line">            final Runnable timeoutRunnable;</span><br><span class="line">            if (timeoutSet) &#123;</span><br><span class="line">                final long startTime = searchContext.getRelativeTimeInMillis();</span><br><span class="line">                final long timeout = searchContext.timeout().millis();</span><br><span class="line">                final long maxTime = startTime + timeout;</span><br><span class="line">                timeoutRunnable = searcher.addQueryCancellation(() -&gt; &#123;</span><br><span class="line">                    final long time = searchContext.getRelativeTimeInMillis();</span><br><span class="line">                    if (time &gt; maxTime) &#123;</span><br><span class="line">                        throw new TimeExceededException();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                timeoutRunnable = null;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (searchContext.lowLevelCancellation()) &#123;</span><br><span class="line">                searcher.addQueryCancellation(() -&gt; &#123;</span><br><span class="line">                    SearchShardTask task = searchContext.getTask();</span><br><span class="line">                    if (task != null &amp;&amp; task.isCancelled()) &#123;</span><br><span class="line">                        throw new TaskCancelledException(&quot;cancelled&quot;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            try &#123;</span><br><span class="line"></span><br><span class="line">                // 检索数据 searchWithCollectorManager、searchWithCollector</span><br><span class="line">                boolean shouldRescore;</span><br><span class="line">                // if we are optimizing sort and there are no other collectors</span><br><span class="line">                if (sortAndFormatsForRewrittenNumericSort != null &amp;&amp; collectors.size() == 0 &amp;&amp; searchContext.getProfilers() == null) &#123;</span><br><span class="line">                    shouldRescore = searchWithCollectorManager(searchContext, searcher, query, leafSorter, timeoutSet);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    shouldRescore = searchWithCollector(searchContext, searcher, query, collectors, hasFilterCollector, timeoutSet);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                // if we rewrote numeric long or date sort, restore fieldDocs based on the original sort</span><br><span class="line">                if (sortAndFormatsForRewrittenNumericSort != null) &#123;</span><br><span class="line">                    searchContext.sort(sortAndFormatsForRewrittenNumericSort); // restore SortAndFormats</span><br><span class="line">                    restoreTopFieldDocs(queryResult, sortAndFormatsForRewrittenNumericSort);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                ExecutorService executor = searchContext.indexShard().getThreadPool().executor(ThreadPool.Names.SEARCH);</span><br><span class="line">                assert executor instanceof EWMATrackingEsThreadPoolExecutor ||</span><br><span class="line">                    (executor instanceof EsThreadPoolExecutor == false /* in case thread pool is mocked out in tests */) :</span><br><span class="line">                    &quot;SEARCH threadpool should have an executor that exposes EWMA metrics, but is of type &quot; + executor.getClass();</span><br><span class="line">                if (executor instanceof EWMATrackingEsThreadPoolExecutor) &#123;</span><br><span class="line">                    EWMATrackingEsThreadPoolExecutor rExecutor = (EWMATrackingEsThreadPoolExecutor) executor;</span><br><span class="line">                    queryResult.nodeQueueSize(rExecutor.getCurrentQueueSize());</span><br><span class="line">                    queryResult.serviceTimeEWMA((long) rExecutor.getTaskExecutionEWMA());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                return shouldRescore;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                // Search phase has finished, no longer need to check for timeout</span><br><span class="line">                // otherwise aggregation phase might get cancelled.</span><br><span class="line">                if (timeoutRunnable != null) &#123;</span><br><span class="line">                   searcher.removeQueryCancellation(timeoutRunnable);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            throw new QueryPhaseExecutionException(searchContext.shardTarget(), &quot;Failed to execute main query&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>searchWithCollectorManager与searchWithCollector都是调用<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java" target="_blank" rel="noopener">ContextIndexSearcher</a>类中的search调用Lucene接口进行查询。</p><p>到目前为止都没发现，针对-*查询都没有任何优化。</p><p>唯一有希望进行优化的地方就是通过luece检索shard的时候，会进行优化，事实上会进行一定的优化，比如借助Lucene的PointValues来优化IntField，LongField，FloatField，DoubleField。</p><p>但不管怎么优化，对于搜索而言，还是能缩小范围就缩小，不管怎么优化，都不是一点成本没有的。</p><h1>总结</h1><p>elasticsearch针对-*检索不会在索引、shard层面优化，但会在检索具体shard的时候，通过luece的特性来快速调过一些不符合条件的shard。但这些特性不能保证一定会快速检索某些shard，因为很有可能你的检索条件位于shard的上下限之间。</p><p>所以说，还是在数据入es时，拆分到合适的索引，效果最好。</p><p>推荐阅读：</p><ul><li><p><a href="https://jiankunking.com/elasticsearch-performance-tuning-practice-at-ebay.html">https://jiankunking.com/elasticsearch-performance-tuning-practice-at-ebay.html</a></p></li><li><p><a href="https://www.easyice.cn/archives/350" target="_blank" rel="noopener">https://www.easyice.cn/archives/350</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/range.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.11/range.html</a></p></li></ul>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch Refresh vs Flush</title>
    <url>/elasticsearch-refresh-vs-flush.html</url>
    <content><![CDATA[<blockquote><p>Elasticsearch Refresh和Flush区别</p></blockquote><a id="more"></a><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-refresh.html" target="_blank" rel="noopener">Refresh</a></h1><p>使用refresh API显式刷新一个或多个索引。 如果请求以数据流为目标，则刷新该流的后台索引。<font color="DeepPink"><strong>刷新使自上次刷新以来对索引执行的所有操作都可用于搜索。</strong></font></p><p><font color="DeepPink"><strong>默认情况下，Elasticsearch会定期每秒刷新一次索引，但仅在最近30秒内收到搜索请求的索引上刷新。</strong></font>也可以使用index.refresh_interval设置更改此默认间隔。</p><p>刷新请求是同步的，并且在刷新操作完成之前不会返回响应。</p><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-flush.html#flush-api-desc" target="_blank" rel="noopener">Flush</a></h1><p>通过刷新data stream或者index将当前仅存储在事务日志中的数据永久存储到Lucene索引中。当Elasticsearch重启时，会重放事务日志中未刷新到Lucene索引的数据，从而将Elasticsearch恢复到重启前的状态。</p><blockquote><p>默认情况下，Elasticsearch使用内存启发式，以便根据需要自动触发刷新操作，以便清除内存。<br>Elasticsearch automatically triggers flushes as needed, using heuristics that trade off the size of the unflushed transaction log against the cost of performing each flush.</p></blockquote><p><font color="DeepPink"><strong>一旦一个操作被刷新，它就会永久存储在Lucene索引中。</strong></font>这意味着不需要在事务日志中维护它的额外副本，除非出于某些<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html#index-modules-translog-retention" target="_blank" rel="noopener">其他原因而保留它</a>。事务日志由多个文件组成，称为generations，一旦不再需要生成文件，Elasticsearch将删除它们，释放磁盘空间。</p><p>使用flush API也可以在一个或多个索引上触发刷新，尽管用户很少需要直接调用这个API。如果在对一些文档建立索引之后调用flush API，那么成功的响应表明Elasticsearch已经flush了所有在调用flush API之前建立索引的文档。</p><p>translog的<a href="https://www.elastic.co/guide/en/Elasticsearch/reference/current/indices-flush.html" target="_blank" rel="noopener">Flush</a>是Elasticsearch在后台自动运行的。默认情况下Elasticsearch每隔5s会去检测要不要<a href="https://www.elastic.co/guide/en/Elasticsearch/reference/current/indices-flush.html" target="_blank" rel="noopener">Flush</a> translog，默认条件是:每30分钟主动进行一次<a href="https://www.elastic.co/guide/en/Elasticsearch/reference/current/indices-flush.html#flush-api-desc" target="_blank" rel="noopener">Flush</a>或者当translog文件大小大于512MB主动进行一次<a href="https://www.elastic.co/guide/en/Elasticsearch/reference/current/indices-flush.html" target="_blank" rel="noopener">Flush</a>。<font color="DeepPink"><strong>默认配置下，每次index、bulk、delete、update完成的时候，会触发Flush translog到磁盘上,然后才返回200 OK。</strong></font>这个提高了数据安全性，但是会对写入的性能造成不小的影响。</p><p>在写入效率优先的情况下，可以在index template里设置如下参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;index.translog.durability&quot;:&quot;async&quot;(默认是request) </span><br><span class="line">&quot;index.translog.sync_interval&quot;:30s (默认是5s)</span><br></pre></td></tr></table></figure><h1>小结</h1><p>简而言之，_refresh用于使新文档在搜索时可见。<br>反过来，_flush用于在硬盘上持久化内存段。<br>_flush不会影响Elasticsearch中文档的可见性，因为搜索是在内存段中进行的，而_refresh会影响它们的可见性。</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Refresh</tag>
        <tag>Flush</tag>
      </tags>
  </entry>
  <entry>
    <title>【Elasticsearch源码】 写入分析</title>
    <url>/elasticsearch-write-source-code-analysis.html</url>
    <content><![CDATA[<blockquote><p>带着疑问学源码，第一篇：Elasticsearch写入<br>代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>Elasticsearch 7.10.2+</p></blockquote><a id="more"></a><h1>目的</h1><p>在看源码之前先梳理一下，自己对于写入流程疑惑的点：</p><ul><li>Elasticsearch写入是等待所有副本都写入完成了才返回还是只要主副本写入了就返回？</li><li>副本写入成功的标准是什么？</li><li>wait_for_active_shard参数的作用是啥？</li><li>Elasticsearch为什么bulk写入会比单条写入更快?</li><li>都说Elasticsearch数据复制使用了PacificA，那到底是在哪里用的？<ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#basic-write-model" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#basic-write-model</a></li></ul></li></ul><h1>源码分析</h1><p><font color="DeepPink"><strong>第二部分是代码分析的过程，不想看的朋友可以跳过直接看第三部分总结。</strong></font></p><p>分析的话，咱们就以_bulk操作为主线。</p><p>通过搜索_bulk API找到<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/document/RestBulkAction.java" target="_blank" rel="noopener">RestBulkAction</a>。在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/document/RestBulkAction.java" target="_blank" rel="noopener">RestBulkAction</a>可以看到：</p><p>1、<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/document/RestBulkAction.java#L58" target="_blank" rel="noopener">路由注册</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public List&lt;Route&gt; routes() &#123;</span><br><span class="line">    return List.of(</span><br><span class="line">        new Route(POST, &quot;/_bulk&quot;),</span><br><span class="line">        new Route(PUT, &quot;/_bulk&quot;),</span><br><span class="line">        new Route(POST, &quot;/&#123;index&#125;/_bulk&quot;),</span><br><span class="line">        new Route(PUT, &quot;/&#123;index&#125;/_bulk&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/document/RestBulkAction.java#L72" target="_blank" rel="noopener">请求参数转换</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public RestChannelConsumer prepareRequest(final RestRequest request, final NodeClient client) throws IOException &#123;</span><br><span class="line">    BulkRequest bulkRequest = Requests.bulkRequest();</span><br><span class="line">    String defaultIndex = request.param(&quot;index&quot;);</span><br><span class="line">    String defaultRouting = request.param(&quot;routing&quot;);</span><br><span class="line">    FetchSourceContext defaultFetchSourceContext = FetchSourceContext.parseFromRestRequest(request);</span><br><span class="line">    String defaultPipeline = request.param(&quot;pipeline&quot;);</span><br><span class="line">    String waitForActiveShards = request.param(&quot;wait_for_active_shards&quot;);</span><br><span class="line">    if (waitForActiveShards != null) &#123;</span><br><span class="line">        bulkRequest.waitForActiveShards(ActiveShardCount.parseString(waitForActiveShards));</span><br><span class="line">    &#125;</span><br><span class="line">    Boolean defaultRequireAlias = request.paramAsBoolean(DocWriteRequest.REQUIRE_ALIAS, null);</span><br><span class="line">    bulkRequest.timeout(request.paramAsTime(&quot;timeout&quot;, BulkShardRequest.DEFAULT_TIMEOUT));</span><br><span class="line">    bulkRequest.setRefreshPolicy(request.param(&quot;refresh&quot;));</span><br><span class="line">    bulkRequest.add(request.requiredContent(), defaultIndex, defaultRouting,</span><br><span class="line">        defaultFetchSourceContext, defaultPipeline, defaultRequireAlias, allowExplicitIndex, request.getXContentType());</span><br><span class="line"></span><br><span class="line">    return channel -&gt; client.bulk(bulkRequest, new RestStatusToXContentListener&lt;&gt;(channel));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码中可以看到RestRequest解析并转化为BulkRequest，再通过<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/client/node/NodeClient.java" target="_blank" rel="noopener">NodeClient</a>对bulkRequest进行处理。</p><p>bulk方法是在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/client/support/AbstractClient.java#L462" target="_blank" rel="noopener">AbstractClient</a>，但实际执行的方法是<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/client/node/NodeClient.java#L85" target="_blank" rel="noopener">NodeClient</a>中的doExecute。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public &lt;Request extends ActionRequest, Response extends ActionResponse&gt;</span><br><span class="line">void doExecute(ActionType&lt;Response&gt; action, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    // Discard the task because the Client interface doesn&apos;t use it.</span><br><span class="line">    try &#123;</span><br><span class="line">        executeLocally(action, request, listener);</span><br><span class="line">    &#125; catch (TaskCancelledException | IllegalArgumentException | IllegalStateException e) &#123;</span><br><span class="line">        // #executeLocally returns the task and throws TaskCancelledException if it fails to register the task because the parent</span><br><span class="line">        // task has been cancelled, IllegalStateException if the client was not in a state to execute the request because it was not</span><br><span class="line">        // yet properly initialized or IllegalArgumentException if header validation fails we forward them to listener since this API</span><br><span class="line">        // does not concern itself with the specifics of the task handling</span><br><span class="line">        listener.onFailure(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Execute an &#123;@link ActionType&#125; locally, returning that &#123;@link Task&#125; used to track it, and linking an &#123;@link ActionListener&#125;.</span><br><span class="line"> * Prefer this method if you don&apos;t need access to the task when listening for the response. This is the method used to</span><br><span class="line"> * implement the &#123;@link Client&#125; interface.</span><br><span class="line"> *</span><br><span class="line"> * @throws TaskCancelledException if the request&apos;s parent task has been cancelled already</span><br><span class="line"> */</span><br><span class="line">public &lt;    Request extends ActionRequest,</span><br><span class="line">            Response extends ActionResponse</span><br><span class="line">        &gt; Task executeLocally(ActionType&lt;Response&gt; action, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    return taskManager.registerAndExecute(&quot;transport&quot;, transportAction(action), request, localConnection,</span><br><span class="line">            (t, r) -&gt; &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    listener.onResponse(r);</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                    assert false : new AssertionError(&quot;callback must handle its own exceptions&quot;, e);</span><br><span class="line">                    throw e;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, (t, e) -&gt; &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    listener.onFailure(e);</span><br><span class="line">                &#125; catch (Exception ex) &#123;</span><br><span class="line">                    ex.addSuppressed(e);</span><br><span class="line">                    assert false : new AssertionError(&quot;callback must handle its own exceptions&quot;, ex);</span><br><span class="line">                    throw ex;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NodeClient在处理BulkRequest请求时，会将请求的action转化为对应Transport层的action，再由<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/tasks/TaskManager.java" target="_blank" rel="noopener">TaskManager</a>的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/tasks/TaskManager.java#L158" target="_blank" rel="noopener">registerAndExecute</a>将请求转发到<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/TransportAction.java" target="_blank" rel="noopener">TransportAction</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/TransportAction.java#L52" target="_blank" rel="noopener">execute</a>来进行处理。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public &lt;Request extends ActionRequest, Response extends ActionResponse&gt;</span><br><span class="line">    Task registerAndExecute(String type, TransportAction&lt;Request, Response&gt; action, Request request, Transport.Connection localConnection,</span><br><span class="line">                            BiConsumer&lt;Task, Response&gt; onResponse, BiConsumer&lt;Task, Exception&gt; onFailure) &#123;</span><br><span class="line">        final Releasable unregisterChildNode;</span><br><span class="line">        if (request.getParentTask().isSet()) &#123;</span><br><span class="line">            unregisterChildNode = registerChildConnection(request.getParentTask().getId(), localConnection);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            unregisterChildNode = () -&gt; &#123;&#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        final Task task;</span><br><span class="line">        try &#123;</span><br><span class="line">            task = register(type, action.actionName, request);</span><br><span class="line">        &#125; catch (TaskCancelledException e) &#123;</span><br><span class="line">            unregisterChildNode.close();</span><br><span class="line">            throw e;</span><br><span class="line">        &#125;</span><br><span class="line">        // NOTE: ActionListener cannot infer Response, see https://bugs.openjdk.java.net/browse/JDK-8203195</span><br><span class="line">        action.execute(task, request, new ActionListener&lt;Response&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void onResponse(Response response) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Releasables.close(unregisterChildNode, () -&gt; unregister(task));</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    onResponse.accept(task, response);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void onFailure(Exception e) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Releasables.close(unregisterChildNode, () -&gt; unregister(task));</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    onFailure.accept(task, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        return task;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/TransportAction.java" target="_blank" rel="noopener">TransportAction</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/TransportAction.java#L52" target="_blank" rel="noopener">execute</a>代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Use this method when the transport action should continue to run in the context of the current task</span><br><span class="line"> */</span><br><span class="line">public final void execute(Task task, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    ActionRequestValidationException validationException = request.validate();</span><br><span class="line">    if (validationException != null) &#123;</span><br><span class="line">        listener.onFailure(validationException);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (task != null &amp;&amp; request.getShouldStoreResult()) &#123;</span><br><span class="line">        listener = new TaskResultStoringActionListener&lt;&gt;(taskManager, task, listener);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    RequestFilterChain&lt;Request, Response&gt; requestFilterChain = new RequestFilterChain&lt;&gt;(this, logger);</span><br><span class="line">    requestFilterChain.proceed(task, actionName, request, listener);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line"> * Continue processing the request. Should only be called if a response has not been sent through</span><br><span class="line"> * the given &#123;@link ActionListener listener&#125;</span><br><span class="line"> * 摘自父类ActionFilterChain的注释</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">public void proceed(Task task, String actionName, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">        int i = index.getAndIncrement();</span><br><span class="line">        try &#123;</span><br><span class="line">            if (i &lt; this.action.filters.length) &#123;</span><br><span class="line">                // 先执行filter逻辑</span><br><span class="line">                this.action.filters[i].apply(task, actionName, request, listener, this);</span><br><span class="line">            &#125; else if (i == this.action.filters.length) &#123;</span><br><span class="line">                // 执行TransportAction逻辑</span><br><span class="line">                this.action.doExecute(task, request, listener);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                listener.onFailure(new IllegalStateException(&quot;proceed was called too many times&quot;));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch(Exception e) &#123;</span><br><span class="line">            logger.trace(&quot;Error during transport action execution.&quot;, e);</span><br><span class="line">            listener.onFailure(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>下面看一下到<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java" target="_blank" rel="noopener">TransportBulkAction</a>中看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L161" target="_blank" rel="noopener">doExecute</a>具体做了啥？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Use this method when the transport action should continue to run in the context of the current task</span><br><span class="line"> * 摘自父类TransportAction的注释</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">protected void doExecute(Task task, BulkRequest bulkRequest, ActionListener&lt;BulkResponse&gt; listener) &#123;</span><br><span class="line">    final int indexingOps = bulkRequest.numberOfActions();</span><br><span class="line">    final long indexingBytes = bulkRequest.ramBytesUsed();</span><br><span class="line">    final boolean isOnlySystem = isOnlySystem(bulkRequest, clusterService.state().metadata().getIndicesLookup(), systemIndices);</span><br><span class="line">    final Releasable releasable = indexingPressure.markCoordinatingOperationStarted(indexingOps, indexingBytes, isOnlySystem);</span><br><span class="line">    final ActionListener&lt;BulkResponse&gt; releasingListener = ActionListener.runBefore(listener, releasable::close);</span><br><span class="line">    final String executorName = isOnlySystem ? Names.SYSTEM_WRITE : Names.WRITE;</span><br><span class="line">    try &#123;</span><br><span class="line">        doInternalExecute(task, bulkRequest, executorName, releasingListener);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        releasingListener.onFailure(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protected void doInternalExecute(Task task, BulkRequest bulkRequest, String executorName, ActionListener&lt;BulkResponse&gt; listener) &#123;</span><br><span class="line">    final long startTime = relativeTime();</span><br><span class="line">    final AtomicArray&lt;BulkItemResponse&gt; responses = new AtomicArray&lt;&gt;(bulkRequest.requests.size());</span><br><span class="line"></span><br><span class="line">    boolean hasIndexRequestsWithPipelines = false;</span><br><span class="line">    final Metadata metadata = clusterService.state().getMetadata();</span><br><span class="line">    final Version minNodeVersion = clusterService.state().getNodes().getMinNodeVersion();</span><br><span class="line">    for (DocWriteRequest&lt;?&gt; actionRequest : bulkRequest.requests) &#123;</span><br><span class="line">        IndexRequest indexRequest = getIndexWriteRequest(actionRequest);</span><br><span class="line">        if (indexRequest != null) &#123;</span><br><span class="line">            // Each index request needs to be evaluated, because this method also modifies the IndexRequest</span><br><span class="line">            boolean indexRequestHasPipeline = IngestService.resolvePipelines(actionRequest, indexRequest, metadata);</span><br><span class="line">            hasIndexRequestsWithPipelines |= indexRequestHasPipeline;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (actionRequest instanceof IndexRequest) &#123;</span><br><span class="line">            IndexRequest ir = (IndexRequest) actionRequest;</span><br><span class="line">            ir.checkAutoIdWithOpTypeCreateSupportedByVersion(minNodeVersion);</span><br><span class="line">            if (ir.getAutoGeneratedTimestamp() != IndexRequest.UNSET_AUTO_GENERATED_TIMESTAMP) &#123;</span><br><span class="line">                throw new IllegalArgumentException(&quot;autoGeneratedTimestamp should not be set externally&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (hasIndexRequestsWithPipelines) &#123;</span><br><span class="line">        // this method (doExecute) will be called again, but with the bulk requests updated from the ingest node processing but</span><br><span class="line">        // also with IngestService.NOOP_PIPELINE_NAME on each request. This ensures that this on the second time through this method,</span><br><span class="line">        // this path is never taken.</span><br><span class="line">        try &#123;</span><br><span class="line">            if (Assertions.ENABLED) &#123;</span><br><span class="line">                final boolean arePipelinesResolved = bulkRequest.requests()</span><br><span class="line">                    .stream()</span><br><span class="line">                    .map(TransportBulkAction::getIndexWriteRequest)</span><br><span class="line">                    .filter(Objects::nonNull)</span><br><span class="line">                    .allMatch(IndexRequest::isPipelineResolved);</span><br><span class="line">                assert arePipelinesResolved : bulkRequest;</span><br><span class="line">            &#125;</span><br><span class="line">            if (clusterService.localNode().isIngestNode()) &#123;</span><br><span class="line">                processBulkIndexIngestRequest(task, bulkRequest, executorName, listener);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                ingestForwarder.forwardIngestRequest(BulkAction.INSTANCE, bulkRequest, listener);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            listener.onFailure(e);</span><br><span class="line">        &#125;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Attempt to create all the indices that we&apos;re going to need during the bulk before we start.</span><br><span class="line">    // Step 1: collect all the indices in the request</span><br><span class="line">    final Map&lt;String, Boolean&gt; indices = bulkRequest.requests.stream()</span><br><span class="line">        // delete requests should not attempt to create the index (if the index does not</span><br><span class="line">        // exists), unless an external versioning is used</span><br><span class="line">        .filter(request -&gt; request.opType() != DocWriteRequest.OpType.DELETE</span><br><span class="line">            || request.versionType() == VersionType.EXTERNAL</span><br><span class="line">            || request.versionType() == VersionType.EXTERNAL_GTE)</span><br><span class="line">        .collect(Collectors.toMap(DocWriteRequest::index, DocWriteRequest::isRequireAlias, (v1, v2) -&gt; v1 || v2));</span><br><span class="line"></span><br><span class="line">    // Step 2: filter the list of indices to find those that don&apos;t currently exist.</span><br><span class="line">    final Map&lt;String, IndexNotFoundException&gt; indicesThatCannotBeCreated = new HashMap&lt;&gt;();</span><br><span class="line">    Set&lt;String&gt; autoCreateIndices = new HashSet&lt;&gt;();</span><br><span class="line">    ClusterState state = clusterService.state();</span><br><span class="line">    for (Map.Entry&lt;String, Boolean&gt; indexAndFlag : indices.entrySet()) &#123;</span><br><span class="line">        final String index = indexAndFlag.getKey();</span><br><span class="line">        boolean shouldAutoCreate = indexNameExpressionResolver.hasIndexAbstraction(index, state) == false;</span><br><span class="line">        // We should only auto create if we are not requiring it to be an alias</span><br><span class="line">        if (shouldAutoCreate &amp;&amp; (indexAndFlag.getValue() == false)) &#123;</span><br><span class="line">            autoCreateIndices.add(index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Step 3: create all the indices that are missing, if there are any missing. start the bulk after all the creates come back.</span><br><span class="line">    // 如果bulk操作的所有索引都不需要创建索引,则直接执行批量请求,否则会先创建索引</span><br><span class="line">    if (autoCreateIndices.isEmpty()) &#123;</span><br><span class="line">        executeBulk(task, bulkRequest, startTime, listener, responses, indicesThatCannotBeCreated);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final AtomicInteger counter = new AtomicInteger(autoCreateIndices.size());</span><br><span class="line">        for (String index : autoCreateIndices) &#123;</span><br><span class="line">            // 创建索引的具体实现交给TransportCreateIndexAction来完成,而TransportCreateIndexAction是TransportMasterNodeAction的子类,在TransportMasterNodeAction中完成了索引创建,这里也说明创建索引操作都会在master节点上完成</span><br><span class="line">            createIndex(index, bulkRequest.timeout(), minNodeVersion, new ActionListener&lt;&gt;() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onResponse(CreateIndexResponse result) &#123;</span><br><span class="line">                    if (counter.decrementAndGet() == 0) &#123;</span><br><span class="line">                        threadPool.executor(executorName).execute(new ActionRunnable&lt;&gt;(listener) &#123;</span><br><span class="line"></span><br><span class="line">                            @Override</span><br><span class="line">                            protected void doRun() &#123;</span><br><span class="line">                                executeBulk(task, bulkRequest, startTime, listener, responses, indicesThatCannotBeCreated);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onFailure(Exception e) &#123;</span><br><span class="line">                    final Throwable cause = ExceptionsHelper.unwrapCause(e);</span><br><span class="line">                    if (cause instanceof IndexNotFoundException) &#123;</span><br><span class="line">                        indicesThatCannotBeCreated.put(index, (IndexNotFoundException) e);</span><br><span class="line">                    &#125;</span><br><span class="line">                    else if ((cause instanceof ResourceAlreadyExistsException) == false) &#123;</span><br><span class="line">                        // fail all requests involving this index, if create didn&apos;t work</span><br><span class="line">                        for (int i = 0; i &lt; bulkRequest.requests.size(); i++) &#123;</span><br><span class="line">                            DocWriteRequest&lt;?&gt; request = bulkRequest.requests.get(i);</span><br><span class="line">                            if (request != null &amp;&amp; setResponseFailureIfIndexMatches(responses, i, request, index, e)) &#123;</span><br><span class="line">                                bulkRequest.requests.set(i, null);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    if (counter.decrementAndGet() == 0) &#123;</span><br><span class="line">                        final ActionListener&lt;BulkResponse&gt; wrappedListener = ActionListener.wrap(listener::onResponse, inner -&gt; &#123;</span><br><span class="line">                            inner.addSuppressed(e);</span><br><span class="line">                            listener.onFailure(inner);</span><br><span class="line">                        &#125;);</span><br><span class="line">                        threadPool.executor(executorName).execute(new ActionRunnable&lt;&gt;(wrappedListener) &#123;</span><br><span class="line">                            @Override</span><br><span class="line">                            protected void doRun() &#123;</span><br><span class="line">                                executeBulk(task, bulkRequest, startTime, wrappedListener, responses, indicesThatCannotBeCreated);</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            @Override</span><br><span class="line">                            public void onRejection(Exception rejectedException) &#123;</span><br><span class="line">                                rejectedException.addSuppressed(e);</span><br><span class="line">                                super.onRejection(rejectedException);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码的核心在于executeBulk，下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L397" target="_blank" rel="noopener">executeBulk</a>部分,<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L397" target="_blank" rel="noopener">executeBulk</a>在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java" target="_blank" rel="noopener">BulkOperation</a>类中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void executeBulk(Task task, final BulkRequest bulkRequest, final long startTimeNanos, final ActionListener&lt;BulkResponse&gt; listener,</span><br><span class="line">           final AtomicArray&lt;BulkItemResponse&gt; responses, Map&lt;String, IndexNotFoundException&gt; indicesThatCannotBeCreated) &#123;</span><br><span class="line">       new BulkOperation(task, bulkRequest, listener, responses, startTimeNanos, indicesThatCannotBeCreated).run();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>再看一下run，run的定义是在<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/common/util/concurrent/AbstractRunnable.java" target="_blank" rel="noopener">AbstractRunnable</a>,具体实现就是BulkOperation的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L417" target="_blank" rel="noopener">doRun</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * This method has the same semantics as &#123;@link Runnable#run()&#125;</span><br><span class="line"> * @throws InterruptedException if the run method throws an InterruptedException</span><br><span class="line"> * 摘自父类AbstractRunnable的注释</span><br><span class="line">*/</span><br><span class="line"> @Override</span><br><span class="line"> protected void doRun() &#123;</span><br><span class="line">     assert bulkRequest != null;</span><br><span class="line">     final ClusterState clusterState = observer.setAndGetObservedState();</span><br><span class="line">     if (handleBlockExceptions(clusterState)) &#123;</span><br><span class="line">         return;</span><br><span class="line">     &#125;</span><br><span class="line">     final ConcreteIndices concreteIndices = new ConcreteIndices(clusterState, indexNameExpressionResolver);</span><br><span class="line">     Metadata metadata = clusterState.metadata();</span><br><span class="line">     // 注意这里,即使是bulk请求,但对于id生成、别名获取等操作还是通过</span><br><span class="line">     // 遍历处理的,所以这里对于写入性能没有什么优化</span><br><span class="line">     for (int i = 0; i &lt; bulkRequest.requests.size(); i++) &#123;</span><br><span class="line">         DocWriteRequest&lt;?&gt; docWriteRequest = bulkRequest.requests.get(i);</span><br><span class="line">         //the request can only be null because we set it to null in the previous step, so it gets ignored</span><br><span class="line">         if (docWriteRequest == null) &#123;</span><br><span class="line">             continue;</span><br><span class="line">         &#125;</span><br><span class="line">         if (addFailureIfRequiresAliasAndAliasIsMissing(docWriteRequest, i, metadata)) &#123;</span><br><span class="line">             continue;</span><br><span class="line">         &#125;</span><br><span class="line">         if (addFailureIfIndexIsUnavailable(docWriteRequest, i, concreteIndices, metadata)) &#123;</span><br><span class="line">             continue;</span><br><span class="line">         &#125;</span><br><span class="line">         Index concreteIndex = concreteIndices.resolveIfAbsent(docWriteRequest);</span><br><span class="line">         try &#123;</span><br><span class="line">             // The ConcreteIndices#resolveIfAbsent(...) method validates via IndexNameExpressionResolver whether</span><br><span class="line">             // an operation is allowed in index into a data stream, but this isn&apos;t done when resolve call is cached, so</span><br><span class="line">             // the validation needs to be performed here too.</span><br><span class="line">             IndexAbstraction indexAbstraction = clusterState.getMetadata().getIndicesLookup().get(concreteIndex.getName());</span><br><span class="line">             if (indexAbstraction.getParentDataStream() != null &amp;&amp;</span><br><span class="line">                 // avoid valid cases when directly indexing into a backing index</span><br><span class="line">                 // (for example when directly indexing into .ds-logs-foobar-000001)</span><br><span class="line">                 concreteIndex.getName().equals(docWriteRequest.index()) == false &amp;&amp;</span><br><span class="line">                 docWriteRequest.opType() != DocWriteRequest.OpType.CREATE) &#123;</span><br><span class="line">                 throw new IllegalArgumentException(&quot;only write ops with an op_type of create are allowed in data streams&quot;);</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             switch (docWriteRequest.opType()) &#123;</span><br><span class="line">                 case CREATE:</span><br><span class="line">                 case INDEX:</span><br><span class="line">                     prohibitAppendWritesInBackingIndices(docWriteRequest, metadata);</span><br><span class="line">                     prohibitCustomRoutingOnDataStream(docWriteRequest, metadata);</span><br><span class="line">                     IndexRequest indexRequest = (IndexRequest) docWriteRequest;</span><br><span class="line">                     final IndexMetadata indexMetadata = metadata.index(concreteIndex);</span><br><span class="line">                     MappingMetadata mappingMd = indexMetadata.mapping();</span><br><span class="line">                     Version indexCreated = indexMetadata.getCreationVersion();</span><br><span class="line">                     // 路由解析，比如别名等获取</span><br><span class="line">                     indexRequest.resolveRouting(metadata);</span><br><span class="line">                     // id 处理，如果没有指定id，在这里会生成id</span><br><span class="line">                     indexRequest.process(indexCreated, mappingMd, concreteIndex.getName());</span><br><span class="line">                     break;</span><br><span class="line">                 case UPDATE:</span><br><span class="line">                     // 路由解析，比如别名等获取,如果路由有问题，这里会快速失败</span><br><span class="line">                     TransportUpdateAction.resolveAndValidateRouting(metadata, concreteIndex.getName(),</span><br><span class="line">                         (UpdateRequest) docWriteRequest);</span><br><span class="line">                     break;</span><br><span class="line">                 case DELETE:</span><br><span class="line">                     docWriteRequest.routing(metadata.resolveWriteIndexRouting(docWriteRequest.routing(), docWriteRequest.index()));</span><br><span class="line">                     // check if routing is required, if so, throw error if routing wasn&apos;t specified</span><br><span class="line">                     if (docWriteRequest.routing() == null &amp;&amp; metadata.routingRequired(concreteIndex.getName())) &#123;</span><br><span class="line">                         throw new RoutingMissingException(concreteIndex.getName(), docWriteRequest.id());</span><br><span class="line">                     &#125;</span><br><span class="line">                     break;</span><br><span class="line">                 default: throw new AssertionError(&quot;request type not supported: [&quot; + docWriteRequest.opType() + &quot;]&quot;);</span><br><span class="line">             &#125;</span><br><span class="line">         &#125; catch (ElasticsearchParseException | IllegalArgumentException | RoutingMissingException e) &#123;</span><br><span class="line">             BulkItemResponse.Failure failure = new BulkItemResponse.Failure(concreteIndex.getName(),</span><br><span class="line">                 docWriteRequest.id(), e);</span><br><span class="line">             BulkItemResponse bulkItemResponse = new BulkItemResponse(i, docWriteRequest.opType(), failure);</span><br><span class="line">             responses.set(i, bulkItemResponse);</span><br><span class="line">             // make sure the request gets never processed again</span><br><span class="line">             bulkRequest.requests.set(i, null);</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     // first, go over all the requests and create a ShardId -&gt; Operations mapping</span><br><span class="line">     // 注意这里就是bulk写入性能好的原因,通过按照shard聚合,减少内部请求次数</span><br><span class="line">     // 将请求按照shard维度聚合，以便同一个shard的document可以在一次请求中处理掉。</span><br><span class="line">     Map&lt;ShardId, List&lt;BulkItemRequest&gt;&gt; requestsByShard = new HashMap&lt;&gt;();</span><br><span class="line">     for (int i = 0; i &lt; bulkRequest.requests.size(); i++) &#123;</span><br><span class="line">         DocWriteRequest&lt;?&gt; request = bulkRequest.requests.get(i);</span><br><span class="line">         if (request == null) &#123;</span><br><span class="line">             continue;</span><br><span class="line">         &#125;</span><br><span class="line">         String concreteIndex = concreteIndices.getConcreteIndex(request.index()).getName();</span><br><span class="line">         ShardId shardId = clusterService.operationRouting().indexShards(clusterState, concreteIndex, request.id(),</span><br><span class="line">             request.routing()).shardId();</span><br><span class="line">         List&lt;BulkItemRequest&gt; shardRequests = requestsByShard.computeIfAbsent(shardId, shard -&gt; new ArrayList&lt;&gt;());</span><br><span class="line">         shardRequests.add(new BulkItemRequest(i, request));</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     if (requestsByShard.isEmpty()) &#123;</span><br><span class="line">         listener.onResponse(new BulkResponse(responses.toArray(new BulkItemResponse[responses.length()]),</span><br><span class="line">             buildTookInMillis(startTimeNanos)));</span><br><span class="line">         return;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     final AtomicInteger counter = new AtomicInteger(requestsByShard.size());</span><br><span class="line">     String nodeId = clusterService.localNode().getId();</span><br><span class="line">     for (Map.Entry&lt;ShardId, List&lt;BulkItemRequest&gt;&gt; entry : requestsByShard.entrySet()) &#123;</span><br><span class="line">         final ShardId shardId = entry.getKey();</span><br><span class="line">         final List&lt;BulkItemRequest&gt; requests = entry.getValue();</span><br><span class="line">         BulkShardRequest bulkShardRequest = new BulkShardRequest(shardId, bulkRequest.getRefreshPolicy(),</span><br><span class="line">                 requests.toArray(new BulkItemRequest[requests.size()]));</span><br><span class="line">         bulkShardRequest.waitForActiveShards(bulkRequest.waitForActiveShards());</span><br><span class="line">         bulkShardRequest.timeout(bulkRequest.timeout());</span><br><span class="line">         bulkShardRequest.routedBasedOnClusterVersion(clusterState.version());</span><br><span class="line">         if (task != null) &#123;</span><br><span class="line">             bulkShardRequest.setParentTask(nodeId, task.getId());</span><br><span class="line">         &#125;</span><br><span class="line">         client.executeLocally(TransportShardBulkAction.TYPE, bulkShardRequest, new ActionListener&lt;&gt;() &#123;</span><br><span class="line">             @Override</span><br><span class="line">             public void onResponse(BulkShardResponse bulkShardResponse) &#123;</span><br><span class="line">                 for (BulkItemResponse bulkItemResponse : bulkShardResponse.getResponses()) &#123;</span><br><span class="line">                     // we may have no response if item failed</span><br><span class="line">                     if (bulkItemResponse.getResponse() != null) &#123;</span><br><span class="line">                         bulkItemResponse.getResponse().setShardInfo(bulkShardResponse.getShardInfo());</span><br><span class="line">                     &#125;</span><br><span class="line">                     responses.set(bulkItemResponse.getItemId(), bulkItemResponse);</span><br><span class="line">                 &#125;</span><br><span class="line">                 if (counter.decrementAndGet() == 0) &#123;</span><br><span class="line">                     finishHim();</span><br><span class="line">                 &#125;</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             @Override</span><br><span class="line">             public void onFailure(Exception e) &#123;</span><br><span class="line">                 // create failures for all relevant requests</span><br><span class="line">                 for (BulkItemRequest request : requests) &#123;</span><br><span class="line">                     final String indexName = concreteIndices.getConcreteIndex(request.index()).getName();</span><br><span class="line">                     DocWriteRequest&lt;?&gt; docWriteRequest = request.request();</span><br><span class="line">                     responses.set(request.id(), new BulkItemResponse(request.id(), docWriteRequest.opType(),</span><br><span class="line">                             new BulkItemResponse.Failure(indexName, docWriteRequest.id(), e)));</span><br><span class="line">                 &#125;</span><br><span class="line">                 if (counter.decrementAndGet() == 0) &#123;</span><br><span class="line">                     finishHim();</span><br><span class="line">                 &#125;</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             private void finishHim() &#123;</span><br><span class="line">                 listener.onResponse(new BulkResponse(responses.toArray(new BulkItemResponse[responses.length()]),</span><br><span class="line">                     buildTookInMillis(startTimeNanos)));</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;);</span><br><span class="line">     &#125;</span><br><span class="line">     bulkRequest = null; // allow memory for bulk request items to be reclaimed before all items have been completed</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>这里需要注意的是：又到了NodeClient executeLocally方法了:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NodeClient executeLocally=&gt;</span><br><span class="line">TaskManager registerAndExecute=&gt;</span><br><span class="line">action execute(此处action为TransportShardBulkAction.TYPE)=&gt;</span><br><span class="line">TransportAction execute =&gt;</span><br><span class="line">TransportAction proceed =&gt; </span><br><span class="line">action doExecute(此处action为TransportShardBulkAction.TYPE)=&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>下面到<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java" target="_blank" rel="noopener">TransportShardBulkAction</a>中找一下doExecute,最终在TransportShardBulkAction的父类TransportReplicationAction中找到了<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java#L182" target="_blank" rel="noopener">doExecute</a>：</p><p><img data-src="/images/elasticsearch-write-source-code-analysis/TransportShardBulkAction.png" alt></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void doExecute(Task task, Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    assert request.shardId() != null : &quot;request shardId must be set&quot;;</span><br><span class="line">    runReroutePhase(task, request, listener, true);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void runReroutePhase(Task task, Request request, ActionListener&lt;Response&gt; listener, boolean initiatedByNodeClient) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        // ReroutePhase也是继承 AbstractRunnable 从而要到ReroutePhase找 doRun</span><br><span class="line">        new ReroutePhase((ReplicationTask) task, request, listener, initiatedByNodeClient).run();</span><br><span class="line">    &#125; catch (RuntimeException e) &#123;</span><br><span class="line">        listener.onFailure(e);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java#L669" target="_blank" rel="noopener">ReroutePhase</a>类中<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java#L698" target="_blank" rel="noopener">doRun()</a>方法如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void doRun() &#123;</span><br><span class="line">    setPhase(task, &quot;routing&quot;);</span><br><span class="line">    final ClusterState state = observer.setAndGetObservedState();</span><br><span class="line">    final ClusterBlockException blockException = blockExceptions(state, request.shardId().getIndexName());</span><br><span class="line">    if (blockException != null) &#123;</span><br><span class="line">        if (blockException.retryable()) &#123;</span><br><span class="line">            logger.trace(&quot;cluster is blocked, scheduling a retry&quot;, blockException);</span><br><span class="line">            retry(blockException);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            finishAsFailed(blockException);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final IndexMetadata indexMetadata = state.metadata().index(request.shardId().getIndex());</span><br><span class="line">        if (indexMetadata == null) &#123;</span><br><span class="line">            // ensure that the cluster state on the node is at least as high as the node that decided that the index was there</span><br><span class="line">            if (state.version() &lt; request.routedBasedOnClusterVersion()) &#123;</span><br><span class="line">                logger.trace(&quot;failed to find index [&#123;&#125;] for request [&#123;&#125;] despite sender thinking it would be here. &quot; +</span><br><span class="line">                        &quot;Local cluster state version [&#123;&#125;]] is older than on sending node (version [&#123;&#125;]), scheduling a retry...&quot;,</span><br><span class="line">                    request.shardId().getIndex(), request, state.version(), request.routedBasedOnClusterVersion());</span><br><span class="line">                retry(new IndexNotFoundException(&quot;failed to find index as current cluster state with version [&quot; + state.version() +</span><br><span class="line">                    &quot;] is stale (expected at least [&quot; + request.routedBasedOnClusterVersion() + &quot;]&quot;,</span><br><span class="line">                    request.shardId().getIndexName()));</span><br><span class="line">                return;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                finishAsFailed(new IndexNotFoundException(request.shardId().getIndex()));</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (indexMetadata.getState() == IndexMetadata.State.CLOSE) &#123;</span><br><span class="line">            finishAsFailed(new IndexClosedException(indexMetadata.getIndex()));</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (request.waitForActiveShards() == ActiveShardCount.DEFAULT) &#123;</span><br><span class="line">            // if the wait for active shard count has not been set in the request,</span><br><span class="line">            // resolve it from the index settings</span><br><span class="line">            request.waitForActiveShards(indexMetadata.getWaitForActiveShards());</span><br><span class="line">        &#125;</span><br><span class="line">        assert request.waitForActiveShards() != ActiveShardCount.DEFAULT :</span><br><span class="line">            &quot;request waitForActiveShards must be set in resolveRequest&quot;;</span><br><span class="line"></span><br><span class="line">        final ShardRouting primary = state.getRoutingTable().shardRoutingTable(request.shardId()).primaryShard();</span><br><span class="line">        if (primary == null || primary.active() == false) &#123;</span><br><span class="line">            logger.trace(&quot;primary shard [&#123;&#125;] is not yet active, scheduling a retry: action [&#123;&#125;], request [&#123;&#125;], &quot;</span><br><span class="line">                + &quot;cluster state version [&#123;&#125;]&quot;, request.shardId(), actionName, request, state.version());</span><br><span class="line">            retryBecauseUnavailable(request.shardId(), &quot;primary shard is not active&quot;);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        if (state.nodes().nodeExists(primary.currentNodeId()) == false) &#123;</span><br><span class="line">            logger.trace(&quot;primary shard [&#123;&#125;] is assigned to an unknown node [&#123;&#125;], scheduling a retry: action [&#123;&#125;], request [&#123;&#125;], &quot;</span><br><span class="line">                + &quot;cluster state version [&#123;&#125;]&quot;, request.shardId(), primary.currentNodeId(), actionName, request, state.version());</span><br><span class="line">            retryBecauseUnavailable(request.shardId(), &quot;primary shard isn&apos;t assigned to a known node.&quot;);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        final DiscoveryNode node = state.nodes().get(primary.currentNodeId());</span><br><span class="line">        if (primary.currentNodeId().equals(state.nodes().getLocalNodeId())) &#123;</span><br><span class="line">            // 是当前节点，继续执行</span><br><span class="line">            performLocalAction(state, primary, node, indexMetadata);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // 不是当前节点，转发到对应的node上进行处理</span><br><span class="line">            performRemoteAction(state, primary, node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果分片在当前节点，task当前阶段置为“waiting_on_primary”，否则为“rerouted”，两者都走到同一入口，即performAction(…)， 在performAction方法中，会调用TransportService的sendRequest方法，将请求发送出去（不管是local还是remote都会发请求）。</p><p>如果返回异常，比如ConnectTransportException、NodeClosedException等，会进行重试，重试的逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void retry(Exception failure) &#123;</span><br><span class="line">            assert failure != null;</span><br><span class="line">            if (observer.isTimedOut()) &#123;</span><br><span class="line">                // we running as a last attempt after a timeout has happened. don&apos;t retry</span><br><span class="line">                finishAsFailed(failure);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            setPhase(task, &quot;waiting_for_retry&quot;);</span><br><span class="line">            request.onRetry();</span><br><span class="line">            observer.waitForNextChange(new ClusterStateObserver.Listener() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onNewClusterState(ClusterState state) &#123;</span><br><span class="line">                    run();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onClusterServiceClose() &#123;</span><br><span class="line">                    finishAsFailed(new NodeClosedException(clusterService.localNode()));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onTimeout(TimeValue timeout) &#123;</span><br><span class="line">                    // Try one more time...</span><br><span class="line">                    run();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>在TransportReplicationAction构造函数中，注册了主分片、副本分片的处理函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transportService.registerRequestHandler(transportPrimaryAction, executor, forceExecutionOnPrimary, true,</span><br><span class="line">    in -&gt; new ConcreteShardRequest&lt;&gt;(requestReader, in), this::handlePrimaryRequest);</span><br><span class="line"></span><br><span class="line">// we must never reject on because of thread pool capacity on replicas</span><br><span class="line">transportService.registerRequestHandler(transportReplicaAction, executor, true, true,</span><br><span class="line">    in -&gt; new ConcreteReplicaRequest&lt;&gt;(replicaRequestReader, in), this::handleReplicaRequest);</span><br></pre></td></tr></table></figure><p>下面先看一下主分片的处理逻辑：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected void handlePrimaryRequest(final ConcreteShardRequest&lt;Request&gt; request, final TransportChannel channel, final Task task) &#123;</span><br><span class="line">        Releasable releasable = checkPrimaryLimits(request.getRequest(), request.sentFromLocalReroute(),</span><br><span class="line">            request.localRerouteInitiatedByNodeClient());</span><br><span class="line">        ActionListener&lt;Response&gt; listener =</span><br><span class="line">            ActionListener.runBefore(new ChannelActionListener&lt;&gt;(channel, transportPrimaryAction, request), releasable::close);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            new AsyncPrimaryAction(request, listener, (ReplicationTask) task).run();</span><br><span class="line">        &#125; catch (RuntimeException e) &#123;</span><br><span class="line">            listener.onFailure(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>往主分片写入、副本分片写入操作分别在：<br><a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java" target="_blank" rel="noopener">TransportReplicationAction</a>的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java#L314" target="_blank" rel="noopener">AsyncPrimaryAction</a>、<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java#L550" target="_blank" rel="noopener">AsyncReplicaAction</a>中。</p></blockquote><p>调用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TransportReplicationAction handlePrimaryRequest =&gt;</span><br><span class="line">AsyncPrimaryAction doRun()=&gt;</span><br><span class="line">// 注意：runWithPrimaryShardReference，该函数会在处理完主分片后</span><br><span class="line">// 开始处理分片副本</span><br><span class="line">AsyncPrimaryAction runWithPrimaryShardReference(final PrimaryShardReference primaryShardReference)</span><br><span class="line">ReplicationOperation execute()=&gt;</span><br><span class="line">PrimaryShardReference perform(Request request, ActionListener&lt;PrimaryResult&lt;ReplicaRequest, Response&gt;&gt; listener)=&gt;</span><br><span class="line">TransportWriteAction shardOperationOnPrimary =&gt;</span><br><span class="line">TransportShardBulkAction dispatchedShardOperationOnPrimary =&gt;</span><br><span class="line">// 注意：</span><br><span class="line">// 1、performOnPrimary会调用shardOperationOnPrimary注册监听器</span><br><span class="line">// 当ReplicationOperation handlePrimaryResult完成时 会调用maybeSyncTranslog 进行flush translog</span><br><span class="line">// 2、performOnPrimary doRun()会遍历BulkShardRequest中BulkItemRequest[]</span><br><span class="line">TransportShardBulkAction performOnPrimary =&gt;</span><br><span class="line">// executeBulkItemRequest处理单个请求及异常</span><br><span class="line">// 会根据BulkItemRequest的不同类型而进行不同的处理。</span><br><span class="line">// 其实就是IndexRequest,DeleteRequest,UpdateRequest。</span><br><span class="line">TransportShardBulkAction executeBulkItemRequest =&gt;</span><br><span class="line">IndexShard applyIndexOperationOnPrimary =&gt;</span><br><span class="line">IndexShard applyIndexOperation =&gt;</span><br><span class="line">IndexShard index =&gt;</span><br><span class="line">InternalEngine index =&gt;</span><br><span class="line">InternalEngine indexIntoLucene =&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><blockquote><p><code>通过TransportShardBulkAction中的executeBulkItemRequest可以看到，即使是bulk请求，在真实处理的时候，还是通过一个循环，一个一个处理的，并没有什么神奇之处。</code></p></blockquote><p>maybeSyncTranslog:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void maybeSyncTranslog(final IndexShard indexShard) throws IOException &#123;</span><br><span class="line">    if (indexShard.getTranslogDurability() == Translog.Durability.REQUEST &amp;&amp;</span><br><span class="line">        indexShard.getLastSyncedGlobalCheckpoint() &lt; indexShard.getLastKnownGlobalCheckpoint()) &#123;</span><br><span class="line">        indexShard.sync();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面仔细看看index函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Perform document index operation on the engine</span><br><span class="line"> * @param index operation to perform</span><br><span class="line"> * @return &#123;@link IndexResult&#125; containing updated translog location, version and</span><br><span class="line"> * document specific failures</span><br><span class="line"> *</span><br><span class="line"> * Note: engine level failures (i.e. persistent engine failures) are thrown</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">public IndexResult index(Index index) throws IOException &#123;</span><br><span class="line">    assert Objects.equals(index.uid().field(), IdFieldMapper.NAME) : index.uid().field();</span><br><span class="line">    final boolean doThrottle = index.origin().isRecovery() == false;</span><br><span class="line">    try (ReleasableLock releasableLock = readLock.acquire()) &#123;</span><br><span class="line">        // 监测shard是否close，如果close了，这里会抛出异常</span><br><span class="line">        ensureOpen();</span><br><span class="line">        assert assertIncomingSequenceNumber(index.origin(), index.seqNo());</span><br><span class="line">        int reservedDocs = 0;</span><br><span class="line">        try (Releasable ignored = versionMap.acquireLock(index.uid().bytes());</span><br><span class="line">            Releasable indexThrottle = doThrottle ? throttle.acquireThrottle() : () -&gt; &#123;&#125;) &#123;</span><br><span class="line">            lastWriteNanos = index.startTime();</span><br><span class="line">            // 在非自定义id的情况下，直接将文档add，否则需要update</span><br><span class="line">            // 而update比add成本高很多。</span><br><span class="line">            /* A NOTE ABOUT APPEND ONLY OPTIMIZATIONS:</span><br><span class="line">             * if we have an autoGeneratedID that comes into the engine we can potentially optimize</span><br><span class="line">             * and just use addDocument instead of updateDocument and skip the entire version and index lookupVersion across the board.</span><br><span class="line">             * Yet, we have to deal with multiple document delivery, for this we use a property of the document that is added</span><br><span class="line">             * to detect if it has potentially been added before. We use the documents timestamp for this since it&apos;s something</span><br><span class="line">             * that:</span><br><span class="line">             *  - doesn&apos;t change per document</span><br><span class="line">             *  - is preserved in the transaction log</span><br><span class="line">             *  - and is assigned before we start to index / replicate</span><br><span class="line">             * NOTE: it&apos;s not important for this timestamp to be consistent across nodes etc. it&apos;s just a number that is in the common</span><br><span class="line">             * case increasing and can be used in the failure case when we retry and resent documents to establish a happens before</span><br><span class="line">             * relationship. For instance:</span><br><span class="line">             *  - doc A has autoGeneratedIdTimestamp = 10, isRetry = false</span><br><span class="line">             *  - doc B has autoGeneratedIdTimestamp = 9, isRetry = false</span><br><span class="line">             *</span><br><span class="line">             *  while both docs are in in flight, we disconnect on one node, reconnect and send doc A again</span><br><span class="line">             *  - now doc A&apos; has autoGeneratedIdTimestamp = 10, isRetry = true</span><br><span class="line">             *</span><br><span class="line">             *  if A&apos; arrives on the shard first we update maxUnsafeAutoIdTimestamp to 10 and use update document. All subsequent</span><br><span class="line">             *  documents that arrive (A and B) will also use updateDocument since their timestamps are less than</span><br><span class="line">             *  maxUnsafeAutoIdTimestamp. While this is not strictly needed for doc B it is just much simpler to implement since it</span><br><span class="line">             *  will just de-optimize some doc in the worst case.</span><br><span class="line">             *</span><br><span class="line">             *  if A arrives on the shard first we use addDocument since maxUnsafeAutoIdTimestamp is &lt; 10. A` will then just be skipped</span><br><span class="line">             *  or calls updateDocument.</span><br><span class="line">             */</span><br><span class="line"></span><br><span class="line">            // 检查版本号是否冲突等</span><br><span class="line">            // 1、尝试从versionMap中读取待写入文档的version，也即从内存中读取。</span><br><span class="line">            // versionMap会暂存还没有commit到磁盘的文档版本信息。</span><br><span class="line">            // 具体逻辑在：InternalEngine getVersionFromMap中</span><br><span class="line">            // 2、如果第1步中没有读到，则从index中读取，也即从文件中读取。</span><br><span class="line">            // 具体逻辑在VersionsAndSeqNoResolver loadDocIdAndVersion中（loadDocIdAndVersion是Lucene的方法）</span><br><span class="line">            // 注意：这里不会get整个文档，而是只会获取文档的版本号做对比。</span><br><span class="line">            final IndexingStrategy plan = indexingStrategyForOperation(index);</span><br><span class="line">            reservedDocs = plan.reservedDocs;</span><br><span class="line"></span><br><span class="line">            final IndexResult indexResult;</span><br><span class="line">            if (plan.earlyResultOnPreFlightError.isPresent()) &#123;</span><br><span class="line">                assert index.origin() == Operation.Origin.PRIMARY : index.origin();</span><br><span class="line">                indexResult = plan.earlyResultOnPreFlightError.get();</span><br><span class="line">                assert indexResult.getResultType() == Result.Type.FAILURE : indexResult.getResultType();</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // generate or register sequence number</span><br><span class="line">                if (index.origin() == Operation.Origin.PRIMARY) &#123;</span><br><span class="line">                    index = new Index(index.uid(), index.parsedDoc(), generateSeqNoForOperationOnPrimary(index), index.primaryTerm(),</span><br><span class="line">                        index.version(), index.versionType(), index.origin(), index.startTime(), index.getAutoGeneratedIdTimestamp(),</span><br><span class="line">                        index.isRetry(), index.getIfSeqNo(), index.getIfPrimaryTerm());</span><br><span class="line"></span><br><span class="line">                    final boolean toAppend = plan.indexIntoLucene &amp;&amp; plan.useLuceneUpdateDocument == false;</span><br><span class="line">                    if (toAppend == false) &#123;</span><br><span class="line">                        advanceMaxSeqNoOfUpdatesOrDeletesOnPrimary(index.seqNo());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    markSeqNoAsSeen(index.seqNo());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                assert index.seqNo() &gt;= 0 : &quot;ops should have an assigned seq no.; origin: &quot; + index.origin();</span><br><span class="line"></span><br><span class="line">                if (plan.indexIntoLucene || plan.addStaleOpToLucene) &#123;</span><br><span class="line">                    // 将数据写入lucene，最终会调用lucene的文档写入接口</span><br><span class="line">                    indexResult = indexIntoLucene(index, plan);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    indexResult = new IndexResult(</span><br><span class="line">                        plan.versionForIndexing, index.primaryTerm(), index.seqNo(), plan.currentNotFoundOrDeleted);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (index.origin().isFromTranslog() == false) &#123;</span><br><span class="line">                final Translog.Location location;</span><br><span class="line">                if (indexResult.getResultType() == Result.Type.SUCCESS) &#123;</span><br><span class="line">                    location = translog.add(new Translog.Index(index, indexResult));</span><br><span class="line">                &#125; else if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) &#123;</span><br><span class="line">                    // if we have document failure, record it as a no-op in the translog and Lucene with the generated seq_no</span><br><span class="line">                    final NoOp noOp = new NoOp(indexResult.getSeqNo(), index.primaryTerm(), index.origin(),</span><br><span class="line">                        index.startTime(), indexResult.getFailure().toString());</span><br><span class="line">                    location = innerNoOp(noOp).getTranslogLocation();</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    location = null;</span><br><span class="line">                &#125;</span><br><span class="line">                indexResult.setTranslogLocation(location);</span><br><span class="line">            &#125;</span><br><span class="line">            if (plan.indexIntoLucene &amp;&amp; indexResult.getResultType() == Result.Type.SUCCESS) &#123;</span><br><span class="line">                final Translog.Location translogLocation = trackTranslogLocation.get() ? indexResult.getTranslogLocation() : null;</span><br><span class="line">                versionMap.maybePutIndexUnderLock(index.uid().bytes(),</span><br><span class="line">                    new IndexVersionValue(translogLocation, plan.versionForIndexing, index.seqNo(), index.primaryTerm()));</span><br><span class="line">            &#125;</span><br><span class="line">            localCheckpointTracker.markSeqNoAsProcessed(indexResult.getSeqNo());</span><br><span class="line">            if (indexResult.getTranslogLocation() == null) &#123;</span><br><span class="line">                // the op is coming from the translog (and is hence persisted already) or it does not have a sequence number</span><br><span class="line">                assert index.origin().isFromTranslog() || indexResult.getSeqNo() == SequenceNumbers.UNASSIGNED_SEQ_NO;</span><br><span class="line">                localCheckpointTracker.markSeqNoAsPersisted(indexResult.getSeqNo());</span><br><span class="line">            &#125;</span><br><span class="line">            indexResult.setTook(System.nanoTime() - index.startTime());</span><br><span class="line">            indexResult.freeze();</span><br><span class="line">            return indexResult;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            releaseInFlightDocs(reservedDocs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (RuntimeException | IOException e) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (e instanceof AlreadyClosedException == false &amp;&amp; treatDocumentFailureAsTragicError(index)) &#123;</span><br><span class="line">                failEngine(&quot;index id[&quot; + index.id() + &quot;] origin[&quot; + index.origin() + &quot;] seq#[&quot; + index.seqNo() + &quot;]&quot;, e);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                maybeFailEngine(&quot;index id[&quot; + index.id() + &quot;] origin[&quot; + index.origin() + &quot;] seq#[&quot; + index.seqNo() + &quot;]&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception inner) &#123;</span><br><span class="line">            e.addSuppressed(inner);</span><br><span class="line">        &#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ES的写入操作是先写lucene，将数据写入到lucene内存后再写translog。ES之所以先写lucene后写log主要原因大概是写入Lucene时，Lucene会再对数据进行一些检查，有可能出现写入Lucene失败的情况。如果先写translog，那么就要处理写入translog成功但是写入Lucene一直失败的问题，所以ES采用了先写Lucene的方式。</p><p>在写完primary后，会继续写replicas：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void runWithPrimaryShardReference(final PrimaryShardReference primaryShardReference) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                 </span><br><span class="line">            		......</span><br><span class="line"></span><br><span class="line">                    new ReplicationOperation&lt;&gt;(primaryRequest.getRequest(), primaryShardReference,</span><br><span class="line">                        responseListener.map(result -&gt; result.finalResponseIfSuccessful),</span><br><span class="line">                        newReplicasProxy(), logger, threadPool, actionName, primaryRequest.getPrimaryTerm(), initialRetryBackoffBound,</span><br><span class="line">                        retryTimeout)</span><br><span class="line">                        .execute();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                handleException(primaryShardReference, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>下面看一下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java" target="_blank" rel="noopener">ReplicationOperation</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java#L110" target="_blank" rel="noopener">execute()</a>都干了啥？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void execute() throws Exception &#123;</span><br><span class="line">        // checkActiveShardCount返回null表示副本符合要求</span><br><span class="line">        // 注意点：这个检查是在写入主副本之前，如果活跃分片不符合要求，</span><br><span class="line">        // 则这时就终止整个请求了</span><br><span class="line">        final String activeShardCountFailure = checkActiveShardCount();</span><br><span class="line">        final ShardRouting primaryRouting = primary.routingEntry();</span><br><span class="line">        final ShardId primaryId = primaryRouting.shardId();</span><br><span class="line">        if (activeShardCountFailure != null) &#123;</span><br><span class="line">            finishAsFailed(new UnavailableShardsException(primaryId,</span><br><span class="line">                &quot;&#123;&#125; Timeout: [&#123;&#125;], request: [&#123;&#125;]&quot;, activeShardCountFailure, request.timeout(), request));</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        totalShards.incrementAndGet();</span><br><span class="line">        pendingActions.incrementAndGet(); // increase by 1 until we finish all primary coordination</span><br><span class="line">        // 主副本写入完成 回调ReplicationOperation handlePrimaryResult</span><br><span class="line">        primary.perform(request, ActionListener.wrap(this::handlePrimaryResult, resultListener::onFailure));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">     /**</span><br><span class="line">     * Checks whether we can perform a write based on the required active shard count setting.</span><br><span class="line">     * Returns **null* if OK to proceed, or a string describing the reason to stop</span><br><span class="line">     * wait_for_active_shards 参数 真正起作用的地方</span><br><span class="line">     */</span><br><span class="line">    protected String checkActiveShardCount() &#123;</span><br><span class="line">        final ShardId shardId = primary.routingEntry().shardId();</span><br><span class="line">        final ActiveShardCount waitForActiveShards = request.waitForActiveShards();</span><br><span class="line">        if (waitForActiveShards == ActiveShardCount.NONE) &#123;</span><br><span class="line">            return null;  // not waiting for any shards</span><br><span class="line">        &#125;</span><br><span class="line">        final IndexShardRoutingTable shardRoutingTable = primary.getReplicationGroup().getRoutingTable();</span><br><span class="line">        if (waitForActiveShards.enoughShardsActive(shardRoutingTable)) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            final String resolvedShards = waitForActiveShards == ActiveShardCount.ALL ? Integer.toString(shardRoutingTable.shards().size())</span><br><span class="line">                                              : waitForActiveShards.toString();</span><br><span class="line">            logger.trace(&quot;[&#123;&#125;] not enough active copies to meet shard count of [&#123;&#125;] (have &#123;&#125;, needed &#123;&#125;), scheduling a retry. op [&#123;&#125;], &quot; +</span><br><span class="line">                         &quot;request [&#123;&#125;]&quot;, shardId, waitForActiveShards, shardRoutingTable.activeShards().size(),</span><br><span class="line">                         resolvedShards, opType, request);</span><br><span class="line">            return &quot;Not enough active copies to meet shard count of [&quot; + waitForActiveShards + &quot;] (have &quot; +</span><br><span class="line">                       shardRoutingTable.activeShards().size() + &quot;, needed &quot; + resolvedShards + &quot;).&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>下面看下<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java" target="_blank" rel="noopener">ReplicationOperation</a>中的<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java#L115" target="_blank" rel="noopener">handlePrimaryResult</a>:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    private void handlePrimaryResult(final PrimaryResultT primaryResult) &#123;</span><br><span class="line">    this.primaryResult = primaryResult;</span><br><span class="line">    final ReplicaRequest replicaRequest = primaryResult.replicaRequest();</span><br><span class="line">    if (replicaRequest != null) &#123;</span><br><span class="line">        if (logger.isTraceEnabled()) &#123;</span><br><span class="line">            logger.trace(&quot;[&#123;&#125;] op [&#123;&#125;] completed on primary for request [&#123;&#125;]&quot;, primary.routingEntry().shardId(), opType, request);</span><br><span class="line">        &#125;</span><br><span class="line">        // we have to get the replication group after successfully indexing into the primary in order to honour recovery semantics.</span><br><span class="line">        // we have to make sure that every operation indexed into the primary after recovery start will also be replicated</span><br><span class="line">        // to the recovery target. If we used an old replication group, we may miss a recovery that has started since then.</span><br><span class="line">        // we also have to make sure to get the global checkpoint before the replication group, to ensure that the global checkpoint</span><br><span class="line">        // is valid for this replication group. If we would sample in the reverse, the global checkpoint might be based on a subset</span><br><span class="line">        // of the sampled replication group, and advanced further than what the given replication group would allow it to.</span><br><span class="line">        // This would entail that some shards could learn about a global checkpoint that would be higher than its local checkpoint.</span><br><span class="line">        final long globalCheckpoint = primary.computedGlobalCheckpoint();</span><br><span class="line">        // we have to capture the max_seq_no_of_updates after this request was completed on the primary to make sure the value of</span><br><span class="line">        // max_seq_no_of_updates on replica when this request is executed is at least the value on the primary when it was executed</span><br><span class="line">        // on.</span><br><span class="line">        final long maxSeqNoOfUpdatesOrDeletes = primary.maxSeqNoOfUpdatesOrDeletes();</span><br><span class="line">        assert maxSeqNoOfUpdatesOrDeletes != SequenceNumbers.UNASSIGNED_SEQ_NO : &quot;seqno_of_updates still uninitialized&quot;;</span><br><span class="line">        // 获取活跃的shard</span><br><span class="line">        // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java#L70</span><br><span class="line">        final ReplicationGroup replicationGroup = primary.getReplicationGroup();</span><br><span class="line">        final PendingReplicationActions pendingReplicationActions = primary.getPendingReplicationActions();</span><br><span class="line">        markUnavailableShardsAsStale(replicaRequest, replicationGroup);</span><br><span class="line">        // 并发写入 所有副本(in-sync set中的)</span><br><span class="line">        performOnReplicas(replicaRequest, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes, replicationGroup, pendingReplicationActions);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void performOnReplicas(final ReplicaRequest replicaRequest, final long globalCheckpoint,</span><br><span class="line">                               final long maxSeqNoOfUpdatesOrDeletes, final ReplicationGroup replicationGroup,</span><br><span class="line">                               final PendingReplicationActions pendingReplicationActions) &#123;</span><br><span class="line">    // for total stats, add number of unassigned shards and</span><br><span class="line">    // number of initializing shards that are not ready yet to receive operations (recovery has not opened engine yet on the target)</span><br><span class="line">    totalShards.addAndGet(replicationGroup.getSkippedShards().size());</span><br><span class="line"></span><br><span class="line">    final ShardRouting primaryRouting = primary.routingEntry();</span><br><span class="line"></span><br><span class="line">    for (final ShardRouting shard : replicationGroup.getReplicationTargets()) &#123;</span><br><span class="line">        if (shard.isSameAllocation(primaryRouting) == false) &#123;</span><br><span class="line">            performOnReplica(shard, replicaRequest, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes, pendingReplicationActions);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void performOnReplica(final ShardRouting shard, final ReplicaRequest replicaRequest,</span><br><span class="line">                              final long globalCheckpoint, final long maxSeqNoOfUpdatesOrDeletes,</span><br><span class="line">                              final PendingReplicationActions pendingReplicationActions) &#123;</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;[&#123;&#125;] sending op [&#123;&#125;] to replica &#123;&#125; for request [&#123;&#125;]&quot;, shard.shardId(), opType, shard, replicaRequest);</span><br><span class="line">    &#125;</span><br><span class="line">    totalShards.incrementAndGet();</span><br><span class="line">    pendingActions.incrementAndGet();</span><br><span class="line">    final ActionListener&lt;ReplicaResponse&gt; replicationListener = new ActionListener&lt;&gt;() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void onResponse(ReplicaResponse response) &#123;</span><br><span class="line">            successfulShards.incrementAndGet();</span><br><span class="line">            try &#123;</span><br><span class="line">                updateCheckPoints(shard, response::localCheckpoint, response::globalCheckpoint);</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                decPendingAndFinishIfNeeded();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void onFailure(Exception replicaException) &#123;</span><br><span class="line">            logger.trace(() -&gt; new ParameterizedMessage(</span><br><span class="line">                &quot;[&#123;&#125;] failure while performing [&#123;&#125;] on replica &#123;&#125;, request [&#123;&#125;]&quot;,</span><br><span class="line">                shard.shardId(), opType, shard, replicaRequest), replicaException);</span><br><span class="line">            // Only report &quot;critical&quot; exceptions - TODO: Reach out to the master node to get the latest shard state then report.</span><br><span class="line">            if (TransportActions.isShardNotAvailableException(replicaException) == false) &#123;</span><br><span class="line">                RestStatus restStatus = ExceptionsHelper.status(replicaException);</span><br><span class="line">                shardReplicaFailures.add(new ReplicationResponse.ShardInfo.Failure(</span><br><span class="line">                    shard.shardId(), shard.currentNodeId(), replicaException, restStatus, false));</span><br><span class="line">            &#125;</span><br><span class="line">            String message = String.format(Locale.ROOT, &quot;failed to perform %s on replica %s&quot;, opType, shard);</span><br><span class="line">            </span><br><span class="line">            // failShardIfNeeded 具体执行何种操作要看 replicasProxy的真正实现类:</span><br><span class="line">            // 如果是WriteActionReplicasProxy,则会报告shard错误。</span><br><span class="line">            // 在写入场景中replicasProxy的真正实现类就是WriteActionReplicasProxy。</span><br><span class="line">            replicasProxy.failShardIfNeeded(shard, primaryTerm, message, replicaException,</span><br><span class="line">                ActionListener.wrap(r -&gt; decPendingAndFinishIfNeeded(), ReplicationOperation.this::onNoLongerPrimary));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public String toString() &#123;</span><br><span class="line">            return &quot;[&quot; + replicaRequest + &quot;][&quot; + shard + &quot;]&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line"> * A proxy for &lt;b&gt;write&lt;/b&gt; operations that need to be performed on the</span><br><span class="line"> * replicas, where a failure to execute the operation should fail</span><br><span class="line"> * the replica shard and/or mark the replica as stale.</span><br><span class="line"> *</span><br><span class="line"> * This extends &#123;@code TransportReplicationAction.ReplicasProxy&#125; to do the</span><br><span class="line"> * failing and stale-ing.</span><br><span class="line"> */</span><br><span class="line">class WriteActionReplicasProxy extends ReplicasProxy &#123;</span><br><span class="line"></span><br><span class="line">    // 注意 </span><br><span class="line">    // 1、如果写入副本节点失败，则主节点将问题报告给主节点，</span><br><span class="line">    // 然后主节点更新Meta中索引的InSyncAllocations配置并删除副本节点。</span><br><span class="line">    // 也就是说 之后，它将不再处理读取请求。 </span><br><span class="line">    // 在Meta更新到达每个节点之前，用户仍然可以在此副本节点上读取数据，</span><br><span class="line">    // 但是在Meta更新完成之后不会发生。 </span><br><span class="line">    // 这个解决方案并不严格。 考虑到ES是近乎实时的系统，因此在写入数据后，需要刷新才能使其可见。</span><br><span class="line">    // 因此，一般而言，可以在短时间内读取旧数据是可以接受的。</span><br><span class="line">    // 2、从代码中看一旦副本写入失败，就会触发shardStateAction.remoteShardFailed，从而引起shard下线</span><br><span class="line">    // 3、https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#basic-write-model</span><br><span class="line">    @Override</span><br><span class="line">    public void failShardIfNeeded(ShardRouting replica, long primaryTerm, String message, Exception exception,</span><br><span class="line">                                  ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        if (TransportActions.isShardNotAvailableException(exception) == false) &#123;</span><br><span class="line">            logger.warn(new ParameterizedMessage(&quot;[&#123;&#125;] &#123;&#125;&quot;, replica.shardId(), message), exception);</span><br><span class="line">        &#125;</span><br><span class="line">        shardStateAction.remoteShardFailed(</span><br><span class="line">            replica.shardId(), replica.allocationId().getId(), primaryTerm, true, message, exception, listener);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void markShardCopyAsStaleIfNeeded(ShardId shardId, String allocationId, long primaryTerm, ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        shardStateAction.remoteShardFailed(shardId, allocationId, primaryTerm, true, &quot;mark copy as stale&quot;, null, listener);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * A proxy for &lt;b&gt;write&lt;/b&gt; operations that need to be performed on the</span><br><span class="line"> * replicas, where a failure to execute the operation should fail</span><br><span class="line"> * the replica shard and/or mark the replica as stale.</span><br><span class="line"> *</span><br><span class="line"> * This extends &#123;@code TransportReplicationAction.ReplicasProxy&#125; to do the</span><br><span class="line"> * failing and stale-ing.</span><br><span class="line"> */</span><br><span class="line">class WriteActionReplicasProxy extends ReplicasProxy &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void failShardIfNeeded(ShardRouting replica, long primaryTerm, String message, Exception exception,</span><br><span class="line">                                  ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        if (TransportActions.isShardNotAvailableException(exception) == false) &#123;</span><br><span class="line">            logger.warn(new ParameterizedMessage(&quot;[&#123;&#125;] &#123;&#125;&quot;, replica.shardId(), message), exception);</span><br><span class="line">        &#125;</span><br><span class="line">        shardStateAction.remoteShardFailed(</span><br><span class="line">            replica.shardId(), replica.allocationId().getId(), primaryTerm, true, message, exception, listener);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void markShardCopyAsStaleIfNeeded(ShardId shardId, String allocationId, long primaryTerm, ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        shardStateAction.remoteShardFailed(shardId, allocationId, primaryTerm, true, &quot;mark copy as stale&quot;, null, listener);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ShardStateAction::remoteShardFailed</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Send a shard failed request to the master node to update the cluster state with the failure of a shard on another node. This means</span><br><span class="line">     * that the shard should be failed because a write made it into the primary but was not replicated to this shard copy. If the shard</span><br><span class="line">     * does not exist anymore but still has an entry in the in-sync set, remove its allocation id from the in-sync set.</span><br><span class="line">     *</span><br><span class="line">     * @param shardId            shard id of the shard to fail</span><br><span class="line">     * @param allocationId       allocation id of the shard to fail</span><br><span class="line">     * @param primaryTerm        the primary term associated with the primary shard that is failing the shard. Must be strictly positive.</span><br><span class="line">     * @param markAsStale        whether or not to mark a failing shard as stale (eg. removing from in-sync set) when failing the shard.</span><br><span class="line">     * @param message            the reason for the failure</span><br><span class="line">     * @param failure            the underlying cause of the failure</span><br><span class="line">     * @param listener           callback upon completion of the request</span><br><span class="line">     */</span><br><span class="line">    public void remoteShardFailed(final ShardId shardId, String allocationId, long primaryTerm, boolean markAsStale, final String message,</span><br><span class="line">                                  @Nullable final Exception failure, ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        assert primaryTerm &gt; 0L : &quot;primary term should be strictly positive&quot;;</span><br><span class="line">        remoteFailedShardsDeduplicator.executeOnce(</span><br><span class="line">            new FailedShardEntry(shardId, allocationId, primaryTerm, message, failure, markAsStale), listener,</span><br><span class="line">            (req, reqListener) -&gt; sendShardAction(SHARD_FAILED_ACTION_NAME, clusterService.state(), req, reqListener));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1>总结</h1><h2 id="Elasticsearch写入是等待所有副本都写入完成了才返回还是只要主副本写入了就返回？">Elasticsearch写入是等待所有副本都写入完成了才返回还是只要主副本写入了就返回？</h2><p>Elasticsearch写入是等待所有副本(in-sync set中的)都写入完成（完成不一定是成功，也有可能是失败）了才返回</p><h2 id="副本写入成功的标准是什么？">副本写入成功的标准是什么？</h2><p>副本写入成功的标志是Translog写入完成；</p><h2 id="wait-for-active-shard参数的作用是啥？">wait_for_active_shard参数的作用是啥？</h2><p>既然<code>Elasticsearch写入是等待所有副本都写入完成了才返回</code>,那么wait_for_active_shards参数的作用是什么？</p><p>其实，wait_for_active_shards参数（该值默认为1）作用：<br>是在<a href="https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java" target="_blank" rel="noopener">ReplicationOperation</a>中<a href="https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java#L305" target="_blank" rel="noopener">checkActiveShardCount()</a>起作用的。</p><p><strong>wait_for_active_shards的作用是在写入数据之前检查正常的副本数。</strong></p><p>例如，假设我们有一个由三个节点A，B和C组成的集群，并创建了一个索引，其副本数设置为3（产生4个分片副本，副本数比节点数多）。如果我们进行写入操作，则默认情况下，该操作将仅确保每个分片的主副本可用，然后再继续操作。这意味着，如果A托管了主分片副本，即使B和C崩溃了，索引操作仍将仅对数据的一个副本进行。如果在请求上将wait_for_active_shards设置为3（并且3个节点都已启动），则索引操作将需要3个活动的分片副本，然后才能继续进行，因为集群中有3个活动的节点，每个节点保持分片的副本。但是，如果将wait_for_active_shards设置为全部（或设置为4，则相同），则索引操作将不会继续进行，因为我们在索引中没有每个活动的分片的所有4个副本。除非在群集中调出新节点来托管分片的第四副本，否则该操作将超时。</p><p>重要的是要注意，此设置大大减少了写操作未写入所需数量的分片副本的机会，但并不能完全消除这种可能性，因为此检查发生在写操作开始之前。 一旦执行写操作，仍然有可能在任何数量的分片副本上失败，但在主副本上仍然成功。 写入操作响应的_shards部分显示复制成功/失败的分片副本数。</p><h2 id="Elasticsearch为什么bulk写入会比单条写入更快">Elasticsearch为什么bulk写入会比单条写入更快?</h2><ul><li>减少了client与es之间交互的次数</li><li>es bulk写入会将写入的内容,按照要写入shard分组,同一个shard,多条合并为一次写入</li></ul><h2 id="都说Elasticsearch数据复制使用了PacificA，那到底是在哪里用的？">都说Elasticsearch数据复制使用了PacificA，那到底是在哪里用的？</h2><ul><li><a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java#L160" target="_blank" rel="noopener">master节点维护了一份in-sync set副本数据，副本一旦写入失败，会上报错误给master节点，从in-sync set将异常shard移除</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#_failure_handling" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#_failure_handling</a></li></ul>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>源码</tag>
        <tag>Index</tag>
        <tag>Write</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 设计</title>
    <url>/rocketmq-design.html</url>
    <content><![CDATA[<blockquote><p>消息存储、通信机制、消息过滤、负载均衡、事务消息、消息查询<br>转载自RocketMQ官方文档</p></blockquote><a id="more"></a><h3 id="1-消息存储">1 消息存储</h3><p><img data-src="/images/rocketmq-design/rocketmq_design_1.png" alt></p><p>消息存储是RocketMQ中最为复杂和最为重要的一部分,本节将分别从RocketMQ的消息存储整体架构、PageCache与Mmap内存映射以及RocketMQ中两种不同的刷盘方式三方面来分别展开叙述。</p><h4 id="1-1-消息存储整体架构">1.1 消息存储整体架构</h4><p>消息存储架构图中主要有下面三个跟消息存储相关的文件构成。</p><p>(1) CommitLog:消息主体以及元数据的存储主体,存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ,文件名长度为20位,左边补零,剩余为起始偏移量,比如00000000000000000000代表了第一个文件,起始偏移量为0,文件大小为1G=1073741824;当第一个文件写满了,第二个文件为00000000001073741824,起始偏移量为1073741824,以此类推。消息主要是顺序写入日志文件,当文件满了,写入下一个文件;</p><p>(2) ConsumeQueue:消息消费队列,引入的目的主要是提高消息消费的性能,由于RocketMQ是基于主题topic的订阅模式,消息消费是针对主题进行的,如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中,<font color="DeepPink">ConsumeQueue(逻辑消费队列）作为消费消息的索引,保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset,消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件,故consumequeue文件夹的组织方式如下:topic/queue/file三层组织结构</font>,具体存储路径为:$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计,每一个条目共20个字节,分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode,单个文件由30W个条目组成,可以像数组一样随机访问每一个条目,每个ConsumeQueue文件大小约5.72M;</p><p>(3) IndexFile:<font color="DeepPink">IndexFile(索引文件）提供了一种可以通过key或时间区间来查询消息的方法。</font>Index文件的存储位置是:$HOME \store\index${fileName},文件名fileName是以创建时的时间戳命名的,固定的单个IndexFile文件大小约为400M,一个IndexFile可以保存 2000W个索引,IndexFile的底层存储设计为在文件系统中实现HashMap结构,故rocketmq的索引文件其底层实现为hash索引。</p><p>在上面的RocketMQ的消息存储整体架构图中可以看出,RocketMQ采用的是混合型的存储结构,<font color="DeepPink">即为Broker单个实例下所有的队列共用一个日志数据文件(即为CommitLog）来存储。RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构,Producer发送消息至Broker端,然后Broker端使用同步或者异步的方式对消息刷盘持久化,保存至CommitLog中。只要消息被刷盘持久化至磁盘文件CommitLog中,那么Producer发送的消息就不会丢失。</font>正因为如此,Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后,可以等下一次消息拉取,同时服务端也支持长轮询模式,如果一个消息拉取请求未拉取到消息,Broker允许等待30s的时间,只要这段时间内有新消息到达,将直接返回给消费端。这里,RocketMQ的具体做法是,使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue(逻辑消费队列）和IndexFile(索引文件）数据。</p><h4 id="1-2-页缓存与内存映射">1.2 页缓存与内存映射</h4><p>页缓存(PageCache)是OS对文件的缓存,用于加速对文件的读写。一般来说,程序对文件进行顺序读写的速度几乎接近于内存的读写速度,主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化,将一部分的内存用作PageCache。对于数据的写入,OS会先写入至Cache内,随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取,如果一次读取文件时出现未命中PageCache的情况,OS从物理磁盘上访问读取文件的同时,会顺序对其他相邻块的数据文件进行预读取。</p><p>在RocketMQ中,ConsumeQueue逻辑消费队列存储的数据较少,并且是顺序读取,在page cache机制的预读取作用下,Consume Queue文件的读性能几乎接近读内存,即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说,读取消息内容时候会产生较多的随机访问读取,严重影响性能。如果选择合适的系统IO调度算法,比如设置调度算法为“Deadline”(此时块存储采用SSD的话）,随机读的性能也会有所提升。</p><p>另外,RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中,利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中(这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销）,将对文件的操作转化为直接对内存地址进行操作,从而极大地提高了文件的读写效率(正因为需要使用内存映射机制,故RocketMQ的文件存储都使用定长结构来存储,方便一次将整个文件映射至内存）。</p><h4 id="1-3-消息刷盘">1.3 消息刷盘</h4><p><img data-src="/images/rocketmq-design/rocketmq_design_2.png" alt></p><p>(1) 同步刷盘:如上图所示,只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障,但是性能上会有较大影响,一般适用于金融业务应用该模式较多。</p><p>(2) 异步刷盘:能够充分利用OS的PageCache的优势,只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行,降低了读写延迟,提高了MQ的性能和吞吐量。</p><h3 id="2-通信机制">2 通信机制</h3><p>RocketMQ消息队列集群主要包括NameServer、Broker(Master/Slave)、Producer、Consumer4个角色,基本通讯流程如下:</p><p>(1) Broker启动后需要完成一次将自己注册至NameServer的操作;随后每隔30s时间定时向NameServer上报Topic路由信息。</p><p>(2) 消息生产者Producer作为客户端发送消息时候,需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取,同时Producer会默认每隔30s向NameServer拉取一次路由信息。</p><p>(3) 消息生产者Producer根据2）中获取的路由信息选择一个队列(MessageQueue）进行消息发送;Broker作为消息的接收者接收消息并落盘存储。</p><p>(4) 消息消费者Consumer根据2）中获取的路由信息,并再完成客户端的负载均衡后,选择其中的某一个或者某几个消息队列来拉取消息并进行消费。</p><p>从上面1）~3）中可以看出在消息生产者, Broker和NameServer之间都会发生通信(这里只说了MQ的部分通信）,因此如何设计一个良好的网络通信模块在MQ中至关重要,它将决定RocketMQ集群整体的消息传输能力与最终的性能。</p><p>rocketmq-remoting 模块是 RocketMQ消息队列中负责网络通信的模块,它几乎被其他所有需要网络通信的模块(诸如rocketmq-client、rocketmq-broker、rocketmq-namesrv）所依赖和引用。为了实现客户端与服务器之间高效的数据请求与接收,RocketMQ消息队列自定义了通信协议并在Netty的基础之上扩展了通信模块。</p><h4 id="2-1-Remoting通信类结构">2.1 Remoting通信类结构</h4><p><img data-src="/images/rocketmq-design/rocketmq_design_3.png" alt></p><h4 id="2-2-协议设计与编解码">2.2 协议设计与编解码</h4><p>在Client和Server之间完成一次消息发送时,需要对发送的消息进行一个协议约定,因此就有必要自定义RocketMQ的消息协议。同时,为了高效地在网络中传输消息和对收到的消息读取,就需要对消息进行编解码。在RocketMQ中,RemotingCommand这个类在消息传输过程中对所有数据内容的封装,不但包含了所有的数据结构,还包含了编码解码操作。</p><table><thead><tr><th>Header字段</th><th>类型</th><th>Request说明</th><th>Response说明</th></tr></thead><tbody><tr><td>code</td><td>int</td><td>请求操作码,应答方根据不同的请求码进行不同的业务处理</td><td>应答响应码。0表示成功,非0则表示各种错误</td></tr><tr><td>language</td><td>LanguageCode</td><td>请求方实现的语言</td><td>应答方实现的语言</td></tr><tr><td>version</td><td>int</td><td>请求方程序的版本</td><td>应答方程序的版本</td></tr><tr><td>opaque</td><td>int</td><td>相当于requestId,在同一个连接上的不同请求标识码,与响应消息中的相对应</td><td>应答不做修改直接返回</td></tr><tr><td>flag</td><td>int</td><td>区分是普通RPC还是onewayRPC得标志</td><td>区分是普通RPC还是onewayRPC得标志</td></tr><tr><td>remark</td><td>String</td><td>传输自定义文本信息</td><td>传输自定义文本信息</td></tr><tr><td>extFields</td><td>HashMap&lt;String, String&gt;</td><td>请求自定义扩展信息</td><td>响应自定义扩展信息</td></tr></tbody></table><p><img data-src="/images/rocketmq-design/rocketmq_design_4.png" alt></p><p>可见传输内容主要可以分为以下4部分:</p><p>(1) 消息长度:总长度,四个字节存储,占用一个int类型;</p><p>(2) 序列化类型&amp;消息头长度:同样占用一个int类型,第一个字节表示序列化类型,后面三个字节表示消息头长度;</p><p>(3) 消息头数据:经过序列化后的消息头数据;</p><p>(4) 消息主体数据:消息主体的二进制字节数据内容;</p><h4 id="2-3-消息的通信方式和流程">2.3 消息的通信方式和流程</h4><p>在RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway)<br>三种。其中“单向”通信模式相对简单,一般用在发送心跳包场景下,无需关注其Response。这里,主要介绍RocketMQ的异步通信流程。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_5.png" alt></p><h4 id="2-4-Reactor多线程设计">2.4 Reactor多线程设计</h4><p>RocketMQ的RPC通信采用Netty组件作为底层通信库,同样也遵循了Reactor多线程模型,同时又在这之上做了一些扩展和优化。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_6.png" alt></p><p>上面的框图中可以大致了解RocketMQ中NettyRemotingServer的Reactor 多线程模型。一个 Reactor 主线程(eventLoopGroupBoss,即为上面的1）负责监听 TCP网络连接请求,建立好连接,创建SocketChannel,并注册到selector上。RocketMQ的源码中会自动根据OS的类型选择NIO和Epoll,也可以通过参数配置）,然后监听真正的网络数据。拿到网络数据后,再丢给Worker线程池(eventLoopGroupSelector,即为上面的“N”,源码中默认设置为3）,在真正执行业务逻辑之前需要进行SSL验证、编解码、空闲检查、网络连接管理,这些工作交给defaultEventExecutorGroup(即为上面的“M1”,源码中默认设置为8）去做。而处理业务操作放在业务线程池中执行,根据 RomotingCommand 的业务请求码code去processorTable这个本地缓存变量中找到对应的 processor,然后封装成task任务后,提交给对应的业务processor处理线程池来执行(sendMessageExecutor,以发送消息为例,即为上面的 “M2”）。从入口到业务逻辑的几个步骤中线程池一直再增加,这跟每一步逻辑复杂性相关,越复杂,需要的并发通道越宽。</p><table><thead><tr><th>线程数</th><th>线程名</th><th>线程具体说明</th></tr></thead><tbody><tr><td>1</td><td>NettyBoss_%d</td><td>Reactor 主线程</td></tr><tr><td>N</td><td>NettyServerEPOLLSelector_%d_%d</td><td>Reactor 线程池</td></tr><tr><td>M1</td><td>NettyServerCodecThread_%d</td><td>Worker线程池</td></tr><tr><td>M2</td><td>RemotingExecutorThread_%d</td><td>业务processor处理线程池</td></tr></tbody></table><h3 id="3-消息过滤">3 消息过滤</h3><p>RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件,是在Consumer端订阅消息时再做消息过滤的。RocketMQ这么做是在于其Producer端写入消息和Consumer端订阅消息采用分离存储的机制来实现的,Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引,然后再从CommitLog里面读取真正的消息实体内容,所以说到底也是还绕不开其存储结构。其ConsumeQueue的存储结构如下,可以看到其中有8个字节存储的Message Tag的哈希值,基于Tag的消息过滤正式基于这个字段值的。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_7.png" alt></p><p>主要支持如下2种的过滤方式<br>(1) Tag过滤方式:Consumer端在订阅消息时除了指定Topic还可以指定TAG,如果一个消息有多个TAG,可以用||分隔。其中,Consumer端会将这个订阅请求构建成一个 SubscriptionData,发送一个Pull消息的请求给Broker端。Broker端从RocketMQ的文件存储层—Store读取数据之前,会用这些数据先构建一个MessageFilter,然后传给Store。Store从 ConsumeQueue读取到一条记录后,会用它记录的消息tag hash值去做过滤,由于在服务端只是根据hashcode进行判断,无法精确对tag原始字符串进行过滤,故在消息消费端拉取到消息后,还需要对消息的原始tag字符串进行比对,如果不同,则丢弃该消息,不进行消息消费。</p><p>(2) SQL92的过滤方式:这种方式的大致做法和上面的Tag过滤方式一样,只是在Store层的具体过滤过程不太一样,真正的 SQL expression 的构建和执行由rocketmq-filter模块负责的。每次过滤都去执行SQL表达式会影响效率,所以RocketMQ使用了BloomFilter避免了每次都去执行。SQL92的表达式上下文为消息的属性。</p><h3 id="4-负载均衡">4 负载均衡</h3><p>RocketMQ中的负载均衡都在Client端完成,具体来说的话,主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p><h4 id="4-1-Producer的负载均衡">4.1 Producer的负载均衡</h4><p>Producer端在发送消息的时候,会先根据Topic找到指定的TopicPublishInfo,在获取了TopicPublishInfo路由信息后,RocketMQ的客户端在默认方式下selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列(MessageQueue）进行发送消息。具体的容错策略均在MQFaultStrategy这个类中定义。这里有一个sendLatencyFaultEnable开关变量,如果开启,在随机递增取模的基础上,再过滤掉not available的Broker代理。所谓的&quot;latencyFaultTolerance&quot;,是指对之前失败的,按一定的时间做退避。例如,如果上次请求的latency超过550Lms,就退避3000Lms;超过1000L,就退避60000L;如果关闭,采用随机递增取模的方式选择一个队列(MessageQueue）来发送消息,latencyFaultTolerance机制是实现消息发送高可用的核心关键所在。</p><h4 id="4-2-Consumer的负载均衡">4.2 Consumer的负载均衡</h4><p>在RocketMQ中,Consumer端的两种消费模式(Push/Pull）都是基于拉模式来获取消息的,而在Push模式只是对pull模式的一种封装,其本质实现为消息拉取线程在从服务器拉取到一批消息后,然后提交到消息消费线程池后,又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息,则延迟一下又继续拉取。在两种基于拉模式的消费方式(Push/Pull）中,均需要Consumer端在知道从Broker端的哪一个消息队列—队列中去获取消息。因此,有必要在Consumer端来做负载均衡,即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。</p><p>1、Consumer端的心跳包发送</p><p>在Consumer启动后,它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包(其中包含了,消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到Consumer的心跳消息后,会将它维护在ConsumerManager的本地缓存变量—consumerTable,同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中,为之后做Consumer端的负载均衡提供可以依据的元数据信息。</p><p>2、Consumer端实现负载均衡的核心类—RebalanceImpl</p><p>在Consumer实例的启动流程中的启动MQClientInstance实例部分,会完成负载均衡服务线程—RebalanceService的启动(每隔20s执行一次）。通过查看源码可以发现,RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法,该方法是实现Consumer端负载均衡的核心。这里,rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程:</p><p>(1) 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中,获取该Topic主题下的消息消费队列集合(mqSet）;</p><p>(2) 根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送获取该消费组下消费者Id列表的RPC通信请求(Broker端基于前面Consumer端上报的心跳包数据而构建的consumerTable做出响应返回,业务请求码:GET_CONSUMER_LIST_BY_GROUP）;</p><p>(3) 先对Topic下的消息消费队列、消费者Id排序,然后用消息队列分配策略算法(默认为:消息队列的平均分配算法）,计算出待拉取的消息队列。这里的平均分配算法,类似于分页的算法,将所有MessageQueue排好序类似于记录,将所有消费端Consumer排好序类似页数,并求出每一页需要包含的平均size和每个页面记录的范围range,最后遍历整个range而计算出当前Consumer端应该分配到的记录(这里即为:MessageQueue）。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_8.png" alt></p><p>(4) 然后,调用updateProcessQueueTableInRebalance()方法,具体的做法是,先将分配到的消息队列集合(mqSet）与processQueueTable做一个过滤比对。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_9.png" alt></p><ul><li><p>上图中processQueueTable标注的红色部分,表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true,然后查看这些队列是否可以移除出processQueueTable缓存变量,这里具体执行removeUnnecessaryMessageQueue()方法,即每隔1s 查看是否可以获取当前消费处理队列的锁,拿到的话返回true。如果等待1s后,仍然拿不到当前消费处理队列的锁则返回false。如果返回true,则从processQueueTable缓存变量中移除对应的Entry;</p></li><li><p>上图中processQueueTable的绿色部分,表示与分配到的消息队列集合mqSet的交集。判断该ProcessQueue是否已经过期了,在Pull模式的不用管,如果是Push模式的,设置Dropped属性为true,并且调用removeUnnecessaryMessageQueue()方法,像上面一样尝试移除Entry;</p></li></ul><p>最后,为过滤后的消息队列集合(mqSet）中的每个MessageQueue创建一个ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中(其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset,随后填充至接下来要创建的pullRequest对象属性中）,并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中,最后执行dispatchPullRequest()方法,将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中,待该服务线程取出后向Broker端发起Pull消息的请求。其中,可以重点对比下,RebalancePushImpl和RebalancePullImpl两个实现类的dispatchPullRequest()方法不同,RebalancePullImpl类里面的该方法为空,这样子也就回答了上一篇中最后的那道思考题了。</p><p>消息消费队列在同一消费组不同消费者之间的负载均衡,其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费,一个消息消费者能同时消费多个消息队列。</p><h3 id="5-事务消息">5 事务消息</h3><p>Apache RocketMQ在4.3.0版中已经支持分布式事务消息,这里RocketMQ采用了2PC的思想来实现了提交事务消息,同时增加一个补偿逻辑来处理二阶段超时或者失败的消息,如下图所示。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_10.png" alt></p><h4 id="5-1-RocketMQ事务消息流程概要">5.1 RocketMQ事务消息流程概要</h4><p>上图说明了事务消息的大致方案,其中分为两个流程:正常事务消息的发送及提交、事务消息的补偿流程。</p><p>1.事务消息发送及提交:</p><p>(1) 发送消息(half消息）。</p><p>(2) 服务端响应消息写入结果。</p><p>(3) 根据发送结果执行本地事务(如果写入失败,此时half消息对业务不可见,本地逻辑不执行）。</p><p>(4) 根据本地事务状态执行Commit或者Rollback(Commit操作生成消息索引,消息对消费者可见）</p><p>2.补偿流程:</p><p>(1) 对没有Commit/Rollback的事务消息(pending状态的消息）,从服务端发起一次“回查”</p><p>(2) Producer收到回查消息,检查回查消息对应的本地事务的状态</p><p>(3) 根据本地事务状态,重新Commit或者Rollback</p><p>其中,补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。</p><h4 id="5-2-RocketMQ事务消息设计">5.2 RocketMQ事务消息设计</h4><p>1.事务消息在一阶段对用户不可见</p><p>在RocketMQ事务消息的主要流程中,一阶段的消息如何对用户不可见。其中,事务消息相对普通消息最大的特点就是一阶段发送的消息对用户是不可见的。那么,如何做到写入消息但是对用户不可见呢？RocketMQ事务消息的做法是:如果消息是half消息,将备份原消息的主题与消息消费队列,然后改变主题为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题,故消费端无法消费half类型的消息,然后RocketMQ会开启一个定时任务,从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费,根据生产者组获取一个服务提供者发送回查事务状态请求,根据事务状态来决定是提交或回滚消息。</p><p>在RocketMQ中,消息在服务端的存储结构如下,每条消息都会有对应的索引信息,Consumer通过ConsumeQueue这个二级索引来读取消息实体内容,其流程如下:</p><p><img data-src="/images/rocketmq-design/rocketmq_design_11.png" alt></p><p>RocketMQ的具体实现策略是:写入的如果事务消息,对消息的Topic和Queue等属性进行替换,同时将原来的Topic和Queue信息存储到消息的属性中,正因为消息主题被替换,故消息并不会转发到该原主题的消息消费队列,消费者无法感知消息的存在,不会消费。其实改变消息主题是RocketMQ的常用“套路”,回想一下延时消息的实现机制。</p><p>2.Commit和Rollback操作以及Op消息的引入</p><p>在完成一阶段写入一条对用户不可见的消息后,二阶段如果是Commit操作,则需要让消息对用户可见;如果是Rollback则需要撤销一阶段的消息。先说Rollback的情况。对于Rollback,本身一阶段的消息对用户是不可见的,其实不需要真正撤销消息(实际上RocketMQ也无法去真正的删除一条消息,因为是顺序写文件的）。但是区别于这条消息没有确定状态(Pending状态,事务悬而未决）,需要一个操作来标识这条消息的最终状态。RocketMQ事务消息方案中引入了Op消息的概念,用Op消息标识事务消息已经确定的状态(Commit或者Rollback）。如果一条事务消息没有对应的Op消息,说明这个事务的状态还无法确定(可能是二阶段失败了）。引入Op消息后,事务消息无论是Commit或者Rollback都会记录一个Op操作。Commit相对于Rollback只是在写入Op消息前创建Half消息的索引。</p><p>3.Op消息的存储和对应关系</p><p>RocketMQ将Op消息写入到全局一个特定的Topic中通过源码中的方法—TransactionalMessageUtil.buildOpTopic();这个Topic是一个内部的Topic(像Half消息的Topic一样）,不会被用户消费。Op消息的内容为对应的Half消息的存储的Offset,这样通过Op消息能索引到Half消息进行后续的回查操作。</p><p><img data-src="/images/rocketmq-design/rocketmq_design_12.png" alt></p><p>4.Half消息的索引构建</p><p>在执行二阶段Commit操作时,需要构建出Half消息的索引。一阶段的Half消息由于是写到一个特殊的Topic,所以二阶段构建索引时需要读取出Half消息,并将Topic和Queue替换成真正的目标的Topic和Queue,之后通过一次普通消息的写入操作来生成一条对用户可见的消息。所以RocketMQ事务消息二阶段其实是利用了一阶段存储的消息的内容,在二阶段时恢复出一条完整的普通消息,然后走一遍消息写入流程。</p><p>5.如何处理二阶段失败的消息？</p><p>如果在RocketMQ事务消息的二阶段过程中失败了,例如在做Commit操作时,出现网络问题导致Commit失败,那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制,称为“回查”。Broker端对未确定状态的消息发起回查,将消息发送到对应的Producer端(同一个Group的Producer）,由Producer根据消息来检查本地事务的状态,进而执行Commit或者Rollback。Broker端通过对比Half消息和Op消息进行事务消息的回查并且推进CheckPoint(记录那些事务消息的状态是确定的）。</p><p>值得注意的是,rocketmq并不会无休止的的信息事务状态回查,默认回查15次,如果15次回查还是无法得知事务状态,rocketmq默认回滚该消息。</p><h3 id="6-消息查询">6 消息查询</h3><p>RocketMQ支持按照下面两种维度(“按照Message Id查询消息”、“按照Message Key查询消息”）进行消息查询。</p><h4 id="6-1-按照MessageId查询消息">6.1 按照MessageId查询消息</h4><p>RocketMQ中的MessageId的长度总共有16字节,其中包含了消息存储主机地址(IP地址和端口）,消息Commit Log offset。“按照MessageId查询消息”在RocketMQ中具体做法是:Client端从MessageId中解析出Broker的地址(IP地址和端口）和Commit Log的偏移地址后封装成一个RPC请求后通过Remoting通信层发送(业务请求码:VIEW_MESSAGE_BY_ID）。Broker端走的是QueryMessageProcessor,读取消息的过程用其中的 commitLog offset 和 size 去 commitLog 中找到真正的记录并解析成一个完整的消息返回。</p><h4 id="6-2-按照Message-Key查询消息">6.2 按照Message Key查询消息</h4><p>“按照Message Key查询消息”,主要是基于RocketMQ的IndexFile索引文件来实现的。RocketMQ的索引文件逻辑结构,类似JDK中HashMap的实现。索引文件的具体结构如下:</p><p><img data-src="/images/rocketmq-design/rocketmq_design_13.png" alt></p><p>IndexFile索引文件为用户提供通过“按照Message Key查询消息”的消息索引查询服务,IndexFile文件的存储位置是:$HOME\store\index${fileName},文件名fileName是以创建时的时间戳命名的,文件大小是固定的,等于40+500W*4+2000W*20= 420000040个字节大小。如果消息的properties中设置了UNIQ_KEY这个属性,就用 topic + “#” + UNIQ_KEY的value作为 key 来做写入操作。如果消息设置了KEYS属性(多个KEY以空格分隔）,也会用 topic + “#” + KEY 来做索引。</p><p>其中的索引数据包含了Key Hash/CommitLog Offset/Timestamp/NextIndex offset 这四个字段,一共20 Byte。NextIndex offset 即前面读出来的 slotValue,如果有 hash冲突,就可以用这个字段将所有冲突的索引用链表的方式串起来了。Timestamp记录的是消息storeTimestamp之间的差,并不是一个绝对的时间。整个Index File的结构如图,40 Byte 的Header用于保存一些总的统计信息,4*500W的 Slot Table并不保存真正的索引数据,而是保存每个槽位对应的单向链表的头。20*2000W 是真正的索引数据,即一个 Index File 可以保存 2000W个索引。</p><p>“按照Message Key查询消息”的方式,RocketMQ的具体做法是,主要通过Broker端的QueryMessageProcessor业务处理器来查询,读取消息的过程就是用topic和key找到IndexFile索引文件中的一条记录,根据其中的commitLog offset从CommitLog文件中读取消息的实体内容。</p><p>本文整理自:<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/design.md" target="_blank" rel="noopener">https://github.com/apache/rocketmq/blob/master/docs/cn/design.md</a></p>]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>后端存储实战课 笔记</title>
    <url>/back-end-storage-practical-lesson.html</url>
    <content><![CDATA[<p>后端存储实战课 笔记<br>作者： 李玥</p><a id="more"></a><p>最近在读《后端存储实战课》，其中有几条对于我个人而言，感触很深，特此摘录一下：</p><ul><li><p><font color="DeepPink"><strong>解决海量数据导致存储系统慢的问题，思想非常简单，就是一个“拆”字，把一大坨数据拆分成 N 个小坨，学名叫“分片（Shard）”。</strong></font>拆开之后，每个分片里的数据就没那么多了，然后让查找尽量落在某一个分片上，这样来提升查找性能。所有分布式存储系统解决海量数据查找问题都是遵循的这个思想。</p></li><li><p>同样一份商品数据，如果我们是按照关键字搜索，放在 ES 里就比放在 MySQL 快了几个数量级。原因是，数据组织方式、物理存储结构和查询方式，对查询性能的影响是巨大的，而且海量数据还会指数级地放大这个性能差距。</p><p>所以，在大厂中，<font color="DeepPink"><strong>对于海量数据的处理原则，都是根据业务对数据查询的需求，反过来确定选择什么数据库、如何组织数据结构、如何分片数据，这样才能达到最优的查询性能。同样一份订单数据，除了在订单库保存一份用于在线交易以外，还会在各种数据库中，以各种各样的组织方式存储，用于满足不同业务系统的查询需求。像 BAT 这种大厂，它的核心业务数据，存个几十上百份是非常正常的。</strong></font></p></li></ul>]]></content>
      <categories>
        <category>Storage</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Storage</tag>
      </tags>
  </entry>
  <entry>
    <title>对于Java系高级特性的个人看法</title>
    <url>/personal-views-on-the-advanced-features-of-java.html</url>
    <content><![CDATA[<blockquote><p>CompletableFuture、Lambda、Reactive，欢迎留言讨论。</p></blockquote><a id="more"></a><p>说一下我个人的观点吧：</p><h1>Lambda</h1><h2 id="优点">优点</h2><ul><li>代码简洁</li></ul><h2 id="缺点">缺点</h2><ul><li>不方便调试.</li><li>会拉升代码维护的成本。对于写代码/维护代码的人，有一定的要求（需要学习语法糖）。</li><li>对于非 CPU密集型的程序，性能方面没有什么提升。</li></ul><p>拓展：<a href="https://jiankunking.com/java-lambda.html">Java Lambda表达式 实现原理分析</a></p><h1>CompletableFuture</h1><p>CompletableFuture这种回调底层还是Fork/Join框架，Fork/Join对于io这种操作还是会阻塞线程，而且CompletableFuture默认线程数是与CPU核数一样的。在现在容器化的场景下，CPU核数都不会很多（一般都是个位数），那么使用CompletableFuture是执行io操作是不是会更早的无响应？因为个位数的线程很快就都被阻塞了。</p><blockquote><p>这里说一下我的理解：</p><p>CompletableFuture还不能等完全同于ForkJoin。<br>可以简单的理解为<br>CompletableFuture.then() 等于 Fork<br>CompletableFuture.get() 等于 Join</p><p>但不是所有场景下，CompletableFuture都需要用get()结束的。也就是说，有时候是不需要调用阻塞的get()方法的。</p><p>另外，虽然CompletableFuture 默认使用 ForkJoinPool，但你完全可以给它提供一个自定义的执行器。</p><p>– <cite>李玥</cite></p></blockquote><h1>Spring Reactive</h1><p>Spring Reactive基于Netty，用更少的线程可以满足更多的并发请求，可以减少微服务部署的实例，但对于使用者来说Reactor不是很友好，而且排查问题麻烦。</p><p>拓展：<a href="https://jiankunking.com/spring-webflux-vs-spring-mvc.html">Spring WebFlux vs Spring MVC</a></p><h1>总结</h1><p>目前来看CompletableFuture、Lambda、Reactive，对于目前Web开发而言可以说是意义不大，尤其是CompletableFuture、Spring Reactive，终将被<a href="http://openjdk.java.net/projects/loom/" target="_blank" rel="noopener">Loom项目</a>代替或者将基于<a href="http://openjdk.java.net/projects/loom/" target="_blank" rel="noopener">Loom</a>再次开发。</p><p><code>Java目前的问题在于语言层面没有协程这种东西，所以io操作仍然会阻塞线程（除非基于Netty开发）。</code></p><p>Java在云原生的路上，内存归还OS问题，已在G1、ZGC中解决了，剩下的就是协程跟<a href="https://jiankunking.com/spring-boot-clound-native-by-graalvm.html">AOT</a>了。</p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>Lambda</tag>
        <tag>CompletableFuture</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch Breaker CircuitBreakingException Parent Data Too Large Real Usage</title>
    <url>/elasticsearch-breaker-circuitbreakingexception-parent-data-too-large-transport-request-real-usage.html</url>
    <content><![CDATA[<blockquote><p>indices.breaker.total.use_real_memory 引发的问题</p></blockquote><a id="more"></a><p>最近业务日志es（7.6.2）集群，写入时经常返回以下异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-11-24T02:59:05.557085524Z &#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-11-24T02:59:05,556Z&quot;, &quot;level&quot;: &quot;DEBUG&quot;, &quot;component&quot;: &quot;o.e.a.a.c.n.i.TransportNodesInfoAction&quot;, &quot;cluster.name&quot;: &quot;business-log&quot;, &quot;node.name&quot;: &quot;es-b-193&quot;, &quot;message&quot;: &quot;failed to execute on node [EKFLTB1jTrSbTHi80t8lDw]&quot;, &quot;cluster.uuid&quot;: &quot;ArYy-qmCTbCQTDUI8ogsBg&quot;, &quot;node.id&quot;: &quot;w8mHCBNORpa8P73ML3c1zg&quot; ,</span><br><span class="line">2020-11-24T02:59:05.557111874Z &quot;stacktrace&quot;: [&quot;org.elasticsearch.transport.RemoteTransportException: [es-b-194][127.0.0.1:9300][cluster:monitor/nodes/info[n]]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557116050Z &quot;Caused by: org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [&lt;transport_request&gt;] would be [27684654388/25.7gb], which is larger than the limit of [26521423052/24.6gb], real usage: [27684652880/25.7gb], new bytes reserved: [1508/1.4kb], usages [request=0/0b, fielddata=19858/19.3kb, in_flight_requests=2805740/2.6mb, accounting=86606929/82.5mb]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557120478Z &quot;at org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService.checkParentLimit(HierarchyCircuitBreakerService.java:343) ~[elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557123616Z &quot;at org.elasticsearch.common.breaker.ChildMemoryCircuitBreaker.addEstimateBytesAndMaybeBreak(ChildMemoryCircuitBreaker.java:128) ~[elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557126392Z &quot;at org.elasticsearch.transport.InboundHandler.handleRequest(InboundHandler.java:171) [elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557129043Z &quot;at org.elasticsearch.transport.InboundHandler.messageReceived(InboundHandler.java:119) [elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557131767Z &quot;at org.elasticsearch.transport.InboundHandler.inboundMessage(InboundHandler.java:103) [elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557134387Z &quot;at org.elasticsearch.transport.TcpTransport.inboundMessage(TcpTransport.java:667) [elasticsearch-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557137050Z &quot;at org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.channelRead(Netty4MessageChannelHandler.java:62) [transport-netty4-client-7.6.2.jar:7.6.2]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557139775Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557143378Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557146200Z &quot;at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557157569Z &quot;at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:326) [netty-codec-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557160772Z &quot;at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:300) [netty-codec-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557163614Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557166366Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557169060Z &quot;at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557171799Z &quot;at io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:241) [netty-handler-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557174627Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557177412Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557180299Z &quot;at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557182991Z &quot;at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557185677Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557188907Z &quot;at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557191750Z &quot;at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557194464Z &quot;at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557197166Z &quot;at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557199910Z &quot;at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:600) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557202599Z &quot;at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:554) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557205278Z &quot;at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514) [netty-transport-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557207911Z &quot;at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050) [netty-common-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557214146Z &quot;at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.43.Final.jar:4.1.43.Final]&quot;,</span><br><span class="line">2020-11-24T02:59:05.557216961Z &quot;at java.lang.Thread.run(Thread.java:830) [?:?]&quot;] &#125;</span><br></pre></td></tr></table></figure><p>出现异常时，jvm.options配置如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## GC configuration</span><br><span class="line">#-XX:+UseConcMarkSweepGC</span><br><span class="line">#-XX:CMSInitiatingOccupancyFraction=75</span><br><span class="line">#-XX:+UseCMSInitiatingOccupancyOnly</span><br><span class="line"></span><br><span class="line">## G1GC Configuration</span><br><span class="line"># NOTE: G1GC is only supported on JDK version 10 or later.</span><br><span class="line"># To use G1GC uncomment the lines below.</span><br><span class="line">#-XX:-UseConcMarkSweepGC</span><br><span class="line">#-XX:-UseCMSInitiatingOccupancyOnly</span><br><span class="line">-XX:+UseG1GC</span><br><span class="line">-XX:InitiatingHeapOccupancyPercent=75</span><br></pre></td></tr></table></figure><p>经过一顿Google之后，发现该问题是由于：<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/breaking-changes-7.0.html#_parent_circuit_breaker_changes" target="_blank" rel="noopener">es 7.x之后引入了indices.breaker.total.use_real_memory造成的</a><br>，从文档来看indices.breaker.total.use_real_memory控制的是jvm实际使用的内存。</p><p>那么jvm内存用到多少的时候，会触发该熔断呢？</p><p>从集群系统配置中可以看到indices.breaker.total.limit默认是95。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl --location --request GET &apos;http://127.0.0.1:9200/_cluster/settings?include_defaults&amp;flat_settings&amp;local&amp;filter_path=defaults.indices*&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">	&quot;defaults&quot;: &#123;</span><br><span class="line">		&quot;indices.analysis.hunspell.dictionary.ignore_case&quot;: &quot;false&quot;,</span><br><span class="line">		&quot;indices.analysis.hunspell.dictionary.lazy&quot;: &quot;false&quot;,</span><br><span class="line">		&quot;indices.breaker.accounting.limit&quot;: &quot;100%&quot;,</span><br><span class="line">		&quot;indices.breaker.accounting.overhead&quot;: &quot;1.0&quot;,</span><br><span class="line">		&quot;indices.breaker.fielddata.limit&quot;: &quot;40%&quot;,</span><br><span class="line">		&quot;indices.breaker.fielddata.overhead&quot;: &quot;1.03&quot;,</span><br><span class="line">		&quot;indices.breaker.fielddata.type&quot;: &quot;memory&quot;,</span><br><span class="line">		&quot;indices.breaker.request.limit&quot;: &quot;60%&quot;,</span><br><span class="line">		&quot;indices.breaker.request.overhead&quot;: &quot;1.0&quot;,</span><br><span class="line">		&quot;indices.breaker.request.type&quot;: &quot;memory&quot;,</span><br><span class="line">		&quot;indices.breaker.total.limit&quot;: &quot;95%&quot;,</span><br><span class="line">		&quot;indices.breaker.total.use_real_memory&quot;: &quot;true&quot;,</span><br><span class="line">		&quot;indices.breaker.type&quot;: &quot;hierarchy&quot;,</span><br><span class="line">		&quot;indices.cache.cleanup_interval&quot;: &quot;1m&quot;,</span><br><span class="line">		&quot;indices.fielddata.cache.size&quot;: &quot;-1b&quot;,</span><br><span class="line">		&quot;indices.id_field_data.enabled&quot;: &quot;true&quot;,</span><br><span class="line">		&quot;indices.lifecycle.history_index_enabled&quot;: &quot;true&quot;,</span><br><span class="line">		&quot;indices.lifecycle.poll_interval&quot;: &quot;10m&quot;,</span><br><span class="line">		&quot;indices.mapping.dynamic_timeout&quot;: &quot;30s&quot;,</span><br><span class="line">		&quot;indices.memory.index_buffer_size&quot;: &quot;10%&quot;,</span><br><span class="line">		&quot;indices.memory.interval&quot;: &quot;5s&quot;,</span><br><span class="line">		&quot;indices.memory.max_index_buffer_size&quot;: &quot;-1&quot;,</span><br><span class="line">		&quot;indices.memory.min_index_buffer_size&quot;: &quot;48mb&quot;,</span><br><span class="line">		&quot;indices.memory.shard_inactive_time&quot;: &quot;5m&quot;,</span><br><span class="line">		&quot;indices.queries.cache.all_segments&quot;: &quot;false&quot;,</span><br><span class="line">		&quot;indices.queries.cache.count&quot;: &quot;10000&quot;,</span><br><span class="line">		&quot;indices.queries.cache.size&quot;: &quot;10%&quot;,</span><br><span class="line">		&quot;indices.query.bool.max_clause_count&quot;: &quot;1024&quot;,</span><br><span class="line">		&quot;indices.query.query_string.allowLeadingWildcard&quot;: &quot;true&quot;,</span><br><span class="line">		&quot;indices.query.query_string.analyze_wildcard&quot;: &quot;false&quot;,</span><br><span class="line">		&quot;indices.recovery.internal_action_long_timeout&quot;: &quot;1800000ms&quot;,</span><br><span class="line">		&quot;indices.recovery.internal_action_timeout&quot;: &quot;15m&quot;,</span><br><span class="line">		&quot;indices.recovery.max_bytes_per_sec&quot;: &quot;40mb&quot;,</span><br><span class="line">		&quot;indices.recovery.max_concurrent_file_chunks&quot;: &quot;2&quot;,</span><br><span class="line">		&quot;indices.recovery.recovery_activity_timeout&quot;: &quot;1800000ms&quot;,</span><br><span class="line">		&quot;indices.recovery.retry_delay_network&quot;: &quot;5s&quot;,</span><br><span class="line">		&quot;indices.recovery.retry_delay_state_sync&quot;: &quot;500ms&quot;,</span><br><span class="line">		&quot;indices.requests.cache.expire&quot;: &quot;0ms&quot;,</span><br><span class="line">		&quot;indices.requests.cache.size&quot;: &quot;1%&quot;,</span><br><span class="line">		&quot;indices.store.delete.shard.timeout&quot;: &quot;30s&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于为什么在默认开启indices.breaker.total.use_real_memory之后，如果GC算法是G1的话，会频繁触发熔断呢？</p><p>先解释一下G1的几个参数：</p><ul><li>InitiatingHeapOccupancyPercent：表示G1 GC并行循环初始设置的堆大小值，这个值决定了一个并行循环是不是要开始执行。它的逻辑是在一次GC完成后，比较老年代占用的空间和整个Java堆之间的比例。如果大于这个值，则预约下一次GC开始一个并行循环回收垃圾，从初始标记阶段开始。这个值越小，GC越频繁，反之，值越大，可以让应用程序执行时间更长。不过在内存消耗很快的情况下，我认为早运行并行循环比晚运行要好，看病要趁早。</li><li>G1NewSizePercent：年轻代初始化值，默认是 5%</li><li>G1MaxNewSizePercent：年轻代占用最大值，最大值默认是整个Java堆大小的60%</li></ul><p>关于该问题具体分析可以看：<a href="https://github.com/elastic/elasticsearch/pull/46169" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch/pull/46169</a></p><p>简单来说就是：es jvm.options之前的默认配置会导致老年代+年轻代的内存占用超过95%（理论上内存阈值会达到60+75=135），从而导致频繁的熔断。</p><p>修复该问题最有效的方式是根据不同版本JDK调整GC算法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># GC configuration</span><br><span class="line">8-13:-XX:+UseConcMarkSweepGC</span><br><span class="line">8-13:-XX:CMSInitiatingOccupancyFraction=75</span><br><span class="line">8-13:-XX:+UseCMSInitiatingOccupancyOnly</span><br><span class="line"></span><br><span class="line">## G1GC Configuration</span><br><span class="line"># NOTE: G1 GC is only supported on JDK version 10 or later</span><br><span class="line"># to use G1GC, uncomment the next two lines and update the version on the</span><br><span class="line"># following three lines to your version of the JDK</span><br><span class="line"># 10-13:-XX:-UseConcMarkSweepGC</span><br><span class="line"># 10-13:-XX:-UseCMSInitiatingOccupancyOnly</span><br><span class="line">14-:-XX:+UseG1GC</span><br><span class="line">14-:-XX:G1ReservePercent=25</span><br><span class="line">14-:-XX:InitiatingHeapOccupancyPercent=30</span><br></pre></td></tr></table></figure><p>这也是最新版es jvm.options中的默认配置。</p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Lucene 评分简介</title>
    <url>/apache-lucene-scoring-introduction.html</url>
    <content><![CDATA[<p>我也是不很懂，算是给自己扫盲吧。<br>😂 😂 😂 😂 😂 😂 😂 😂 😂 😂 😂 😂</p><a id="more"></a><p>当谈到查询及其相关性，我们不能忽略得分以及它从哪里来。但得分是什么？得分是描述文档与查询相关度的一个参数。本节将讨论Apache Lucene的默认评分机制：TF/IDF算法，看看它如何影响返回的文档。</p><blockquote><p>TF/IDF算法不是Elasticsearch公开的唯一可用的算法。</p></blockquote><h1>当文档被匹配时</h1><p>Lucene返回文档时，意味着文档与我们发送的查询匹配，并且对该文档已给出一个分数。得分越高，从搜索引擎的角度来看文档越相关。然而，两个不同的查询将对同一文档计算出不同的分数。正因为如此，在查询之间比较分数通常没什么意义。我们回到评分这个话题。计算文档的评分属性时，考虑以下因素:</p><ul><li>文档加权：对文档建立索引时，对文档的加权值。</li><li>字段加权：查询和索引时，对字段的加权值。</li><li>协调：基于文档词条数的协调因子。对包含更多查询词条的文档，它提供更大的值。</li><li>逆文档频率：基于词条的因子，它告诉评分公式，给定词条出现的频率有多低。逆文档频率越高，词条越罕见。</li><li>长度规范：基于字段的规范化因子，它基于给定字段包含的词条数目。字段越长，该因子给的加权值越小。这基本上意味着更短的文档更受分数的青睐。</li><li>词频：基于词条的因子，描述给定词条在文档中出现的次数，词频越高，文档的得分越高。</li><li>查询规范：基于查询的规范化因子，由每个查询词条比重的平方之和计算而成。查询规范用于查询之间的得分比较，但这并不一定很容易，有时甚至做不到。</li></ul><h1>默认评分公式</h1><p>TF/IDF算法的实用计算公式如下：<br><img data-src="/images/apache-lucene-scoring-introduction/td-idf-score.png" alt></p><p>为了调整查询相关性，你不需要记住这个等式的细节，但至少要知道它是如何工作的。我们可以看到，文档的评分因子是查询q和文档d的一个函数。还有两个不直接依赖于查询词条的因子，coord和queryNorm。公式中这两个元素跟查询中的每个词计算而得的总和相乘。另一方面，该总和由给定词的词频、逆文档频率、词条加权和规范相乘而来，其中的规范就是我们前面讨论过的长度规范。</p><blockquote><p>注意前面的公式是实用性的，你可以在Lucene Javadocs中查看更多概念公式的信息，网址是：<br><a href="http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html" target="_blank" rel="noopener">http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html</a></p></blockquote><p>上述规则的好处是，你不需要记住全部内容。应该知道的是影响文档评分的因素。下面是一些派生自上述等式的规则：</p><ul><li>匹配的词条越罕见，文档的得分越高；</li><li>文档的字段越小，文档的得分越高；</li><li>字段的加权越高，文档的得分越高；</li><li>我们可以看到，文档匹配的查询词条数目越高、字段越少（意味着索引的词条越少），Lucene给文档的分数越高。同时，罕见词条比常见词条更受评分的青睐。</li></ul><h1>相关性的意义</h1><p>在大多数情况下，我们希望得到最匹配的文档，但最相关的不一定是最匹配的。一些用例定义了非常严格的规则，规定了某些文档应该在结果列表中排位靠前。例如，文档除了被TF/IDF相似度模型完美匹配外，有客户付钱让他们的文档出现在结果中更靠前的位置。基于客户计划，我们想给这样的文档更大的重要性，把付费最高的用户的文档放到搜索结果的最顶部。当然，这就不属于TF/IDF相关性了。</p><p>在进行搜索相关性方面的工作时，你应该永远记住，这不是一次性的过程。随着时间的推移，你的数据将改变，查询也需要相应调整。在大多数情况下，优化查询相关性是持续性的工作，要根据业务规则、需求以及用户行为方式等调整。有一点非常重要：记住这不是设置之后就可以抛诸脑后的一次性过程。</p><h1>补充</h1><p>从Elasticsearch 5之后, 缺省的打分机制改成了Okapi BM25, 它也是基于TF/IDF进化来的。</p><h2 id="TF-IDF与BM25的相同点">TF/IDF与BM25的相同点</h2><p>TF/IDF和BM25同样使用<code>逆向文档频率</code>来区分普通词（不重要）和非普通词（重要），同样认为：</p><ul><li><font color="DeepPink"><strong>文档里的某个词出现次数越频繁，文档与这个词就越相关，得分越高。</strong></font></li><li><font color="DeepPink"><strong>某个词在集合所有文档里出现的频率是多少？频次越高，权重越低，得分越低。某个词在集合中所有文档中越罕见，得分越高。</strong></font></li></ul><h2 id="TF-IDF与BM25的不同点">TF/IDF与BM25的不同点</h2><p>BM25在传统TF/IDF的基础上增加了几个可调节的参数，使得它在应用上更佳灵活和强大，具有较高的实用性。</p><ul><li>传统的TF值理论上是可以无限大的。而BM25与之不同，它在TF计算方法中增加了一个常量k，用来限制TF值的增长极限。</li><li>BM25还引入了平均文档长度的概念，单个文档长度对相关性的影响力与它和平均长度的比值有关系。</li></ul><blockquote><p>本文整理自：《Elasticsearch服务器开发（第2版）》 ，补充部分整理自网络。</p></blockquote>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ElasticSearch</tag>
        <tag>Lucene</tag>
        <tag>Score</tag>
      </tags>
  </entry>
  <entry>
    <title>集成容器云</title>
    <url>/integrated-container-cloud.html</url>
    <content><![CDATA[<blockquote><p>赋予<a href="https://jiankunking.com/console-architecture.html">控制台</a>基于Kubernetes的一些能力</p></blockquote><a id="more"></a><h1>功能分析</h1><p>图中虚线框是直接对接Compass的api，其余的都是对接的Kubernetes，但兼容了Compass。</p><p><img data-src="/images/integrated-container-cloud/%E9%9B%86%E6%88%90%E5%AE%B9%E5%99%A8%E4%BA%91.png" alt></p><h1>集群规模</h1><p>Kubernetes 集群数 10+，单集群机器30+。</p>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>Design</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>To Be a Better Man</title>
    <url>/to-be-a-better-man.html</url>
    <content><![CDATA[<p>昨天跟磊哥聊天的时候，有几个很深的感触，记录一下：</p><p>1、<code>Open一点，主动一点，不要那么在意别人的感受（因为很多时候，你所想的别人的感受与别人真实的感受是不一样的），直接、简单的表达自己。表达出自己的观点。</code><br>2、要多经历一些事，才能体会的更多。<br>3、要提高Level，通过不同的视角，看不到不一样的东西。</p>]]></content>
      <tags>
        <tag>原创</tag>
        <tag>Life-Experience</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 集群内应该设置多少个分片(shard)？</title>
    <url>/how-many-shards-should-i-have-in-elasticsearch-cluster.html</url>
    <content><![CDATA[<p>我应该设置多少个分片？</p><p>我应该设置多大的分片？</p><a id="more"></a><p>Elasticsearch 是一个功能十分丰富的平台，支持各种用例，能够在数据整理和复制战略方面提供很大的灵活性。然而这一灵活性有时也会带来困扰，让您在前期难以确定如何最好地将数据整理为索引和分片，如果您刚上手使用 Elastic Stack，这一点可能更明显。如果未能做出最佳选择，尽管这在开始的时候可能不会造成问题，但随着数据量越来越大，便有可能会引发性能问题。集群中的数据越多，要纠正这一问题就越难，这是因为有时必须对大量数据进行重新索引。</p><p>据我们了解，当用户遇到性能问题时，原因通常都可回溯至数据的索引方式以及集群中的分片数量。对于涉及多租户和/或用到时序型索引的用例，这一点尤为突出。与用户讨论这一问题时，无论是在活动或聚会中面对面讨论，还是在论坛上讨论，<font color="DeepPink"><strong>我们遇到的一些最常见问题就是“我应该设置多少个分片？”以及“我应该设置多大的分片？”。</strong></font></p><p>这篇博文旨在帮您集中解答这些问题，并为涉及时序型索引（例如日志或安全分析）的用例提供实用指南。</p><h1>什么是分片？</h1><p>开始之前，我们需要明确一下基本知识以及在后面部分会用到的术语。</p><p>Elasticsearch 中的数据会整理为<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/_add_an_index.html" target="_blank" rel="noopener">索引</a>。每个索引又由一个或多个分片组成。 每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询。</p><p>数据写到分片上之后，会定期发布到磁盘上不可更改的新 Lucene 段中，此时，数据便可用于查询了。这称为刷新。相关原理的详细介绍，请参见 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/inside-a-shard.html" target="_blank" rel="noopener">Elasticsearch：权威指南</a>。</p><p>随着段数越来越多，这些段会定期合并为更大的段。这一过程称为<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/index-modules-merge.html" target="_blank" rel="noopener">合并</a>。由于所有段都是不可更改的，这意味着在索引期间所用磁盘空间通常会上下浮动，这是因为只有合并后的新段创建完毕之后，它们所替换的那些段才能删掉。合并是一项极其耗费资源的任务，尤其耗费磁盘 I/O。</p><p>分片是 Elasticsearch 在集群内分发数据的单位。Elasticsearch 在对数据进行再平衡（例如发生故障后）时移动分片的速度取决于分片的大小和数量，以及网络和磁盘性能。</p><blockquote><p>提示： <font color="DeepPink"><strong>避免分片过大，因为这样会对集群从故障中恢复造成不利影响。尽管并没有关于分片大小的固定限值，但是人们通常将 50GB 作为分片上限，而且这一限值在各种用例中都已得到验证。</strong></font></p></blockquote><h1>按照保留期限进行索引</h1><p>由于段是不可更改的，所以<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/update-doc.html" target="_blank" rel="noopener">更新文档</a>时必须要求 Elasticsearch 首先找到既有文档，然后将其标为已删除，并添加更新后版本。<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/delete-doc.html" target="_blank" rel="noopener">删除文档</a>时同样也要求先找到文档，再将其标为已删除。有鉴于此，<a href="https://www.elastic.co/cn/blog/lucenes-handling-of-deleted-documents" target="_blank" rel="noopener">已删除文档仍将继续占用磁盘空间和系统资源，直至将它们合并</a>，而合并过程也会消耗大量系统资源。</p><p>通过 Elasticsearch，用户可以十分高效地从文件系统中直接删除整个索引，而无需单独删除所有记录。这是迄今为止从 Elasticsearch 中删除数据的最高效方法。</p><blockquote><p>提示：但凡可能，尽量使用<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/time-based.html" target="_blank" rel="noopener">时序型索引</a>来管理具有数据保留期要求的数据。根据保留期限对数据分组，将它们存储到索引中。通过时序型索引，用户还能随着时间推移轻松调整主分片和副本分片的数量，这是因为用户可针对要生成的下个索引进行这方面的更改。这样便能简化对不断变化的数据量和数据要求的适应过程。</p></blockquote><h1>索引分片不是免费的吗？</h1><p>对于每个 Elasticsearch 索引，映射和状态的相关信息都存储在集群状态中。这些信息存储在内存中，以便快速访问。因此，如果集群中的索引和分片数量过多，这会导致集群状态过大，如果映射较大的话，尤为如此。这会导致更新变慢，因为所有更新都需要通过单线程完成，从而在将变更分发到整个集群之前确保一致性。</p><blockquote><p>提示： 为了减少索引数量并避免造成过大且无序的映射，可以考虑在同一索引中存储类似结构的数据，而不要基于数据来源将数据分到不同的索引中。很重要的一点是在索引/分片的数量和每个单独索引的映射大小之间实现良好平衡。由于<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/finite-scale.html#finite-scale" target="_blank" rel="noopener">集群状态</a>会加载到每个节点（包括主节点）上的堆内存中，而且堆内存大小与索引数量以及单个索引和分片中的字段数成正比关系，所以还需要同时监测主节点上的堆内存使用量并确保其大小适宜，这一点很重要。</p></blockquote><p>每个分片都有一部分数据需要保存在内存中，这部分数据也会占用堆内存空间。这包括存储分片级别以及段级别信息的数据结构，因为只有这样才能确定数据在磁盘上的存储位置。这些数据结构的大小并不固定，不同用例之间会有很大的差别。</p><p>段相关开销有一个重要特征，那就是其并不与段的大小呈严格正比关系。这意味着，与较小的段相比，对于较大的段而言，其单位数据量所需的开销要小一些。二者之间的差异可能会十分巨大。</p><p>为了能够在单个节点上存储尽可能多的数据，下面两点至关重要：管理堆内存使用量；尽可能减少开销。节点的堆内存空间越多，其能处理的数据和分片就越多。</p><p>从集群角度来说，索引和分片都不是免费的，因为每个索引和分片都会产生一定的资源开销。</p><blockquote><p>提示： <font color="DeepPink"><strong>分片过小会导致段过小，进而致使开销增加。您要尽量将分片的平均大小控制在至少几 GB 到几十 GB 之间。对时序型数据用例而言，分片大小通常介于 20GB 至 40GB 之间。</strong></font></p></blockquote><blockquote><p>提示： 由于单个分片的开销取决于段数量和段大小，所以通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-forcemerge.html" target="_blank" rel="noopener">forcemerge</a> 操作强制将较小的段合并为较大的段能够减少开销并改善查询性能。理想状况下，应当在索引内再无数据写入时完成此操作。请注意：这是一个极其耗费资源的操作，所以应该在非高峰时段进行。</p></blockquote><blockquote><p>提示： 每个节点上可以存储的分片数量与可用的堆内存大小成正比关系，但是 Elasticsearch 并未强制规定固定限值。这里有一个很好的经验法则：<font color="DeepPink"><strong>确保对于节点上已配置的每个 GB，将分片数量保持在 20 以下。如果某个节点拥有 30GB 的堆内存，那其最多可有 600 个分片，但是在此限值范围内，您设置的分片数量越少，效果就越好。</strong></font>一般而言，这可以帮助集群保持良好的运行状态。</p></blockquote><h1>分片大小对性能有何影响？</h1><p>在 Elasticsearch 中，每个查询都是在单个分片上以单线程方式执行的。然而，可以同时对多个分片进行处理，正如可以针对同一分片进行多次查询和聚合一样。</p><p>这意味着，最低查询延时（假设没有缓存）将取决于数据、查询类型，以及分片大小。尽管查询很多个小分片会加快单个分片的处理速度，但是由于有很多任务需要进入队列并按顺序加以处理，所以与查询较少的大分片相比，这种方法并不一定会加快查询速度。如果有多个并发查询，拥有很多小分片还会降低查询吞吐量。</p><blockquote><p>提示： 从查询性能的角度来看，确定最大分片大小的最佳方法是<a href="https://www.elastic.co/cn/elasticon/conf/2016/sf/quantitative-cluster-sizing" target="_blank" rel="noopener">使用具有实际意义的数据和查询进行基准测试</a>。进行基准测试时，务必确保所使用的查询和索引负载能够代表节点在生产环境中需要处理的内容，因为只针对单一查询进行优化可能会得出错误结果。</p></blockquote><h1>我应该如何管理分片大小呢？</h1><p>使用时序型索引时，按照传统方法，每个索引都关联至固定时间段。按天索引是一种十分常见的方法，通常用来存储保留期较短的数据或者用来存储较大的每日数据量。此类索引允许用户在很细的粒度层面管理保留期，也方便用户根据每天不断变化的数据量轻松进行调整。对于拥有较长保留期的数据，尤其如果每日数据量并不能保证用完每日索引，通常可按周索引或按月索引，以便提高分片大小。长期来看，这有助于减少存储在集群中的索引和分片数量。</p><blockquote><p>提示： 如果使用时序型索引来存储固定期限内的数据，用户应根据保留期和预计数据量对每个索引覆盖的期限进行调整，从而确保达到目标分片大小。</p></blockquote><p>如果能够很好地预估数据量并且数据量变化缓慢，则固定期限式时序型索引的效果很好。如果索引速度变化很快，则很难保持统一的目标分片大小。</p><p>为了能够更好地应对此类情形，可以采用所推出的 <a href="https://www.elastic.co/cn/blog/managing-time-based-indices-efficiently" target="_blank" rel="noopener">Rollover（汇总）和 Shrink（压缩）API</a>。这些 API 能够让用户更加灵活地管理索引和分片，尤其是时序型索引。</p><p>通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-rollover-index.html" target="_blank" rel="noopener">rollover index API</a>（汇总索引 API），用户能够指定每个索引应该存储的文档数量，以及/或者最长可在多长时间内向索引内写入文档。一旦超出这些条件，Elasticsearch 可触发新索引创建操作以继续写入数据，而不会造成中断。通过这种方法，每个索引不再覆盖特定的时间段，数据可在索引达到具体大小后转到新索引，这样用户可以更加轻松地确保所有索引都达到均等的分片大小。</p><p>由于使用此 API 时事件时间戳与事件所在的索引之间并无明显联系，所以如需更新数据，需要先搜索才能完成每次更新，而这会大大降低更新效率。</p><blockquote><p>提示： 如果您拥有不可更改的时序型数据，并且数据量在一段期间内会巨幅变化，可以考虑使用 rollover index API（汇总索引 API）通过动态调整每个索引所覆盖的时间段来实现最佳的目标分片大小。这为用户提供了很大的灵活性，并且在数据量难以预测时，还有助于避免分片过大或过小。</p></blockquote><p>通过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-shrink-index.html" target="_blank" rel="noopener">shrink index API</a>（压缩索引 API），您能够将现有索引压缩到拥有较少主分片的新索引中。如果在索引时希望不同节点上的分片覆盖均等的时间段，但是这会导致分片过小，则您可以考虑在索引内再无数据写入时使用此 API 来降低主分片数量。这会形成较大的分片，能够更好地满足长期存储数据的需求。</p><blockquote><p>提示： 如果您希望每个索引既要对应至特定时间段，同时还想将索引过程分散到大量节点上，可以考虑使用 Shrink（压缩）API 来在索引内再无数据写入时减少主分片数量。如果开始时配置了过多的分片，您也可以使用此 API 来减少分片数量。</p></blockquote><h1>结论</h1><p>本篇博文针对在 Elasticsearch 中管理数据的最佳方法提供了一些建议和使用指南。如想深入了解，可以参阅“Elasticsearch：权威指南”中的<a href="https://www.elastic.co/guide/en/elasticsearch/guide/2.x/scale.html" target="_blank" rel="noopener">扩容设计</a>一节，尽管此部分内容已经发布一段时间了，但却仍然值得一读。</p><p>虽讲了这么多，关于如何最好地在索引和分片之间分配数据，很多决策仍取决于用例的具体情况，有时的确很难确定如何最好地应用现有建议。</p><blockquote><p>原文地址：<a href="https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster" target="_blank" rel="noopener">https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster</a></p></blockquote>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ElasticSearch</tag>
        <tag>Cluster</tag>
        <tag>Shard</tag>
      </tags>
  </entry>
  <entry>
    <title>控制台</title>
    <url>/console-features.html</url>
    <content><![CDATA[<blockquote><p>今天思考Q4要做啥的时候，顺便梳理一下目前已经或者准备做的功能。</p></blockquote><a id="more"></a><p><img data-src="/images/console-features/%E6%8E%A7%E5%88%B6%E5%8F%B0.png" alt></p><p><a href="https://jiankunking.com/integrated-container-cloud.html">集成容器云部分</a></p>]]></content>
      <categories>
        <category>Console</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Console</tag>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes中Java应用Heap Dump</title>
    <url>/how-to-do-java-jvm-heap-dump-in-kubernetes.html</url>
    <content><![CDATA[<blockquote><p>Dump Java Heap to OSS</p></blockquote><a id="more"></a><p>伴随着微服务及容器化的发展，越来越多的应用运行在kubernetes集群中，运维、调试的问题也随之而来。以Java为例，当线上环境出现内存问题，比如OOM，这时候需要Dump内存进行分析的时候，就会发现对于普通开发人员来说他们没有操作kubernetes集群机器的权限，从而导致，Dump出来的文件无法回传到开发手中进行MAT之类的分析。</p><p>本文的解决办法是这样的，当用户需要Dump某个应用实例的时候，只需要在实例终端界面点击一下按钮，后台会自动Dump Heap到OSS上，上传完成后，会将下载的信息展示在列表页，这时候开发人员就可以进行下载了。</p><p>具体的操作流程是这样的：<br>1、检测Pod中是否有JDK TOOLS<br>2、拷贝Dump工具到对应的Pod中<br>3、赋予Dump工具可执行权限<br>4、运行Dump工具</p><blockquote><p>Dump工具会识别Java进程，如果有多个Java进程会Dump进程号小的那一个。</p></blockquote><p>核心代码主要是拷贝Dump工具到对应的Pod中</p><p>jmap.go</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package dump</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;bytes&quot;</span><br><span class="line">	&quot;context&quot;</span><br><span class="line">	&quot;errors&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;os&quot;</span><br><span class="line">	&quot;strings&quot;</span><br><span class="line"></span><br><span class="line">	corev1 &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class="line">	&quot;k8s.io/client-go/rest&quot;</span><br><span class="line">	&quot;k8s.io/client-go/tools/remotecommand&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">var jmapDumpTool = &quot;jmap-dump-tool&quot;</span><br><span class="line"></span><br><span class="line">func init() &#123;</span><br><span class="line">	// jmap-dump-tool 文件名</span><br><span class="line">	if os.Getenv(&quot;JMAP_DUMP_TOOL_NAME&quot;) != &quot;&quot; &#123;</span><br><span class="line">		jmapDumpTool = os.Getenv(&quot;JMAP_DUMP_TOOL_NAME&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">	log.Println(&quot;JMAP_DUMP_TOOL_NAME:&quot; + jmapDumpTool)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func DumpJavaHeap(ctx context.Context, project, app, env, cluster, namespace, podID, container string) error &#123;</span><br><span class="line">   </span><br><span class="line">	// todo 获取k8s信息部分 需要替换成自己的</span><br><span class="line">	ctxName := meta.GetContextName(cluster)</span><br><span class="line">	kclient, err := k8s.GetClient(ctxName)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return errors.New(&quot;获取kubernetes client失败！&quot;)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 获取kube config配置</span><br><span class="line">	config, err := k8s.GetClientConfig(ctxName)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return errors.New(&quot;获取kube config失败！&quot;)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	pod := new(pod)</span><br><span class="line">	pod.Namespace = namespace</span><br><span class="line">	pod.Name = podID</span><br><span class="line">	pod.ContainerName = container</span><br><span class="line"></span><br><span class="line">	log.Println(&quot;开始检测目标容器中是否有JDK Tool&quot;)</span><br><span class="line">	//检测是否 容器中是否有jps命令</span><br><span class="line">	cmds := []string&#123;&quot;sh&quot;, &quot;-c&quot;, &quot;jps&quot;&#125;</span><br><span class="line">	req := kclient.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Namespace(pod.Namespace).</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(pod.Name).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(&amp;corev1.PodExecOptions&#123;</span><br><span class="line">			Container: pod.ContainerName,</span><br><span class="line">			Command:   cmds,</span><br><span class="line">			Stdin:     true,</span><br><span class="line">			Stdout:    true,</span><br><span class="line">			Stderr:    true,</span><br><span class="line">			TTY:       false,</span><br><span class="line">		&#125;, scheme.ParameterCodec)</span><br><span class="line"></span><br><span class="line">	exec, err := remotecommand.NewSPDYExecutor(config, &quot;POST&quot;, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return &amp;customerr.JavaHeapDumpError&#123;Msg: &quot;检查对应容器中是否有JDK Tools时发生异常！&quot;&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	bufErr := new(bytes.Buffer)</span><br><span class="line">	err = exec.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:  strings.NewReader(&quot;&quot;),</span><br><span class="line">		Stdout: os.Stdout,</span><br><span class="line">		Stderr: bufErr,</span><br><span class="line">		Tty:    false,</span><br><span class="line">	&#125;)</span><br><span class="line">	if bufErr.Len() &gt; 0 &#123;</span><br><span class="line">		e := string(bufErr.Bytes())</span><br><span class="line">		if e != &quot;&quot; &#123;</span><br><span class="line">			log.Println(e)</span><br><span class="line">			return &amp;customerr.JavaHeapDumpError&#123;Msg: &quot;请检查对应容器中是否有JDK Tools，&quot; + e&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	log.Println(&quot;检测完成，目标容器中有JDK Tool&quot;)</span><br><span class="line"></span><br><span class="line">	srcPath := &quot;/&quot; + jmapDumpTool</span><br><span class="line">	log.Println(&quot;srcPath:&quot; + srcPath)</span><br><span class="line">	destPath := &quot;/&quot; + jmapDumpTool</span><br><span class="line">	log.Println(&quot;destPath:&quot; + destPath)</span><br><span class="line"></span><br><span class="line">	err = pod.copyToPod(ctx, kclient, config, srcPath, destPath)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return &amp;customerr.JavaHeapDumpError&#123;Msg: &quot;dump工具拷贝失败！&quot;&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	log.Println(&quot;jmap-dump-tool copy to pod end&quot;)</span><br><span class="line">	// 赋予可执行权限</span><br><span class="line">	cmds = []string&#123;&quot;sh&quot;, &quot;-c&quot;, &quot;chmod +x /&quot; + jmapDumpTool&#125;</span><br><span class="line">	err = pod.Exec(ctx, kclient, config, cmds)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return &amp;customerr.JavaHeapDumpError&#123;Msg: &quot;dump工具赋予可执行权限失败！&quot;&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	log.Println(&quot;jmap-dump-tool 已赋予可执行权限&quot;)</span><br><span class="line">	go execDump(*pod, jmapDumpTool, project, app, env, kclient, config)</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func execDump(p pod, jmapDumpTool, project, app, env string, client *kubernetes.Clientset, config *rest.Config) &#123;</span><br><span class="line">	// 执行</span><br><span class="line">	c := fmt.Sprintf(&quot;/%s %s %s %s&quot;, jmapDumpTool, project, app, env)</span><br><span class="line">	cmds := []string&#123;&quot;sh&quot;, &quot;-c&quot;, c&#125;</span><br><span class="line">	err := p.Exec(context.Background(), client, config, cmds)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cp.go（参考kubectl cp的实现）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package dump</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;archive/tar&quot;</span><br><span class="line">	&quot;context&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;io&quot;</span><br><span class="line">	&quot;io/ioutil&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;os&quot;</span><br><span class="line">	&quot;path&quot;</span><br><span class="line">	&quot;strings&quot;</span><br><span class="line"></span><br><span class="line">	corev1 &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class="line">	&quot;k8s.io/client-go/rest&quot;</span><br><span class="line">	&quot;k8s.io/client-go/tools/remotecommand&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type pod struct &#123;</span><br><span class="line">	Name          string</span><br><span class="line">	Namespace     string</span><br><span class="line">	ContainerName string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (i *pod) copyToPod(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, srcPath string, destPath string) error &#123;</span><br><span class="line">	reader, writer := io.Pipe()</span><br><span class="line"></span><br><span class="line">	if destPath != &quot;/&quot; &amp;&amp; strings.HasSuffix(string(destPath[len(destPath)-1]), &quot;/&quot;) &#123;</span><br><span class="line">		destPath = destPath[:len(destPath)-1]</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if err := checkDestinationIsDir(ctx, client, config, i, destPath); err == nil &#123;</span><br><span class="line">		destPath = destPath + &quot;/&quot; + path.Base(srcPath)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	go func() &#123;</span><br><span class="line">		defer writer.Close()</span><br><span class="line">		err := makeTar(srcPath, destPath, writer)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			fmt.Println(err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	var cmdArr []string</span><br><span class="line"></span><br><span class="line">	cmdArr = []string&#123;&quot;tar&quot;, &quot;-xf&quot;, &quot;-&quot;&#125;</span><br><span class="line">	destDir := path.Dir(destPath)</span><br><span class="line">	if len(destDir) &gt; 0 &#123;</span><br><span class="line">		cmdArr = append(cmdArr, &quot;-C&quot;, destDir)</span><br><span class="line">	&#125;</span><br><span class="line">	//remote shell.</span><br><span class="line">	req := client.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Namespace(i.Namespace).</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(i.Name).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(&amp;corev1.PodExecOptions&#123;</span><br><span class="line">			Container: i.ContainerName,</span><br><span class="line">			Command:   cmdArr,</span><br><span class="line">			Stdin:     true,</span><br><span class="line">			Stdout:    true,</span><br><span class="line">			Stderr:    true,</span><br><span class="line">			TTY:       false,</span><br><span class="line">		&#125;, scheme.ParameterCodec)</span><br><span class="line"></span><br><span class="line">	exec, err := remotecommand.NewSPDYExecutor(config, &quot;POST&quot;, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = exec.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:  reader,</span><br><span class="line">		Stdout: os.Stdout,</span><br><span class="line">		Stderr: os.Stderr,</span><br><span class="line">		Tty:    false,</span><br><span class="line">	&#125;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func checkDestinationIsDir(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, i *pod, destPath string) error &#123;</span><br><span class="line">	return i.Exec(ctx, client, config, []string&#123;&quot;test&quot;, &quot;-d&quot;, destPath&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func makeTar(srcPath, destPath string, writer io.Writer) error &#123;</span><br><span class="line">	// TODO: use compression here?</span><br><span class="line">	tarWriter := tar.NewWriter(writer)</span><br><span class="line">	defer tarWriter.Close()</span><br><span class="line"></span><br><span class="line">	srcPath = path.Clean(srcPath)</span><br><span class="line">	destPath = path.Clean(destPath)</span><br><span class="line">	return recursiveTar(path.Dir(srcPath), path.Base(srcPath), path.Dir(destPath), path.Base(destPath), tarWriter)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func recursiveTar(srcBase, srcFile, destBase, destFile string, tarWriter *tar.Writer) error &#123;</span><br><span class="line"></span><br><span class="line">	filepath := path.Join(srcBase, srcFile)</span><br><span class="line">	stat, err := os.Lstat(filepath)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	if stat.IsDir() &#123;</span><br><span class="line">		files, err := ioutil.ReadDir(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		if len(files) == 0 &#123;</span><br><span class="line">			//case empty directory</span><br><span class="line">			hdr, _ := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">			hdr.Name = destFile</span><br><span class="line">			if err := tarWriter.WriteHeader(hdr); err != nil &#123;</span><br><span class="line">				return err</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		for _, f := range files &#123;</span><br><span class="line">			if err := recursiveTar(srcBase, path.Join(srcFile, f.Name()), destBase, path.Join(destFile, f.Name()), tarWriter); err != nil &#123;</span><br><span class="line">				return err</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return nil</span><br><span class="line">	&#125; else if stat.Mode()&amp;os.ModeSymlink != 0 &#123;</span><br><span class="line">		//case soft link</span><br><span class="line">		hdr, _ := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">		target, err := os.Readlink(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		hdr.Linkname = target</span><br><span class="line">		hdr.Name = destFile</span><br><span class="line">		if err := tarWriter.WriteHeader(hdr); err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		//case regular file or other file type like pipe</span><br><span class="line">		hdr, err := tar.FileInfoHeader(stat, filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		hdr.Name = destFile</span><br><span class="line">		err = tarWriter.WriteHeader(hdr)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			log.Println(err)</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		f, err := os.Open(filepath)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		defer f.Close()</span><br><span class="line"></span><br><span class="line">		if _, err := io.Copy(tarWriter, f); err != nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		return f.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (i *pod) Exec(ctx context.Context, client *kubernetes.Clientset, config *rest.Config, cmd []string) error &#123;</span><br><span class="line"></span><br><span class="line">	req := client.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Namespace(i.Namespace).</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(i.Name).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(&amp;corev1.PodExecOptions&#123;</span><br><span class="line">			Container: i.ContainerName,</span><br><span class="line">			Command:   cmd,</span><br><span class="line">			Stdin:     true,</span><br><span class="line">			Stdout:    true,</span><br><span class="line">			Stderr:    true,</span><br><span class="line">			TTY:       false,</span><br><span class="line">		&#125;, scheme.ParameterCodec)</span><br><span class="line"></span><br><span class="line">	exec, err := remotecommand.NewSPDYExecutor(config, &quot;POST&quot;, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = exec.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:  strings.NewReader(&quot;&quot;),</span><br><span class="line">		Stdout: os.Stdout,</span><br><span class="line">		Stderr: os.Stderr,</span><br><span class="line">		Tty:    false,</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kubernetes</tag>
        <tag>Heap</tag>
        <tag>Dump</tag>
      </tags>
  </entry>
  <entry>
    <title>一个Kubernetes Web终端连接工具</title>
    <url>/kubernetes-client-go-how-to-make-a-web-terminal.html</url>
    <content><![CDATA[<blockquote><p>当应用部署到Kubernetes集群中之后，如何提供Web终端的功能，以便开发人员调试？</p></blockquote><a id="more"></a><h1>方案一</h1><p>该功能的核心就是实现kubernetes executor接口</p><p>exec.go</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package pod</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;context&quot;</span><br><span class="line">	&quot;errors&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;net/http&quot;</span><br><span class="line">	&quot;sync&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com/gorilla/websocket&quot;</span><br><span class="line">	corev1 &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class="line">	&quot;k8s.io/client-go/tools/remotecommand&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">// 封装websocket连接</span><br><span class="line">type WsConnection struct &#123;</span><br><span class="line">	wsSocket  *websocket.Conn // 底层websocket</span><br><span class="line">	inChan    chan *WsMessage // 读取队列</span><br><span class="line">	outChan   chan *WsMessage // 发送队列</span><br><span class="line">	mutex     sync.Mutex      // 避免重复关闭管道</span><br><span class="line">	isClosed  bool</span><br><span class="line">	closeChan chan byte // 关闭通知</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// web终端发来的包</span><br><span class="line">type xtermMessage struct &#123;</span><br><span class="line">	MsgType string `json:&quot;type&quot;`  // 类型:resize客户端调整终端, input客户端输入</span><br><span class="line">	Input   string `json:&quot;input&quot;` // msgtype=input情况下使用</span><br><span class="line">	Rows    uint16 `json:&quot;rows&quot;`  // msgtype=resize情况下使用</span><br><span class="line">	Cols    uint16 `json:&quot;cols&quot;`  // msgtype=resize情况下使用</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// websocket消息</span><br><span class="line">type WsMessage struct &#123;</span><br><span class="line">	MessageType int</span><br><span class="line">	Data        []byte</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 关闭连接</span><br><span class="line">func (wsConn *WsConnection) WsClose() &#123;</span><br><span class="line">	wsConn.wsSocket.Close()</span><br><span class="line">	wsConn.mutex.Lock()</span><br><span class="line">	defer wsConn.mutex.Unlock()</span><br><span class="line">	if !wsConn.isClosed &#123;</span><br><span class="line">		wsConn.isClosed = true</span><br><span class="line">		close(wsConn.closeChan)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// ssh流式处理器</span><br><span class="line">type streamHandler struct &#123;</span><br><span class="line">	wsConn      *WsConnection</span><br><span class="line">	resizeEvent chan remotecommand.TerminalSize</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// executor回调获取web是否resize</span><br><span class="line">func (handler *streamHandler) Next() (size *remotecommand.TerminalSize) &#123;</span><br><span class="line">	ret := &lt;-handler.resizeEvent</span><br><span class="line">	size = &amp;ret</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 发送返回消息到协程</span><br><span class="line">func (wsConn *WsConnection) WsWrite(messageType int, data []byte) (err error) &#123;</span><br><span class="line">	select &#123;</span><br><span class="line">	case wsConn.outChan &lt;- &amp;WsMessage&#123;messageType, data&#125;:</span><br><span class="line">	case &lt;-wsConn.closeChan:</span><br><span class="line">		err = errors.New(&quot;WsWrite websocket closed&quot;)</span><br><span class="line">		break</span><br><span class="line">	&#125;</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 读取协程</span><br><span class="line">func (wsConn *WsConnection) wsReadLoop() &#123;</span><br><span class="line">	for &#123;</span><br><span class="line">		// 读一条message</span><br><span class="line">		// ReadMessage返回的messageType只可能是：TextMessage BinaryMessage</span><br><span class="line">		msgType, data, err := wsConn.wsSocket.ReadMessage()</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			log.Println(err)</span><br><span class="line">			break</span><br><span class="line">		&#125;</span><br><span class="line">		//log.Print(string(data))</span><br><span class="line">		// 放入请求队列</span><br><span class="line">		wsConn.inChan &lt;- &amp;WsMessage&#123;</span><br><span class="line">			msgType,</span><br><span class="line">			data,</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 发送协程</span><br><span class="line">func (wsConn *WsConnection) wsWriteLoop() &#123;</span><br><span class="line">	// 服务端返回给页面的数据</span><br><span class="line">	for &#123;</span><br><span class="line">		select &#123;</span><br><span class="line">		// 取一个应答</span><br><span class="line">		case msg := &lt;-wsConn.outChan:</span><br><span class="line">			//log.Print(string(msg.Data))</span><br><span class="line">			// 写给web  websocket</span><br><span class="line">			if err := wsConn.wsSocket.WriteMessage(msg.MessageType, msg.Data); err != nil &#123;</span><br><span class="line">				log.Println(err)</span><br><span class="line">				break</span><br><span class="line">			&#125;</span><br><span class="line">		case &lt;-wsConn.closeChan:</span><br><span class="line">			wsConn.WsClose()</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (wsConn *WsConnection) onContextCancel(ctx context.Context) &#123;</span><br><span class="line">	for &#123;</span><br><span class="line">		select &#123;</span><br><span class="line">		case &lt;-ctx.Done():</span><br><span class="line">			log.Println(&quot;web cancel context or time out..........&quot;)</span><br><span class="line">			wsConn.WsClose()</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 读取 页面消息到协程</span><br><span class="line">func (wsConn *WsConnection) WsRead() (msg *WsMessage, err error) &#123;</span><br><span class="line">	select &#123;</span><br><span class="line">	case msg = &lt;-wsConn.inChan:</span><br><span class="line">		return</span><br><span class="line">	case &lt;-wsConn.closeChan:</span><br><span class="line">		err = errors.New(&quot;WsRead websocket closed&quot;)</span><br><span class="line">		break</span><br><span class="line">	&#125;</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// executor回调读取web端的输入</span><br><span class="line">func (handler *streamHandler) Read(p []byte) (size int, err error) &#123;</span><br><span class="line">	// 读web发来的输入</span><br><span class="line">	msg, err := handler.wsConn.WsRead()</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		handler.wsConn.WsClose()</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	xtermMsg := &amp;xtermMessage&#123;</span><br><span class="line">		//MsgType: string(msg.MessageType),</span><br><span class="line">		Input: string(msg.Data),</span><br><span class="line">	&#125;</span><br><span class="line">	// 放到channel里，等remotecommand executor调用我们的Next取走</span><br><span class="line">	handler.resizeEvent &lt;- remotecommand.TerminalSize&#123;Width: xtermMsg.Cols, Height: xtermMsg.Rows&#125;</span><br><span class="line">	size = len(xtermMsg.Input)</span><br><span class="line">	copy(p, xtermMsg.Input)</span><br><span class="line">	return</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// executor回调向web端输出</span><br><span class="line">func (handler *streamHandler) Write(p []byte) (size int, err error) &#123;</span><br><span class="line">	// 产生副本</span><br><span class="line">	copyData := make([]byte, len(p))</span><br><span class="line">	copy(copyData, p)</span><br><span class="line">	size = len(p)</span><br><span class="line">	err = handler.wsConn.WsWrite(websocket.TextMessage, copyData)</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ContainerExec(ctx context.Context, r *http.Request, w http.ResponseWriter, cluster, namespace, podID, container string) error &#123;</span><br><span class="line"></span><br><span class="line">	// todo 获取k8s信息部分 需要替换成自己的</span><br><span class="line">	ctxName := meta.GetContextName(cluster)</span><br><span class="line">	kclient, err := k8s.GetClient(ctxName)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	cmds := []string&#123;&quot;sh&quot;, &quot;-c&quot;, &quot;test -f /bin/bash &amp;&amp; bash || sh&quot;&#125;</span><br><span class="line">	option := &amp;corev1.PodExecOptions&#123;</span><br><span class="line">		Command:   cmds,</span><br><span class="line">		Stdin:     true,</span><br><span class="line">		Stdout:    true,</span><br><span class="line">		Stderr:    true,</span><br><span class="line">		TTY:       true,</span><br><span class="line">		Container: container,</span><br><span class="line">	&#125;</span><br><span class="line">	subCtx, cancel := context.WithTimeout(ctx, models.READ_LOG_TIMEOUT)</span><br><span class="line">	defer cancel()</span><br><span class="line">	req := kclient.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(podID).</span><br><span class="line">		Namespace(namespace).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(option, scheme.ParameterCodec).Timeout(models.READ_LOG_TIMEOUT)</span><br><span class="line">	wsSocket, err := upGrader.Upgrade(w, r, nil)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	wsConn := &amp;WsConnection&#123;</span><br><span class="line">		wsSocket:  wsSocket,</span><br><span class="line">		inChan:    make(chan *WsMessage, 1000),</span><br><span class="line">		outChan:   make(chan *WsMessage, 1000),</span><br><span class="line">		closeChan: make(chan byte),</span><br><span class="line">		isClosed:  false,</span><br><span class="line">	&#125;</span><br><span class="line">	// 获取kube config配置</span><br><span class="line">	config, err := k8s.GetClientConfig(ctxName)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		wsConn.WsClose()</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	// 创建到容器的连接</span><br><span class="line">	executor, err := remotecommand.NewSPDYExecutor(config, http.MethodPost, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		wsConn.WsClose()</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	// 页面读入输入 协程</span><br><span class="line">	go wsConn.wsReadLoop()</span><br><span class="line">	// 服务端返回数据 协程</span><br><span class="line">	go wsConn.wsWriteLoop()</span><br><span class="line"></span><br><span class="line">	// 监听前端请求</span><br><span class="line">	go wsConn.onContextCancel(subCtx)</span><br><span class="line"></span><br><span class="line">	// 配置与容器之间的数据流处理回调</span><br><span class="line">	handler := &amp;streamHandler&#123;wsConn: wsConn, resizeEvent: make(chan remotecommand.TerminalSize)&#125;</span><br><span class="line">	if err = executor.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:             handler,</span><br><span class="line">		Stdout:            handler,</span><br><span class="line">		Stderr:            handler,</span><br><span class="line">		TerminalSizeQueue: handler,</span><br><span class="line">		Tty:               true,</span><br><span class="line">	&#125;); err != nil &#123;</span><br><span class="line">		log.Println(&quot;handler&quot;, err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>参考资料：</p><p><a href="https://github.com/jiankunking/k8-web-terminal" target="_blank" rel="noopener">https://github.com/jiankunking/k8-web-terminal</a></p><blockquote><p>方案一存在内存泄漏问题，<a href="https://github.com/kubernetes/client-go/issues/884" target="_blank" rel="noopener">https://github.com/kubernetes/client-go/issues/884</a></p></blockquote><h1>方案二</h1><p>exec.go</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;context&quot;</span><br><span class="line">	&quot;encoding/json&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;io&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;net/http&quot;</span><br><span class="line">	&quot;time&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com/gorilla/websocket&quot;</span><br><span class="line">	corev1 &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">	&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class="line">	&quot;k8s.io/client-go/tools/remotecommand&quot;</span><br><span class="line"></span><br><span class="line">	&quot;git.jiankunking.net/console/k8s-ext/k8s&quot;</span><br><span class="line">	&quot;git.jiankunking.net/console/k8s-ext/pkg/models&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">// https://github.com/kubernetes/dashboard/blob/master/src/app/backend/handler/terminal.go</span><br><span class="line"></span><br><span class="line">type PtyHandler interface &#123;</span><br><span class="line">	io.Reader</span><br><span class="line">	io.Writer</span><br><span class="line">	remotecommand.TerminalSizeQueue</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">const END_OF_TRANSMISSION = &quot;\u0004&quot;</span><br><span class="line"></span><br><span class="line">// TerminalMessage is the messaging protocol between ShellController and TerminalSession.</span><br><span class="line">//</span><br><span class="line">// OP      DIRECTION  FIELD(S) USED  DESCRIPTION</span><br><span class="line">// ---------------------------------------------------------------------</span><br><span class="line">// bind    fe-&gt;be     SessionID      Id sent back from TerminalResponse</span><br><span class="line">// stdin   fe-&gt;be     Data           Keystrokes/paste buffer</span><br><span class="line">// resize  fe-&gt;be     Rows, Cols     New terminal size</span><br><span class="line">// stdout  be-&gt;fe     Data           Output from the process</span><br><span class="line">// toast   be-&gt;fe     Data           OOB message to be shown to the user</span><br><span class="line">type TerminalMessage struct &#123;</span><br><span class="line">	Op, Data string</span><br><span class="line">	//SessionID  string `json:&quot;,omitempty&quot;`</span><br><span class="line">	Rows, Cols uint16 `json:&quot;,omitempty&quot;`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// TerminalSession</span><br><span class="line">type TerminalSession struct &#123;</span><br><span class="line">	ID       string</span><br><span class="line">	wsConn   *websocket.Conn</span><br><span class="line">	sizeChan chan remotecommand.TerminalSize</span><br><span class="line">	doneChan chan struct&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// TerminalSize handles pty-&gt;process resize events</span><br><span class="line">// Called in a loop from remotecommand as long as the process is running</span><br><span class="line">func (t *TerminalSession) Next() *remotecommand.TerminalSize &#123;</span><br><span class="line">	select &#123;</span><br><span class="line">	case size := &lt;-t.sizeChan:</span><br><span class="line">		return &amp;size</span><br><span class="line">	case &lt;-t.doneChan:</span><br><span class="line">		return nil</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Read handles pty-&gt;process messages (stdin, resize)</span><br><span class="line">// Called in a loop from remotecommand as long as the process is running</span><br><span class="line">func (t *TerminalSession) Read(p []byte) (int, error) &#123;</span><br><span class="line">	_, message, err := t.wsConn.ReadMessage()</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Printf(&quot;%s: read ws message failed: %v&quot;, t.ID, err)</span><br><span class="line">		return copy(p, END_OF_TRANSMISSION), err</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(&quot;%s: read&quot;, t.ID)</span><br><span class="line">	var msg TerminalMessage</span><br><span class="line">	if err := json.Unmarshal(message, &amp;msg); err != nil &#123;</span><br><span class="line">		// TODO: temp workaround for non-json input</span><br><span class="line">		return 0, nil</span><br><span class="line">		//log.Printf(&quot;%s: json decoded failed: %v&quot;, t.ID, err)</span><br><span class="line">		//return copy(p, END_OF_TRANSMISSION), err</span><br><span class="line">	&#125;</span><br><span class="line">	switch msg.Op &#123;</span><br><span class="line">	case &quot;stdin&quot;:</span><br><span class="line">		return copy(p, msg.Data), nil</span><br><span class="line">	case &quot;resize&quot;:</span><br><span class="line">		t.sizeChan &lt;- remotecommand.TerminalSize&#123;Width: msg.Cols, Height: msg.Rows&#125;</span><br><span class="line">		return 0, nil</span><br><span class="line">	default:</span><br><span class="line">		log.Printf(&quot;%s: unknown message type &apos;%s&apos;&quot;, t.ID, msg.Op)</span><br><span class="line">		return copy(p, END_OF_TRANSMISSION), fmt.Errorf(&quot;unknown message type &apos;%s&apos;&quot;, msg.Op)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Write handles process-&gt;pty stdout</span><br><span class="line">// Called from remotecommand whenever there is any output</span><br><span class="line">func (t *TerminalSession) Write(p []byte) (int, error) &#123;</span><br><span class="line">	//msg, err := json.Marshal(TerminalMessage&#123;</span><br><span class="line">	//    Op:   &quot;stdout&quot;,</span><br><span class="line">	//    Data: string(p),</span><br><span class="line">	//&#125;)</span><br><span class="line">	//if err != nil &#123;</span><br><span class="line">	//    log.Printf(&quot;json encode failed: %v&quot;, err)</span><br><span class="line">	//    return 0, err</span><br><span class="line">	//&#125;</span><br><span class="line">	if err := t.wsConn.WriteMessage(websocket.TextMessage, p); err != nil &#123;</span><br><span class="line">		log.Printf(&quot;%s: write ws message failed: %v&quot;, t.ID, err)</span><br><span class="line">		return 0, err</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(&quot;%s: write&quot;, t.ID)</span><br><span class="line">	return len(p), nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (t *TerminalSession) Close() error &#123;</span><br><span class="line">	close(t.doneChan)</span><br><span class="line">	return t.wsConn.Close()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func newTerminalSession(id string, r *http.Request, w http.ResponseWriter) (*TerminalSession, error) &#123;</span><br><span class="line">	conn, err := upGrader.Upgrade(w, r, nil)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	return &amp;TerminalSession&#123;</span><br><span class="line">		ID:       id,</span><br><span class="line">		wsConn:   conn,</span><br><span class="line">		sizeChan: make(chan remotecommand.TerminalSize),</span><br><span class="line">		doneChan: make(chan struct&#123;&#125;),</span><br><span class="line">	&#125;, nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ContainerExec(ctx context.Context, r *http.Request, w http.ResponseWriter, cluster, namespace, podName, container string) error &#123;</span><br><span class="line">	kclient, err := k8s.GetKubeClient(cluster)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 获取kube config配置</span><br><span class="line">	config, err := k8s.GetClientConfig(cluster)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	cmd := []string&#123;&quot;sh&quot;, &quot;-c&quot;, &quot;test -f /bin/bash &amp;&amp; bash || sh&quot;&#125;</span><br><span class="line">	option := &amp;corev1.PodExecOptions&#123;</span><br><span class="line">		Command:   cmd,</span><br><span class="line">		Stdin:     true,</span><br><span class="line">		Stdout:    true,</span><br><span class="line">		Stderr:    true,</span><br><span class="line">		TTY:       true,</span><br><span class="line">		Container: container,</span><br><span class="line">	&#125;</span><br><span class="line">	//ctx, cancel := context.WithTimeout(ctx, models.READ_LOG_TIMEOUT)</span><br><span class="line">	//defer cancel()</span><br><span class="line">	req := kclient.CoreV1().RESTClient().</span><br><span class="line">		Post().</span><br><span class="line">		Resource(&quot;pods&quot;).</span><br><span class="line">		Name(podName).</span><br><span class="line">		Namespace(namespace).</span><br><span class="line">		SubResource(&quot;exec&quot;).</span><br><span class="line">		VersionedParams(option, scheme.ParameterCodec).</span><br><span class="line">		Timeout(models.READ_LOG_TIMEOUT)</span><br><span class="line"></span><br><span class="line">	executor, err := remotecommand.NewSPDYExecutor(config, http.MethodPost, req.URL())</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	sessID := fmt.Sprintf(&quot;%s|%s|%s|%s|%v&quot;, cluster, namespace, podName, container, time.Now().Unix())</span><br><span class="line">	t, err := newTerminalSession(sessID, r, w)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Println(err)</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	defer t.Close()</span><br><span class="line"></span><br><span class="line">	if err = executor.Stream(remotecommand.StreamOptions&#123;</span><br><span class="line">		Stdin:             t,</span><br><span class="line">		Stdout:            t,</span><br><span class="line">		Stderr:            t,</span><br><span class="line">		TerminalSizeQueue: t,</span><br><span class="line">		Tty:               true,</span><br><span class="line">	&#125;); err != nil &#123;</span><br><span class="line">		// http连接已经被hijacked，http.ResponseWriter不能再使用，所以不返回err</span><br><span class="line">		log.Printf(&quot;exec stream failed: %v&quot;, err)</span><br><span class="line">		return nil</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>client-go</tag>
        <tag>exec</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 八大经典应用</title>
    <url>/elasticsearch-eight-classic-application-scenarios.html</url>
    <content><![CDATA[<blockquote><p>Elasticsearch 对比主流数据产品，到底有哪些优劣势？人脸识别、地理位置分析等典型场景，如何轻松完成？PB级大数据下，如何保障毫秒级的检索与秒级分析？</p></blockquote><a id="more"></a><p>在线：<a href="/attachments/Elasticsearch八大经典应用.pdf" target="_blank">Elasticsearch八大经典应用</a></p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Java Volatile Keyword</title>
    <url>/java-volatile-keyword.html</url>
    <content><![CDATA[<blockquote><p>翻译自：Java Volatile Keyword<br>地址：<a href="http://tutorials.jenkov.com/java-concurrency/volatile.html" target="_blank" rel="noopener">http://tutorials.jenkov.com/java-concurrency/volatile.html</a></p></blockquote><a id="more"></a><p>Java volatile关键字用于将Java变量标记为“存储在主内存中”。更准确地说，这意味着对volatile变量的每次读取都将从计算机的主存中读取，而不是从CPU缓存中读取，而且对volatile变量的每次写入都将写入主存，而不仅仅是写入CPU缓存中。</p><p>实际上，由于Java 5 volatile关键字不仅仅保证volatile变量被写入主存和从主存中读取。我将在下面的部分中对此进行解释。</p><h1>变量可见性问题</h1><p>Java volatile关键字保证跨线程对变量的更改可见性。这听起来可能有点抽象，所以让我来详细说明一下。</p><p>在对非volatile变量进行操作的多线程应用程序中，出于性能原因，每个线程在处理变量时可能会将它们从主存复制到CPU缓存中。如果您的计算机包含多个CPU，则每个线程可以在不同的CPU上运行。这意味着，每个线程可以将这些变量复制到不同CPU的CPU缓存中。如图所示:</p><p><img data-src="/images/java-volatile-keyword/java-volatile-1.png" alt></p><p>对于volatile变量，无法保证Java虚拟机(JVM)何时将数据从主存读入CPU缓存，或何时将数据从CPU缓存写入主存。这可能会导致几个问题，我将在下面几节中解释这些问题。想象这样一种情况:两个或多个线程访问一个共享对象，该对象包含一个这样声明的计数器变量:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class SharedObject &#123;</span><br><span class="line">    public int counter = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再想象一下，只有线程1增加了计数器变量，但是线程1和线程2都可以不时地读取计数器变量。如果计数器变量未声明为volatile，则无法保证何时将计数器变量的值从CPU缓存写入主存。这意味着，CPU缓存中的计数器变量值可能与主存中的不同。这里说明了这种情况:</p><p><img data-src="/images/java-volatile-keyword/java-volatile-2.png" alt></p><p>线程看不到变量的最新值，因为它还没有被另一个线程写回主存，这种问题称为“可见性”问题。一个线程的更新对其他线程是不可见的。</p><h1>Java volatile可见性保证</h1><p>Java volatile关键字旨在解决可变可见性问题。通过声明volatile计数器变量，所有对计数器变量的写操作都将立即写回主存。另外，对计数器变量的所有读取都将直接从主存中读取。</p><p>下面是volatile声明计数器变量的样子:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class SharedObject &#123;</span><br><span class="line">    public volatile int counter = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将变量声明为volatile可以保证其他写入该变量的线程的可见性。</p><p>在上面给出的场景中，一个线程(T1)修改计数器，而另一个线程(T2)读取计数器(但从不修改它)，因此声明计数器变量为volatile就足以保证T2写入计数器变量时的可见性。</p><p>但是，如果T1和T2都在递增计数器变量，那么将计数器变量声明为volatile是不够的。稍后会详细介绍。</p><h1>完整的volatile可见性保证</h1><p>实际上，Java volatile的可见性保证超出了volatile变量本身。可见性保证如下:</p><ul><li><font color="DeepPink"><strong>如果线程A写入了一个volatile变量，而线程B随后又读取了同一个volatile变量，那么线程A在写入该volatile变量之前可见的所有变量，在线程B读取了该volatile变量之后也将可见。</strong></font></li><li><font color="DeepPink"><strong>如果线程A读取一个volatile变量，那么线程A在读取该volatile变量时可见的所有变量也将从主存中重新读取。</strong></font></li></ul><p>让我用一个代码示例来说明:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class MyClass &#123;</span><br><span class="line">    private int years;</span><br><span class="line">    private int months</span><br><span class="line">    private volatile int days;</span><br><span class="line"></span><br><span class="line">    public void update(int years, int months, int days)&#123;</span><br><span class="line">        this.years  = years;</span><br><span class="line">        this.months = months;</span><br><span class="line">        this.days   = days;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>update()方法写入三个变量，其中只有days是volatile变量。</p><p>完整的volatile可见性保证意味着，当一个值写入到days时，所有对线程可见的变量也会写入到主存中。这意味着，当一个值被写入days时，years和months的值也被写入主存。</p><p>当读取years、months、days的值时，可以这样做:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class MyClass &#123;</span><br><span class="line">    private int years;</span><br><span class="line">    private int months</span><br><span class="line">    private volatile int days;</span><br><span class="line"></span><br><span class="line">    public int totalDays() &#123;</span><br><span class="line">        int total = this.days;</span><br><span class="line">        total += months * 30;</span><br><span class="line">        total += years * 365;</span><br><span class="line">        return total;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void update(int years, int months, int days)&#123;</span><br><span class="line">        this.years  = years;</span><br><span class="line">        this.months = months;</span><br><span class="line">        this.days   = days;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，totalDays()方法首先将days的值读入total变量。当读取days的值时，months和years的值也被读入主存。因此，通过上述读取序列，您可以保证看到最新的days、months和years的值。</p><h1>指令重新排序的挑战</h1><p>出于性能原因，允许Java VM和CPU对程序中的指令重新排序，只要指令的语义意义保持不变。例如，看看下面的说明:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int a = 1;</span><br><span class="line">int b = 2;</span><br><span class="line"></span><br><span class="line">a++;</span><br><span class="line">b++;</span><br></pre></td></tr></table></figure><p>这些指令可以被重新排序到以下序列，而不会失去程序的语义意义:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int a = 1;</span><br><span class="line">a++;</span><br><span class="line"></span><br><span class="line">int b = 2;</span><br><span class="line">b++;</span><br></pre></td></tr></table></figure><p>但是，当其中一个变量是volatile变量时，指令重新排序就会带来挑战。让我们看看之前Java volatile教程中的例子中的MyClass:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class MyClass &#123;</span><br><span class="line">    private int years;</span><br><span class="line">    private int months</span><br><span class="line">    private volatile int days;</span><br><span class="line"></span><br><span class="line">    public void update(int years, int months, int days)&#123;</span><br><span class="line">        this.years  = years;</span><br><span class="line">        this.months = months;</span><br><span class="line">        this.days   = days;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>update()方法将值写入days之后，将新写入years和months的值也写入主存。但是，如果Java VM重新排序指令，像这样:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void update(int years, int months, int days)&#123;</span><br><span class="line">    this.days   = days;</span><br><span class="line">    this.months = months;</span><br><span class="line">    this.years  = years;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改days变量时，months和years的值仍然会写入主存，但这一次是在新值写入months和years之前。因此，不能正确地使新值对其他线程可见。重新排序的指令的语义已经改变。</p><p>Java有一个解决这个问题的方案，我们将在下一节中看到。</p><h1>Java volatile Happens-Before Guarantee</h1><p>为了解决指令重新排序的问题，Java volatile关键字除了提供可见性保证外，还提供了“happens-before”保证。The happens-before保证:</p><ul><li><font color="DeepPink"><strong>如果读/写是在写volatile变量之前发生的，那么对其他变量的读和写操作不能在写volatile变量之后重新排序。在对volatile变量进行写操作之前的读/写操作保证会“happen before”对volatile变量进行写操作之前。注意，它仍然是可能的，例如，对其他变量的读/写，位于写入一个volatile之后，重新排序发生在写入volatile之前。</strong></font>只是不是反过来。允许从后到前，但不允许从前到后。</li><li><font color="DeepPink"><strong>如果最初的读/写发生在读volatile变量之后，那么对其他变量的读和写操作就不能在读volatile变量之前重新排序。请注意，对于在volatile变量读取之前发生的其他变量的读取，可以重新排序为在volatile变量读取之后发生。只是不是反过来。</strong></font>允许从前到后，但不允许从后到前。</li></ul><p>以上happens-before保证确保执行volatile关键字的可见性保证。</p><h1>volatile 不适用的场景</h1><p>即使volatile关键字保证对volatile变量的所有读操作都直接从主存中读取，并且对volatile变量的所有写操作都直接写入主存中，仍然存在声明volatile变量是不够的情况。</p><p>在前面解释的只有线程1写入共享计数器变量的情况下，将计数器变量声明为volatile就足以确保线程2总是看到最新的写入值。</p><p>事实上，如果写入变量的新值不依赖于它以前的值，多个线程甚至可以写入共享volatile变量，并且仍然将正确的值存储在主内存中。换句话说，如果一个线程向共享volatile变量写入一个值，那么它不需要首先读取它的值来计算下一个值。</p><p>一旦线程需要首先读取volatile变量的值，并根据该值为共享volatile变量生成一个新值，那么volatile变量就不再足以保证正确的可见性。读取volatile变量与写入新值之间的时间间隔很短，这造成了竞争状态，其中多个线程可能会读取volatile变量的相同值，为该变量生成一个新值，以及在写入该值时 返回主内存-覆盖彼此的值。</p><p>多个线程递增同一个计数器的情况恰恰是一个volatile变量不够用的情况。下面几节将更详细地解释这种情况。</p><p>设想一下，如果线程1将一个值为0的共享计数器变量读入其CPU缓存，将其增量为1，并且不将更改后的值写回主存。然后，线程2可以从主存中读取相同的计数器变量(该变量的值仍然为0)到它自己的CPU缓存中。然后，线程2也可以将计数器增加到1，并且不将计数器写回主存。这一情况如下图所示:</p><p><img data-src="/images/java-volatile-keyword/java-volatile-3.png" alt></p><p>线程1和线程2现在实际上是不同步的。共享计数器变量的实际值应该是2，但是每个线程的CPU缓存中该变量的值都是1，而在主存中该值仍然是0。真是一团糟!即使线程最终将共享计数器变量的值写回主存，该值也将是错误的。</p><h1>volatile 适用的场景</h1><p>如前所述，如果两个线程同时读取和写入共享变量，那么使用volatile关键字是不够的。在这种情况下，需要使用synchronized来保证对变量的读写是原子性的。读或写volatile变量不会阻塞线程的读或写。要做到这一点，您必须在关键部分周围使用synchronized关键字。</p><p>作为同步块的替代方法，您还可以使用java.util.concurrent中找到的许多原子数据类型之一。例如，AtomicLong或AtomicReference或其他的一个。</p><p>如果只有一个线程读取和写入volatile变量的值，而其他线程只读取该变量，那么读取的线程将确保看到写入volatile变量的最新值。如果不使用volatile变量，这将无法得到保证。</p><p>volatile关键字可以保证在32位和64位变量上工作。</p><h1>volatile 性能</h1><p>对volatile变量的读写会导致该变量被读写到主存中。从主存读取和写入比访问CPU缓存开销更大。访问volatile变量还会阻止指令重排序，而指令重排序是一种普通的性能增强技术。因此，只有在真正需要增强变量的可见性时，才应该使用volatile变量。</p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>翻译</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
        <tag>Volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>ReentrantLock 重入与重试</title>
    <url>/java-reentrantlock-reentrant-and-retryry.html</url>
    <content><![CDATA[<blockquote><p>Java JDK 12 ReentrantLock</p></blockquote><a id="more"></a><p>今天突然想起了个问题：<br>1、ReentrantLock在获取锁的时候，会不会自旋？如果自旋的话，会自旋多少次？<br>2、ReentrantLock可重入次数会有上限控制吗？</p><p>1、看一下ReentrantLock中锁的实现：</p><p>非公平锁：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class="line"> * subclasses, but both need nonfair try for trylock method.</span><br><span class="line"> */</span><br><span class="line">@ReservedStackAccess</span><br><span class="line">final boolean nonfairTryAcquire(int acquires) &#123;</span><br><span class="line">    final Thread current = Thread.currentThread();</span><br><span class="line">    int c = getState();</span><br><span class="line">    if (c == 0) &#123;</span><br><span class="line">        if (compareAndSetState(0, acquires)) &#123;</span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        int nextc = c + acquires;</span><br><span class="line">        if (nextc &lt; 0) // overflow</span><br><span class="line">            throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>公平锁：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">     /**</span><br><span class="line">     * Fair version of tryAcquire.  Don&apos;t grant access unless</span><br><span class="line">     * recursive call or no waiters or is first.</span><br><span class="line">     */</span><br><span class="line">    @ReservedStackAccess</span><br><span class="line">    protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">        final Thread current = Thread.currentThread();</span><br><span class="line">        int c = getState();</span><br><span class="line">        if (c == 0) &#123;</span><br><span class="line">            if (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">                compareAndSetState(0, acquires)) &#123;</span><br><span class="line">                setExclusiveOwnerThread(current);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">            int nextc = c + acquires;</span><br><span class="line">            if (nextc &lt; 0)</span><br><span class="line">                throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">            setState(nextc);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码中可以看到不管是公平锁还是非公平锁再获取不到锁的时候，都没有自旋。区别在于非公平锁在获取锁的时候，会先获取一下锁，而公平锁会先判断队列中有没有。</p><p>同时在代码中也没有看到获取不到锁就入队，难道会在外面自旋重试？看下AbstractQueuedSynchronizer中代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Acquires in exclusive mode, ignoring interrupts.  Implemented</span><br><span class="line"> * by invoking at least once &#123;@link #tryAcquire&#125;,</span><br><span class="line"> * returning on success.  Otherwise the thread is queued, possibly</span><br><span class="line"> * repeatedly blocking and unblocking, invoking &#123;@link</span><br><span class="line"> * #tryAcquire&#125; until success.  This method can be used</span><br><span class="line"> * to implement method &#123;@link Lock#lock&#125;.</span><br><span class="line"> *</span><br><span class="line"> * @param arg the acquire argument.  This value is conveyed to</span><br><span class="line"> *        &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and</span><br><span class="line"> *        can represent anything you like.</span><br><span class="line"> */</span><br><span class="line">public final void acquire(int arg) &#123;</span><br><span class="line">    if (!tryAcquire(arg) &amp;&amp;</span><br><span class="line">        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line">        selfInterrupt();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这里可以看到获取不到锁，就直接入队了。</p><p>2、因为AQS中的state使用int类型存储，最大到2^31-1。</p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Sentry：如何从数据存储中获得更强的一致性</title>
    <url>/sentry-how-to-get-stronger-consistency-out-of-a-datastore.html</url>
    <content><![CDATA[<blockquote><p>翻译自：How to Get Stronger Consistency Out of a Datastore<br>地址：<a href="https://blog.sentry.io/2019/09/17/how-to-get-stronger-consistency-out-of-a-datastore" target="_blank" rel="noopener">https://blog.sentry.io/2019/09/17/how-to-get-stronger-consistency-out-of-a-datastore</a></p></blockquote><a id="more"></a><p>Sentry的首要工作是接收、解析用户的异常信息。当用户异常信息大量上报时，Sentry的流量将达到高峰。同时，提供<code>近实时</code>的错误追踪，对于用户是有帮助的。</p><p>这里有两个相互排斥的地方：</p><ul><li>事件（Event）提取服务必须在各种负载的情况下都具有响应快速且可伸缩的能力。</li><li>Sentry用户必须近实时地可以看到异常信息。</li></ul><p>为了能够应对流量高峰，Sentry从客户端接收事件，并异步执行一系列处理。 因此，这些处理不一定客户端接收到HTTP响应之前完成。</p><p>其中两个阶段包括在Sentry主存储器(ClickHouse)上保存事件和发送通知、调用插件等的后处理任务（post process task）。</p><blockquote><p>下文中的后处理指的都是post process</p></blockquote><p><img data-src="/images/how-to-get-stronger-consistency-out-of-a-datastore/post_process.png" alt></p><p>在事件保存到ClickHouse之前，我们先将事件插入到Kafka主题中。一些消费者从该主题中读取并以批量插入的方式写入到ClickHouse中。</p><p>在保存了事件之后，我们触发了上面讨论的后处理任务，它需要从ClickHouse读取最新的事件(比如历史数据和我们刚刚处理的事件)才能正常工作。</p><p>等等。“事件保存后？”。在尝试读取事件之前，我们如何确定该事件已被保存到ClickHouse中？好吧，我们不能完全确定。最后，事件提取任务只是将事件保存到Kafka主题中。</p><p>为了确保事件在我们尝试读取之前已经被存储(持久化)，我们需要一个提供顺序一致性模型的存储系统（假设事件提取和后处理发生在单独的进程中），或者读写一致性模型，如果两个操作在同一进程中发生。 （有关<a href="https://jepsen.io/consistency" target="_blank" rel="noopener">一致性模型</a>的更多信息。）</p><p>如果一个存储系统的写操作是异步发生的，而读操作与写操作过程不是同步的，那么这个存储系统就不能提供这些保证。因此，我们需要用不同的架构来缓解这个问题。</p><p>我们可以把这个问题分成两部分:</p><ul><li>当后期处理任务尝试读取时，事件可能根本没有到达ClickHouse。作为一种解决方案，后期处理任务需要等待事件通过Kafka到达ClickHouse之后再进行。</li><li>即使在对ClickHouse的写操作发生之后再运行处理后任务，我们也依赖于ClickHouse的一致性保证。ClickHouse是分布式和有<a href="https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/" target="_blank" rel="noopener">副本</a>的，默认情况下不提供自己的读后写一致性。我们需要确保从已经接收到我们想要读取的事件的副本中读取。</li></ul><h1>写入ClickHouse后，触发后处理程序</h1><p>解决这个问题相当于在运行后处理逻辑之前，等待一个主题一个Kafka消费者<code>消费并提交</code>事件。</p><p>对于这个问题，有下面几种解决办法:</p><ul><li>使用<a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html" target="_blank" rel="noopener">分布式锁框架</a>使后处理程序等待。虽然这可以工作，但它需要我们在架构中添加另一个分布式系统框架，从而增加复杂性。</li><li>在写入ClickHouse之后，让<a href="https://blog.sentry.io/2019/05/16/introducing-snuba-sentrys-new-search-infrastructure/" target="_blank" rel="noopener">Snuba</a>触发后处理任务。这个解决方案有一个重要的架构含义，Snuba将依赖于Sentry(而不是相反)。添加这种附加依赖关系不是我们所期望的。</li><li>使用Kafka __consumer_offset主题<a href="https://kafka.apache.org/0110/documentation.html#impl_offsettracking" target="_blank" rel="noopener">使后处理任务等待</a>。 该策略与我们构建的解决方案没有什么不同。主要问题是实践。例如，我们用来访问Kafka的库并没有提供一个抽象来解码关于该主题的消息。</li><li>将完整的事件传递给需要它的后处理任务，而不是从数据库中重新加载数据。我们实际上是这样做的。不幸的是，这还不够，因为后处理任务需要运行需要最新存储的聚合查询。</li></ul><h1>同步消费</h1><p>我们没有使用这四个解决方案，而是构建了一个系统，该系统允许Kafka消费者暂停自己并等待另一个消费者（在独立消费组上）提交偏移量，然后再使用相同的消息。</p><p><img data-src="/images/how-to-get-stronger-consistency-out-of-a-datastore/sync_consumer.png" alt></p><p>如上图所示，消费事件主题中的事件将触发后处理任务。我们希望只有当Snuba事件消费者将事件存储到ClickHouse时，处理后任务组件才能处理事件，以便处理后任务可以读取事件。</p><p>为了实现这一点，我们需要为Snuba提供一种方式，以便在事件存储到ClickHouse时进行广告（advertise）。广告（advertisement）通过另一个Kafka主题(commit log topic)来传递。Snuba事件使用者在提交偏移量后在提交主题上写入。</p><p>以下代码段是有关提交日志主题的有效负载示例。消息的关键字通过提供主题，分区和组来标识事件主题。有效负载本身就是要提交的偏移量。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">key: events:0:snuba-consumers #topic:partition:group</span><br><span class="line">payload: 70</span><br></pre></td></tr></table></figure><p>启动同步消费者时，需要从提交日志主题重新加载所有分区的状态（最后提交的偏移量）。为了使此过程快速进行，提交日志主题是一个压缩的主题，并且初始偏移量设置为最早的（最早的提交偏移量）。</p><p>由于我们仅在Kafka消息存储在ClickHouse中时才提交它们，因此这是我们需要的解决方案；它是由我们的<a href="https://github.com/getsentry/batching-kafka-consumer" target="_blank" rel="noopener">批处理Kafka消费者</a>执行的。</p><p>现在，我们在Kafka中有一个主题，它告诉我们通过Snuba Consumer从每个分区消费的偏移量是多少。因此，只有在消费者处理了偏移量后，我们才需要对事件进行后处理。</p><p>同步消费者处理协调。 该消费者同时读取事件主题和提交日志主题（在两个独立的线程上）。 它在内部运行状态机，该状态机跟踪与提交日志的最大偏移，并仅从事件主题消费直到追上提交日志中的偏移（watermark）。</p><p>当同步消费者赶上分区的提交日志中的最新偏移量时，它将停止消费该分区中的事件，直到提交了更多事件为止。</p><p>这个解决方案是可行的，但是，作为这个问题的任何解决方案，在可用性方面都存在妥协。如果流的存储部分被延迟，读取就会被暂停，处理后任务也是如此。</p><h1>确保ClickHouse在副本上复制了我们的事件</h1><p>ClickHouse是一个分布式数据库，具有多主、最终一致的异步复制。这句话很很宽泛，所以让我们来分析一下它与当前问题的关联:</p><ul><li><a href="https://clickhouse.yandex/docs/en/operations/table_engines/distributed/" target="_blank" rel="noopener">分布式数据库</a>→在这种情况下，“分布式数据库”意味着我们将表分区到多个节点上。当ClickHouse接收到一批要写入的行时，默认情况下，它将对这些行进行分区并异步地将它们发送到正确的分区。当写入端收到响应时，可能未将批处理写入所有分区。</li><li>复制是异步的，并且最终是一致的→读取可以发生在任何副本上，使用默认的负载平衡模式。在读取时，我们可能会遇到过时的数据，因为我们读取的副本可能未收到最新的写入数据。</li><li>多主复制→写可以发生在任何节点上，并且可能不会以相同的顺序应用在所有副本上。最后，合并处理确保所有副本上的数据是一致的。在写入一个节点和一个副本之后，ClickHouse返回(默认情况下)。</li></ul><p>即使我们在开始后处理之前等待Kafka提交(如上所述)，我们仍然可以从ClickHouse副本中读到不是最新的数据;以上的解决方案仍然不够。</p><p>幸运的是，ClickHouse的灵活性更高，它使我们能够为每个查询提供更强的一致性保证，而不会损害不需要强一致性的查询的性能。</p><p>最初的想法是<a href="https://clickhouse.tech/docs/en/operations/settings/settings/#settings-select_sequential_consistency" target="_blank" rel="noopener">结合</a>insert_quorum和select_sequential_consistency设置，这将保证给定数量的副本在返回之前收到更新。该组合设置可以保证我们查询的是最新的副本。</p><p>主要问题是select_sequential_consistency不能保证负载平衡器选择一个最新的副本。相反，如果所选择的副本在任何写入过程中都不是最新的，查询就会失败——这对我们不起作用。</p><p>因此，我们将问题一分为二，以探索不同的解决方案:</p><h2 id="如何确保读取的副本是最新的">如何确保读取的副本是最新的?</h2><p>当我们需要这种保证时(不是所有查询都需要)，我们使用in_order<a href="https://clickhouse.tech/docs/en/operations/settings/settings/#load_balancing-in_order" target="_blank" rel="noopener">负载均衡模式</a>。该模式驱动负载均衡器按照配置中定义的顺序选择健康的副本。因此，只要第一个副本启动并运行，负载均衡器就会选择它。我们可以对读和写都这样做，本质上是对同一个副本进行读写，只要它运行状况良好。这个副本显然是最新的。</p><h2 id="我们如何确保所有分区在读取前都已写入批处理？">我们如何确保所有分区在读取前都已写入批处理？</h2><p>在写入时，ClickHouse为我们提供了另一个方便的选项:insert_distributed_sync，它将分区设置为同步运行(而不是异步运行)。客户端只有在所有分区都收到写操作之后才会收到确认，这样就消除了读取器从非最新分区读取的风险。</p><h2 id="顺序一致性">顺序一致性</h2><p>这两个解决方案产生了一个一致性模型，该模型表面上类似于顺序一致性。通过通过同一个节点进行读写，所有的写操作看起来都是按一个总的顺序进行的。客户端读取事件，读取的都是最新的状态。</p><blockquote><p>我们是否打破了CAP定理？没有。</p></blockquote><p>我们选择一致性并牺牲可用性了吗？不，我们仍然依赖可用性。只要所有副本都在运行，这就是系统提供的一致性模型（这意味着系统不保证此一致性模型）。如果我们在副本上进行写操作并且在读取之前就死了，则不能保证负载均衡器转到已经收到该写操作的副本。我们不能说我们保证<a href="https://jepsen.io/consistency/models/sequential" target="_blank" rel="noopener">顺序</a>一致性或<a href="https://jepsen.io/consistency/models/read-your-writes" target="_blank" rel="noopener">读写</a>一致性，尽管这是我们经常达到的结果。</p><p>这是性能问题吗?在一定程度上是的。对同一个副本的读写显然会将存储性能绑定到该副本，但到目前为止，它已经足够好了。</p><p>并非所有读取都需要保持一致，因此查询时何时使用in_order负载平衡由客户端决定。这种解决方案允许在不过度降低性能的情况下实现足够好的一致性。</p><hr><p>到目前为止，我们讨论了如何在大多数情况下从最终一致的数据库中获得更强的一致性。在另一个领域，我们尝试做一些ClickHouse不打算做的事情:在记录写入数据库后更新记录。ClickHouse最适合不可变数据，而Sentry在大多数情况下是不可变的，有一些操作确实需要更新记录的能力。</p>]]></content>
      <categories>
        <category>Sentry</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>翻译</tag>
        <tag>Sentry</tag>
        <tag>Stronger</tag>
        <tag>Consistency</tag>
        <tag>Datastore</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生时代的Spring Boot</title>
    <url>/spring-boot-clound-native-by-graalvm.html</url>
    <content><![CDATA[<p>云原生时代的Spring Boot/Java</p><a id="more"></a><p>Spring Boot毫无疑问是Java后端开发的第一大框架，基于Spring Boot有着一套完整的工具链，各种各样的starter。对于日常业务开发而言，可以说是轮子很全。</p><p>但随着云原生时代的到来，Spring Boot应用或者说是Java应用却暴露出了一些问题，其中比较突出的有：</p><ul><li>启动慢</li><li>应用内存占用多</li></ul><p>其中启动慢的主要原因：代码编译。</p><p>当然对于Spring Boot来说，Bean实例注入也会花费一定的时间，但花费时间相比编译会小的多。大家可以通过开启延迟初始化试试。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring:</span><br><span class="line">  main:</span><br><span class="line">    lazy-initialization: true</span><br></pre></td></tr></table></figure><blockquote><p>Spring Boot 2.2开始支持。</p></blockquote><p>个人本地开启延迟初始化之后，启动能快了1~2秒，整个启动时间10秒左右。</p><blockquote><p>测试机配置：i7-6500U 2.50@GHz 内存:16G</p></blockquote><p>内存占用多主要是内存占用后不会归还操作系统，这个正在逐步改善：</p><ul><li>G1 JDK12及之后 已支持</li><li>ZGC JDK13及之后 已支持</li></ul><blockquote><p>由于Java语言的特性及Spring Boot的一些实现方式，决定了即便是开启了G1/ZGC的未使用内存及时归还操作系统，Spring Boot的内存占用，仍然远大于Golang这种编译型语言。</p></blockquote><p>2017年9月，Java 9发布，在Java 9中引入了<a href="https://openjdk.java.net/jeps/295" target="_blank" rel="noopener">AOT（Ahead-of-Time Compilation）</a>。</p><blockquote><p>AOT在内部使用是通过GraalVM来生成代码的。</p></blockquote><p>但对于普通用户而言通过Java的AOT去编译Spring程序还是不可行的。</p><p>那么有没有一种比较优雅的解决方案呢？既能使用Spring Boot又能像Golang一样启动快、内存占用低？</p><p>有朋友可能想到了<a href="https://quarkus.io/" target="_blank" rel="noopener">Quarkus</a>、<a href="https://quarkus.io/" target="_blank" rel="noopener">Micronaut</a>，但这两个框架如果是从头开始开发，可以考虑一下，但还是要注意两点：</p><ul><li>需要去学习使用</li><li>某些库有可能不支持</li></ul><p>其实，Java想要解决云原生时代的问题，目前的方案基本都是基于GraalVM来的，不管是Quarkus还是Micronaut都是。</p><p>那么，Spring Boot有没有类似的方案呢？</p><p>答案是有的。</p><p>在<a href="%E8%BF%99%E4%B8%AA%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%8A%B6%E6%80%81%E6%98%AFalpha">spring-projects-experimental</a> Organizations下有这么一个项目：<a href="https://github.com/spring-projects-experimental/spring-graalvm-native" target="_blank" rel="noopener">spring-graalvm-native</a></p><p>目前已发布到0.7.0 release，不过从github的文档中可以看到这个项目的状态仍然是alpha，也就是说目前用到生产中还是为时过早。</p><p><img data-src="/images/spring-graalvm-native/alpha.png" alt></p><p>希望能早日spring-graalvm-native能早日发布生产可用版本吧。</p><p>graalvm+AOT如此美好？</p><p>其实，GraalVM目前来看还是有一些局限的：</p><p>Not Supported</p><ul><li>Dynamic Class Loading/Unloading</li><li>Runtime Bytecode Generation *</li><li>InvokeDynamic Bytecode and Method Handles</li><li>…</li></ul><p>Require Configuration</p><ul><li>Resource Access</li><li>Reflection</li><li>Dynamic Proxy（JDK，not CGLIB）</li><li>JNI (Java Native Interface)</li><li>…</li></ul><p>更详细限制可以看：</p><p><a href="https://github.com/oracle/graal/blob/master/substratevm/LIMITATIONS.md" target="_blank" rel="noopener">https://github.com/oracle/graal/blob/master/substratevm/LIMITATIONS.md</a></p><p>同时，由于提前编译无法像JIT那样获取到运行时的信息，所以在做Profile-Guided Optimization，PGO时，会更麻烦。</p><p>具体做法：<a href="https://www.graalvm.org/docs/release-notes/19_2/" target="_blank" rel="noopener">https://www.graalvm.org/docs/release-notes/19_2/</a></p><p>JIT会做的典型的PGO<a href="#fnref:1"><sup>1</sup></a>：</p><ul><li><p>type-feedback optimization：主要针对多态的面向对象程序来做优化。根据profile收集到的receiver type信息来把原本多态的虚方法调用点（virtual method call site）或属性访问点（property access site）根据类型来去虚化（devirtualize）。</p></li><li><p>single-value profiling：这个相对少见一些。它的思路是有些参数、函数返回值可能在一次运行中只会遇到一个具体值。如果是这样的话可以把那个具体值给记录下来，然后在JIT编译时把它当作常量来做优化，于是常见的常量相关优化（常量折叠、条件常量传播等）就可以针对一个静态意义上本来不是常量的值来做了。branch-profile-based code scheduling：主要目的是把“热”的（频繁执行的）代码路径集中放在一起，而把“冷”的（不频繁执行的）代码路径放到别的地方。AOT编译的话常常会利用一些静态的启发条件来猜测哪些路径比较热，或者让用户指定哪些路径比较热（例如likely()/unlikely()宏），而JIT搭配PGO的话可以有比较准确的路径热度信息，对应可以做的优化也就更吻合实际执行情况，于是效果会更好。</p></li><li><p>profile-guided inlining heuristics：根据profile信息得知函数调用点的热度，从而影响内联决策——对某个调用点，到底值不值得把目标函数内联进来。</p></li><li><p>implicit exception：隐式异常，例如Java/C#的空指针异常检查，又例如Java/C#的除以零检查。这些异常如果在某块代码里从来没有发生过，就可以用更快的方式来实现，而不必生成显式检查代码。但如果在某块代码经常发生这种异常，则显式检查会更快。</p></li></ul><p>附录：</p><div id="fnref:1">1.</div>JIT会做的典型的PGO<p><a href="https://www.zhihu.com/question/52572852%E2%86%A9%EF%B8%8E" target="_blank" rel="noopener">https://www.zhihu.com/question/52572852↩︎</a></p><p>个人思考：</p><p>其实，通过openjdk jeps及spring boot的一些实验性的项目可以看出，Java正在实现一些新的特性：比如本文提到的AOT,<a href="https://openjdk.java.net/projects/loom/" target="_blank" rel="noopener">Loom</a>来解决Java的一些痛点。</p><p>但这些新的特性具体什么时候能用于生产还是一个未知数。</p><p>相对于Golang，在使用Java的过程中，我个人感觉有以下几个痛点：</p><ul><li>没有协程，无法轻量的异步。</li><li>也正是没有协程，IO请求的阻塞，会导致线程上下文的切换，成本太高。</li><li>内存占用过高</li><li>没有Context，调用方请求取消，感知不到；调用别人的时候，也没有办法很好的传递调用状态及请求取消。</li></ul>]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Spring</tag>
        <tag>Cloud</tag>
        <tag>Native</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Go Select 实现分析</title>
    <url>/go-select.html</url>
    <content><![CDATA[<blockquote><p>Go Select</p></blockquote><a id="more"></a><p>很多 C 语言或者 Unix 开发者听到 <code>select</code> 想到的都是系统调用，而谈到 I/O 模型时最终大都会提到基于 <code>select</code>、<code>poll</code> 和 <code>epoll</code> 等函数构建的 IO 多路复用模型。Go 语言的 <code>select</code> 与 C 语言中的 <code>select</code> 有着比较相似的功能。本节会介绍 Go 语言 <code>select</code> 常见的现象、数据结构以及四种不同情况下的实现原理。</p><p><font color="DeepPink"><strong>C 语言中的 <code>select</code> 关键字可以同时监听多个文件描述符的可读或者可写的状态，Go 语言中的 <code>select</code> 关键字也能够让 Goroutine 同时等待多个 Channel 的可读或者可写，在多个文件或者 Channel 发生状态改变之前，<code>select</code> 会一直阻塞当前线程或者 Goroutine。</strong></font></p><p><img data-src="/images/go-select/Golang-Select-Channels.png" alt></p><p><code>select</code> 是一种与 <code>switch</code> 相似的控制结构，与 <code>switch</code> 不同的是，<code>select</code> 中虽然也有多个 <code>case</code>，但是这些 <code>case</code> 中的表达式必须都是 Channel 的收发操作。下面的代码就展示了一个包含 Channel 收发操作的 <code>select</code> 结构：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func fibonacci(c, quit chan int) &#123;</span><br><span class="line">	x, y := 0, 1</span><br><span class="line">	for &#123;</span><br><span class="line">		select &#123;</span><br><span class="line">		case c &lt;- x:</span><br><span class="line">			x, y = y, x+y</span><br><span class="line">		case &lt;-quit:</span><br><span class="line">			fmt.Println(&quot;quit&quot;)</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述控制结构会等待 <code>c &lt;- x</code> 或者 <code>&lt;-quit</code> 两个表达式中任意一个的返回。无论哪一个表达式返回都会立刻执行 <code>case</code> 中的代码，当 <code>select</code> 中的两个 <code>case</code> 同时被触发时，就会随机选择一个 <code>case</code> 执行。</p><h1>现象</h1><p>当我们在 Go 语言中使用 <code>select</code> 控制结构时，会遇到两个有趣的现象：</p><ul><li><code>select</code> 能在 Channel 上进行非阻塞的收发操作；</li><li><code>select</code> 在遇到多个 Channel 同时响应时会随机挑选 <code>case</code> 执行；</li></ul><p>这两个现象是学习 <code>select</code> 时经常会遇到的，我们来深入了解具体的场景并分析这两个现象背后的设计原理。</p><h2 id="非阻塞的收发">非阻塞的收发</h2><p>在通常情况下，<code>select</code> 语句会阻塞当前 Goroutine 并等待多个 Channel 中的一个达到可以收发的状态。但是如果 <code>select</code> 控制结构中包含 default 语句，那么这个 <code>select</code> 语句在执行时会遇到以下两种情况：</p><ul><li>当存在可以收发的 Channel 时，直接处理该 Channel 对应的 <code>case</code></li><li>当不存在可以收发的 Channel 是，执行 <code>default</code> 中的语句；</li></ul><p>当我们运行下面的代码时就不会阻塞当前的 Goroutine，它会直接执行 <code>default</code> 中的代码并返回。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">	ch := make(chan int)</span><br><span class="line">	select &#123;</span><br><span class="line">	case i := &lt;-ch:</span><br><span class="line">		println(i)</span><br><span class="line"></span><br><span class="line">	default:</span><br><span class="line">		println(&quot;default&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ go run main.go</span><br><span class="line">default</span><br></pre></td></tr></table></figure><p>只要我们稍微想一下，就会发现 Go 语言设计的这个现象就非常合理。<code>select</code> 的作用就是同时监听多个 <code>case</code> 是否可以执行，如果多个 Channel 都不能执行，那么运行 <code>default</code> 中的代码也是理所当然的。</p><p>非阻塞的 Channel 发送和接收操作还是很有必要的，在很多场景下我们不希望向 Channel 发送消息或者从 Channel 中接收消息会阻塞当前 Goroutine，我们只是想看看 Channel 的可读或者可写状态。下面就是一个常见的例子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">errCh := make(chan error, len(tasks))</span><br><span class="line">wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">wg.Add(len(tasks))</span><br><span class="line">for i := range tasks &#123;</span><br><span class="line">    go func() &#123;</span><br><span class="line">        defer wg.Done()</span><br><span class="line">        if err := tasks[i].Run(); err != nil &#123;</span><br><span class="line">            errCh &lt;- err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case err := &lt;-errCh:</span><br><span class="line">    return err</span><br><span class="line">default:</span><br><span class="line">    return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面这段代码中，我们不关心到底多少个任务执行失败了，只关心是否存在返回错误的任务，最后的 <code>select</code> 语句就能很好地完成这个任务。然而使用 <code>select</code> 的语法不是最原始的设计，它在最初版本使用 <code>x, ok := &lt;-c</code> 的语法实现非阻塞的收发，以下是与非阻塞收发的相关提交：</p><ul><li><a href="https://github.com/golang/go/commit/79fbbe37a76502e6f5f9647d2d82bab953ab1546#diff-fb0a5ae9dd70f0a43038d55c0204fdff" target="_blank" rel="noopener">select default</a> 提交支持了 <code>select</code> 语句中的 <code>default</code> 情况<a href="#fnref:1"><sup>1</sup></a>；</li><li><a href="https://github.com/golang/go/commit/5038792837355abde32f2e9549ef132fc5ffbd16" target="_blank" rel="noopener">gc: special case code for single-op blocking and non-blocking selects</a> 提交引入了基于 <code>select</code> 的非阻塞收发的特性<a href="#fnref:2"><sup>2</sup></a>。</li><li><a href="https://github.com/golang/go/commit/cb584707af2d8803adba88fd9692e665ecd2f059" target="_blank" rel="noopener">gc: remove non-blocking send, receive syntax</a> 提交将 <code>x, ok := &lt;-c</code> 语法删除删除<a href="#fnref:3"><sup>3</sup></a>；</li><li><a href="https://github.com/golang/go/commit/8bf34e335686816f7fe7e28614b2c7a3e04e9e7c" target="_blank" rel="noopener">gc, runtime: replace closed© with x, ok := &lt;-c</a> 提交使用 <code>x, ok := &lt;-c</code> 语法替代 <code>closed©</code> 语法判断 Channel 的关闭状态<a href="#fnref:4"><sup>4</sup></a>；</li></ul><p>我们可以从上面的几个提交中看到非阻塞收发从最初到现在的演变。</p><h2 id="随机执行">随机执行</h2><p>另一个使用 <code>select</code> 遇到的情况是同时有多个 <code>case</code> 就绪时，<code>select</code> 会选择那个 <code>case</code> 执行的问题，我们通过下面的代码可以简单了解一下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">	ch := make(chan int)</span><br><span class="line">	go func() &#123;</span><br><span class="line">		for range time.Tick(1 * time.Second) &#123;</span><br><span class="line">			ch &lt;- 0</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	for &#123;</span><br><span class="line">		select &#123;</span><br><span class="line">		case &lt;-ch:</span><br><span class="line">			println(&quot;case1&quot;)</span><br><span class="line">		case &lt;-ch:</span><br><span class="line">			println(&quot;case2&quot;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ go run main.go</span><br><span class="line">case1</span><br><span class="line">case2</span><br><span class="line">case1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>从上述代码输出的结果中我们可以看到，<code>select</code> 在遇到多个 <code>&lt;-ch</code> 同时满足可读或者可写条件时会随机选择一个 <code>case</code> 执行其中的代码。</p><p>这个设计是在十多年前被 <a href="https://github.com/golang/go/commit/cb9b1038db77198c2b0961634cf161258af2374d" target="_blank" rel="noopener">select</a> 提交<a href="#fnref:5"><sup>5</sup></a>引入并一直保留到现在的，虽然中间经历过一些修改<a href="#fnref:6"><sup>6</sup></a>，但是语义一直都没有改变。在上面的代码中，两个 <code>case</code> 都是同时满足执行条件的，如果我们按照顺序依次判断，那么后面的条件永远都会得不到执行，而随机的引入就是为了避免饥饿问题的发生。</p><h1>数据结构</h1><p><code>select</code> 在 Go 语言的源代码中不存在对应的结构体，但是 <code>select</code> 控制结构中的 <code>case</code> 却使用 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L28-L34" target="_blank" rel="noopener">runtime.scase</a> 结构体来表示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type scase struct &#123;</span><br><span class="line">	c           *hchan</span><br><span class="line">	elem        unsafe.Pointer</span><br><span class="line">	kind        uint16</span><br><span class="line">	pc          uintptr</span><br><span class="line">	releasetime int64</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为非默认的 <code>case</code> 中都与 Channel 的发送和接收有关，所以 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L28-L34" target="_blank" rel="noopener">runtime.scase</a> 结构体中也包含一个 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L32-L51" target="_blank" rel="noopener">runtime.hchan</a> 类型的字段存储 <code>case</code> 中使用的 Channel；除此之外，<code>elem</code> 是接收或者发送数据的变量地址、<code>kind</code> 表示 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L28-L34" target="_blank" rel="noopener">runtime.scase</a> 的种类，总共包含以下四种：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">const (</span><br><span class="line">	caseNil = iota</span><br><span class="line">	caseRecv</span><br><span class="line">	caseSend</span><br><span class="line">	caseDefault</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这四种常量分别表示不同类型的 <code>case</code>，相信它们的命名已经能够充分帮助我们理解它们的作用了，所以这里也不一一介绍了。</p><h1>实现原理</h1><p><code>select</code> 语句在编译期间会被转换成 <code>OSELECT</code> 节点。每一个 <code>OSELECT</code> 节点都会持有一组 <code>OCASE</code> 节点，如果 <code>OCASE</code> 的执行条件是空，那就意味着这是一个 <code>default</code> 节点:</p><p><img data-src="/images/go-select/golang-oselect-and-ocases.png" alt></p><p>上图展示的就是 <code>select</code> 语句在编译期间的结构，每一个 OCASE 既包含执行条件也包含满足条件后执行的代码。</p><p>编译器在中间代码生成期间会根据 <code>select</code> 中 <code>case</code> 的不同对控制语句进行优化，这一过程都发生在 <a href="https://github.com/golang/go/blob/c729116332ffb66a21dd587e3ee003cb8d0b16fe/src/cmd/compile/internal/gc/select.go#L108-L370" target="_blank" rel="noopener">cmd/compile/internal/gc.walkselectcases</a> 函数中，我们在这里会分四种情况介绍处理的过程和结果：</p><ul><li><code>select</code> 不存在任何的 <code>case</code>；</li><li><code>select</code> 只存在一个 <code>case</code>；</li><li><code>select</code> 存在两个 <code>case</code>，其中一个 <code>case</code> 是 <code>default</code>；</li><li><code>select</code> 存在多个 <code>case</code>；</li></ul><p>上述的四种情况不仅会涉及编译器的重写和优化，还会涉及 Go 语言的运行时机制，我们会从编译期间和运行时两方面分析上述情况。</p><h2 id="直接阻塞">直接阻塞</h2><p>首先介绍的是最简单的情况，也就是当 <code>select</code> 结构中不包含任何 <code>case</code> 时编译器是如何进行处理的，我们截取 <a href="https://github.com/golang/go/blob/c729116332ffb66a21dd587e3ee003cb8d0b16fe/src/cmd/compile/internal/gc/select.go#L108-L370" target="_blank" rel="noopener">cmd/compile/internal/gc.walkselectcases</a> 函数的前几行代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func walkselectcases(cases *Nodes) []*Node &#123;</span><br><span class="line">	n := cases.Len()</span><br><span class="line"></span><br><span class="line">	if n == 0 &#123;</span><br><span class="line">		return []*Node&#123;mkcall(&quot;block&quot;, nil, nil)&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码非常简单并且容易理解，它直接将类似 <code>select {}</code> 的空语句转换成调用 <a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/select.go#L104-L106" target="_blank" rel="noopener">runtime.block</a> 函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func block() &#123;</span><br><span class="line">	gopark(nil, nil, waitReasonSelectNoCases, traceEvGoStop, 1)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/select.go#L104-L106" target="_blank" rel="noopener">runtime.block</a> 函数的实现非常简单，它会调用 <a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/proc.go#L287-L305" target="_blank" rel="noopener">runtime.gopark</a> 让出当前 Goroutine 对处理器的使用权，传入的等待原因是 <code>waitReasonSelectNoCases</code>。</p><p>简单总结一下，空的 <code>select</code> 语句会直接阻塞当前的 Goroutine，导致 Goroutine 进入无法被唤醒的永久休眠状态。</p><h2 id="单一管道">单一管道</h2><p>如果当前的 <code>select</code> 条件只包含一个 <code>case</code>，那么就会将 <code>select</code> 改写成 <code>if</code> 条件语句。下面展示了原始的 <code>select</code> 语句和被改写、优化后的代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 改写前</span><br><span class="line">select &#123;</span><br><span class="line">case v, ok &lt;-ch: // case ch &lt;- v</span><br><span class="line">    ...    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 改写后</span><br><span class="line">if ch == nil &#123;</span><br><span class="line">    block()</span><br><span class="line">&#125;</span><br><span class="line">v, ok := &lt;-ch // case ch &lt;- v</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><a href="https://github.com/golang/go/blob/c729116332ffb66a21dd587e3ee003cb8d0b16fe/src/cmd/compile/internal/gc/select.go#L108-L370" target="_blank" rel="noopener">cmd/compile/internal/gc.walkselectcases</a> 在处理单操作 <code>select</code> 语句时，会根据 Channel 的收发情况生成不同的语句。当 <code>case</code> 中的 Channel 是空指针时，就会直接挂起当前 Goroutine 并永久休眠。</p><h2 id="非阻塞操作">非阻塞操作</h2><p>当 <code>select</code> 中仅包含两个 <code>case</code>，并且其中一个是 <code>default</code> 时，Go 语言的编译器就会认为这是一次非阻塞的收发操作。<a href="https://github.com/golang/go/blob/c729116332ffb66a21dd587e3ee003cb8d0b16fe/src/cmd/compile/internal/gc/select.go#L108-L370" target="_blank" rel="noopener">cmd/compile/internal/gc.walkselectcases</a> 函数会对这种情况单独处理，不过在正式优化之前，该函数会将 <code>case</code> 中的所有 Channel 都转换成指向 Channel 的地址。我们会分别介绍非阻塞发送和非阻塞接收时，编译器进行的不同优化。</p><h3 id="发送">发送</h3><p>首先是 Channel 的发送过程，当 <code>case</code> 中表达式的类型是 <code>OSEND</code> 时，编译器会使用 <code>if/else</code> 语句和 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L662-L664" target="_blank" rel="noopener">runtime.selectnbsend</a> 函数改写代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select &#123;</span><br><span class="line">case ch &lt;- i:</span><br><span class="line">    ...</span><br><span class="line">default:</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if selectnbsend(ch, i) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码中最重要的就是 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L662-L664" target="_blank" rel="noopener">runtime.selectnbsend</a> 函数，它为我们提供了向 Channel 非阻塞地发送数据的能力。我们在 Channel 一节介绍了向 Channel 发送数据的 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L157-L278" target="_blank" rel="noopener">runtime.chansend</a> 函数包含一个 <code>block</code> 参数，该参数会决定这一次的发送是不是阻塞的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) &#123;</span><br><span class="line">	return chansend(c, elem, false, getcallerpc())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="接收">接收</h3><p>由于从 Channel 中接收数据可能会返回一个或者两个值，所以接受数据的情况会比发送稍显复杂，不过改写的套路是差不多的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 改写前</span><br><span class="line">select &#123;</span><br><span class="line">case v &lt;- ch: // case v, ok &lt;- ch:</span><br><span class="line">    ......</span><br><span class="line">default:</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 改写后</span><br><span class="line">if selectnbrecv(&amp;v, ch) &#123; // if selectnbrecv2(&amp;v, &amp;ok, ch) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回值数量不同会导致使用函数的不同，两个用于非阻塞接收消息的函数 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L683-L686" target="_blank" rel="noopener">runtime.selectnbrecv</a> 和 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L705-L709" target="_blank" rel="noopener">runtime.selectnbrecv2</a> 只是对 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L448-L579" target="_blank" rel="noopener">runtime.chanrecv</a> 返回值的处理稍有不同：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) &#123;</span><br><span class="line">	selected, _ = chanrecv(c, elem, false)</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) &#123;</span><br><span class="line">	selected, *received = chanrecv(c, elem, false)</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为接收方不需要，所以 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L683-L686" target="_blank" rel="noopener">runtime.selectnbrecv</a> 会直接忽略返回的布尔值，而 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L705-L709" target="_blank" rel="noopener">runtime.selectnbrecv2</a> 会将布尔值回传给调用方。与 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L157-L278" target="_blank" rel="noopener">runtime.chansend</a> 一样，<a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L448-L579" target="_blank" rel="noopener">runtime.chanrecv</a> 也提供了一个 block 参数用于控制这一次接收是否阻塞。</p><h3 id="常见流程">常见流程</h3><p>在默认的情况下，编译器会使用如下的流程处理 <code>select</code> 语句：</p><ul><li>将所有的 <code>case</code> 转换成包含 Channel 以及类型等信息的 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L28-L34" target="_blank" rel="noopener">runtime.scase</a> 结构体；</li><li>调用运行时函数 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 从多个准备就绪的 Channel 中选择一个可执行的 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L28-L34" target="_blank" rel="noopener">runtime.scase</a> 结构体；</li><li>通过 <code>for</code> 循环生成一组 <code>if</code> 语句，在语句中判断自己是不是被选中的 <code>case</code></li></ul><p>一个包含三个 <code>case</code> 的正常 <code>select</code> 语句其实会被展开成如下所示的逻辑，我们可以看到其中处理的三个部分：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">selv := [3]scase&#123;&#125;</span><br><span class="line">order := [6]uint16</span><br><span class="line">for i, cas := range cases &#123;</span><br><span class="line">    c := scase&#123;&#125;</span><br><span class="line">    c.kind = ...</span><br><span class="line">    c.elem = ...</span><br><span class="line">    c.c = ...</span><br><span class="line">&#125;</span><br><span class="line">chosen, revcOK := selectgo(selv, order, 3)</span><br><span class="line">if chosen == 0 &#123;</span><br><span class="line">    ...</span><br><span class="line">    break</span><br><span class="line">&#125;</span><br><span class="line">if chosen == 1 &#123;</span><br><span class="line">    ...</span><br><span class="line">    break</span><br><span class="line">&#125;</span><br><span class="line">if chosen == 2 &#123;</span><br><span class="line">    ...</span><br><span class="line">    break</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>展开后的代码片段中最重要的就是用于选择待执行 <code>case</code> 的运行时函数 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a>，这也是我们要关注的重点。因为这个函数的实现比较复杂， 所以这里分两部分分析它的执行过程：</p><ul><li>执行一些必要的初始化操作并确定 <code>case</code> 的处理顺序；</li><li>在循环中根据 <code>case</code> 的类型做出不同的处理；</li></ul><h4 id="初始化">初始化</h4><p><a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数首先会进行执行必要的初始化操作并决定处理 <code>case</code> 的两个顺序 — 轮询顺序 <code>pollOrder</code> 和加锁顺序 <code>lockOrder</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool) &#123;</span><br><span class="line">	cas1 := (*[1 &lt;&lt; 16]scase)(unsafe.Pointer(cas0))</span><br><span class="line">	order1 := (*[1 &lt;&lt; 17]uint16)(unsafe.Pointer(order0))</span><br><span class="line">	</span><br><span class="line">	scases := cas1[:ncases:ncases]</span><br><span class="line">	pollorder := order1[:ncases:ncases]</span><br><span class="line">	lockorder := order1[ncases:][:ncases:ncases]</span><br><span class="line">	for i := range scases &#123;</span><br><span class="line">		cas := &amp;scases[i]</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	for i := 1; i &lt; ncases; i++ &#123;</span><br><span class="line">		j := fastrandn(uint32(i + 1))</span><br><span class="line">		pollorder[i] = pollorder[j]</span><br><span class="line">		pollorder[j] = uint16(i)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 根据 Channel 的地址排序确定加锁顺序</span><br><span class="line">	...</span><br><span class="line">	sellock(scases, lockorder)</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>轮询顺序 <code>pollOrder</code> 和加锁顺序 <code>lockOrder</code> 分别是通过以下的方式确认的：</p><ul><li>轮询顺序：通过 <a href="https://github.com/golang/go/blob/383b447e0da5bd1fcdc2439230b5a1d3e3402117/src/runtime/stubs.go#L114-L118" target="_blank" rel="noopener">runtime.fastrandn</a> 函数引入随机性；</li><li>加锁顺序：按照 Channel 的地址排序后确定加锁顺序；</li></ul><p>随机的轮询顺序可以避免 Channel 的饥饿问题，保证公平性；而根据 Channel 的地址顺序确定加锁顺序能够避免死锁的发生。这段代码最后调用的 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L45-L54" target="_blank" rel="noopener">runtime.sellock</a> 函数会按照之前生成的加锁顺序锁定 <code>select</code> 语句中包含所有的 Channel。</p><h4 id="循环">循环</h4><p>当我们为 <code>select</code> 语句锁定了所有 Channel 之后就会进入 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数的主循环，它会分三个阶段查找或者等待某个 Channel 准备就绪：</p><p>查找是否已经存在准备就绪的 Channel，即可以执行收发操作；<br>将当前 Goroutine 加入 Channel 对应的收发队列上并等待其他 Goroutine 的唤醒；<br>当前 Goroutine 被唤醒之后找到满足条件的 Channel 并进行处理；<br><a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数会根据不同情况通过 <code>goto</code> 跳转到函数内部的不同标签执行相应的逻辑，其中包括：</p><ul><li><code>bufrecv</code>：可以从缓冲区读取数据；</li><li><code>bufsend</code>：可以向缓冲区写入数据；</li><li><code>recv</code>：可以从休眠的发送方获取数据；</li><li><code>send</code>：可以向休眠的接收方发送数据；</li><li><code>rclose</code>：可以从关闭的 Channel 读取 EOF；</li><li><code>sclose</code>：向关闭的 Channel 发送数据；</li><li><code>retc</code>：结束调用并返回；</li></ul><p>我们先来分析循环执行的第一个阶段，查找已经准备就绪的 Channel。循环会遍历所有的 <code>case</code> 并找到需要被唤起的 runtime.sudog 结构，在这个阶段，我们会根据 <code>case</code> 的四种类型分别处理：</p><ol><li><code>caseNil</code>：当前 <code>case</code> 不包含 Channel；<ul><li>这种 <code>case</code> 会被跳过；</li></ul></li><li><code>caseRecv</code>：当前 <code>case</code> 会从 Channel 中接收数据；<ul><li>如果当前 Channel 的 <code>sendq</code> 上有等待的 Goroutine，就会跳到 <code>recv</code> 标签从 Goroutine 中读取数据；</li><li>如果当前 Channel 的缓冲区不为空，就会跳到 <code>bufrecv</code> 标签处从缓冲区获取数据；</li><li>如果当前 Channel 已经被关闭，就会跳到 <code>rclose</code> 做一些清除的收尾工作；</li></ul></li><li><code>caseSend</code>：当前 <code>case</code> 会向 Channel 发送数据；<ul><li>如果当前 Channel 已经被关，闭就会直接跳到 <code>sclose</code> 标签，触发 <code>panic</code> 尝试中止程序；</li><li>如果当前 Channel 的 <code>recvq</code> 上有等待的 Goroutine，就会跳到 <code>send</code> 标签向 Channel 发送数据；</li><li>如果当前 Channel 的缓冲区存在空闲位置，就会将待发送的数据存入缓冲区；</li></ul></li><li><code>caseDefault</code>：当前 <code>case</code> 为 <code>default</code> 语句；<ul><li>表示前面的所有 <code>case</code> 都没有被执行，这里会解锁所有 Channel 并返回，意味着当前 <code>select</code> 结构中的收发都是非阻塞的；</li></ul></li></ol><p><img data-src="/images/go-select/golang-runtime-selectgo.png" alt></p><p>第一阶段的主要职责是查找所有 <code>case</code> 中 Channel 是否有可以立刻被处理的情况。无论是在包含等待的 Goroutine 还是缓冲区中存在数据，只要满足条件就会立刻处理，如果不能立刻找到活跃的 Channel 就会进入循环的下一阶段，按照需要将当前的 Goroutine 加入到 Channel 的 <code>sendq</code> 或者 <code>recvq</code> 队列中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool) &#123;</span><br><span class="line">	...</span><br><span class="line">	gp = getg()</span><br><span class="line">	nextp = &amp;gp.waiting</span><br><span class="line">	for _, casei := range lockorder &#123;</span><br><span class="line">		casi = int(casei)</span><br><span class="line">		cas = &amp;scases[casi]</span><br><span class="line">		c = cas.c</span><br><span class="line">		sg := acquireSudog()</span><br><span class="line">		sg.g = gp</span><br><span class="line">		sg.c = c</span><br><span class="line"></span><br><span class="line">		switch cas.kind &#123;</span><br><span class="line">		case caseRecv:</span><br><span class="line">			c.recvq.enqueue(sg)</span><br><span class="line">		case caseSend:</span><br><span class="line">			c.sendq.enqueue(sg)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	gopark(selparkcommit, nil, waitReasonSelect, traceEvGoBlockSelect, 1)</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了将当前 Goroutine 对应的 <a href="https://github.com/golang/go/blob/cfe3cd903f018dec3cb5997d53b1744df4e53909/src/runtime/runtime2.go#L342-L368" target="_blank" rel="noopener">runtime.sudog</a> 结构体加入队列之外，这些 <a href="https://github.com/golang/go/blob/cfe3cd903f018dec3cb5997d53b1744df4e53909/src/runtime/runtime2.go#L342-L368" target="_blank" rel="noopener">runtime.sudog</a> 结构体都会被串成链表附着在 Goroutine 上。在入队之后会调用 <a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/proc.go#L287-L305" target="_blank" rel="noopener">runtime.gopark</a> 函数挂起当前 Goroutine 等待调度器的唤醒。</p><p><img data-src="/images/go-select/Golang-Select-Waiting.png" alt></p><p>等到 <code>select</code> 中的一些 Channel 准备就绪之后，当前 Goroutine 就会被调度器唤醒。这时会继续执行 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数的第三阶段，从 <a href="https://github.com/golang/go/blob/cfe3cd903f018dec3cb5997d53b1744df4e53909/src/runtime/runtime2.go#L342-L368" target="_blank" rel="noopener">runtime.sudog</a> 结构体中获取数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool) &#123;</span><br><span class="line">	...</span><br><span class="line">	sg = (*sudog)(gp.param)</span><br><span class="line">	gp.param = nil</span><br><span class="line"></span><br><span class="line">	casi = -1</span><br><span class="line">	cas = nil</span><br><span class="line">	sglist = gp.waiting</span><br><span class="line">	for _, casei := range lockorder &#123;</span><br><span class="line">		k = &amp;scases[casei]</span><br><span class="line">		if sg == sglist &#123;</span><br><span class="line">			casi = int(casei)</span><br><span class="line">			cas = k</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			if k.kind == caseSend &#123;</span><br><span class="line">				c.sendq.dequeueSudoG(sglist)</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				c.recvq.dequeueSudoG(sglist)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		sgnext = sglist.waitlink</span><br><span class="line">		sglist.waitlink = nil</span><br><span class="line">		releaseSudog(sglist)</span><br><span class="line">		sglist = sgnext</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	c = cas.c</span><br><span class="line">	goto retc</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三次遍历全部 <code>case</code> 时，我们会先获取当前 Goroutine 接收到的参数 <code>sudog</code> 结构，我们会依次对比所有 <code>case</code> 对应的 <code>sudog</code> 结构找到被唤醒的 <code>case</code>，获取该 <code>case</code> 对应的索引并返回。</p><p>由于当前的 <code>select</code> 结构找到了一个 <code>case</code> 执行，那么剩下 <code>case</code> 中没有被用到的 <code>sudog</code> 就会被忽略并且释放掉。为了不影响 Channel 的正常使用，我们还是需要将这些废弃的 <code>sudog</code> 从 Channel 中出队。</p><p>当我们在循环中发现缓冲区中有元素或者缓冲区未满时就会通过 <code>goto</code> 关键字跳转到 <code>bufrecv</code> 和 <code>bufsend</code> 两个代码段，这两段代码的执行过程都很简单，它们只是向 Channel 中发送数据或者从缓冲区中获取新数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bufrecv:</span><br><span class="line">	recvOK = true</span><br><span class="line">	qp = chanbuf(c, c.recvx)</span><br><span class="line">	if cas.elem != nil &#123;</span><br><span class="line">		typedmemmove(c.elemtype, cas.elem, qp)</span><br><span class="line">	&#125;</span><br><span class="line">	typedmemclr(c.elemtype, qp)</span><br><span class="line">	c.recvx++</span><br><span class="line">	if c.recvx == c.dataqsiz &#123;</span><br><span class="line">		c.recvx = 0</span><br><span class="line">	&#125;</span><br><span class="line">	c.qcount--</span><br><span class="line">	selunlock(scases, lockorder)</span><br><span class="line">	goto retc</span><br><span class="line"></span><br><span class="line">bufsend:</span><br><span class="line">	typedmemmove(c.elemtype, chanbuf(c, c.sendx), cas.elem)</span><br><span class="line">	c.sendx++</span><br><span class="line">	if c.sendx == c.dataqsiz &#123;</span><br><span class="line">		c.sendx = 0</span><br><span class="line">	&#125;</span><br><span class="line">	c.qcount++</span><br><span class="line">	selunlock(scases, lockorder)</span><br><span class="line">	goto retc</span><br></pre></td></tr></table></figure><p>这里在缓冲区进行的操作和直接调用 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L157-L278" target="_blank" rel="noopener">runtime.chansend</a> 和 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L448-L579" target="_blank" rel="noopener">runtime.chanrecv</a> 函数差不多，上述两个过程在执行结束之后都会直接跳到 <code>retc</code> 字段。</p><p>两个直接对 Channel 收发的情况会调用 Channel 运行时函数 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L286-L317" target="_blank" rel="noopener">runtime.send</a> 和 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L594-L635" target="_blank" rel="noopener">runtime.recv</a>，这两个函数会直接与处于休眠状态的 Goroutine 打交道：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">recv:</span><br><span class="line">	recv(c, sg, cas.elem, func() &#123; selunlock(scases, lockorder) &#125;, 2)</span><br><span class="line">	recvOK = true</span><br><span class="line">	goto retc</span><br><span class="line"></span><br><span class="line">send:</span><br><span class="line">	send(c, sg, cas.elem, func() &#123; selunlock(scases, lockorder) &#125;, 2)</span><br><span class="line">	goto retc</span><br></pre></td></tr></table></figure><p>不过如果向关闭的 Channel 发送数据或者从关闭的 Channel 中接收数据，情况就稍微有一点复杂了：</p><ul><li>从一个关闭 Channel 中接收数据会直接清除 Channel 中的相关内容；</li><li>向一个关闭的 Channel 发送数据就会直接 <code>panic</code> 造成程序崩溃：</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rclose:</span><br><span class="line">	selunlock(scases, lockorder)</span><br><span class="line">	recvOK = false</span><br><span class="line">	if cas.elem != nil &#123;</span><br><span class="line">		typedmemclr(c.elemtype, cas.elem)</span><br><span class="line">	&#125;</span><br><span class="line">	goto retc</span><br><span class="line"></span><br><span class="line">sclose:</span><br><span class="line">	selunlock(scases, lockorder)</span><br><span class="line">	panic(plainError(&quot;send on closed channel&quot;))</span><br></pre></td></tr></table></figure><p>总体来看，<code>select</code> 语句中的 Channel 收发操作和直接操作 Channel 没有太多出入，只是由于 <code>select</code> 多出了 <code>default</code> 关键字所以会支持非阻塞的收发。</p><h1>小结</h1><p>我们简单总结一下 <code>select</code> 结构的执行过程与实现原理，首先在编译期间，Go 语言会对 <code>select</code> 语句进行优化，它会根据 <code>select</code> 中 <code>case</code> 的不同选择不同的优化路径：</p><ol><li>空的 <code>select</code> 语句会被转换成 <a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/select.go#L104-L106" target="_blank" rel="noopener">runtime.block</a> 函数的调用，直接挂起当前 Goroutine；</li><li>如果 <code>select</code> 语句中只包含一个 <code>case</code>，就会被转换成 <code>if ch == nil { block }; n;</code> 表达式；<ul><li>首先判断操作的 Channel 是不是空的；</li><li>然后执行 <code>case</code> 结构中的内容；</li></ul></li><li>如果 <code>select</code> 语句中只包含两个 <code>case</code> 并且其中一个是 <code>default</code>，那么会使用 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L683-L686" target="_blank" rel="noopener">runtime.selectnbrecv</a> 和 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/chan.go#L662-L664" target="_blank" rel="noopener">runtime.selectnbsend</a> 非阻塞地执行收发操作；</li><li>在默认情况下会通过 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数获取执行 <code>case</code> 的索引，并通过多个 <code>if</code> 语句执行对应 <code>case</code> 中的代码；</li></ol><p>在编译器已经对 <code>select</code> 语句进行优化之后，Go 语言会在运行时执行编译期间展开的 <a href="https://github.com/golang/go/blob/d1969015b4ac29be4f518b94817d3f525380639d/src/runtime/select.go#L118-L497" target="_blank" rel="noopener">runtime.selectgo</a> 函数，该函数会按照以下的流程执行：</p><ol><li>随机生成一个遍历的轮询顺序 <code>pollOrder</code> 并根据 Channel 地址生成锁定顺序 <code>lockOrder</code>；</li><li>根据 <code>pollOrder</code> 遍历所有的 <code>case</code> 查看是否有可以立刻处理的 Channel；<ol><li>如果存在就直接获取 <code>case</code> 对应的索引并返回；</li><li>如果不存在就会创建 <a href="https://github.com/golang/go/blob/cfe3cd903f018dec3cb5997d53b1744df4e53909/src/runtime/runtime2.go#L342-L368" target="_blank" rel="noopener">runtime.sudog</a> 结构体，将当前 Goroutine 加入到所有相关 Channel 的收发队列，并调用 <a href="https://github.com/golang/go/blob/c112289ee4141ebc31db50328c355b01278b987b/src/runtime/proc.go#L287-L305" target="_blank" rel="noopener">runtime.gopark</a> 挂起当前 Goroutine 等待调度器的唤醒；</li></ol></li><li>当调度器唤醒当前 Goroutine 时就会再次按照 <code>lockOrder</code> 遍历所有的 <code>case</code>，从中查找需要被处理的 <a href="https://github.com/golang/go/blob/cfe3cd903f018dec3cb5997d53b1744df4e53909/src/runtime/runtime2.go#L342-L368" target="_blank" rel="noopener">runtime.sudog</a> 结构对应的索引；</li></ol><p><code>select</code> 关键字是 Go 语言特有的控制结构，它的实现原理比较复杂，需要编译器和运行时函数的通力合作。</p><h1>拓展阅读</h1><p><a href="https://man7.org/linux/man-pages/man2/select.2.html" target="_blank" rel="noopener">SELECT(2) · Linux</a></p><div id="fnref:1">1.</div>Ken Thompson. Nov 6, 2008. select default.<p><a href="https://github.com/golang/go/commit/79fbbe37a76502e6f5f9647d2d82bab953ab1546#diff-fb0a5ae9dd70f0a43038d55c0204fdff" target="_blank" rel="noopener">https://github.com/golang/go/commit/79fbbe37a76502e6f5f9647d2d82bab953ab1546#diff-fb0a5ae9dd70f0a43038d55c0204fdff</a> ↩︎</p><div id="fnref:2">2.</div>Russ Cox. Jan 31, 2011. gc: special case code for single-op blocking and non-blocking selects.<p><a href="https://github.com/golang/go/commit/5038792837355abde32f2e9549ef132fc5ffbd16" target="_blank" rel="noopener">https://github.com/golang/go/commit/5038792837355abde32f2e9549ef132fc5ffbd16</a> ↩︎</p><div id="fnref:3">3.</div>Russ Cox. Feb 1, 2011. gc: remove non-blocking send, receive syntax.<p><a href="https://github.com/golang/go/commit/cb584707af2d8803adba88fd9692e665ecd2f059" target="_blank" rel="noopener">https://github.com/golang/go/commit/cb584707af2d8803adba88fd9692e665ecd2f059</a> ↩︎</p><div id="fnref:4">4.</div>Russ Cox. Mar 12, 2011. gc, runtime: replace closed(c) with x, ok := <-c.<p><a href="https://github.com/golang/go/commit/8bf34e335686816f7fe7e28614b2c7a3e04e9e7c" target="_blank" rel="noopener">https://github.com/golang/go/commit/8bf34e335686816f7fe7e28614b2c7a3e04e9e7c</a> ↩︎<p></p><div id="fnref:5">5.</div>Ken Thompson. Jul 25, 2008. select.<p><a href="https://github.com/golang/go/commit/cb9b1038db77198c2b0961634cf161258af2374d" target="_blank" rel="noopener">https://github.com/golang/go/commit/cb9b1038db77198c2b0961634cf161258af2374d</a> ↩︎</p><div id="fnref:6">6.</div>Gustavo Niemeyer. Aug 15, 2011. runtime: fix pseudo-randomness on some selects.<p><a href="https://github.com/golang/go/commit/175849295ce632c2ddeca7024f7c783327b5e571" target="_blank" rel="noopener">https://github.com/golang/go/commit/175849295ce632c2ddeca7024f7c783327b5e571</a> ↩︎</p><h1>原文</h1><p><a href="https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-select/" target="_blank" rel="noopener">https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-select/</a></p></-c.<p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>Select</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Go 并发 : Context</title>
    <url>/go-concurrency-patterns-context.html</url>
    <content><![CDATA[<blockquote><p>翻译自：Go Concurrency Patterns: Context<br>地址：<a href="https://blog.golang.org/context" target="_blank" rel="noopener">https://blog.golang.org/context</a></p></blockquote><a id="more"></a><h1>简介</h1><p>在Go server端，每个请求都是通过新起goroutine来处理。请求处理程序通常会启动其他goroutine来访问后端，例如数据库和RPC服务。处理该请求的goroutine集合通常需要访问特定于请求的值，例如最终用户的身份，授权令牌和请求的时限。当一个请求被取消或超时时，处理该请求的所有goroutine应该迅速退出，以便系统可以回收他们正在使用的资源。</p><p>在Google，我们开发了一个Context包，可以轻松地跨API边界将请求范围（request-scoped）的值，取消信号和截止日期（deadlines）传递给处理请求的所有goroutine。该软件包可作为Context公开使用。本文将介绍如何使用该package。</p><h1>Context</h1><p>Context包的核心是Context类型:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Context跨API边界携带期限(deadline)、取消信号和请求范围(request-scoped)的值。Context的方法是协程安全的。</span><br><span class="line">type Context interface &#123;</span><br><span class="line">    // Done返回一个channel，该channel在Context被取消或超时时关闭。</span><br><span class="line">    Done() &lt;-chan struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">    // Err表示在Done channel关闭后取消此Context的原因。</span><br><span class="line">    Err() error</span><br><span class="line"></span><br><span class="line">    // Deadline返回Context将被取消的时间(如果有的话)。</span><br><span class="line">    Deadline() (deadline time.Time, ok bool)</span><br><span class="line"></span><br><span class="line">    // Value返回与key关联的值(如果没有，返回nil)。</span><br><span class="line">    Value(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更详细的介绍，参见godoc：<a href="https://golang.org/pkg/context/" target="_blank" rel="noopener">https://golang.org/pkg/context/</a></p><p>Done方法返回一个channel，作为代表Context运行的函数的取消信号:当channel关闭时，函数应该放弃它们的工作并返回。Err方法返回一个错误，指示Context被取消的原因。</p><p>因为Done channel只用于接收的原因，Context没有取消方法：接收取消信号的方法与发送信号方法往往不是同一个。特别是，当父操作（parent operation）为子操作（sub-operations）启动goroutines时，这些子操作应该不能取消父操作。相反，WithCancel函数（如下所述）提供了一种取消新的上下文值的方法。</p><p>Context是协程安全的。代码中可以将单个Context传递给任意数量的goroutine，并在取消该Context时可以将信号传递给所有的goroutine。</p><p>最后期限（Deadline）方法允许函数决定他们是否应该开始工作;如果剩下的时间太少，可能就不值得了。代码也可以使用期限（Deadline）来设置I/O操作的超时。</p><p>值（Value）允许Context携带请求范围(request-scoped)的数据。 该数据必须是协程安全的，以便多个goroutine可以同时使用。</p><h1>Derived contexts</h1><p><font color="DeepPink"><strong>Context包提供了从现有Context值派生新Context值的函数。这些值形成一个树:当一个Context被取消时，从它派生的所有Context也被取消。</strong></font></p><p>Background是所有Context树的根;它永远不会被取消:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Background返回一个空Context。它永远不会被取消，没有截止日期，也没有值。</span><br><span class="line">// 后台通常用于main、init和测试，并作为传入请求的顶级上下文。</span><br><span class="line">func Background() Context</span><br></pre></td></tr></table></figure><p>WithCancel和WithTimeout返回派生的Context值，该值可以比父Context早被取消。请求处理程序返回时，通常会取消与传入请求关联的Context。 使用多个副本时，WithCancel对于取消冗余请求也很有用。WithTimeout对于设置对后端服务器的请求的最后期限很有用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// WithCancel返回parent的副本，该副本的parent channel在parent结束后立即关闭。done关闭或调用cancel。</span><br><span class="line">func WithCancel(parent Context) (ctx Context, cancel CancelFunc)</span><br><span class="line"></span><br><span class="line">// CancelFunc取消Context。</span><br><span class="line">type CancelFunc func()</span><br><span class="line"></span><br><span class="line">// WithTimeout返回父对象的副本，该父对象的Done channel会在父对象关闭后立即关闭。</span><br><span class="line">// 调用cancel或超时,关闭Done。 </span><br><span class="line">// 新的上下文截止日期是now + timeout和父级截止日期（如果有）中的较早者。 </span><br><span class="line">// 如果计时器仍在运行，则取消功能将释放其资源。</span><br><span class="line">func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)</span><br></pre></td></tr></table></figure><p>WithValue提供了一种将请求范围的值与Context关联的方法:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// WithValue returns a copy of parent whose Value method returns val for key.</span><br><span class="line">func WithValue(parent Context, key interface&#123;&#125;, val interface&#123;&#125;) Context</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>翻译</tag>
        <tag>Go</tag>
        <tag>Concurrency</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title>学习开源代码该如何入手？</title>
    <url>/how-to-start-learning-open-source-code.html</url>
    <content><![CDATA[<p>消息队列高手课 笔记</p><p>作者：李玥</p><a id="more"></a><ul><li>通过文档了解项目<ul><li>这个项目是干什么的?</li><li>能解决哪些问题?</li><li>适合在哪些场景使用?</li><li>有哪些功能?</li><li>如何使用?</li></ul></li><li>用以点带面的方式来阅读源码<ul><li>最好是带着问题阅读源码，最好是带着问题答案去阅读源码<ul><li>RocketMQ的消息是怎么写到文件里的?</li><li>Kafka的Coordinator是怎么维护消费位置的?</li></ul></li></ul></li></ul><p><a href="/attachments/消息队列高手课/09学习开源代码该如何入手.pdf" target="_blank">学习开源代码该如何入手？</a></p>]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>该如何选择消息队列？</title>
    <url>/how-to-choose-a-message-queue.html</url>
    <content><![CDATA[<p>消息队列高手课 笔记</p><p>作者：李玥</p><a id="more"></a><p>在了解了上面这些开源消息队列各自的特点和优劣势后,我相信你对于消息队列的选择已经可以做到心中有数了。我也总结了几条选择的建议供你参考。</p><ul><li><p>如果说,消息队列并不是你将要构建系统的主角之一,你对消息队列功能和性能都没有很高的要求,只需要一个开箱即用易于维护的产品,我建议你使用RabbitMQ。</p></li><li><p>如果你的系统使用消息队列主要场景是处理在线业务,比如在交易系统中用消息队列传递订单那 RocketMQ的低延迟和金融级的稳定性是你需要的。</p></li><li><p>如果你需要处理海量的消息,像收集日志、监控信息或是前端的埋点这类数据,或是你的应用场景大量使用了大数据、流计算相关的开源产品,那 Kafka是最适合你的消息队列。</p></li></ul><p>如果我说的这些场景和你的场景都不符合,你看了我之前介绍的这些消息队列的特点后,还是不知道如何选择,那就选你最熟悉的吧,毕竟这些产品都能满足大多数应用场景,使用熟悉的产品还可以快速上手不是?</p><p><a href="/attachments/消息队列高手课/02该如何选择消息队列.pdf" target="_blank">该如何选择消息队列？</a></p>]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]关于Go net/http 超时完全指南</title>
    <url>/go-net-http-timeout-sequence-diagram.html</url>
    <content><![CDATA[<blockquote><p>翻译自：The complete guide to Go net/http timeouts<br>地址：<a href="https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/" target="_blank" rel="noopener">https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/</a></p></blockquote><a id="more"></a><p>使用Go编写HTTP服务器或客户端时，超时是最容易出错的最容易发生的事情:一个错误可能在很长一段时间内没有任何影响，直到网络出现故障并挂起该进程为止。</p><p>HTTP是一个复杂的多阶段协议，因此没有一个适合所有超时的解决方案。考虑一下流端点、JSON API和<a href="https://en.wikipedia.org/wiki/Comet_%28programming%29" target="_blank" rel="noopener">Comet</a>端点。实际上，默认设置通常不是您想要的。</p><p>在本文中，我将介绍在服务器端和客户端都可能会导致应用超时的各个阶段，并探讨解决超时的不同方法。</p><h1>SetDeadline</h1><p>首先，您需要了解Go用于实现超时的网络原语:Deadlines。</p><p><a href="https://golang.org/pkg/net/#Conn" target="_blank" rel="noopener">net.Conn</a>使用Set[Read|Write]Deadline(time.Time)方法公开，Deadlines是绝对时间，一旦到时，所有I/O操作都会因超时错误而失败。</p><p>Deadlines不是超时。一旦设置，它们就会永久生效(直到下一次调用SetDeadline)，不管在此期间是否使用连接以及如何使用连接。因此，要使用SetDeadline建立超时，您必须在每次读/写操作之前调用它。</p><p>实际开发中，你并不需要直接调用SetDeadline，而是在标准库net/http中使用更高层次的超时设置。但是，请记住，所有超时都是根据Deadlines实现的，因此它们不会在每次发送或接收数据时重置。</p><h1>Server Timeouts</h1><p><a href="https://blog.cloudflare.com/exposing-go-on-the-internet/" target="_blank" rel="noopener">&quot;So you want to expose Go on the Internet&quot;</a>一文提供了有关服务器超时的更多信息，尤其是有关HTTP/2和Go 1.7的信息。</p><p><img data-src="/images/go-net-http-timeout-sequence-diagram/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B6%85%E6%97%B6.png" alt></p><p>对于暴露于Internet的HTTP服务器来说，设置客户端链接超时，是至关重要的。否则，非常缓慢或消失的客户端可能会泄漏文件描述符，最终导致以下情况:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http: Accept error: accept tcp [::]:80: accept4: too many open files; retrying in 5ms</span><br></pre></td></tr></table></figure><p>http.Server有两个设置超时的方法:ReadTimeout和WriteTimeout。你可以显式地设置它们：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">srv := &amp;http.Server&#123;</span><br><span class="line">    ReadTimeout: 5 * time.Second,</span><br><span class="line">    WriteTimeout: 10 * time.Second,</span><br><span class="line">&#125;</span><br><span class="line">log.Println(srv.ListenAndServe())</span><br></pre></td></tr></table></figure><p>ReadTimeout的时间计算是从连接被接受(accept)到request body完全被读取(if you do read the body, otherwise to the end of the headers)。net/http的内部实现是在<a href="https://github.com/golang/go/blob/3ba31558d1bca8ae6d2f03209b4cae55381175b3/src/net/http/server.go#L750" target="_blank" rel="noopener">Accept之后立即调用SetReadDeadline</a>。</p><p>WriteTimeout的时间计算正常是从request header的读取结束开始，到response write结束为止(也就是ServeHTTP的生命周期), 它是通过在<a href="https://github.com/golang/go/blob/3ba31558d1bca8ae6d2f03209b4cae55381175b3/src/net/http/server.go#L753-L755" target="_blank" rel="noopener">readRequest方法结束的时候调用SetWriteDeadline</a>实现的。</p><p>但是，当连接为HTTPS时，会在<a href="https://github.com/golang/go/blob/3ba31558d1bca8ae6d2f03209b4cae55381175b3/src/net/http/server.go#L1477-L1483" target="_blank" rel="noopener">Accept之后立即调用SetWriteDeadline</a>，所以它的时间计算也包括 TLS握手时的写的时间。令人讨厌的是，这意味着(仅在这种情况下)WriteTimeout最终将包括Header和读取body第一个字节这段时间。</p><p>当你处理不可信的客户端和网络的时候，你应该同时设置读写超时，这样客户端就不会因为读慢或者写慢长久的持有这个连接了。</p><p>最后,还有<a href="https://golang.org/pkg/net/http/#TimeoutHandler" target="_blank" rel="noopener">http.TimeoutHandler</a>。它不是一个Server参数，而是一个Handler包装函数，限制了ServeHTTP调用的最大持续时间。它缓存response, 如果deadline超过了则发送504 Gateway Timeout错误。 注意这个功能在1.6 中有问题，在1.6.2中改正了。</p><h1>http.ListenAndServe is doing it wrong</h1><p>顺便说一句，这意味着绕过诸如http.ListenAndServe，http.ListenAndServeTLS和http.Serve之类的http.Server的程序包级便捷功能不适用于公共Internet服务器。</p><p>因为这些函数默认关闭了超时设置，也无法手动设置。使用这些函数，将很快泄露连接，然后耗尽文件描述符。对于这点，我至少犯了6次以上这样的错误。</p><p>对此，你应该使用http.server。在创建http.server实例的时候，调用相应的方法指定ReadTimeout（读取超时时间）和WriteTimeout（写超时时间），在以下会有一些案例。</p><h1>About streaming</h1><p>非常烦人的是，无法从ServeHTTP访问底层net.Conn，因此打算流式传输响应的服务器被迫取消WriteTimeout的设置（这也可能是默认情况下它们为0的原因）。这是因为没有net.Conn访问，就无法在每次Write之前调用SetWriteDeadline来实现适当的空闲（不是绝对）超时。</p><p>同样，也没有办法取消一个被阻塞的ResponseWriter。由于无法确认ResponseWriter.Close支持并发写操作。因此，也没有办法使用计时器手动构建超时。</p><p>这意味着流媒体服务器面对一个低速客户端时，将无法有效保障自身的效率、稳定</p><p>我提交了<a href="https://github.com/golang/go/issues/16100" target="_blank" rel="noopener">一个问题和一些建议</a>，期待反馈。</p><blockquote><p>译者注：: 原文作者此处的说法有问题，其实通过Hijack是可以获取到net.Conn的。</p></blockquote><p><img data-src="/images/go-net-http-timeout-sequence-diagram/Hijack%E8%8E%B7%E5%8F%96conn.png" alt></p><h1>Client Timeouts</h1><p><img data-src="/images/go-net-http-timeout-sequence-diagram/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B6%85%E6%97%B6.png" alt></p><p>客户端超时，可以很简单，也可以很复杂，取决于你怎么用。但同样重要的是：要防止资源泄漏和阻塞。</p><p>最简单的使用超时的方式是<a href="https://golang.org/pkg/net/http/#Client" target="_blank" rel="noopener">http.Client</a>。它涵盖整个交互过程，从发起连接(如果未重用连接)到接收响应报文结束。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c := &amp;http.Client&#123;</span><br><span class="line">    Timeout: 15 * time.Second,</span><br><span class="line">&#125;</span><br><span class="line">resp, err := c.Get(&quot;https://jiankunking.com&quot;)</span><br></pre></td></tr></table></figure><p>与服务端情况类似，程序包级别的功能（例如http.Get）可以使用<a href="https://golang.org/pkg/net/http/#DefaultClient" target="_blank" rel="noopener">没有超时的客户端</a>，因此在开放的Internet上使用非常危险。</p><p>还有其它一些方法，可以让你进行更精细的超时控制：</p><ul><li>net.Dialer.Timeout 限制创建一个TCP连接使用的时间（如果需要一个新的链接）</li><li>http.Transport.TLSHandshakeTimeout 限制TLS握手使用的时间</li><li>http.Transport.ResponseHeaderTimeout 限制读取响应报文头使用的时间</li><li>http.Transport.ExpectContinueTimeout 限制客户端在发送一个包含：100-continue的http报文头后，等待收到一个go-ahead响应报文所用的时间。<a href="https://github.com/golang/go/issues/14391" target="_blank" rel="noopener">在1.6中，此设置对HTTP/2无效</a>。（<a href="https://github.com/golang/go/commit/406752b640fcc56a9287b8454564cffe2f0021c1#diff-6951e7593bfb1e773c9121df44df1c36R179" target="_blank" rel="noopener">在1.6.2中提供了一个特定的封装DefaultTransport</a>）</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c := &amp;http.Client&#123;</span><br><span class="line">    Transport: &amp;http.Transport&#123;</span><br><span class="line">        Dial: (&amp;net.Dialer&#123;</span><br><span class="line">                Timeout:   30 * time.Second,</span><br><span class="line">                KeepAlive: 30 * time.Second,</span><br><span class="line">        &#125;).Dial,</span><br><span class="line">        TLSHandshakeTimeout:   10 * time.Second,</span><br><span class="line">        ResponseHeaderTimeout: 10 * time.Second,</span><br><span class="line">        ExpectContinueTimeout: 1 * time.Second,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>据我了解，尚没有限制发送请求使用时间的机制。目前的解决方案是，在客户端方法返回后，通过time.Timer来个手工控制读取请求信息的时间（参见下面的“如何取消请求”）。</p><p>最后，在新的1.7版本中，提供了http.Transport.IdleConnTimeout。它用于控制一个闲置连接在连接池中的保留时间，而不考虑一个客户端请求被阻塞在哪个阶段。</p><p>请注意，客户端将使用默认的重定向机制。由于http.Transport是一个底层的系统机制，没有重定向概念，因此http.Client.Timeout涵盖了用于重定向花费的时间，而更精细的超时控，可以根据请求的不同，进行定制。</p><h1>Cancel and Context</h1><p>net/http提供了两种方式取消一个client的请求: Request.Cancel以及Go 1.7新加的Context。</p><p>Request.Cancel是一个可选channel。在Request.Timeout被触发时，Request.Cancel将被设置并关闭，进而促使请求中断（基本上“撤销”都采用相同的机制，在写此文时，我发现一个1.7中的bug，所有的撤销操作，都会当作一个超时错误返回）。</p><p>我们可以使用Request.Cancel和time.Timer来构建一个细粒度的超时控制，以允许流传输，每次成功从Body读取一些数据时，都将截止日期推迟:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;io&quot;</span><br><span class="line">	&quot;io/ioutil&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;net/http&quot;</span><br><span class="line">	&quot;time&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">	c := make(chan struct&#123;&#125;)</span><br><span class="line">	timer := time.AfterFunc(5*time.Second, func() &#123;</span><br><span class="line">		close(c)</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">        // Serve 256 bytes every second.</span><br><span class="line">	req, err := http.NewRequest(&quot;GET&quot;, &quot;http://httpbin.org/range/2048?duration=8&amp;chunk_size=256&quot;, nil)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">	req.Cancel = c</span><br><span class="line"></span><br><span class="line">	log.Println(&quot;Sending request...&quot;)</span><br><span class="line">	resp, err := http.DefaultClient.Do(req)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">	defer resp.Body.Close()</span><br><span class="line"></span><br><span class="line">	log.Println(&quot;Reading body...&quot;)</span><br><span class="line">	for &#123;</span><br><span class="line">		timer.Reset(2 * time.Second)</span><br><span class="line">                // Try instead: timer.Reset(50 * time.Millisecond)</span><br><span class="line">		_, err = io.CopyN(ioutil.Discard, resp.Body, 256)</span><br><span class="line">		if err == io.EOF &#123;</span><br><span class="line">			break</span><br><span class="line">		&#125; else if err != nil &#123;</span><br><span class="line">			log.Fatal(err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面这个例子中，我们在请求阶段，设置了一个5秒钟的超时。但读取响应报文阶段，我们需要读8次，至少8秒钟的时间。每次读操作，设置2秒钟的超时。采用这样的机制，我们可以无限制的获取流媒体，而不用担心阻塞的风险。如果我们没有在2秒钟内读取到任何数据，io.CopyN将返回错误信息：net/http: request canceled.。</p><p>context包升级了，进入到标准库中。<a href="https://blog.golang.org/context" target="_blank" rel="noopener">关于Contexts，我们有大量需要学习的东西</a>。基于本文的主旨，你首先应该知道的是：Contexts将替代Request.Cancel，不再建议(反对)使用Request.Cancel。</p><p>为了使用Contexts来撤销一个请求，我们需要创建一个新的Context以及它的基于context.WithCancel的cancel()函数，同时还有创建一个基于Request.WithContext的Request。当我们要撤销一个请求时，我们其实际是通过cancel()函数撤销相应的Context（取代原有的关闭Cancel channel的方式）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ctx, cancel := context.WithCancel(context.TODO())</span><br><span class="line">timer := time.AfterFunc(5*time.Second, func() &#123;</span><br><span class="line">	cancel()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">req, err := http.NewRequest(&quot;GET&quot;, &quot;http://httpbin.org/range/2048?duration=8&amp;chunk_size=256&quot;, nil)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">	log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">req = req.WithContext(ctx)</span><br></pre></td></tr></table></figure><p>Context好处还在于如果parent context被取消的时候(在context.WithCancel调用的时候传递进来的)，子context也会取消， 消息会进行传递。</p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>翻译</tag>
        <tag>Go</tag>
        <tag>net/http</tag>
        <tag>Http</tag>
        <tag>Timeout</tag>
      </tags>
  </entry>
  <entry>
    <title>重构：改善既有代码的设计 笔记</title>
    <url>/refactoring-improving-the-design-of-existing-code.html</url>
    <content><![CDATA[<p>本文整理自：《重构改善既有代码的设计》</p><p>作者：MartinFowler</p><p>出版时间：2015-08</p><a id="more"></a><h1>重构，第一个案例</h1><p>如果你发现自己需要为程序添加一个特性，而代码结构使你无法很方便地达成目的，那就先重构那个程序，使特性添加比较容易进行，然后再添加特性。</p><p>每当我要进行重构的时候，第一个步骤永远相同：我得为即将修改的代码建立一组可靠的测试环境。这些测试是必要的，因为尽管遵循重构手法可以使我避免绝大多数引入bug的情形，但我毕竟是人，毕竟有可能犯错。所以我需要可靠的测试。</p><p>测试过程中很重要的一部分，就是测试程序对于结果的报告方式，他们要么说“OK”，表示所有新字符串都和参考字符串一样，要么就列出失败清单，显示问题字符串的出现行号。这些测试都能够自我检验。是的，你必须让测试有能力自我检验，否则就得耗费大把时间来回比对，这会降低你的开发速度。</p><p><font color="DeepPink"><strong>进行重构的时候， 我们需要依赖测试， 让它告诉我们是引入Bug。好的测试是重构的根本。花时间建立一个优良的测试机制是完全值得的，因为当你修改程序时，好测试会给你必要的安全保障。</strong></font></p><h1>重构原则</h1><h2 id="何谓重构">何谓重构</h2><blockquote><p>重构（名词）：对软件内部结构的一种调整，目的是在不改变软件可观察行为的前提下，提高其可理解性，降低其修改成本。</p></blockquote><p>首先，重构的目的是使软件更容易被理解和修改。你可以在软件内部做很多修改，但必须对软件可观察的外部行为只造成很小变化，或甚至不造成变化。与之形成对比的是性能优化。和重构一样，性能优化通常不会改变组件的行为（除了执行速度），只会改变其内部结构。但是两者出发点不同:性能优化往往使代码较难理解，但为了得到所需的性能你不得不那么做。</p><p>我要强调的第二点是:重构不会改变软件可观察的行为——重构之后软件功能一如以往。任何用户，不论最终用户或其他程序员，都不知道已经有东西发生了变化。</p><h2 id="何时重构">何时重构</h2><h3 id="三次法则">三次法则</h3><p>Don Roberts 给了我一条准则：<font color="DeepPink"><strong>第一次做某件事时只管去做；第二次做类似的事会产生反感，但无论如何还是可以去做；第三次再做类似的事，你就应该重构。</strong></font></p><blockquote><p>事不过三，三则重构。</p></blockquote><h3 id="复审代码时重构">复审代码时重构</h3><p>如果是比较大的设计复审工作，那么在一个较大团队内保留多种观点通常会更好一些。此时直接展示代码往往不是最佳办法。我喜欢运用 UML 示意图展现设计，并以 CRC 卡展示软件情节。换句话说，我会和某个团队进行设计复审，而和单个复审者进行代码复审。</p><p>极限编程[ Beck , XP ]中的“结对编程”形式，把代码复审的积极性发挥到了极致。一旦采用这种形式，所有正式开发任务都由两名开发者在同一台机器上进行。这样便在开发过程中形成随时进行的代码复审工作，而重构也就被包含在开发过程内了。</p><h2 id="重构的难题">重构的难题</h2><h3 id="修改接口">修改接口</h3><p>如今的问题是：该如何面对那些必须修改“已发布接口”的重构手法？</p><p>简言之，如果重构手法改变了已发布接口，你必须同时维护新旧两个接口，直到所有用户都有时间对这个变化做出反应。幸运的是，这不太困难。你通常都有办法把事情组织好，让旧接口继续工作。请尽量这么做：让旧接口调用新接口。当你要修改某个函数名称时，请留下旧函数，让它调用新函数。千万不要复制函数实现，那会让你陷入重复代码的泥悼中难以自拔。你还应该使用 Java 提供的 deprecation (不建议使用）设施，将旧接口标记为 deprecated 。这么一来你的调用者就会注意到它了。</p><p>这个过程的一个好例子就是 Java 容器类（集合类 ， collection classes)。 Java 2的新容器取代了原先一些容器。当 Java 2容器发布时， JavaSoft 花了很大力气来为开发者提供一条顺利迁徙之路。</p><p>“保留旧接口”的办法通常可行，但很烦人。起码在一段时间里你必须构造并维护一些额外的函数。它们会使接口变得复杂，使接口难以使用。还好我们有另一个选择：不要发布接口。当然我不是说要完全禁止，因为很明显你总得发布一些接口。如果你正在建造供外部使用的 API (就像 Sim 公司所做的那样），就必须发布接口。之所以说尽量不要发布，是因为我常常看到一些开发团队公开了太多接口。我曾经看到一支三人团队这么工作：每个人都向另外两人公开发布接口。这使他们不得不经常来回维护接口，而其实他们原本可以直換进入程序库，径行修改自己管理的那一部分，那会轻松许多。过度强调代码所有权的团队常常会犯这种错误。发布接口很有用，但也有代价。所以除非真有必要，不要发布接口。这可能意味需要改变你的代码所有权观念，让每个人都可以修改别人的代码，以适应接口的改动。以结对编程的方式完成这一切通常是个好主意。</p><blockquote><p><font color="DeepPink"><strong>不要过早发布接口。请修改你的代码所有权政策，使重构更顺畅。</strong></font></p></blockquote><h1>代码的坏味道</h1><h2 id="Duplicated-Code-重复代码">Duplicated Code 重复代码</h2><h2 id="LongMethod-过长方法">LongMethod 过长方法</h2><p>我们遵循这样一条原则：每当感觉需要以注释来说明点什么的时候，我们就把需要说明的东西写进一个独立函数中，并以其用途（而非实现手法）命名。</p><h2 id="Large-Class-过长类">Large Class 过长类</h2><h2 id="Long-Parameter-List-过长参数列表">Long Parameter List 过长参数列表</h2><h2 id="Divergent-Change-发散式变化">Divergent Change 发散式变化</h2><p>我们希望软件能够更容易被修改——毕竟软件再怎么说本来就该是“软”的。**一旦需要修改，我们希望能够跳到系统的某一点，只在该处做修改。**如果不能做到这点，你就嗅出两种紧密相关的刺鼻味道中的一种了。</p><p>如果某个类经常因为不同的原因在不同的方向上发生变化 ，Divergent Change就出现了。当你看着一个类说：“呃，如果新加入一个数据库，我必须修改这三个函数；如果新出现一种金融工具，我必须修改这四个函数。”那么此时也许将这个对象分成两个会更好，这么一来每个对象就可以只因一种变化而需要修改。当然，往往只有在加入新数据库或新金融工具后，你才能发现这一点。<font color="DeepPink"><strong>针对某一外界变化的所有相应修改，都只应该发生在单一类中，而这个新类内的所有内容都应该反应此变化。</strong></font>为此，你应该找出某特定原因而造成的所有变化，然后运用Extract Class将它们提炼到另一个类中。</p><h2 id="Shotgun-Surgery-霰弹式修改">Shotgun Surgery 霰弹式修改</h2><p>Shotgun Surgery 类似 Divergent Change ，但恰恰相反。如果每遇到某种变化，你都必须在许多不同的类内做出许多小修改，你所面临的坏味道就是Shotgun Surgery。如果需要修改的代码散布四处，你不但很难找到它们，也很容易忘记某个重要的修改。</p><p>这种情况下你应该使用Move Method和 Move Filed把所有需要修改的代码放进同一个类。如果眼下没有合适的类可以安置这些代码，就创造一个。通常可以运用Inline Class把一系列相关行为放进同一个类 。 这可能会造成少量Divergent Change ，但你可以轻易处理它。</p><p><font color="DeepPink"><strong>Divergent Change是指“一个类受多种变化的影响”，Shotgun Surgery则是指“一种变化引发多个类相应修改”。这两种情况下你都会希望整理代码使“外界变化”与“需要修改的类”趋于一一对应。</strong></font></p><h2 id="Feature-Envy-特性依恋">Feature Envy 特性依恋</h2><p>对象技术的全部要点在于：这是一种“将数据和对数据的操作行为包装在一起”的技术。有一种经典气味是：函数对某个类的兴趣高过对自己所处类的兴趣。这种孺慕之情最通常的焦点便是数据。无数次经验里，我们看到某个函数为了计算某个值，从另一个对象那儿调用几乎半打的取值函数。疗法显而易见：把这个函数移至另一个地点。你应该使用Move Method把它移到它该去的地方。有时候函数中只有一部分受这种依恋之苦，这时候你应该使用Extract Method把这一部分提炼到独立函数中，再使用Move Method带它去它的梦中家园。</p><p>当然，并非所有情况都这么简单 。一个函数往往会用到几个类的功能，那么它究竟该被置于何处呢?我们的原则是：判断哪个类拥有最多被此函数使用的数据，然后就把这个函数和那些数据摆在一起。如果先以Extract Method将这个函数分解为数个较小函数并分别置放于不同地点，上述步骤也就比较容易完成了。</p><p>有几个复杂精巧的模式破坏了这个规则。说起这个话题， GoF的Strategy和Visitor立刻跳入我的脑海，Kent Beck的Self Delegation [Beck]也在此列。使用这些模式是为了对抗坏味道Divergent Change 。最根本的原则是：将总是一起变化的东西放在一块儿。数据和引用这些数据的行为总是一起变化的，但也有例外。如果例外出现，我们就搬移那些行为，保持变化只在一地发生。Strategy和Visitor使你得以轻松修改函数行为，因为它们将少量需被扭写的行为隔离开来―当然也付出了“多一层间接性”的代价。</p><h2 id="Data-Clumps-数据泥团">Data Clumps 数据泥团</h2><p>数据项就像小孩子，喜欢成群结队地待在一块儿。你常常可以在很多地方看到相同的三四项数据：两个类中相同的字段、许多函数签名中相同的参数。这些总是绑在一起出现的数据真应该拥有属于它们自己的对象。首先请找出这些数据以字段形式出现的地方， 运用Extract Class将它们提炼到一个独立对象中。然后将注意力转移到函数签名上，运用Introduce Parameter Object(或Preserve Whole Object为它减肥。这么做的直接好处是可以将很多参数列缩短，简化函数调用。是的，不必在意Data Clumps只用上新对象的一部分字段，只要以新对象取代两个(或更多)字段，你就值回票价了。</p><p>一个好的评判办法是：删掉众多数据中的一项。这么做，其他数据有没有因而失去意义?如果它们不再有意义，这就是个明确信号：你应该为它们产生一个新对象。</p><p>减少字段和参数的个数，当然可以去除一些坏味道，但更重要的是：一旦拥有新对象，你就有机会让程序散发出一种芳香。得到新对象后，你就可以着手寻找Feature Envy，这可以帮你指出能够移至新类中的种种程序行为。不必太久， 所有的类都将在它们的小小社会中充分发挥价值。</p><h2 id="Primitive-Obsession-基本类型偏执">Primitive Obsession 基本类型偏执</h2><p>如果你有一组应该总是被放在一起的字段，可以运用Extract Class。如果你在参数列表中看到基本型数据，不妨试试Introduce Parameter Object。如果你发现自己正从数组中挑选数据，可运用Replace Array with Object。</p><h2 id="Switch-Statements-switch-语句">Switch Statements switch 语句</h2><p>面向对象程序的一个最明显特征就是：少用switch(或case) 语句。从本质上说，switch语句的问题在于重复。你常会发现同样的switch语句散布于不同地点。如果要为它添加一个新的case子句， 就必须找到所有switch语句并修改它们。面向对象中的多态概念可为此带来优雅的解决办法。</p><p><font color="DeepPink"><strong>大多数时候，一看到switch语句，你就应该考虑以多态来替换它。</strong></font>问题是多态该出现在哪儿?switch语句常常根据类型码进行选择，你要的是“与该类型码相关的函数或类”，所以应该使用Extract Method将switch语句提炼到一个独立函数中，再以Move Method将它搬移到需要多态性的那个类里。此时你必须决定是否使用Replace Type Code with Subclasses或Replace Type Code with State/Strategy 。一旦这样完成继承结构之后，你就可以运用Replace Conditional with Polymorphism了。</p><p>如果你只是在单一函数中有些选择事例，且并不想改动它们，那么多态就有点杀鸡用牛刀了。这种情况下Replace Parameter with Explicit Methods是个不错的选择。如果你的选择条件之一是null，可以试试Introduce Null Object 。</p><h2 id="ParallelInheritanceHierarchies-平行继承体系">ParallelInheritanceHierarchies 平行继承体系</h2><p>Parallel Inheritance hierarchies其实是Shotgun Surgery的特殊情况。在这种情况下,每当你为某个类增加一个子类,必须也为另一个类相应增加一个子类。<strong>如果你发现某个继承体系的类名称前缀和另一个继承体系的类名称前缀完全相同,便是闻到了这种坏味道。</strong></p><p>消除这种重复性的一般策略是:让一个继承体系的实例引用另一个继承体系的实例。如果再接再励运用Move method和Move Field,就可以将引用端的继承体系消弭于无形。</p><h2 id="LazyClass-冗余类">LazyClass 冗余类</h2><h2 id="SpeculativeGenerality-夸夸其谈未来性">SpeculativeGenerality 夸夸其谈未来性</h2><p>这个令我们十分敏感的坏味道,命名者是 Brian Foote。当有人说“噢,我想我们总有一天需要做这事”,并因而企图以各式各样的钩子和特殊情况来处理一些非必要的事情,这种坏味道就出现了。那么做的结果往往造成系统更难理解和维护。如果所有装置都会被用到,那就值得那么做;如果用不到,就不值得。用不上的装置只会挡你的路,所以,把它搬开吧。</p><p><font color="DeepPink"><strong>如果你的某个抽象类其实没有太大作用,请运用Collapse Hierarchy。不必要的委托可运用Inline class除掉。如果函数的某些参数未被用上,可对它实施Remove Parameter。如果函数名称带有多余的抽象意味,应该对它实施Rename Method,让它现实一些。</strong></font></p><h2 id="Temporary-Field-令人迷惑的临时字段">Temporary Field 令人迷惑的临时字段</h2><h2 id="Message-Chains-过度耦合的消息链">Message Chains (过度耦合的消息链)</h2><p>如果你看到用户向一个对象请求另一个对象,然后再向后者请求另一个对象,然后再请求另一个对象……这就是消息链。实际代码中你看到的可能是一长串getThis()或一长串临时变量。采取这种方式,意味客户代码将与查找过程中的导航结构紧密耦合。一旦对象间的关系发生任何变化,客户端就不得不做出相应修改。</p><p>这时候你应该使用Hide Delegate。你可以在消息链的不同位置进行这种重构手法。理论上可以重构消息链上的任何一个对象,但这么做往往会把一系列对象(intermediate object)都变成Middle Man。通常更好的选择是:先观察消息链最终得到的对象是用来干什么的,看看能否以Extract Method把使用该对象的代码提炼到一个独立函数中,再运用Move Method把这个函数推入消息链。如果这条链上的某个对象有多位客户打算航行此航线的剩余部分,就加一个函数来做这件事。</p><p>有些人把任何函数链都视为坏东西,我们不这样想。呵呵,我们的冷静镇定是出了名的,起码在这件事上是这样</p><h2 id="Middle-Man-中间人">Middle Man 中间人</h2><p>对象的基本特征之一就是封装——对外部世界隐藏其内部细节。封装往往伴随委托。比如说你问主管是否有时间参加一个会议,他就把这个消息“委托”给他的记事簿,然后才能回答你。很好,你没必要知道这位主管到底使用传统记事簿或电子记事簿亦或秘书来记录自己的约会。</p><p>但是人们可能过度运用委托。你也许会看到某个类接口有一半的函数都委托给其他类,这样就是过度运用。这时应该使用Remove Middle Man,直接和真正负责的对象打交道。如果这样“不干实事”的函数只有少数几个,可以运用Inline Method把它们放进调用端。如果这些Middle Man还有其他行为,可以运用Replace Delegation with Inheritance把它变成实责对象的子类,这样你既可以扩展原对象的行为,又不必负担那么多的委托动作。</p><h2 id="Inappropriate-Intimacy-过度亲密">Inappropriate Intimacy 过度亲密</h2><p>过分狎昵的类必须拆散。你可以采用Move Method和Move Field帮它们划清界线,从而减少狎昵行径。你也可以看看是否可以运用Change Bidirectional Association to Unidirectional让其中一个类对另一个斩断情丝。如果两个类实在是情投意合,可以运用Extract Class把两者共同点提炼到一个安全地点,让它们坦荡地使用这个新类。或者也可以尝试运用Hide Delegate让另一个类来为它们传递相思情。</p><p><font color="DeepPink"><strong>继承往往造成过度亲密,因为子类对超类的了解总是超过后者的主观愿望。如果你觉得该让这个孩子独自生活了,请运用Replace Inheritance with Delegation让它离开继承体系。</strong></font></p><h2 id="Alternative-Classes-with-Different-Interfaces-异曲同工的类">Alternative Classes with Different Interfaces 异曲同工的类</h2><p>如果两个函数做同一件事,却有着不同的签名,请运用Rename Method根据它们的用途重新命名。但这往往不够,请反复运用Move Method将某些行为移入类,直到两者的协议一致为止。如果你必须重复而赘余地移入代码才能完成这些,或许可运用Extract Superclass为自己赎点罪。</p><h2 id="Incomplete-Library-Class-不完整的库类">Incomplete Library Class 不完整的库类</h2><p>如果你只想修改库类的一两个函数,可以运用Introduce Foreign Method;如果想要添加一大堆额外行为,就得运用Introduce Local Extension。</p><h2 id="Data-Class-数据类">Data Class 数据类</h2><p>所谓Data Class是指:它们拥有一些字段,以及用于访问(读写)这些字段的函数,除此之外一无长物。这样的类只是一种不会说话的数据容器,它们几乎一定被其他类过分细琐地操控着。这些类早期可能拥有public字段,果真如此你应该在别人注意到它们之前,立刻运用Encapsulate Field将它们封装起来。如果这些类内含容器类的字段,你应该检查它们是不是得到了恰当的封装:如果没有,就运用Encapsulate Collection把它们封装起来。对于那些不该被其他类修改的字段,请运用Remove Setting Method。</p><p>然后,找出这些取值设值函数被其他类运用的地点。尝试以Move Method把那些调用行为搬移到Data Class。如果无法搬移整个函数,就运用Extract Method产生一个可被搬移的函数。不久之后你就可以运用Hide Method把这些取值/设值函数隐藏起来了。</p><h2 id="Refused-Bequest-拒绝继承">Refused Bequest 拒绝继承</h2><p>子类应该继承超类的函数和数据。但如果它们不想或不需要继承,又该怎么办呢?它们得到所有礼物,却只从中挑选几样来玩!</p><p>按传统说法,这就意味着继承体系设计错误。你需要为这个子类新建一个兄弟类,再运用Push Down Method和Push Down Field把所有用不到的函数下推给那个兄弟。这样一来,超类就只持有所有子类共享的东西。你常常会听到这样的建议:所有超类都应该是抽象(abstract)的。</p><p>既然使用“传统说法”这个略带贬义的词,你就可以猜到,我们不建议你这么做,起码不建议你每次都这么做。我们经常利用继承来复用一些行为,并发现这可以很好地应用于日常工作。这也是一种坏味道,我们不否认,但气味通常并不强烈。所以我们说:如果Refused Bequest引起困惑和问题,请遵循传统忠告。但不必认为你每次都得那么做。十有八九这种坏味道很淡,不值得理睬。</p><p>如果子类复用了超类的行为(实现),却又不愿意支持超类的接口, Refused Bequest的坏味道就会变得浓烈。拒绝继承超类的实现,这一点我们不介意;但如果拒绝继承超类的接口,我们不以为然。不过即使你不愿意继承接口,也不要胡乱修改继承体系,应该运用Replace Inheritance with Delegation来达到目的</p><h2 id="Comments-注释过多">Comments 注释过多</h2><p>别担心,我们并不是说你不该写注释。从嗅觉上说, Comments不是一种坏味道,事实上它们还是一种香味呢。我们之所以要在这里提到 Comments,是因为人们常把它当作除臭剂来使用。常常会有这样的情况:你看到一段代码有着长长的注释,然后发现,这些注释之所以存在乃是因为代码很糟糕。这种情况的发生次数之多,实在令人吃惊。</p><p>Comments可以带我们找到本章先前提到的各种坏味道。找到坏味道后,我们首先应该以各种重构手法把坏味道去除。完成之后我们常常会发现:注释已经变得多余了,因为代码已经清楚说明了一切。</p><p>如果你需要注释来解释一块代码做了什么,试试Extract Method;如果函数已经提炼出来,但还是需要注释来解释其行为,试试Rename Method;如果你需要注释说明某些系统的需求规格,试试Introduce Assertion。</p><blockquote><p>当你感觉需要撰写注释时,请先尝试重构,试着让所有注释都变得多余。</p></blockquote><p><font color="DeepPink"><strong>如果你不知道该做什么,这才是注释的良好运用时机。除了用来记述将来的打算之外,注释还可以用来标记你并无十足把握的区域。你可以在注释里写下自己“为什么做某某事”。这类信息可以帮助将来的修改者,尤其是那些健忘的家伙。</strong></font></p><h1>重构列表</h1><h2 id="重构的记录格式">重构的记录格式</h2><p>介绍重构时,我采用一种标准格式。每个重构手法都有如下五个部分。</p><ul><li>首先是名称(name)。建造一个重构词汇表,名称是很重要的。这个名称也就是我将在本书其他地方使用的名称。</li><li>名称之后是一个简短概要(summary)。简单介绍此一重构手法的适用情景以及它所做的事情。这部分可以帮助你更快找到你所需要的重构手法。</li><li>动机(motivation)为你介绍“为什么需要这个重构”和“什么情况下不该使用这个重构”。</li><li>做法(mechanics)简明扼要地一步一步介绍如何进行此一重构。</li><li>范例(examples)以一个十分简单的例子说明此重构手法如何运作。</li></ul><p>概要”包括三个部分:(1)一句话,介绍这个重构能够帮助解决的问题;(2)段简短陈述,介绍你应该做的事:(3)一幅速写图,简单展现重构前后示例:有时候我展示代码,有时候我展示UML图。总之,哪种形式能更好呈现该重构的本质,我就使用哪种形式(本书所有UML图都根据实现观点而画[Fowler,UML]。)如果你以前见过这一重构手法,那么速写图能够让你迅速了解这一重构的概况;如果你不曾见过这个重构,可能就需要浏览整个范例,才能得到较好的认识。</p><p>“做法”出自我自己的笔记。这些笔记是为了让我在一段时间不做某项重构之后还能记得怎么做。它们也颇为简洁,通常不会解释“为什么要这么做那么做”。我会在“范例”中给出更多解释。这么一来,“做法”就成了简短的笔记。如果你知道该使用哪个重构,但记不清具体步骤,可以参考“做法”部分(至少我是这么使用它们的);如果你初次使用某个重构,可能只参考“做法”还不够,你还需要阅读“范例”。</p><p>撰写“做法”的时候,我尽量将重构的每个步骤都写得简短。我强调安全的重构方式,所以应该采用非常小的步骤,并且在每个步骤之后进行测试。真正工作时,我通常会采用比这里介绍的“婴儿学步”稍大些的步骤,然而一旦出问题,我就会撤销上一步,换用比较小的步骤。这些步骤还包含一些特定状况的参考,所以它们也有检验表的作用。我自己经常忘掉这些该做的事情。</p><p>“范例”像是简单而有趣的教科书。我使用这些范例是为了帮助解释重构的基本要素,最大限度地避免其他枝节,所以我希望你能原谅其中的简化工作(它们当然不是优秀商用对象设计的适当例子)。不过我敢肯定,你一定能在你手上那些更复杂的情况中使用它们。某些十分简单的重构干脆没有范例,因为我觉得为它们加上个范例不会有多大意义。</p><p>更明确地说,加上范例仅仅是为了阐释当时讨论的重构手法。通常那些代码最终仍有其他问题,但修正那些问题需要用到其他重构手法。某些情况下数个重构经常被一并运用,这时候我会把某些范例拿到另一个重构中继续使用。大部分时候,个范例只为一项重构而设计,这么做是为了让每一项重构手法自成一体,因为这份重构列表的首要目的还是作为参考工具。</p><h2 id="这些重构的成熟度如何？">这些重构的成熟度如何？</h2><p>重构的基本技巧—小步前进、频繁测试——已经得到多年的实践检验。所以,我敢保证,重构的这些基础思想是非常可靠的。</p><h1>重新组织方法</h1><h2 id="Extract-Method-提炼函数">Extract Method 提炼函数</h2><h3 id="动机">动机</h3><p>有几个原因造成我喜欢简短而命名良好的函数。首先,如果每个函数的粒度都很小,那么函数被复用的机会就更大;其次,这会使高层函数读起来就像一系列注释:再次,如果函数都是细粒度,那么函数的覆写也会更容易些。</p><p><font color="DeepPink"><strong>人们有时会问我,一个函数多长才算合适?在我看来,长度不是问题,关键在于函数名称和函数本体之间的语义距离。如果提炼可以强化代码的清晰度,那就去做,就算函数名称比提炼出来的代码还长也无所谓。</strong></font></p><h3 id="做法">做法</h3><ul><li><p><font color="DeepPink"><strong>创造一个新函数,根据这个函数的意图来对它命名</strong></font>(以它“做什么”来命名,而不是以它“怎样做”命名)</p><ul><li>→<font color="DeepPink"><strong>即使你想要提炼的代码非常简单,例如只是一条消息或一个函数调用,只要新函数的名称能够以更好的方式昭示代码意图,你也应该提炼它。但如果你想不出一个更有意义的名称,就别动。</strong></font></li></ul></li><li><p>将提炼出的代码从源函数复制到新建的目标函数中。</p></li><li><p>仔细检查提炼出的代码,看看其中是否引用了“作用域限于源函数”的变量(包括局部变量和源函数参数)。</p></li><li><p>检查是否有“仅用于被提炼代码段”的临时变量。如果有,在目标函数中将它们声明为临时变量。</p></li><li><p>检査被提炼代码段,看看是否有任何局部变量的值被它改变。如果一个临时变量值被修改了,看看是否可以将被提炼代码段处理为一个查询,并将结果赋值给相关变量。如果很难这样做,或如果被修改的变量不止一个,你就不能仅仅将这段代码原封不动地提炼出来。你可能需要先使用Split Temporary Ariable,然后再尝试提炼。也可以使用Replace Temp with Query将临时变量消灭掉。</p></li><li><p>将被提炼代码段中需要读取的局部变量,当作参数传给目标函数。</p></li><li><p>处理完所有局部变量之后,进行编译。</p></li><li><p>在源函数中,将被提炼代码段替换为对目标函数的调用。</p><ul><li>如果你将任何临时变量移到目标函数中,请检查它们原本的声明式是否在被提炼代码段的外围。如果是,现在你可以删除这些声明式了</li></ul></li><li><p>编译,测试。</p></li></ul><p>临时变量往往为数众多,甚至会使提炼工作举步维艰。这种情况下,我会尝试先运用Replace Temp with Query(减少临时变量。如果即使这么做了提炼依旧困难重重,我就会动用Replace Method with Method Object,这个重构手法不在乎 代码中有多少临时变量,也不在乎你如何使用它们。</p><h2 id="Inline-Method-内联方法">Inline Method 内联方法</h2><p>一个函数的本体与名称同样清楚易懂。</p><p>在函数调用点插入函数本体,然后移除该函数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int getRating()&#123;</span><br><span class="line">	return (moreThanFiveLateDeliveries())? 2: 1;</span><br><span class="line">&#125;</span><br><span class="line">boolean moreThanFiveLateDeliveries()&#123;</span><br><span class="line">	return numberofLateDeliveries &gt;5:</span><br><span class="line">&#125;</span><br><span class="line">    ||</span><br><span class="line">    ||</span><br><span class="line">    \/</span><br><span class="line">int getRating()&#123;</span><br><span class="line">	return(numberofLateDeliveries &gt;5)?2: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Inline-Temp-内联临时变量">Inline Temp 内联临时变量</h2><p>你有一个临时变量,只被一个简单表达式赋值一次,而它妨碍了其他重构手法。</p><p><strong>将所有对该变量的引用动作,替换为对它赋值的那个表达式自身。</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double basePrice= anorder.basePrice();</span><br><span class="line">return (basePrice&gt;1000)</span><br><span class="line">    ||</span><br><span class="line">    ||</span><br><span class="line">    \/</span><br><span class="line">return (anorder. basePrice()&gt; 1000)</span><br></pre></td></tr></table></figure><h2 id="Replace-Temp-with-Query-用查询方法代替临时变量">Replace Temp with Query 用查询方法代替临时变量</h2><p>你的程序以一个临时变量保存某一表达式的运算结果。</p><p>将这个表达式提炼到一个独立函数中。将这个临时变量的所有引用点替换为对新函数的调用。此后,新函数就可被其他函数使用。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double basePrice =quantity *_itemPrice:</span><br><span class="line">	if(baseprice&gt;1000)</span><br><span class="line">		return baseprice *0.95</span><br><span class="line">	else</span><br><span class="line">		return baseprice *0.98;</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(basePrice())&gt; 1000</span><br><span class="line">	return baseprice() *0. 95:</span><br><span class="line">else</span><br><span class="line">	return basePrice()*0.98</span><br><span class="line"></span><br><span class="line">double basePrice()&#123;</span><br><span class="line">	return _quantity*_itemPrice;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="动机-v2">动机</h3><p><font color="DeepPink"><strong>临时变量的问题在于:它们是暂时的,而且只能在所属函数内使用。由于临时变量只在所属函数内可见,所以它们会驱使你写出更长的函数,因为只有这样你才能访问到需要的临时变量。如果把临时变量替换为一个查询,那么同一个类中的所有函数都将可以获得这份信息。这将带给你极大帮助,使你能够为这个类编写更清晰的代码。</strong></font></p><p>Replace Temp with Query往往是你运用Extract Method之前必不可少的个步骤。局部变量会使代码难以被提炼,所以你应该尽可能把它们替换为查询式。</p><p>这个重构手法较为简单的情况是:临时变量只被赋值一次,或者赋值给临时变量的表达式不受其他条件影响。其他情况比较棘手,但也有可能发生。你可能需要先运用Split Temporary Variable或Separate Query from Modifier使情况变得简单一些,然后再替换临时变量。如果你想替换的临时变量是用来收集结果的,就需要将某些程序逻辑(例如循环)复制到查询函数去。</p><h3 id="做法-v2">做法</h3><p>首先是简单情况:</p><ul><li>找出只被赋值一次的临时变量。<ul><li>→如果某个临时变量被赋值超过一次,考虑使用Split Temporary Variable将它分割成多个变量。</li></ul></li><li>将该临时变量声明为final。</li><li>编译。</li><li>这可确保该临时变量的确只被赋值一次。</li><li>将“对该临时变量赋值”之语句的等号右侧部分提炼到一个独立函数中。<ul><li>→首先将函数声明为private.日后你可能会发现有更多类需要使用它,那时放松对它的保护也很容易</li><li>→确保提炼出来的函数无任何副作用,也就是说该函数并不修改任何对象内容。如果它有副作用,就对它进行Separate Query from Modifler</li></ul></li><li>编译,测试。</li><li>在该临时变量身上实施Inline Temp。</li></ul><p>我们常常使用临时变量保存循环中的累加信息。在这种情况下,整个循环都可以被提炼为一个独立函数,这也使原本的函数可以少掉几行扰人的循环逻辑。<font color="DeepPink"><strong>有时候,你可能会在一个循环中累加好几个值。这种情况下你应该针对每个累加值重复一遍循环,这样就可以将所有临时变量都替换为查询。</strong></font>当然,循环应该很简单,复制这些代码时才不会带来危险。</p><p>运用此手法,你可能会担心性能问题。和其他性能问题一样,我们现在不管它,因为它十有八九根本不会造成任何影响。若是性能真的出了问题,你也可以在优化时期解决它。代码组织良好,你往往能够发现更有效的优化方案:如果没有进行重构,好的优化方案就可能与你失之交臂。如果性能实在太糟糕,要把临时变量放回去也是很容易的。</p><h2 id="Introduce-Explaining-Variable-引入解释性变量">Introduce Explaining Variable 引入解释性变量</h2><p>你有一个复杂的表达式,将该复杂表达式(或其中一部分)的结果放进一个临时变量,以此变量名称来解释表达式用途。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if ((platform.toUppercase().indexof(&quot;MAC&quot;)&gt;-1)&amp;&amp;</span><br><span class="line">   (browser, toUppercase().idexon(“IE”)&gt;-1)&amp;&amp;</span><br><span class="line">	wasInitialized() &amp;&amp; resize &gt; 0)&#123;</span><br><span class="line">	//do something</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final boolean isMacos=platform.toUppercase() indexof(&quot;MAC&quot;)&gt;-1:</span><br><span class="line">final boolean isIEBrowser=browser.toUppercase().indexof(&quot;IE&quot;)&gt;-1</span><br><span class="line">final boolean wasResized=resize &gt;0</span><br><span class="line">if (isMacOs &amp;&amp; isIEBrowser &amp;&amp; wasInitialized() &amp;&amp; wasResized)&#123;</span><br><span class="line">	//do something</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="动机-v3">动机</h3><p>表达式有可能非常复杂而难以阅读。这种情况下,临时变量可以帮助你将表达式分解为比较容易管理的形式。</p><p>在条件逻辑中,Introduce Explaining Variable特别有价值:你可以用这项重构将每个条件子句提炼出来,以一个良好命名的临时变量来解释对应条件子句的意义。使用这项重构的另一种情况是,在较长算法中,可以运用临时变量来解释每步运算的意义。</p><p><font color="DeepPink"><strong>Introduce Explaining Variable是一个很常见的重构手法,但我得承认,我并不常用它。我几乎总是尽量使用Extract Method(来解释一段代码的意义。毕竟临时变量只在它所处的那个函数中才有意义,局限性较大,函数则可以在对象的整个生命中都有用,并且可被其他对象使用。但有时候,当局部变量使Extract Method难以进行时,我就使用Introduce Explaining Variable。</strong></font></p><h2 id="Split-Temporary-Variable-分解临时变量">Split Temporary Variable 分解临时变量</h2><p><font color="DeepPink"><strong>你的程序有某个临时变量被赋值超过一次,它既不是循环变量,也不被用于收集计算结果针对每次赋值,创造一个独立、对应的临时变量。</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double temp = 2*(_height +_width);</span><br><span class="line">System.out.println(temp);</span><br><span class="line">temp = _height*_width;</span><br><span class="line">System.out.printIn (temp);</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final double perimeter = 2*(_height+_width);</span><br><span class="line">System.out.println(perimeter);</span><br><span class="line">final double areas =_height * _width;</span><br><span class="line">System.out.println(area);</span><br></pre></td></tr></table></figure><h3 id="动机-v4">动机</h3><p>临时变量有各种不同用途,其中某些用途会很自然地导致临时变量被多次赋值。“循环变量”和“结果收集变量”就是两个典型例子:循环变量(loop variable)[Beck]会随循环的每次运行而改变(例如for(inti=0;i&lt;10;i++)语句中的i);结果收集变量(collecting temporary variable)[Beck]负责将“通过整个函数的运算”而构成的某个值收集起来。</p><p>除了这两种情况,还有很多临时变量用于保存一段冗长代码的运算结果,以便稍后使用。这种临时变量应该只被赋值一次。<font color="DeepPink"><strong>如果它们被赋值超过一次,就意味它们在函数中承担了一个以上的责任。如果临时变量承担多个责任,它就应该被替换(分解)为多个临时变量,每个变量只承担一个责任。</strong></font>同一个临时变量承担两件不同的事情,会令代码阅读者糊涂。</p><h2 id="Remove-Assignments-to-Parameters-移除对参数的赋值">Remove Assignments to Parameters 移除对参数的赋值</h2><p>代码对一个参数进行赋值。以一个临时变量取代该参数的位置。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int discount (int inputval, int quantity, int yearToDate)&#123;</span><br><span class="line">	 if(inputval&gt; 50) inputval -=2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int discount (int inputval, int quantity, int yearToDate)&#123;</span><br><span class="line">	int result = inputval;</span><br><span class="line">	if(inputval&gt; 50) result -=2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Replace-Method-with-Method-Object-以函数对象取代函数">Replace Method with Method Object 以函数对象取代函数</h2><p>你有一个大型函数,其中对局部变量的使用使你无法采用Extract Method。将这个函数放进一个单独对象中,如此一来局部变量就成了对象内的字段。然后你可以在同一个对象中将这个大型函数分解为多个小型函数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Order...</span><br><span class="line">	double price()&#123;</span><br><span class="line">		double primaryBasePrice</span><br><span class="line">		double secondaryBasePrice:</span><br><span class="line">		double tertiaryBasePrice</span><br><span class="line">		// long computation:</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p>替换为：<br><img data-src="/images/refactoring-improving-the-design-of-existing-code/replace-method-with-method-object.png" alt></p><h3 id="做法-v3">做法</h3><p>我厚着脸皮从Kent Beck[Beck]那里偷来了下列做法。</p><ul><li>建立一个新类,根据待处理函数的用途,为这个类命名。</li><li><font color="DeepPink"><strong>在新类中建立一个final字段,用以保存原先大型函数所在的对象</strong></font>。我们将这个字段称为“源对象”。同时,针对原函数的每个临时变量和每个参数在新类中建立一个对应的字段保存之。</li><li>在新类中建立一个构造函数,接收源对象及原函数的所有参数作为参数。</li><li>在新类中建立一个compute()函数。</li><li>将原函数的代码复制到compute()函数中。如果需要调用源对象的任何函数,请通过源对象字段调用。</li><li>编译。</li><li>将旧函数的函数本体替换为这样一条语句:“创建上述新类的一个新对象而后调用其中的compute()函数”</li><li>现在进行到很有趣的部分了。因为所有局部变量现在都成了字段,所以你可以任意分解这个大型函数,不必传递任何参数。</li></ul><h1>在对象之间移动特性</h1><p>类往往会因为承担过多责任而变得臃肿不堪。这种情况下,我会使用Extract Class将一部分责任分离出去。如果一个类变得太“不负责任”,我就会使用Inline Class将它融入另一个类。如果一个类使用了另一个类,运用Hide Delegate将这种关系隐藏起来通常是有帮助的。有时候隐藏委托类会导致拥有者的接口经常变化,此时需要使用Remove Middle Man。</p><p>本章的最后两项重构—Introduce Foreign Method和Introduce Local Extension比较特殊。只有当我不能访问某个类的源码,却又想把其他责任移进这个不可修改的类时,我才会使用这两个重构手法。如果我想加入的只是一或两个函数,就会使用Introduce Foreign Method;如果不止一两个函数,就使用Introduce Local Extension。</p><h2 id="Move-Method-搬移函数">Move Method 搬移函数</h2><p>你的程序中,有个函数与其所驻类之外的另一个类进行更多交流:调用后者,或被后者调用。<br>在该函数最常引用的类中建立一个有着类似行为的新函数。将旧函数变成一个单纯的委托函数,或是将旧函数完全移除。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/move-method.png" alt></p><h2 id="Move-Field-搬移字段">Move Field 搬移字段</h2><p>在你的程序中,某个字段被其所驻类之外的另一个类更多地用到。<br>在目标类新建一个字段,修改源字段的所有用户,令它们改用新字段。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/move-field.png" alt></p><h2 id="Extract-Class-提炼类">Extract Class 提炼类</h2><p>某个类做了应该由两个类做的事。<br>建立一个新类,将相关的字段和函数从旧类搬移到新类。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/extract-class.png" alt></p><h3 id="做法-v4">做法</h3><ul><li>决定如何分解类所负的责任。</li><li>建立一个新类,用以表现从旧类中分离出来的责任。<ul><li>→如果旧类剩下的责任与旧类名称不符,为旧类更名</li></ul></li><li>建立“从旧类访问新类”的连接关系。<ul><li>→<font color="DeepPink"><strong>有可能需要一个双向连接。但是在真正需要它之前,不要建立“从新类通往旧类”的连接。</strong></font></li></ul></li><li>对于你想搬移的每一个字段,运用Move Field搬移之。</li><li>每次搬移后,编译、测试</li><li>使用Move Method将必要函数搬移到新类。先搬移较低层函数(也就是被其他函数调用”多于“调用其他函数”者),再搬移较高层函数。</li><li>每次搬移之后,编译、测试。</li><li>检查,精简每个类的接口。<ul><li>→<font color="DeepPink"><strong>如果你建立起双向连接,检查是否可以将它改为单向连接。</strong></font></li></ul></li><li><font color="DeepPink"><strong>决定是否公开新类。如果你的确需要公开它,就要决定让它成为引用对象还是不可变的值对象。</strong></font></li></ul><h2 id="Inline-Class-将类内联化">Inline Class 将类内联化</h2><p>某个类没有做太多事情。<br>将这个类的所有特性搬移到另一个类中,然后移除原类。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/inline-class.png" alt></p><h2 id="Hide-Delegate-隐藏“委托关系”">Hide Delegate 隐藏“委托关系”</h2><p>客户通过一个委托类来调用另一个对象。<br>在服务类上建立客户所需的所有函数,用以隐藏委托关系。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/hide-delegate.png" alt></p><h2 id="Remove-Middle-Man-移除中间人">Remove Middle Man 移除中间人</h2><p>某个类做了过多的简单委托动作。<br>让客户直接调用受托类。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/remove-middle-man.png" alt></p><h2 id="Introduce-Foreign-Method-引入外加函数">Introduce Foreign Method 引入外加函数</h2><p>你需要为提供服务的类增加一个函数,但你无法修改这个类。<br>在客户类中建立一个函数,并以第一参数形式传入一个服务类实例。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Date newstart= new Date (previousEnd.getYear(),</span><br><span class="line">						previousEnd.getMonth(),</span><br><span class="line">						previousEnd.getDate()+1);</span><br></pre></td></tr></table></figure><p>替换为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Date newstart = nextDay(previousEnd);</span><br><span class="line"></span><br><span class="line">private static Date nextDay(Date arg)&#123;</span><br><span class="line">	return new Date (arg.getYear(), arg.getMonth(), arg.getDate()+1)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="动机-v5">动机</h3><p>这种事情发生过太多次了:你正在使用一个类,它真的很好,为你提供了需要的所有服务。而后,你又需要一项新服务,这个类却无法供应。于是你开始咒骂:“为什么不能做这件事?”如果可以修改源码,你便可以自行添加一个新函数:如果不能,你就得在客户端编码,补足你要的那个函数。</p><p>如果你发现自己为一个服务类建立了大量外加函数,或者发现有许多类都需要同样的外加函数,就不应该再使用本项重构,而应该使用Introduce Local Extension。</p><h2 id="Introduce-Local-Extension-引入本地扩展">Introduce Local Extension 引入本地扩展</h2><p>你需要为服务类提供一些额外函数,但你无法修改这个类。<br>建立一个新类,使它包含这些额外函数。让这个扩展品成为源类的子类或包装类。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/introduce-local-extension.png" alt></p><h3 id="动机-v6">动机</h3><p>很遗憾,类的作者无法预知未来,他们常常没能为你预先准备一些有用的函数。如果你可以修改源码,最好的办法就是直接加入自己需要的函数。但你经常无法修改源码。如果只需要一两个函数,你可以使用Introduce Foreign Method。但如果你需要的额外函数超过两个,外加函数就很难控制它们了。所以,你需要将这些函数组织在一起,放到一个恰当地方去。要达到这一目的,两种标准对象技术子类化(subclassing)和包装(wrapping)—是显而易见的办法。这种情况下,我把子类或包装类统称为本地扩展(local extension)。</p><p>所谓本地扩展是一个独立的类,但也是被扩展类的子类型:它提供源类的一切特性,同时额外添加新特性。在任何使用源类的地方,你都可以使用本地扩展取而代之。</p><p>使用本地扩展使你得以坚持“函数和数据应该被统一封装”的原则。如果你直把本该放在扩展类中的代码零散地放置于其他类中,最终只会让其他这些类变得过分复杂,并使得其中函数难以被复用。</p><p>在子类和包装类之间做选择时,我通常首选子类,因为这样的工作量比较少。制作子类的最大障碍在于,它必须在对象创建期实施。如果我可以接管对象创建过程,那当然没问题;但如果你想在对象创建之后再使用本地扩展,就有问题了。此外,子类化方案还必须产生一个子类对象,这种情况下,如果有其他对象引用了旧对象,我们就同时有两个对象保存了原数据!如果原数据是不可修改的,那也没问题,我可以放心进行复制:但如果原数据允许被修改,问题就来了,因为一个修改动作无法同时改变两份副本。这时候我就必须改用包装类。使用包装类时,对本地扩展的修改会波及原对象,反之亦然。</p><h3 id="做法-v5">做法</h3><ul><li>建立一个扩展类,将它作为原始类的子类或包装类。</li><li>在扩展类中加入转型构造函数。<ul><li>→<font color="DeepPink"><strong>所谓“转型构造函数”是指“接受原对象作为参数”的构造函数。如果采用子类化方案,那么转型构造函数应该调用适当的超类构造函数;如果采用包装类方案,那么转型构造函数应该将它得到的传入参数以实例变量的形式保存起来,用作接受委托的原对象。</strong></font></li></ul></li><li>在扩展类中加入新特性。</li><li>根据需要,将原对象替换为扩展对象</li><li>将针对原始类定义的所有外加函数搬移到扩展类中。</li></ul><h1>简化条件表达式</h1><h2 id="Replace-Nested-Conditional-with-Guard-Clauses-以卫语句取代嵌套条件表达式">Replace Nested Conditional with Guard Clauses 以卫语句取代嵌套条件表达式</h2><p>函数中的条件逻辑使人难以看清正常的执行路径。<br>使用卫语句表现所有特殊情况。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E5%8D%AB%E8%AF%AD%E5%8F%A5.png" alt></p><blockquote><p>谓语句是我个人比较喜欢的一种处理方式，通俗点说就是让函数尽快结束。</p></blockquote><h2 id="Replace-Conditional-with-Polymorphism-以多态取代条件表达式">Replace Conditional with Polymorphism 以多态取代条件表达式</h2><p>你手上有个条件表达式,它根据对象类型的不同而选择不同的行为。<br><font color="DeepPink"><strong>将这个条件表达式的每个分支放进一个子类内的覆写函数中,然后将原始函数声明为抽象函数。</strong></font></p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E5%A4%9A%E6%80%81%E6%9B%BF%E6%8D%A2%E6%9D%A1%E4%BB%B6%E8%A1%A8%E8%BE%BE%E5%BC%8F.png" alt></p><h3 id="动机-v7">动机</h3><p>在面向对象术语中,听上去最高贵的词非“多态”莫属。<font color="DeepPink"><strong>多态最根本的好处就是:如果你需要根据对象的不同类型而采取不同的行为,多态使你不必编写明显的条件表达式。</strong></font></p><p>正因为有了多态,所以你会发现:“类型码的switch语句”以及“基于类型名称的if-then-e1se语句”在面向对象程序中很少出现。</p><p>多态能够给你带来很多好处。如果同一组条件表达式在程序许多地点出现,那么使用多态的收益是最大的。<font color="DeepPink"><strong>使用条件表达式时,如果你想添加一种新类型,就必须查找并更新所有条件表达式。但如果改用多态,只需建立一个新的子类,并在其中提供适当的函数就行了。类的用户不需要了解这个子类,这就大大降低了系统各部分之间的依赖,使系统升级更加容易。</strong></font></p><h2 id="Introduce-Assertion-引入断言">Introduce Assertion 引入断言</h2><p>某一段代码需要对程序状态做出某种假设。以断言明确表现这种假设。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E6%96%AD%E8%A8%80.png" alt></p><h3 id="动机-v8">动机</h3><p>常常会有这样一段代码:只有当某个条件为真时,该段代码才能正常运行。例如平方根计算只对正值才能进行,又例如某个对象可能假设其字段至少有一个不等于null。</p><p>这样的假设通常并没有在代码中明确表现出来,你必须阅读整个算法才能看出。有时程序员会以注释写出这样的假设。而我要介绍的是一种更好的技术:使用断言明确标明这些假设。</p><p>断言是一个条件表达式,应该总是为真。如果它失败,表示程序员犯了错误。因此断言的失败应该导致一个非受控异常(unchecked exception)。断言绝对不能被系统的其他部分使用。实际上,程序最后的成品往往将断言统统删除。因此,标记“某些东西是个断言”是很重要的。</p><p>断言可以作为交流与调试的辅助。在交流的角度上,断言可以帮助程序阅读者理解代码所做的假设;在调试的角度上,断言可以在距离bug最近的地方抓住它们。当我编写自我测试代码的时候发现,断言在调试方面的帮助变得不那么重要了,但我仍然非常看重它们在交流方面的价值。</p><p>注意,不要滥用断言。请不要使用它来检査“你认为应该为真”的条件,请只使用它来检査“一定必须为真”的条件。滥用断言可能会造成难以维护的重复逻辑。在一段逻辑中加入断言是有好处的,因为它迫使你重新考虑这段代码的约束条件。如果不满足这些约束条件,程序也可以正常运行,断言就不会带给你任何帮助,只会把代码变得混乱,并且有可能妨碍以后的修改。</p><p>你应该常常问自己:如果断言所指示的约束条件不能满足,代码是否仍能正常运行?如果可以,就把断言拿掉。</p><p>另外,还需要注意断言中的重复代码。它们和其他任何地方的重复代码一样不好闻。你可以大胆使用Extract Method去掉那些重复代码。</p><h1>简化函数调用</h1><p>关于缩减参数列的重构手法, Doug Lea对我提出了一个警告:并发编程往往需要使用较长的参数列,因为这样你可以保证传递给函数的参数都是不可被修改的, 例如内置型对象和值对象一定是不可变的。通常,你可以使用不可变对象取代这样的长参数列,但另一方面你也必须对此类重构保持谨慎。</p><h2 id="Separate-Query-from-Modifier-将查询函数和修改函数分离">Separate Query from Modifier 将查询函数和修改函数分离</h2><p>某个函数既返回对象状态值,又修改对象状态。<br>建立两个不同的函数,其中一个负责查询,另一个负责修改。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E5%B0%86%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0%E5%92%8C%E4%BF%AE%E6%94%B9%E5%87%BD%E6%95%B0%E5%88%86%E7%A6%BB.png" alt></p><h3 id="动机-v9">动机</h3><p>如果某个函数只是向你提供一个值,没有任何看得到的副作用,那么这是个很有价值的东西。你可以任意调用这个函数,也可以把调用动作搬到函数的其他地方。</p><p>简而言之,需要操心的事情少多了。明确表现出“有副作用”与“无副作用”两种函数之间的差异,是个很好的想法。下面是一条好规则:<font color="DeepPink"><strong>任何有返回值的函数,都不应该有看得到的副作用。</strong></font>有些程序员甚至将此作为一条必须遵守的规则。就像对待任何东西一样,我并不绝对遵守它,不过我总是尽量遵守,而它也回报我很好的效果。</p><p><font color="DeepPink"><strong>如果你遇到一个“既有返回值又有副作用”的函数,就应该试着将查询动作从修改动作中分割出来。</strong></font></p><h3 id="并发问题">并发问题</h3><p>如果你在一个多线程系统中工作,肯定知道这样一个重要的惯用手法:在同一个动作中完成检查和赋值。这是否和Separate Query from Modifier互相矛盾呢?我曾经和Doug Lea讨论过这个问题,并得出结论:两者并不矛盾,但你需要做一些额外工作。将查询动作和修改动作分开来仍然是很有价值的。但你需要保留第三个函数来同时做这两件事。这个“查询一修改”函数将调用各自独立的查询函数和修改函数,并被声明为synchronized。如果查询函数和修改函数未被声明为synchronized,那么你还应该将它们的可见范围限制在包级别或private级别。这样,你就可以拥有一个安全、同步的操作,它由两个较易理解的函数组成。这两个较低层函数也可以用于其他场合。</p><h2 id="Replace-Constructor-with-Factory-Method-以工厂函数取代构造函数">Replace Constructor with Factory Method 以工厂函数取代构造函数</h2><p>你希望在创建对象时不仅仅是做简单的建构动作。<br>将构造函数替换为工厂函数。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E4%BB%A5%E5%B7%A5%E5%8E%82%E5%87%BD%E6%95%B0%E5%8F%96%E4%BB%A3%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0.png" alt></p><h3 id="动机-v10">动机</h3><p>使用Replace Constructor with Factory Method的最显而易见的动机,就是在派生子类的过程中以工厂函数取代类型码。你可能常常需要根据类型码创建相应的对象,现在,创建名单中还得加上子类,那些子类也是根据类型码来创建。然而由于构造函数只能返回单一类型的对象,因此你需要将构造函数替换为工厂函数。此外,如果构造函数的功能不能满足你的需要,也可以使用工厂函数来代替它。工厂函数也是Change Value to Reference的基础。你也可以令你的工厂函数根据参数的个数和类型,选择不同的创建行为。</p><h2 id="Replace-Error-Code-with-Exception-以异常取代错误码">Replace Error Code with Exception 以异常取代错误码</h2><p>某个函数返回一个特定的代码,用以表示某种错误情况。<br>改用异常。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E4%BB%A5%E5%BC%82%E5%B8%B8%E4%BB%A3%E6%9B%BF%E9%94%99%E8%AF%AF%E7%A0%81.png" alt></p><h3 id="做法-v6">做法</h3><ul><li><font color="DeepPink"><strong>决定应该抛出受控(checked)异常还是非受控(unchecked)异常。</strong></font><ul><li>→如果调用者有责任在调用前检查必要状态,就抛出非受控异常。</li><li>→如果想拋出受控异常,你可以新建一个异常类,也可以使用现有的异常类。</li></ul></li><li>找到该函数的所有调用者,对它们进行相应调整,让它们使用异常。<ul><li>→如果函数抛出非受控异常,那么就调整调用者,使其在调用函数前做适当检查。每次修改后,编译并测试。</li><li>→如果函数拋出受控异常,那么就调整调用者,使其在try区段中调用该函数。</li></ul></li><li>修改该函数的签名,令它反映出新用法。</li></ul><h1>处理概括关系</h1><p>有一批重构手法专门用来处理类的概括关系(generalization,即继承关系),其中主要是将函数上下移动于继承体系之中。Pull Up Field和Pull Up Method都用于将特性向继承体系的上端移动,Push Down Method和Push Down Field则将特性向继承体系的下端移动。构造函数比较难以向上拉动,因此专门有一个Pull Up Constructor Body处理它。我们不会将构造函数往下推,因为Replace Constructor with Factory Method通常更管用。</p><p>Pull Up Method过程中最麻烦的一点就是:<font color="DeepPink"><strong>被提升的函数可能会引用只出现于子类而不出现于超类的特性。如果被引用的是个函数,你可以将该函数也一同提升到超类,或者在超类中建立一个抽象函数。在此过程中,你可能需要修改某个函数的签名,或建立一个委托函数。</strong></font></p><p><font color="DeepPink"><strong>如果两个函数相似但不相同,你或许可以先借助Form Template Method构造出相同的函数,然后再提升它们。</strong></font></p><h2 id="Form-Template-Method-塑造模板函数">Form Template Method 塑造模板函数</h2><p>你有一些子类,其中相应的某些函数以相同顺序执行类似的操作,但各个操作的细节上有所不同。<br>将这些操作分别放进独立函数中,并保持它们都有相同的签名,于是原函数也就变得相同了。然后将原函数上移至超类。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E5%A1%91%E9%80%A0%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0.png" alt></p><h3 id="动机-v11">动机</h3><p>继承是避免重复行为的一个强大工具。无论何时,只要你看见两个子类之中有类似的函数,就可以把它们提升到超类。但是如果这些函数并不完全相同该怎么办?我们仍有必要尽量避免重复,但又必须保持这些函数之间的实质差异。</p><p>常见的一种情况是:<font color="DeepPink"><strong>两个函数以相同顺序执行大致相近的操作,但是各操作不完全相同。这种情况下我们可以将执行操作的序列移至超类,并借助多态保证各操作仍得以保持差异性。这样的函数被称为Template Method(模板函数）</strong></font></p><h2 id="Replace-Inheritance-with-Delegation-以委托取代继承">Replace Inheritance with Delegation 以委托取代继承</h2><p>某个子类只使用超类接口中的一部分,或是根本不需要继承而来的数据。<br>在子类中新建一个字段用以保存超类;调整子类函数,令它改而委托超类;然后去掉两者之间的继承关系。</p><p><img data-src="/images/refactoring-improving-the-design-of-existing-code-notes/%E4%BB%A5%E5%A7%94%E6%89%98%E5%8F%96%E4%BB%A3%E7%BB%A7%E6%89%BF.png" alt></p><h3 id="动机-v12">动机</h3><p>继承是个好东西,但有时候它并不是你要的。你常常会遇到这样的情况:一开始继承了一个类,随后发现超类中的许多操作并不真正适用于子类。这种情况下,你所拥有的接口并未真正反映出子类的功能。或者,你可能发现你从超类中继承了大堆子类并不需要的数据,抑或你可能发现超类中的某些protected函数对子类并没有什么意义。</p><p>你可以选择容忍,并接受传统说法:子类可以只使用超类功能的一部分。但这样做的结果是:代码传达的信息与你的意图南辕北辙—这是一种混淆,你应该将它去除。</p><p><font color="DeepPink"><strong>如果以委托取代继承,你可以更清楚地表明:你只需要受托类的一部分功能。接口中的哪一部分应该被使用,哪一部分应该被忽略,完全由你主导控制。</strong></font>这样做的成本则是需要额外写出委托函数,但这些函数都非常简单,极少可能出错。</p><h2 id="Replace-Delegation-with-Inheritance-以继承取代委托">Replace Delegation with Inheritance 以继承取代委托</h2><p>你在两个类之间使用委托关系,并经常为整个接口编写许多极简单的委托函数。<br>让委托类继承受托类。</p><h3 id="动机-v13">动机</h3><p>本重构与Replace Inheritance with Delegation恰恰相反。如果你发现自己需要使用受托类中的所有函数,并且费了很大力气编写所有极简的委托函数,本重构可以帮助你轻松回头使用继承。</p><p>两条告诫需牢记于心。首先,<font color="DeepPink"><strong>如果你并没有使用受托类的所有函数,那么就不应该使用Replace Delegation With Inheritance,因为子类应该总是遵循超类的接口。</strong></font>如果过多的委托函数让你烦心,你有别的选择:你可以通过Remove Middle Man让客户端自己调用受托函数,也可以使用Extract Superclass将两个类接口相同的部分提炼到超类中,然后让两个类都继承这个新的超类;你还可以用类似的手法使用Extract Interface。</p><p>另一种需要当心的情况是:受托对象被不止一个其他对象共享,而且受托对象是可变的。在这种情况下,你就不能将委托关系替换为继承关系,因为这样就无法再共享数据了。数据共享是必须由委托关系承担的一种责任,你无法把它转给继承关系。如果受托对象是不可变的,数据共享就不成问题,因为你大可放心地复制对象,谁都不会知道。</p><h1>大型重构</h1><p>要指出继承体系是否承担了两项不同的责任并不困难:<font color="DeepPink"><strong>如果继承体系中的某一特定层级上的所有类,其子类名称都以相同的形容词开始,那么这个体系很可能就是承担着两项不同的责任。</strong></font></p><h1>重构，复用与现实</h1><p>关于研究,Ralph Johnson给我上了重要的一课:如果有人(文章读者或是演讲会听众)说“我不懂”或者不打算接受它,那就是我们的失败。我们有责任努力发展自己的思想,并将它清楚表达出来。</p><h1>总结</h1><p>正如我所说,这是一种可以学习的技术。那么,应该如何学习呢?</p><ul><li>随时挑一个目标。某个地方的代码开始发臭了,你就应该将问题解决掉。你应该朝目标前进,达成目标后就停止。你之所以重构,不是为了探索真善美(至少不全是),而是为了让你的系统更容易被人理解,为了防止程序变得散乱。</li><li><font color="DeepPink"><strong>没把握就停下来。朝目标前进的过程中,可能会有这样的时候:你无法证明自己所做的一切能够保持程序原本的语义。此时你就应该停下来。如果代码已经改善了一些,就发布你的成果;如果没有,就撤销所有修改。</strong></font></li><li>学习原路返回。重构的原则不好学,而且很容易遗失准头。就连我自己,也经常忘记这些原则。我有时会连续做两三项甚至四项重构,而没有每次执行测试用例。当然那是因为我完全相信,即使没有测试的帮助,我也不会出错。于是我就放手干了。然后,“砰”的一声,某个测试失败,我却无法找到究竟哪一次修改造成了这个问题。</li><li>二重奏。和别人一起重构,可以收到更好的效果。两人结对,对于任何一种软件开发都有很多好处,对于重构也不例外。重构时,小心谨慎、按部就班的态度是有好处的。如果两人结伴,你的搭档能够帮助你一步一步前进,你也能够帮助他。重构时,时刻留意远景目标是有好处的。如果两人结伴,你的搭档可能看到你没看到的东西,能想到你没想到的事情。重构时,明智结束是有好处的。如果你的搭档不知道你在干什么,那就意味你肯定也不知道自己在干什么,此时你就应该结束重构。最重要的是,重构时,拥有绝对自信是绝对有好处的。如果两人结伴,你的搭档能够给你温柔的鼓励,让你不至于灰心丧气。</li></ul>]]></content>
      <categories>
        <category>Refactoring</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Design</tag>
        <tag>Refactoring</tag>
        <tag>Code</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Elasticsearch集群规模和性能调优</title>
    <url>/elasticsearch-cluster-sizing-and-performance-tuning.html</url>
    <content><![CDATA[<blockquote><p>翻译自：Elasticsearch Cluster Sizing and Performance Tuning<br>地址：<a href="https://www.elastic.co/cn/blog/found-sizing-elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/found-sizing-elasticsearch</a></p></blockquote><a id="more"></a><p>集群应该有多少个节点?应该创建多少个副本?为了获得最佳的搜索性能，分片(Shard)的最佳平均大小是多少？诸如此类的问题只有你自己知道答案。</p><p>没有人知道你的数据和查询结构，你使用的硬件，你的吞吐量。没有数学公式，也没有理论计算方法。如果你带着这样的期望而来，我很抱歉让你失望。但是别担心，你可以自己回答。</p><h1>数据的大小</h1><p>如您所知，由于分布式体系结构中的硬件限制，数据被划分为更小的块，并分布在不同的节点上。这些小片段称为分片。实际上，当其中一个节点发生故障时，与原始节点完全相同的分片仍保留在备用中。这些分片称为副本。</p><h2 id="分片的最佳数量是多少">分片的最佳数量是多少?</h2><p><font color="DeepPink"><strong>每个请求在每个分片的单个线程中处理。如果您有多个分片，则可以并行处理查询。</strong></font>将分片数量增加到一定程度可能会对性能产生积极影响，但这并不完全正确。如果您有很多小分片，则过一会儿，将有大量并行任务需要在队列中等待。当同时接收到多个请求时，这将降低性能。</p><p>分片是Lucene索引，它通过一个或多个段来将数据存储在磁盘上。较大的段能更有效地存储数据。因此，增加分片的数量可能并不总是一个好主意。</p><p><img data-src="/images/elasticsearch-cluster-sizing-and-performance-tuning/shard-lucene-index-segment.jpeg" alt></p><p>您可以通过在单节点群集中创建分片来进行测试。考虑一下索引的大小和我在下一节中提到的平均分片大小，一次增加一个分片。您可以自己找到理想分片的数量。</p><h2 id="分片的最佳平均大小是多少">分片的最佳平均大小是多少?</h2><p>在这个问题上没有绝对的准则。您应该为自己选择一个起点，然后尝试找到最佳尺寸。Elasticsearch官网的建议如下：</p><ul><li>分片的平均大小应在几GB到几十GB之间。</li><li>确定用例的最佳大小的最佳方法是使用您自己的数据和查询进行测试。</li></ul><h2 id="副本的最佳数量是多少">副本的最佳数量是多少?</h2><p>考虑到硬件故障，建议至少有一个副本。副本提高了搜索性能，但并不总是如此。这取决于您的硬件和索引的行为(大量写入或大量搜索)。如果您的索引写入很多，那么增加副本的数量不是一个好主意。由于数据复制过程会导致资源使用增加，并且搜索性能会下降。</p><h1>让负载更加均衡</h1><p>Elasticsearch自己管理负载均衡。但是，我们必须考虑要有多少个节点，有多少个分片和副本，并且必须在它们之间建立一定比例以实现均匀的负载分配。</p><blockquote><p>此时，我们应该确保节点的数量和分片(主分片+副本)的数量是成比例的。</p></blockquote><p>例如，如果集群中有5个节点，那么分片的数量应该是5的倍数。这对于Elasticsearch确保适当的负载均衡非常重要。如果节点之间存在不均衡的负载分布，那么具有更多分片的节点的资源使用率将更高，并且瞬时平均负载将高于其他节点。换句话说，其他节点上的资源将使用得更少，而具有更多分片的节点将使用得更多。</p><p><font color="DeepPink"><strong>具有更多分片的节点会收到更多请求。</strong></font>一段时间后，这些节点将无法及时处理请求，传入的请求将在队列中等待。在这种情况下，这些节点成为系统的瓶颈，增加了所有请求的响应时间。<font color="DeepPink"><strong>因为传入的请求必须通过所有分片才能完成。</strong></font>例如下图，每个主碎片共有6个节点(DG_Data1…DG_Data6)、9个主分片(0…8)和2个副本，主分片共有18个副本。我们有6个节点和27个分片。27/6 = 4.5它不是整数。这意味着有些节点有5个分片，有些节点有4个分片。因此，与其他节点相比，节点DG_Data2、DG_Data4和DG_Data6的平均负载更高。因此，如果我们将主分片的数量增加到10个，我们将在集群中得到均匀的负载分布。</p><p><img data-src="/images/elasticsearch-cluster-sizing-and-performance-tuning/Scheme-2.png" alt="Scheme-2"></p><p>假设我们向该集群发送了一个请求。将从0到8的所有分片中搜索与该请求匹配的文档。那么将访问多少个节点？在此群集中，必须至少访问3个节点才能完成搜索请求。 Elasticsearch将确定将访问哪些节点。例如，节点将是DG_DATA1（4,7），DG_DATA2（0,1,3,5），DG_DATA5（2,6,7,8）。</p><blockquote><p>我们的态度和目标<font color="DeepPink"><strong>应该是通过访问尽可能少的节点来完成我们的请求。</strong></font></p></blockquote><p>这并不意味着增加副本的数量直到访问一个节点就能完成请求，这是非常危险的。因为将数据复制到副本会浪费资源。</p><h1>确定索引的行为</h1><p>索引的结构及其映射(mapping)非常重要。首先，您需要确定索引是哪种索引。是大量写入还是大量读取？其次，我们应该将文档设计得尽可能平坦。数据去范式化可能是一个选择，如果我们不关心它的负面影响。如果我们无法设计平面文档，则根据索引的行为，我们可能更喜欢嵌套(nested)或子(join)文档类型。</p><blockquote><p>译者注：这里的平坦/面指的是设计mapping的时候，尽量将数据打平，比如之前在关系型数据库中是关联表，在elasticsearch中应该冗余到一个文档中。</p></blockquote><h2 id="读密集型索引">读密集型索引</h2><p>如果来自索引的大多数请求都是搜索请求，我们就可以说索引是读密集型的。换句话说，搜索操作的数量大于索引操作。比如：电商中的产品的索引。一个普通的电商应用更新的产品非常少，但是大量的用户在搜索产品。</p><p><font color="DeepPink"><strong>与子文档相比，嵌套文档可以提高搜索性能。但是不要忘记将数据写入嵌套文档是非常昂贵的。</strong></font></p><p><font color="DeepPink"><strong>增加副本的数量可以在一定程度上提高性能。</strong></font>在某些情况下，由于硬件的限制，性能会下降。您可以通过逐个增加副本的数量来找到这个断点。您可以使用诸如JMeter、Apache Bench ab之类的工具来度量搜索性能，同时增加副本的数量。</p><h2 id="写密集型索引">写密集型索引</h2><p>在这些索引中，索引操作的数量大于搜索操作的数量。在包含此类索引的群集中，资源通常用于写入数据。如果增加副本的数量，则写入分片的文档将被复制到副本，因此写入过程将增加。这将导致资源使用量增加。</p><p>子文档读得快，写得慢。因此，这种类型的索引更受欢迎。</p><h1>只要获取你需要的数据</h1><blockquote><p>只需提取所需的数据即可。检索不必要的数据会增加网络和计算的成本。不要索引不需要的数据。</p></blockquote><p>在查询中尽可能有效地使用&quot;from&quot;,&quot;size&quot;和&quot;source&quot;属性。请记住，服务器在尝试写入数据时也会使用资源。</p><p>使用best_compression压缩_source数据。</p><h1>监控索引大小</h1><p>索引的大小可能会随时间增长，这可能要求您对集群或硬件进行一些更改。</p><h2 id="定期Reindex索引">定期Reindex索引</h2><p>特别是在写密集型索引中，索引大小会随着时间增加。这是由于更新的文档。<font color="DeepPink"><strong>实际上，在Elasticsearch中，文档不会更新，因为它们是不可变的。因此，使用新数据创建了另一个文档，并且该文档的版本增加了一个。重新索引索引时，新索引将包含最新版本的文档。因此索引大小将减小。</strong></font></p><h2 id="强制合并">强制合并</h2><p>在Elasticsearch中，所有分片都是Lucene索引。Lucene索引由一个或多个文件组成。<font color="DeepPink"><strong>强制合并使我们可以合并这些文件并导致形成更大的段。较大的段能更有效地存储数据。</strong></font></p><h1>刷新间隔</h1><p><font color="DeepPink"><strong>刷新时间是建立索引后可搜索数据所需的时间。</strong></font> 这就是为什么Elasticsearch近实时，而不是实时的原因。</p><p>如果您的数据不经常更改，并且您不需要实时数据，则应增加或不使用刷新间隔。 如果您根本不希望刷新，则可以将其分配为-1。刷新是一项昂贵的任务。 较小的刷新时间可能会对搜索性能产生不利影响。</p><p>初始索引时，应将刷新间隔设置为-1。</p><p>作为一种选择，您可以在建立文档索引时发送刷新参数。 与刷新整个索引不同，只刷新该文档更有效。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /test/_doc/1?refresh</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test&quot;: &quot;test&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>译者注：refresh_interval设置为-1，并不意味着不进行进行refresh操作。</p></blockquote><h1>优先过滤上下文而不是查询</h1><p>如果您在搜索中不需要评分功能，请避免使用查询。 您应该首选过滤器上下文。 由于过滤器已缓存且不会影响得分，因此比查询要快。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.6/query-filter-context.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.6/query-filter-context.html</a></p><h1>初始索引时禁用副本</h1><p>索引文档时，首先将其写入主分片，然后将其复制到副本。复制到副本是一个代价高昂的操作，它限制了初始索引。因此，您应该禁用副本，直到初始索引完成。</p><h1>使用批量请求</h1><p>在索引操作中发送批量请求，尤其是在初始索引中。 批量请求比单个请求具有更好的性能。 请注意，请求限制为100 MB。</p><h1>监控您的集群和查询</h1><p>您应该使用性能监视工具（例如New Relic）监视集群，该工具具有Elasticsearch插件。 您可以检查节点的异常行为，平均负载，响应时间以及更改的影响。 通过_profiling API运行已识别的搜索，以查看各个组件的耗时。</p><h1>将ElasticClient对象用作Singleton</h1><p>建议在应用程序的生命周期内使用单个客户端和连接设置实例。 客户端是线程安全的，因此可以跨线程共享实例。 从单例中受益的实际移动部分是ConnectionSettings，因为缓存是按ConnectionSettings进行的。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/net-api/current/lifetimes.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/net-api/current/lifetimes.html</a></p><h1>首选去范式化而不是嵌套类型（Nested Type）</h1><p>如果您对查询进行概要分析，则可以确定将嵌套文档与父文档连接在一起是否需要花费大量时间。 在这种情况下，像在Vivek Mittal的情况下一样，非范式化可以提高性能。 我在下面分享了作为参考。</p><p><a href="https://blog.gojekengineering.com/elasticsearch-the-trouble-with-nested-documents-e97b33b46194" target="_blank" rel="noopener">https://blog.gojekengineering.com/elasticsearch-the-trouble-with-nested-documents-e97b33b46194</a></p><h1>结论</h1><p>在我看来，在elasticsearch，数据索引和搜索上创建索引非常简单。 困难的部分是性能和设计。 在本文中，我想与您分享我的经验。 尽管我不希望您回答所有问题，但这将提供一个起点。 我的建议是根据此处的信息测试所有内容，以找到适合您的最佳配置。 相信我，即使花费时间，您也会找到理想的解决方案。</p><blockquote><p>译者：<br>对于集群规模的确定，以写入密集型来看，应该可以通过业务量的预估确定想要的吞吐量，吞吐量/单台机器写入速度=》需要的节点数。<br>与kafka集群节点数量预估类似，不过kafka集群还需要考虑consumer的消费能力。</p></blockquote>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Cluster</tag>
        <tag>Size</tag>
        <tag>Tuning</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计三原则</title>
    <url>/three-principles-of-architecture.html</url>
    <content><![CDATA[<ul><li><p>合适原则<br>合适原则宣言：“合适优于业界领先”</p></li><li><p>简单原则<br>简单原则宣言：“简单优于复杂”。</p></li><li><p>演化原则<br>演化原则宣言：“演化优于一步到位”。</p></li></ul>]]></content>
  </entry>
  <entry>
    <title>网络分层模型</title>
    <url>/layered-network-model.html</url>
    <content><![CDATA[<p>两个网络分层模型：TCP/IP和OSI,一个是四层模型,一个是七层模型，这两者应该如何互相映射或者说互相解释呢?</p><a id="more"></a><p><img data-src="/images/layered-network-model/%E7%BD%91%E7%BB%9C4%E5%B1%827%E5%B1%82%E6%98%A0%E5%B0%84.png" alt></p><ul><li>第一层：物理层， TCP/IP里无对应；</li><li>第二层：数据链路层， 对应TCP/IP的链接层；</li><li>第三层：网络层， 对应TCP/IP的网际层；</li><li>第四层：传输层， 对应TCP/IP的传输层；</li><li>第五、六、七层：统一对应到TCP/IP的应用层。</li></ul>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>趣谈网络协议 笔记</title>
    <url>/fun-talk-about-network-protocols.html</url>
    <content><![CDATA[<p>趣谈网络协议 笔记<br>作者： 刘超</p><a id="more"></a><h1>网络协议</h1><p><img data-src="/images/fun-talk-about-network-protocols/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE.png" alt></p><h1>网络分层</h1><p><img data-src="/images/fun-talk-about-network-protocols/%E8%AF%B7%E6%B1%82%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82.png" alt></p><h1>无类型域间选路（CIDR）</h1><p>这种方式打破了原来设计的几类地址的做法，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个 IP 地址中有一个斜杠，斜杠后面有个数字 24。这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号。</p><p>伴随着 CIDR 存在的，一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。另一个是子网掩码，255.255.255.0。</p><blockquote><p>“无类型”的意思是选路决策是基于整个32位IP地址的掩码操作。而不管其IP地址是A类、B类或是C类。</p></blockquote><h1>DHCP：IP是怎么来的，又是怎么没的？</h1><h2 id="如何配置-IP-地址？">如何配置 IP 地址？</h2><p>net-tools：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo ifconfig eth1 10.0.0.1/24</span><br><span class="line">$ sudo ifconfig eth1 up</span><br></pre></td></tr></table></figure><p>iproute2：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo ip addr add 10.0.0.1/24 dev eth1</span><br><span class="line">$ sudo ip link set up eth1</span><br></pre></td></tr></table></figure><p>你可能会问了，自己配置这个自由度太大了吧，我是不是配置什么都可以？如果配置一个和谁都不搭边的地址呢？例如，旁边的机器都是 192.168.1.x，我非得配置一个 16.158.23.6，会出现什么现象呢？</p><p>不会出现任何现象，就是包发不出去呗。为什么发不出去呢？我来举例说明。</p><p>192.168.1.6 就在你这台机器的旁边，甚至是在同一个交换机上，而你把机器的地址设为了16.158.23.6。在这台机器上，你企图去 ping 192.168.1.6，你觉得只要将包发出去，同一个交换机的另一台机器马上就能收到，对不对？</p><p>可是 Linux 系统不是这样的，它没你想得那么智能。你用肉眼看到那台机器就在旁边，它则需要根据自己的逻辑进行处理。</p><p>要知道只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。</p><p>所以，你看着它有自己的源 IP 地址 16.158.23.6，也有目标 IP 地址 192.168.1.6，但是包发不出去，这是因为 MAC 层还没填。</p><p>自己的 MAC 地址自己知道，这个容易。但是目标 MAC 填什么呢？是不是填 192.168.1.6 这台机器的MAC 地址呢？</p><p>当然不是。Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址。如果发现不是呢？</p><p>Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。</p><p>如果你配置了网关的话，Linux 会获取网关的 MAC 地址，然后将包发出去。对于 192.168.1.6 这台机器来讲，虽然路过它家门的这个包，目标 IP 是它，但是无奈 MAC 地址不是它的，所以它的网卡是不会把包收进去的。</p><p>如果没有配置网关呢？那包压根就发不出去。</p><p>如果将网关配置为 192.168.1.6 呢？不可能，Linux 不会让你配置成功的，因为网关要和当前的网络至少一个网卡是同一个网段的，怎么可能 16.158.23.6 的网关是 192.168.1.6 呢？</p><p>所以，当你需要手动配置一台机器的网络 IP 时，一定要好好问问你的网络管理员。如果在机房里面，要去网络管理员那里申请，让他给你分配一段正确的 IP 地址。当然，真正配置的时候，一定不是直接用命令配置的，而是放在一个配置文件里面。不同系统的配置文件格式不同，但是无非就是 CIDR、子网掩码、广播地址和网关地址。</p><h2 id="动态主机配置协议（DHCP）">动态主机配置协议（DHCP）</h2><p>动态主机配置协议（Dynamic Host Configuration Protocol），简称DHCP。</p><h3 id="解析-DHCP-的工作方式">解析 DHCP 的工作方式</h3><p>当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，只知道自己的 MAC 地址。怎么办？先吼一句，我来啦，有人吗？这时候的沟通基本靠“吼”。这一步，我们称为DHCP Discover。</p><p>新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。广播包封装在UDP 里面，UDP 封装在 BOOTP 里面。其实 DHCP 是 BOOTP 的增强版，但是如果你去抓包的话，很可能看到的名称还是 BOOTP 协议。</p><p>在这个广播包里面，新人大声喊：我是新来的（Boot request），我的 MAC 地址是这个，我还没有IP，谁能给租给我个 IP 地址！</p><p>格式就像这样：</p><p>请求<br><img data-src="/images/fun-talk-about-network-protocols/%E8%AF%B7%E6%B1%82%E7%BD%91%E7%BB%9CIP%E7%9A%84%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="请求"></p><p>响应<br><img data-src="/images/fun-talk-about-network-protocols/%E5%93%8D%E5%BA%94%E8%AF%B7%E6%B1%82%E7%BD%91%E7%BB%9CIP%E7%9A%84%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="响应"></p><p>新来的机器很开心，它的“吼”得到了回复，并且有人愿意租给它一个 IP 地址了，这意味着它可以在网络上立足了。当然更令人开心的是，如果有多个 DHCP Server，这台新机器会收到多个 IP 地址，简直受宠若惊。</p><p><strong>它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址</strong>，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者。</p><p>当 DHCP Server 接收到客户机的 DHCP request 之后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。</p><h3 id="IP-地址的收回和续租">IP 地址的收回和续租</h3><p>既然是租房子，就是有租期的。租期到了，管理员就要将 IP 收回。</p><p>如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP 也是这样。</p><p>客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。</p><h1>交换机与VLAN</h1><h2 id="拓扑结构是怎么形成的？">拓扑结构是怎么形成的？</h2><p>我们常见到的办公室大多是一排排的桌子，每个桌子都有网口，一排十几个座位就有十几个网口，一个楼层就会有几十个甚至上百个网口。如果算上所有楼层，这个场景自然比你宿舍里的复杂多了。具体哪里复杂呢？我来给你具体讲解。</p><p>首先，这个时候，一个交换机肯定不够用，需要多台交换机，交换机之间连接起来，就形成一个稍微复杂的拓扑结构。</p><p>我们先来看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器1 只知道机器 4 的 IP 地址，当它想要访问机器 4，把包发出去的时候，它必须要知道机器 4 的 MAC 地址。</p><p><img data-src="/images/fun-talk-about-network-protocols/%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84.png" alt></p><p>于是机器 1 发起广播，机器 2 收到这个广播，但是这不是找它的，所以没它什么事。**交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。**于是机器 3 也收到广播信息了，但是这和它也没什么关系。</p><p>当然，交换机 B 也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广播的策略，将包转发到局域网三。这个时候，机器 4 和机器 5 都收到了广播信息。机器 4 主动响应说，这是找我的，这是我的 MAC 地址。于是一个 ARP 请求就成功完成了。</p><p>在上面的过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：机器 1 是在左边这个网口的。当了解到这些拓扑信息之后，情况就好转起来。当机器 2 要访问机器 1 的时候，机器 2 并不知道机器 1 的MAC 地址，所以机器 2 会发起一个 ARP 请求。这个广播消息会到达机器 1，也同时会到达交换机 A。这个时候交换机 A 已经知道机器 1 是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二和局域网三。</p><p>当机器 3 要访问机器 1 的时候，也需要发起一个广播的 ARP 请求。这个时候交换机 A 和交换机 B 都能够收到这个广播请求。交换机 A 当然知道主机 A 是在左边这个网口的，所以会把广播消息转发到局域网一。同时，交换机 B 收到这个广播消息之后，由于它知道机器 1 是不在右边这个网口的，所以不会将消息广播到局域网三。</p><h1>ICMP与ping</h1><h2 id="ICMP-协议的格式">ICMP 协议的格式</h2><p>ping 是基于 ICMP 协议工作的。ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，那具体是怎么控制的呢？</p><p>网络包在异常复杂的网络环境中传输时，常常会遇到各种各样的问题。当遇到问题的时候，总不能“死个不明不白”，要传出消息来，报告情况，这样才可以调整传输策略。</p><p>ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。</p><p><img data-src="/images/fun-talk-about-network-protocols/ICMP.png" alt></p><h2 id="ping：查询报文类型的使用">ping：查询报文类型的使用</h2><p>接下来，我们重点来看 ping 的发送和接收过程。<br><img data-src="/images/fun-talk-about-network-protocols/ping.png" alt></p><p>假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那当你在主机 A 上运行“ping 192.168.1.2”后，会发生什么呢?</p><p>ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为8；另外一个是顺序号，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</p><p>然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。</p><p>接下来，需要加入 MAC 头。<strong>如果在ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址</strong>，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</p><p>主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。</p><p>主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。</p><p>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><p>当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。</p><h1>网关（Gateway）</h1><h2 id="你了解-MAC-头和-IP-头的细节吗？">你了解 MAC 头和 IP 头的细节吗？</h2><p>一旦配置了 IP 地址和网关，往往就能够指定目标地址进行访问了。由于在跨网关访问的时候，牵扯到MAC 地址和 IP 地址的变化，这里有必要详细描述一下 MAC 头和 IP 头的细节。</p><p><img data-src="/images/fun-talk-about-network-protocols/MAC_IP.png" alt></p><p>在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断，这个目标 IP 地址，和当前机器的IP地址，是否在同一个网段。怎么判断同一个网段呢？需要 CIDR 和子网掩码。</p><p>如果不是同一网段，例如，你要访问你们校园网里面的 BBS，该怎么办？这就需要发往默认网关Gateway。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个。例如192.168.1.0/24 这个网段，Gateway 往往会是 192.168.1.1/24 或者 192.168.1.2/24。</p><p>如何发往默认网关呢？网关不是和源 IP 地址是一个网段的么？这个过程就和发往同一个网段的其他机器是一样的：将源地址和目标 IP 地址放入 IP 头中，通过 ARP 获得网关的 MAC 地址，将源 MAC 和网关的 MAC 放入 MAC 头中，发送出去。网关所在的端口，例如 192.168.1.1/24 将网络包收进来，然后接下来怎么做，就完全看网关的了。</p><p>网关往往是一个路由器，是一个三层转发的设备。啥叫三层设备？就是把 MAC 头和 IP头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。</p><blockquote><p>很多情况下，人们把网关就叫作路由器。其实不完全准确，而另一种比喻更加恰当：<font color="DeepPink"><strong>路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP地址相同的网段，每只手都是它握住的那个局域网的网关。</strong></font></p></blockquote><p>任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。</p><h2 id="IP-头和-MAC-头哪些变、哪些不变？">IP 头和 MAC 头哪些变、哪些不变？</h2><p><font color="DeepPink"><strong>MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于 IP 地址是否改变。不改变 IP 地址的网关，我们称为转发网关；改变 IP 地址的网关，我们称为NAT 网关。</strong></font></p><h1>TCP 协议</h1><ul><li>顺序问题 ，稳重不乱；</li><li>丢包问题，承诺靠谱；</li><li>连接维护，有始有终；</li><li>流量控制，把握分寸；</li><li>拥塞控制，知进知退。</li></ul><blockquote><p>SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接</p></blockquote><h2 id="TCP-的三次握手">TCP 的三次握手</h2><p><img data-src="/images/fun-talk-about-network-protocols/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><h2 id="TCP-四次挥手">TCP 四次挥手</h2><p><img data-src="/images/fun-talk-about-network-protocols/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt></p><p>断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消息后，发送知道了，就进入 CLOSE_WAIT 的状态。</p><p>A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间。</p><p>如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要求 A 最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时间到达 B。</p><p>A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B 发送的所有的包都死翘翘，再空出端口来。</p><p>等待的时间设为 2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30秒，1 分钟和 2 分钟等。</p><p>还有一个异常情况就是，B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，怎么办呢？按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送 RST，B 就知道 A 早就跑了。</p><h1>HTTPS 协议</h1><p><a href="/attachments/趣谈网络协议/15HTTPS协议：点外卖的过程原来这么复杂.pdf" target="_blank">HTTPS协议：点外卖的过程原来这么复杂</a></p><h1>HTTPDNS</h1><p><a href="/attachments/趣谈网络协议/19HTTPDNS：网络世界的地址簿也会指错路.pdf" target="_blank">HTTPDNS：网络世界的地址簿也会指错路</a></p><h1>数据中心</h1><p><a href="/attachments/趣谈网络协议/21数据中心：我是开发商，自己拿地盖别墅.pdf" target="_blank">数据中心：我是开发商，自己拿地盖别墅</a></p><h1>VPN</h1><p>VPN通过隧道技术在公众网络上仿真一条点到点的专线，是<font color="DeepPink"><strong>通过利用一种协议来传输另外一种协议的技术</strong></font>。</p><p><a href="/attachments/趣谈网络协议/22VPN：朝中有人好做官.pdf" target="_blank">VPN：朝中有人好做官</a></p><h1>移动网络</h1><p><a href="/attachments/趣谈网络协议/23移动网络：去巴塞罗那，手机也上不了脸书.pdf" target="_blank">移动网络：去巴塞罗那，手机也上不了脸书</a></p><h1>云中网络</h1><p>主要讲虚拟机、虚拟网卡</p><p><a href="/attachments/趣谈网络协议/24云中网络：自己拿地成本高，购买公寓更灵活.pdf" target="_blank">云中网络：自己拿地成本高，购买公寓更灵活</a></p><h1>软件定义网络（SDN）</h1><p><a href="/attachments/趣谈网络协议/25软件定义网络：共享基础设施的小区物业管理办法.pdf" target="_blank">软件定义网络：共享基础设施的小区物业管理办法</a></p><h1>云中的网络安全</h1><p><a href="/attachments/趣谈网络协议/26云中的网络安全：虽然不是土豪，也需要基本安全和保障.pdf" target="_blank">云中的网络安全：虽然不是土豪，也需要基本安全和保障</a></p><h1>云中的网络QoS（Quality of Service）</h1><p><a href="/attachments/趣谈网络协议/27云中的网络QoS：邻居疯狂下电影，我该怎么办？.pdf" target="_blank">云中的网络QoS：邻居疯狂下电影，我该怎么办？</a></p><h1>云中网络的隔离GRE、VXLAN</h1><p><a href="/attachments/趣谈网络协议/28云中网络的隔离GRE、VXLAN：虽然住一个小区，也要保护隐私.pdf" target="_blank">云中网络的隔离GRE、VXLAN：虽然住一个小区，也要保护隐私</a></p><h1>容器网络</h1><p><a href="/attachments/趣谈网络协议/29容器网络：来去自由的日子，不买公寓去合租.pdf" target="_blank">容器网络：来去自由的日子，不买公寓去合租</a></p><h1>容器网络之Flannel</h1><p><a href="/attachments/趣谈网络协议/30容器网络之Flannel：每人一亩三分地.pdf" target="_blank">容器网络之Flannel：每人一亩三分地</a></p><h1>容器网络之Calico</h1><p><a href="/attachments/趣谈网络协议/31容器网络之Calico：为高效说出善意的谎言.pdf" target="_blank">容器网络之Calico：为高效说出善意的谎言</a></p><h1>RPC</h1><p><a href="/attachments/趣谈网络协议/32RPC协议综述：远在天边，近在眼前.pdf" target="_blank">RPC协议综述：远在天边，近在眼前</a></p><p><a href="/attachments/趣谈网络协议/33基于XML的SOAP协议：不要说NBA，请说美国职业篮球联赛.pdf" target="_blank">基于XML的SOAP协议：不要说NBA，请说美国职业篮球联赛</a></p><p><a href="/attachments/趣谈网络协议/34基于JSON的RESTful接口协议：我不关心过程，请给我结果.pdf" target="_blank">基于JSON的RESTful接口协议：我不关心过程，请给我结果</a></p><p><a href="/attachments/趣谈网络协议/35二进制类RPC协议：还是叫NBA吧，总说全称多费劲.pdf" target="_blank">二进制类RPC协议：还是叫NBA吧，总说全称多费劲</a></p><p><a href="/attachments/趣谈网络协议/36跨语言类RPC协议：交流之前，双方先来个专业术语表.pdf" target="_blank">跨语言类RPC协议：交流之前，双方先来个专业术语表</a></p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 磁盘分区、挂载</title>
    <url>/linux-mount-partition.html</url>
    <content><![CDATA[<p>Linux 磁盘分区、挂载</p><a id="more"></a><p>查看已挂账的磁盘</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -hl /*</span><br></pre></td></tr></table></figure><p>查看分区</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure><p>分区指定文件系统（会格式化）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkfs.xfs -f /dev/vdb</span><br></pre></td></tr></table></figure><p>挂载</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount /dev/vdb /data</span><br></pre></td></tr></table></figure><p><strong>以上挂载重启后失效</strong></p><p>查看挂载结果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -TH</span><br></pre></td></tr></table></figure><p>blkid 磁盘分区，查询磁盘分区的UUID。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blkid /dev/vdb</span><br></pre></td></tr></table></figure><p>vim编辑/etc/fstab</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UUID=37aeb018-9dfd-412f-81c1-583f1eb1189f /data                   xfs     defaults        0 2</span><br></pre></td></tr></table></figure><p>lsblk 查看分区和磁盘</p>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Linux</tag>
        <tag>Mount</tag>
        <tag>Partition</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentry 高可用部署</title>
    <url>/sentry-high-availability-deploy.html</url>
    <content><![CDATA[<blockquote><p>Sentry 高可用部署，部署分析基于Sentry 10.1.0.dev 05e720a7<br>对应dockerhub镜像版本分别为：<br>getsentry/snuba:31c967e774759c0548652d986645fdff844e0a39<br>getsentry/sentry:8549f2a492c803bab77af26e7417272975b9369a<br>getsentry/symbolicator:94cdbb7b543ebe53744144305db21a56b6a0d5a8</p></blockquote><a id="more"></a><p>Sentry官方对于<a href="https://docs.sentry.io/server/" target="_blank" rel="noopener">自托管</a>推荐的部署方式是<a href="https://docs.sentry.io/server/installation/" target="_blank" rel="noopener">Docker Compose</a>,但这种方式有以下几个缺点：</p><ul><li>所有服务都部署在一台机器上</li><li>所有的组件都不是高可用的</li></ul><p>对于生产环境来说，组件高可用是一个必备的条件，所以有了下面的高可用部署，高可用部署分为两部分：</p><ul><li>Sentry依赖中间件的高可用</li><li>Sentry本身组件的高可用</li></ul><h1>Sentry 服务</h1><p>Sentry具体的服务关系及依赖，具体见下图：</p><p><img data-src="/images/sentry-high-availability-deploy/Sentry.png" alt></p><p>需要注意以下几点：</p><ul><li>symbolicator、symbolicator-cleanup 依赖挂载卷sentry-symbolicator:/data</li><li>web、cron、worker、post-process-forwarder、sentry-cleanup 也依赖挂载卷，具体可以可见：<a href="https://docs.sentry.io/server/filestore/" target="_blank" rel="noopener">https://docs.sentry.io/server/filestore/</a></li></ul><p>为什么需要关注挂载卷？</p><p>因为挂载卷依赖存储服务，如果没用高可用的存储服务，Sentry自身组件就难以做到全部高可用。</p><h1>部署</h1><h2 id="Sentry依赖中间件">Sentry依赖中间件</h2><ul><li>Sentry依赖中间件的高可用，可以通过购买云服务商的服务来实现或者自己搭建。</li><li>通过修改sentry onpremise将Sentry依赖的服务替换为相关的ip或者域名，具体代码可以参考：<a href="https://github.com/jiankunking/onpremise" target="_blank" rel="noopener">jiankunking/onpremise</a>。</li></ul><h2 id="Sentry自身服务">Sentry自身服务</h2><p>将Sentry服务拆分，部署到kubernetes集群中，具体设置参考onpremise中docker-compose.yml中的启动命令、端口、环境变量来设置。</p><p>其中有以下几点需要注意：</p><ul><li>Sentry各个服务的启动命令，相比docker-compose.yml中command，不太一致，简单列一下：<ul><li>snuba api</li><li>snuba consumer --auto-offset-reset=latest --max-batch-time-ms 750</li><li>snuba replacer --auto-offset-reset=latest --max-batch-size 3</li><li>symbolicator run</li><li>sentry run web --loglevel DEBUG</li><li>sentry run cron</li><li>sentry run worker</li><li>…</li></ul></li><li><a href="https://github.com/jiankunking/snuba" target="_blank" rel="noopener">snuba</a> api默认监听的是127.0.0.1，修改为0.0.0.0，具体修改位置参见：<br><a href="https://github.com/jiankunking/snuba/commit/69fee6253c6a78e7c2668bf6c86692e4df8fe012" target="_blank" rel="noopener">https://github.com/jiankunking/snuba/commit/69fee6253c6a78e7c2668bf6c86692e4df8fe012</a></li><li><a href="https://github.com/jiankunking/sentry" target="_blank" rel="noopener">sentry</a> sentry/conf/server.py中KAFKA_CLUSTERS默认是localhost:9092,修改方式参见：<br><a href="https://github.com/jiankunking/onpremise/blob/master/sentry/cover/server.py#L1640" target="_blank" rel="noopener">https://github.com/jiankunking/onpremise/blob/master/sentry/cover/server.py#L1640</a></li><li>构建sentry镜像，当启动命令为post-process-forwarder时，需要将自定义后的config.yml、sentry.conf.py拷贝到镜像/etc/sentry目录下，具体参见：<br><a href="https://github.com/jiankunking/onpremise/blob/master/sentry/Dockerfile#L10" target="_blank" rel="noopener">https://github.com/jiankunking/onpremise/blob/master/sentry/Dockerfile#L10</a></li><li>sentry 环境变量中添加C_FORCE_ROOT=true，可以强制以root身份运行</li><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh" target="_blank" rel="noopener">install.sh脚本</a><ul><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh#L113" target="_blank" rel="noopener">初始化clickhouse数据库结构</a></li><li><a href="https://github.com/jiankunking/onpremise/blob/master/install.sh#L142" target="_blank" rel="noopener">添加初始用户</a></li></ul></li><li>sentry worker依赖于sentry cron，所以不能只部署worker，否则会有下面的错误提示：Background workers haven’t checked in recently. This is likely an issue with your configuration or the workers aren’t running.</li></ul><h1>小结</h1><p>总的来说，将sentry部署到kubernetes中，需要注意的点还是挺多的，很多细节需要看代码来排查。</p><p>2020-06-17 更新</p><p>Sentry 社区版不支持高可用的ClickHouse分布式表。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Distributed tables are not officially supported. </span><br><span class="line">DATASET_MODE would switch to distributed table names, but bootstrap won&apos;t work. </span><br><span class="line">You would have to manage your tables (create and all DDL operations) manually. </span><br><span class="line">This is not a support process, I can give you some hints, but you would be doing it at your own risk.</span><br><span class="line"></span><br><span class="line">On the other hand, we are working on this support though we cannot commit to a timeline at this time.</span><br></pre></td></tr></table></figure><p><a href="https://github.com/getsentry/snuba/issues/847" target="_blank" rel="noopener">The environment variable DATASET_MODE does not work</a></p><h1>二期</h1><p><img data-src="/images/sentry-high-availability-deploy/Sentry%E9%87%8D%E6%9E%84.png" alt></p><h2 id="具体分析">具体分析</h2><p><img data-src="/images/sentry-high-availability-deploy/Sentry%E9%87%8D%E6%9E%84%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90.png" alt></p><h1>关于本文的一些交流</h1><p><a href="https://forum.sentry.io/t/sentry-high-availability-deploy/11838/4" target="_blank" rel="noopener">https://forum.sentry.io/t/sentry-high-availability-deploy/11838/4</a></p><p><a href="https://github.com/getsentry/onpremise/issues/747#issuecomment-729850059" target="_blank" rel="noopener">https://github.com/getsentry/onpremise/issues/747#issuecomment-729850059</a></p>]]></content>
      <categories>
        <category>Sentry</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Sentry</tag>
        <tag>Deploy</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL实战45讲 笔记</title>
    <url>/45-lectures-on-mysql-in-practice.html</url>
    <content><![CDATA[<p>MySQL实战45讲 笔记<br>作者： 林晓斌</p><a id="more"></a><h1>基础架构：一条SQL查询语句是如何执行的？</h1><p><img data-src="/images/45-lectures-on-mysql-in-practice/mysql_logical_architecture_diagram.png" alt></p><p><strong>大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。</strong></p><p>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>好在MySQL也提供了这种&quot;按需使用&quot;的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select SQL_CACHE * from T where ID=10；</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p></blockquote><h1>日志系统：一条SQL更新语句是如何执行的？</h1><h2 id="重要的日志模块：redo-log">重要的日志模块：redo log</h2><p>当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><p>InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p><p><img data-src="/images/45-lectures-on-mysql-in-practice/checkpoint_and_write_pos.png" alt></p><p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p>如果write pos追上checkpoint，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p><p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。</p><h2 id="重要的日志模块：binlog">重要的日志模块：binlog</h2><p>MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog(归档日志)。</p><p>我想你肯定会问，为什么会有两份日志呢？</p><p>因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统-也就是redo log来实现crash-safe能力。</p><p>这两种日志有以下三点不同。</p><ol><li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li><li>redo log是物理日志，记录的是&quot;在某个数据上做了什么修改&quot;；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如&quot;给ID=2这一行的c字段加1 &quot;。</li><li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。&quot;追加写&quot;是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol><p>有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。</p><ol><li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li><li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交(commit)状态，更新完成。</li></ol><p>最后三步看上去有点&quot;绕&quot;，将redo log的写入拆成了两个步骤：prepare和commit，这就是&quot;两阶段提交&quot;。</p><h2 id="两阶段提交">两阶段提交</h2><p>为什么必须有&quot;两阶段提交&quot;呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？</p><p>前面我们说过了，binlog会记录所有的逻辑操作，并且是采用&quot;追加写&quot;的形式。如果你的DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。这里的&quot;定期&quot;取决于系统的重要性，可以是一天一备，也可以是一周一备。</p><p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p><ul><li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</li><li>然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li></ul><p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p><p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要&quot;两阶段提交&quot;。这里不妨用反证法来进行解释。</p><p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？</p><ol><li>先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。<br>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。<br>然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</li><li>先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务⽆效，所以这一行c的值是0。但是binlog里面已经记录了&quot;把c从0改成1&quot;这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</li></ol><p>可以看到，如果不使用&quot;两阶段提交&quot;，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p><p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？<br>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个&quot;不一致&quot;就会导致你的线上出现主从数据库不一致的情况。</p><p>简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p><h1>事务隔离：为什么你改了我还看不见？</h1><p>SQL标准的事务隔离级别包括：</p><ul><li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li><li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</li><li><strong>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</strong></li><li>串行化，顾名思义是对于同一行记录，“写&quot;会加&quot;写锁”，“读&quot;会加&quot;读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在&quot;可重复读&quot;隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在&quot;读提交&quot;隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，&quot;读未提交&quot;隔离级别下直接返回记录上的最新值，没有视图概念；而&quot;串行化&quot;隔离级别下直接用加锁的方式来避免并行访问。</p><p>总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要&quot;可重复读&quot;的场景呢？我们来看一个数据校对逻辑的案例。</p><p>假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。</p><p>这时候使用&quot;可重复读&quot;隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p><h2 id="事务隔离的实现">事务隔离的实现</h2><p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明&quot;可重复读&quot;。</p><p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p><p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。</p><p><img data-src="/images/45-lectures-on-mysql-in-practice/read-view.png" alt></p><p>当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，<strong>在视图A、B、C里面，这一个记录的值分别是1、2、4</strong>，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制(MVCC)。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。</p><p>同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。</p><h1>深入浅出索引(上)</h1><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用&quot;N叉&quot;树。这里，&quot;N叉&quot;树中的&quot;N&quot;取决于数据块的大小。</p><p><font color="DeepPink"><strong>以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</strong></font></p><p>N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</p><p>不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM树等数据结构也被用于引擎设计中，这里我就不再一一展开了。</p><p><font color="DeepPink"><strong>你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。</strong></font></p><p>在MySQL中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。</p><h2 id="InnoDB-的索引模型">InnoDB 的索引模型</h2><p>**主键索引的叶子节点存的是整行数据。**在InnoDB里，主键索引也被称为聚簇索引(clustered index)。<br>**非主键索引的叶子节点内容是主键的值。**在InnoDB里，非主键索引也被称为二级索引(secondary index)。<br>根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 主键列为ID的表，表中有字段k，并且在k上有索引。</span><br><span class="line">create table T(</span><br><span class="line">id int primary key,</span><br><span class="line">k int not null,</span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure><ul><li>如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。</li></ul><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p><h2 id="索引维护">索引维护</h2><p>B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。</p><blockquote><p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事⽆绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。</p></blockquote><p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。</p><p>插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。</p><p>也就是说，<font color="DeepPink"><strong>自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</strong></font></p><p>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p><p>除了考虑性能外，我们还可以从存储空间的⻆度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型(bigint)则是8个字节。</p><p>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</p><p>所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</p><p>有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p><ol><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ol><p>你一定看出来了，这就是典型的KV场景。</p><p>由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。</p><p>这时候我们就要优先考虑上一段提到的&quot;尽量使用主键查询&quot;原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p><h1>深入浅出索引(下)</h1><p>在下面这个表T中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？</p><p>下面是这个表的初始化语句。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table T (</span><br><span class="line">ID int primary key,</span><br><span class="line">k int NOT NULL DEFAULT 0,</span><br><span class="line">s varchar(16) NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">index k(k))</span><br><span class="line">engine=InnoDB;</span><br><span class="line">insert into T values(100,1, &apos;aa&apos;),(200,2,&apos;bb&apos;),(300,3,&apos;cc&apos;),(500,5,&apos;ee&apos;),(600,6,&apos;ff&apos;),(700,7,&apos;gg&apos;);</span><br></pre></td></tr></table></figure><p><img data-src="/images/45-lectures-on-mysql-in-practice/InnoDB%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.png" alt></p><p>现在，我们一起来看看这条SQL查询语句的执行流程：</p><ol><li>在k索引树上找到k=3的记录，取得 ID = 300；</li><li>再到ID索引树查到ID=300对应的R3；</li><li>在k索引树取下一个值k=5，取得ID=500；</li><li>再回到ID索引树查到ID=500对应的R4；</li><li>在k索引树取下一个值k=6，不满足条件，循环结束。</li></ol><p>在这个过程中，<strong>回到主键索引树搜索的过程，我们称为回表</strong>。可以看到，这个查询过程读了k索引树的3条记录(步骤1、3和5)，回表了两次(步骤2和4)。</p><h2 id="覆盖索引">覆盖索引</h2><p>如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经&quot;覆盖了&quot;我们的查询需求，我们称为覆盖索引。</p><h2 id="索引下推">索引下推</h2><p>而MySQL 5.6 引入的索引下推优化(index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><h1>全局锁和表锁</h1><p>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。</p><h2 id="全局锁">全局锁</h2><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock(FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句(数据的增删改)、数据定义语句(包括建表、修改表结构等)和更新类事务的提交语句。</p><p>**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都select出来存成文本。</p><p>官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？<strong>一致性读是好，但前提是引擎要支持这个隔离级别</strong>。比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。</p><p>所以，<strong>single-transaction方法只适用于所有的表使用事务引擎的库</strong>。如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。</p><p>你也许会问，既然要全库只读，为什么不使用set global readonly=true的方式呢？确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因：</p><ul><li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。</li><li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。</li></ul><h2 id="表级锁">表级锁</h2><p>MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁(meta data lock，MDL)。</p><p><strong>表锁的语法是 lock tables … read/write</strong>。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p><p>举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。</p><p>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。</p><p><strong>另一类表级的锁是MDL(metadata lock)</strong>。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p><p>因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。</p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li></ul><p>你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表t是一个小表。</p><blockquote><p>备注：这里的实验环境是MySQL 5.6。</p></blockquote><p><img data-src="/images/45-lectures-on-mysql-in-practice/MDL_LOCK_EXAMPLES.png" alt></p><p>我们可以看到session A先启动，这时候会对表t加一个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执行。之后session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被阻塞。</p><p>如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。</p><p>如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。</p><p>你现在应该知道了，事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。</p><h1>行锁</h1><p><strong>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放</strong>。这个就是两阶段锁协议。</p><p>知道了这个设定，对我们使用事务有什么帮助呢？那就是，<font color="DeepPink"><strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong></font>我给你举个例子。</p><p>假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p><ol><li>从顾客A账户余额中扣除电影票价；</li><li>给影院B的账户余额增加这张电影票价；</li><li>记录一条交易日志。</li></ol><p>也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p><p>试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p><p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。</p><h1>事务到底是隔离的还是不隔离的？</h1><p>begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句(第一个快照读语句)，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令。</p><p>在MySQL里，有两个&quot;视图&quot;的概念：</p><ul><li>一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view… ，而它的查询方法与表一样。</li><li>另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC(Read Committed，读提交)和RR(Repeatable Read，可重复读)隔离级别的实现。</li></ul><p>它没有物理结构，作用是事务执行期间用来定义&quot;我能看到什么数据&quot;。</p><h2 id="快照-在MVCC里是怎么工作的？">&quot;快照&quot;在MVCC里是怎么工作的？</h2><p>在可重复读隔离级别下，事务在启动的时候就&quot;拍了个快照&quot;。注意，这个快照是基于整库的。</p><p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p><ol><li>版本未提交，不可见；</li><li>版本已提交，但是是在视图创建后提交的，不可见；</li><li>版本已提交，而且是在视图创建前提交的，可见。</li></ol><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为&quot;当前读&quot;(current read)。</p><blockquote><p><font color="DeepPink"><strong>当前读的规则，就是要能读到所有已经提交的记录的最新值。</strong></font></p></blockquote><p>这里我们提到了一个概念，叫作当前读。<font color="DeepPink"><strong>其实，除了update语句外，select语句如果加锁，也是当前读。</strong></font></p><blockquote><p>事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p></blockquote><p><a href="/attachments/MySQL实战45讲/08讲事务到底是隔离的还是不隔离的.pdf" target="_blank">事务到底是隔离的还是不隔离的？</a></p><h1>普通索引和唯一索引，应该怎么选择?</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; create table T(</span><br><span class="line">id int primary key,</span><br><span class="line">k int not null,</span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure><p>假设字段 k 上的值都不重复。</p><p><img data-src="/images/45-lectures-on-mysql-in-practice/InnoDB%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84.png" alt></p><h2 id="查询过程">查询过程</h2><p>假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下⻆的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p><ul><li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。</li><li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li></ul><p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p><p>你知道的，InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。</p><p>因为引擎是按页读写的，所以说，当找到k=5的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次&quot;查找和判断下一条记录&quot;的操作，就只需要一次指针寻找和一次计算。</p><p>当然，如果k=5这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。</p><p>但是，我们之前计算过，对于整型字段，一个数据页可以放近千个key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。</p><h2 id="更新过程">更新过程</h2><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p><p>需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。</p><p>将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭(shutdown)的过程中，也会执行merge操作。</p><p>显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。</p><p>那么，什么条件下可以使用change buffer呢？</p><p>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。</p><p>因此，<strong>唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。</strong></p><p><a href="/attachments/MySQL实战45讲/09讲普通索引和唯一索引，应该怎么选择.pdf" target="_blank">普通索引和唯一索引，应该怎么选择?</a></p><h1>MySQL为什么有时候会选错索引?</h1><p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p><p>估算出来的数字有可能会不准确，从而导致索引选择不对。</p><p><a href="/attachments/MySQL实战45讲/10讲MySQL为什么有时候会选错索引.pdf" target="_blank">MySQL为什么有时候会选错索引?</a></p><h1>怎么给字符串字段加索引？</h1><ol><li>直接创建完整索引，这样可能比较占用空间；</li><li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li><li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li><li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li></ol><h1>为什么我的MySQL会&quot;抖&quot;一下？</h1><p>MySQL偶尔&quot;抖&quot;一下的那个瞬间，可能就是在刷脏页(flush)。</p><p>那么，什么情况会引发数据库的flush过程呢？</p><p>第一种场景是，InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。</p><p><img data-src="/images/45-lectures-on-mysql-in-practice/redo_log%E7%8A%B6%E6%80%81%E5%9B%BE.png" alt></p><p>第二种场景是，就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是&quot;脏页&quot;，就要先将脏页写到磁盘。</p><p>你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p><ul><li>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</li><li>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。</li></ul><p>第三种场景是，就是MySQL认为系统&quot;空闲&quot;的时候。<br>第四种场景是，就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p><p>刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p><ol><li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li><li>日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</li></ol><p>所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</p><h2 id="InnoDB刷脏页的控制策略">InnoDB刷脏页的控制策略</h2><p>合理地设置innodb_io_capacity的值，并且平时要多关注脏页比例，不要让它经常接近75%。</p><p>更详细的关于innodb_io_capacity、innodb_max_dirty_pages_pct等参数的设置参见：<a href="/attachments/MySQL实战45讲/12讲为什么我的MySQL会“抖”一下.pdf" target="_blank">为什么我的MySQL会&quot;抖&quot;一下?</a></p><h1>为什么表数据删掉一半，表文件大小不变？</h1><p>delete命令其实只是把记录的位置，或者数据页标记为了&quot;可复用&quot;，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是&quot;空洞&quot;。</p><p>实际上，不止是删除数据会造成空洞，插入数据也会。</p><p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。</p><p>表空间收缩的方式：重建表</p><p>重建表的方式及需要注意的问题，参见：<a href="/attachments/MySQL实战45讲/13讲为什么表数据删掉一半，表文件大小不变.pdf" target="_blank">为什么表数据删掉一半，表文件大小不变?</a></p><h1>count()这么慢，我该怎么办？</h1><h2 id="count-的实现方式">count(*)的实现方式</h2><p>在不同的MySQL引擎中，count(*)有不同的实现方式。</p><ul><li>MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；</li><li>而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li></ul><p>这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。</p><p>那为什么<strong>InnoDB不跟MyISAM一样，也把数字存起来呢？</strong><br>这是因为即使是在同一个时刻的多个查询，由于多版本并发控制(MVCC)的原因，InnoDB表&quot;应该返回多少行&quot;也是不确定的。</p><p>由于InnoDB要支持事务，从而导致InnoDB表不能把count(*)直接存起来，然后查询的时候直接返回形成的。</p><p>所谓以子之矛攻子之盾，现在我们就利用&quot;事务&quot;这个特性，把问题解决掉。</p><p><img data-src="/images/45-lectures-on-mysql-in-practice/%E4%BC%9A%E8%AF%9DA%E3%80%81B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt></p><p>我们来看下现在的执行结果。虽然会话B的读操作仍然是在T3执行的，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还不可见。</p><p>因此，会话B看到的结果里， 查计数值和&quot;最近100条记录&quot;看到的结果，逻辑上就是一致的。</p><h2 id="不同的count用法">不同的count用法</h2><p>count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段)，则表示返回满足条件的数据行里面，参数&quot;字段&quot;不为NULL的总个数。</p><p>至于分析性能差别的时候，你可以记住这么几个原则：</p><ol><li>server层要什么就给什么；</li><li>InnoDB只给必要的值；</li><li>现在的优化器只优化了count(*)的语义为&quot;取行数&quot;，其他&quot;显而易见&quot;的优化并没有做。</li></ol><p>对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。</p><p>对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字&quot;1&quot;进去，判断是不可能为空的，按行累加。</p><p>单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。</p><p>对于count(字段)来说：</p><ol><li>如果这个&quot;字段&quot;是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；</li><li>如果这个&quot;字段&quot;定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。</li></ol><p>也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。<br>但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。</p><p>所以结论是：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(*)，所以我建议你，尽量使用count(*)。</p><h1>答疑：日志和索引相关问题</h1><ul><li>MySQL怎么知道binlog是完整的?</li><li>redo log 和 binlog是怎么关联起来的?</li><li>处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?</li><li>如果这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</li><li>不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？</li><li>那能不能反过来，只用redo log，不要binlog？</li><li>redo log一般设置多大？</li><li>正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？</li><li>redo log buffer是什么？是先修改内存，还是先写redo log文件？</li></ul><p>详细解答参见：<a href="/attachments/MySQL实战45讲/15讲答疑文章(一)：日志和索引相关问题.pdf" target="_blank">答疑：日志和索引相关问题?</a></p><h1>&quot;order by&quot;是怎么工作的？</h1><p>sort_buffer_size，就是MySQL为排序开辟的内存(sort_buffer)的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</p><p>optimizer_trace 可支持把MySQL查询执行计划树打印出来。</p><p><a href="/attachments/MySQL实战45讲/16讲“orderby”是怎么工作的.pdf" target="_blank">&quot;order by&quot;是怎么工作的？</a></p><h1>为什么这些SQL语句逻辑相同，性能却差异巨大？</h1><h2 id="隐式类型转换">隐式类型转换</h2><p>数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？</p><p>这里有一个简单的方法，看 select “10” &gt; 9 的结果：</p><ol><li>如果规则是&quot;将字符串转成数字&quot;，那么就是做数字比较，结果应该是1；</li><li>如果规则是&quot;将数字转成字符串&quot;，那么就是做字符串比较，结果应该是0。</li></ol><h2 id="隐式字符编码转换">隐式字符编码转换</h2><p>不同表之间字符集不同，可能会导致索引失效。</p><p>具体例子可以参见下文，第3小结：<br><a href="/attachments/MySQL实战45讲/18讲为什么这些SQL语句逻辑相同，性能却差异巨大.pdf" target="_blank">为什么这些SQL语句逻辑相同，性能却差异巨大？</a></p><h1>为什么我只查一行的语句，也执行这么慢？</h1><h2 id="查询长时间不返回">查询长时间不返回</h2><p>等MDL锁<br>等flush<br>等行锁</p><h2 id="查询慢">查询慢</h2><p>详细排查过程参见：<a href="/attachments/MySQL实战45讲/19讲为什么我只查一行的语句，也执行这么慢.pdf" target="_blank">为什么我只查一行的语句，也执行这么慢？</a></p><h1>幻读是什么，幻读有什么问题？</h1><h2 id="如何解决幻读？">如何解决幻读？</h2><p>产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的&quot;间隙&quot;。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。</p><p>间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。</p><p>间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置为row。这，也是现在不少公司使用的配置组合。</p><h1>为什么我只改一行的语句，锁这么多？</h1><p>加锁规则里面，包含了两个&quot;原则&quot;、两个&quot;优化&quot;和一个&quot;bug&quot;。</p><ol><li>原则1：<font color="DeepPink"><strong>加锁的基本单位是next-key lock</strong></font>。希望你还记得，next-key lock是前开后闭区间。</li><li>原则2：查找过程中访问到的对象才会加锁。</li><li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li><li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li><li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ol><blockquote><p>MySQL后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即5.x系列&lt;=5.7.24，8.0系列&lt;=8.0.13。</p></blockquote><p>间隙锁、行锁、next-key lock案例分析：<a href="/attachments/MySQL实战45讲/21讲为什么我只改一行的语句，锁这么多.pdf" target="_blank">为什么我只改一行的语句，锁这么多？</a></p><h1>MySQL有哪些&quot;饮鸩止渴&quot;提高性能的方法</h1><ul><li>短连接风暴<ul><li>先处理掉那些占着连接但是不工作的线程</li><li>减少连接过程的消耗</li></ul></li><li>慢查询性能问题<ul><li>索引没有设计好</li><li>语句没写好</li></ul></li><li>QPS突增问题</li></ul><p>更加详细的处理方法参见：<a href="/attachments/MySQL实战45讲/22讲MySQL有哪些“饮鸩止渴”提高性能的方法.pdf" target="_blank">MySQL有哪些&quot;饮鸩止渴&quot;提高性能的方法</a></p><h1>MySQL是怎么保证数据不丢的？</h1><p>WAL机制主要得益于两个方面：</p><ol><li>redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快；</li><li>组提交机制，可以大幅度降低磁盘的IOPS消耗。</li></ol><p>事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导致主备不一致呢？<br>回答：不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog都没有了，从业务⻆度看这个事务也没有提交，所以数据是一致的。</p><p><a href="/attachments/MySQL实战45讲/23讲MySQL是怎么保证数据不丢的.pdf" target="_blank">MySQL是怎么保证数据不丢的？</a></p><h1>MySQL是怎么保证主备一致的？</h1><p><a href="/attachments/MySQL实战45讲/24讲MySQL是怎么保证主备一致的.pdf" target="_blank">MySQL是怎么保证主备一致的？</a></p><h1>MySQL是怎么保证高可用的？</h1><p><a href="/attachments/MySQL实战45讲/25讲MySQL是怎么保证高可用的.pdf" target="_blank">MySQL是怎么保证高可用的？</a></p><h1>备库为什么会延迟好几个小时？</h1><ul><li>MySQL 5.5版本的并行复制策略<ul><li>按表分发策略</li><li>按行分发策略</li></ul></li><li>MySQL 5.6版本的并行复制策略</li><li>MariaDB的并行复制策略</li><li>MySQL 5.7的并行复制策略</li><li>MySQL 5.7.22的并行复制策略</li></ul><p><a href="/attachments/MySQL实战45讲/26讲备库为什么会延迟好几个小时.pdf" target="_blank">备库为什么会延迟好几个小时？</a></p><h1>主库出问题了从库怎么办？</h1><ul><li>基于位点的主备切换</li><li>GTID</li><li>基于 GTID 的主备切换</li><li>GTID 和在线 DDL</li></ul><p><a href="/attachments/MySQL实战45讲/27讲主库出问题了从库怎么办.pdf" target="_blank">主库出问题了从库怎么办？</a></p><h1>读写分离有哪些坑？</h1><ul><li>强制走主库方案</li><li>sleep 方案</li><li>判断主备无延迟方案</li><li>配合 semi-sync 方案</li><li>等主库位点方案</li><li>等 GTID 方案</li></ul><p><a href="/attachments/MySQL实战45讲/28讲读写分离有哪些坑.pdf" target="_blank">读写分离有哪些坑？</a></p><h1>如何判断一个数据库是不是出问题了？</h1><ul><li>select 1 判断</li><li>查表判断</li><li>更新判断</li><li>内部统计</li></ul><p><a href="/attachments/MySQL实战45讲/29讲如何判断一个数据库是不是出问题了.pdf" target="_blank">如何判断一个数据库是不是出问题了？</a></p><h1>误删数据后除了跑路还能怎么办？</h1><ul><li>误删行</li><li>误删库/表</li><li>延迟复制备库</li><li>预防误删库/表的方法</li><li>rm 删除数据</li></ul><p><a href="/attachments/MySQL实战45讲/31讲误删数据后除了跑路还能怎么办.pdf" target="_blank">误删数据后除了跑路还能怎么办？</a></p><h1>为什么还有kill不掉的语句？</h1><p><a href="/attachments/MySQL实战45讲/32讲为什么还有kill不掉的语句.pdf" target="_blank">为什么还有kill不掉的语句？</a></p><h1>关于Join</h1><p><a href="/attachments/MySQL实战45讲/34讲到底可不可以使用join.pdf" target="_blank">到底可不可以使用join？</a></p><p><a href="/attachments/MySQL实战45讲/35讲join语句怎么优化.pdf" target="_blank">join语句怎么优化？</a></p><h1>自增主键为什么不是连续的？</h1><p>在 MyISAM 引擎里面，自增值是被写在数据文件上的。而在 InnoDB 中，自增值是被记录在内存的。 MySQL 直到 8.0 版本，才给 InnoDB 表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。</p><p><a href="/attachments/MySQL实战45讲/39讲自增主键为什么不是连续的.pdf" target="_blank">自增主键为什么不是连续的？</a></p><h1>insert语句的锁为什么这么多？</h1><p>insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。<br>而如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。<br>insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁 ) 。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</p><h1>怎么最快地复制一张表？</h1><p>介绍了三种将一个表的数据导入到另外一个表中的方法。</p><p>我们来对比一下这三种方法的优缺点。</p><ol><li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：<ul><li>必须是全表拷贝，不能只拷贝部分数据；</li><li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；</li><li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li></ul></li><li>用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。</li><li>用 select … into outfile 的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</li></ol><p>后两种方式都是逻辑备份方式，是可以跨引擎使用的。</p><p>具体操作可以参见：<a href="/attachments/MySQL实战45讲/41怎么最快地复制一张表.pdf" target="_blank">怎么最快地复制一张表？</a></p><h1>grant之后要跟着flush privileges吗？</h1><p>grant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用grant 和 revoke 语句，是不需要随后加上 flush privileges 语句的。</p><p>flush privileges 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用 DML 语句操作系统权限表导致的，所以我们尽量不要使用这类语句。</p><p>具体授权操作可以参见：<a href="/attachments/MySQL实战45讲/42grant之后要跟着flush privileges吗.pdf" target="_blank">grant之后要跟着flush privileges吗？</a></p><h1>要不要使用分区表？</h1><h2 id="分区表是什么？">分区表是什么？</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">`ftime` datetime NOT NULL,</span><br><span class="line">`c` int(11) DEFAULT NULL,</span><br><span class="line">KEY (`ftime`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=latin1</span><br><span class="line">PARTITION BY RANGE (YEAR(ftime))</span><br><span class="line">(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,</span><br><span class="line">PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);</span><br><span class="line">insert into t values(&apos;2017-4-1&apos;,1),(&apos;2018-4-1&apos;,1);</span><br></pre></td></tr></table></figure><p><img data-src="/images/45-lectures-on-mysql-in-practice/%E5%88%86%E5%8C%BA%E8%A1%A8.png" alt></p><p>我在表 t 中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在 p_2018 和 p_2019这两个分区上。</p><p>可以看到，这个表包含了一个 .frm 文件和 4 个 .ibd 文件，每个分区对应一个 .ibd 文件。也就是说：</p><ul><li><font color="DeepPink"><strong>对于引擎层来说，这是 4 个表</strong></font>；</li><li><font color="DeepPink"><strong>对于 Server 层来说，这是 1 个表</strong></font>。</li></ul><h2 id="分区表的-server-层行为">分区表的 server 层行为</h2><p>如果从 server 层看的话，一个分区表就只是一个表。</p><ol><li>MySQL 在第一次打开分区表的时候，需要访问所有的分区；</li><li><font color="DeepPink"><strong>在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁</strong></font>；</li><li><font color="DeepPink"><strong>在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区</strong></font>。</li></ol><h2 id="分区表的应用场景">分区表的应用场景</h2><p>分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据。</p><p>如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过 alter table t drop partition … 这个语法删掉分区，从而删掉过期的历史数据。</p><p>这个 alter table t drop partition … 操作是直接删除分区文件，效果跟 drop 普通表类似。与使用delete 语句删除数据相比，优势是速度快、对系统影响小。</p><h2 id="小结">小结</h2><p>实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用 MDL 锁。</p><p>因此，如果要使用分区表，就不要创建太多的分区。我见过一个用户做了按天分区策略，然后预先创建了10年的分区。这种情况下，访问分区表的性能自然是不好的。这里有两个问题需要注意：</p><ol><li><font color="DeepPink"><strong>分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。</strong></font></li><li>分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可。对于没有数据的历史分区，要及时的 drop 掉。</li></ol><p>至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。</p><p>当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对 DBA 也更直观，自然是更好的。</p><h1>答疑文章：说一说这些好问题</h1><h2 id="join-的写法">join 的写法</h2><ol><li>如果用 left join 的话，左边的表一定是驱动表吗？</li><li>如果两个表的 join 包含多个条件的等值匹配，是都要写到 on 里面呢，还是只把一个条件写到on 里面，其他条件写到 where 部分？</li></ol><p>使用 left join 时，左边的表不一定是驱动表。<br>如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。</p><h2 id="Simple-Nested-Loop-Join-的性能问题">Simple Nested Loop Join 的性能问题</h2><p>虽然 BNL(Block Nested-Loop Join)算法和 Simple Nested Loop Join 算法都是要判断 M*N 次( M 和 N 分别是 join 的两个表的行数)，但是 Simple Nested Loop Join 算法的每轮判断都要走全表扫描，因此性能上 BNL 算法执行起来会快很多。<br>为了便于说明，我还是先为你简单描述一下这两个算法。<br>BNL 算法的执行逻辑是：</p><ol><li>首先，<font color="DeepPink"><strong>将驱动表的数据全部读入内存 join_buffer 中，这里 join_buffer 是无序数组</strong></font>；</li><li>然后，顺序遍历被驱动表的所有行，每一行数据都跟 join_buffer 中的数据进行匹配，匹配成功则作为结果集的一部分返回。</li></ol><p>Simple Nested Loop Join 算法的执行逻辑是：顺序取出驱动表中的每一行数据，到被驱动表去做全表扫描匹配，匹配成功则作为结果集的一部分返回。</p><p>这两位同学的疑问是， Simple Nested Loop Join 算法，其实也是把数据读到内存里，然后按照匹配条件进行判断，为什么性能差距会这么大呢？</p><p>解释这个问题，需要用到 MySQL 中索引结构和 Buffer Pool 的相关知识点：</p><ol><li>在对被驱动表做全表扫描的时候，如果数据没有在 Buffer Pool 中，就需要等待这部分数据从磁盘读入；<br>从磁盘读入数据到内存中，会影响正常业务的 Buffer Pool 命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到 Buffer Pool 的头部；</li><li>即使被驱动表数据都在内存中，每次查找 &quot; 下一个记录的操作 &quot; ，都是类似指针操作。而join_buffer中是数组，遍历的成本更低。</li></ol><p>所以说， BNL 算法的性能会更好。</p><h2 id="distinct-和-group-by-的性能">distinct 和 group by 的性能</h2><p>具体举例描述可以参见：<a href="/attachments/MySQL实战45讲/44答疑文章(三)：说一说这些好问题.pdf" target="_blank">答疑文章：说一说这些好问题</a></p><h1>自增id用完怎么办？</h1><p>每种自增 id 有各自的应用场景，在达到上限后的表现也不同：</p><ol><li>表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。</li><li>row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id ，后写的数据会覆盖之前的数据。</li><li>Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。</li><li>InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来。</li><li>thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。</li></ol><p>具体举例描述可以参见：<a href="/attachments/MySQL实战45讲/45自增id用完怎么办.pdf" target="_blank">自增id用完怎么办？</a></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP 状态图</title>
    <url>/tcp-state-diagram.html</url>
    <content><![CDATA[<p>TCP的三次握手、TCP四次挥手、TCP状态机</p><a id="more"></a><h1>TCP的三次握手</h1><p><img data-src="/images/tcp-state-diagram/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><h1>TCP四次挥手</h1><p><img data-src="/images/tcp-state-diagram/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" alt></p><p><img data-src="/images/tcp-state-diagram/tcp-close.png" alt></p><h2 id="CLOSE-WAIT-堆积的危害">CLOSE_WAIT 堆积的危害</h2><p>每个 CLOSE_WAIT 连接会占据一个文件描述，堆积大量的 CLOSE_WAIT 可能造成文件描述符不够用，导致建连或打开文件失败，报错 <code>too many open files</code>:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dial udp 9.215.0.48:9073: socket: too many open files</span><br></pre></td></tr></table></figure><p>如何判断?<br>检查系统 <code>CLOSE_WAIT</code> 连接数:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof | grep CLOSE_WAIT | wc -l</span><br></pre></td></tr></table></figure><p>检查指定进程 CLOSE_WAIT 连接数:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof -p $PID | grep CLOSE_WAIT | wc -l</span><br></pre></td></tr></table></figure><p>主动关闭的一方发出 FIN 包，被动关闭的一方响应 ACK 包，此时，被动关闭的一方就进入了 <code>CLOSE_WAIT</code> 状态。如果一切正常，稍后被动关闭的一方也会发出 FIN 包，然后迁移到 <code>LAST_ACK</code> 状态。</p><p>通常，<code>CLOSE_WAIT</code> 状态在服务器停留时间很短，如果你发现大量的 <code>CLOSE_WAIT</code> 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般来说都是被动关闭的一方应用程序有问题。</p><h3 id="应用没有-Close">应用没有 Close</h3><p>如果 <code>CLOSE_WAIT</code> 堆积的量特别大(比如 10w+)，甚至导致文件描述符不够用了，一般就是应用没有 Close 连接导致。</p><p>当连接被关闭时，被动关闭方在代码层面没有 close 掉相应的 socket 连接，那么自然不会发出 FIN 包，从而会导致 <code>CLOSE_WAIT</code> 堆积。可能是代码里根本没写 Close，也可能是代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。</p><h3 id="应用迟迟不-accept-连接">应用迟迟不 accept 连接</h3><p>如果 <code>CLOSE_WAIT</code> 堆积的量不是很大，可能是全连接队列 (accept queue) 堆积了。我们先看下 TCP 连接建立的过程:</p><p><img data-src="/images/tcp-state-diagram/tcp-queue.png" alt></p><p>连接建立好之后会被放入 accept queue，等待应用 accept，如果应用迟迟没有从队列里面去 accept 连接，等到 client 超时时间，主动关闭了连接，这时连接在 server 端仍在全连接队列中，状态变为 <code>CLOSE_WAIT</code>。</p><p>如果连接一直不被应用 accept 出来，内核也不会自动响应 ACK 去关闭连接的。不过这种情况的堆积量一般也不高，取决于 accept queue 的大小。</p><h2 id="TIME-WAIT">TIME_WAIT</h2><p>补充我一个之前遇到的场景，有次上线服务，发现连接ES的连接有很多TIME_WAIT<br><img data-src="/images/tcp-state-diagram/cmdb_tcp_time_wait.jpg" alt></p><p>TIME_WAIT很明显就是本地主动关闭连接，但在等2MSL。</p><p>按理说连接ES都是长连接（Keep-Alive），按理说不会有这么多需要关闭的连接。</p><p>看了下代码及issue，找到了原因<br><a href="https://github.com/elastic/go-elasticsearch/issues/123" target="_blank" rel="noopener">https://github.com/elastic/go-elasticsearch/issues/123</a></p><p>发现其实是Golang的一个问题<br><a href="https://pkg.go.dev/net/http#Response" target="_blank" rel="noopener">https://pkg.go.dev/net/http#Response</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// The http Client and Transport guarantee that Body is always</span><br><span class="line">// non-nil, even on responses without a body or responses with</span><br><span class="line">// a zero-length body. It is the caller&apos;s responsibility to</span><br><span class="line">// close Body. The default HTTP client&apos;s Transport may not</span><br><span class="line">// reuse HTTP/1.x &quot;keep-alive&quot; TCP connections if the Body is</span><br><span class="line">// not read to completion and closed.</span><br></pre></td></tr></table></figure><p>在代码中加上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">_ = res.String()</span><br></pre></td></tr></table></figure><p>问题解决</p><p>关于TIME_WAIT一些其它资料推荐:</p><ul><li><a href="/attachments/网络编程实战/TIME_WAIT：隐藏在细节下的魔鬼.pdf" target="_blank">10-TIME_WAIT：隐藏在细节下的魔鬼</a></li><li><a href="https://jiankunking.blog.csdn.net/article/details/132508754?spm=1001.2014.3001.5502" target="_blank" rel="noopener">左耳朵耗子:从一次经历谈 TIME_WAIT 的那些事</a></li></ul><h1>TCP状态机</h1><p>将连接建立和连接断开的两个时序状态图综合起来,就是这个著名的TCP的状态机。学习的时候比较建议将这个状态机和时序状态机对照着看,不然容易晕。</p><p><img data-src="/images/tcp-state-diagram/Tcp_state_diagram.png" alt></p><p>在这个图中,加黑加粗的部分,是上面说到的主要流程,其中阿拉伯数字的序号,是连接过程中的顺序,而大写中文数字的序号,是连接断开过程中的顺序。加粗的实线是客户端A的状态变迁,加粗的虚线是服务端B的状态变迁。</p><h1>TCP Flags</h1><h2 id="TCP中Flags字段">TCP中Flags字段</h2><ul><li>SYN 表示建立连接，在TCP监听中为: Flags [S]；</li><li>FIN 表示关闭连接，在TCP监听中为: Flags [F]；</li><li>ACK 表示收到请求，返回响应，在TCP监听中为: Flags [.]；</li><li>PSH 表示数据传输，在TCP监听中为: Flags [P]；</li><li>RST 表示连接重置，在TCP监听中为: Flags [R]。</li></ul><h2 id="Flags字段组合使用">Flags字段组合使用</h2><ul><li>收到并建立连接为: Flags [S.]</li><li>收到并关闭连接为: Flags [F.]</li><li>收到并传输数据为: Flags [P.]</li><li>收到并连接重置为: Flags [R.]</li></ul><h2 id="简称解释">简称解释</h2><ul><li><code>SYN</code> - The <code>synchronization</code> flag is used to establish a three-way handshake between two hosts. Only the first packet from both the sender and receiver should have this flag set.</li><li><code>ACK</code> - The <code>acknowledgment</code> flag is used to acknowledge the successful receipt of a packet. As we can see from the diagram above, the receiver sends an ACK as well as a SYN in the second step of the three-way handshake process to tell the sender that it received its initial packet.</li><li><code>FIN</code> - The <code>finished</code> flag means there is no more data from the sender. Therefore, it is used in the last packet sent from the sender. It frees the reserved resources and gracefully terminates the connection.</li><li><code>URG</code> - The <code>urgent</code> flag is used to notify the receiver to process the urgent packets before processing all other packets. The receiver will be notified when all known urgent data has been received. See RFC 6093 for more details.</li><li><code>PSH</code> - The <code>push</code> flag is similar to the URG flag and tells the receiver to process these packets as they are received instead of buffering them. Usually, by default, the transport layer waits some time for the application layer to send enough data according to the maximum segment size so that the number of packets transmitted over the network is minimized. However, this is not desirable for certain applications, such as interactive applications (chatting). By using Push, this problem is solved.</li><li><code>RST</code> - The <code>reset</code> flag gets sent from the receiver to the sender when a packet is sent to a particular host that was not expecting it.</li><li><code>ECE</code> - This flag is responsible for indicating if the TCP peer is ECN capable. See <a href="https://datatracker.ietf.org/doc/html/rfc3168" target="_blank" rel="noopener">RFC 3168</a> for more details.</li><li><code>CWR</code> - The <code>congestion window reduced</code> flag is used by the sending host to indicate it received a packet with the ECE flag set. See <a href="https://datatracker.ietf.org/doc/html/rfc3168" target="_blank" rel="noopener">RFC 3168</a> for more details.</li><li><code>NS (experimental)</code> - The <code>nonce sum</code> flag is still an experimental flag used to help protect against accidental, malicious concealment of packets from the sender. See <a href="https://datatracker.ietf.org/doc/html/rfc3540" target="_blank" rel="noopener">RFC 3540</a> for more details.</li></ul><h1>推荐阅读</h1><p><a href="/attachments/系统性能调优必知必会/09如何提升TCP三次握手的性能？.pdf" target="_blank">如何提升TCP三次握手的性能？</a></p><p><a href="/attachments/系统性能调优必知必会/10如何提升TCP四次挥手的性能？.pdf" target="_blank">如何提升TCP四次挥手的性能？</a></p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>TCP</tag>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux性能优化实战 笔记</title>
    <url>/linux-performance-optimization-practices.html</url>
    <content><![CDATA[<p>Linux性能优化实战 笔记<br>作者： 倪朋飞</p><a id="more"></a><h1>平均负载</h1><h2 id="概念">概念</h2><p>简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和CPU使用率并没有直接关系。这里我先解释下，可运行状态和不可中断状态这俩词儿。</p><p>所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态（Running或Runnable）的进程。</p><p>不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的I/O响应，也就是我们在ps命令中看到的D状态（Uninterruptible Sleep，也称为 Disk leep）的进程。<br>比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。</p><p>所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。</p><p>获取CPU核数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep &apos;model name&apos; /proc/cpuinfo | wc -l</span><br></pre></td></tr></table></figure><h2 id="小结">小结</h2><p>平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：</p><ul><li>平均负载高有可能是CPU密集型进程导致的；</li><li>平均负载高并不一定代表CPU使用率高，还有可能是I/O更繁忙了；</li><li>当发现负载高的时候，你可以使用mpstat、pidstat等工具，辅助分析负载的来源。</li></ul><h1>CPU上下文切换</h1><p>线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。</p><p>根据 <a href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="noopener">Tsuna</a> 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。</p><h2 id="实践">实践</h2><p><a href="/attachments/Linux性能优化实战/04经常说的CPU上下文切换是什么意思？.pdf" target="_blank">经常说的CPU上下文切换是什么意思？</a></p><h1>CPU 使用率</h1><p>GDB 并不适合在性能分析的早期应用。</p><p>为什么呢？因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。</p><p>那么哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p><p>使用 perf 分析 CPU 性能问题，我来说两种最常见、也是我最喜欢的用法。<br>第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数，使用界面如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ perf top</span><br><span class="line">Samples: 833 of event &apos;cpu-clock&apos;, Event count (approx.): 97742399</span><br><span class="line">Overhead Shared Object Symbol</span><br><span class="line">7.28% perf [.] 0x00000000001f78a4</span><br><span class="line">4.72% [kernel] [k] vsnprintf</span><br><span class="line">4.32% [kernel] [k] module_get_kallsym</span><br><span class="line">3.65% [kernel] [k] _raw_spin_unlock_irqrestore</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 833 个 CPU 时钟事件，而总事件数则为 97742399。</p><p>另外，采样数需要我们特别注意。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。<br>再往下看是一个表格式样的数据，每一行包含四列，分别是：</p><p>第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。<br>第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。<br>第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。<br>最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。</p><p>还是以上面的输出为例，我们可以看到，占用 CPU 时钟最多的是 perf 工具自身，不过它的比例也只有 7.28%，说明系统并没有 CPU 性能问题。 perf top 的使用你应该很清楚了吧。</p><p>接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ perf record # 按 Ctrl+C 终止采样</span><br><span class="line">[ perf record: Woken up 1 times to write data ]</span><br><span class="line">[ perf record: Captured and wrote 0.452 MB perf.data (6093 samples) ]</span><br><span class="line">$ perf report # 展示类似于 perf top 的报告</span><br></pre></td></tr></table></figure><p>在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。</p><h2 id="小结-v2">小结</h2><ul><li>用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。</li><li>系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。</li><li>I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。</li><li>软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。</li></ul><p><font color="DeepPink"><strong>碰到 CPU 使用率升高的问题，你可以借助 top、pidstat 等工具，确认引发 CPU 性能问题的来源；再使用 perf 等工具，排查出引起性能问题的具体函数。</strong></font></p><p><font color="DeepPink"><strong>短时应用的运行时间比较短，很难在 top 或者 ps 这类展示系统概要和进程快照的工具中发现，你需要使用记录事件的工具来配合诊断，比如 execsnoop 或者 perf top。</strong></font></p><h2 id="实践-v2">实践</h2><p><a href="/attachments/Linux性能优化实战/06系统的CPU使用率很高但为啥却找不到高CPU？.pdf" target="_blank">系统的CPU使用率很高但为啥却找不到高CPU？</a></p><h1>系统中出现大量不可中断进程和僵尸进程怎么办？</h1><h2 id="Top-输出分析">Top 输出分析</h2><p>下面是一个 top 命令输出的示例，S 列（也就是 Status 列）表示进程的状态。从这个示例里，你可以看到<br>R、D、Z、S、I 等几个状态，它们分别是什么意思呢？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ top</span><br><span class="line">PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND</span><br><span class="line">28961 root 20 0 43816 3148 4040 R 3.2 0.0 0:00.01 top</span><br><span class="line">620 root 20 0 37280 33676 908 D 0.3 0.4 0:00.01 app</span><br><span class="line">1 root 20 0 160072 9416 6752 S 0.0 0.1 0:37.64 systemd</span><br><span class="line">1896 root 20 0 0 0 0 Z 0.0 0.0 0:00.00 devapp</span><br><span class="line">2 root 20 0 0 0 0 S 0.0 0.0 0:00.10 kthreadd</span><br><span class="line">4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0:0H</span><br><span class="line">6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 mm_percpu_wq</span><br><span class="line">7 root 20 0 0 0 0 S 0.0 0.0 0:06.37 ksoftirqd/0</span><br></pre></td></tr></table></figure><p>我们挨个来看一下：</p><ul><li>R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。</li><li>D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。</li><li>Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。</li><li>S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。</li><li>I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。</li></ul><p>当然了，上面的示例并没有包括进程的所有状态。除了以上 5 个状态，进程还包括下面这2个状态。</p><p>第一个是 T 或者 t，也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。</p><p>向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。</p><p>而当你用调试器（如 gdb）调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实也是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。</p><p>另一个是 X，也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。</p><blockquote><p>僵尸进程，这是多进程应用很容易碰到的问题。正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册SIGCHLD 信号的处理函数，异步回收资源。<br>如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。换句话说，父亲应该一直对儿子负责，善始善终，如果不作为或者跟不上，都会导致“问题少年”的出现。<br>通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。<br>一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。</p></blockquote><blockquote><p>不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 I/O 性能问题。</p></blockquote><h2 id="实践-v3">实践</h2><p>dstat命令 是一个用来替换vmstat、iostat、netstat、nfsstat和ifstat这些命令的工具，是一个全能系统信息统计工具。与sysstat相比，dstat拥有一个彩色的界面，在手动观察性能状况时，数据比较显眼容易观察；而且dstat支持即时刷新，譬如输入dstat 3即每三秒收集一次，但最新的数据都会每秒刷新显示。和sysstat相同的是，dstat也可以收集指定的性能资源，譬如dstat -c即显示CPU的使用情况。</p><p><a href="/attachments/Linux性能优化实战/08系统中出现大量不可中断进程和僵尸进程怎么办？.pdf" target="_blank">系统中出现大量不可中断进程和僵尸进程怎么办？</a></p><h1>怎么理解Linux软中断？</h1><p><a href="/attachments/Linux性能优化实战/09怎么理解Linux软中断？.pdf" target="_blank">怎么理解Linux软中断？</a></p><h1>如何迅速分析出系统CPU的瓶颈在哪里？</h1><p><a href="/attachments/Linux性能优化实战/11如何迅速分析出系统CPU的瓶颈在哪里？.pdf" target="_blank">如何迅速分析出系统CPU的瓶颈在哪里？</a></p><blockquote><p>pidstat 中， %wait 表示进程等待 CPU 的时间百分比。<br>top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。</p></blockquote><h1>Linux性能优化答疑</h1><p>关注一下：【问题 2：如何用 perf 工具分析 Java 程序】</p><blockquote><p>像是 Java 这种通过 JVM 来运行的应用程序，运行堆栈用的都是 JVM 内置的函数和堆栈管理。所以，从系统层面你只能看到JVM的函数堆栈，而不能直接得到 Java 应用程序的堆栈。<br>perf_events 实际上已经支持了 JIT，但还需要一个 /tmp/perf-PID.map 文件，来进行符号翻译。当然，开源项目 perf-map-agent 可以帮你生成这个符号表。</p></blockquote><p><a href="/attachments/Linux性能优化实战/14Linux性能优化答疑（二）.pdf" target="_blank">Linux性能优化答疑</a></p><h1>怎么理解内存中的Buffer和Cache？</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 注意不同版本的 free 输出可能会有所不同</span><br><span class="line">$ free</span><br><span class="line">total used free shared buff/cache available</span><br><span class="line">Mem: 8169348 263524 6875352 668 1030472 7611064</span><br><span class="line">Swap: 0 0 0</span><br></pre></td></tr></table></figure><p>这里的大部分指标都比较容易理解，但 Buffer 和 Cache 可能不太好区分。从字面上来说，Buffer 是缓冲区，而 Cache 是缓存，两者都是数据在内存中的临时存储。那么，你知道这两种“临时存储”有什么区别吗？</p><h2 id="free-数据的来源">free 数据的来源</h2><p>Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。<br>Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。</p><h2 id="proc-文件系统">proc 文件系统</h2><p>/proc 是 Linux 内核提供的一种特殊文件系统，是用户跟内核交互的接口。比方说，用户可以从 /proc 中查询内核的运行状态和配置选项，查询进程的运行状态、统计数据等，当然，你也可以通过 /proc 来修改内核的配置。</p><p>proc 文件系统同时也是很多性能工具的最终数据来源。比如我们刚才看到的 free ，就是通过读取 /proc/meminfo ，得到内存的使用情况。</p><p>Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。</p><p>Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。</p><blockquote><p>Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。</p></blockquote><h2 id="磁盘与文件">磁盘与文件</h2><p>磁盘是一个存储设备（确切地说是块设备），可以被划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以再创建文件系统，并挂载到系统的某个目录中。这样，系统就可以通过这个挂载目录，来读写文件。</p><p>换句话说，磁盘是存储数据的块设备，也是文件系统的载体。所以，文件系统确实还是要通过磁盘，来保证数据的持久化存储。</p><p>你在很多地方都会看到这句话， Linux 中一切皆文件。换句话说，你可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）。</p><p>在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而在读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸I/O”。</p><p>这两种读写方式使用的缓存自然不同。文件系统管理的缓存，其实就是 Cache 的一部分。而裸磁盘的缓存，用的正是 Buffer。</p><blockquote><p>cache是针对文件系统的缓存,而 buffers是对磁盘数据的缓存,是直接跟硬件那一层相关的,那一般来说, cache会比 buffers 的数量大了很多。</p></blockquote><h2 id="案例">案例</h2><p><a href="/attachments/Linux性能优化实战/17如何利用系统缓存优化程序的运行效率？.pdf" target="_blank">如何利用系统缓存优化程序的运行效率？</a></p><h1>为什么系统的Swap变高了？</h1><h2 id="NUMA-与-Swap">NUMA 与 Swap</h2><p><a href="/attachments/Linux性能优化实战/19为什么系统的Swap变高了？.pdf" target="_blank">19为什么系统的Swap变高了？</a></p><p>在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。</p><p>当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。</p><h1>如何“快准狠”找到系统内存的问题？</h1><p>为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如free、top、vmstat、pidstat 等。</p><p>具体的分析思路主要有这几步。</p><ol><li>先用 free 和 top，查看系统整体的内存使用情况。</li><li>再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。</li><li>最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。</li></ol><h2 id="根据指标查找工具">根据指标查找工具</h2><p><img data-src="/images/linux-performance-optimization-practices/tools_memory.png" alt></p><h2 id="根据工具查找指标">根据工具查找指标</h2><p><img data-src="/images/linux-performance-optimization-practices/memory_tools.png" alt></p><h1>Linux 磁盘I/O是怎么工作的？</h1><h2 id="磁盘性能指标">磁盘性能指标</h2><p>说到磁盘性能的衡量标准，必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。</p><ul><li>使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。</li><li>饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。</li><li>IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。</li><li>吞吐量，是指每秒的 I/O 请求大小。</li><li>响应时间，是指 I/O 请求从发出到收到响应的间隔时间。</li></ul><p>这里要注意的是，使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求。</p><p>这些指标，很可能是你经常挂在嘴边的，一讨论磁盘性能必定提起的对象。不过我还是要强调一点，不要孤立地去比较某一指标，而要结合读写比例、I/O 类型（随机还是连续）以及 I/O 的大小，综合来分析。</p><h2 id="磁盘-I-O-观测">磁盘 I/O 观测</h2><p><img data-src="/images/linux-performance-optimization-practices/iostat.png" alt></p><p>这些指标中，你要注意：</p><ul><li>%util ，就是我们前面提到的磁盘 I/O 使用率；</li><li>r/s+ w/s ，就是 IOPS；</li><li>rkB/s+wkB/s ，就是吞吐量；</li><li>r_await+w_await ，就是响应时间。</li></ul><p>在观测指标时，也别忘了结合请求的大小（ rareq-sz 和 wareq-sz）一起分析。</p><h2 id="进程-I-O-观测">进程 I/O 观测</h2><p>要观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。</p><h2 id="根据指标查找工具-v2">根据指标查找工具</h2><p><img data-src="/images/linux-performance-optimization-practices/file_disk_io_tool.png" alt></p><h2 id="根据工具查找指标-v2">根据工具查找指标</h2><p><img data-src="/images/linux-performance-optimization-practices/tool_file_disk_io.png" alt></p><h1>关于 Linux 网络，你必须知道这些</h1><h2 id="网络模型">网络模型</h2><p>为了解决网络互联中异构设备的兼容性问题，并解耦复杂的网络包处理流程，OSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中：</p><ul><li>应用层，负责为应用程序提供统一的接口。</li><li>表示层，负责把数据转换成兼容接收系统的格式。</li><li>会话层，负责维护计算机之间的通信连接。</li><li>传输层，负责为数据加上传输表头，形成数据包。</li><li>网络层，负责数据的路由和转发。</li><li>数据链路层，负责 MAC 寻址、错误侦测和改错。</li><li>物理层，负责在物理网络中传输数据帧。</li></ul><p>但是 OSI 模型还是太复杂了，也没能提供一个可实现的方法。所以，在 Linux 中，我们实际上使用的是另一个更实用的四层模型，即 TCP/IP 网络模型。</p><p>TCP/IP 模型，把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层，其中：</p><ul><li>应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。</li><li>传输层，负责端到端的通信，比如 TCP、UDP 等。</li><li>网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。</li><li>网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。</li></ul><p><img data-src="/images/linux-performance-optimization-practices/osi_tcp_ip.png" alt></p><h2 id="网络配置">网络配置</h2><p>ifconfig 和 ip 分别属于软件包 net-tools 和 iproute2，iproute2 是 net-tools 的下一代。</p><blockquote><p>我个人更推荐使用 ip 工具，因为它提供了更丰富的功能和更易用的接口。</p></blockquote><p>以网络接口 ens160 为例，你可以运行下面的两个命令，查看它的配置和状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@jiankunking ~]# ip -s addr show dev ens160</span><br><span class="line">2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether 00:50:56:b1:ee:91 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.138.40.223/24 brd 10.138.40.255 scope global noprefixroute ens160</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    RX: bytes  packets  errors  dropped overrun mcast</span><br><span class="line">    105694689249 460305272 0       139334  0       78892</span><br><span class="line">    TX: bytes  packets  errors  dropped carrier collsns</span><br><span class="line">    501968646454 337674507 0       0       0       0</span><br><span class="line">[root@jiankunking ~]# ifconfig ens160</span><br><span class="line">ens160: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 10.138.40.223  netmask 255.255.255.0  broadcast 10.138.40.255</span><br><span class="line">        ether 00:50:56:b1:ee:91  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 460306226  bytes 105694760042 (98.4 GiB)</span><br><span class="line">        RX errors 0  dropped 139334  overruns 0  frame 0</span><br><span class="line">        TX packets 337674596  bytes 501968659316 (467.4 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>你可以看到，ifconfig 和 ip 命令输出的指标基本相同，只是显示格式略微不同。比如，它们都包括了网络接口的状态标志、MTU 大小、IP、子网、MAC 地址以及网络包收发的统计信息。</p><p>这里有几个跟网络性能密切相关的指标，需要你特别关注一下。</p><p>第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。</p><p>第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。</p><p>第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。</p><p>第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：</p><ul><li>errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；</li><li>dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；</li><li>overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；</li><li>carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；</li><li>collisions 表示碰撞数据包数。</li></ul><h2 id="套接字信息">套接字信息</h2><p>可以用 netstat 或者 ss ，来查看套接字、网络栈、网络接口以及路由表的信息。</p><p>我个人更推荐，使用 ss 来查询网络的连接信息，因为它比 netstat 提供了更好的性能（速度更快）。</p><p>比如，你可以执行下面的命令，查询套接字信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># head -n 3 表示只显示前面 3 行</span><br><span class="line"># -l 表示只显示监听套接字</span><br><span class="line"># -n 表示显示数字地址和端口 (而不是名字)</span><br><span class="line"># -p 表示显示进程信息</span><br><span class="line">[root@jiankunking ~]# netstat -nlp | head -n 3</span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span><br><span class="line">tcp        0      0 0.0.0.0:18022           0.0.0.0:*               LISTEN      68726/sshd</span><br><span class="line"></span><br><span class="line"># -l 表示只显示监听套接字</span><br><span class="line"># -t 表示只显示 TCP 套接字</span><br><span class="line"># -n 表示显示数字地址和端口 (而不是名字)</span><br><span class="line"># -p 表示显示进程信息</span><br><span class="line">[root@jiankunking ~]# ss -ltnp | head -n 3</span><br><span class="line">State      Recv-Q Send-Q Local Address:Port               Peer Address:Port</span><br><span class="line">LISTEN     0      128          *:18022                    *:*                   users:((&quot;sshd&quot;,pid=68726,fd=3))</span><br><span class="line">LISTEN     0      128          *:111                      *:*                   users:((&quot;rpcbind&quot;,pid=767,fd=8))</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>netstat 和 ss 的输出也是类似的，都展示了套接字的状态、接收队列、发送队列、本地地址、远端地址、进程 PID 和进程名称等。</p><p>其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。</p><p>当套接字处于连接状态（Established）时，</p><ul><li>Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。</li><li>而 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。</li></ul><p>当套接字处于监听状态（Listening）时，</p><ul><li>Recv-Q 表示 syn backlog 的当前值。</li><li>而 Send-Q 表示最大的 syn backlog 值。</li></ul><p>而 syn backlog 是 TCP 协议栈中的半连接队列长度，相应的也有一个全连接队列（accept queue），它们都是维护 TCP 状态的重要机制。</p><p>顾名思义，所谓半连接，就是还没有完成 TCP 三次握手的连接，连接只进行了一半，而服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送SYN+ACK 包。</p><p>而全连接，则是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要再被 accept() 系统调用取走，这样，服务器就可以开始真正处理客户端的请求了。</p><h2 id="协议栈统计信息">协议栈统计信息</h2><p>类似的，使用 netstat 或 ss ，也可以查看协议栈的信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@jiankunking ~]# netstat -s</span><br><span class="line">Ip:</span><br><span class="line">    402945296 total packets received</span><br><span class="line">    226103155 forwarded</span><br><span class="line">    0 incoming packets discarded</span><br><span class="line">    176782594 incoming packets delivered</span><br><span class="line">    435480099 requests sent out</span><br><span class="line">    83 dropped because of missing route</span><br><span class="line">    10 fragments dropped after timeout</span><br><span class="line">    76066 reassemblies required</span><br><span class="line">    38028 packets reassembled ok</span><br><span class="line">    10 packet reassembles failed</span><br><span class="line">    38028 fragments received ok</span><br><span class="line">    76056 fragments created</span><br><span class="line">Icmp:</span><br><span class="line">    1556987 ICMP messages received</span><br><span class="line">    188 input ICMP message failed.</span><br><span class="line">    ICMP input histogram:</span><br><span class="line">        destination unreachable: 287</span><br><span class="line">        timeout in transit: 51</span><br><span class="line">        echo requests: 1556516</span><br><span class="line">        echo replies: 128</span><br><span class="line">        timestamp request: 1</span><br><span class="line">        address mask request: 3</span><br><span class="line">    1559315 ICMP messages sent</span><br><span class="line">    0 ICMP messages failed</span><br><span class="line">    ICMP output histogram:</span><br><span class="line">        destination unreachable: 1351</span><br><span class="line">        time exceeded: 9</span><br><span class="line">        echo request: 1477</span><br><span class="line">        echo replies: 1556477</span><br><span class="line">        timestamp replies: 1</span><br><span class="line">IcmpMsg:</span><br><span class="line">        InType0: 128</span><br><span class="line">        InType3: 287</span><br><span class="line">        InType8: 1556516</span><br><span class="line">        InType11: 51</span><br><span class="line">        InType13: 1</span><br><span class="line">        InType17: 3</span><br><span class="line">        InType37: 1</span><br><span class="line">        OutType0: 1556477</span><br><span class="line">        OutType3: 1351</span><br><span class="line">        OutType8: 1477</span><br><span class="line">        OutType11: 9</span><br><span class="line">        OutType14: 1</span><br><span class="line">Tcp:</span><br><span class="line">    139812 active connections openings</span><br><span class="line">    211060 passive connection openings</span><br><span class="line">    100597 failed connection attempts</span><br><span class="line">    62428 connection resets received</span><br><span class="line">    4 connections established</span><br><span class="line">    150899781 segments received</span><br><span class="line">    365986218 segments send out</span><br><span class="line">    10055307 segments retransmited</span><br><span class="line">    563 bad segments received.</span><br><span class="line">    11969603 resets sent</span><br><span class="line">Udp:</span><br><span class="line">    222705 packets received</span><br><span class="line">    1284 packets to unknown port received.</span><br><span class="line">    0 packet receive errors</span><br><span class="line">    144320 packets sent</span><br><span class="line">    0 receive buffer errors</span><br><span class="line">    0 send buffer errors</span><br><span class="line">UdpLite:</span><br><span class="line">TcpExt:</span><br><span class="line">    48 invalid SYN cookies received</span><br><span class="line">    66 resets received for embryonic SYN_RECV sockets</span><br><span class="line">    1 packets pruned from receive queue because of socket buffer overrun</span><br><span class="line">    29246 TCP sockets finished time wait in fast timer</span><br><span class="line">    122 packets rejects in established connections because of timestamp</span><br><span class="line">    244108 delayed acks sent</span><br><span class="line">    478 delayed acks further delayed because of locked socket</span><br><span class="line">    Quick ack mode was activated 72512 times</span><br><span class="line">    3 SYNs to LISTEN sockets dropped</span><br><span class="line">    1298878 packets directly queued to recvmsg prequeue.</span><br><span class="line">    25326935 bytes directly in process context from backlog</span><br><span class="line">    893754064 bytes directly received in process context from prequeue</span><br><span class="line">    21894596 packet headers predicted</span><br><span class="line">    464608 packets header predicted and directly queued to user</span><br><span class="line">    80559045 acknowledgments not containing data payload received</span><br><span class="line">    28273640 predicted acknowledgments</span><br><span class="line">    1683221 times recovered from packet loss by selective acknowledgements</span><br><span class="line">    Detected reordering 8 times using FACK</span><br><span class="line">    Detected reordering 29 times using SACK</span><br><span class="line">    Detected reordering 14 times using time stamp</span><br><span class="line">    7 congestion windows fully recovered without slow start</span><br><span class="line">    14 congestion windows partially recovered using Hoe heuristic</span><br><span class="line">    2422 congestion windows recovered without slow start by DSACK</span><br><span class="line">    26128 congestion windows recovered without slow start after partial ack</span><br><span class="line">    TCPLostRetransmit: 464900</span><br><span class="line">    64529 timeouts after SACK recovery</span><br><span class="line">    19702 timeouts in loss state</span><br><span class="line">    7514677 fast retransmits</span><br><span class="line">    64464 forward retransmits</span><br><span class="line">    1952441 retransmits in slow start</span><br><span class="line">    69482 other TCP timeouts</span><br><span class="line">    TCPLossProbes: 2063407</span><br><span class="line">    TCPLossProbeRecovery: 51490</span><br><span class="line">    285857 SACK retransmits failed</span><br><span class="line">    9 times receiver scheduled too late for direct processing</span><br><span class="line">    33 packets collapsed in receive queue due to low socket buffer</span><br><span class="line">    75591 DSACKs sent for old packets</span><br><span class="line">    2417 DSACKs sent for out of order packets</span><br><span class="line">    51166 DSACKs received</span><br><span class="line">    108 DSACKs for out of order packets received</span><br><span class="line">    818 connections reset due to unexpected data</span><br><span class="line">    2539 connections reset due to early user close</span><br><span class="line">    877 connections aborted due to timeout</span><br><span class="line">    TCPDSACKIgnoredOld: 86</span><br><span class="line">    TCPDSACKIgnoredNoUndo: 29967</span><br><span class="line">    TCPSpuriousRTOs: 18826</span><br><span class="line">    TCPSackShifted: 5442611</span><br><span class="line">    TCPSackMerged: 24407294</span><br><span class="line">    TCPSackShiftFallback: 6093474</span><br><span class="line">    IPReversePathFilter: 19377</span><br><span class="line">    TCPRetransFail: 2</span><br><span class="line">    TCPRcvCoalesce: 6972829</span><br><span class="line">    TCPOFOQueue: 1696509</span><br><span class="line">    TCPOFOMerge: 2507</span><br><span class="line">    TCPChallengeACK: 11895</span><br><span class="line">    TCPSYNChallenge: 583</span><br><span class="line">    TCPSpuriousRtxHostQueues: 85</span><br><span class="line">    TCPAutoCorking: 2372093</span><br><span class="line">    TCPFromZeroWindowAdv: 547</span><br><span class="line">    TCPToZeroWindowAdv: 547</span><br><span class="line">    TCPWantZeroWindowAdv: 15006</span><br><span class="line">    TCPSynRetrans: 3442</span><br><span class="line">    TCPOrigDataSent: 332599913</span><br><span class="line">    TCPHystartTrainDetect: 40604</span><br><span class="line">    TCPHystartTrainCwnd: 718075</span><br><span class="line">    TCPHystartDelayDetect: 162</span><br><span class="line">    TCPHystartDelayCwnd: 5279</span><br><span class="line">    TCPACKSkippedSynRecv: 41</span><br><span class="line">    TCPACKSkippedPAWS: 1</span><br><span class="line">    TCPACKSkippedSeq: 18</span><br><span class="line">    TCPACKSkippedChallenge: 7</span><br><span class="line">IpExt:</span><br><span class="line">    InNoRoutes: 3</span><br><span class="line">    InMcastPkts: 78849</span><br><span class="line">    OutMcastPkts: 129</span><br><span class="line">    InBcastPkts: 24101843</span><br><span class="line">    InOctets: 110759051551</span><br><span class="line">    OutOctets: 566785322634</span><br><span class="line">    InMcastOctets: 14057178</span><br><span class="line">    OutMcastOctets: 14779</span><br><span class="line">    InBcastOctets: 2175831088</span><br><span class="line">    InNoECTPkts: 429510271</span><br><span class="line">    InECT0Pkts: 183432</span><br><span class="line">Sctp:</span><br><span class="line">    0 Current Associations</span><br><span class="line">    0 Active Associations</span><br><span class="line">    0 Passive Associations</span><br><span class="line">    0 Number of Aborteds</span><br><span class="line">    0 Number of Graceful Terminations</span><br><span class="line">    0 Number of Out of Blue packets</span><br><span class="line">    0 Number of Packets with invalid Checksum</span><br><span class="line">    0 Number of control chunks sent</span><br><span class="line">    0 Number of ordered chunks sent</span><br><span class="line">    0 Number of Unordered chunks sent</span><br><span class="line">    0 Number of control chunks received</span><br><span class="line">    0 Number of ordered chunks received</span><br><span class="line">    0 Number of Unordered chunks received</span><br><span class="line">    0 Number of messages fragmented</span><br><span class="line">    0 Number of messages reassembled</span><br><span class="line">    0 Number of SCTP packets sent</span><br><span class="line">    0 Number of SCTP packets received</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]# ss -s</span><br><span class="line">Total: 5091 (kernel 5465)</span><br><span class="line">TCP:   51 (estab 4, closed 24, orphaned 0, synrecv 0, timewait 0/0), ports 0</span><br><span class="line"></span><br><span class="line">Transport Total     IP        IPv6</span><br><span class="line">*         5465      -         -</span><br><span class="line">RAW       0         0         0</span><br><span class="line">UDP       12        9         3</span><br><span class="line">TCP       27        10        17</span><br><span class="line">INET      39        19        20</span><br><span class="line">FRAG      0         0         0</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>这些协议栈的统计信息都很直观。ss 只显示已经连接、关闭、孤儿套接字等简要统计，而netstat 则提供的是更详细的网络协议栈信息。</p><h2 id="网络吞吐和-PPS">网络吞吐和 PPS</h2><p>接下来，我们再来看看，如何查看系统当前的网络吞吐量和 PPS。在这里，我推荐使用我们的老朋友 sar，在前面的 CPU、内存和 I/O 模块中，我们已经多次用到它。</p><p>给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 数字 1 表示每隔 1 秒输出一组数据</span><br><span class="line">[root@jiankunking ~]# sar -n DEV 1</span><br><span class="line">Linux 3.10.0-862.el7.x86_64 (hlhtapp36)         01/18/2020      _x86_64_        (4 CPU)</span><br><span class="line"></span><br><span class="line">08:44:18 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">08:44:19 AM br-0e096fe8aab3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth78a4161      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth4d5f845      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth2b3160e      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethf4ce5a2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth2a67a16      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth77ebe8e      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth9eb34b3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethf6f4fec      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth53108ef      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM vethecb9ea8      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM veth842d0d1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM    ens160      8.00      0.00      0.55      0.00      0.00      0.00      0.00</span><br><span class="line">08:44:19 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure><p>这儿输出的指标比较多，我来简单解释下它们的含义。</p><ul><li>rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。</li><li>rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。</li><li>rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。</li><li>%ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。</li></ul><p>其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。如下你可以看到，我的 ens160 网卡就是一个千兆网卡：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@jiankunking ~]# ethtool ens160 | grep Speed</span><br><span class="line">        Speed: 10000Mb/s</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><h2 id="连通性和延时">连通性和延时</h2><p>我们通常使用 ping ，来测试远程主机的连通性和延时，而这基于 ICMP 协议。比如，执行下面的命令，你就可以测试本机到 114.114.114.114 这个 IP 地址的连通性和延时：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -c3 表示发送三次 ICMP 包后停止</span><br><span class="line">[root@jiankunking ~]# ping -c3 114.114.114.114</span><br><span class="line">PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data.</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=1 ttl=66 time=17.1 ms</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=2 ttl=69 time=17.0 ms</span><br><span class="line">64 bytes from 114.114.114.114: icmp_seq=3 ttl=72 time=16.9 ms</span><br><span class="line"></span><br><span class="line">--- 114.114.114.114 ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2002ms</span><br><span class="line">rtt min/avg/max/mdev = 16.919/17.023/17.128/0.173 ms</span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>ping 的输出，可以分为两部分。</p><p>第一部分，是每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。<br>第二部分，则是三次 ICMP 请求的汇总。</p><p>比如上面的示例显示，发送了 3 个网络包，并且接收到 3 个响应，没有丢包发生，这说明测试主机到 114.114.114.114 是连通的；平均往返延时（RTT）是 17ms左右，也就是从发送 ICMP 开始，到接收到 114.114.114.114 回复的确认，总共经历 17ms左右。</p><h1>C10K 和 C1000K</h1><p><a href="/attachments/Linux性能优化实战/35C10K和C1000K回顾.pdf" target="_blank">C10K和C1000K</a></p><h1>DNS 解析</h1><h2 id="域名与-DNS-解析">域名与 DNS 解析</h2><p>DNS 协议在 TCP/IP 栈中属于应用层，不过实际传输还是基于 UDP 或者 TCP 协议（UDP 居多） ，并且域名服务器一般监听在端口 53 上。</p><p>DNS 服务通过资源记录的方式，来管理所有数据，它支持 A、CNAME、MX、NS、PTR 等多种类型的记录。比如：</p><ul><li>A 记录，用来把域名转换成 IP 地址；</li><li>CNAME 记录，用来创建别名；</li><li>而 NS 记录，则表示该域名对应的域名服务器地址。</li></ul><p>如果没有命中缓存，DNS 查询实际上是一个递归过程，那有没有方法可以知道整个递归查询的执行呢？</p><p>其实除了 nslookup，另外一个常用的 DNS 解析工具 dig ，就提供了 trace 功能，可以展示递归查询的整个过程。比如你可以执行下面的命令，得到查询结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@jiankunking ~]# dig +trace +nodnssec jiankunking.com</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; +trace +nodnssec jiankunking.com</span><br><span class="line">;; global options: +cmd</span><br><span class="line">.			151746	IN	NS	e.root-servers.net.</span><br><span class="line">.			151746	IN	NS	f.root-servers.net.</span><br><span class="line">.			151746	IN	NS	g.root-servers.net.</span><br><span class="line">.			151746	IN	NS	h.root-servers.net.</span><br><span class="line">.			151746	IN	NS	i.root-servers.net.</span><br><span class="line">.			151746	IN	NS	j.root-servers.net.</span><br><span class="line">.			151746	IN	NS	k.root-servers.net.</span><br><span class="line">.			151746	IN	NS	l.root-servers.net.</span><br><span class="line">.			151746	IN	NS	m.root-servers.net.</span><br><span class="line">.			151746	IN	NS	a.root-servers.net.</span><br><span class="line">.			151746	IN	NS	b.root-servers.net.</span><br><span class="line">.			151746	IN	NS	c.root-servers.net.</span><br><span class="line">.			151746	IN	NS	d.root-servers.net.</span><br><span class="line">;; Received 239 bytes from 183.60.83.19#53(183.60.83.19) in 0 ms</span><br><span class="line"></span><br><span class="line">com.			172800	IN	NS	a.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	b.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	c.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	d.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	e.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	f.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	g.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	h.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	i.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	j.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	k.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	l.gtld-servers.net.</span><br><span class="line">com.			172800	IN	NS	m.gtld-servers.net.</span><br><span class="line">;; Received 840 bytes from 199.7.91.13#53(d.root-servers.net) in 236 ms</span><br><span class="line"></span><br><span class="line">jiankunking.com.	172800	IN	NS	f1g1ns1.dnspod.net.</span><br><span class="line">jiankunking.com.	172800	IN	NS	f1g1ns2.dnspod.net.</span><br><span class="line">;; Received 98 bytes from 192.52.178.30#53(k.gtld-servers.net) in 200 ms</span><br><span class="line"></span><br><span class="line">jiankunking.com.	600	IN	A	139.199.31.69</span><br><span class="line">jiankunking.com.	86400	IN	NS	f1g1ns1.dnspod.net.</span><br><span class="line">jiankunking.com.	86400	IN	NS	f1g1ns2.dnspod.net.</span><br><span class="line">;; Received 124 bytes from 58.247.212.48#53(f1g1ns2.dnspod.net) in 21 ms</span><br><span class="line"></span><br><span class="line">[root@jiankunking ~]#</span><br></pre></td></tr></table></figure><p>dig trace 的输出，主要包括四部分:<br>第一部分，是从 183.60.83.19 查到的一些根域名服务器（.）的 NS 记录。<br>第二部分，是从 NS 记录结果中选一个（<a href="http://d.root-servers.net" target="_blank" rel="noopener">d.root-servers.net</a>），并查询顶级域名 com.的 NS 记录。<br>第三部分，是从 com. 的 NS 记录中选择一个（<a href="http://k.gtld-servers.net" target="_blank" rel="noopener">k.gtld-servers.net</a>），并查询二级域名 <a href="http://jiankunking.com">jiankunking.com</a>. 的 NS 服务器。<br>最后一部分，就是从 <a href="http://jiankunking.com">jiankunking.com</a>. 的 NS 服务器（<a href="http://f1g1ns2.dnspod.net" target="_blank" rel="noopener">f1g1ns2.dnspod.net</a>）查询最终主机 <a href="http://jiankunking.com">jiankunking.com</a>. 的 A 记录。</p><p>当然，不仅仅是发布到互联网的服务需要域名，很多时候，我们也希望能对局域网内部的主机进行域名解析（即内网域名，大多数情况下为主机名）。Linux 也支持这种行为。<br>所以，你可以把主机名和 IP 地址的映射关系，写入本机的 /etc/hosts 文件中。这样，指定的主机名就可以在<strong>本地直接</strong>找到目标 IP。</p><p>或者，你还可以在内网中，搭建自定义的 DNS 服务器，专门用来解析内网中的域名。而内网 DNS 服务器，一般还会设置一个或多个上游 DNS 服务器，用来解析外网的域名。</p><h1>使用 tcpdump 和 Wireshark 分析网络流量</h1><h2 id="tcpdump">tcpdump</h2><p><img data-src="/images/linux-performance-optimization-practices/tcpdump1.png" alt><br><img data-src="/images/linux-performance-optimization-practices/tcpdump2.png" alt></p><h2 id="实例">实例</h2><p><a href="/attachments/Linux性能优化实战/38怎么使用tcpdump和Wireshark分析网络流量.pdf" target="_blank">怎么使用tcpdump和Wireshark分析网络流量？</a></p><blockquote><p>实际上，<font color="DeepPink"><strong>根据 IP 地址反查域名、根据端口号反查协议名称，是很多网络工具默认的行为，而这往往会导致性能工具的工作缓慢。</strong></font>所以，通常，网络性能工具都会提供一个选项（比如 -n 或者 -nn），来禁止名称解析。</p></blockquote><h1>NAT 原理</h1><p>NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。</p><p>NAT 的主要目的，是实现地址转换。根据实现方式的不同，NAT 可以分为三类：</p><ul><li>静态 NAT，即内网 IP 与公网 IP 是一对一的永久映射关系；</li><li>动态 NAT，即内网 IP 从公网 IP 池中，动态选择一个进行映射；</li><li>网络地址端口转换 NAPT（Network Address and Port Translation），即把内网 IP 映射到公网 IP 的不同端口上，让多个内网 IP 可以共享同一个公网 IP 地址。</li></ul><p>NAPT 是目前最流行的 NAT 类型，我们在 Linux 中配置的 NAT 也是这种类型。而根据转换方式的不同，我们又可以把 NAPT 分为三类。</p><p>第一类是源地址转换 SNAT，即目的地址不变，只替换源 IP 或源端口。SNAT 主要用于，多个内网 IP 共享同一个公网 IP ，来访问外网资源的场景。</p><p>第二类是目的地址转换 DNAT，即源 IP 保持不变，只替换目的 IP 或者目的端口。DNAT主要通过公网 IP 的不同端口号，来访问内网的多种服务，同时会隐藏后端服务器的真实IP 地址。</p><p>第三类是双向地址转换，即同时使用 SNAT 和 DNAT。当接收到网络包时，执行DNAT，把目的 IP 转换为内网 IP；而在发送网络包时，执行 SNAT，把源 IP 替换为外部IP。</p><p>双向地址转换，其实就是外网 IP 与内网 IP 的一对一映射关系，所以常用在虚拟化环境中，为虚拟机分配浮动的公网 IP 地址。</p><h1>网络性能优化的几个思路</h1><h2 id="根据指标查找工具-v3">根据指标查找工具</h2><p><img data-src="/images/linux-performance-optimization-practices/network_tools1.png" alt></p><h2 id="根据工具查找指标-v3">根据工具查找指标</h2><p><img data-src="/images/linux-performance-optimization-practices/network_tools2.png" alt></p><h2 id="实践-v4">实践</h2><p><a href="/attachments/Linux性能优化实战/43网络性能优化的几个思路（上）.pdf" target="_blank">网络性能优化的几个思路（上）</a></p><p><a href="/attachments/Linux性能优化实战/44网络性能优化的几个思路（下）.pdf" target="_blank">网络性能优化的几个思路（下）</a></p><h1>服务器总是时不时丢包，我该怎么办？</h1><p><a href="/attachments/Linux性能优化实战/47服务器总是时不时丢包，我该怎么办？（上）.pdf" target="_blank">服务器总是时不时丢包，我该怎么办？（上）</a></p><p><a href="/attachments/Linux性能优化实战/48服务器总是时不时丢包，我该怎么办？（下）.pdf" target="_blank">服务器总是时不时丢包，我该怎么办？（下）</a></p><h1>内核线程 CPU 利用率太高，我该怎么办？</h1><p><a href="/attachments/Linux性能优化实战/49内核线程CPU利用率太高，我该怎么办？.pdf" target="_blank">内核线程CPU利用率太高，我该怎么办？</a></p><h1>动态追踪怎么用？</h1><p><a href="/attachments/Linux性能优化实战/50动态追踪怎么用？（上）.pdf" target="_blank">动态追踪怎么用？（上）</a></p><p><a href="/attachments/Linux性能优化实战/51动态追踪怎么用？（下）.pdf" target="_blank">动态追踪怎么用？（下）</a></p><h1>服务吞吐量下降很厉害，怎么分析？</h1><p><a href="/attachments/Linux性能优化实战/52服务吞吐量下降很厉害，怎么分析？.pdf" target="_blank">服务吞吐量下降很厉害，怎么分析？</a></p><blockquote><p>注意套接字部分的排查，netstat -s | grep socket<br>套接字丢包? 套接字队列溢出?</p></blockquote><h1>排查问题注意的指标</h1><p><img data-src="/images/linux-performance-optimization-practices/%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87%E5%88%86%E7%B1%BB.png" alt></p><blockquote><p>注意网络部分</p></blockquote><h1>分析性能问题的一般步骤</h1><p><a href="/attachments/Linux性能优化实战/55分析性能问题的一般步骤.pdf" target="_blank">分析性能问题的一般步骤</a></p><p><a href="/attachments/Linux性能优化实战/56优化性能问题的一般方法.pdf" target="_blank">优化性能问题的一般方法</a></p><p><a href="/attachments/Linux性能优化实战/57Linux性能工具速查.pdf" target="_blank">Linux 性能工具速查</a></p><h1>书籍推荐</h1><p><a href="/attachments/Linux性能优化实战/书籍推荐1.pdf" target="_blank">书籍推荐1</a></p><p><a href="/attachments/Linux性能优化实战/书籍推荐2.pdf" target="_blank">书籍推荐2</a></p>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>原创</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法之美：排序部分</title>
    <url>/time-geekbang-sort-algorithm-recommend.html</url>
    <content><![CDATA[<p>在线：</p><p><a href="/attachments/数据结构与算法之美/11讲排序（上）：为什么插入排序比冒泡排序更受欢迎.pdf" target="_blank">为什么插入排序比冒泡排序更受欢迎</a></p><p><a href="/attachments/数据结构与算法之美/12讲排序（下）：如何用快排思想在O(n)内查找第K大元素.pdf" target="_blank">如何用快排思想在O(n)内查找第K大元素</a></p><p><a href="/attachments/数据结构与算法之美/13讲线性排序：如何根据年龄给100万用户数据排序.pdf" target="_blank">如何根据年龄给100万用户数据排序</a></p><p><a href="/attachments/数据结构与算法之美/14讲排序优化：如何实现一个通用的、高性能的排序函数.pdf" target="_blank">如何实现一个通用的、高性能的排序函数</a></p><blockquote><p>以上PDF整理自网络</p></blockquote>]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title>2的幂表</title>
    <url>/2-power-table.html</url>
    <content><![CDATA[<blockquote><p>2的指数字节转与MB、GB换算关系</p></blockquote><a id="more"></a><table><thead><tr><th>2的幂</th><th>准确值（X）</th><th>近似值</th><th>X字节转换成MB、GB等</th></tr></thead><tbody><tr><td>7</td><td>128</td><td></td><td></td></tr><tr><td>8</td><td>256</td><td></td><td></td></tr><tr><td>10</td><td>1 024</td><td>一千</td><td>1K</td></tr><tr><td>16</td><td>65 536</td><td></td><td>64K</td></tr><tr><td>20</td><td>1 048 576</td><td>一百万</td><td>1MB</td></tr><tr><td>30</td><td>1 073 741 824</td><td>十亿</td><td>1GB</td></tr><tr><td>32</td><td>4 294 967 296</td><td></td><td>4GB</td></tr><tr><td>40</td><td>1 099 511 627 776</td><td>一万亿（trillion）</td><td>1TB</td></tr></tbody></table><p>这张表可以拿来做速算。例如，一个将每个32位整数映射成布尔值的向量表可以在一台普通计算机内存中放下。那样的整数有2^<sup>32</sup>个。因为每个整数只占位向量表中的一位，共需要2<sup>32</sup>位（或者2<sup>29</sup> 字节）来存储该映射表，大约是千兆字节的一半，普通机器很容易满足。</p><p><a href="https://jiankunking.com/unit-conversion.html">计算机存储单位换算</a></p>]]></content>
      <categories>
        <category>Interview</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 伪共享</title>
    <url>/java-false-sharing.html</url>
    <content><![CDATA[<blockquote><p>Java False Sharing</p></blockquote><a id="more"></a><h1>伪共享</h1><p>先看一下wiki中对于伪共享的解释：</p><blockquote><p>In computer science, false sharing is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that will never be altered by another party, but those data share a cache block with data that are altered, the caching protocol may force the first participant to reload the whole unit despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource.</p></blockquote><blockquote><p>By far the most common usage of this term is in modern multiprocessor CPU caches, where memory is cached in lines of some small power of two word size (e.g., 64 aligned, contiguous bytes). If two processors operate on independent data in the same memory address region storable in a single line, the cache coherency mechanisms in the system may force the whole line across the bus or interconnect with every data write, forcing memory stalls in addition to wasting system bandwidth. False sharing is an inherent artifact of automatically synchronized cache protocols and can also exist in environments such as distributed file systems or databases, but current prevalence is limited to RAM caches.</p></blockquote><p>在计算机科学中，错误共享是会导致性能下降，它可能出现在使用由缓存机制管理的分布式、一致的缓存的系统中，系统中最小粒度是一个缓存块。当系统参与者试图周期性地访问部分数据，这部分数据只会被自己修改，但是这些数据可能与别的数据存储在同一个缓存块，当别的数据被修改的时候，缓存协议可能会强制第一个参与者重新加载整个单元，尽管缺乏逻辑上的必要性。</p><p>到目前为止，该术语最常见的用法是在现代多处理器CPU高速缓存中，在该高速缓存中，内存以两个字长（例如64个对齐的连续字节）的行高速缓存。如果两个处理器在同一内存地址区域中的独立数据上操作，而该内存地址区域可存储在一行中，则系统中的缓存一致性机制可能会强制每次数据写入都通过总线刷新整个行，除了浪费系统带宽外，还会导致内存暂停。错误共享是自动同步的缓存协议的固有产物，也可以存在于诸如分布式文件系统或数据库之类的环境中，但是当前的流行仅限于RAM缓存。</p><p><font color="DeepPink"><strong>多份数据共同存储于一个缓存行（缓存的最小单位），当其中一份数据发生更改的时候，内存系统强制更新整个缓存行。这么做的目的就是避免内存中同一地址的数据在不同缓存中的副本出现不一致。</strong></font></p><p>更多信息可以参见：<a href="https://jiankunking.com/the-garbage-collection-handbook-the-art-of-automatic-memory-management-note.html">《垃圾回收算法手册：自动内存管理的艺术 笔记》中的 【高速缓存一致性】</a></p><h1>Java中的伪共享</h1><p>Hotspot为了优化内存占用会将字段自由地重新安排，以满足对齐要求，从而使间隙更小。也正是这种优化，导致出现了在同一缓存行上，有可能有多个数据，从而导致伪共享。</p><blockquote><p>伪共享说的是缓存，而缓存的目的就是加快读取速度，也就意味了被缓存的数据不应该频繁更改。<br>换个角度考虑伪共享就是硬件层面高速缓存的失效，导致性能的下降。</p></blockquote><p>以下图为例，当不同处理器上的线程修改驻留在同一高速缓存行上的变量时，会发生错误共享。这将使高速缓存行失效，并强制进行内存更新以保持高速缓存的一致性。</p><p><img data-src="/images/java-false-sharing/5-4-figure-1.gif" alt></p><h1>Java中的解决方案</h1><p>使用@Contended注解，<font color="DeepPink"><strong>使用该注解，我们可以将热的频繁写入的共享字段与其他主要为只读或冷的字段隔离开来。</strong></font>简单的规则是读共享很便宜，写共享很昂贵。我们还可以将经常由同一线程同时写入的字段打包。</p><p>更一般地说，我们试图影响相关字段的位置，以最小化一致性缺失。在一个简单的单线程环境中，在时间上紧密地一起访问的字段应该放在相邻的空间，以促进缓存局部性。也就是说，时间局部性应该制约空间局部性。在时间上一起访问的字段应该在空间上相邻。也就是说，当线程同时访问我们的字段时，我们必须小心避免错误共享和一致性通信的过度失效。因此，我们试图集群或以其他方式隔离在同一线程上大约在同一时间写入相同缓存行的字段。请注意，这里有一个竞争的因素：如果我们过于努力地将单线程容量丢失最小化，那么我们最终可能会在并行环境中运行过多的一致性丢失。在本机C/C++代码中，程序员通常使用通知并发的结构布局。@Contended应该在Java中提供相同的功能，尽管在本地代码中，字段与偏移量的绑定在编译时发生，而在Java的加载时发生。值得指出的是，在一般情况下，对于单线程和多线程环境都没有单一的最佳布局。而理想的布局问题本身就是<a href="https://en.wikipedia.org/wiki/NP-hardness" target="_blank" rel="noopener">NP-hard</a>。</p><p>理想情况下，JVM将使用硬件监控设施来检测共享行为并动态更改布局。这有点困难，因为我们还没有合适的方式来向JVM提供高效和方便的信息。提示：我们需要取消OS和hypervisor的中间层。另一个挑战是，在不安全的设施中使用原始字段偏移，因此我们需要解决这个问题，可能需要额外的间接级别。</p><p>最后，我也希望能够将最终字段打包在一起，因为这些字段是只读的。</p><h1>小结</h1><p><font color="DeepPink"><strong>伪共享本质是就是在缓存中最小的颗粒度仍然大于某个对象的属性的内存占用，导致该缓存最小单元中存储了多个不相关的对象属性，多个不相关属性的（各自）修改会导致缓存状态的频繁变化。由于硬件一般支持高速缓存一致性协议，缓存状态的变化会导致多核CPU频繁更新缓存状态，导致性能下降。</strong></font></p><p>图片来自：<br><a href="https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads</a></p><p>参考资料：<br><a href="https://en.wikipedia.org/wiki/False_sharing" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/False_sharing</a><br><a href="http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html</a><br><a href="https://blogs.oracle.com/dave/java-contended-annotation-to-help-reduce-false-sharing" target="_blank" rel="noopener">https://blogs.oracle.com/dave/java-contended-annotation-to-help-reduce-false-sharing</a></p><p>拓展阅读：<br><a href="https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads</a><br><a href="https://software.intel.com/en-us/articles/intel-guide-for-developing-multithreaded-applications" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/intel-guide-for-developing-multithreaded-applications</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>Sharing</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes权威指南：从Docker到Kubernetes实践全接触 笔记</title>
    <url>/kubernetes-authoritative-guide.html</url>
    <content><![CDATA[<p>Kubernetes权威指南：从Docker到Kubernetes实践全接触（第2版)<br>作者： 龚正 吴治辉 王伟 崔秀龙 闫健勇 崔晓宁 刘晓红</p><a id="more"></a><h1>Kubernetes 入门</h1><h2 id="Kubernetes-是什么">Kubernetes 是什么</h2><p>在Kubernetes中, Service(服务)是分布式集群架构的核心,一个Service对象拥有如下关键特征。</p><ul><li>拥有一个唯一指定的名字(比如mysql-server)</li><li>拥有一个虚拟IP(Cluster、 Service IP或VIP)和端口号。</li><li>能够提供某种远程服务能力。</li><li>被映射到了提供这种服务能力的一组容器应用上</li></ul><p>Service的服务进程目前都基于Socket通信方式对外提供服务,比如Redis、Memcache、MySQL、Web Server,或者是实现了某个具体业务的一个特定的TCP Server进程。虽然一个Service通常由多个相关的服务进程来提供服务,每个服务进程都有一个独立的 Endpoint(IP+Port)访问点,但Kubernetes能够让我们通过Service(虚拟Cluster IP+Service Port)连接到指定的Service上。有了 Kubernetes内建的透明负载均衡和故障恢复机制,不管后端有多少服务进程,也不管某个服务进程是否会由于发生故障而重新部署到其他机器,都不会影响到我们对服务的正常调用。更重要的是这个Service本身一旦创建就不再变化,这意味着,在Kubernetes集群中,我们再也不用为了服务的IP地址变来变去的问题而头疼了</p><p>在通常情况下,Cluster IP是在Service创建后由Kubernetes系统自动分配的,其他Pod无法预先知道某个 Service的Cluster IP地址,因此需要一个服务发现机制来找到这个服务。为此,最初的时候, Kubernetes巧妙地使用了 Linux环境变量(Environment Variable)来解决这个问题,后面会详细说明其机制。现在我们只需知道,根据 Service的唯一名字,容器可以从环境变量中获取到Service对应的Cluster IP地址和端口,从而发起TCP/IP连接请求了。</p><h2 id="Kubernetes-基本概念与术语">Kubernetes 基本概念与术语</h2><h3 id="Master">Master</h3><p>Kubernetes里的Master指的是集群控制节点,每个Kubernetes集群里需要有一个Master节点来负责整个集群的管理和控制,基本上Kubernetes所有的控制命令都是发给它,它来负责具体的执行过程,我们后面所有执行的命令基本都是在Master节点上运行的。Master节点通常会占据一个独立的X86服务器(或者一个虚拟机),一个主要的原因是它太重要了,它是整个集群的“首脑”,如果它宕机或者不可用,那么我们所有的控制命令都将失效。</p><p>Master节点上运行着以下一组关键进程。</p><ul><li>Kubernetes API Server(kube-apipserver),提供了HTTP Rest接口的关键服务进程,是Kubernetes里所有资源的增、删、改、查等操作的唯一入口,也是集群控制的入口进程。</li><li>Kubernetes Controller Manager(kube-controller-manager), Kubernetes里所有资源对象的自动化控制中心,可以理解为资源对象的“大总管”。</li><li>Kubernetes Scheduler(kube-scheduler),负责资源调度(Pod调度)的进程,相当于公交公司的“调度室”。</li></ul><p>其实Master节点上往往还启动了一个etcd Server进程,因为Kubernetes里的所有资源对象的数据全部是保存在etcd中的。</p><h3 id="Node">Node</h3><p>除了Master, Kubernetes集群中的其他机器被称为Node节点,在较早的版本中也被称为Minion。与Master一样,Node节点可以是一台物理主机,也可以是一台虚拟机。Node节点才是Kubernetes集群中的工作负载节点,每个Node都会被Master分配一些工作负载(Docker容器),当某个Node宕机时,其上的工作负载会被Master自动转移到其他节点上去。</p><p>每个Node节点上都运行着以下一组关键进程。</p><ul><li>kubelet:负责Pod对应的容器的创建、启停等任务,同时与Master节点密切协作,实现集群管理的基本功能。</li><li>kube-proxy:实现Kubernetes service的通信与负载均衡机制的重要组件。</li><li>Docker Engine(docker): Docker引擎,负责本机的容器创建和管理工作。</li></ul><p>Node节点可以在运行期间动态增加到Kubernetes集群中,前提是这个节点上已经正确安装、配置和启动了上述关键进程,在默认情况下kubelet会向Master注册自己,这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范围,kubelet进程就会定时向 Master节点汇报自身的情报,例如操作系统、Docker版本、机器的CPU和内存情况,以及之前有哪些Pod在运行等,这样 Master可以获知每个Node的资源使用情况,并实现高效均衡的资源调度策略。而某个Node超过指定时间不上报信息时,会被 Master判定为“失联”,Noe的状态被标记为不可用(Not Ready),随后 Master会触发“工作负载大转移”的自动流程。</p><h3 id="Pod">Pod</h3><p>Pod是Kubernetes的最重要也最基本的概念,如图1.6所示是Pod的组成示意图,我们看到每个Pod都有一个特殊的被称为“根容器”的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分,除了Pause容器,每个Pod还包含一个或多个紧密相关的用户业务容器。<br><img data-src="/images/kubernetes-authoritative-guide/1.6Pod%E7%9A%84%E7%BB%84%E6%88%90%E4%B8%8E%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt></p><p>为什么Kubernetes会设计出一个全新的Pod的概念并且Pod有这样特殊的组成结构?</p><p>原因之一:在一组容器作为一个单元的情况下,我们难以对“整体”简单地进行判断及有效地进行行动。比如,一个容器死亡了,此时算是整体死亡么?是N/M的死亡率么?引入业务无关并且不易死亡的Pause容器作为Pod的根容器,以它的状态代表整个容器组的状态,就简单、巧妙地解决了这个难题。</p><p>原因之二:Pod里的多个业务容器共享Pause容器的IP,共享Pause容器挂接的Volume,这样既简化了密切关联的业务容器之间的通信问题,也很好地解决了它们之间的文件共享问题。</p><p>Kubernetes为每个Pod都分配了唯一的IP地址,称之为Pod IP,一个Pod里的多个容器共享Pod IP地址。<font color="DeepPink"><strong>Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信,这通常采用虚拟二层网络技术来实现</strong></font>,例如Flannel、Openvswitch等,因此我们需要牢记一点:在Kubernetes里,一个Pod里的容器与另外主机上的Pod容器能够直接通信。</p><p>Pod其实有两种类型:普通的Pod及静态Pod(static Pod),后者比较特殊,它并不存放在Kubernetes的etcd存储里,而是存放在某个具体的Node上的一个具体文件中,并且只在此Node上启动运行。而普通的Pod一旦被创建,就会被放入到etcd中存储,随后会被Kubernetes master调度到某个具体的Node上并进行绑定(Binding),随后该Pod被对应的Node上的kubelet进程实例化成一组相关的 Docker容器并启动起来。在默认情况下,当Pod里的某个容器停止时Kubernetes会自动检测到这个问题并且重新启动这个Pod(重启Pod里的所有容器),如果Pod所在的Node宕机,则会将这个Node上的所有Pod重新调度到其他节点上。</p><p>每个Pod都可以对其能使用的服务器上的计算资源设置限额,当前可以设置限额的计算资源有CPU与 Memory两种,其中CPU的资源单位为CPU(Core)的数量,是一个绝对值而非相对值。</p><p>一个CPU的配额对于绝大多数容器来说是相当大的一个资源配额了,所以,在Kubernetes里,通常以千分之一的CPU配额为最小单位,用m来表示。通常一个容器的CPU配额被定义为100~300m,即占用0.1~0.3个CPU。由于CPU配额是一个绝对值,所以无论在拥有一个Core的机器上,还是在拥有48个Core的机器上,100m这个配额所代表的CPU的使用量都是样的。与CPU配额类似,Memory配额也是一个绝对值,它的单位是内存字节数。</p><p>在Kubernetes里,一个计算资源进行配额限定需要设定以下两个参数：</p><ul><li>Requests:该资源的最小申请量,系统必须满足要求。</li><li>Limits:该资源最大允许使用的量,不能被突破,当容器试图使用超过这个量的资源时可能会被Kubernetes kill并重启。</li></ul><p>通常我们会把Request设置为一个比较小的数值,符合容器平时的工作负载情况下的资源需求,而把 Limit设置为峰值负载情况下资源占用的最大量。</p><h3 id="Label-标签">Label(标签)</h3><p>Label是Kubernetes系统中另外一个核心概念。一个Label是一个key=value的键值对,其中key与 value由用户自己指定。 Label可以附加到各种资源对象上,例如Node、Pod、Service、RC等,一个资源对象可以定义任意数量的Label,同一个Label也可以被添加到任意数量的资源对象上去,Label通常在资源对象定义时确定,也可以在对象创建后动态添加或者删除。</p><p>我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能,以便于灵活、方便地进行资源分配、调度、配置、部署等管理工作。例如:部署不同版本的应用到不同的环境中;或者监控和分析应用(日志记录、监控、告警)等。一些常用的Label示例如下。</p><ul><li>版本标签:“release”:“stable”,“release”:&quot;canary</li><li>环境标签:“environment”:“dev”,“environment”:“qa”,“environment”:“production”</li><li>架构标签:“tier”:“frontend”,“tier”:“backend”,“tier”:“middleware”</li><li>质量管控标签:“rack”:“daily”,“rack”:“week”</li></ul><p>Label相当于我们熟悉的“标签”,给某个资源对象定义一个Label,就相当于给它打了一个标签,随后可以通过Label Selector(标签选择器)查询和筛选拥有某些 Label的资源对象,Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制Label Selector可以被类比为SQL语句中的where查询条件,例如,name=redis-slave这个Label selector作用于Pod时,可以被类比为’select* from pod where pods name= redis-slave’这样的语句。当前有两种Label Selector的表达式:基于等式的(Equality-based)和基于集合的(Set-based),前者采用“等式类”的表达式匹配标签,下面是一些具体的例子。</p><ul><li>name=redis-slave:匹配所有具有标签name=redis-slave的资源对象。</li><li>env!= production:匹配所有不具有标签env= production的资源对象,比如env=test就是满足此条件的标签之一。</li></ul><p>而后者则使用集合操作的表达式匹配标签,下面是一些具体的例子。</p><ul><li>name in(redis-master, redis-save):匹配所有具有标签name=redis-master或者name=redis-slave的资源对象。</li><li>name not in(php-frontend):匹配所有不具有标签name=php-frontend的资源对象。</li></ul><p>可以通过多个Label Selector表达式的组合实现复杂的条件选择,多个表达式之间用&quot;,&quot;进行分隔即可,几个条件之间是“AND”的关系,即同时满足多个条件,比如下面的例子:</p><ul><li>name=redis-slave, env!=production</li><li>name not in (php-frontend), env!=production</li></ul><p>Label Selector在Kubernetes中的重要使用场景有以下几处。</p><ul><li><font color="DeepPink"><strong>kube-controller进程通过资源对象RC上定义的Label Selector来筛选要监控的Pod副本的数量,从而实现Pod副本的数量始终符合预期设定的全自动控制流程。</strong></font></li><li><font color="DeepPink"><strong>kube-proxy进程通过Service的Label selector来选择对应的Pod,自动建立起每个Service到对应Pod的请求转发路由表,从而实现 Service的智能负载均衡机制。</strong></font></li><li><font color="DeepPink"><strong>通过对某些Node定义特定的Label,并且在Pod定义文件中使用NodeSelector这种标签调度策略,kube-scheduler进程可以实现Pod“定向调度”的特性。</strong></font></li></ul><h3 id="Replication-Controller-RC">Replication Controller (RC)</h3><p>RC是Kubernetes系统中的核心概念之一,简单来说,它其实是定义了一个期望的场景,即声明某种Pod的副本数量在任意时刻都符合某个预期值,所以RC的定义包括如下几个部分。</p><ul><li>Pod期待的副本数(replicas)。</li><li>用于筛选目标Pod的Label Selector</li><li>当Pod的副本数量小于预期数量的时候,用于创建新Pod的Pod模板(template)。</li></ul><p>当我们定义了一个RC并提交到Kubernetes集群中以后, Master节点上的Controller Manager组件就得到通知,定期巡检系统中当前存活的目标Pod,并确保目标Pod实例的数量刚好等于此RC的期望值,如果有过多的Pod副本在运行,系统就会停掉一些Pod,否则系统就会再自动创建一些Pod。可以说,通过RC,Kubernetes实现了用户应用集群的高可用性,并且大大减少了系统管理员在传统T环境中需要完成的许多手工运维工作(如主机监控脚本、应用监控脚本、故障恢复脚本等）。</p><p>Replica Set与Deployment这两个重要资源对象逐步替换了之前的RC的作用,是Kubernetes 1.3里Pod自动扩容(伸缩)这个告警功能实现的基础,也将继续在 Kubernetes未来的版本中发挥重要的作用。</p><p>最后我们总结一下关于RC(Replica Set)的一些特性与作用。</p><ul><li>在大多数情况下,我们通过定义一个RC实现Pod的创建过程及副本数量的自动控制。</li><li>RC里包括完整的Pod定义模板。</li><li>RC通过Label Selector机制实现对Pod副本的自动控制。</li><li>通过改变RC里的Pod副本数量,可以实现Pod的扩容或缩容功能。</li><li>通过改变RC里Pod模板中的镜像版本,可以实现Pod的滚动升级功能。</li></ul><h3 id="Deployment">Deployment</h3><p>Deployment是Kubernetes12引入的新概念,引入的目的是为了更好地解决Pod的编排问题。为此, Deployment在内部使用了 Replica Set来实现目的,无论从Deployment的作用与目的、它的YAM定义,还是从它的具体命令行操作来看,我们都可以把它看作RC的一次升级两者的相似度超过90%。</p><p>Deployment相对于RC的一个最大升级是我们可以随时知道当前Pod“部署”的进度。实际上由于一个Pod的创建、调度、绑定节点及在目标Node上启动对应的容器这一完整过程需要一定的时间,所以我们期待系统启动N个Pod副本的目标状态,实际上是一个连续变化的“部署过程”导致的最终状态。</p><p>Deployment的典型使用场景有以下几个。</p><ul><li>创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建过程。</li><li>检查Deployment的状态来看部署动作是否完成(Pod副本的数量是否达到预期的值)。</li><li>更新Deployment以创建新的Pod(比如镜像升级)。</li><li>如果当前Deployment不稳定,则回滚到一个早先的Deployment版本。</li><li>挂起或者恢复一个Deployment。</li></ul><h3 id="Horizontal-Pod-Autoscaler-HPA">Horizontal Pod Autoscaler(HPA)</h3><p>Horizontal Pod Autoscaling简称HPA,意思是Pod横向自动扩容,与之前的RC、Deployment样,也属于一种Kubernetes资源对象。通过追踪分析RC控制的所有目标Pod的负载变化情况,来确定是否需要针对性地调整目标Pod的副本数,这是HPA的实现原理。当前,HPA可以有以下两种方式作为Pod负载的度量指标。</p><ul><li>CPUUtilization Percentage</li><li>应用程序自定义的度量指标,比如服务在每秒内的相应的请求数(TPS或QPS)。</li></ul><p>CPUUtilization Percentage是一个算术平均值,即目标Pod所有副本自身的CPU利用率的平均值。一个Pod自身的CPU利用率是该Pod当前CPU的使用量除以它的Pod Request的值,比如我们定义一个Pod的Pod Request为0.4,而当前Pod的CPU使用量为0.2,则它的CPU使用率为50%,如此一来,我们就可以就算出来一个RC控制的所有Pod副本的CPU利用率的算术平均值了。如果某一时刻CPUUtilization Percentage的值超过80%,则意味着当前的Pod副本数很可能不足以支撑接下来更多的请求,需要进行动态扩容,而当请求高峰时段过去后,Pod的CPU利用率又会降下来,此时对应的Pod副本数应该自动减少到一个合理的水平。</p><p>CPUUtilization Percentage计算过程中使用到的Pod的CPU使用量通常是1分钟内的平均值,目前通过查询Heapster扩展组件来得到这个值,所以需要安装部署Heapster,这样一来便增加了系统的复杂度和实施HPA特性的复杂度,因此,未来的计划是Kubernetes自身实现一个基础性能数据采集模块,从而更好地支持HPA和其他需要用到基础性能数据的功能模块。此外,我们也看到,如果目标Pod没有定义Pod Request的值,则无法使用CPUUtilization Percentage来实现Pod横向自动扩容的能力。除了使用CPUUtiliationPercentage, Kubernetes从1.2版本开始,尝试支持应用程序自定义的度量指标,目前仍然为实验特性,不建议在生产环境中使用。</p><h3 id="Service-服务">Service(服务)</h3><h4 id="概述">概述</h4><p>Service也是Kubernetes里的最核心的资源对象之一,Kubernetes里的每个Service其实就是我们经常提起的微服务架构中的一个“微服务”,之前我们所说的Pod、RC等资源对象其实都是为这节所说的“服务”—Kubernetes Service做“嫁衣”的。图1.14显示了Pod、RC与 Service的逻辑关系。<br><img data-src="/images/kubernetes-authoritative-guide/1.14Pod_RC_Service%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt><br>从图1.14中我们看到,Kubernetes的 Service定义了一个服务的访问入口地址,前端的应用(Pod)通过这个入口地址访问其背后的一组由Pod副本组成的集群实例,<font color="DeepPink"><strong>Service与其后端Pod副本集群之间则是通过Label selector来实现“无缝对接”的。</strong></font>而RC的作用实际上是保证Service的服务能力和服务质量始终处于预期的标准。</p><p><font color="DeepPink"><strong>运行在每个Node上的kube-proxy进程其实就是一个智能的软件负载均衡器,它负责把对Service的请求转发到后端的某个Pod实例上,并在内部实现服务的负载均衡与会话保持机制。但 Kubernetes发明了一种很巧妙又影响深远的设计:Service不是共用一个负载均衡器的IP地址,而是每个Service分配了一个全局唯一的虚拟IP地址,这个虚拟IP被称为Cluster IP。这样一来,每个服务就变成了具备唯一IP地址的“通信节点”,服务调用就变成了最基础的TCP网络通信问题。</strong></font></p><p>我们知道,<font color="DeepPink"><strong>Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变,因为新Pod的IP地址与之前旧Pod的不同。而 Service一旦创建, Kubernetes就会自动为它分配一个可用的Cluster IP,而且在Service的整个生命周期内,它的Cluster IP不会发生改变。于是,服务发现这个棘手的问题在Kubernetes的架构里也得以轻松解决:只要用Service的Name与Service的Cluster IP地址做一个DNS域名映射即可完美解决问题。现在想想,这真是一个很棒的设计。</strong></font></p><h4 id="Kubernetes的服务发现机制">Kubernetes的服务发现机制</h4><p>任何分布式系统都会涉及“服务发现”这个基础问题,大部分分布式系统通过提供特定的API接口来实现服务发现的功能,但这样做会导致平台的侵入性比较强,也增加了开发测试的困难。Kubernetes则采用了直观朴素的思路去解决这个棘手的问题。</p><p>首先,每个Kubernetes中的Service都有一个唯一的Cluster IP以及唯一的名字,而名字是由开发者自己定义的,部署的时候也没必要改变,所以完全可以固定在配置中。接下来的问题就是如何通过Service的名字找到对应的Cluster IP?</p><p>Kubernetes通过Add-On增值包的方式引入了DNS系统,把服务名作为DNs域名,这样一来,程序就可以直接使用服务名来建立通信连接了。</p><h4 id="外部系统访问Service的问题">外部系统访问Service的问题</h4><p>为了更加深入地理解和掌握Kubernetes,我们需要弄明白Kubernetes里的“三种IP”这个关键问题,这三种IP分别如下。</p><ul><li>Node IP:Node节点的IP地址。</li><li>Pod IP:Pod的IP地址</li><li>Cluster IP: Service的IP地址。</li></ul><p>首先,Node IP是Kubernetes集群中每个节点的物理网卡的IP地址,这是一个真实存在的物理网络,所有属于这个网络的服务器之间都能通过这个网络直接通信,不管它们中是否有部分节点不属于这个Kubernetes集群。这也表明了Kubernetes集群之外的节点访问Kubernetes集群之内的某个节点或者TCP/IP服务的时候,必须要通过Node IP进行通信。</p><p>其次,Pod IP是每个Pod的IP地址,它是Docker Engine根据docker0网桥的IP地址段进行分配的,通常是一个虚拟的二层网络,前面我们说过,Kubernetes要求位于不同Node上的Pod能够彼此直接通信,所以Kubernetes里一个Pod里的容器访问另外一个Pod里的容器,就是通过Pod IP所在的虚拟二层网络进行通信的,而真实的TCP/IP流量则是通过Node IP所在的物理网卡流出的。</p><p>最后,我们说说Service的Cluster IP,它也是一个虚拟的IP,但更像是一个“伪造”的IP网络,原因有以下几点。</p><ul><li>Cluster IP仅仅作用于Kubernetes Service这个对象,并由Kubernetes管理和分配IP地址(来源于Cluster IP地址池)。</li><li>Cluster IP无法被Ping,因为没有一个“实体网络对象”来响应。</li><li>Cluster IP只能结合Service Port组成一个具体的通信端口,单独的Cluster IP不具备TCP/IP通信的基础,并且它们属于Kubernetes集群这样一个封闭的空间,集群之外的节点如果要访问这个通信端口,则需要做一些额外的工作。</li><li>在Kubernetes集群之内,Node IP网、Pod IP网与Cluster IP网之间的通信,采用的是Kubernetes自己设计的一种编程方式的特殊的路由规则,与我们所熟知的IP路由有很大的不同。</li></ul><p>NodePort的实现方式是在Kubernetes集群里的每个Node上为需要外部访问的Service开启个对应的TCP监听端口,外部系统只要用任意一个Node的IP地址+具体的NodePort端口号即可访问此服务。</p><p>但NodePort还没有完全解决外部访问Service的所有问题,比如负载均衡问题,假如我们的集群中有10个Node,则此时最好有一个负载均衡器,外部的请求只需访问此负载均衡器的IP地址,由负载均衡器负责转发流量到后面某个Node的NodePort上。如图1.17所示。</p><p><img data-src="/images/kubernetes-authoritative-guide/1.17_NodePort_LB.png" alt></p><p>图1.17中的Load balancer组件独立于Kubernetes集群之外,通常是一个硬件的负载均衡器,或者是以软件方式实现的,例如HAProxy或者Nginx。对于每个Service,我们通常需要配置个对应的Load balancer实例来转发流量到后端的Node上,这的确增加了工作量及出错的概率。于是Kubernetes提供了自动化的解决方案,如果我们的集群运行在谷歌的GCE公有云上,那么只要我们把Service的type=Node Port改为type=LoadBalancer,此时Kubernetes会自动创建个对应的Load balancer实例并返回它的IP地址供外部客户端使用。其他公有云提供商只要实现了支持此特性的驱动,则也可以达到上述目的。此外,裸机上的类似机制(Bare Metal Service Load Balancers)也正在被开发。</p><h3 id="Volume-存储卷">Volume(存储卷)</h3><p>Volume是Pod中能够被多个容器访问的共享目录Kubernetes Volume概念、用途和目的与Docker的Volume比较类似,但两者不能等价。首先,Kubernetes中的Volume定义在Pod上,然后被一个Pod里的多个容器挂载到具体的文件目录下;其次,Kubernetes中的Volume与Pod的生命周期相同,但与容器的生命周期不相关,当容器终止或者重启时,Volume中的数据也不会丢失。最后,Kubernetes支持多种类型的 Volume,例如GlusterFS、ceph等先进的分布式文件系统。</p><p>除了可以让一个Pod里的多个容器共享文件、让容器的数据写到宿主机的磁盘上或者写文件到网络存储中, Kubernetes的Volume还扩展出了一种非常有实用价值的功能,即容器配置文件集中化定义与管理,这是通过ConfigMap这个新的资源对象来实现的,后面我们会详细说明。</p><p>Kubernetes提供了非常丰富的Volume类型,下面逐一进行说明。</p><h4 id="empty-Dir">empty Dir</h4><p>一个empty Dir Volume是在Pod分配到Node时创建的。从它的名称就可以看出,它的初始内容为空,并且无须指定宿主机上对应的目录文件,因为这是 Kubernetes自动分配的一个目录当Pod从Node上移除时,empty Dir中的数据也会被永久删除。empty Dir的一些用途如下。</p><ul><li>临时空间,例如用于某些应用程序运行时所需的临时目录,且无须永久保留。</li><li>长时间任务的中间过程 Check Point的临时保存目录。</li><li>一个容器需要从另一个容器中获取数据的目录(多容器共享目录)。</li></ul><p>目前,用户无法控制emptyDir使用的介质种类。如果kubelet的配置是使用硬盘,那么所有empty都将创建在该硬盘上。Pod在将来可以设置empty Dir是位于硬盘、固态硬盘上还是基于内存的tmpfs上,上面的例子便采用了emptyDir类的 Volume。</p><h4 id="hostPath">hostPath</h4><p>hostPath为在Pod上挂载宿主机上的文件或目录,它通常可以用于以下几方面：</p><ul><li>容器应用程序生成的日志文件需要永久保存时,可以使用宿主机的高速文件系统进行存储。</li><li>需要访问宿主机上Docker引擎内部数据结构的容器应用时,可以通过定义hostPath为宿主机/var/lib/docker目录,使容器内部应用可以直接访问Docker的文件系统。</li></ul><p>在使用这种类型的Volume时,需要注意以下几点。</p><ul><li>在不同的Node上具有相同配置的Pod可能会因为宿主机上的目录和文件不同而导致对Volume上目录和文件的访问结果不一致。</li><li>如果使用了资源配额管理,则 Kubernetes无法将 hostPath在宿主机上使用的资源纳入管理。</li></ul><h4 id="gcePersistentDisk">gcePersistentDisk</h4><p>使用这种类型的Volume表示使用谷歌公有云提供的永久磁盘(Persistent Disk,PD)存放Volume的数据,它与Empty Dir不同,PD上的内容会被永久保存,当Pod被删除时,PD只是被卸载(Unmount),但不会被删除。需要注意的是,你需要先创建一个永久磁盘(PD),才能使用gcePersistent Disk。<br>使用gcePersistent Disk有以下一些限制条件。</p><ul><li>Node(运行 kubelet的节点)需要是GCE虚拟机。<br>*这些虚拟机需要与PD存在于相同的GCE项目和Zone中。</li></ul><h4 id="awsElasticBlock-Store">awsElasticBlock Store</h4><p>与GCE类似,该类型的Volume使用亚马逊公有云提供的EBS Volume存储数据,需要先创建一个EBS Volume才能使用awsElasticBlockStore。</p><p>使用awsElasticBlockStore的一些限制条件如下。</p><ul><li>Node(运行kubelet的节点)需要是AWS EC2实例。</li><li>这些AWS EC2实例需要与EBS volume存在于相同的region和availability-zone中。</li><li>EBS只支持单个EC2实例mount一个volume。</li></ul><h4 id="NFS">NFS</h4><p>使用NFS网络文件系统提供的共享目录存储数据时,我们需要在系统中部署一个NFS Server。</p><h4 id="其他类型的Volume">其他类型的Volume</h4><ul><li>iscsi:使用 ISCSI存储设备上的目录挂载到Pod中。</li><li>flocker:使用 Flocker来管理存储卷。</li><li>glusterfs:使用开源GlusterFS网络文件系统的目录挂载到Pod中。</li><li>rbd:使用Linux块设备共享存储(Rados block device)挂载到Pod中。</li><li>gitRepo:通过挂载一个空目录,并从GIT库clone一个git repository以供Pod使用。</li><li>secret:一个secret volume用于为Pod提供加密的信息,你可以将定义在Kubernetes中的secret直接挂载为文件让Pod访问。secret volume是通过tmfs(内存文件系统)实现的,所以这种类型的volume总是不会持久化的。</li></ul><h3 id="Persistent-Volume">Persistent Volume</h3><p>之前我们提到的Volume是定义在Pod上的,属于“计算资源”的一部分,而实际上,“网络存储”是相对独立于“计算资源”而存在的一种实体资源。比如在使用虚机的情况下,我们通常会先定义一个网络存储,然后从中划出一个“网盘”并挂接到虚机上。Persistent Volume(简称PV)和与之相关联的Persistent Volume Claim(简称PVC)也起到了类似的作用。</p><p>PV可以理解成Kubernetes集群中的某个网络存储中对应的一块存储,它与Volume很类似,</p><p>但有以下区别。</p><ul><li>PV只能是网络存储,不属于任何Node,但可以在每个Node上访问。</li><li>PV并不是定义在Pod上的,而是独立于Pod之外定义。</li><li>PV目前只有几种类型: GCE Persistent Disks、NFS、RBD、 ISCSI、AWS、ElasticBlock Store、 GlusterFS等。</li></ul><p>比较重要的是PV的accessModes属性,目前有以下类型：</p><ul><li>Read WriteOnce:读写权限、并且只能被单个Node挂载。</li><li>ReadOnly Many:只读权限、允许被多个Node挂载。</li><li>Read WriteMany:读写权限、允许被多个Node挂载。</li></ul><p>如果某个Pod想申请某种条件的PV,则首先需要定义一个Persistent Volume Claim(PVC)。</p><p>最后,我们说说PV的状态,PV是有状态的对象,它有以下几种状态。</p><ul><li>Available:空闲状态。</li><li>Bound:已经绑定到某个PVC上。</li><li>Released:对应的PVC已经删除,但资源还没有被集群收回。</li><li>Failed:PⅤ自动回收失败。</li></ul><h3 id="Namespace-命名空间">Namespace(命名空间)</h3><p>Namespace(命名空间)是Kubernetes系统中的另一个非常重要的概念,Namespace在很多情况下用于实现多租户的资源隔离。Namespace通过将集群内部的资源对象“分配”到不同的Namespace中,形成逻辑上分组的不同项目、小组或用户组,便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。</p><h3 id="Annotation-注解">Annotation(注解)</h3><p>Annotation与Label类似,也使用key/value键值对的形式进行定义。不同的是Label具有严格的命名规则,它定义的是 Kubernetes对象的元数据(Metadata),并且用于Label Selector而Annotation则是用户任意定义的“附加”信息,以便于外部工具进行查找,很多时候,Kubernetes的模块自身会通过Annotation的方式标记资源对象的一些特殊信息。</p><p>通常来说,用Annotation来记录的信息如下。</p><ul><li>build信息、release信息、Docker镜像信息等,例如时间戳、release id号、PR号、镜像hash值、docker registry地址等。</li><li>日志库、监控库、分析库等资源库的地址信息</li><li>程序调试工具信息,例如工具名称、版本号等</li><li>团队的联系信息,例如电话号码、负责人名称、网址等。</li></ul><blockquote><p>只看了第一章</p></blockquote>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Docker</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 查询语句执行顺序</title>
    <url>/order-of-execution-of-the-sql-query.html</url>
    <content><![CDATA[<ul><li>FROM clause</li><li>WHERE clause</li><li>GROUP BY clause</li><li>HAVING clause</li><li>SELECT clause</li><li>ORDER BY clause</li></ul><p>该执行顺序整理自网络，<a href="https://qxf2.com/blog/mysql-query-execution/" target="_blank" rel="noopener">mysql-query-execution</a></p><blockquote><p>一直想找一个权威的解释出处，比如官网，但没有找到，如果有人知道，欢迎留言。</p></blockquote>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Query</tag>
        <tag>Execution</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Uber Go 语言编码规范</title>
    <url>/uber-go-guide.html</url>
    <content><![CDATA[<blockquote><p>原文地址：<br><a href="https://github.com/xxjwxc/uber_go_guide_cn" target="_blank" rel="noopener">https://github.com/xxjwxc/uber_go_guide_cn</a></p></blockquote><a id="more"></a><p><a href="https://www.uber.com/" target="_blank" rel="noopener">Uber</a> 是一家美国硅谷的科技公司，也是 Go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 Gopher 圈熟知的 <a href="https://github.com/uber-go/zap" target="_blank" rel="noopener">zap</a>、<a href="https://github.com/jaegertracing/jaeger" target="_blank" rel="noopener">jaeger</a> 等。2018 年年末 Uber 将内部的 <a href="https://github.com/uber-go/guide" target="_blank" rel="noopener">Go 风格规范</a> 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 Gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。</p><h2 id="版本">版本</h2><ul><li>当前更新版本：2019-11-13 版本地址：<a href="https://github.com/uber-go/guide/commit/85bf203f4371a8ae9e5e9a4d52ea77b17ca04ae6" target="_blank" rel="noopener">commit:#71</a></li><li>如果您发现任何更新、问题或改进，请随时 fork 和 PR</li><li>Please feel free to fork and PR if you find any updates, issues or improvement.</li></ul><h2 id="目录">目录</h2><ul><li><a href="#%E4%BB%8B%E7%BB%8D">介绍</a></li><li><a href="#%E6%8C%87%E5%AF%BC%E5%8E%9F%E5%88%99">指导原则</a><ul><li><a href="#%E6%8C%87%E5%90%91-interface-%E7%9A%84%E6%8C%87%E9%92%88">指向 interface 的指针</a></li><li><a href="#%E6%8E%A5%E6%94%B6%E5%99%A8-receiver-%E4%B8%8E%E6%8E%A5%E5%8F%A3">接收器 (receiver) 与接口</a></li><li><a href="#%E9%9B%B6%E5%80%BC-Mutex-%E6%98%AF%E6%9C%89%E6%95%88%E7%9A%84">零值 Mutex 是有效的</a></li><li><a href="#%E5%9C%A8%E8%BE%B9%E7%95%8C%E5%A4%84%E6%8B%B7%E8%B4%9D-Slices-%E5%92%8C-Maps">在边界处拷贝 Slices 和 Maps</a></li><li><a href="#%E4%BD%BF%E7%94%A8-defer-%E9%87%8A%E6%94%BE%E8%B5%84%E6%BA%90">使用 defer 释放资源</a></li><li><a href="#Channel-%E7%9A%84-size-%E8%A6%81%E4%B9%88%E6%98%AF-1%E8%A6%81%E4%B9%88%E6%98%AF%E6%97%A0%E7%BC%93%E5%86%B2%E7%9A%84">Channel 的 size 要么是 1，要么是无缓冲的</a></li><li><a href="#%E6%9E%9A%E4%B8%BE%E4%BB%8E-1-%E5%BC%80%E5%A7%8B">枚举从 1 开始</a></li><li><a href="#%E9%94%99%E8%AF%AF%E7%B1%BB%E5%9E%8B">错误类型</a></li><li><a href="#%E9%94%99%E8%AF%AF%E5%8C%85%E8%A3%85-(Error-Wrapping)">错误包装 (Error Wrapping)</a></li><li><a href="#%E5%A4%84%E7%90%86%E7%B1%BB%E5%9E%8B%E6%96%AD%E8%A8%80%E5%A4%B1%E8%B4%A5">处理类型断言失败</a></li><li><a href="#%E4%B8%8D%E8%A6%81-panic">不要 panic</a></li><li><a href="#%E4%BD%BF%E7%94%A8-gouberorgatomic">使用 go.uber.org/atomic</a></li></ul></li><li><a href="#%E6%80%A7%E8%83%BD">性能</a><ul><li><a href="#%E4%BC%98%E5%85%88%E4%BD%BF%E7%94%A8-strconv-%E8%80%8C%E4%B8%8D%E6%98%AF-fmt">优先使用 strconv 而不是 fmt</a></li><li><a href="#%E9%81%BF%E5%85%8D%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%B0%E5%AD%97%E8%8A%82%E7%9A%84%E8%BD%AC%E6%8D%A2">避免字符串到字节的转换</a></li><li><a href="#%E5%B0%BD%E9%87%8F%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%8C%87%E5%AE%9A-Map-%E5%AE%B9%E9%87%8F">尽量初始化时指定 Map 容量</a></li></ul></li><li><a href="#%E8%A7%84%E8%8C%83">规范</a><ul><li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7">一致性</a></li><li><a href="#%E7%9B%B8%E4%BC%BC%E7%9A%84%E5%A3%B0%E6%98%8E%E6%94%BE%E5%9C%A8%E4%B8%80%E7%BB%84">相似的声明放在一组</a></li><li><a href="#import-%E5%88%86%E7%BB%84">import 分组</a></li><li><a href="#%E5%8C%85%E5%90%8D">包名</a></li><li><a href="#%E5%87%BD%E6%95%B0%E5%90%8D">函数名</a></li><li><a href="#%E5%AF%BC%E5%85%A5%E5%88%AB%E5%90%8D">导入别名</a></li><li><a href="#%E5%87%BD%E6%95%B0%E5%88%86%E7%BB%84%E4%B8%8E%E9%A1%BA%E5%BA%8F">函数分组与顺序</a></li><li><a href="#%E5%87%8F%E5%B0%91%E5%B5%8C%E5%A5%97">减少嵌套</a></li><li><a href="#%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84-else">不必要的 else</a></li><li><a href="#%E9%A1%B6%E5%B1%82%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E">顶层变量声明</a></li><li><a href="#%E5%AF%B9%E4%BA%8E%E6%9C%AA%E5%AF%BC%E5%87%BA%E7%9A%84%E9%A1%B6%E5%B1%82%E5%B8%B8%E9%87%8F%E5%92%8C%E5%8F%98%E9%87%8F%E4%BD%BF%E7%94%A8_%E4%BD%9C%E4%B8%BA%E5%89%8D%E7%BC%80">对于未导出的顶层常量和变量，使用_作为前缀</a></li><li><a href="#%E7%BB%93%E6%9E%84%E4%BD%93%E4%B8%AD%E7%9A%84%E5%B5%8C%E5%85%A5">结构体中的嵌入</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E5%90%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E7%BB%93%E6%9E%84%E4%BD%93">使用字段名初始化结构体</a></li><li><a href="#%E6%9C%AC%E5%9C%B0%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E">本地变量声明</a></li><li><a href="#nil-%E6%98%AF%E4%B8%80%E4%B8%AA%E6%9C%89%E6%95%88%E7%9A%84-slice">nil 是一个有效的 slice</a></li><li><a href="#%E5%B0%8F%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F">小变量作用域</a></li><li><a href="#%E9%81%BF%E5%85%8D%E5%8F%82%E6%95%B0%E8%AF%AD%E4%B9%89%E4%B8%8D%E6%98%8E%E7%A1%AEAvoid-Naked-Parameters">避免参数语义不明确（Avoid Naked Parameters）</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E9%9D%A2%E5%80%BC%E9%81%BF%E5%85%8D%E8%BD%AC%E4%B9%89">使用原始字符串字面值，避免转义</a></li><li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96-Struct-%E5%BC%95%E7%94%A8">初始化 Struct 引用</a></li><li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96-maps">初始化 Maps</a></li><li><a href="#%E5%AD%97%E7%AC%A6%E4%B8%B2-string-format">字符串 string format</a></li><li><a href="#%E5%91%BD%E5%90%8D-Printf-%E6%A0%B7%E5%BC%8F%E7%9A%84%E5%87%BD%E6%95%B0">命名 Printf 样式的函数</a></li></ul></li><li><a href="#%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F">编程模式</a><ul><li><a href="#%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%B5%8B%E8%AF%95">表驱动测试</a></li><li><a href="#%E5%8A%9F%E8%83%BD%E9%80%89%E9%A1%B9">功能选项</a></li></ul></li></ul><h2 id="介绍">介绍</h2><p>样式 (style) 是支配我们代码的惯例。术语<code>样式</code>有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。</p><p>本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 Go 语言功能。</p><p>该指南最初由 <a href="https://github.com/prashantv" target="_blank" rel="noopener">Prashant Varanasi</a> 和 <a href="https://github.com/nomis52" target="_blank" rel="noopener">Simon Newton</a> 编写，目的是使一些同事能快速使用 Go。多年来，该指南已根据其他人的反馈进行了修改。</p><p>本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则，而其他扩展准则依赖于下面外部的指南：</p><ol><li><a href="https://golang.org/doc/effective_go.html" target="_blank" rel="noopener">Effective Go</a></li><li><a href="https://github.com/golang/go/wiki/CodeReviewComments" target="_blank" rel="noopener">The Go common mistakes guide</a></li></ol><p>所有代码都应该通过<code>golint</code>和<code>go vet</code>的检查并无错误。我们建议您将编辑器设置为：</p><ul><li>保存时运行 <code>goimports</code></li><li>运行 <code>golint</code> 和 <code>go vet</code> 检查错误</li></ul><p>您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息：<br><a href="https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins" target="_blank" rel="noopener">https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins</a></p><h2 id="指导原则">指导原则</h2><h3 id="指向-interface-的指针">指向 interface 的指针</h3><p>您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。</p><p>接口实质上在底层用两个字段表示：</p><ol><li>一个指向某些特定类型信息的指针。您可以将其视为&quot;type&quot;。</li><li>数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。</li></ol><p>如果希望接口方法修改基础数据，则必须使用指针传递。</p><h3 id="接收器-receiver-与接口">接收器 (receiver) 与接口</h3><p>使用值接收器的方法既可以通过值调用，也可以通过指针调用。</p><p>例如，</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> S <span class="keyword">struct</span> &#123;</span><br><span class="line">  data <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s S)</span> <span class="title">Read</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> s.data</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *S)</span> <span class="title">Write</span><span class="params">(str <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">  s.data = str</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sVals := <span class="keyword">map</span>[<span class="keyword">int</span>]S&#123;<span class="number">1</span>: &#123;<span class="string">"A"</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 你只能通过值调用 Read</span></span><br><span class="line">sVals[<span class="number">1</span>].Read()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这不能编译通过：</span></span><br><span class="line"><span class="comment">//  sVals[1].Write("test")</span></span><br><span class="line"></span><br><span class="line">sPtrs := <span class="keyword">map</span>[<span class="keyword">int</span>]*S&#123;<span class="number">1</span>: &#123;<span class="string">"A"</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过指针既可以调用 Read，也可以调用 Write 方法</span></span><br><span class="line">sPtrs[<span class="number">1</span>].Read()</span><br><span class="line">sPtrs[<span class="number">1</span>].Write(<span class="string">"test"</span>)</span><br></pre></td></tr></table></figure><p>同样，即使该方法具有值接收器，也可以通过指针来满足接口。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> F <span class="keyword">interface</span> &#123;</span><br><span class="line">  f()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> S1 <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s S1)</span> <span class="title">f</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> S2 <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *S2)</span> <span class="title">f</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">s1Val := S1&#123;&#125;</span><br><span class="line">s1Ptr := &amp;S1&#123;&#125;</span><br><span class="line">s2Val := S2&#123;&#125;</span><br><span class="line">s2Ptr := &amp;S2&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i F</span><br><span class="line">i = s1Val</span><br><span class="line">i = s1Ptr</span><br><span class="line">i = s2Ptr</span><br><span class="line"></span><br><span class="line"><span class="comment">//  下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器</span></span><br><span class="line"><span class="comment">//   i = s2Val</span></span><br></pre></td></tr></table></figure><p><a href="https://golang.org/doc/effective_go.html" target="_blank" rel="noopener">Effective Go</a> 中有一段关于 <a href="https://golang.org/doc/effective_go.html#pointers_vs_values" target="_blank" rel="noopener">pointers vs. values</a> 的精彩讲解。</p><h3 id="零值-Mutex-是有效的">零值 Mutex 是有效的</h3><p>零值 <code>sync.Mutex</code> 和 <code>sync.RWMutex</code> 是有效的。所以指向 mutex 的指针基本是不必要的。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">mu := <span class="built_in">new</span>(sync.Mutex)</span><br><span class="line">mu.Lock()</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">mu.Lock()</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果你使用结构体指针，mutex 可以非指针形式作为结构体的组成字段，或者更好的方式是直接嵌入到结构体中。<br>如果是私有结构体类型或是要实现 Mutex 接口的类型，我们可以使用嵌入 mutex 的方法：</p><table><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> smap <span class="keyword">struct</span> &#123;</span><br><span class="line">  sync.Mutex <span class="comment">// only for unexported types（仅适用于非导出类型）</span></span><br><span class="line"></span><br><span class="line">  data <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSMap</span><span class="params">()</span> *<span class="title">smap</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;smap&#123;</span><br><span class="line">    data: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *smap)</span> <span class="title">Get</span><span class="params">(k <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  m.Lock()</span><br><span class="line">  <span class="keyword">defer</span> m.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> m.data[k]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> SMap <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex <span class="comment">// 对于导出类型，请使用私有锁</span></span><br><span class="line"></span><br><span class="line">  data <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewSMap</span><span class="params">()</span> *<span class="title">SMap</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;SMap&#123;</span><br><span class="line">    data: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *SMap)</span> <span class="title">Get</span><span class="params">(k <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  m.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> m.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> m.data[k]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td>为私有类型或需要实现互斥接口的类型嵌入。</td><td>对于导出的类型，请使用专用字段。</td></tr></tbody></table><h3 id="在边界处拷贝-Slices-和-Maps">在边界处拷贝 Slices 和 Maps</h3><p>slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。</p><h4 id="接收-Slices-和-Maps">接收 Slices 和 Maps</h4><p>请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *Driver)</span> <span class="title">SetTrips</span><span class="params">(trips []Trip)</span></span> &#123;</span><br><span class="line">  d.trips = trips</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trips := ...</span><br><span class="line">d1.SetTrips(trips)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 你是要修改 d1.trips 吗？</span></span><br><span class="line">trips[<span class="number">0</span>] = ...</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *Driver)</span> <span class="title">SetTrips</span><span class="params">(trips []Trip)</span></span> &#123;</span><br><span class="line">  d.trips = <span class="built_in">make</span>([]Trip, <span class="built_in">len</span>(trips))</span><br><span class="line">  <span class="built_in">copy</span>(d.trips, trips)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trips := ...</span><br><span class="line">d1.SetTrips(trips)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里我们修改 trips[0]，但不会影响到 d1.trips</span></span><br><span class="line">trips[<span class="number">0</span>] = ...</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h4 id="返回-slices-或-maps">返回 slices 或 maps</h4><p>同样，请注意用户对暴露内部状态的 map 或 slice 的修改。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Stats <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  counters <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Snapshot 返回当前状态。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Stats)</span> <span class="title">Snapshot</span><span class="params">()</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">int</span></span> &#123;</span><br><span class="line">  s.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> s.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> s.counters</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// snapshot 不再受互斥锁保护</span></span><br><span class="line"><span class="comment">// 因此对 snapshot 的任何访问都将受到数据竞争的影响</span></span><br><span class="line"><span class="comment">// 影响 stats.counters</span></span><br><span class="line">snapshot := stats.Snapshot()</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Stats <span class="keyword">struct</span> &#123;</span><br><span class="line">  mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  counters <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Stats)</span> <span class="title">Snapshot</span><span class="params">()</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">int</span></span> &#123;</span><br><span class="line">  s.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> s.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  result := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>, <span class="built_in">len</span>(s.counters))</span><br><span class="line">  <span class="keyword">for</span> k, v := <span class="keyword">range</span> s.counters &#123;</span><br><span class="line">    result[k] = v</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// snapshot 现在是一个拷贝</span></span><br><span class="line">snapshot := stats.Snapshot()</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="使用-defer-释放资源">使用 defer 释放资源</h3><p>使用 defer 释放资源，诸如文件和锁。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">p.Lock()</span><br><span class="line"><span class="keyword">if</span> p.count &lt; <span class="number">10</span> &#123;</span><br><span class="line">  p.Unlock()</span><br><span class="line">  <span class="keyword">return</span> p.count</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.count++</span><br><span class="line">newCount := p.count</span><br><span class="line">p.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> newCount</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当有多个 return 分支时，很容易遗忘 unlock</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">p.Lock()</span><br><span class="line"><span class="keyword">defer</span> p.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.count &lt; <span class="number">10</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> p.count</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p.count++</span><br><span class="line"><span class="keyword">return</span> p.count</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更可读</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 <code>defer</code>。</p><h3 id="Channel-的-size-要么是-1，要么是无缓冲的">Channel 的 size 要么是 1，要么是无缓冲的</h3><p>channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。考虑如何确定大小，是什么阻止了 channel 在负载下被填满并阻止写入，以及发生这种情况时发生了什么。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 应该足以满足任何情况！</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">64</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 大小：1</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">1</span>) <span class="comment">// 或者</span></span><br><span class="line"><span class="comment">// 无缓冲 channel，大小为 0</span></span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="枚举从-1-开始">枚举从 1 开始</h3><p>在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add=0, Subtract=1, Multiply=2</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add=1, Subtract=2, Multiply=3</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> LogOutput <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  LogToStdout LogOutput = <span class="literal">iota</span></span><br><span class="line">  LogToFile</span><br><span class="line">  LogToRemote</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// LogToStdout=0, LogToFile=1, LogToRemote=2</span></span><br></pre></td></tr></table></figure><h3 id="错误类型">错误类型</h3><p>Go 中有多种声明错误（Error) 的选项：</p><ul><li><a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a> 对于简单静态字符串的错误</li><li><a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a> 用于格式化的错误字符串</li><li>实现 <code>Error()</code> 方法的自定义类型</li><li>用 <a href="https://godoc.org/github.com/pkg/errors#Wrap" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Wrap</code></a> 的 Wrapped errors</li></ul><p>返回错误时，请考虑以下因素以确定最佳选择：</p><ul><li><p>这是一个不需要额外信息的简单错误吗？如果是这样，<a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a> 足够了。</p></li><li><p>客户需要检测并处理此错误吗？如果是这样，则应使用自定义类型并实现该 <code>Error()</code> 方法。</p></li><li><p>您是否正在传播下游函数返回的错误？如果是这样，请查看本文后面有关错误包装 <a href="#%E9%94%99%E8%AF%AF%E5%8C%85%E8%A3%85" title="Error-Wrapping">section on error wrapping</a> 部分的内容。</p></li><li><p>否则 <a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a> 就可以了。</p></li></ul><p>如果客户端需要检测错误，并且您已使用创建了一个简单的错误 <a href="https://golang.org/pkg/errors/#New" target="_blank" rel="noopener"><code>errors.New</code></a>，请使用一个错误变量。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errors.New(<span class="string">"could not open"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := foo.Open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err.Error() == <span class="string">"could not open"</span> &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> ErrCouldNotOpen = errors.New(<span class="string">"could not open"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> ErrCouldNotOpen</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := foo.Open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err == foo.ErrCouldNotOpen &#123;</span><br><span class="line">    <span class="comment">// handle</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果您有可能需要客户端检测的错误，并且想向其中添加更多信息（例如，它不是静态字符串），则应使用自定义类型。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Errorf(<span class="string">"file %q not found"</span>, file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> strings.Contains(err.Error(), <span class="string">"not found"</span>) &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> errNotFound <span class="keyword">struct</span> &#123;</span><br><span class="line">  file <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e errNotFound)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Sprintf(<span class="string">"file %q not found"</span>, e.file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errNotFound&#123;file: file&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">use</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> err := open(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> _, ok := err.(errNotFound); ok &#123;</span><br><span class="line">      <span class="comment">// handle</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>直接导出自定义错误类型时要小心，因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// package foo</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> errNotFound <span class="keyword">struct</span> &#123;</span><br><span class="line">  file <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e errNotFound)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Sprintf(<span class="string">"file %q not found"</span>, e.file)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">IsNotFoundError</span><span class="params">(err error)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  _, ok := err.(errNotFound)</span><br><span class="line">  <span class="keyword">return</span> ok</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(file <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> errNotFound&#123;file: file&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// package bar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := foo.Open(<span class="string">"foo"</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> foo.IsNotFoundError(err) &#123;</span><br><span class="line">    <span class="comment">// handle</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"unknown error"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="错误包装-Error-Wrapping">错误包装 (Error Wrapping)</h3><p>一个（函数/方法）调用失败时，有三种主要的错误传播方式：</p><ul><li><p>如果没有要添加的其他上下文，并且您想要维护原始错误类型，则返回原始错误。</p></li><li><p>添加上下文，使用 <a href="https://godoc.org/github.com/pkg/errors#Wrap" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Wrap</code></a> 以便错误消息提供更多上下文 ,<a href="https://godoc.org/github.com/pkg/errors#Cause" target="_blank" rel="noopener"><code>&quot;pkg/errors&quot;.Cause</code></a> 可用于提取原始错误。<br>Use fmt.Errorf if the callers do not need to detect or handle that specific error case.</p></li><li><p>如果调用者不需要检测或处理的特定错误情况，使用 <a href="https://golang.org/pkg/fmt/#Errorf" target="_blank" rel="noopener"><code>fmt.Errorf</code></a>。</p></li></ul><p>建议在可能的地方添加上下文，以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误，而不是诸如“连接被拒绝”之类的模糊错误。</p><p>在将上下文添加到返回的错误时，请避免使用“failed to”之类的短语来保持上下文简洁，这些短语会陈述明显的内容，并随着错误在堆栈中的渗透而逐渐堆积：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">s, err := store.New()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Errorf(</span><br><span class="line">        <span class="string">"failed to create new store: %s"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">s, err := store.New()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Errorf(</span><br><span class="line">        <span class="string">"new store: %s"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">failed to x: failed to y: failed to create new store: the error</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x: y: new store: the error</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>但是，一旦将错误发送到另一个系统，就应该明确消息是错误消息（例如使用<code>err</code>标记，或在日志中以”Failed”为前缀）。</p><p>另请参见 <a href="https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully" target="_blank" rel="noopener">Don’t just check errors, handle them gracefully</a>. 不要只是检查错误，要优雅地处理错误</p><h3 id="处理类型断言失败">处理类型断言失败</h3><p><a href="https://golang.org/ref/spec#Type_assertions" target="_blank" rel="noopener">type assertion</a> 的单个返回值形式针对不正确的类型将产生 panic。因此，请始终使用“comma ok”的惯用法。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">t := i.(<span class="keyword">string</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">t, ok := i.(<span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">  <span class="comment">// 优雅地处理错误</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="不要-panic">不要 panic</h3><p>在生产环境中运行的代码必须避免出现 panic。panic 是 <a href="https://en.wikipedia.org/wiki/Cascading_failure" target="_blank" rel="noopener">cascading failures</a> 级联失败的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(bar <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(bar) == <span class="number">0</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"bar must not be empty"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(os.Args) != <span class="number">2</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"USAGE: foo &lt;bar&gt;"</span>)</span><br><span class="line">    os.Exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  foo(os.Args[<span class="number">1</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(bar <span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(bar) == <span class="number">0</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> errors.New(<span class="string">"bar must not be empty"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(os.Args) != <span class="number">2</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"USAGE: foo &lt;bar&gt;"</span>)</span><br><span class="line">    os.Exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> err := foo(os.Args[<span class="number">1</span>]); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> _statusTemplate = template.Must(template.New(<span class="string">"name"</span>).Parse(<span class="string">"_statusHTML"</span>))</span><br></pre></td></tr></table></figure><p>即使在测试代码中，也优先使用<code>t.Fatal</code>或者<code>t.FailNow</code>而不是 panic 来确保失败被标记。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func TestFoo(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">f, err := ioutil.TempFile(<span class="string">""</span>, <span class="string">"test"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="built_in">panic</span>(<span class="string">"failed to set up test"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func TestFoo(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">f, err := ioutil.TempFile(<span class="string">""</span>, <span class="string">"test"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  t.Fatal(<span class="string">"failed to set up test"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="使用-go-uber-org-atomic">使用 <a href="http://go.uber.org/atomic" target="_blank" rel="noopener">go.uber.org/atomic</a></h3><p>使用 <a href="https://golang.org/pkg/sync/atomic/" target="_blank" rel="noopener">sync/atomic</a> 包的原子操作对原始类型 (<code>int32</code>, <code>int64</code>等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。</p><p><a href="https://godoc.org/go.uber.org/atomic" target="_blank" rel="noopener">go.uber.org/atomic</a> 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的<code>atomic.Bool</code>类型。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> foo <span class="keyword">struct</span> &#123;</span><br><span class="line">  running <span class="keyword">int32</span>  <span class="comment">// atomic</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f* foo)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> atomic.SwapInt32(&amp;f.running, <span class="number">1</span>) == <span class="number">1</span> &#123;</span><br><span class="line">     <span class="comment">// already running…</span></span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// start the Foo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">isRunning</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> f.running == <span class="number">1</span>  <span class="comment">// race!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> foo <span class="keyword">struct</span> &#123;</span><br><span class="line">  running atomic.Bool</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> f.running.Swap(<span class="literal">true</span>) &#123;</span><br><span class="line">     <span class="comment">// already running…</span></span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// start the Foo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *foo)</span> <span class="title">isRunning</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> f.running.Load()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h2 id="性能">性能</h2><p>性能方面的特定准则只适用于高频场景。</p><h3 id="优先使用-strconv-而不是-fmt">优先使用 strconv 而不是 fmt</h3><p>将原语转换为字符串或从字符串转换时，<code>strconv</code>速度比<code>fmt</code>快。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  s := fmt.Sprint(rand.Int())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  s := strconv.Itoa(rand.Int())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BenchmarkFmtSprint-4    143 ns/op    2 allocs/op</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BenchmarkStrconv-4    64.2 ns/op    1 allocs/op</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="避免字符串到字节的转换">避免字符串到字节的转换</h3><p>不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  w.Write([]<span class="keyword">byte</span>(<span class="string">"Hello world"</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">data := []<span class="keyword">byte</span>(<span class="string">"Hello world"</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">  w.Write(data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BenchmarkBad-4   50000000   22.2 ns/op</span><br></pre></td></tr></table></figure></td><td><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BenchmarkGood-4  500000000   3.25 ns/op</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="尽量初始化时指定-Map-容量">尽量初始化时指定 Map 容量</h3><p>在尽可能的情况下，在使用 <code>make()</code> 初始化的时候提供容量信息</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2, hint)</span><br></pre></td></tr></table></figure><p>为 <code>make()</code> 提供容量信息（hint）尝试在初始化时调整 map 大小，<br>这减少了在将元素添加到 map 时增长和分配的开销。<br>注意，map 不能保证分配 hint 个容量。因此，即使提供了容量，添加元素仍然可以进行分配。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]os.FileInfo)</span><br><span class="line"></span><br><span class="line">files, _ := ioutil.ReadDir(<span class="string">"./files"</span>)</span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> files &#123;</span><br><span class="line">    m[f.Name()] = f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">files, _ := ioutil.ReadDir(<span class="string">"./files"</span>)</span><br><span class="line"></span><br><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]os.FileInfo, <span class="built_in">len</span>(files))</span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> files &#123;</span><br><span class="line">    m[f.Name()] = f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr><tr><td><p><code>m</code> 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。</p></td><td><p><code>m</code> 是有大小提示创建的；在运行时可能会有更少的分配。</p></td></tr></tbody></table><h2 id="规范">规范</h2><h3 id="一致性">一致性</h3><p>本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断；</p><p>但是最重要的是，<strong>保持一致</strong>.</p><p>一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug</p><p>相反，一个单一的代码库会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、<br>代码审查痛苦、而且增加 bug 数量</p><p>将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。</p><h3 id="相似的声明放在一组">相似的声明放在一组</h3><p>Go 语言支持将相似的声明放在一个组内。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"a"</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">"b"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"a"</span></span><br><span class="line">  <span class="string">"b"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>这同样适用于常量、变量和类型声明：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">const</span> a = <span class="number">1</span></span><br><span class="line"><span class="keyword">const</span> b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> a = <span class="number">1</span></span><br><span class="line"><span class="keyword">var</span> b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Area <span class="keyword">float64</span></span><br><span class="line"><span class="keyword">type</span> Volume <span class="keyword">float64</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  a = <span class="number">1</span></span><br><span class="line">  b = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  a = <span class="number">1</span></span><br><span class="line">  b = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> (</span><br><span class="line">  Area <span class="keyword">float64</span></span><br><span class="line">  Volume <span class="keyword">float64</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>仅将相关的声明放在一组。不要将不相关的声明放在一组。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">  ENV_VAR = <span class="string">"MY_ENV"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Operation <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  Add Operation = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  Subtract</span><br><span class="line">  Multiply</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> ENV_VAR = <span class="string">"MY_ENV"</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>分组使用的位置没有限制，例如：你可以在函数内部使用它们：</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> red = color.New(<span class="number">0xff</span>0000)</span><br><span class="line">  <span class="keyword">var</span> green = color.New(<span class="number">0x00ff</span>00)</span><br><span class="line">  <span class="keyword">var</span> blue = color.New(<span class="number">0x0000ff</span>)</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> (</span><br><span class="line">    red   = color.New(<span class="number">0xff</span>0000)</span><br><span class="line">    green = color.New(<span class="number">0x00ff</span>00)</span><br><span class="line">    blue  = color.New(<span class="number">0x0000ff</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="import-分组">import 分组</h3><p>导入应该分为两组：</p><ul><li>标准库</li><li>其他库</li></ul><p>默认情况下，这是 goimports 应用的分组。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"go.uber.org/atomic"</span></span><br><span class="line">  <span class="string">"golang.org/x/sync/errgroup"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line"></span><br><span class="line">  <span class="string">"go.uber.org/atomic"</span></span><br><span class="line">  <span class="string">"golang.org/x/sync/errgroup"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="包名">包名</h3><p>当命名包时，请按下面规则选择一个名称：</p><ul><li>全部小写。没有大写或下划线。</li><li>大多数使用命名导入的情况下，不需要重命名。</li><li>简短而简洁。请记住，在每个使用的地方都完整标识了该名称。</li><li>不用复数。例如<code>net/url</code>，而不是<code>net/urls</code>。</li><li>不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。</li></ul><p>另请参阅 <a href="https://blog.golang.org/package-names" target="_blank" rel="noopener">Package Names</a> 和 <a href="https://rakyll.org/style-packages/" target="_blank" rel="noopener">Go 包样式指南</a>.</p><h3 id="函数名">函数名</h3><p>我们遵循 Go 社区关于使用 <a href="https://golang.org/doc/effective_go.html#mixed-caps" target="_blank" rel="noopener">MixedCaps 作为函数名</a> 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：<code>TestMyFunction_WhatIsBeingTested</code>.</p><h3 id="导入别名">导入别名</h3><p>如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"net/http"</span></span><br><span class="line"></span><br><span class="line">  client <span class="string">"example.com/client-go"</span></span><br><span class="line">  trace <span class="string">"example.com/trace/v2"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line"></span><br><span class="line">  nettrace <span class="string">"golang.net/x/trace"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"runtime/trace"</span></span><br><span class="line"></span><br><span class="line">  nettrace <span class="string">"golang.net/x/trace"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="函数分组与顺序">函数分组与顺序</h3><ul><li>函数应按粗略的调用顺序排序。</li><li>同一文件中的函数应按接收者分组。</li></ul><p>因此，导出的函数应先出现在文件中，放在<code>struct</code>, <code>const</code>, <code>var</code>定义的后面。</p><p>在定义类型之后，但在接收者的其余方法之前，可能会出现一个 <code>newXYZ()</code>/<code>NewXYZ()</code></p><p>由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Cost</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> calcCost(s.weights)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> something <span class="keyword">struct</span>&#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">calcCost</span><span class="params">(n []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Stop</span><span class="params">()</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSomething</span><span class="params">()</span> *<span class="title">something</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;something&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> something <span class="keyword">struct</span>&#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newSomething</span><span class="params">()</span> *<span class="title">something</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;something&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Cost</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> calcCost(s.weights)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *something)</span> <span class="title">Stop</span><span class="params">()</span></span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">calcCost</span><span class="params">(n []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;...&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="减少嵌套">减少嵌套</h3><p>代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> data &#123;</span><br><span class="line">  <span class="keyword">if</span> v.F1 == <span class="number">1</span> &#123;</span><br><span class="line">    v = process(v)</span><br><span class="line">    <span class="keyword">if</span> err := v.Call(); err == <span class="literal">nil</span> &#123;</span><br><span class="line">      v.Send()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.Printf(<span class="string">"Invalid v: %v"</span>, v)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> data &#123;</span><br><span class="line">  <span class="keyword">if</span> v.F1 != <span class="number">1</span> &#123;</span><br><span class="line">    log.Printf(<span class="string">"Invalid v: %v"</span>, v)</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  v = process(v)</span><br><span class="line">  <span class="keyword">if</span> err := v.Call(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line">  v.Send()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="不必要的-else">不必要的 else</h3><p>如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">int</span></span><br><span class="line"><span class="keyword">if</span> b &#123;</span><br><span class="line">  a = <span class="number">100</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  a = <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">a := <span class="number">10</span></span><br><span class="line"><span class="keyword">if</span> b &#123;</span><br><span class="line">  a = <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="顶层变量声明">顶层变量声明</h3><p>在顶层，使用标准<code>var</code>关键字。请勿指定类型，除非它与表达式的类型不同。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> _s <span class="keyword">string</span> = F()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"A"</span> &#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> _s = F()</span><br><span class="line"><span class="comment">// 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型</span></span><br><span class="line"><span class="comment">// 还是那种类型</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"A"</span> &#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果表达式的类型与所需的类型不完全匹配，请指定类型。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> myError <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(myError)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123; <span class="keyword">return</span> <span class="string">"error"</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">F</span><span class="params">()</span> <span class="title">myError</span></span> &#123; <span class="keyword">return</span> myError&#123;&#125; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> _e error = F()</span><br><span class="line"><span class="comment">// F 返回一个 myError 类型的实例，但是我们要 error 类型</span></span><br></pre></td></tr></table></figure><h3 id="对于未导出的顶层常量和变量，使用-作为前缀">对于未导出的顶层常量和变量，使用_作为前缀</h3><p>在未导出的顶级<code>vars</code>和<code>consts</code>， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。</p><p>例外：未导出的错误值，应以<code>err</code>开头。</p><p>基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// foo.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  defaultPort = <span class="number">8080</span></span><br><span class="line">  defaultUser = <span class="string">"user"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// bar.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Bar</span><span class="params">()</span></span> &#123;</span><br><span class="line">  defaultPort := <span class="number">9090</span></span><br><span class="line">  ...</span><br><span class="line">  fmt.Println(<span class="string">"Default port"</span>, defaultPort)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// We will not see a compile error if the first line of</span></span><br><span class="line">  <span class="comment">// Bar() is deleted.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// foo.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  _defaultPort = <span class="number">8080</span></span><br><span class="line">  _defaultUser = <span class="string">"user"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="结构体中的嵌入">结构体中的嵌入</h3><p>嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Client <span class="keyword">struct</span> &#123;</span><br><span class="line">  version <span class="keyword">int</span></span><br><span class="line">  http.Client</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Client <span class="keyword">struct</span> &#123;</span><br><span class="line">  http.Client</span><br><span class="line"></span><br><span class="line">  version <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="使用字段名初始化结构体">使用字段名初始化结构体</h3><p>初始化结构体时，几乎始终应该指定字段名称。现在由 <a href="https://golang.org/cmd/vet/" target="_blank" rel="noopener"><code>go vet</code></a> 强制执行。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">k := User&#123;<span class="string">"John"</span>, <span class="string">"Doe"</span>, <span class="literal">true</span>&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">k := User&#123;</span><br><span class="line">    FirstName: <span class="string">"John"</span>,</span><br><span class="line">    LastName: <span class="string">"Doe"</span>,</span><br><span class="line">    Admin: <span class="literal">true</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>例外：如果有 3 个或更少的字段，则可以在测试表中省略字段名称。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  op Operation</span><br><span class="line">  want <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  &#123;Add, <span class="string">"add"</span>&#125;,</span><br><span class="line">  &#123;Subtract, <span class="string">"subtract"</span>&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="本地变量声明">本地变量声明</h3><p>如果将变量明确设置为某个值，则应使用短变量声明形式 (<code>:=</code>)。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> s = <span class="string">"foo"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">s := <span class="string">"foo"</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>但是，在某些情况下，<code>var</code> 使用关键字时默认值会更清晰。例如，声明空切片。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(list []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  filtered := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> _, v := <span class="keyword">range</span> list &#123;</span><br><span class="line">    <span class="keyword">if</span> v &gt; <span class="number">10</span> &#123;</span><br><span class="line">      filtered = <span class="built_in">append</span>(filtered, v)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(list []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> filtered []<span class="keyword">int</span></span><br><span class="line">  <span class="keyword">for</span> _, v := <span class="keyword">range</span> list &#123;</span><br><span class="line">    <span class="keyword">if</span> v &gt; <span class="number">10</span> &#123;</span><br><span class="line">      filtered = <span class="built_in">append</span>(filtered, v)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="nil-是一个有效的-slice">nil 是一个有效的 slice</h3><p><code>nil</code> 是一个有效的长度为 0 的 slice，这意味着，</p><ul><li><p>您不应明确返回长度为零的切片。应该返回<code>nil</code> 来代替。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="string">""</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="string">""</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li><li><p>要检查切片是否为空，请始终使用<code>len(s) == 0</code>。而非 <code>nil</code>。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isEmpty</span><span class="params">(s []<span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> s == <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isEmpty</span><span class="params">(s []<span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">len</span>(s) == <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li><li><p>零值切片（用<code>var</code>声明的切片）可立即使用，无需调用<code>make()</code>创建。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">nums := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"><span class="comment">// or, nums := make([]int)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add1 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add2 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> nums []<span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add1 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> add2 &#123;</span><br><span class="line">  nums = <span class="built_in">append</span>(nums, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table></li></ul><h3 id="小变量作用域">小变量作用域</h3><p>如果有可能，尽量缩小变量作用范围。除非它与 <a href="#%E5%87%8F%E5%B0%91%E5%B5%8C%E5%A5%97">减少嵌套</a>的规则冲突。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">err := ioutil.WriteFile(name, data, <span class="number">0644</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> err := ioutil.WriteFile(name, data, <span class="number">0644</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> data, err := ioutil.ReadFile(name); err == <span class="literal">nil</span> &#123;</span><br><span class="line">  err = cfg.Decode(data)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  fmt.Println(cfg)</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">data, err := ioutil.ReadFile(name)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := cfg.Decode(data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(cfg)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="避免参数语义不明确-Avoid-Naked-Parameters">避免参数语义不明确(Avoid Naked Parameters)</h3><p>函数调用中的<code>意义不明确的参数</code>可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (<code>/* ... */</code>)</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func printInfo(name string, isLocal, done bool)</span></span><br><span class="line"></span><br><span class="line">printInfo(<span class="string">"foo"</span>, <span class="literal">true</span>, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func printInfo(name string, isLocal, done bool)</span></span><br><span class="line"></span><br><span class="line">printInfo(<span class="string">"foo"</span>, <span class="literal">true</span> <span class="comment">/* isLocal */</span>, <span class="literal">true</span> <span class="comment">/* done */</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>对于上面的示例代码，还有一种更好的处理方式是将上面的 <code>bool</code> 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Region <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  UnknownRegion Region = <span class="literal">iota</span></span><br><span class="line">  Local</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Status <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  StatusReady = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">  StatusDone</span><br><span class="line">  <span class="comment">// Maybe we will have a StatusInProgress in the future.</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printInfo</span><span class="params">(name <span class="keyword">string</span>, region Region, status Status)</span></span></span><br></pre></td></tr></table></figure><h3 id="使用原始字符串字面值，避免转义">使用原始字符串字面值，避免转义</h3><p>Go 支持使用 <a href="https://golang.org/ref/spec#raw_string_lit" target="_blank" rel="noopener">原始字符串字面值</a>，也就是 &quot; ` &quot; 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。</p><p>可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">wantError := <span class="string">"unknown name:\"test\""</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">wantError := <span class="string">`unknown error:"test"`</span></span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="初始化-Struct-引用">初始化 Struct 引用</h3><p>在初始化结构引用时，请使用<code>&amp;T{}</code>代替<code>new(T)</code>，以使其与结构体初始化一致。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sval := T&#123;Name: <span class="string">"foo"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// inconsistent</span></span><br><span class="line">sptr := <span class="built_in">new</span>(T)</span><br><span class="line">sptr.Name = <span class="string">"bar"</span></span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sval := T&#123;Name: <span class="string">"foo"</span>&#125;</span><br><span class="line"></span><br><span class="line">sptr := &amp;T&#123;Name: <span class="string">"bar"</span>&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="初始化-Maps">初始化 Maps</h3><p>对于空 map 请使用 <code>make(..)</code> 初始化， 并且 map 是通过编程方式填充的。<br>这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  <span class="comment">// m1 读写安全;</span></span><br><span class="line">  <span class="comment">// m2 在写入时会 panic</span></span><br><span class="line">  m1 = <span class="keyword">map</span>[T1]T2&#123;&#125;</span><br><span class="line">  m2 <span class="keyword">map</span>[T1]T2</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  <span class="comment">// m1 读写安全;</span></span><br><span class="line">  <span class="comment">// m2 在写入时会 panic</span></span><br><span class="line">  m1 = <span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2)</span><br><span class="line">  m2 <span class="keyword">map</span>[T1]T2</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr><tr><td><p>声明和初始化看起来非常相似的。</p></td><td><p>声明和初始化看起来差别非常大。</p></td></tr></tbody></table><p>在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 <a href="#%E5%B0%BD%E9%87%8F%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%8C%87%E5%AE%9A-Map-%E5%AE%B9%E9%87%8F">尽量初始化时指定 Map 容量</a>。</p><p>另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[T1]T2, <span class="number">3</span>)</span><br><span class="line">m[k1] = v1</span><br><span class="line">m[k2] = v2</span><br><span class="line">m[k3] = v3</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">m := <span class="keyword">map</span>[T1]T2&#123;</span><br><span class="line">  k1: v1,</span><br><span class="line">  k2: v2,</span><br><span class="line">  k3: v3,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 <code>make</code> (如果可以，请尽量指定 map 容量)。</p><h3 id="字符串-string-format">字符串 string format</h3><p>如果你为<code>Printf</code>-style 函数声明格式字符串，请将格式化字符串放在外面，并将其设置为<code>const</code>常量。</p><p>这有助于<code>go vet</code>对格式字符串执行静态分析。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">msg := <span class="string">"unexpected values %v, %v\n"</span></span><br><span class="line">fmt.Printf(msg, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> msg = <span class="string">"unexpected values %v, %v\n"</span></span><br><span class="line">fmt.Printf(msg, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><h3 id="命名-Printf-样式的函数">命名 Printf 样式的函数</h3><p>声明<code>Printf</code>-style 函数时，请确保<code>go vet</code>可以检测到它并检查格式字符串。</p><p>这意味着您应尽可能使用预定义的<code>Printf</code>-style 函数名称。<code>go vet</code>将默认检查这些。有关更多信息，请参见 <a href="https://golang.org/cmd/vet/#hdr-Printf_family" target="_blank" rel="noopener">Printf 系列</a>。</p><p>如果不能使用预定义的名称，请以 f 结束选择的名称：<code>Wrapf</code>，而不是<code>Wrap</code>。<code>go vet</code>可以要求检查特定的 Printf 样式名称，但名称必须以<code>f</code>结尾。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go vet -printfuncs=wrapf,statusf</span></span><br></pre></td></tr></table></figure><p>另请参阅 <a href="https://kuzminva.wordpress.com/2017/11/07/go-vet-printf-family-check/" target="_blank" rel="noopener">go vet: Printf family check</a>.</p><h2 id="编程模式">编程模式</h2><h3 id="表驱动测试">表驱动测试</h3><p>当测试逻辑是重复的时候，通过 <a href="https://blog.golang.org/subtests" target="_blank" rel="noopener">subtests</a> 使用 table 驱动的方式编写 case 代码看上去会更简洁。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func TestSplitHostPort(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">host, port, err := net.SplitHostPort(<span class="string">"192.0.2.0:8000"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"192.0.2.0"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8000"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">"192.0.2.0:http"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"192.0.2.0"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"http"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">":8000"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">""</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8000"</span>, port)</span><br><span class="line"></span><br><span class="line">host, port, err = net.SplitHostPort(<span class="string">"1:8"</span>)</span><br><span class="line">require.NoError(t, err)</span><br><span class="line">assert.Equal(t, <span class="string">"1"</span>, host)</span><br><span class="line">assert.Equal(t, <span class="string">"8"</span>, port)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// func TestSplitHostPort(t *testing.T)</span></span><br><span class="line"></span><br><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  give     <span class="keyword">string</span></span><br><span class="line">  wantHost <span class="keyword">string</span></span><br><span class="line">  wantPort <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"192.0.2.0:8000"</span>,</span><br><span class="line">    wantHost: <span class="string">"192.0.2.0"</span>,</span><br><span class="line">    wantPort: <span class="string">"8000"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"192.0.2.0:http"</span>,</span><br><span class="line">    wantHost: <span class="string">"192.0.2.0"</span>,</span><br><span class="line">    wantPort: <span class="string">"http"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">":8000"</span>,</span><br><span class="line">    wantHost: <span class="string">""</span>,</span><br><span class="line">    wantPort: <span class="string">"8000"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    give:     <span class="string">"1:8"</span>,</span><br><span class="line">    wantHost: <span class="string">"1"</span>,</span><br><span class="line">    wantPort: <span class="string">"8"</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, tt := <span class="keyword">range</span> tests &#123;</span><br><span class="line">  t.Run(tt.give, <span class="function"><span class="keyword">func</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">    host, port, err := net.SplitHostPort(tt.give)</span><br><span class="line">    require.NoError(t, err)</span><br><span class="line">    assert.Equal(t, tt.wantHost, host)</span><br><span class="line">    assert.Equal(t, tt.wantPort, port)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。</p><p>我们遵循这样的约定：将结构体切片称为<code>tests</code>。 每个测试用例称为<code>tt</code>。此外，我们鼓励使用<code>give</code>和<code>want</code>前缀说明每个测试用例的输入和输出值。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">tests := []<span class="keyword">struct</span>&#123;</span><br><span class="line">  give     <span class="keyword">string</span></span><br><span class="line">  wantHost <span class="keyword">string</span></span><br><span class="line">  wantPort <span class="keyword">string</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, tt := <span class="keyword">range</span> tests &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="功能选项">功能选项</h3><p>功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。</p><p>将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。</p><table><thead><tr><th>Bad</th><th>Good</th></tr></thead><tbody><tr><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// package db</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Connect</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  addr <span class="keyword">string</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  timeout time.Duration,</span></span></span><br><span class="line"><span class="function"><span class="params">  caching <span class="keyword">bool</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*Connection, error)</span></span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Timeout and caching must always be provided,</span></span><br><span class="line"><span class="comment">// even if the user wants to use the default.</span></span><br><span class="line"></span><br><span class="line">db.Connect(addr, db.DefaultTimeout, db.DefaultCaching)</span><br><span class="line">db.Connect(addr, newTimeout, db.DefaultCaching)</span><br><span class="line">db.Connect(addr, db.DefaultTimeout, <span class="literal">false</span> <span class="comment">/* caching */</span>)</span><br><span class="line">db.Connect(addr, newTimeout, <span class="literal">false</span> <span class="comment">/* caching */</span>)</span><br></pre></td></tr></table></figure></td><td><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> options <span class="keyword">struct</span> &#123;</span><br><span class="line">  timeout time.Duration</span><br><span class="line">  caching <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Option overrides behavior of Connect.</span></span><br><span class="line"><span class="keyword">type</span> Option <span class="keyword">interface</span> &#123;</span><br><span class="line">  apply(*options)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> optionFunc <span class="function"><span class="keyword">func</span><span class="params">(*options)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(f optionFunc)</span> <span class="title">apply</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">  f(o)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(t time.Duration)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> optionFunc(<span class="function"><span class="keyword">func</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">    o.timeout = t</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCaching</span><span class="params">(cache <span class="keyword">bool</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> optionFunc(<span class="function"><span class="keyword">func</span><span class="params">(o *options)</span></span> &#123;</span><br><span class="line">    o.caching = cache</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Connect creates a connection.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Connect</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  addr <span class="keyword">string</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  opts ...Option,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*Connection, error)</span></span> &#123;</span><br><span class="line">  options := options&#123;</span><br><span class="line">    timeout: defaultTimeout,</span><br><span class="line">    caching: defaultCaching,</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, o := <span class="keyword">range</span> opts &#123;</span><br><span class="line">    o.apply(&amp;options)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Options must be provided only if needed.</span></span><br><span class="line"></span><br><span class="line">db.Connect(addr)</span><br><span class="line">db.Connect(addr, db.WithTimeout(newTimeout))</span><br><span class="line">db.Connect(addr, db.WithCaching(<span class="literal">false</span>))</span><br><span class="line">db.Connect(</span><br><span class="line">  addr,</span><br><span class="line">  db.WithCaching(<span class="literal">false</span>),</span><br><span class="line">  db.WithTimeout(newTimeout),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></td></tr></tbody></table><p>还可以参考下面资料：</p><ul><li><p><a href="https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html" target="_blank" rel="noopener">Self-referential functions and the design of options</a></p></li><li><p><a href="https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis" target="_blank" rel="noopener">Functional options for friendly APIs</a></p></li></ul>]]></content>
      <categories>
        <category>编码规范</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>编码规范</tag>
        <tag>Go</tag>
        <tag>Uber</tag>
        <tag>Style</tag>
        <tag>Guide</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Spring WebFlux vs Spring MVC</title>
    <url>/spring-webflux-vs-spring-mvc.html</url>
    <content><![CDATA[<p>Spring MVC or WebFlux?</p><a id="more"></a><p><img data-src="/images/spring-webflux-vs-spring-mvc/spring-mvc-and-webflux-venn.png" alt></p><ul><li><font color="DeepPink"><strong>如果你的Spring MVC应用运行良好，则不需要改变。</strong></font>Spring MVC更容易编写、理解、调试，可以选择更多的库，因为目前大多数库都是阻塞的。</li></ul><ul><li>如果你对轻量的web框架感兴趣，并希望使用Java 8 lambdas或者Kotlin，则可以选择Spring WebFlux。对于小型应用程序或微服务来说，这也是一个不错的选择，因为它们可以从更大的透明性（transparency）和控制中获益。</li><li>在微服务体系架构中，可以混合使用带有Spring MVC或Spring WebFlux控制器或Spring WebFlux 函数式的应用程序。在两个框架中都支持相同的基于注释的编程模型，这使得重用知识更容易，同时也为正确的工作选择了正确的工具。<br>*评估的一个简单方法是检查应用的依赖项。 <font color="DeepPink"><strong>如果你要使用阻塞持久性APIs (JPA、JDBC)或网络APIs，那么Spring MVC至少是通用架构的最佳选择。</strong></font>在技术上，Reactor和RxJava都可以在单独的线程上执行阻塞调用，但这时就无法充分利用非阻塞网络栈。</li><li><font color="DeepPink"><strong>如果你的Spring MVC应用程序需要远程调用别的服务，请尝试reactive WebClient。</strong></font>你可以直接从Spring MVC控制器方法返回反应类型（Reactor、RxJava或其他）。每次调用的延迟或调用之间的相互依赖性越大，好处就越显著。Spring MVC控制器也可以调用其他响应性组件。</li><li><font color="DeepPink"><strong>如果你有一个大型团队，请记住向非阻塞、函数式和声明式编程转变的陡峭学习曲线。一种不需要完全切换的实用方法是使用响应式的WebClient。</strong></font>除此之外，从小处着手，衡量收益。我们认为，对于广泛的应用程序，这种转变是不必要的。如果你不确定要寻找什么好处，可以从学习非阻塞I/O的工作原理（例如，在单线程Node.js上的并发性）及其效果开始。</li></ul><p>原文地址：<br><a href="https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html" target="_blank" rel="noopener">https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html</a></p>]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Spring</tag>
        <tag>WebFlux</tag>
        <tag>MVC</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch Scroll and Search After</title>
    <url>/elasticsearch-scroll-and-search-after.html</url>
    <content><![CDATA[<blockquote><p>Elasticsearch From/Size、Scroll、Search After对比</p></blockquote><a id="more"></a><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-from-size" target="_blank" rel="noopener">From/Size</a></h1><p>可以使用from和size参数对结果进行分页。from参数定义要获取的第一个结果的偏移量。 size 参数允许您配置要返回的最大匹配数。</p><blockquote><p>简单来说，需要查询from + size 的条数时，coordinate node就向该index的其余的shards 发送同样的请求，等汇总到（shards * （from + size））条数时在coordinate node再做一次排序，最终抽取出真正的 from 后的 size 条结果。</p></blockquote><blockquote><p>注意from + size 不能超过 index.max_result_window 索引设置，默认为 10,000。 有关深入滚动的更有效方法，请参阅 Scroll 或 Search After API。</p></blockquote><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-body.html#request-body-search-search-type" target="_blank" rel="noopener">Search Type</a></h1><p>在执行分布式搜索时可以执行不同的执行路径。分布式搜索操作需要分散到所有相关的shard，然后收集所有的结果。当使用分散/集中类型执行时，有几种方法可以做到这一点，特别是使用搜索引擎。</p><p>执行分布式搜索时的一个问题是从每个shard检索多少结果。例如，如果我们有 10 个shard，则第一个shard可能保存从 0 到 10 的最相关的结果，而其他shard的结果排在后面。因此，在执行请求时，我们需要从所有shard中获取从0到10的结果，对它们进行排序，然后返回结果(如果我们希望确保得到正确的结果)。</p><p>与搜索引擎相关的另一个问题是每个shard独立存在的事实。当在特定shard上执行查询时，它不会考虑来自其他shard上term频率及（其他shard上）搜索引擎的信息。如果我们想要支持准确的排名，我们需要首先收集所有shard中的term频率，以计算全局term频率，然后使用这些term频率对每个shard执行查询。</p><p>此外，由于需要对结果进行排序，在维护正确的排序行为的同时，获取大型文档集，甚至是滚动它，可能是一个非常昂贵的操作。对于大型结果集滚动，如果返回文档的顺序不重要，则最好按_doc排序。</p><p>Elasticsearch非常灵活，可以根据每个搜索请求控制执行的搜索类型。可以通过设置查询字符串中的search_type参数来配置类型。类型是:</p><h2 id="Query-Then-Fetch">Query Then Fetch</h2><p>参数值： query_then_fetch。</p><p>请求分两个阶段处理。 在第一阶段，查询被转发到所有涉及的分片。 每个分片执行搜索并生成对该分片本地的结果的排序列表。 <font color="DeepPink"><strong>每个分片只向协调节点返回足够的信息，以允许其合并并将分片级结果重新排序为全局排序的最大长度大小的结果集。</strong></font></p><p>在第二阶段期间，<font color="DeepPink"><strong>协调节点仅从相关分片请求文档内容（以及高亮显示的片段，如果有的话）。</strong></font></p><blockquote><p>如果您未在请求中指定 search_type，那么这是默认设置。</p></blockquote><h2 id="Dfs-Query-Then-Fetch">Dfs, Query Then Fetch</h2><p>参数值：dfs_query_then_fetch</p><p>与 “Query Then Fetch” 相同，除了初始分散阶段，该阶段计算分布式term频率以获得更准确的评分。</p><blockquote><p>Scroll与Search After 都依赖于Search Type</p></blockquote><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-search-after" target="_blank" rel="noopener">Search After</a></h1><p>在<a href="https://jiankunking.com/log-service-architecture-design.html">日志服务架构设计</a>中日志搜索后翻页、日志上下文的功能就是通过search_after实现的。</p><p>在官网文档中可以看出Search After有以下特点：</p><ul><li>实时</li><li>可以深度分页（使用前一页的结果来帮助检索下一页）</li><li>不支持跳页</li></ul><blockquote><p>注意：每个文档具有一个唯一值的字段应用作排序规范的仲裁。 否则，具有相同排序值的文档的排序顺序将是未定义的。<s>建议的方法是使用字段 _uid（elasticsearch 6.x _uid 废弃 替换为_id），它确保每个文档包含一个唯一值。</s></p></blockquote><blockquote><p><font color="DeepPink"><strong>The _id field is restricted from use in aggregations, sorting, and scripting. In case sorting or aggregating on the _id field is required, it is advised to duplicate the content of the _id field into another field that has doc_values enabled.</strong></font><br>_id 字段被限制在聚合、排序和脚本中使用。 如果需要对 _id 字段进行排序或聚合，建议将 _id 字段的内容复制到另一个启用了 doc_values 的字段中。</p></blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-id-field.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-id-field.html</a></p><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/search-request-body.html#request-body-search-scroll" target="_blank" rel="noopener">Scroll</a></h1><p>虽然搜索请求返回单个 “page” 的结果，但是滚动 API 可以用于从<font color="DeepPink"><strong>单个搜索请求</strong></font>中检索大量结果（甚至是所有结果），与在传统数据库上使用游标的方式大致相同。</p><p>滚动不是用于实时用户请求，而是用于处理大量数据，例如， 以便将一个索引的内容重新索引到具有不同配置的新索引中。</p><blockquote><p>从滚动请求返回的结果反映了进行初始搜索请求时索引的状态，如时间快照。 对文档（索引，更新或删除）的后续更改只会影响以后的搜索请求。</p></blockquote><p>可以把 scroll 分为初始化和遍历两步，初始化时将所有符合搜索条件的搜索结果缓存起来，可以想象成快照，在遍历时，从这个快照里取数据，也就是说，在初始化后对索引插入、删除、更新数据都不会影响遍历结果。</p><blockquote><p>滚动请求具有优化，使排序顺序为_doc时更快。 如果你想迭代所有文档，无论顺序如何，这是最有效的选择：</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /_search?scroll=1m</span><br><span class="line">&#123;</span><br><span class="line">  &quot;sort&quot;: [</span><br><span class="line">    &quot;_doc&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Keeping-the-search-context-alive">Keeping the search context alive</h2><p>滚动参数（传递到搜索请求和每个滚动请求）告诉Elasticsearch应该保持搜索上下文活动的时间。其值（例如，1m，请参阅 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/common-options.html#time-units" target="_blank" rel="noopener">“Time unit”</a> 一节）不需要足够长以处理所有数据 - 它只需要足够长的时间来处理前一批结果。每个滚动请求（具有滚动参数）设置新的到期时间。</p><p>通常，后台合并过程通过将较小的段合并在一起以创建新的较大段来优化索引，此时较小的段被删除。此过程在滚动期间继续，但是打开的搜索上下文防止旧段在它们仍在使用时被删除。这就是Elasticsearch如何能够返回初始搜索请求的结果，而不考虑对文档的后续更改。</p><h1>小结</h1><p>如果要做非常多页的查询时，search after是一个常量查询延迟和开销，并无什么副作用，可是，就像要查询结果全量导出那样，要在短时间内不断重复同一查询成百甚至上千次，效率就显得非常低了。</p><p>20230318现在不用纠结了 😭 😭 😭 😭 😭 😭</p><p><img data-src="/images/elasticsearch-scroll-and-search-after/scroll.png" alt></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#scroll-search-results" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#scroll-search-results</a></p><p>search after是lucene原生支持的:<br><a href="https://lucene.apache.org/core/8_0_0/core/org/apache/lucene/search/IndexSearcher.html" target="_blank" rel="noopener">https://lucene.apache.org/core/8_0_0/core/org/apache/lucene/search/IndexSearcher.html</a><br><a href="https://lucene.apache.org/core/8_0_0/core/org/apache/lucene/search/IndexSearcher.html#searchAfter-org.apache.lucene.search.ScoreDoc-org.apache.lucene.search.Query-int-" target="_blank" rel="noopener">https://lucene.apache.org/core/8_0_0/core/org/apache/lucene/search/IndexSearcher.html#searchAfter-org.apache.lucene.search.ScoreDoc-org.apache.lucene.search.Query-int-</a></p><blockquote><p>猜测一下search after的实现原理,应该是通过doc_values来实现的<br>doc_values已经排好序了,所以通过每次search_after制定的值,往后查找即可</p></blockquote><p><img data-src="/images/elasticsearch-scroll-and-search-after/doc_values.png" alt></p><blockquote><p>本文内容来自官方文档，主要是做了翻译及汇总。</p></blockquote>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Query</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务理想国</title>
    <url>/microservice-ideal-country.html</url>
    <content><![CDATA[<blockquote><p>微服务的现在、未来</p></blockquote><a id="more"></a><h1>微服务</h1><ul><li><a href="https://jenkins.io/zh/" target="_blank" rel="noopener">Jenkins</a> CI&amp;CD</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a> 调度、负载、高可用<ul><li>自动化容器的部署和复制</li><li>随时扩展或收缩容器规模</li><li>将容器组织成组，并且提供容器间的负载均衡</li><li>很容易地升级应用程序容器的新版本</li><li>提供容器弹性，如果容器失效就替换它，等等…</li></ul></li><li><a href="https://istio.io/" target="_blank" rel="noopener">Istio</a> 监控、熔断、限流<ul><li>流量管理（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能</li><li>安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密。</li><li>控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配。</li><li>观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</li></ul></li><li><a href="http://skywalking.apache.org/zh/" target="_blank" rel="noopener">SkyWalking</a> 监控<ul><li>分布式系统的应用程序性能监视工具</li></ul></li><li>收集Kubernetes Pod日志到<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener">ElasticSearch</a>进行日志检索</li><li>通过<a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>监控机器、实例的运行情况</li><li>通过<a href="https://prometheus.io/docs/alerting/alertmanager/" target="_blank" rel="noopener">Alertmanager</a>将监控信息进行告警</li></ul><p>其中最重要的Kubernetes服务，<a href="https://cloud.tencent.com/product/tke" target="_blank" rel="noopener">腾讯云</a>、<a href="https://www.aliyun.com/product/kubernetes?spm=5176.13342246.1kquk9v2l.2.42243ccbAwomc4&amp;aly_as=i7TpRzFx" target="_blank" rel="noopener">阿里云</a>都已经支持。</p><p>微服务的未来应该是开发人员只需要写Sping Boot或者Gin/Iris应用就可以了，剩下的就交给Kubernetes。</p><h1>Spring Cloud/Kubernetes</h1><p><img data-src="/images/microservice-ideal-country/Spring-Cloud.png" alt></p><h1>Istio Knowledge Map</h1><p>下图转自：<a href="https://github.com/servicemesher/istio-knowledge-map/blob/master/png/istio-knowledge-map.png" target="_blank" rel="noopener">istio-knowledge-map</a><br><img data-src="/images/microservice-ideal-country/istio-knowledge-map.png" alt></p>]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>原创</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL Explain</title>
    <url>/mysql-explain.html</url>
    <content><![CDATA[<p>Explain SQL</p><a id="more"></a><p>语法：explain + SQL</p><p>参数：</p><table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>type</td><td>system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all（至少达到 range 级别，最好达到 ref 级别）</td></tr><tr><td>possible_keys</td><td>显示可能应用在这张表中的索引</td></tr><tr><td>rows</td><td>扫描行数，越小越好</td></tr></tbody></table><p>说明：</p><ul><li>consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。</li><li>ref 指的是使用普通的索引（normal index）。</li><li>range 对索引进行范围检索。</li></ul><blockquote><p>反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比 range还低，与全表扫描是小巫见大巫。</p></blockquote><p>Extra字段显示Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。</p><p>推荐阅读阿里巴巴开发手册MySQL部分：<a href="/attachments/阿里巴巴Java开发手册（华山版）.pdf" target="_blank">阿里巴巴Java开发手册（华山版）.pdf</a></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Explain</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Final</title>
    <url>/java-final.html</url>
    <content><![CDATA[<blockquote><p>Java Final 内存语义</p></blockquote><a id="more"></a><h1>读</h1><p>初次读对象引用与初次读该对象包含的final域，这两个操作之间存在间接依赖关系。由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，也不会重排序这两个操作。但有少数处理器允许对存在间接依赖关系的操作做重排序（比如alpha处理器），这个规则就是专门用来针对这种处理器的。</p><h1>写</h1><p>在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中“逸出”。</p><h1>拓展</h1><p><a href="https://dzone.com/articles/final-keyword-and-jvm-memory-impact" target="_blank" rel="noopener">final-keyword-and-jvm-memory-impact</a></p><p>在线JSR：<a href="/attachments/jsr133.pdf" target="_blank">JSR 133:3.2 Final Fields（第九页）</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Final</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机存储单位换算</title>
    <url>/unit-conversion.html</url>
    <content><![CDATA[<blockquote><p>bit、byte、KB、MB、GB</p></blockquote><a id="more"></a><p>常见的单位换算如下：</p><ul><li>1 byte = 8 bit</li><li>1 KB = 2<sup>10</sup> byte = 1024 byte ≈ 10<sup>3</sup> byte</li><li>1 MB = 2<sup>20</sup> byte ≈ 10 <sup>6</sup> byte</li><li>1 GB = 2<sup>30</sup> byte ≈ 10 <sup>9</sup> byte</li><li>1 亿 = 10<sup>8</sup></li></ul><p>1 个整数占 4 byte，1 亿个整数占 4*10<sup>8</sup> byte ≈ 400 MB。</p>]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>Basic</tag>
      </tags>
  </entry>
  <entry>
    <title>客户中心架构设计</title>
    <url>/customer-center-design.html</url>
    <content><![CDATA[<blockquote><p>客户中心梳理</p></blockquote><a id="more"></a><h1>现状</h1><p>客户数据分散在多个系统之间，而这多个系统中又有三个最为主要的系统：365、Y、E。</p><ul><li>365的客户账号登陆用的是CAS</li><li>E、Y系统定时同步CAS数据，自己维护了一份数据</li></ul><p>客户中心的目的是实现客户维度的账户数据统一，以替换掉目前客户多套账户数据，系统之间通过数据表同步实现账户数据同步的现状。</p><p>从客户中心的名称中就可以知道，该部分对应的主体是客户，而非平常To C的用户。</p><blockquote><p>这里的客户账号主要是公司的经销商、各级门店的员工。</p></blockquote><p>客户与To C用户两者之间最大的区别在于：账号注册、账户管理的不同。客户账号的注册主要是通过分配，而非自己注册。</p><h1>服务层面</h1><p>服务主要拆分为以下几部分：</p><ul><li>OpenApi：客户中心网关、OAuth部分</li><li>账户服务：与账户相关的服务</li><li>短信服务：<ul><li>将集团Web Services短信服务转换成HTTP REST服务（下面简称SMS服务）</li><li>Nginx 代理（组内服务发送短信是调用SMS服务，SMS服务再通过Nginx代理调用集团短信服务）</li></ul></li><li>后台管理服务：公告通知</li></ul><p>更新细致的描述如下图：<br><img data-src="/images/customer-center-design/%E5%AE%A2%E6%88%B7%E4%B8%AD%E5%BF%83%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.png" alt="服务架构图"></p><h1>OAuth</h1><p>OAuth部分主要是熟悉下面这个图，只是有时扮演OAuth Server、有时扮演OAuth Client而已。</p><blockquote><p>比如微信登陆，OpenApi就是微信OAuth Server的client。</p></blockquote><p><img data-src="/images/customer-center-design/oauth_web_server_flow.png" alt="Authorization Code"></p><p>OAuth涉及的点有：</p><ul><li>Authorization Code：有效期内只能使用一次</li><li>Access Token是采用JWT还是一个随机字符串？<ul><li>JWT不依赖存储，但一旦颁发无法取消其有效性</li><li>随机字符串一般都是一个字符ID，具体的数据是存储在Redis中</li></ul></li><li>OAuth 框架选择<ul><li>Java<ul><li><a href="https://github.com/spring-projects/spring-security" target="_blank" rel="noopener">Spring Security</a></li><li><a href="http://shiro.apache.org" target="_blank" rel="noopener">Shiro</a></li></ul></li><li>Golang<ul><li><a href="https://github.com/openshift/osin" target="_blank" rel="noopener">OpenShift OSIN</a></li><li>…</li></ul></li></ul></li></ul><h2 id="OAuth-Server">OAuth Server</h2><p>OAuth Server需要做以下事情：</p><ul><li>/authorize接口，负责校验是否登录（比如校验Header中bear令牌）及登陆账号是否需要别的操作（比如账号合并时的登陆账号id是一个临时id，这时需要强制跳转到账号合并、选择的页面，通过用户选择将多个账号合并为一个账号）<ul><li>已登录，设置Cookie，跳转请求authorize接口参数中的redirect_uri并携带code及state</li><li>未登录，跳转鉴权中心的登陆页<ul><li>用户在鉴权中心的登录页输入用户名密码,校验通过，跳转请求authorize接口参数中的redirect_uri并携带code及state</li></ul></li></ul></li><li>/token接口，负责校验code，颁发access_token及refresh_token</li><li>/refresh_token接口，负责通过refresh_token刷新access_token</li><li>/logout接口，清理Cookie</li></ul><blockquote><p>code分为两种情况：一种是通过浏览器传递给接入方后端；一种是通过移动端获取到code后，通过调用接入方后端接口传递给接入方后端。<br>redirect_uri、post_logout_redirect_uri 需要校验是否与配置的一样。</p></blockquote><h2 id="OAuth-Client">OAuth Client</h2><p>OAuth Client对接OAuth Server需要做以下事情：</p><ul><li>拦截请求，校验是否已登录<ul><li>已登录，放行</li><li>未登录，跳转OAuth Server的/authorize接口接口<ul><li>根据code获取用户信息，设置Cookie、颁发自己的token（access_token、refresh_token）</li></ul></li></ul></li><li>/token接口，调用鉴权中心的密码模式校验密码，获取用户信息，颁发access_token、refresh_token</li><li>/refresh_token接口，负责通过refresh_token刷新access_token</li><li>对于Web端而言，打开首页的时候，先调用me或者profile等接口获取用户信息<ul><li>如果能获取到，则意味着登录成功</li><li>如果获取不到，则前端调用后端/login接口<ul><li>后端/login接口（接口需要传递参数redirect_uri）校验是否登录<ul><li>未登录，跳转鉴权中心的登陆页</li><li>已登录，跳转参数redirect_uri</li></ul></li></ul></li></ul></li><li>对于移动端而言，调用/token接口</li><li>/logout接口，清理自己设置的Cookie，再调用鉴权中心的登出接口</li><li>/callback接口，供OAuth Server回调</li></ul><h1>实现</h1><h2 id="一期">一期</h2><p>从服务架构图中可以看出，业务逻辑最复杂的是账户服务。</p><p>账户服务的复杂的地方主要在：</p><ul><li>数据清理逻辑服务（多系统账户合并）</li><li>多系统迭代替换时间不一致</li></ul><h3 id="账户合并">账户合并</h3><p>下面简单说一下多系统账户合并的逻辑：</p><ul><li>多账户合并在账户首次登陆的时候进行（账户登录，需要区分出是否是首次登陆）</li><li>检验账户是否需要合并的逻辑是：当前登陆账户名、手机号在多个系统之间重复<ul><li>账户名登陆不仅仅需要校验账户名，还需要校验账户名对应的手机号</li><li>手机号登陆不仅仅需要校验手机号，还需要校验手机号对应的账户名</li></ul></li><li>重复账户数据选择、修改、补充合并</li></ul><blockquote><p>这部分开发的时候，有个坑就是业务人员本身不熟悉自己的业务，合并的细节基本都是开发人员通过数据库数据自己梳理，再与业务人员确认。</p></blockquote><h3 id="切换">切换</h3><p>系统很多，但登陆用到的主要有两部分：</p><ul><li>CAS登陆（大部分系统客户用的都是CAS登陆）</li><li>Y、E系统，该系统自己维护了一份客户账号数据</li></ul><p>初始的计划是在一期将所有系统客户登陆统一替换掉，后来由于Y、E系统自身业务优先级的原因，无法参与这次切换，又将替换范围调整为替换CAS。</p><p>业务范围调整造成了两个影响：</p><ul><li>不需要多系统账号合并</li><li>业务范围调整的时候，账户服务根据之前的逻辑已经开发完成</li></ul><p>这就引入了另一个问题，虽然最复杂的多系统账户合并不要了，但很多的功能点在CAS替换与多系统统一替换中基本都是一样的（由于需要合并多个系统间的账户数据，而多个系统目前的账户数据又是千奇百怪，所以根据账户数据来源的不同，分别存储在不同的表中，所以对于账户数据的操作这部分需要再次开发）。简单的CTRL+C CTRL+V再复制一份，再在公共部分加一些if else？还是通过别的方式实现？</p><p>主要的重复点在：</p><ul><li>账户绑定手机号</li><li>账户登录</li><li>账户密码通过手机号重置</li><li>发送短信验证码</li></ul><p>基本上都是输入一样，但最终处理的时候校验、操作的表都有所不同，这个可以通过命令模式来处理。</p><p>将统一账户的处理逻辑、CAS账户的处理逻辑分别放置到Receiver中，通过不同的Command来起到隔离而又不会重复代码的作用。</p><blockquote><p>命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。</p></blockquote><h2 id="二期">二期</h2><p>对接之前未对接的Y、E系统，这时E系统已经合并到Y系统了，所以这时只需要对接Y系统就好。</p><p>对接Y系统主要是根据各种业务规则进行账号清洗、合并。</p><p><img data-src="/images/customer-center-design/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97.png" alt="数据清洗"></p><h1>其它</h1><h2 id="短信发送">短信发送</h2><p>1、线程池发送（以防短信服务不稳，造成OOM,设定BlockingQueue长度）<br>2、抽象短信服务基类BaseVerificationCodeSender，因为有可能对接多个短信服务，但线程池及需要做的事是一样的。</p><p><img data-src="/images/customer-center-design/CocSmsVerificationCodeSender.png" alt="具体的实现类"></p><h2 id="验证码校验">验证码校验</h2><p>由于集团短信服务不太稳定，所以每类（登陆、忘记密码、修改手机号等）验证码缓存最多三个未过期的短信验证码。</p><blockquote><p>只要验证了一个，该手机号缓存某类的验证码，均失效。</p></blockquote><h2 id="其它">其它</h2><p>略</p><h1>附录</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+--------+                               +---------------+</span><br><span class="line">|        |--(A)- Authorization Request -&gt;|   Resource    |</span><br><span class="line">|        |                               |     Owner     |</span><br><span class="line">|        |&lt;-(B)-- Authorization Grant ---|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(C)-- Authorization Grant --&gt;| Authorization |</span><br><span class="line">| Client |                               |     Server    |</span><br><span class="line">|        |&lt;-(D)----- Access Token -------|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(E)----- Access Token ------&gt;|    Resource   |</span><br><span class="line">|        |                               |     Server    |</span><br><span class="line">|        |&lt;-(F)--- Protected Resource ---|               |</span><br><span class="line">+--------+                               +---------------+</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>原创</tag>
        <tag>OAuth</tag>
        <tag>Login</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 知识点 概要</title>
    <url>/mysql-schema.html</url>
    <content><![CDATA[<blockquote><p>B+ Tree、索引、Explain、InnoDB、MyISAM、Sharding</p></blockquote><a id="more"></a><h1>一、索引</h1><h2 id="B-Tree-原理">B+ Tree 原理</h2><h3 id="1-数据结构">1. 数据结构</h3><p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p><p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。</p><p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 key<sub>i</sub> 和 key<sub>i+1</sub>，且不为 null，则该指针指向节点的所有 key 大于等于 key<sub>i</sub> 且小于等于 key<sub>i+1</sub>。</p><div align="center"><img data-src="/images/mysql-schema/33576849-9275-47bb-ada7-8ded5f5e7c73.png" width="350px"></div><br><h3 id="2-操作">2. 操作</h3><p>进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。</p><p>插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。</p><h3 id="3-与红黑树的比较">3. 与红黑树的比较</h3><p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：</p><p>（一）更少的查找次数</p><p>平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(log<sub>d</sub>N)，其中 d 为每个节点的出度。</p><p>红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。</p><p>（二）利用磁盘预读特性</p><p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。</p><p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。</p><h2 id="MySQL-索引">MySQL 索引</h2><p>索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。</p><h3 id="1-B-Tree-索引">1. B+Tree 索引</h3><p>是大多数 MySQL 存储引擎的默认索引类型。</p><p>因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。</p><p>因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。</p><p>可以指定多个列作为索引列，多个索引列共同组成键。</p><p>适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。</p><p>InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。</p><div align="center"><img data-src="/images/mysql-schema/45016e98-6879-4709-8569-262b2d6d60b9.png" width="350px"></div><br><p>辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。</p><div align="center"><img data-src="/images/mysql-schema/7c349b91-050b-4d72-a7f8-ec86320307ea.png" width="350px"></div><br><h3 id="2-哈希索引">2. 哈希索引</h3><p>哈希索引能以 O(1) 时间进行查找，但是失去了有序性：</p><ul><li>无法用于排序与分组；</li><li>只支持精确查找，无法用于部分查找和范围查找。</li></ul><p>InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。</p><h3 id="3-全文索引">3. 全文索引</h3><p>MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。</p><p>查找条件使用 MATCH AGAINST，而不是普通的 WHERE。</p><p>全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。</p><p>InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。</p><h3 id="4-空间数据索引">4. 空间数据索引</h3><p>MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。</p><p>必须使用 GIS 相关的函数来维护数据。</p><h2 id="索引优化">索引优化</h2><h3 id="1-独立的列">1. 独立的列</h3><p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。</p><p>例如下面的查询不能使用 actor_id 列的索引：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> actor_id <span class="keyword">FROM</span> sakila.actor <span class="keyword">WHERE</span> actor_id + <span class="number">1</span> = <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h3 id="2-多列索引">2. 多列索引</h3><p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> film_id, actor_ <span class="keyword">id</span> <span class="keyword">FROM</span> sakila.film_actor</span><br><span class="line"><span class="keyword">WHERE</span> actor_id = <span class="number">1</span> <span class="keyword">AND</span> film_id = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h3 id="3-索引列的顺序">3. 索引列的顺序</h3><p>让选择性最强的索引列放在前面。</p><p>索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。</p><p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> staff_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> staff_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> customer_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> payment;</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">   staff_id_selectivity: 0.0001</span><br><span class="line">customer_id_selectivity: 0.0373</span><br><span class="line">               COUNT(*): 16049</span><br></pre></td></tr></table></figure><h3 id="4-前缀索引">4. 前缀索引</h3><p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。</p><p>前缀长度的选取需要根据索引选择性来确定。</p><h3 id="5-覆盖索引">5. 覆盖索引</h3><p>索引包含所有需要查询的字段的值。</p><p>具有以下优点：</p><ul><li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。</li><li>一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。</li><li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。</li></ul><h2 id="索引的优点">索引的优点</h2><ul><li><p>大大减少了服务器需要扫描的数据行数。</p></li><li><p>帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。</p></li><li><p>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。</p></li></ul><h2 id="索引的使用条件">索引的使用条件</h2><ul><li><p>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；</p></li><li><p>对于中到大型的表，索引就非常有效；</p></li><li><p>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</p></li></ul><h1>二、查询性能优化</h1><h2 id="使用-Explain-进行分析">使用 Explain 进行分析</h2><p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。</p><p>比较重要的字段有：</p><ul><li>select_type : 查询类型，有简单查询、联合查询、子查询等</li><li>key : 使用的索引</li><li>rows : 扫描的行数</li></ul><h2 id="优化数据访问">优化数据访问</h2><h3 id="1-减少请求的数据量">1. 减少请求的数据量</h3><ul><li>只返回必要的列：最好不要使用 SELECT * 语句。</li><li>只返回必要的行：使用 LIMIT 语句来限制返回的数据。</li><li>缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。</li></ul><h3 id="2-减少服务器端扫描的行数">2. 减少服务器端扫描的行数</h3><p>最有效的方式是使用索引来覆盖查询。</p><h2 id="重构查询方式">重构查询方式</h2><h3 id="1-切分大查询">1. 切分大查询</h3><p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> messages <span class="keyword">WHERE</span> <span class="keyword">create</span> &lt; <span class="keyword">DATE_SUB</span>(<span class="keyword">NOW</span>(), <span class="built_in">INTERVAL</span> <span class="number">3</span> <span class="keyword">MONTH</span>);</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">rows_affected = 0</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    rows_affected = do_query(</span><br><span class="line">    <span class="string">"DELETE FROM messages WHERE create  &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000"</span>)</span><br><span class="line">&#125; <span class="keyword">while</span> rows_affected &gt; <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="2-分解大连接查询">2. 分解大连接查询</h3><p>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：</p><ul><li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。</li><li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。</li><li>减少锁竞争；</li><li>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。</li><li>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag</span><br><span class="line"><span class="keyword">JOIN</span> tag_post <span class="keyword">ON</span> tag_post.tag_id=tag.id</span><br><span class="line"><span class="keyword">JOIN</span> post <span class="keyword">ON</span> tag_post.post_id=post.id</span><br><span class="line"><span class="keyword">WHERE</span> tag.tag=<span class="string">'mysql'</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag <span class="keyword">WHERE</span> tag=<span class="string">'mysql'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tag_post <span class="keyword">WHERE</span> tag_id=<span class="number">1234</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> post <span class="keyword">WHERE</span> post.id <span class="keyword">IN</span> (<span class="number">123</span>,<span class="number">456</span>,<span class="number">567</span>,<span class="number">9098</span>,<span class="number">8904</span>);</span><br></pre></td></tr></table></figure><h1>三、存储引擎</h1><h2 id="InnoDB">InnoDB</h2><p>是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。</p><p>实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。</p><p>主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。</p><p>内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。</p><p>支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。</p><h2 id="MyISAM">MyISAM</h2><p>设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。</p><p>提供了大量的特性，包括压缩表、空间数据索引等。</p><p>不支持事务。</p><p>不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。</p><p>可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。</p><p>如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。</p><h2 id="比较">比较</h2><ul><li><p>事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。</p></li><li><p>并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。</p></li><li><p>外键：InnoDB 支持外键。</p></li><li><p>备份：InnoDB 支持在线热备份。</p></li><li><p>崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。</p></li><li><p>其它特性：MyISAM 支持压缩表和空间数据索引。</p></li></ul><h1>四、数据类型</h1><h2 id="整型">整型</h2><p>TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。</p><p>INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。</p><h2 id="浮点数">浮点数</h2><p>FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。</p><p>FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。</p><h2 id="字符串">字符串</h2><p>主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。</p><p>VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。</p><p>在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。</p><h2 id="时间和日期">时间和日期</h2><p>MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。</p><h3 id="1-DATETIME">1. DATETIME</h3><p>能够保存从 1000 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。</p><p>它与时区无关。</p><p>默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATETIME 值，例如“2008-01-16 22<span>:</span>37<span>:</span>08”，这是 ANSI 标准定义的日期和时间表示方法。</p><h3 id="2-TIMESTAMP">2. TIMESTAMP</h3><p>和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。</p><p>它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。</p><p>MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。</p><p>默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。</p><p>应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。</p><h1>五、切分</h1><h2 id="水平切分">水平切分</h2><p>水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。</p><p>当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。</p><div align="center"><img data-src="/images/mysql-schema/63c2909f-0c5f-496f-9fe5-ee9176b31aba.jpg" width></div><br><h2 id="垂直切分">垂直切分</h2><p>垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。</p><p>在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。</p><div align="center"><img data-src="/images/mysql-schema/e130e5b8-b19a-4f1e-b860-223040525cf6.jpg" width></div><br><h2 id="Sharding-策略">Sharding 策略</h2><ul><li>哈希取模：hash(key) % N；</li><li>范围：可以是 ID 范围也可以是时间范围；</li><li>映射表：使用单独的一个数据库来存储映射关系。</li></ul><h2 id="Sharding-存在的问题">Sharding 存在的问题</h2><h3 id="1-事务问题">1. 事务问题</h3><p>使用分布式事务来解决，比如 XA 接口。</p><h3 id="2-连接">2. 连接</h3><p>可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。</p><h3 id="3-ID-唯一性">3. ID 唯一性</h3><ul><li>使用全局唯一 ID（GUID）</li><li>为每个分片指定一个 ID 范围</li><li>分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)</li></ul><h1>六、复制</h1><h2 id="主从复制">主从复制</h2><p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。</p><ul><li><strong>binlog 线程</strong> ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。</li><li><strong>I/O 线程</strong> ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。</li><li><strong>SQL 线程</strong> ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。</li></ul><div align="center"><img data-src="/images/mysql-schema/master-slave.png" width></div><br><h2 id="读写分离">读写分离</h2><p>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。</p><p>读写分离能提高性能的原因在于：</p><ul><li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；</li><li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；</li><li>增加冗余，提高可用性。</li></ul><p>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。</p><div align="center"><img data-src="/images/mysql-schema/master-slave-proxy.png" width></div><br><h1>参考资料</h1><ul><li>BaronScbwartz, PeterZaitsev, VadimTkacbenko, 等. 高性能 MySQL[M]. 电子工业出版社, 2013.</li><li>姜承尧. MySQL 技术内幕: InnoDB 存储引擎 [M]. 机械工业出版社, 2011.</li><li><a href="https://www.jfox.info/20-tiao-mysql-xing-nen-you-hua-de-zui-jia-jing-yan.html" target="_blank" rel="noopener">20+ 条 MySQL 性能优化的最佳经验</a></li><li><a href="http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/" title="服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策" target="_blank" rel="noopener">服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策</a></li><li><a href="https://stackoverflow.com/questions/788829/how-to-create-unique-row-id-in-sharded-databases" target="_blank" rel="noopener">How to create unique row ID in sharded databases?</a></li><li><a href="http://geekswithblogs.net/shaunxu/archive/2012/01/07/sql-azure-federation-ndash-introduction.aspx" title="Title of this entry." target="_blank" rel="noopener">SQL Azure Federation – Introduction</a></li><li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="noopener">MySQL 索引背后的数据结构及算法原理</a></li><li><a href="https://segmentfault.com/a/1190000008131735" target="_blank" rel="noopener">MySQL 性能优化神器 Explain 使用分析</a></li><li><a href="https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6" target="_blank" rel="noopener">How Sharding Works</a></li><li><a href="https://tech.meituan.com/dianping_order_db_sharding.html" target="_blank" rel="noopener">大众点评订单系统分库分表实践</a></li><li><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" target="_blank" rel="noopener">B + 树</a></li></ul><h1>原文</h1><p><a href="https://github.com/CyC2018/CS-Notes/blob/master/notes/MySQL.md#innodb" target="_blank" rel="noopener">https://github.com/CyC2018/CS-Notes/blob/master/notes/MySQL.md#innodb</a></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL UNION vs OR 性能</title>
    <url>/sql-performance-union-vs-or.html</url>
    <content><![CDATA[<p>本文整理自：stackoverflow<br>地址：<br><a href="https://stackoverflow.com/questions/13750475/sql-performance-union-vs-or" target="_blank" rel="noopener">https://stackoverflow.com/questions/13750475/sql-performance-union-vs-or</a></p><a id="more"></a><p>翻译自Bill Karwin回答：</p><p>要么你读的那篇文章用了一个不好的例子，要么你误解了他们的观点。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; or company = &apos;itv&apos;;</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select username from users where company IN (&apos;bbc&apos;, &apos;itv&apos;);</span><br></pre></td></tr></table></figure><p>在这个查询中MySQL会使用company上的索引。不需要改成UNION。</p><p>更棘手的情况是，OR条件涉及两个不同的列。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; or city = &apos;London&apos;;</span><br></pre></td></tr></table></figure><p>假设company列和city列都有一个独立的索引。MySQL通常在一个给定的查询中每个表只使用一个索引，那么应该使用哪个索引呢?如果它使用company上的索引，它仍然必须执行表扫描，以找到伦敦所在的行。如果它使用city上的索引，则必须对company为bbc的行进行表扫描。</p><p>UNION 解决方案适用于这种情况。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select username from users where company = &apos;bbc&apos; </span><br><span class="line">union</span><br><span class="line">select username from users where city = &apos;London&apos;;</span><br></pre></td></tr></table></figure><p>这样的话每个子查询都可以使用索引进行搜索,然后再将子查询的结果合并在一起。</p><blockquote><p>union ? union all ? 取决于需求及where过滤后的数据量<br>对于索引列来最好使用union all，因复杂的查询【包含运算等】将使or、in放弃索引而全表扫描，除非你能确定or、in会使用索引。<br>对于只有非索引字段来说你就老老实实的用or或者in，因为 非索引字段本来要全表扫描而union all 只成倍增加表扫描的次数。</p></blockquote>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>原创</tag>
        <tag>UNION</tag>
        <tag>OR</tag>
      </tags>
  </entry>
  <entry>
    <title>时间量级</title>
    <url>/time-scales.html</url>
    <content><![CDATA[<p>本文整理自：《性能之巅》<br>作者：【美】 Brendan Gregg<br>英文版出版时间：2014年</p><a id="more"></a><p>我们可以用数字来作为时间的比较方法,同时可以用时间的长短经验来判断延时的源头。系统各组件的操作所处的时间量级差别巨大,大到了难以体会的地步。表2.2提供的延时示例,从访问3.3GHz的CPU寄存器的延时开始,阐释了我们所打交道的时间量级的差别,表中是发生单次操作的时间均值,等比放大成为想象的系统,一次寄存器访问0.3ns(十亿分之一秒的三分之一)相当于现实生活中的1秒。</p><center>表2.2 系统的各种延时</center><table><thead><tr><th>事件</th><th>延时</th><th>相对时间比例</th></tr></thead><tbody><tr><td>1个CPU周期</td><td>0.3ns</td><td>1s</td></tr><tr><td>L1缓存访问</td><td>0.9ns</td><td>3s</td></tr><tr><td>L2缓存访问</td><td>2.8ns</td><td>9s</td></tr><tr><td>L3缓存访问</td><td>12.9ns</td><td>43s</td></tr><tr><td>主存访问(从CPU访问DRAM)</td><td>120ns</td><td>6分钟</td></tr><tr><td>固态硬盘I/O(闪存)</td><td>50-150us</td><td>2-6天</td></tr><tr><td>旋转磁盘I/O</td><td>1-10 ms</td><td>1-12月</td></tr><tr><td>互联网:从旧金山到纽约</td><td>40 ms</td><td>4年</td></tr><tr><td>互联网:从旧金山到英国</td><td>81 ms</td><td>8年</td></tr><tr><td>互联网:从旧金山到澳大利亚</td><td>183ms</td><td>19年</td></tr><tr><td>TCP包重传</td><td>1-3s</td><td>105-317年</td></tr><tr><td>OS虚拟化系统重启</td><td>4s</td><td>423年</td></tr><tr><td>SCSI命令超时</td><td>30s</td><td>3千年</td></tr><tr><td>硬件虚拟化系统重启</td><td>40s</td><td>4千年</td></tr><tr><td>物理系统重启</td><td>5m</td><td>32千年</td></tr></tbody></table><blockquote><p>这个表需要时刻记在心中。</p></blockquote>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]ZGC: 未使用堆内存归还操作系统</title>
    <url>/zgc-uncommit-unused-memory.html</url>
    <content><![CDATA[<blockquote><p>翻译自：JEP 351<br>地址：<a href="https://openjdk.java.net/jeps/351" target="_blank" rel="noopener">https://openjdk.java.net/jeps/351</a></p></blockquote><a id="more"></a><h1>一、摘要</h1><p>增强ZGC，将未使用的堆内存返回给操作系统。</p><h1>二、动机</h1><p>目前ZGC不会将未使用的内存归还给操作系统，即使该内存已经很长时间没有使用了。这种行为并不适合所有类型的应用程序和环境，特别是那些需要考虑内存占用的应用程序和环境。例如：</p><ul><li>按资源使用付费的容器环境。</li><li>应用程序可能长时间处于空闲状态并与许多其他应用程序共享或竞争资源的环境。</li><li>应用程序在执行期间可能有非常不同的堆空间需求。例如，启动期间所需的堆可能大于稍后在稳定状态执行期间所需的堆。</li></ul><p>HotSpot中的其他垃圾收集器(如G1和Shenandoah)已经提供了这种功能，该功能对于一些用户非常有用。将此功能添加到ZGC将受到这些用户的欢迎。</p><h1>三、描述</h1><p>ZGC堆由一组称为ZPages的堆区域组成。每个Zpage与数量可变的已提交内存相关联。当ZGC压缩堆时，ZPages被释放并插入到页面缓存ZPageCache中。页面缓存中的ZPages可以重用，以满足新的堆分配，在这种情况下，它们将从缓存中删除。页面缓存对性能至关重要，因为提交和不提交内存都是昂贵的操作。</p><p>页面缓存中的ZPages集合表示堆中未使用的部分，这些部分可以归还给操作系统。因此，取消提交内存可以通过简单地从页面缓存中删除一组精心选择的ZPages，并取消与这些页面关联的内存的提交来完成。页面缓存已经将ZPages保持在最近最少使用(LRU)的顺序，并按大小(小、中、大)进行分隔，因此清除ZPages和取消提交内存的机制相对简单。挑战在于设计策略来决定何时从缓存中驱逐ZPage。</p><p><font color="DeepPink"><strong>一个简单的策略是设置一个timeout或delay值，该值指定ZPage在被清除之前可以在页面缓存中驻留多长时间。这个超时将有一些合理的默认值，可以使用命令行选项覆盖它。Shenandoah GC使用这样的策略，默认值为5分钟，命令行选项-XX:ShenandoahUncommitDelay=&lt;milliseconds&gt;来覆盖默认值。</strong></font></p><p><font color="DeepPink"><strong>类似上述策略的效果可能相当不错。然而，人们也可以设想更复杂的策略，不涉及添加新的命令行选项。例如，根据GC频率或其他数据找到合适超时值的启发式方法。我们将首先提供一个简单的超时策略，使用-XX:ZUncommitDelay=&lt;seconds&gt;选项，稍后再提供一个更复杂的策略(如果找到了)。</strong></font></p><p><font color="DeepPink"><strong>默认情况下将启用uncommit功能。但是无论策略如何决定，ZGC都不能把堆内存降到低于Xms。这就意味着，如果Xmx和Xms相等的话，这个能力就失效了，-XX:-ZUncommit这个参数也能让这个内存管理能力失效。</strong></font></p><p>最后，Linux/x64上的ZGC使用tmpfs或hugetlbfs文件来支持堆。这些文件使用的未提交内存需要fallocate(2)和FALLOC_FL_PUNCH_HOLE支持，FALLOC_FL_PUNCH_HOLE支持最早出现在Linux 3.5 (tmpfs)和4.3(hugetlbfs)中。在旧的Linux内核上运行时，ZGC应该像以前一样继续工作，但是禁用了uncommit功能。</p><blockquote><p>Java 越来越云原生了，下一个期盼就是fiber了。</p></blockquote>]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>JVM</tag>
        <tag>ZGC</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]如何用Linux命令行管理网络：11个你必须知道的命令</title>
    <url>/how-to-work-with-network-from-linux-terminal.html</url>
    <content><![CDATA[<blockquote><p>如何用Linux命令行管理网络：11个你必须知道的命令</p></blockquote><a id="more"></a><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/network-commands-header.png" alt="网络命令"></p><p>无论你是要下载文件、诊断网络问题、管理网络接口，还是查看网络的统计数据，都有终端命令可以来完成。这篇文章收集了久经考验靠谱的命令，也收集了几个比较新的命令。</p><p>多数命令都可以在图形桌面执行，即使是没什么终端使用经验的<code>Linux</code>用户也会常常执行命令来使用<code>ping</code>或是其它的网络诊断工具。</p><h2 id="curl-wget"><code>curl</code> &amp; <code>wget</code></h2><p>使用<code>curl</code>或<code>wget</code>命令，不用离开终端就可以下载文件。如你用<code>curl</code>，键入<code>curl -O</code>后面跟一个文件路径。<code>wget</code>则不需要任何选项。下载的文件在当前目录。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -O website.com/file</span><br><span class="line">wget website.com/file</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/curl.png" alt="curl"></p><h2 id="ping"><code>ping</code></h2><p><code>ping</code>发送<code>ECHO_REQUEST</code>包到你指定的地址。这样你可以很方便确认你的电脑和<code>Internet</code>或是一个指定的<code>IP</code>地址是不是通的。使用<code>-c</code>开关，可以指定发送<code>ECHO_REQUEST</code>包的个数。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ping -c 4 google.com</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/ping.png" alt="ping"></p><h2 id="tracepath-traceroute"><code>tracepath</code> &amp; <code>traceroute</code></h2><p><code>tracepath</code>命令和<code>traceroute</code>命令功能类似，但不需要<code>root</code>权限。并且<code>Ubuntu</code>预装了这个命令，<code>traceroute</code>命令没有预装的。<code>tracepath</code>追踪出到指定的目的地址的网络路径，并给出在路径上的每一跳（<code>hop</code>）。如果你的网络有问题或是慢了，<code>tracepath</code>可以查出网络在哪里断了或是慢了。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tracepath example.com</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/tracepath.png" alt="tracepath"></p><h2 id="mtr"><code>mtr</code></h2><p><code>mtr</code>命令把<code>ping</code>命令和<code>tracepath</code>命令合成了一个。<code>mtr</code>会持续发包，并显示每一跳ping所用的时间。也会显示过程中的任何问题，在下面的示例中，可以看到在第6跳丢了超过20%的包。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mtr howtogeek.com</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/mtr.png" alt="mtr"></p><p>键入<code>q</code>或是<code>CTRL + C</code>来退出命令。</p><h2 id="host"><code>host</code></h2><p><code>host</code>命令用来做<code>DNS</code>查询。如果命令参数是域名，命令会输出关联的<code>IP</code>；如果命令参数是<code>IP</code>，命令则输出关联的域名。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">host howtogeek.com</span><br><span class="line">host 208.43.115.82</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/host.png" alt="host"></p><h2 id="whois"><code>whois</code></h2><p><code>whois</code>命令输出指定站点的<code>whois</code>记录，可以查看到更多如谁注册和持有这个站点这样的信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">whois example.com</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/whois.png" alt="whois"></p><h2 id="ifplugstatus"><code>ifplugstatus</code></h2><p><code>ifplugstatus</code>命令可以告诉你是否有网线插到在网络接口上。这个命令<code>Ubuntu</code>没有预装，通过下面的命令来安装：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install ifplugd</span><br></pre></td></tr></table></figure><p>这个命令可以查看所有网络接口的状态，或是指定网络接口的状态：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifplugstatus</span><br><span class="line">ifplugstatus eth0</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/ifplugstatus.png" alt="ifplugstatus"></p><p>命令输出『<code>Link beat detected</code>』（检测到连接心跳）表示有网线插着，如没有则会输出『<code>unplugged</code>』（未插入）。</p><h2 id="ifconfig"><code>ifconfig</code></h2><p><code>ifconfig</code>用于输出网络接口配置、调优和Debug的各种选项。可以快捷地查看<code>IP</code>地址和其它网络接口的信息。键入<code>ifconfig</code>查看所有启用的网络接口的状态，包括它们的名字。可以指定网络接口的名字来只显示这一个接口的信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br><span class="line">ifconfig eth0</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/ifconfig.png" alt="ifconfig"></p><h2 id="ifdown-ifup"><code>ifdown</code> &amp; <code>ifup</code></h2><p><code>ifdown</code>和<code>ifup</code>命令和运行<code>ifconfig up</code>，<code>ifconfig down</code>的功能一样。给定网络接口的名字可以只禁用或启用这一个接口。需要<code>root</code>权限，所以在<code>Ubuntu</code>上需要使用<code>sudo</code>来运行。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ifdown eth0</span><br><span class="line">sudo ifup eth0</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/ifdown-ifup.png" alt="ifdown &amp; ifup"></p><p>在<code>Linux</code>桌面系统上运行这2个命令，很可能会输出出错信息。<code>Linux</code>桌面通过使用网络管理器（<code>NetworkManager</code>）来管理你的网络接口。不过在没有安装网络管理器的服务器版上，这2个命令仍然可用。</p><p>如果确实要在命令行上配置网络管理器，用<code>nmcli</code>命令。</p><h2 id="dhclient"><code>dhclient</code></h2><p><code>dhclient</code>命令可以释放你的电脑的<code>IP</code>地址并从<code>DHCP</code>服务器上获得一个新的。需要<code>root</code>权限，所以在<code>Ubuntu</code>上需要<code>sudo</code>。无选项运行命令获取新<code>IP</code>，或指定<code>-r</code>开关来释放当前的<code>IP</code>地址。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dhclient -r</span><br><span class="line">sudo dhclient</span><br></pre></td></tr></table></figure><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/dhclient.png" alt="dhclient"></p><h2 id="netstat"><code>netstat</code></h2><p><code>netstat</code>命令可以显示网络接口的很多统计信息，包括打开的<code>socket</code>和路由表。无选项运行命令显示打开的<code>socket</code>。</p><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/netstat.png" alt="netstat"></p><p>这条命令还有很多功能。比如，<code>netstat -p</code>命令可以显示打开的<code>socket</code>对应的程序。</p><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/netstat-p.png" alt="netstat -p"></p><p><code>netstat -s</code>则显示所有端口的详细统计信息。</p><p><img data-src="/images/how-to-work-with-network-from-linux-terminal/netstat-s.png" alt="netstat -s"></p><h2 id="原文"><code>原文</code></h2><p><a href="https://github.com/oldratlee/translations/blob/master/how-to-work-with-network-from-linux-terminal/README.md" target="_blank" rel="noopener">https://github.com/oldratlee/translations/blob/master/how-to-work-with-network-from-linux-terminal/README.md</a></p>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收算法手册：自动内存管理的艺术 笔记</title>
    <url>/the-garbage-collection-handbook-the-art-of-automatic-memory-management.html</url>
    <content><![CDATA[<p>本文整理自：《垃圾回收算法手册：自动内存管理的艺术》<br>作者：Richard Jones、Antony Hosking、Eliot Moss</p><a id="more"></a><h1>引言</h1><p>几乎所有的现代编程语言都使用动态内存分配(allocation),即允许进程在运行时分配或者释放无法在编译期确定大小的对象,且允许对象的存活时间超出创建这些对象的子程序时间。<font color="DeepPink"><strong>动态分配的对象存在于堆(heap)中而非栈(stack)或者静态区(statically)中。所谓栈,即程序的活动记录(activation record)或者栈帧(stack frame);静态区则是指在编译期或者链接期就可以确定范围的存储区域。</strong></font>堆分配是十分重要的功能,它允许开发者:</p><ul><li>在运行时动态地确定新创建对象的大小(从而避免程序在运行时遭遇硬编码数组长度不足产生的失败)。</li><li>定义和使用具有递归特征的数据结构,例如链表(list)、树(tree)和映射(map)。</li><li>向父过程返回新创建的对象,例如工厂方法。</li><li>将一个函数作为另一个函数的返回值,例如函数式语言中的闭包(closure)或者悬挂(suspension)。</li></ul><p>在不支持自动化动态内存管理的语言中,众多研究者已经付出了相当大的努力来解决这一难题,其方法主要是管理对象的所有权(ownership)[Belotsky,2003; Cline, Lomo,1995]。Belotsky[2003]等人针对C++提出了几个可行策略:</p><ul><li>第一,开发者在任何情况下都应当避免堆分配,例如可以将对象分配在栈上,当创建对象的函数返回之后,栈的弹出(pop)操作会自动将对象释放。</li><li>第二,在传递参数与返回值时,应尽量传值而非引用。尽管这些方法避免了分配、释放错误,但其不仅会造成内存方面的压力,而且失去了对象共享的能力。</li></ul><p>另外,开发者也可以在一些特殊场景下使用自定义内存分配器,例如对象池(pool of object),在程序的一个阶段完成之后,池中的对象将作为一个整体全部释放。</p><h2 id="垃圾算法之间的比较">垃圾算法之间的比较</h2><h3 id="安全性">安全性</h3><p>垃圾回收器首先要考虑的因素是安全性(safety),即在任何时候都不能回收存活对象。但安全性是需要付出一定代价的,特别是在并发回收器中。</p><h3 id="吞吐量">吞吐量</h3><p>对程序的最终用户而言,程序当然是运行得越快越好,但这是由几方面因素决定的。其中的一方面便是花费在垃圾回收上的时间应当越少越好,文献中通常用标记/构造率(mark/cons ratio)衡量这一指标。这一概念是在早期的Lisp语言中最先提出的,它表示回收器(对存活对象进行标记)与赋值器(mutator)(创建或者构造新的链表单元)活跃度的比值。然而<font color="DeepPink"><strong>在大多数设计良好的架构中,赋值器会比回收器占用更多的CPU时间,因此在适当牺牲回收器效率的基础上提升赋值器的吞吐量,并进一步提升整个程序(赋值器+回收器)的执行速度,一般来说是值得的。</strong></font>例如,使用标记一清扫回收的系统偶尔会执行存活对象整理以减少内存碎片,虽然这一操作开销较大,但它可以提升赋值器的分配性能。</p><h3 id="完整性与及时性">完整性与及时性</h3><p>理想情况下,垃圾回收过程应当是完整的,即堆中的所有垃圾最终都应当得到回收,但这通常是不现实的,甚至是不可取的,例如纯粹的引用计数回收器便无法回收环状引用垃圾(自引用结构)。从性能方面考虑,在一次回收过程(collection cycle)中只处理堆中部分对象或许更加合理,例如分代回收器会依照堆中对象的年龄将其划分为两代或者更多代,并把回收的主要精力集中在年轻代,这样不仅可以提高回收效率,而且可以减少单次回收的平均停顿时间(pause time)。</p><p><font color="DeepPink"><strong>在并发垃圾回收器中,赋值器与回收器同时工作,其目的在于避免或者尽量减少用户程序的停顿。此类回收器会遇到浮动垃圾(floating garbage)问题,即如果某个对象在回收过程启动之后才变成垃圾,那么该对象只能在下一个回收周期内得到回收。因此在并发回收器中,衡量完整性更好的方法是统计所有垃圾的最终回收情况,而不是单个回收周期的回收情况。不同的回收算法在回收及时性(promptness)方面存在较大差异,进而需要在时间和空间上进行权衡。</strong></font></p><h3 id="停顿时间">停顿时间</h3><p>许多回收器在进行垃圾回收时需要中断赋值器线程,因此会导致在程序执行过程中出现停顿。回收器应当尽量减少对程序主要执行过程的影响,因此要求停顿时间越短越好,这点对于交互式程序或者事务处理服务器(超时将引发事务的重试,进而导致事务的积压)尤为重要。但正如我们在后面章节中将要看到的,限制停顿时间会带来一些副作用。例如,分代式回收器通过频繁且快速地回收较小的、较为年轻的对象来缩短停顿时间,而对较大的、较为年老对象的回收则只是偶尔进行。<font color="DeepPink"><strong>显然,在对分代回收器进行调优时,需要平衡不同分代的大小,进而才能平衡不同分代之间的停顿时间与回收频率。</strong></font>但由于分代回收器必须记录些分代间指针的来源,因此赋值器的指针写操作会存在少量的额外开销。</p><p>并行回收器(parallel collector)虽然也需要停顿整个程序,但它可以通过多线程回收的策略缩短停顿时间。为进一步减少停顿时间,<font color="DeepPink"><strong>并发回收器与增量回收器(incremental collector)偶尔会将部分回收工作与赋值器动作交替进行或者同时进行,但这一过程需要确保赋值器与回收器之间的同步,因而增大了赋值器的额外开销。</strong></font>回收机制的选择会影响程序在空间和时间两个方面的开销,也会影响垃圾回收周期的结束。<font color="DeepPink"><strong>赋值器在时间方面的额外开销取决于需要记录的赋值器操作类型(读或者写)及其如何记录。回收器在空间方面的开销以及回收周期的结束取决于系统可以容忍的浮动垃圾数量。</strong></font>多线程赋值器与回收器会增大设计复杂度。不论如何,缩短停顿时间的措施通常会增大整体处理时间(即降低整体处理速度)。</p><p>仅对最大或者平均停顿时间进行度量是不够的,必须要同时考虑赋值器的性能,因此停顿时间的分布也值得关注。</p><h3 id="空间开销">空间开销</h3><p>内存管理的目的是安全且高效地使用内存空间。不论是显式内存管理还是自动内存管理,不同的管理策略均会产生不同程度的空间开销(space overhead)。某些垃圾回收器需要在每个对象内部占用一定的空间(例如保存引用计数),还有一些回收器会复用对象现有布局上已经存在的域(例如将标记位放在对象头部的某个字中,或者将转发指针(forwarding pointer)记录在用户数据上)。回收器也可能会引入堆级别的空间开销,例如复制式回收器需要将堆分为两个半区,任何时候赋值器只能使用一个半区,另一个半区会被回收器保留,并在回收过程中将存活对象复制到其中。<font color="DeepPink"><strong>回收器也可能需要一些辅助的数据结构,例如追踪式回收器需要通过标记栈来引导堆中指针图表的遍历,回收器在标记对象时也可以使用额外的位图(bitmap)而非对象中的域;对于并发回收器或者其他需要将堆划分为数个独立区域的回收器,其需要额外的记忆集(remembered set)来保存赋值器所修改的指针值或者跨区域指针的位置。</strong></font></p><h3 id="针对特定语言的优化">针对特定语言的优化</h3><p>垃圾回收算法可以根据它们所服务的不同语言范式来归类。在函数式语言中,内存管理有着很大的优化空间。某些语言(例如ML)将可变数据与不可变数据进行区分,纯函数式语言(例如Haskell)则更为极端,它不允许用户改变任何数据,即程序是透明引用(referentially transparent)的。然而,在函数式语言内部,数据结构的更新一般不超过一次,即从待计算值(thunk)到一个弱头部范式(weak head normal form,WHNF),分代垃圾回收器可以据此尽快提升已经完成计算的数据结构。研究者们还提出了基于引用计数来处理环状数据结构的完整机制。声明式语言(declarative language)或许还可以使用其他策略来提升堆空间管理的效率,即如果某一对象创建于一个“选择点”(choice point)之后,那么当程序再次回到该选择点时,该对象将不可达,如果对象在堆中的布局是按照其分配时间排布的,那么某个选择点之后分配的内存可以在一个固定的时间内全部回收。不同种类的语言可能对回收器具有不同的要求,最显著的差异是语言中指针功能的不同,以及回收器调用对象终结的需求不同。</p><blockquote><p>所谓透明引用,即以相同的参数调用同一个函数两次,所得到的结果总是相同的,也可理解为函数没有副作用。<br>thunk和WHNF均为函数式语言中的与懒情计算相关的概念。</p></blockquote><h3 id="可扩展性与可移植性">可扩展性与可移植性</h3><p>可扩展性(scalability)与可移植性(portability)是我们定义的最后两个指标。随着PC,甚至笔记本计算机中(且不说大型服务器)多核硬件的普及,借助硬件的并行优势来提升垃圾回收的性能将变得越来越重要。我们期待并行硬件在规模上(内核与套接字数量上)能有进一步发展,也希望异构处理器(heterogeneous processer)越来越普遍。在服务器方面,堆的大小可以达到数十甚至数百吉字节,事务型负载也越来越多,这些都给垃圾回收带来更多的要求。很多垃圾回收算法需要操作系统或者硬件的支持(例如需要依赖页保护机制,需要对虚拟内存空间进行二次映射,或者要求处理器能够提供特定的原子操作),但这些技术并不需要很强的可移植性。</p><h2 id="性能上的劣势">性能上的劣势</h2><p>与显式内存管理相比,自动内存管理是否存在性能上的劣势?我们将通过对这一问题的分析,来对两者的优劣进行总结。一般来说,自动内存管理的运行开销很大程度上取决于程序的行为,甚至硬件条件,因而很难对其进行简单评估。一个长期以来的观点是,垃圾回收通常会在总内存吞吐量以及垃圾回收停顿时间方面引人一些不可接受的开销,从而导致应用程序的执行速度慢于显式内存管理策略。自动内存管理确实会牺牲程序的部分性能,但是远不如想象中那样严重。诸如ma1loc和free等显式内存操作也会带来一些显著开销。Herts, Feng, Herger[2005测量了多种Java基准测试程序和回收算法花费在垃圾回收上的真正开销。他们构建了一个Java虚拟机并用其精确地观察到对象何时不可达,同时使用可达追踪的方法驱动模拟器来测量回收周期与高速缓存不命中(cache miss)的情况。他们将许多不同种类的垃圾回收器配置与各种不同的ma1lo/free实现进行比较,比较的方法是:如果追踪发现某一对象变成垃圾,则调用free将其释放。 Herts等人发现,尽管用这两种方式的测量结果差异较大,但是<font color="DeepPink"><strong>如果堆足够大(达到所需最小空间的5倍),那么垃圾回收器的执行时间性能将可以与显式分配相匹敌,但对于一般大小的堆,垃圾回收的开销会平均增大17%。</strong></font></p><h2 id="实验方法">实验方法</h2><p>内存管理涉及时间和空间两方面的权衡。<font color="DeepPink"><strong>大多数环境下,降低回收停顿时间的一种方法是增大堆的空间(增大到一定程度后将达到最优,但如果再增大,则由于局部性原理,执行时间将会变长)。</strong></font></p><h2 id="术语和符号">术语和符号</h2><p>首先需要说明的是存储的单位。我们遵循一个字节包含八个位这一惯例。我们简单地使用KB(kilobyte)、MB(megabyte)、GB(gigabyte)、TB(terabyte)来描述对应的2的整数次幂内存单元(分别是20、20、20、20),而不使用SI数字前缀的标准定义。</p><h3 id="赋值器与回收器">赋值器与回收器</h3><p>对于使用垃圾回收的程序, Dijkstra等[1976、1978]将其执行过程划分为两个半独立的部分:</p><ul><li>赋值器执行应用代码。这一过程会分配新的对象,并且修改对象之间的引用关系,进而改变堆中对象图的拓扑结构,引用域可能是堆中对象,也可能是根,例如静态变量、线程栈等。随着引用关系的不断变更,部分对象会失去与根的联系,即从根出发沿着对象图的任何一条边进行遍历都无法到达该对象。</li><li>回收器(collector)执行垃圾回收代码,即找到不可达对象并将其回收。</li></ul><p>一个程序可能拥有多个赋值器线程,但是它们共用同一个堆。相应的,也可能存在多个回收器线程。</p><h3 id="分配器">分配器</h3><p>分配器(allocator)与回收器在功能上是正交关系。分配器支持两种操作:分配(allocate)和释放(free)。分配是为某一对象保留底层的内存存储,释放是将内存归还给分配器以便复用。分配存储空间的大小是由一个可选参数来控制的,如果我们在伪代码中忽略这一参数,意味着分配器将返回一个固定大小的对象,或者对象大小对于算法的理解并非必要。分配操作也可能支持更多参数,例如将数组的分配与单个对象的分配进行区分,或者将指针数组的分配和不包含指针的数组进行区分,或者包含其他一些必要信息以便初始化对象头部。</p><h1>标记-清扫回收</h1><p>标记一清扫算法是一种间接回收(indirect collection)算法,它并非直接检测垃圾本身而是先确定所有存活对象,然后反过来判定其他对象都是垃圾。需要注意的是,该算法的每次调用都需要重新计算存活对象集合,但并非所有的垃圾回收算法都需要如此。</p><h2 id="三色抽象">三色抽象</h2><p>三色抽象(tricolour abstraction)[Dijkstra等,1976,1978]可以简洁地描述回收过程中对象状态的变化(是否已被标记、是否在工作列表中等)。三色抽象是描述追踪式回收器的种十分有用的方法,利用它可以推演回收器的正确性,这正是回收器必须保证的。<font color="DeepPink"><strong>在三色抽象中,回收器将对象图划分为黑色对象(确定存活)和白色对象(可能死亡)。任意对象在初始状态下均为白色,当回收器初次扫描到某一对象时将其着为灰色,当完成该对象的扫描并找到其所有子节点之后,回收器会将其着为黑色。从概念上讲,黑色意味着已经被回收器处理过,灰色意味着已经被回收器遍历但尚未完成处理(或者需要再次进行处理)。</strong></font>三色抽象也可以推广到对象的域中:灰色表示正在处理的域,黑色表示已经处理过的域。如果把赋值器也当作一个对象,则三色抽象也可用于推演赋值器根集合的状态变化[Pirinen,1998]灰色赋值器表示回收器尚未完成对其根集合的扫描,黑色赋值器表示回收器已经完成对其根集合的扫描(并且不需要再次扫描)。一次堆遍历过程可以形象地看作是回收器以灰色对象作为“波面”(wavefront),将黑色对象和白色对象分离,不断向前推进波面,直到所有可达对象都变成黑色的过程。</p><p>上述算法中存在一个重要的不变式:<font color="DeepPink"><strong>在标记过程完成后,对象图中将不可能存在从黑色对象指向白色对象的引用,因此在标记过程中,所有白色可达对象都只能是从灰色对象可达。如果这一不变式被打破,那么回收器将不会进一步处理黑色对象,从而可能导致某个黑色对象的后代可达但未被标记(进而被错误地释放)。</strong></font></p><h2 id="改进的标记-清扫算法">改进的标记-清扫算法</h2><p>程序的性能通常与其高速缓存的相关行为有很大关系。从内存中加载一个值可能要花费上百个时钟周期,但从L1高速缓存(L1 cache)中加载可能只需要花费三到四个时钟周期。高速缓存之所以能够提升程序的性能,主要是因为程序在运行时表现出了良好的时间局部性」(temporal locality),即一旦程序访问了某个内存地址,则很可能在不久之后再次访问该地址,因此值得将它的值缓存。程序也可能表现出良好的空间局部性(space locality),即一旦程序访问了某个内存地址,则很有可能在不久之后访问该地址附近的数据。<font color="DeepPink"><strong>现代硬件可以从两个方面利用程序的局部性特征:一方面,高速缓存与更低级别内存之间不会进行单个字节的数据传输,而是以一个固定的字节数为最小传输单元(即高速缓存行或者高速缓存块的大小),通常是32~128字节;另一方面,处理器可能会使用硬件预取(prefetch)技术,例如Intel Core微处理器架构可以探测到有规律的步进内存访问操作,进而提前读取数据流。</strong></font>开发者也可以利用显式预取指令引导预取过程。</p><h2 id="位图标记">位图标记</h2><p><font color="DeepPink"><strong>回收器可以将对象的标记位保存在其头部的某个字中,除此之外也可以使用一个独立的位图来维护标记位,即:位图中的每个位关联堆中每个可能分配对象的地址。位图所需的空间取决于虚拟机的字节对齐要求。</strong></font>位图可以只有一个,也可以存在多个,例如在块结构的堆中,回收器可以为每个内存块维护独立的位图,这一方式可以避免由于堆不连续导致的内存浪费。回收器可以将每个内存块的位图置于其自身内部,但如果所有内存块中位图的相对位置全部相同,则可能导致性能的下降,因为不同内存块的位图之间可能会争用相同的组相关高速缓存(set- associative cache)。对位图的访问同时也意味着对位图所在页的访问(即可能导致缺页异常——译者注),因此基于换页和高速缓存相关性的考虑,在访问位图时花费更多的指令以保持程序的局部性通常来说是值得的。为避免高速缓存的相关问题,可以将内存块中位图的位置增加一个简单偏移量,例如内存块地址的简单哈希值。还可以将位图存放在个额外的区域[Boehm and Weiser,1988年]中,并以其所对应内存块的哈希值等作为索引,这样既避免了换页问题,也避免了高速缓存冲突。</p><p>位图标记通常仅适用于单线程环境,因为多线程同时修改位图可能存在较大的写冲突风险。设置对象头部中的标记位通常是安全的,因为该操作是幂等的,即最多只会将标记位设置多次。相对于位图,实践中更常用的是字节图(byte-map),虽然它占用的空间是前者的8倍,但却解决了写冲突问题。另外还可以使用同步操作来设置位图中的位。<font color="DeepPink"><strong>在实际应用中,如果将标记位保存在对象头部通常会带来额外的复杂度,因为头部通常会存放一些赋值器共享数据,例如锁或者哈希值,那么当标记线程与赋值器线程并发执行时可能会产生冲突。</strong></font>因此,为了确保安全,标记位通常会占用头部中一个额外的字,以便与赋值器共享数据区分,当然也可以使用原子操作来设置头部中的标记位。</p><p>相对于将标记位放置在对象头部这一策略,位图可以使得标记位更加密集;对于使用位图的标记一清扫回收器,标记过程只需读取存活对象的指针域而不会修改任何对象;对于不包含引用的对象,回收器只需要读取其类型信息描述域;清扫器不会对存活对象进行任何读写操作,它只会在释放垃圾对象的过程中覆盖其某些域(例如将它们链接到空闲链表上)。因此,位图标记不仅可以减少内存中需要修改的字节数,而且减少了对高速缓存行的写入,进而减少需要写回内存的数据量。</p><p>位图标记最初应用在保守式回收器(conservative collector)中。保守式回收器的设计初衷是为C和C++等“不合作”的语言提供自动内存管理功能[Boehm and Weiser,1988]型精确(type-accurate)系统可以精确地识别每一个包含指针的槽,不论其位于对象中,是位于线程栈或者其他根集合中,而<font color="DeepPink"><strong>保守式回收器则无法得到编译器和运行时系统的支持因而其在识别指针时必须采用保守的判定方式,即:如果槽中某个值看起来像是指针引用,那么就必须假定它是一个指针。</strong></font>保守式回收器可能错误地将一个槽当作指针,这带来了两个安全上的要求:第一,回收器不能修改任何赋值器可能访问到的内存地址的值(包括对象和根集合)。这一要求导致保守式回收器不能使F任何可能移动对象的算法,因为对象被移动之后需要更新指向该对象的所有引用。这同时导致在头域中保存标记位的方案不可行,因为错误的指针会指向一个实际并不存在的象”,因此设置或者清理标记位可能会破坏用户数据。第二,应当尽可能减少赋值器破坏回收器数据的可能性。与将标记位等回收器元数据存放在一个单独区域的方案相比,为每个对象增加一个回收器专用头部数据会存在更高的风险。</p><p><font color="DeepPink"><strong>使用位图标记的另一个重要目的是减少回收过程中的换页次数</strong></font>[Boehm,2000在现代系统中,任何由回收器导致的换页行为通常都是不可接受的,因此位图标记是否可以提升高速缓存性能便成为一个值得关注的问题。许多证据表明,对象往往成簇诞生并成批死亡[Hayes,1991; Jones, Ryder,2008],而许多分配器往往也会将这些对象分配在相邻的空间。使用位图来引导清扫可以带来两个好处:第一,在位图/字节图中,一个字内部的每个位/字节全部都被设置/清空的情况会经常出现,因此回收器可以批量读取/清空一批对象的标记位;第二,通过位图标记可以更简单地判定某一内存块中的所有对象是否都是垃圾,进而可能一次性回收整个内存块。</p><p>许多内存管理器都使用块结构堆(如Boehm and Weiser[1988])。最直接的位图标记实现策略可能是在每个内存块的前端保留一块内存以用作位图。但正如我们前面所提到的,这策略可能会导致不必要的高速缓存冲突或者换页,因此回收器通常将位图与用户数据块分开并单独存放。</p><p>Garner等[2007]提出了一种<font color="DeepPink"><strong>混合标记策略,即将分区适应分配器(segregated fitsallocator)所管理的每个数据块与字节图中的一个字节相关联,同时依然保留对象头部的标记位。当且仅当内存块中至少存在一个存活对象时,该内存块所对应的标记字节才会被设置。清扫器可以根据字节图快速地判定某一内存块是否完全为空(即不包含存活对象),进而可以将其整体回收。</strong></font>这一策略有两个优点:第一,在并发情况下,无需使用同步操作来设置字节图中的标记字节以及对象头部的标记位;第二,写操作没有数据依赖(这可能导致高速缓存延迟),且对字节图中标记字节的写操作也是无条件的。</p><h2 id="标记过程中的高速缓存不命中问题">标记过程中的高速缓存不命中问题</h2><p>Bohm[2000]发现标记过程的开销决定着回收时间:在 Intel PentiumⅢ系统中,预取对象第一个指针域的开销通常会占到标记该对象总开销的三分之一。为此 Boehm提出一种灰色预取( prefetching on gray)技术,即当对象为灰色时,预取其第一个高速缓存行中的数据,如果被扫描的对象很大,则预取适当数量的高速缓存行。然而,这种技术依赖于预取时间,如果过早地进行高速缓存行预取,则数据很可能在得到使用之前就被换出,而过晚地预取则会导致高速缓存不命中。</p><h2 id="需要考虑的问题">需要考虑的问题</h2><h3 id="空间利用率">空间利用率</h3><p>将标记位放在对象头部基本不会产生额外的空间开销,而如果使用位图来保存标记位,则额外空间开销的大小取决于对象的字节对齐要求,但其总大小不会超过堆的字节对齐要求的倒数(即堆空间的1/64或1/32,具体的值取决于堆的组织架构)。</p><h1>引用计数</h1><h2 id="环状引用计数">环状引用计数</h2><p>对于环状数据结构而言,其内部对象的引用计数至少为1,因此仅靠引用计数本身无法回收环状垃圾。不论是在应用程序还是在运行时系统中,环状数据结构都十分普遍,如双向链表或者环状缓冲区。对象一关系映射(object-relations mapping)系统可能要求数据库和其中的表互相引用对方的一些信息。真实世界中的某些结构天然就是环状的,例如地理信息系统中的道路。懒惰函数式语言(lazy functional language)通常使用环来表示递归[urner 1979,Y组合子(Combinator)]。研究者们提出了多种解决环状引用计数问题的策略,我们介绍其中的几种。</p><p>最简单的策略是在引用计数之外偶尔使用追踪式回收作为补充。该方法假定大多数对象不会被环状数据结构所引用,因此可以通过引用计数方法实现快速回收,而追踪式回收则负责处理剩余的环状数据结构。这一方案简单地减少了追踪式回收的发起频率。在语言层面上, Friedman和wise[1979]发现,纯函数式语言中只有递归定义才会产生环,因此只要遵从一定的规则便可对这种情况下的环状引用计数进行特殊处理。在 Bobrow1980]的方法中,开发者可以把一组对象作为整体进行引用计数操作,当整体引用计数为零时便可将其集体回收。</p><p>许多学者建议将导致闭环出现的指针与其他指针进行区分[Friedman and Wise,1979;Brownbridge,1985; Salkeld,1987; Repels等,1988; Axford,19901。他们将普通引用称为强引用(strong reference),将导致闭环出现的引用称为弱引用(weak reference)。如果不允许强引用组成环,则强引用图可以使用标准引用计数算法处理。Brownbridge的算法得到了广泛应用,简而言之,每个对象需要包含一个强引用计数以及一个弱引用计数,在进行写操作时,写屏障会检测指针以及目标对象的强弱,并将所有可能产生环的引用设置为弱引用。为维护“所有可达对象均为强可达,且强引用不产生环”这一不变式,赋值器在删除引用时可能需要改变指针的强弱属性。但是,这一算法并不安全,且可能导致对象提前被回收,具体可以参见Salkeld的引用计数示例[Jones,1996,6.5节]。Salkeld[1987]对该算法进行修正并提升了它的安全性,但代价是在某些情况下算法将无法结束。Repels等[1988]提出了一种非常复杂的解决方案,但该算法在空间以及性能方面的开销却更加明显:与普通的引用计数相比,其所需的空间开销翻倍,在大多数情况下,其性能开销是标准引用计数的两倍,在极端情况下,甚至会呈现指数级增长。</p><p>在所有能够处理环状数据结构的引用计数算法中,得到了最广泛认可的是试验删除(trial deletion)算法。该算法无须使用后备的追踪式回收器来进行整个存活对象图的扫描,相反,它将注意力集中在可能会因删除引用而产生环状垃圾的局部对象图上。在引用计数算法中:</p><ul><li>在环状垃圾指针结构内部,所有对象的引用计数均由其内部对象之间的指针产生。</li><li>只有在删除某一对象的某个引用后该对象的引用计数仍大于零时,才有可能出现环状垃圾。</li></ul><p>部分追踪(partial tracing)算法充分利用上述两个结论,该算法从一个可能是垃圾的对象开始进行子图追踪。对于遍历到的每个引用,算法将对其目标对象进行试验删除,即临时性地减少目标对象的引用计数,从而移除由内部指针产生的引用计数。追踪完成后,如果某个对象的引用计数仍然不是零,则必然是因为子图之外的其他对象引用了该对象,进而可以判定该对象及其传递闭包都不是垃圾。</p><p>Recycler算法[Bacon等,2001; Bacon and Rajan,2001;Paz等,2007]支持环状引用计数的并发回收。环状数据结构的回收分为3个阶段:</p><ul><li>首先,回收器从某个可能是环状垃圾成员的对象出发进行子图追踪,同时减少由内部指针产生的引用计数。算法将遍历到的对象着为灰色。</li><li>其次,对子图中的所有对象进行检测,如果某一对象的引用计数不是零,则该对象必然被子图外的其他对象引用。此时需要对第一阶段的试验删除操作进行修正,算法将存活的灰色对象重新着为黑色,同时将其他灰色对象着为白色。</li><li>最后,子图中所有依然为白色的对象必然是垃圾,算法可以将其回收。</li></ul><h1>内存分配</h1><p>对于首次适应或循环首次适应分配而言,将空闲内存单元依照地址进行排序的另一种有效策略是位图适应分配(bitmapped- fits allocation)。该算法使用额外的位图来记录堆中每个可分配内存颗粒的状态,因此在进行内存分配时,分配器可以基于位图而非堆本身进行搜索。借助一张预先计算好的映射表,分配器仅需要对位图中一个字节进行计算,便可得知其所对应的8个连续内存颗粒所能组成的最长连续可用空间。也可以使用额外的长度信息记录较大的空闲内存单元或者已分配内存单元,从而快速将其跳过以提升分配性能。位图适应分配具有如下一些优点:</p><ul><li>位图本身与对象相互隔离,因此不容易遭到破坏。这一特性不仅对于诸如C和C++等安全性稍低的语言十分重要,而且对于安全性更高的语言也十分有用,因为这可以提升回收器的可靠性以及可调试性。</li><li>引入位图之后,无论是对于空闲内存单元还是已分配内存单元,回收器都不需要占据其中的任何空间来记录回收相关信息,从而最大限度地降低了对内存单元大小的要求。如果以一个32位的字作为最小内存分配单元,该策略会引入大约3%的空间开销,但其所带来收益却远大于这一开销。不过,基于其他一些方面的考虑,对象可能依然需要一个头部,因而这一优点并非始终能够得到体现。</li><li>相对于堆中的内存单元,位图更加紧凑,因此基于位图进行扫描可以提升高速缓存命中率,从而提升分配器的局部性。</li></ul><h2 id="分区适应分配">分区适应分配</h2><h3 id="空间大小分级的填充">空间大小分级的填充</h3><p>伙伴系统(buddy system)其空间大小分级均为2的整数次幂[Knowlton,1965; Peterson and Norman,1977]。我们可以将一个大小为2<sup>(i+1)的空闲内存单元分裂为两个大小为2</sup>i的空闲内存单元,同时也可以将两个相邻的大小为2<sup>i的空闲内存单元合并成大小为2</sup>(i+1)的一个,但进行合并的前提是两个相邻空闲内存单元原本就是由同一个较大的空闲内存单元分裂得到的。在该算法中,大小为2^i的空闲内存单元两两成对,因而称之为伙伴。<font color="DeepPink"><strong>由于伙伴系统的内部碎片通常较为严重(对于任意的内存分配需求,其平均空间浪费率会达到25%),因此该算法基本已经成为历史,在实践中较少使用。</strong></font></p><p>斐波那契伙伴系统(Fibonacci buddy system)[Hirschberg,1973; Burton,1976; Peterson and<br>Norman,1977是伙伴系统的一个变种,其空间大小分级符合斐波那契序列,即s<sub>i+2</sub> = s<sub>i+1</sub> + s<sub>i</sub>,同时需要选定合适的s0和s1。与传统的伙伴系统相比,该算法相邻空闲内存单元的大小比值更小,因而在一定程度上缓解了内部碎片问题。但该算法的问题在于,在回收完成后将相邻空闲内存单元合并的操作会更加复杂,因为回收器需要判定某一空闲内存单元究竟应当与相邻两个空闲内存单元中的哪一个进行合并。</p><h2 id="其它需要考虑的问题">其它需要考虑的问题</h2><h3 id="字节对齐">字节对齐</h3><p>将对象按照特定的边界要求进行对齐,一方面是底层硬件或者机器指令集的要求,另方面这样做有助于提升各层次存储器的性能(包括高速缓存、转译后备缓冲区、内存页以Java语言的 double数组为例,某些机器可能要求double这一双字浮点数必须以双字为边<br>界进行对齐,即其地址必须是8的整数倍(地址的后三位为零)。一种简单但稍显浪费的解决方案是将双字作为内存分配的颗粒,即所有已分配或未分配内存单元的大小均为8的整数倍,且均按照8字节边界对齐。但即便如此,当分配一个doub1e类型的数组时,分配器仍需要进行一些额外工作。假设Java语言中纯对象(即非数组对象)头部都必须保留两个字,一个指向对象的类型信息(用于虚函数调用、类型判定等),另一个用于记录对象的哈希值以及同步操作所需的锁(这也是一种典型的设计方式)。数组对象则需要第三个字来记录其中元素的个数。如果将这三个头部字保存在已分配内存单元的起始位置,则数组元素就不得不以奇数字为单位进行对齐。如果使用双字作为内存颗粒,则可以简单地用四个字(即两个双字)来保存这三个头部字,然后浪费掉一个。</p><p>但如果内存颗粒是一个字,我们则希望尽量减少上述的内存浪费。此时,如果某个空闲内存单元按照奇数字对齐(即其地址模8余4),则我们可以简单地将三个头部字放在内存单字对齐,则我们必须浪费一个字以满足对齐要求。这一方案增加了分配过程的复杂度,因为某一空闲内存单元是否满足分配需求不仅取决于所需空间的大小,还取决于字节对齐要求。</p><blockquote><p>字：16个位为一个字，它代表计算机处理指令或数据的二进制数位数，是计算机进行数据存储和数据处理的运算的单位。通常称16位是一个字，而32位呢，则是一个双字，64位是两个双字。</p></blockquote><h3 id="空间大小限制">空间大小限制</h3><p>某些回收器要求对象(内存单元)的大小必须大于某一下界。例如,基本的整理式回收要求对象内部至少可以容纳一个指针,还有一些回收器可能需要用两个字来保存锁或状态以及转发指针,这就意味着即使开发者仅需要分配一个字,分配器也必须多分配两个字。如果开发者需要分配不包含任何数据、仅用作唯一标识的对象,原则上编译器无需分配任何空间,但在实际情况下这通常不可行:对象必须要有唯一的地址,因此对象的大小至少应为一个字节。</p><h3 id="边界标签">边界标签</h3><p>为了确保在释放内存时可以将相邻空闲内存单元合并,许多内存分配系统为每个内存单元增加了额外的头部或者边界标签,它们通常不属于可用内存的范畴[Knuth,1973]。边界标签保存了内存单元的大小及其状态(即空闲或已分配),还可以在其中记录上一个内存单元的大小,从而可以快速读取上一个内存单元的状态并判断其是否为空。当内存单元空闲时,边界标签也可用于保存构建空闲链表的指针。基于这些原因,边界标签可能达到两个字或者更大,但如果使用一些额外的方法,并允许在分配和释放的过程中引入一定的额外开销,则仍有可能将边界标签压缩到一个字。</p><p>如果使用额外的位图来标记堆中每个内存颗粒的状态,则不仅无需使用边界标签,而且可以增加程序的鲁棒性。这一方法是否会减少空间开销,取决于对象的平均大小以及内存颗粒的大小。</p><p>我们进一步注意到,垃圾回收通常会一次性释放大量对象,因此某些特定的算法可能不再需要边界标签,或者其边界标签中需要包含的信息较少。另外,托管语言中对象的大小通常可以通过其类型得出,因而无需使用额外的边界标签来单独记录相关信息。</p><h3 id="局部性">局部性</h3><p>事实证明,同一时刻分配的对象通常也会在同一时刻成为垃圾,因此非移动式回收器所面临的内存碎片问题比人们预想的要小[Hayes,1991; Dimpsey等,2000; Blackburn and McKinley,2008],这同时也说明,将连续两次分配的对象连续排列或者尽可能靠近排列的启发式方法是有价值的。</p><h3 id="并发系统中的内存分配">并发系统中的内存分配</h3><p>在多线程环境下,分配过程的许多操作都需要原子化以确保分配数据结构的完整性,这些操作都必须使用原子操作或者锁,但这样一来,内存分配就可能成为性能瓶颈。最基本的解决方案是为每个线程开辟独立的内存分配空间,如果某个线程的可分配空间耗尽,则从全局内存池中为其分配一个新的空闲块,此时只有与全局内存池的交互才需要原子化。不同线程的内存分配频度可能不同,因此如果在为线程分配内存块时使用自适应算法(即:为分配速度较慢的线程分配较小的内存块,而为分配速度较快的线程分配较大的内存块),则程序的时间和空间性能均可获得提升。Dimpsey等[20001声称,在多处理器Java系统中,为每个线程配备一个合适的本地分配缓冲区(local allocation buffer,LAB)可以大幅提升性能。他们进一步指出,由于几乎所有的小对象都是从本地分配缓冲区分配的,因而我们有理由对全局(基于空闲链表的)分配器进行调整,以使其能够更加高效地分配用于线程本地分配缓冲区的内存块。</p><p>Garthwaite等[2005]讨论了如何对本地分配缓冲区的大小进行自适应调整,他们同时发现,将本地分配缓冲区与处理器而非线程相关联效果更佳。该算法通过如下方式对本地分配缓冲区的大小进行调整:线程初次申请本地分配缓冲区时将获得24个字的内存块,之后每次新申请的内存块均为上一次的1.5倍,同时每经历一次垃圾回收过程,回收器都会将线程的本地分配缓冲区的大小折半。该算法同时也会根据不同线程的分配次数调整年轻代的空间大小。每处理器(per-processor)本地分配缓冲区的实现依赖于多处理器的可重启临界区(restartable critical section),Garthwaite等人对此做了介绍。其基本原理是,线程可以判断自身是否被抢占(preempt)或者被重新调度(reschedule),然后可以据此判断自身是否被切换到其他处理器上运行。当线程抢占发生时,处理器会对某个本地寄存器进行修改,该操作会为抢占完成后的写入操作设置一个陷阱,而陷阱处理函数则会重启被中断的分配过程。尽管每处理器本地分配缓冲区需要更多的指令支持,但与每线程本地分配缓冲区相比,其分配时延相同,且不需要复杂的缓冲区调整机制。 Garthwaite同时发现,当线程数量较少时(特别是当线程数量小于处理器数量时),每线程(per-thread)本地分配缓冲区的性能较好,而在线程数量较多的情况下,每处理器本地分配缓冲区的表现更佳,因此他们将系统设计成可在两种方案之间进行动态切换。</p><p>本地分配缓冲区通常使用顺序分配策略。每个线程(或处理器)也可以独立维护自身对应的分区适应空闲链表,同时使用增量清扫策略。线程在内存分配过程中会执行增量清扫,并将清扫所得的空闲内存单元添加到自身空闲链表中,但Berger等[2000]指出,如果将该算法用于显式内存管理会存在一些问题。例如,在某一使用生产者一消费者模型的程序中消息对象通常由生产者创建并由消费者释放,因此两个线程之间将会产生单方向的内存转移。在垃圾回收环境下通常不会存在这一问题,因为回收器可以将空闲内存释放到全局内存池中。如果使用增量清扫,空闲内存单元将被执行清扫的线程所获取,从而自然地将回收所得的内存返还给分配最频繁的线程。</p><h2 id="需要考虑的问题-v2">需要考虑的问题</h2><p><font color="DeepPink"><strong>使用额外的位图表来标记内存颗粒的状态(空闲/已分配)以及内存单元/对象的起始地址,不仅能提升程序的鲁棒性,而且可以简化对象头部的设计。该策略同时可以加速回收器的操作,并可以在存储器层次结构方面提升回收器的性能。基于位图的分配策略空间开销不大,但其分配过程通常会存在额外的时间开销。</strong></font></p><h2 id="分代间指针">分代间指针</h2><p>分代间指针的创建有3种方式:一是在对象创建时写入,二是在赋值器更新指针槽时写入,三是在将对象移动到其他分代时产生。回收器必须要对分代间指针进行记录,只有这样才能确保在对某一分代单独进行回收时根的完整性。</p><h3 id="记忆集">记忆集</h3><p>因此,每个分代的记忆集均只需记录可能指向该分代内部对象的回收相关指针来源。不同的记忆集实现方式在来源地址的记录方面所能达到的精度也各不相同。精度并非越髙越好,较高的精度通常会增大赋值器的额外开销、记忆集空间开销以及回收器处理记忆集的时间开销。</p><h2 id="带式回收框架">带式回收框架</h2><p>回收策略的基本指导思想大体上可以总结如下:</p><ul><li>“大多数对象都在年轻时死亡”,即弱分代假说。</li><li>分代回收器会避免对年老对象进行频繁回收。</li><li>增量回收可以改善回收停顿时间。在分代垃圾回收器中,新生代的空间通常较小;其他回收技术通常也会限制待回收空间的大小,例如成熟对象空间回收器(mature object space collector)(也称为火车回收器)。</li><li>在较小的诞生空间中使用顺序分配可以提升数据的局部性。</li><li>对象需要足够的时间到达死亡。</li></ul><h2 id="启发式方法在分代垃圾回收中的应用">启发式方法在分代垃圾回收中的应用</h2><p>分代垃圾回收器可以较好地处理短命对象,但其对长寿对象的处理能力则略显不足,这一问题主要表现在两个方面:第一,年老代垃圾的回收不够及时,因为没有哪种策略可以确保在年老代出现大量垃圾时尽快将其回收;第二,年老代的所有长寿对象都必须是从年轻代复制而来的,同时为避免过早地提升对象,某些回收器要求年轻代对象在得到提升之前必须在年轻代中经历数次回收。对于长寿对象而言,这些复制操作都相当于是无用功,更好的解决方案是直接将长寿对象预分配到其最终可能到达的分代中。</p><p>一些研究者尝试通过分析程序特定代码位置所分配对象的生命周期分布来解决这一问题。这一方案对于虚拟机的开发者来说具有一定的可行性,因为他们可以知道在其具体的虚拟机中哪些数据结构会是永久性的、哪些库或者代码对象永远不会或者至少不太可能被卸载。这些对象的预分配逻辑可以在虚拟机内部实现。</p><h1>其他分区策略</h1><p>每种回收器都通过一种不同的方式来解决如下3个问题:</p><ul><li>如何最好地利用堆空间</li><li>如何避免对去碎片化操作(复制或标记一整理)的依赖</li><li>如何降低回收器循环的时间开销</li></ul><h1>运行时接口</h1><p>我们将对象的分配以及初始化过程划分为3个阶段,但并非所有的语言或者所有情况下都需要完成所有阶段。</p><ul><li>阶段1:分配一块大小合适的、符合字节对齐要求的内存单元,这一工作是由内存管理器的分配子系统完成的。</li><li>阶段2:系统级初始化(system initialisation),即在对象被用户程序访问之前,其所有的域都必须初始化到适当的值。例如在面向对象语言中,设定新分配对象的方法分派向量(method dispatch vector)即是该阶段的任务之一。该阶段通常也需要在对象头部设置编程语言或内存管理器所需的头域,对Java对象而言,则包括哈希值以及同步相关信息,而Java数组则需要明确记录其长度。</li><li>阶段3:次级初始化(secondary initialisation),即在对象已经“脱离”分配子空间,并且可以潜在被程序的其他部分、线程访问时,进一步设置(或更新)其某些域。</li></ul><p>Java:阶段1和阶段2共同完成新对象的方法分派向量、哈希值、同步信息的初始化,同时将所有其他域设置为某一默认值(通常全为零)。数组的长度域也在这两个阶段完成初始化。字节码new所返回的对象便处于这一状态,此时尽管对象满足类型安全要求,但其依然是完全“空白”的对象。阶段3在Java语言中对应的表现形式是对象构造函数或者静态初始化程序中的代码,或者在对象创建完成后将某些域设置为非零值的代码段。final域的初始化也是在阶段3中完成的,因此一旦过早地将新创建的对象暴露给其他线程,同时又要避免其他线程感知到对象域的变化,实现起来将十分复杂。</p><h2 id="来自外部代码的引用">来自外部代码的引用</h2><p>句柄不仅可以作为托管堆和非托管世界之间的一道桥梁,而且可以更好地适应移动式回收器,但并非所有的外部访问都可以遵从这一访问协议,特别是操作系统调用。此时回收器就必须避免移动被外部代码所引用的对象。为此,回收器可能需要提供一个钉住接口,并提供钉住(pin)和解钉(unpin)操作,当某一对象被钉住时,回收器将不会移动该对象,同时也意味着该对象可达且不会被回收。</p><p>如果我们在分配对象时便知道该对象可能需要钉住,则可以直接将其分配到非移动空间中。文件流IO缓冲区便是以这种方式进行分配的。但程序通常很难事先判断哪个对象未来需要钉住,因此某些语言支持pin和unpin函数以便开发者自主进行任何对象的钉住与解钉操作。</p><p>钉住操作在非移动式回收器中不会成为问题,但却会给移动式回收器造成一定不便,针对这一问题存在多种解决方案,每种方案各有优劣。</p><ul><li>延迟回收,或者至少对包含被钉住对象的区域延迟回收。该方案实现简单,但却有可能在解钉之前耗尽内存。</li><li>如果应用程序需要钉住某一对象,且对象当前位于可移动区域中,则我们可以立即回收该对象所在的区域(以及其他必须同时回收的区域)并将其移动到非移动区域中。该策略适用于钉住操作不频繁的场景,同时也适用于将新生代存活对象提升到非移动式成熟空间的回收器(例如分代回收器)。</li><li>对回收器进行扩展以便在回收时不移动被钉住的对象,但这会增加回收器的复杂度并可能引入新的效率问题。</li></ul><h2 id="针对代码的回收">针对代码的回收</h2><p>许多系统会预先对所有代码进行静态编译,但也有一些程序可以在运行时构建并执行代码,例如垃圾回收技术的鼻祖—Lisp语言。尽管Lisp最初是解释型语言,但其在很早就已经能够编译成本地代码。目前,越来越多的系统已经能够动态加载或者构建代码,并在运行时进行优化。由于系统可以动态加载或者生成代码,所以我们自然会希望当这些代码不再使用时,其所占用的空间能够得到回收。面对这一问题,直接的追踪式或引用计数算法通常无法满足该要求,因为许多从全局变量或者符号表可达的函数代码将永远无法清空。某些语言只能靠开发者显式卸载这些代码实例,但语言本身甚至可能根本不支持这一操作。</p><p>另外,还有两个特殊场景值得进一步关注。首先是由一个函数和一组环境变量绑定而成的闭包。我们假设某一简单的闭包是由内嵌在函数f中的函数g,以及函数f的完整环境变量构成的,它们之间可能会共享某一环境对象。Thomas和Jones[1994]描述了一种系统,该系统可以在进行垃圾回收时将闭包的环境变量特化为仅由函数g使用的变量。该策略可以确保某些其他闭包最终不可达并得到回收。</p><p>另一种场景出现在基于类的系统中,例如Java。此类系统中的对象实例通常会引用其所属类型的信息。系统通常会将类型信息及其方法所对应的代码保存在非移动的、不会进行垃圾回收的区域,因此回收器便可忽略掉所有对象中指向类型信息的指针。但是如果要回收类型信息,回收器就必须要对所有对象中指向类型信息的指针进行追踪,在正常情况下这一操作可能会显著增大回收开销。回收器可以仅在特殊模式下才对指向类型信息的指针进行追踪。</p><p><font color="DeepPink"><strong>对于Java而言,运行时类是由其类代码以及类加载器(class loader)同决定的由于系统在加载类时通常会存在一些副作用(例如初始化静态变量),所以类的卸载会变得不透明(即存在副作用—译者注),这是因为该类可能会被同一个类加载器重新加载。唯一可以确保该类不被某个类加载器加载的方法是使类加载器本身也能得到回收。类加载器中包含一个已加载类表(以避免重复加载或者重复初始化等),运行时类也需要引用其类加载器(作为自身标识的一部分)。因此,如果要回收一个类,则必须确保其类加载器、该类加载器所加载的其他类、所有由该类加载器所加载的类的实例都不被现有的线程以及全局变量所引用(此处的全局变量应当是由其他类加载器加载的类的实例)。另外,由于引导类加载器(bootstrap class loader)永远不会被回收,所以其所加载的任何类都无法得到回收。由于Java类卸载是一种特殊的情况,所以某些依赖这一特性的程序或者服务器可能会因此耗尽空间。</strong></font></p><h2 id="读写屏障">读写屏障</h2><h3 id="卡表">卡表</h3><p>卡表(卡标记)策略将堆在逻辑上划分为固定大小的连续区域,每个区域称之为卡。卡通常较小,介于128~512字节之间。卡表最简单的实现方案是使用字节数组,并以卡的编号作为索引。当某个卡内部发生指针写操作时,写屏障将该卡在卡表中对应的字节设置为脏。卡的索引号可以通过对指针域的地址进行移位获得。卡表的设计初衷在于尽量简化写屏障的实现并提高其性能,从而将其内联到赋值器代码中。另外,与哈希表或者顺序存储缓冲区不同,卡表不存在溢出问题。但这些收益总是要付出一定代价的:回收器的工作负荷会加重,因为回收器必须对脏卡中的域进行逐个扫描,并找出其中已被修改的、可能包含回收相关指针的域,此时回收器的工作量将正比于已标记卡的数量(以及卡的大小),而非产生回收相关指针的写操作的发生次数。</p><p>使用卡表的目的在于尽可能减轻赋值器的负担,因而其通常应用在无条件写屏障中,这便意味着卡表必须能够将所有可能被 Write操作修改的地址映射到卡表中的某个槽。如果我们可以确保堆中的某些区域永远不可能写入回收相关指针,同时引入条件检测来过滤掉这些区域的指针写操作,则可以减少卡表的大小。例如,如果将堆中高于某一固定虚拟地址边界的空间用作新生区(回收器在每次回收过程中都处理该区域),则卡表只需要对低于该边界地址的空间创建对应的槽。</p><p><font color="DeepPink"><strong>最紧凑的卡表实现方式应当是位数组,但多种因素决定了位数组并非最佳实现方案。</strong></font>现代处理器的指令集并不会针对单个位的写入设置单独的指令,因而位操作比原始操作需要更多的指令:读取一个字节、通过逻辑运算设置或清除一个位、写回该字节。更糟糕的是,这些操作序列并不是原子化的,多线程同时更新同一个卡表条目可能会导致某些信息丢失,即使它们所修改的是堆中不同的域或者对象。正因如此,卡表才通常使用字节数组。由于处理器清空内存的指令的执行速度更快,所以通常使用0来表示“脏”标记。在使用字节数组的场景下,在卡表中设置脏标记只需要两条SPARC指令(其他架构所需的指令可能会稍多一些)。</p><p><font color="DeepPink"><strong>Detlefs等观察发现,绝大多数卡都是干净的,且单个卡中很少会包含超过16个分代间指针。因此可以使用两级卡表来加速回收器查找脏卡的过程,尽管这一策略会付出额外的空间开销。第二级卡占用的空间更小,其中的每个槽对应2<sup>n</sup>个粒度更细的卡,因而其能够将干净卡的扫描速度提升n倍。</strong></font></p><h1>特定语言相关内容</h1><h2 id="弱引用">弱引用</h2><h3 id="对不同强度指针的支持">对不同强度指针的支持</h3><p>每种强度的引用通常会与回收器的特定行为相关联。在支持多种不同强度的弱引用的编程语言中,最知名的当属Java,其提供的引用类型从最强到最弱可以分为以下几种:</p><ul><li>强引用(strong reference):普通的引用,具有最高的引用强度。回收器永远不会将强引用置空。</li><li>软引用(soft reference):回收器可以根据当前的空间使用率来判定是否需要将软引用置空。如果Jaa回收器将某个指向对象O的软引用置空,它必须在同一时刻自动将所有导致对象O强可达的软引用置空。这一规则可以确保在回收器将这些引用置空之后,对象将不再软可达。</li><li>弱引用(weak reference):一旦回收器发现某一(软可达的)弱引用的目标对象变为弱可达,则回收器必须将该引用置空(从而确保其目标对象不再软可达)。与软引用类似旦回收器将某个指向对象O的弱引用置空,则必须同时将所有其他导致该对象软可达的软可达弱引用置空。</li><li>终结方法引用(finaliser reference):我们将从终结表到待终结对象的引用称为终结方法引用。终结方法引用只在运行时系统内部出现,它并不会像弱对象一样暴露给开发者。</li><li>虚引用(phantom reference):Java中最弱的一种引用类型。虚引用只有与通知机制联合使用才具有一定意义,这是因为虚引用对象不允许程序经由该引用获取目标对象的引用,因此程序唯一可能的操作是将虚引用置空。程序必须显式地将虚引用置空来确保回收器将其目标对象回收。</li></ul><p>Java语言中不同强度的引用并没有我们此处描述的这么多,但此处的每种语义却与语言规范所定义的每种弱引用相关联。软引用允许系统对可调整的缓存进行收缩;弱引用可以用于规范化表或者其他场景;虚引用允许开发者控制回收的顺序以及时间。</p><p>多强度引用的实现需要在回收过程中增加额外的遍历,但这些操作通常可以很快完成。下面我们以Java的4种强度为例来描述复制式回收器对不同强度引用的处理方式。标记清扫回收器也可以通过类似的方式实现,同时也会更加简单。回收器应当以如下方式执行堆遍历过程：<br>1)从根开始,仅对强可达对象进行追踪并复制,同时找出所有的软对象、弱对象、虚对象(但不对这些对象进行追踪)。<br>2)如果必要,则自动将所有软引用置空。如果无需将软引用置空,则需对其进行追踪和复制,并找出所有的软可达对象。对软可达对象进行追踪时可能会发现新的弱可达或虚可达对象。<br>3)如果弱引用的目标对象已被复制到目标空间,则更新该引用,否则将该引用置空。<br>4)如果尚未复制的对象中存在需要终结的对象,则将其加入终结队列,然后回到第1步,并以终结队列作为新的根进行追踪。需要注意的是,在第二轮执行过程中将不会再有需要终结的对象产生。<br>5)如果虚引用的目标对象并未得到复制,则将其加入ReferenceQueue里。然后回收器将从该对象开始完成虚可达对象的追踪与复制。需要注意的是,回收器不会将任何虚引用置空,这一操作必须由开发者显式操作。</p><h3 id="使用虚对象控制终结顺序">使用虚对象控制终结顺序</h3><p>假设有两个对象,A和B,我们希望它们的终结顺序是先A后B。一种实现策略是创建虚对象A来持有对象A的虚引用。除此之外,A的类型应该是对Java的PhantomReference的扩展,其将持有一个指向对象B的强引用,以避免对象B被提早终结。图12.5演示了这一情况。<br><img data-src="/images/the-garbage-collection-handbook-the-art-of-automatic-memory-management/12.5%E6%8C%89%E5%BA%8F%E7%BB%88%E7%BB%93.png" alt><br>一旦对象A’(即对象A的虚引用来源)加入到用户指定的队列,意味着对象A已经从应用程序不可达,并且A对应的终结方法已经运行过,这是因为终结队列可达要比虚可达的强度更高。然后我们将虚对象A指向A的虚引用图12.5按序终结。我们希望在对象A和B置空,再将其指向B的强引用置空,如此一来,对象B的终结方法将在下一轮回收中得到调用最后我们再把虚对象从全局对象表中删除,则虚对象本身也将得到回收。我们很容易将该策略进行推广,进而实现三个或者更多对象的终结顺序控制,所付出的代价是在两两对象之间通过虚对象来施加终结顺序限制。</p><p>终结顺序的控制只能通过虚对象完成,弱对象无法胜任。对于图12.5所示的状态,如果我们将虚对象替换为弱对象,则当对象A不可达时,A中的弱引用将被置空,且A’将被添加到用户指定的队列中。此时我们可以将A中指向B的强引用置空,但不幸的是,置空A中弱引用的操作将发生在A的终结方法执行之前(因为弱引用的强度高于终结方法引用——译者注),此时我们将很难知道A的终结方法何时执行完毕,因此对象B的终结方法可能会先得到执行。故意将虚引用的强度设计得比终结方法引用更低,目的正在于确保只有当对象的终结方法执行完毕之后,其虚引用来源才会被加入到用户指定的队列。</p><h3 id="弱指针置空时的通知">弱指针置空时的通知</h3><p>在弱引用机制之上,某些应用程序可能需要在特定的弱引用被清空时得到通知(虚引用可以通知应用程序对象已被终结,而弱引用则可以通知应用程序对象可能将要终结),然后再执行某些适当的动作。因此,弱引用机制通常也会支持通知,其实现策略一般是将弱对象添加到开发者指定的队列中。例如,Java的ReferenceQueue内建类便是以此为目的设计的,应用程序既可以对其进行轮询,也可使用阻塞式的操作来获取元素(或者附加额外的超时时间)。应用程序也可以检测某个给定的弱对象是否已经加入到某个队列中(Java只允许弱对象最多被加入到一个队列中)。回收器在对弱指针的多次遍历过程中可以很轻松地实现弱对象的人队。许多语言都增加了类似的通知机制。</p><h1>并发算法预备知识</h1><h2 id="硬件">硬件</h2><h3 id="处理器与线程">处理器与线程</h3><p>处理器(processor)是硬件执行指令的单元。线程(thread)是单一顺序控制流,是软件执行的具体化。线程的状态可以是运行中(running)(也称调度中(scheduled))、可运行(ready to run),或者是为等待某些条件而被阻塞(blocked),例如等待消息的到来、输入/输出的完成,或者到达特定的时间。调度器(scheduler)通常是操作系统组件,其功能是确定在任意时刻哪些线程应当在哪些处理器上执行。如果某个线程被调度器从某个处理器换出(其状态从运行中转变为可运行或者被阻塞),则当其下一次被调度时很可能会在另一个不同的处理器上运行。当然,调度器也允许线程和处理器之间存在一定的亲和性(affinity)。</p><p>某些处理器硬件支持多个逻辑处理器共用一条指令流水线,该技术称为同时多线程(simultaneous multithreading,SMT)或者超线程(hyperthreading)。这一概念会给我们的定义带来一定的麻烦。在我们的术语中,逻辑处理器通常被称为线程,但在此处,同时多线程处理器则可以看作是多(逻辑)处理器,并可以独立进行调度,因而线程这一概念便只能代表软件实体。</p><p>多处理器(multiprocessor)是包含多个处理器的计算机。片上多处理器(chip multiprocessor,CMP)是指在单个集成电路芯片上集成多个处理器的技术,也称多核处理器(multicore processor)甚至众核处理器(many-core processor)。抛开并发多处理器的概念不谈,多线程(multithread)是指使用多个线程的软件,且每个线程可能在多个处理器上并发运行。多程序(multiprogram)是指在单一处理器上执行多个进程或者线程的软件。</p><h3 id="处理器与内存之间的互联">处理器与内存之间的互联</h3><p>多处理器与集群计算、云计算或者分布式计算的区别在于,前者存在每个处理器都可以直接访问的共享内存。处理器对共享内存的访问需要以某种互联网络作为媒介。最简单的互联方式是处理器和内存之间使用单个共享总线(bus)来传递信息。我们可以简单地将内存访问操作看作是处理器和内存单元之间的消息通信,每次通信所需的时间可能会达到上百个处理器时钟周期。单个总线的原始速度相当快,但该速度在多处理器同时发起请求时却仍然会成为瓶颈。带宽最高的互联方式可能是在处理器和内存两两之间建立私有通道,但该方案所需的硬件资源却会正比于处理器和内存单元数量的乘积。为获取更高的整体带宽(整个系统中处理器和内存在一秒内可以传输的数据量,将内存分割成多个单元也是一种不错的方案。另外,处理器与内存之间的数据传输通常都是以高速缓存行而非单独的字或者字节为单位的。</p><p>对于更大的片上多处理器,一次内存访问请求在互联网络中的传递可能需要经过多个节点,例如当互联网络以网状或者环状方式组织时。此处的具体细节超出本书的讨论范围,但我们需要了解的是,内存的访问时间可能会随着处理器与内存单元在互联网络中的位置不同而发生变化。另外,相同互联路径上的并发访问也可能引发更大的延迟。</p><p><font color="DeepPink"><strong>在单总线系统中,当处理器的数量达到8~16个之后,总线一般都会成为瓶颈。但相比其他互联方式,总线的实现通常更加简单且更加廉价,且总线允许每个单元侦听(listen)总线中的所有通信(有时也称为窥探(snoopIng),这可以简化系统对高速缓存一致性的支持。</strong></font></p><p><font color="DeepPink"><strong>如果内存单元与处理器之间相互独立,则该系统可以称为对称多处理器(symmetric multiprocessor,SMP)架构,该架构中每个处理器访问任意内存单元的时间都是相同的。我们同样也可以将内存与每个处理器相关联,此时处理器在访问与自身关联的内存时速度更快,而在访问与其他处理器关联的内存时则速度较慢。此类系统被称为非一致内存访问 (non-uniform memory access,NUMA)架构。同一系统可以同时包含全局的SMP内存以及NUMA内存,每个处理器还可以拥有私有内存,但共享内存与垃圾回收技术的关联更大。</strong></font></p><p>对于处理器与内存之间的互联,最值得注意的地方是内存访问需要花费较长的时间,且互联网络可能成为系统的瓶颈,与此同时,不同处理器访问内存的不同部分可能会花费不同的时间。</p><h3 id="内存">内存</h3><p>尽管内存在物理上可能会跨越多个内存单元或者处理器,但从垃圾回收器的角度来看,共享内存看起来就是一块由字或者字节组成的单个地址空间。由于内存是由多个可以并发访问的单元组成的,所以我们无法对其在任意时刻的状态给出一个全局性的描述,但是内存中的每个单元(也就是每个字)在每个时刻的状态都是确定的。</p><h3 id="高速缓存">高速缓存</h3><p>由于内存的访问速度如此之慢,所以现代体系架构通常会在处理器和内存之间增加一到多层高速缓存,其中所记录的是处理器最近访问过的数据,进而降低了程序运行期间处理器需要访问内存的次数。高速缓存与内存的数据交换是以高速缓存行(也称高速缓存块)为单位的,通常为32或者64字节。如果处理器在访问某一地址时发现其所需要的数据已经存在于高速缓存中,这一情况称为高速缓存命中(cache hit,反之则称高速缓存不命中(cache miss),此时处理器便需访问更高一级缓存,如果最高一级缓存依然不命中,则处理器必须访问内存。片上多处理器(CMP)中某些处理器可能会共享最高一级缓存,例如,每个处理器可能都拥有专属的L1高速缓存,但是其会与相邻的一个存储器共享L2高速缓存。各级高速缓存的缓存行大小可以不同。</p><p>当某一级缓存出现不命中,且该级缓存也无法容纳新的缓存行时,处理器就必须依照某种策略从中选择一个缓存行进行置换,被换出的缓存行称作受害者(victim)。当在缓存中写入数据时,某些缓存使用的是写通(write- through)策略,即当某一缓存行中的数据得到更新时,下一级缓存中的对应数据也会尽快得到更新。另一种策略是写回(write-back),即在被修改的行(也称脏行)得到换出之前其中的数据不会写入下一级缓存,除非进行显式刷新fush)(需要使用特殊的指令)或者显式写回(也需要特殊指令支持)。</p><p>缓存置换策略在很大程度上依赖于缓存的内部组织形式。全相联(fully- associative)缓存允许内存中任意地址的数据放置到缓存的任意一行中,其置换策略也可选择任意一行进行淘汰。与之对应的另一个极端是直接映射(direct-maped)缓存,即内存中某一地址的数据只能放置到缓存中特定的行,因而其置换策略只可能淘汰特定的缓存行。k路组相联(k-wayset- associative)缓存是上述两种极端方案的折中,该策略允许内存中特定地址的数据映射到缓存中的k个缓存行,其置换策略也可从这k个缓存行中选择一个进行淘汰。这三种基本的缓存置换策略还存在其他一些变种,例如受害者缓存(victim cache),该缓存包括一个使用直接映射策略的主缓存以及一个额外的容量较小的全相联缓存,从主缓存中淘汰的行将被置于全相联缓存中。该策略的缓存相联性较高,且硬件开销较小。</p><p>高速缓存设计中需要注意的另一方面是各级缓存之间的关系。对于相邻两级缓存,如果较低级别缓存中的数据一定会在高级别缓存中存在,则两级缓存为(严格)包容(inclusive)关系。相反,如果同一数据最多只能出现在两级缓存中的一级,则两级缓存为排他(exclusive)关系。真正的高速缓存设计也可进行折中,即允许同一行存在于两级缓存中,但也并不强制要求高级别缓存一定要包容低级别缓存的数据。</p><h3 id="高速缓存一致性">高速缓存一致性</h3><p>高速缓存中所持有的数据在内存中很可能是共享的。由于每个缓存中的数据不可能同时得到更新(特别是对于使用写回策略的缓存),所以内存中同一地址的数据在不同缓存中的副本可能会出现不一致。因此,不同处理器在同一时刻读取同一地址的数据,可能会获得不同的结果,这显然是不应该出现的。为解决这一问题,底层硬件通常会提供一定级别的高速缓存一致性支持。<font color="DeepPink"><strong>一种经典的高速缓存一致性协议(coherence protocol)是MESI,在该协议中,每个缓存行可能有4种状态,这4种状态的首字母构成了该协议的名称。</strong></font></p><ul><li>被修改(modified):该缓存行持有数据的唯一有效副本,其中的数据被修改过,但尚未写回内存。</li><li>独占(exclusive):该缓存行持有数据的唯一有效副本,同时其中的数据与内存保持一致。</li><li>共享(shared):其他缓存行也可能持有数据的有效副本,同时所有副本中的数据均与内存保持一致。</li><li>无效(Invalide):缓存行中不包含任何有效数据。</li></ul><p>只有当缓存行的状态为“被修改”、“独占”、“共享”其中之一时,处理器才可以读取该缓存行;只有当缓存行的状态为“被修改”或“独占”时,处理器才可以将数据写入该缓存行,写入之后其状态将成为“被修改”。如果处理器需要从“无效”缓存行中读取数据,则系统的后续行为取决于该缓存行在其他缓存中的状态:如果为“被修改”,则处理器必须将其写回内存,并将其状态置为“共享”(或者“无效”);如果状态为“独占”,则只需将其降级为“共享”(或“无效”);如果其状态为“共享”或者“无效”,则处理器只需简单地从内存或者其他缓存里状态为“共享”的缓存行中加载数据。如果处理器需要将数据写入“无效”缓存行中,系统的后续行为与读取时的行为类似,唯一的不同之处在于其他缓存行的最终状态都将是“无效”。如果处理器需要将数据写入“共享”缓存行中,其必须先将其他缓存行降级为“无效”。该协议可以进行的改进包括:以写为目的读可以在读取完成之后将其他缓存行的状态降级为“无效”;写回操作可以将缓存行的状态从“被修改”降级为“独占”;令某一缓存行失效的操作可以将状态为“被修改”的缓存行写回内存,然后将其状态置为“无效”。</p><p><font color="DeepPink"><strong>MESI协议的关键之处在于,任意缓存行在同一时刻只能被一个处理器写,且两个缓存针对同一数据的缓存行永远不会产生不一致。MESI协议的实现难点在于,当处理器数量增大时算法的性能会下降,这也是所有由硬件支持的缓存一致性协议的共有问题。因此,更大的片上多处理器逐渐开始放弃内建的缓存一致性协议,转而开始由软件来管理一致性,此时软件便可选择任意类型的缓存一致性协议。即便如此,处理器数量增大时算法依然会存在性能问题,但与将算法固化在硬件中的策略相比,开发者至少可以根据其具体需求选择更好的致性算法。</strong></font></p><p><font color="DeepPink"><strong>缓存一致性要求引发了另一个问题,即伪共享(false sharing):当两个处理器同时访问并更新位于相同缓存行的不同数据时,由于处理器在写操作之前必须将缓存的状态更改为“独占”,所以两个处理器令对方缓存行失效的操作会产生“乒乓”效应,从而引发互联网络中大量的一致性通信,并可能引发额外的内存读取操作。</strong></font></p><h3 id="高速缓存一致性对性能的影响示例-自旋锁">高速缓存一致性对性能的影响示例:自旋锁</h3><p>典型的互斥锁可以通过AtomicExchange原语实现,如算法13.1所示。后续描述中我们均以首字母大写的方式来区分原子指令原语,我们同时也使用首字母小写的1oad和store来表示低级读写操作,并以此避免与应用程序和赋值器之间的读写接口混淆。锁的初始值应该为零,意味着未上锁。如果尝试加锁失败,处理器将在whie循环中自旋,因而称其为自旋锁。每次循环中,原子化的“读一修改-写”操作都会尝试独占其所在的高速缓存行,因而如果多处理器竞争该锁,高速缓存行将会出现“乒乓”效应,即使对于已经持有锁的处理器也不例外。更加糟糕的是,即使持有锁的处理器想要释放锁,其也需要与其他处理器竞争该高速缓存行的独占权。此种自旋锁实现方式被称为“检测并设置”锁(test-and- set lock)尽管它并未依赖我们后文将要介绍的 TestAndset原语。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 算法13.1基于 AtomicExchange原语的自旋锁</span><br><span class="line">exchangeLock(x):</span><br><span class="line">	while AtomicExchange(x, 1)=1</span><br><span class="line">	/*空*/</span><br><span class="line"></span><br><span class="line">exchangeUnlock(x):</span><br><span class="line">	*x &lt;- 0</span><br><span class="line"></span><br><span class="line">AtomicExchange(x, v):</span><br><span class="line">	atomic</span><br><span class="line">		old ← *X</span><br><span class="line">		*x &lt;- v</span><br><span class="line">	return old</span><br></pre></td></tr></table></figure><p>算法13.1所描述的自旋锁的实现方式会导致最严重的一种竞争情况出现,因而算法13.2所描述的“检测一检测并设置”锁(test-and-test-and-set lock)作为一种更加巧妙的改进版本,在许多程序中得到应用。其最大的改进之处在于第10行,算法在调用AtomicExchange方法之前先通过一般的读操作判断锁是否已被占用,因而此处的自旋操作只需访问处理器自身的(已经保持一致)的高速缓存,无需进一步访问总线。如果锁位于不可缓存(noncacheable)的内存中,则该线程可以使用空循环来等待,也可在检测之间插入硬件iale指令,如果等待时间稍长,则在两次检测之间的等待时间可以呈指数级别增加或者采用其他类似算法。如果等待时间过长,则线程可以请求操作系统的调度器介入并放弃剩余时间片,或者转而采取等待某一显式信号的方式,此时便要求锁的持有者在释放锁时发送信号。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//算法13.2基于AtomicExchange原语的“检测一检测并设置”自旋锁</span><br><span class="line">testAndTestAndSetExchange Lock(x):</span><br><span class="line">	while testAndExchange(x)=1</span><br><span class="line">		/*空*/</span><br><span class="line"></span><br><span class="line">testAndTestAndSetExchangeUnlock(x):</span><br><span class="line">	*x &lt;- 0</span><br><span class="line"></span><br><span class="line">testAndExchange(x):</span><br><span class="line">	while *x=1</span><br><span class="line">	/*空*/</span><br><span class="line">	return AtomicExchange(x, 1)</span><br></pre></td></tr></table></figure><h2 id="硬件内存一致性">硬件内存一致性</h2><p>我们假定共享内存可以提供与高速缓存相同的一致性(coherence)保障,即:不存在未完成的写操作。如果两个处理器读取内存中相同位置的值,所获取的值也是相同的。<font color="DeepPink"><strong>大多数硬件还可以进一步保证:如果两个处理器同时对内存的相同位置发起写操作,则其中的一个将先于另一个发生,同时所有处理器后续读取到的值都将是最后一次写入的值。另外,如果某一处理器已经读取到了最终的值,则在下一次写操作发生之前,其不可能读取到其他值。也就是说,针对内存中任何特定位置的写操作都是经过排序的,且在任意处理器看来,特定位置值的变化顺序都是相同的。</strong></font></p><p>但是,对于程序在多个位置的写入(或者读取)操作,硬件系统却不能保证程序发起操作的顺序与其在高速缓存或者内存中的生效顺序完全一致,更不能保证其他处理器能够以相同的顺序感知到这些地址的数据变更。也就是说,程序顺序(program order)不一定要与内存顺序(memory order)完全一致。读者可能不禁会问:为何如此?其中的含义是什么?前一个问题关乎于硬件和软件,概括来讲,不要求两者完全一致是出于性能考虑—严格一致性(consistency)要么会耗费更多的硬件资源,要么会降低性能,或者两者兼有。对于硬件而言,许多处理器会使用写缓冲区(write buffer/store buffer)来保存未完成的内存写入操作。写缓冲区本质上是一个&lt;地址,数据&gt;对组队列。正常情况下,写操作可能会有序执行,但如果某一后发写操作的目的地址已经存在于写缓冲区中,则硬件可能会将其合并到队列里尚未完成的写操作中,这便意味着写操作可能会出现“后发先至”的情况,即较晚的写操作可能会越过较早的、针对其他地址的写操作而立即在内存中生效。处理器的设计者会小心地确保处理器操作针对其自身的一致性,也就是说,如果处理器在读取某一位置的值时发现该位置存在未完成的写操作,则处理器要么通过直接硬件路径(速度较快但开销较大)来读取该值,要么必须等写缓冲区刷新完毕后再从高速缓存中读取该值。另一个可能导致程序操作被重排序的原因是高速缓存不命中。一旦读取过程中发生高速缓存不命中,许多处理器会将其跳过并继续执行后续指令,进而可能出现后发读/写操作越过先发读/写操作先执行完毕的情况。另外,对于使用写回机制的高速缓存,其中的数据只有在被淘汰或者显式刷新时才会写入内存,因此针对不同缓存行的写操作的执行顺序可能会出现大幅度调整。上述各种硬件方面的原因只是说明性的,但并非面面俱到。</p><p>由软件产生的重排序大多是由编译器造成的。例如,如果编译器已知两个引用指向的是同一地址,且两个引用的读取操作之间并无其他写操作会影响该值,则编译器可能直接使用其第一次读取到的值优化掉第二次读操作。更一般的情况是,如果编译器可以确保各变量之间均不存在别名关系(即不引用相同的内存地址),则其可以对这些变量的读写操作以任意方式重排序,因为不论采用何种顺序,最终的执行结果都是相同的(对于单处理器而言,且假定不存在线程切换)。读取结果复用以及重排序策略可以产生更高效的代码,且在大多数情况下并不影响语义,因而许多编程语言都允许这一策略。</p><p>从开发者的角度来看,程序顺序与内存顺序之间缺乏一致性显然是一个潜在的问题,但是从硬件实现者的角度来看,如此设计可以大幅提升性能并减少开销。</p><p>放宽一致性要求将会产生怎样的后果?第一,这可能导致程序的执行完全背离开发者的意图,也可能导致在完全一致性模型下可正常执行的代码在更加复杂的一致性模型下产生混乱的执行结果。第二,锁相关等技术要求硬件以某种方式确保对不同地址的访问能够有序执行。各种顺序模型必须能够区别出3种主要的访问原语:读(read)、写( write)、原子(atomic)操作。原子操作需要原子化的“读一修改-写”原语,该原语通常是条件性的,例如TestAndset。内存一致性对于依赖加载(dependent load)也十分重要,所谓依赖加载,即程序需要先从地址x加载数据,然后再从地址y加载数据,但第二次加载操作的地址y取决于地址x的加载结果。依赖加载的一个典型案例是沿着指针链进行追踪。在完全一致性之外,还存在着许多较弱的内存访问顺序模型,我们将选择其中较为常见的进行介绍。</p><h3 id="内存屏障与先于关系">内存屏障与先于关系</h3><p><font color="DeepPink"><strong>内存屏障(memory fence)是一种处理器操作,它可以阻止处理器对某些内存访问进行重排序。</strong></font>特别地,它可以避免某些访问指令在屏障之前发送(issue),也可以避免某些访问指令被延迟到屏障之后发送,或者两者皆可。例如,完全读内存屏障可以确保屏障之前的所有读操作都能先于屏障之后的读操作执行。</p><p>先于关系(happens- before)这一概念则更加规范化,它是指内存访问操作在存储中所应遵从的发生顺序。完全读内存屏障相当于是在每两个相邻读操作之间施加了先于关系。<font color="DeepPink"><strong>原子操作通常会为其内部的所有子操作施加完全内存屏障:所有较早的读、写、原子操作都必须先于较晚的读、写、原子操作发生。</strong></font>在先于关系之外还存在其他一些模型,例如获取一释放(acquire-release)语义。在该模型下,获取操作(acquire operation)(可以将其看作是获取锁)能够阻止较晚操作在该操作之前发生,但较早的读写操作则可以在获取操作之后发生;释放操作(release operation)与之完全对称:它能够阻止较早的操作在释放操作之后发生,但是较晩的操作则可以在释放操作之前发生。简而言之,处理器可以将获取一释放操作对之外的操作移动到其内部,但却不能将其内部的操作移动到外部。临界区(critical section)便可使用获取一释放模型来实现。</p><h3 id="内存一致性模型">内存一致性模型</h3><p>最强的内存一致性模型当属严格一致性(strict consitency),即所有的读、写、原子操作在整个系统中的任意位置都以相同的顺序发生(occur)。严格一致性意味着所有操作的发生顺序都满足先于关系,且这一顺序是由某一全局时钟决定的。严格一致性是最容易理解的种模型,这可能也是大多数开发者以为硬件系统所遵从的顺序,但这一模型很难高效地实现。稍弱的一种模型是顺序一致性(sequential consistency)模型,在该模型中,全局先于顺序只需要与每个处理器的程序顺序保持一致即可。相对于其他更加宽松的一致性模型,顺序一致性模型下的编程更加简单,因而规模较小的处理器通常会尝试达到或者接近顺序一致性的要求。弱一致性(weak consitency)会将所有原子操作当作完全屏障。上文所描述的获取释放模型通常被称为释放一致性(release consitency)模型。因果一致性(causal consistency)模型的强度介于顺序一致性和弱一致性之间,该模型要求程序所发起的读操作与其后续的写操作之间必须满足先于关系,其目的在于避免读操作对写操作所写入的值造成影响,即对于先读取某个值然后再将其写入内存的操作,因果一致性会确保它们之间的先于关系。宽松一致性(relaxed consistency)模型泛指所有比顺序一致性模型更弱的模型。</p><p><img data-src="/images/the-garbage-collection-handbook-the-art-of-automatic-memory-management/13.1%E5%86%85%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8F%AF%E8%83%BD%E7%9A%84%E9%87%8D%E6%8E%92%E5%88%97%E6%96%B9%E5%BC%8F.png" alt></p><h2 id="硬件原语">硬件原语</h2><h3 id="比较并交换">比较并交换</h3><p>即先判断内存地址的当前值,然后再尝试原子性地将其更新,该操作通常被称为“比较一比较并交换”(compare-then- compare-and-swap)。CompareAndSwap原语潜藏着一个微妙的陷阱,即在调用CompareAndSwap时,目标内存地址的值改变了数次,但该地址的当前值却与调用者之前获取到的值相等。某些情况下这可能不会出现问题,但在其他情况下,相同的值并不意味着相同的状态。例如在垃圾回收中,在经历两次半区复制回收之后,某一指针的目标对象很可能与其最初的目标对象完全不同。CompareAndswap原语无法探测到“某个值被修改,然后再被改回原值”的情况,即所谓的ABA问题(ABA problem)。</p><h3 id="加载链接-条件存储">加载链接/条件存储</h3><p>在LoadLinked和StoreConditionally原语中,处理器会记录LoadLinked原语所访问的地址,并使用处理器的一致性机制来探测所有针对该地址的更新操作,从而解决ABA问题。</p><p>LoadLinked/StoreConditionally原语还有另外一个特征需要注意:即使任何处理器都没有更新过保留地址的值, StoreConditionally原语也有可能出现假性失败。多种低级硬件状况可能导致假性失败,其中值得注意的是中断的出现,包括缺页陷阱、溢出陷阱、时钟中断、IO中断等,这些中断均需要由内核进行处理。这种失败通常不会成为问题,但是如果Loadlinked和StoreConditiona11y之间的某段代码总是引发陷阱,则StoreConditionallsy操作可能始终都会失败。</p><p>由于LoadLinked/StoreConditionally原语可以优雅地解决ABA问题,所以我们更加倾向于用其替代可能产生ABA问题的 CompareAndSwap原语。当然,我们也可为CompareAndswap原语关联一个计数器来解决ABA问题。</p><p>严格意义上讲,如果StoreConditionally原语所操作的并非之前保留的地址,则其最终结果可能是未定义的。但某些处理器在设计上便允许这种使用方式,这相当于提供了一种在某些场景下有用的、针对任意两个内存地址的原子操作。</p><h3 id="原子算术原语">原子算术原语</h3><p>我们也可使用AtomicAdd或FetchAndAdd原语来实现 AtomicIncrement和AtomicDecrement操作,且其返回值既可以是原始值,也可以是新值。另外,处理器在执行这些原语时通常会设置条件码(condition code),其值可以用于反映目标地址的值是否为零(或者原始值为零),也可反映其他一些信息。在垃圾回收领域, FetchAndAdd原语可以用于实现并发环境下的顺序分配(即阶跃指针分配),但更好的做法通常是为每个线程建立本地分配缓冲区。FetchAndAdd可以简单地用于从队列中添加或者移除元素的操作,但是对于环状缓冲区,还需要小心地处理回绕(wrap-around)问题。</p><p>这些原子算术原语的能力严格弱于CompareAndswap,同时也弱于LoadLinked/StoreConditionally(参见Herlihy and Shavit)。每种原语都存在一个可以用一致数(consensus number)来描述的特征,如果某个原语的一致数为k,意味着它可以解决k个线程之间的一致问题,但无法解决多于k个线程之间的一致问题。所谓一致问题,是指多处理器算法是否能达到如下要求:</p><ol><li>对于某个变量,每个线程均建议一个值;</li><li>所有线程针对某个值达成一致;</li><li>该变量的最终值为某个线程所建议的值;</li><li>所有线程均能够在有限步骤内完成操作,即算法必须满足无等待(wait-free)要求。</li></ol><p>对于所有的无条件设置原语(例如AtomicExchange)或者对相同值产生相同运算结果的更新原语(如AtomicIncrement与FetchAndAdd),其一致数均为2。而CompareAndSwap和LoadLinked/StoreConditionally的一致数则为∞,即它们能够以无等待的方式解决任意多个线程之间的一致问题。</p><p>无条件算术原语的一个潜在优势在于它们通常都会成功,而如果使用CompareAndSwap或者LoadLinked/StoreConditionally来模拟无条件算术原语,线程之间的竞争很可能导致“饥饿”现象的出现。</p><h3 id="更加强大的原语">更加强大的原语</h3><p>在我们描述过的硬件原语中,LoadLinked/StoreConditionally的通用性最强,也是针对单字的最强的原子更新语义。除此之外,允许对多个独立字进行原子更新的硬件原语则更加强大。在单字原语之外,某些处理器还支持双字原语,例如双字比较并交换,我们称之为CompareAndSwapWide/CompareAndSetWide。如果仅从概念上来看,该原语的强大之处没得到充分体现。但是,使用双字CompareAndSwap操作却可以轻松应对单字CompareAndswap无法解决的ABA问题,此时我们只需要将第二个字用作记录第一个字被更新次数的计数器。对于32位的字,计数器的值最多可以达到2<sup>32</sup>,因而基本上可以忽略计数器回绕可能带来的安全问题。支持对相邻两个64位的字进行原子更新的硬件原语则更加强大。因此,尽管CompareAndSwapWide在概念上与常规的CompareAndswap并无较大差别,但其在使用上却更加方便、更加高效。</p><p>尽管更新相邻两个字的原子操作原语十分有用,但如果其能够原子化地更新内存中任意两个(不相邻)字则会显得更加强大。 Motorola880000以及Sun的Rock处理器均提供了“双比较并交换”指令(compare-and-swap-two,也称double-compare-and-swap)。 CompareAndswap2的硬件实现较为复杂,因而目前尚无商业级别的处理器支持这一原语。 CompareAndSwap2可以泛化为通用的n路比较并交换(compare-and-swap-n,也称n-way-compare-and-swap),同理,也可对LoadLinkedStoreConditiona1ly原语进行泛化,由此得到的结果便是事务内存(transactional memory)。</p><h3 id="原子操作原语的开销">原子操作原语的开销</h3><p>开发者经常会错误地使用原子操作原语,其原因之一是他们知道原子操作的开销较大,因而会刻意避免使用原子操作,而另一种原因则是他们可能错误地使用了原子操作。我们曾经提到,有两个原因导致原子操作的开销较大:一是原子化的“读一修改一写”原语必须以独占方式访问相关的高速缓存行;二是在指令结束之前,处理器必须完成数据读取、计算新值、写入新值这一系列操作。现代处理器可能会使用多指令重叠(overlap)技术,但是如果后续操作强依赖于原子操作的结果,则必然会减少流水线中的指令条数。由于原子操作需要确保一致性,因而其通常会涉及总线甚至内存的访问,这通常会花费较多的指令周期。</p><p>另一个导致原子操作执行速度较慢的原因是,它们要么天然包括内存屏障语义,要么要求开发者在其开始和结束位置手动添加额外的内存屏障。这潜在削减了指令重叠与流水线技术所带来的性能优势,从而导致处理器很难隐藏这些原语访问总线或者内存的开销。</p><h2 id="前进保障">前进保障</h2><p>当多个线程之间竞争相同数据结构时(例如共享堆,或者回收器数据结构),确保整个系统能够正常往下执行尤为重要(特别是在实时环境中),我们将这一要求称为前进保障(progress guarantee)。了解不同硬件原语在前进保障方面的相对强度也十分必要,常见的前进保障级别从强到弱分别是:无等待、无障碍、无锁。对于并发算法而言,如果每个线程始终都可以向前执行(不论其他线程执行何种操作),则称其为无等待(wait-free)算法;如果在并发算法中,对于任意一个线程,只要其拥有足够长的独占式执行时间,便能够在有限步骤内完成操作,则称该算法为无障碍(obstruction-free)算法;如果算法永远可以保证某些线程能在有限步骤内完成操作,则称该算法为无锁(lock-free)算法。在真实系统中,前进保障通常是条件性的,例如,某一算法满足无等待要求的条件可能是存储空间尚未耗尽。Herlihy和Shavit对这些概念及其实现进行了详尽的论述。</p><p>无等待算法通常会引入线程互助的概念,也就是说,如果线程t2即将执行的操作可能会打断线程t1正在执行的、在一定程度上可以确定超前于线程n的操作,则线程t2将协助t1完成其工作,然后再开始执行自身工作。假设线程数量存在固定上界,且线程之间相互协助的工作单元或者对数据结构的操作也存在上界,则任何工作单元或者操作的完成步骤便都存在上界。但是,这一上界通常较大,且与较弱的前进保障相比,线程互助需要引入额外的数据结构与工作量,因而其操作时间通常相当长。对于较为简单的一致性场景,为其设计时间开销较小的无等待算法通常比较容易。从中我们可以看出,该算法满足解决N个线程的一致问题的所有标准,但是其空间开销正比于N。</p><p>与无等待要求相比,无障碍更容易实现,但是其可能需要调度器的协助。如果线程发现当前存在竞争,则它可以使用随机递增的时间退让策略来确保其他线程优先完成工作。也就是说,每当线程探测到竞争时,其首先会计算一个比上次退让时间更长的时间周期T,然后再从0~T之间选择某一随机值作为本次退让的时间。从概率上讲,对于较少出现竞争的场景,每个线程最终都会成功执行。</p><p>无锁要求的实现则更加简单,它只要求在任何情况下至少一个竞争者可以继续往下执行,即使其他线程可能会永久性地等待下去。</p><h2 id="工作共享与结束检测">工作共享与结束检测</h2><h3 id="汇聚屏障">汇聚屏障</h3><p>并发回收或者并行回收中另一种常见的同步机制是要求所有回收线程到达算法的某点(基本上就是某一回收阶段的结束点),然后再继续往下执行。一般情况下,上述任意种结束检测算法都可以胜任这一场景的要求。另一种常见的场景是:算法在某一阶段的工作并不存在任何形式的工作共享或者负载均衡,但其仍要求所有线程都到达指定点,即汇聚屏障(rendezvous barrier)。</p><h2 id="并发数据结构">并发数据结构</h2><p>有多种通用实现策略可供开发者在构建并发数据结构时选择,这些策略在并发程度方面从最低到最高(通常也是从最简单到最复杂)分别如下:</p><ul><li>粗粒度锁(coarse-grained locking):使用一个“大”锁来控制整个数据结构的访问。</li><li>细粒度锁(fine-grained locking):该方案为较大数据结构中的每个元素维护独立的锁,例如为链表或树中的每个节点维护一个锁。<font color="DeepPink"><strong>如果各线程对数据结构的访问与更新足够分散,则该策略可以显著提升并发程度。</strong></font>该策略通常需要考虑一个问题,即如果某一操作会对多个元素加锁,则其必须保证没有其他相同操作(或者任何其他操作)会以相反的顺序对相同元素进行加锁,否则将导致死锁的产生。一种通用的解决方案是要求所有操作在访问(单链表或者树中的)元素时遵从相同的方向,即锁联结(lock coupling):某一操作先对节点A加锁,然后再对A所指向的节点B加锁,接着再释放节点A的锁并对节点B所指向的节点C加锁,以此类推。使用这一逐步推进策略来遍历数据结构可以确保后发线程无法超越先发的线程,同时也可以确保在链表/树中插入/删除元素操作的安全性。<font color="DeepPink"><strong>细粒度锁的一个潜在缺陷是,对不同元素多次加解锁可能会给共享总线或者存储带来一定开销,进而掩盖了相对于粗粒度锁的优势。</strong></font></li><li>乐观锁(optimistic locking):该方案对细粒度锁进行了改进,<font color="DeepPink"><strong>即线程在对数据结构进行遍历时先不加锁,直到其找到合适元素时才尝试对其进行加锁。但在从发现合适元素到加锁成功的过程中,该元素可能已被其他并发线程修改,因而线程在加锁完成后需要再次对该元素进行校验。如果校验失败,则其需要释放锁并继续查找。这种尽量将加锁操作延迟、直到迫不得已时才加锁的策略可以减少开销并提升并发能力。乐观锁在大多数场景下都具有较高的性能,但如果频繁发生更新冲突,</strong></font></li><li>懒惰更新(lazy update):即使采用乐观锁,只读操作仍需要对其所读取的元素加锁,这不仅会成为提升并发程度的瓶颈,还可能在只读操作中引入写操作(即加解锁)。为此我们可以设计出一种数据结构,在该结构中只读操作无需加锁,代价是更新操作的复杂度稍有提高。<font color="DeepPink"><strong>一般来讲,懒惰更新策略中的写操作需要先达到其在“逻辑上”的目标(前提是不影响其他线程的并发访问),然后再进一步执行真正的更新操作,并确保数据结构回归正常状态。</strong></font>我们可以通过一个例子来理解懒惰更新的含义:对于以链表方式实现的集合, remove操作首先需要(在逻辑上)将待移除元素打上deleted标记,然后再将其前一个节点的指针重定向从而真正实现节点的移除。为避免并发更新可能带来的问题,所有操作都需要在持有相关元素锁的前提下执行。remove操作必须依照先标记再移除的顺序执行,这样才能确保其他线程能够在不加锁的情况下正确进行读操作。向链表中插入元素的操作只需要更新数据结构中的next指针,因而只需要一次更新操作(即无需事先设置标记),当然,这一操作同样必须在持有相关元素锁的前提下执行。</li><li>非阻塞(non-blocking):在非阻塞策略中,对数据结构的所有操作均无需使用锁,仅依赖原子更新原语便可完成数据结构的状态变更。一般来说,状态变更操作通常都会存在某些特殊的原子更新事件,这些事件的发生点即为该操作的线性化点。与此相比,基于锁的策略则需要引入临界区来标识线性化“点”。非阻塞策略的并发能力可以通过前进保障来衡量,无锁实现可能允许部分线程出现饥饿;无障碍实现中的每个线程可能需要足够长的时间进行独占式操作,才能确保算法整体往下执行;无等待实现可以确保所有线程都能正确往下执行。</li></ul><h2 id="需要考虑的问题-v3">需要考虑的问题</h2><p>平台支持哪些原子更新原语?尽管LoadLinked/StoreConditionally原语便于使用且更加高效,但大多数流行系统仅支持 CompareAndSwap或者等价原语,后者可能会遇到ABA问题,但该问题也可通过某种方式来避免。或许在不久的将来,事务内存将逐渐实用化。</p><p>算法需要达到何种级别的前进保障要求?较弱的前进保障更容易实现,也更易于推导。对于访问量较低的数据结构,直接进行加锁可能会更加合适,因为与具有更强前进保障级别的无锁算法相比,加锁不仅容易实现,而且更容易正确地实现。另外,即使在某些已发布的、绝大多数场景满足无等待要求的系统中,某些极端情况的处理仍会使用更加简单的实现技术,将这些非关键场景无等待化并不具有太大价值。</p><h1>并行垃圾回收</h1><h2 id="并行垃圾回收分类">并行垃圾回收分类</h2><p>不论是对于哪种情况,我们均需要关注算法如何实现回收工作的获取(acquire)、执行(perform)、生成(generate),这3种操作的设计与实现决定了算法所需同步操作的类型、单个回收线程的负载粒度,以及在多个处理器之间进行负载均衡的策略行垃圾回收算法大致可以划分为两大类,即以处理器为中心(processor-centric)的并行算法和以内存为中心(memory- centrIc)的并行算法。在以处理器为中心的算法中,线程所获取的工作通常大小不等,且线程之间通常会存在工作窃取行为。该策略通常不关注线程所处理对象的位置,但通过前面的章节我们知道,即使是在单处理器环境下,局部性都会对处理性能产生显著影响,而对于非一致内存或者异构系统而言,局部性的作用则更加重要。以内存为中心的算法会更多考虑局部性因素,此类算法通常会针对堆中连续内存块进行操作,并从共享工作缓冲区池中获取工作包(或者将工作包释放到全局工作池中),工作包的大小通常固定。绝大多数并行复制式回收器均使用这一策略。</p><p>最后让我们关注并行回收的结束。回收线程不仅会尝试获取工作,而且还会进一步动态地生成新的工作。因此,简单判定共享工作池是否为空通常不足以断定回收过程是否结束,因为活动线程可能还会向工作池中加入新的任务。</p><blockquote><p>14章及以后，只是泛读了一下</p></blockquote>]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>GC</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA 个人常用插件</title>
    <url>/idea-plugin.html</url>
    <content><![CDATA[<blockquote><p>IDEA 个人常用插件整理，持续更新中</p></blockquote><a id="more"></a><h1>mybatis-lite</h1><p>根据数据库表自动生成代码<br>git地址：<a href="https://github.com/mustfun/mybatis-lite" target="_blank" rel="noopener">https://github.com/mustfun/mybatis-lite</a></p><h1>MyBatis Log Plugin</h1><p>把mybatis输出的日志还原成完整的sql语句<br>git地址：<a href="https://github.com/kookob/mybatis-log-plugin" target="_blank" rel="noopener">https://github.com/kookob/mybatis-log-plugin</a></p><h1>MyBatisX</h1><p>mapper和xml互相跳转<br><a href="https://baomidou.com/pages/ba5b24/" target="_blank" rel="noopener">https://baomidou.com/pages/ba5b24/</a><br>git地址：<a href="https://github.com/baomidou/MybatisX" target="_blank" rel="noopener">https://github.com/baomidou/MybatisX</a></p>]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>码出高效：Java 开发手册</title>
    <url>/alibaba-p3c.html</url>
    <content><![CDATA[<blockquote><p>开发规范</p></blockquote><a id="more"></a><p>在线PDF版本：<a href="/attachments/阿里巴巴Java开发手册（华山版）.pdf" target="_blank">阿里巴巴Java开发手册（华山版）.pdf</a></p><p><a href="https://github.com/alibaba/p3c" target="_blank" rel="noopener">https://github.com/alibaba/p3c</a></p>]]></content>
      <categories>
        <category>编码规范</category>
      </categories>
      <tags>
        <tag>编码规范</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP/IP详解 卷1：协议 笔记</title>
    <url>/tcp-ip-illustrated-volume-1-the-protocols.html</url>
    <content><![CDATA[<p>本文整理自：《TCP/IP详解 卷1:协议》<br>作者：W. Richard Stevens</p><a id="more"></a><p><font color="DeepPink"><strong>一个bit是二进制中的最小单位，代表一个0或1的位置。 bit是位。 Byte是字节。 1Byte=8bit。</strong></font></p><h1>概述</h1><h2 id="分层">分层</h2><p>网络协议通常分不同层次进行开发，每一层分别负责不同的通信功能。一个协议族，比如TCP/IP，是一组不同层次上的多个协议的组合。TCP/IP通常被认为是一个四层协议系统，如图1-1所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/TCPIP%E5%8D%8F%E8%AE%AE%E6%97%8F%E7%9A%84%E5%9B%9B%E4%B8%AA%E5%B1%82%E6%AC%A1.png" alt></p><p>每一层负责不同的功能：<br>1)<font color="DeepPink"><strong>链路层，有时也称作数据链路层或网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。</strong></font><br>2)<font color="DeepPink"><strong>网络层，有时也称作互联网层，处理分组在网络中的活动，例如分组的选路。</strong></font>在TCP/IP协议族中，网络层协议包括IP协议（网际协议），ICMP协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议）。<br>3)<font color="DeepPink"><strong>运输层主要为两台主机上的应用程序提供端到端的通信。</strong></font>在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。而另一方面，UDP则为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。这两种运输层协议分别在不同的应用程序中有不同的用途，这一点将在后面看到。<br>4)应用层负责处理特定的应用程序细节。几乎各种不同的TCP/IP实现都会提供下面这些通用的应用程序：</p><ul><li>Telnet 远程登录。</li><li>FTP 文件传输协议。</li><li>SMTP 简单邮件传送协议。</li><li>SNMP 简单网络管理协议。</li></ul><p>在TCP/IP协议族中，网络层IP提供的是一种不可靠的服务。也就是说，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。而另一方面，TCP在不可靠的IP层上提供了一个可靠的运输层。为了提供这种可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。由此可见，运输层和网络层分别负责不同的功能。</p><p>连接网络的另一个途径是使用网桥。网桥是在链路层上对网络进行互连，而路由器则是在网络层上对网络进行互连。网桥使得多个局域网（LAN）组合在一起，这样对上层来说就好像是一个局域网。</p><h2 id="TCP-IP的分层">TCP/IP的分层</h2><p>在TCP/IP协议族中，有很多种协议。图1-4给出了本书将要讨论的其他协议。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/TCPIP%E5%8D%8F%E8%AE%AE%E6%97%8F%E4%B8%AD%E4%B8%8D%E5%90%8C%E5%B1%82%E6%AC%A1%E7%9A%84%E5%8D%8F%E8%AE%AE.png" alt></p><p>IP是网络层上的主要协议，同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。</p><p>ICMP是IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。</p><p>IGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。</p><p>ARP（地址解析协议）和RARP（逆地址解析协议）是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。</p><h2 id="互联网地址">互联网地址</h2><p>互联网上的每个接口必须有一个唯一的Internet地址（也称作IP地址）。IP地址长32bit。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E4%BA%94%E7%B1%BB%E4%BA%92%E8%81%94%E7%BD%91%E5%9C%B0%E5%9D%80.png" alt></p><p>这些32位的地址通常写成四个十进制的数，其中每个整数对应一个字节。这种表示方法称作“点分十进制表示法（Dotted decimal notation）”。</p><p>区分各类地址的最简单方法是看它的第一个十进制整数。图1-6列出了各类地址的起止范围，其中第一个十进制整数用加黑字体表示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E5%90%84%E7%B1%BBIP%E5%9C%B0%E5%9D%80%E7%9A%84%E8%8C%83%E5%9B%B4.png" alt></p><p>需要再次指出的是，多接口主机具有多个IP地址，其中每个接口都对应一个IP地址。由于互联网上的每个接口必须有一个唯一的IP地址，因此必须要有一个管理机构为接入互联网的网络分配IP地址。这个管理机构就是互联网络信息中心（Internet Network Information Centre），称作InterNIC。InterNIC只分配网络号。主机号的分配由系统管理员来负责。</p><p>有三类IP地址：单播地址（目的为单个主机）、广播地址（目的端为给定网络上的所有主机）以及多播地址（目的端为同一组内的所有主机）。</p><h2 id="封装">封装</h2><p>当应用程序用TCP传送数据时，数据被送入协议栈中，然后逐个通过每一层直到被当作一串比特流送入网络。其中每一层对收到的数据都要增加一些首部信息（有时还要增加尾部信息），该过程如图1-7所示。TCP传给IP的数据单元称作TCP报文段或简称为TCP段（TCP segment）。IP传给网络接口层的数据单元称作IP数据报(IP datagram)。通过以太网传输的比特流称作帧(Frame)。</p><p>图1-7中帧头和帧尾下面所标注的数字是典型以太网帧首部的字节长度。</p><p>以太网数据帧的物理特性是其长度必须在46～1500字节之间。</p><blockquote><p>更准确地说，图1-7中IP和网络接口层之间传送的数据单元应该是分组（packet）。分组既可以是一个IP数据报，也可以是IP数据报的一个片（fragment）。</p></blockquote><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%85%A5%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%97%B6%E7%9A%84%E5%B0%81%E8%A3%85%E8%BF%87%E7%A8%8B.png" alt></p><p>UDP数据与TCP数据基本一致。唯一的不同是UDP传给IP的信息单元称作UDP数据报（UDP datagram），而且UDP的首部长为8字节。</p><p><font color="DeepPink"><strong>由于TCP、UDP、ICMP和IGMP都要向IP传送数据，因此IP必须在生成的IP首部中加入某种标识，以表明数据属于哪一层。为此，IP在首部中存入一个长度为8 bit的数值，称作协议域。1表示为ICMP协议，2表示为IGMP协议，6表示为TCP协议，17表示为UDP协议。</strong></font></p><p>类似地，许多应用程序都可以使用TCP或UDP来传送数据。运输层协议在生成报文首部时要存入一个应用程序的标识符。TCP和UDP都用一个16 bit的端口号来表示不同的应用程序。TCP和UDP把源端口号和目的端口号分别存入报文首部中。</p><p>网络接口分别要发送和接收IP、ARP和RARP数据，因此也必须在以太网的帧首部中加入某种形式的标识，以指明生成数据的网络层协议。为此，以太网的帧首部也有一个16 bit的帧类型域。</p><h2 id="分用">分用</h2><p><font color="DeepPink"><strong>当目的主机收到一个以太网数据帧时，数据就开始从协议栈中由底向上升，同时去掉各层协议加上的报文首部。</strong></font>每层协议盒都要去检查报文首部中的协议标识，以确定接收数据的上层协议。这个过程称作分用（Demultiplexing），图1-8显示了该过程是如何发生的。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E4%BB%A5%E5%A4%AA%E7%BD%91%E6%95%B0%E6%8D%AE%E5%B8%A7%E7%9A%84%E5%88%86%E7%94%A8%E8%BF%87%E7%A8%8B.png" alt></p><h2 id="小结">小结</h2><p>TCP/IP协议族分为四层：链路层、网络层、运输层和应用层，每一层各有不同的责任。在TCP/IP中，网络层和运输层之间的区别是最为关键的：<font color="DeepPink"><strong>网络层（IP）提供点到点的服务，而运输层（TCP和UDP）提供端到端的服务。</strong></font></p><h1>链路层</h1><p>从图1-4中可以看出，在TCP/IP协议族中，链路层主要有三个目的：（1）为IP模块发送和接收IP数据报；（2）为ARP模块发送ARP请求和接收ARP应答；（3）为RARP发送RARP请求和接收RARP应答。</p><h2 id="环回接口">环回接口</h2><p>大多数的产品都支持环回接口（Loopback Interface），以允许运行在同一台主机上的客户程序和服务器程序通过TCP/IP进行通信。A类网络号127就是为环回接口预留的。根据惯例，大多数系统把IP地址127.0.0.1分配给这个接口，并命名为localhost。一个传给环回接口的IP数据报不能在任何网络上出现。</p><h1>IP：网际协议</h1><h2 id="引言">引言</h2><p>IP是TCP/IP协议族中最为核心的协议。所有的TCP、UDP、ICMP及IGMP数据都以IP数据报格式传输（见图1-4）。</p><p>不可靠（unreliable）的意思是它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP）。</p><p>无连接（connectionless）这个术语的意思是IP并不维护任何关于后续数据报的状态信息。每个数据报的处理是相互独立的。这也说明，IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达。</p><h2 id="IP首部">IP首部</h2><p>IP数据报的格式如图3-1所示。普通的IP首部长为20个字节，除非含有选项字段。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%A0%BC%E5%BC%8F%E5%8F%8A%E9%A6%96%E9%83%A8%E4%B8%AD%E7%9A%84%E5%90%84%E5%AD%97%E6%AE%B5.png" alt></p><p>分析图3-1中的首部。最高位在左边，记为0 bit；最低位在右边，记为31 bit。</p><p>4个字节的32 bit值以下面的次序传输：首先是0～7 bit，其次8～15 bit，然后16～23 bit，最后是24~31 bit。这种传输次序称作bigendian字节序。由于TCP/IP首部中所有的二进制整数在网络中传输时都要求以这种次序，因此它又称作网络字节序。以其他形式存储二进制整数的机器，如little endian格式，则必须在传输数据之前把首部转换成网络字节序。</p><p>目前的协议版本号是4，因此IP有时也称作IPv4。</p><p>首部长度指的是首部占32 bit字的数目，包括任何选项。由于它是一个4比特字段，因此首部最长为60个字节。普通IP数据报（没有任何选择项）字段的值是5。</p><p>总长度字段是指整个IP数据报的长度，以字节为单位。利用首部长度字段和总长度字段，就可以知道IP数据报中数据内容的起始位置和长度。</p><p>总长度字段是IP首部中必要的内容，因为一些数据链路（如以太网）需要填充一些数据以达到最小长度。尽管以太网的最小帧长为46字节，但是I P数据可能会更短。如果没有总长度字段，那么IP层就不知道46字节中有多少是IP数据报的内容。</p><p>标识字段唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加 1。</p><p>TTL（time-to-live）生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1。当该字段的值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。</p><p>首部检验和字段是根据IP首部计算的检验和码。它不对首部后面的数据进行计算。ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。</p><p>为了计算一份数据报的IP检验和，首先把检验和字段置为 0。然后，对首部中每个16 bit进行二进制反码求和（整个首部看成是由一串 16 bit的字组成），结果存在检验和字段中。当收到一份IP数据报后，同样对首部中每个 16 bit进行二进制反码的求和。由于接收方在计算过程中包含了发送方存在首部中的检验和，因此，如果首部在传输过程中没有发生任何差错，那么接收方计算的结果应该为全 1。如果结果不是全1（即检验和错误），那么IP就丢弃收到的数据报。但是不生成差错报文，由上层去发现丢失的数据报并进行重传。</p><p>选项字段一直都是以 32 bit作为界限，在必要的时候插入值为 0的填充字节。这样就保证IP首部始终是32 bit的整数倍（这是首部长度字段所要求的）。</p><h2 id="IP路由选择">IP路由选择</h2><p>从概念上说，IP路由选择是简单的，特别对于主机来说。如果目的主机与源主机直接相连（如点对点链路）或都在一个共享网络上（以太网或令牌环网），那么IP数据报就直接送到目的主机上。否则，主机把数据报发往一默认的路由器上，由路由器来转发该数据报。大多数的主机都是采用这种简单机制。</p><p>在一般的体制中，IP可以从TCP、UDP、ICMP和IGMP接收数据报（即在本地生成的数据报）并进行发送，或者从一个网络接口接收数据报（待转发的数据报）并进行发送。IP层在内存中有一个路由表。当收到一份数据报并进行发送时，它都要对该表搜索一次。当数据报来自某个网络接口时，IP首先检查目的IP地址是否为本机的IP地址之一或者IP广播地址。如果确实是这样，数据报就被送到由IP首部协议字段所指定的协议模块进行处理。如果数据报的目的不是这些地址，那么（1）如果IP层被设置为路由器的功能，那么就对数据报进行转发（也就是说，像下面对待发出的数据报一样处理）；否则（2）数据报被丢弃。</p><p>路由表中的每一项都包含下面这些信息：</p><ul><li>目的IP地址。它既可以是一个完整的主机地址，也可以是一个网络地址，由该表目中的标志字段来指定（如下所述）。主机地址有一个非0的主机号（见图1-5），以指定某一特定的主机，而网络地址中的主机号为0，以指定网络中的所有主机（如以太网，令牌环网）。</li><li>下一站（或下一跳）路由器（next-hoprouter）的IP地址，或者有直接连接的网络IP地址。下一站路由器是指一个在直接相连网络上的路由器，通过它可以转发数据报。下一站路由器不是最终的目的，但是它可以把传送给它的数据报转发到最终目的。</li><li>标志。其中一个标志指明目的IP地址是网络地址还是主机地址，另一个标志指明下一站路由器是否为真正的下一站路由器，还是一个直接相连的接口。</li><li>为数据报的传输指定一个网络接口。</li></ul><p>IP路由选择是逐跳地（hop-by-hop）进行的。从这个路由表信息可以看出，IP并不知道到达任何目的的完整路径（当然，除了那些与主机直接相连的目的）。所有的IP路由选择只为数据报传输提供下一站路由器的IP地址。它假定下一站路由器比发送数据报的主机更接近目的，而且下一站路由器与该主机是直接相连的。</p><p>IP路由选择主要完成以下这些功能：</p><ol><li>搜索路由表，寻找能与目的IP地址完全匹配的表目（网络号和主机号都要匹配）。如果找到，则把报文发送给该表目指定的下一站路由器或直接连接的网络接口（取决于标志字段的值）。</li><li>搜索路由表，寻找能与目的网络号相匹配的表目。如果找到，则把报文发送给该表目指定的下一站路由器或直接连接的网络接口（取决于标志字段的值）。目的网络上的所有主机都可以通过这个表目来处置。例如，一个以太网上的所有主机都是通过这种表目进行寻径的。这种搜索网络的匹配方法必须考虑可能的子网掩码。</li><li>搜索路由表，寻找标为“默认（default）”的表目。如果找到，则把报文发送给该表目指定的下一站路由器。</li></ol><p>如果上面这些步骤都没有成功，那么该数据报就不能被传送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或“网络不可达”的错误。完整主机地址匹配在网络号匹配之前执行。只有当它们都失败后才选择默认路由。默认路由，以及下一站路由器发送的ICMP间接报文（如果我们为数据报选择了错误的默认路由），是IP路由选择机制中功能强大的特性。</p><p>为一个网络指定一个路由器，而不必为每个主机指定一个路由器，这是IP路由选择机制的另一个基本特性。这样做可以极大地缩小路由表的规模，比如Internet上的路由器有只有几千个表目，而不会是超过100万个表目。</p><h2 id="子网寻址">子网寻址</h2><p>现在所有的主机都要求支持子网编址（RFC 950 [Mogul and Postel 1985]）。不是把IP地址看成由单纯的一个网络号和一个主机号组成，而是把主机号再分成一个子网号和一个主机号。</p><p>这样做的原因是因为A类和B类地址为主机号分配了太多的空间，可分别容纳的主机数为2^24 -2和2^16 -2。事实上，在一个网络中人们并不安排这么多的主机（各类IP地址的格式如图1-5所示）。由于全0或全1的主机号都是无效的，因此我们把总数减去 2。</p><h2 id="子网掩码">子网掩码</h2><p>任何主机在引导时进行的部分配置是指定主机IP地址。大多数系统把IP地址存在一个磁盘文件里供引导时读用。</p><p>除了IP地址以外，主机还需要知道有多少比特用于子网号及多少比特用于主机号。这是在引导过程中通过子网掩码来确定的。这个掩码是一个32 bit的值，其中值为1的比特留给网络号和子网号，为0的比特留给主机号。图3-7是一个B类地址的两种不同的子网掩码格式。第一个例子是noao.edu网络采用的子网划分方法，子网号和主机号都是8 bit宽。第二个例子是一个B类地址划分成10 bit的子网号和6 bit的主机号。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84B%E7%B1%BB%E5%9C%B0%E5%9D%80%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt></p><p>给定IP地址和子网掩码以后，主机就可以确定IP数据报的目的是：(1)本子网上的主机；(2)本网络中其他子网中的主机；(3)其他网络上的主机。如果知道本机的IP地址，那么就知道它是否为A类、B类或C类地址(从IP地址的高位可以得知)，也就知道网络号和子网号之间的分界线。而根据子网掩码就可知道子网号与主机号之间的分界线。</p><p>将来或许会有更多的主机和网络，但是为了不让主机跨越不同的网络就得使用不同的子网号。我们的解决方法是把子网号从8 bit扩充到11 bit，把主机号从8 bit减为5 bit。这就叫作变长子网，因为140.252网络中的大多数子网都采用8 bit子网掩码，而我们的子网却采用11 bit的子网掩码。</p><p>作者子网中的IP地址结构如图3-11所示，11位子网号中的前8bit始终是13。在剩下的3 bit中，我们用二进制001表示以太网，010表示点对点SLIP链路。这个变长子网掩码在140.252网络中不会给其他主机和路由器带来问题—只要目的是子网140.252.13的所有数据报都传给路由器sun（IP地址是140.252.1.29），如图3-11所示。如果sun知道子网13中的主机有11bit子网号，那么一切都好办了。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91.png" alt></p><p>140.252.13子网中的所有接口的子网掩码是255.255.255.224，或0xffffffe0。这表明最右边的5bit留给主机号，左边的27bit留给网络号和子网号。</p><h2 id="ifconfig命令">ifconfig命令</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ifconfig -a</span><br><span class="line">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class="line">        ether 02:42:a5:fc:a8:b0  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 1803610  bytes 751152220 (716.3 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1715508  bytes 1981302829 (1.8 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.21.0.3  netmask 255.255.240.0  broadcast 172.21.15.255</span><br><span class="line">        ether 52:54:00:9f:9a:52  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 25626090  bytes 6434619435 (5.9 GiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 27765770  bytes 6026731597 (5.6 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 2  bytes 272 (272.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 2  bytes 272 (272.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">veth7423cb0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        ether 0a:19:63:74:aa:32  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 1939  bytes 158399 (154.6 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1810  bytes 2114402 (2.0 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>环回接口被认为是一个网络接口。它是一个 A类地址，没有进行子网划分。</p><h2 id="小结-v2">小结</h2><p>在进行路由选择决策时，主机和路由器都使用路由表。在表中有三种类型的路由：特定主机型、特定网络型和默认路由型。路由表中的表目具有一定的优先级。在选择路由时，主机路由优先于网络路由，最后在没有其他可选路由存在时才选择默认路由。</p><p>IP路由选择是通过逐跳来实现的。数据报在各站的传输过程中目的 IP地址始终不变，但是封装和目的链路层地址在每一站都可以改变。大多数的主机和许多路由器对于非本地网络的数据报都使用默认的下一站路由器。</p><h1>ARP：地址解析协议</h1><h2 id="引言-v2">引言</h2><p>当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据 48 bit的以太网地址来确定目的接口的。设备驱动程序从不检查 IP数据报中的目的IP地址。</p><p>地址解析为这两种不同的地址形式提供映射： 32 bit的IP地址和数据链路层使用的任何类型的地址。</p><p>ARP为IP地址到对应的硬件地址之间提供动态映射。我们之所以用动态这个词是因为这个过程是自动完成的，一般应用程序用户或系统管理员不必关心。</p><p>RARP是被那些没有磁盘驱动器的系统使用（一般是无盘工作站或X终端），它需要系统管理员进行手工设置。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AEARP%E5%92%8CRARP.png" alt></p><h2 id="一个例子">一个例子</h2><p>任何时候我们敲入下面这个形式的命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ftp bsdi</span><br></pre></td></tr></table></figure><p>都会进行以下这些步骤。这些步骤的序号如图4-2所示。</p><ol><li>应用程序FTP客户端调用函数gethostbyname(3)把主机名（bsdi）转换成32bit的IP地址。这个函数在DNS（域名系统）中称作解析器，我们将在第14章对它进行介绍。这个转换过程或者使用DNS，或者在较小网络中使用一个静态的主机文件（/etc/hosts）。</li><li>FTP客户端请求TCP用得到的IP地址建立连接。</li><li>TCP发送一个连接请求分段到远端的主机，即用上述IP地址发送一份IP数据报。</li><li>如果目的主机在本地网络上（如以太网、令牌环网或点对点链接的另一端），那么IP数据报可以直接送到目的主机上。如果目的主机在一个远程网络上，那么就通过IP选路函数来确定位于本地网络上的下一站路由器地址，并让它转发IP数据报。在这两种情况下，IP数据报都是被送到位于本地网络上的一台主机或路由器。</li><li>假定是一个以太网，那么发送端主机必须把32bit的IP地址变换成48bit的以太网地址。从逻辑Internet地址到对应的物理硬件地址需要进行翻译。这就是ARP的功能。ARP本来是用于广播网络的，有许多主机或路由器连在同一个网络上。</li><li>ARP发送一份称作ARP请求的以太网数据帧给以太网上的每个主机。这个过程称作广播，如图4-2中的虚线所示。ARP请求数据帧中包含目的主机的IP地址（主机名为bsdi），其意思是“如果你是这个IP地址的拥有者，请回答你的硬件地址。”</li></ol><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E5%BD%93%E7%94%A8%E6%88%B7%E8%BE%93%E5%85%A5%E5%91%BD%E4%BB%A4ftp%E4%B8%BB%E6%9C%BA%E5%90%8D%E6%97%B6ARP%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt></p><ol start="7"><li>目的主机的ARP层收到这份广播报文后，识别出这是发送端在寻问它的IP地址，于是发送一个ARP应答。这个ARP应答包含IP地址及对应的硬件地址。</li><li>收到ARP应答后，使ARP进行请求—应答交换的IP数据报现在就可以传送了。</li><li>发送IP数据报到目的主机。</li></ol><p><font color="DeepPink"><strong>在ARP背后有一个基本概念，那就是网络接口有一个硬件地址（一个48bit的值，标识不同的以太网或令牌环网络接口）。在硬件层次上进行的数据帧交换必须有正确的接口地址。但是，TCP/IP有自己的地址：32bit的IP地址。知道主机的IP地址并不能让内核发送一帧数据给主机。内核（如以太网驱动程序）必须知道目的端的硬件地址才能发送数据。ARP的功能是在32bit的IP地址和采用不同网络技术的硬件地址之间提供动态映射。</strong></font></p><h2 id="ARP高速缓存">ARP高速缓存</h2><p>ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存。这个高速缓存存放了最近Internet地址到硬件地址之间的映射记录。高速缓存中每一项的生存时间一般为20分钟，起始时间从被创建时开始算起。</p><p>我们可以用arp命令来检查ARP高速缓存。参数-a的意思是显示高速缓存中所有的内容。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# arp -a</span><br><span class="line">? (169.254.0.15) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.0.3) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (172.17.0.4) at 02:42:ac:11:00:04 [ether] on docker0</span><br><span class="line">? (169.254.0.2) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.0.4) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (172.17.0.3) at 02:42:ac:11:00:03 [ether] on docker0</span><br><span class="line">? (172.17.0.2) at 02:42:ac:11:00:02 [ether] on docker0</span><br><span class="line">? (169.254.0.23) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.128.3) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">? (169.254.128.5) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">gateway (172.21.0.1) at fe:ee:0b:ca:e5:69 [ether] on eth0</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>48 bit的以太网地址用6个十六进制的数来表示，中间以冒号隔开。</p><h2 id="ARP的分组格式">ARP的分组格式</h2><p>在以太网上解析IP地址时，ARP请求和应答分组的格式如图4-3所示（ARP可以用于其他类型的网络，可以解析IP地址以外的地址。紧跟着帧类型字段的前四个字段指定了最后四个字段的类型和长度）。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E7%94%A8%E4%BA%8E%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84ARP%E8%AF%B7%E6%B1%82%E6%88%96%E5%BA%94%E7%AD%94%E5%88%86%E7%BB%84%E6%A0%BC%E5%BC%8F.png" alt></p><p>以太网报头中的前两个字段是以太网的源地址和目的地址。目的地址为全 1的特殊地址是广播地址。电缆上的所有以太网接口都要接收广播的数据帧。</p><p>两个字节长的以太网帧类型表示后面数据的类型。对于ARP请求或应答来说，该字段的值为0x0806。</p><p>形容词hardware(硬件)和protocol(协议)用来描述ARP分组中的各个字段。例如，一个ARP请求分组询问协议地址（这里是IP地址）对应的硬件地址（这里是以太网地址）。</p><p>硬件类型字段表示硬件地址的类型。它的值为1即表示以太网地址。协议类型字段表示要映射的协议地址类型。它的值为0x0800即表示IP地址。它的值与包含IP数据报的以太网数据帧中的类型字段的值相同，这是有意设计的。</p><p>接下来的两个1字节的字段，硬件地址长度和协议地址长度分别指出硬件地址和协议地址的长度，以字节为单位。对于以太网上IP地址的ARP请求或应答来说，它们的值分别为6和4。</p><p>操作字段指出四种操作类型，它们是ARP请求（值为1）、ARP应答（值为2）、RARP请求（值为3）和RARP应答（值为4）（我们在第5章讨论RARP）。这个字段必需的，因为ARP请求和ARP应答的帧类型字段值是相同的。</p><p>接下来的四个字段是发送端的硬件地址（在本例中是以太网地址）、发送端的协议地址（IP地址）、目的端的硬件地址和目的端的协议地址。注意，这里有一些重复信息：在以太网的数据帧报头中和ARP请求数据帧中都有发送端的硬件地址。</p><p>对于一个ARP请求来说，除目的端硬件地址外的所有其他的字段都有填充值。当系统收到一份目的端为本机的ARP请求报文后，它就把硬件地址填进去，然后用两个目的端地址分别替换两个发送端地址，并把操作字段置为2，最后把它发送回去。</p><h2 id="ARP代理">ARP代理</h2><p>如果ARP请求是从一个网络的主机发往另一个网络上的主机，那么连接这两个网络的路由器就可以回答该请求，这个过程称作委托ARP或ARP代理(Proxy ARP)。这样可以欺骗发起ARP请求的发送端，使它误以为路由器就是目的主机，而事实上目的主机是在路由器的“另一边”。路由器的功能相当于目的主机的代理，把分组从其他主机转发给它。</p><p>ARP代理也称作混合ARP（promiscuousARP）或ARP出租(ARPhack)。这些名字来自于ARP代理的其他用途：通过两个物理网络之间的路由器可以互相隐藏物理网络。在这种情况下，两个物理网络可以使用相同的网络号，只要把中间的路由器设置成一个ARP代理，以响应一个网络到另一个网络主机的ARP请求。这种技术在过去用来隐藏一组在不同物理电缆上运行旧版TCP/IP的主机。分开这些旧主机有两个共同的理由，其一是它们不能处理子网划分，其二是它们使用旧的广播地址（所有比特值为0的主机号，而不是目前使用的所有比特值为1的主机号）。</p><h2 id="免费ARP">免费ARP</h2><p>我们可以看到的另一个ARP特性称作免费ARP(gratuitous ARP)。它是指主机发送ARP查找自己的IP地址。通常，它发生在系统引导期间进行接口配置的时候。</p><p>免费ARP可以有两个方面的作用：</p><ol><li>一个主机可以通过它来确定另一个主机是否设置了相同的IP地址。主机bsdi并不希望对此请求有一个回答。但是，如果收到一个回答，那么就会在终端日志上产生一个错误消息“以太网地址：a🅱️c:d:e:f发送来重复的IP地址”。这样就可以警告系统管理员，某个系统有不正确的设置。</li><li>如果发送免费ARP的主机正好改变了硬件地址（很可能是主机关机了，并换了一块接口卡，然后重新启动），那么这个分组就可以使其他主机高速缓存中旧的硬件地址进行相应的更新。一个比较著名的ARP协议事实[Plummer1982]是，如果主机收到某个IP地址的ARP请求，而且它已经在接收者的高速缓存中，那么就要用ARP请求中的发送端硬件地址（如以太网地址）对高速缓存中相应的内容进行更新。主机接收到任何ARP请求都要完成这个操作（ARP请求是在网上广播的，因此每次发送ARP请求时网络上的所有主机都要这样做）。</li></ol><h2 id="arp命令">arp命令</h2><ul><li>参数-a来显示ARP高速缓存中的所有内容</li><li>超级用户可以用选项-d来删除ARP高速缓存中的某一项内容</li><li>可以通过选项-s来增加高速缓存中的内容。这个参数需要主机名和以太网地址：对应于主机名的IP地址和以太网地址被增加到高速缓存中。新增加的内容是永久性的（比如，它没有超时值），除非在命令行的末尾附上关键字temp。</li><li>位于命令行末尾的关键字pub和-s选项一起，可以使系统起着主机ARP代理的作用。系统将回答与主机名对应的IP地址的ARP请求，并以指定的以太网地址作为应答。如果广播的地址是系统本身，那么系统就为指定的主机名起着委托ARP代理的作用。</li></ul><h1>RARP：逆地址解析协议</h1><h2 id="引言-v3">引言</h2><p>具有本地磁盘的系统引导时，一般是从磁盘上的配置文件中读取IP地址。但是无盘机，如X终端或无盘工作站，则需要采用其他方法来获得IP地址。</p><p>网络上的每个系统都具有唯一的硬件地址，它是由网络接口生产厂家配置的。无盘系统的RARP实现过程是从接口卡上读取唯一的硬件地址，然后发送一份RARP请求（一帧在网络上广播的数据），请求某个主机响应该无盘系统的IP地址（在RARP应答中）。</p><h2 id="RARP的分组格式">RARP的分组格式</h2><p>RARP分组的格式与ARP分组基本一致（见图4-3）。它们之间主要的差别是RARP请求或应答的帧类型代码为0x8035，而且RARP请求的操作代码为3，应答操作代码为4。</p><p>对应于ARP，RARP请求以广播方式传送，而RARP应答一般是单播(unicast)传送的。</p><h2 id="RARP服务器的设计">RARP服务器的设计</h2><p>虽然RARP在概念上很简单，但是一个RARP服务器的设计与系统相关而且比较复杂。相反，提供一个ARP服务器很简单，通常是TCP/IP在内核中实现的一部分。由于内核知道IP地址和硬件地址，因此当它收到一个询问IP地址的ARP请求时，只需用相应的硬件地址来提供应答就可以了。</p><h3 id="作为用户进程的RARP服务器">作为用户进程的RARP服务器</h3><p>RARP服务器的复杂性在于，服务器一般要为多个主机（网络上所有的无盘系统）提供硬件地址到IP地址的映射。该映射包含在一个磁盘文件中（在Unix系统中一般位于/etc/ethers目录中）。由于内核一般不读取和分析磁盘文件，因此RARP服务器的功能就由用户进程来提供，而不是作为内核的TCP/IP实现的一部分。</p><p>更为复杂的是，RARP请求是作为一个特殊类型的以太网数据帧来传送的（帧类型字段值为0x8035）。这说明RARP服务器必须能够发送和接收这种类型的以太网数据帧。在附录A中，我们描述了BSD分组过滤器、Sun的网络接口栓以及SVR4数据链路提供者接口都可用来接收这些数据帧。由于发送和接收这些数据帧与系统有关，因此RARP服务器的实现是与系统捆绑在一起的。</p><h3 id="每个网络有多个RARP服务器">每个网络有多个RARP服务器</h3><p>RARP服务器实现的一个复杂因素是RARP请求是在硬件层上进行广播的。这意味着它们不经过路由器进行转发。为了让无盘系统在RARP服务器关机的状态下也能引导，<br>通常在一个网络上（例如一根电缆）要提供多个RARP服务器。</p><p>当服务器的数目增加时（以提供冗余备份），网络流量也随之增加，因为每个服务器对每个RARP请求都要发送RARP应答。发送RARP请求的无盘系统一般采用最先收到的RARP应答（对于ARP，我们从来没有遇到这种情况，因为只有一台主机发送ARP应答）。另外，还有一种可能发生的情况是每个RARP服务器同时应答，这样会增加以太网发生冲突的概率。</p><h2 id="小结-v3">小结</h2><p>RARP协议是许多无盘系统在引导时用来获取IP地址的。RARP分组格式基本上与ARP分组一致。一个RARP请求在网络上进行广播，它在分组中标明发送端的硬件地址，以请求相应IP地址的响应。应答通常是单播传送的。</p><p>RARP带来的问题包括使用链路层广播，这样就阻止大多数路由器转发RARP请求，只返回很少信息：只是系统的IP地址。</p><p>虽然RARP在概念上很简单，但是RARP服务器的实现却与系统相关。因此，并不是所有的TCP/IP实现都提供RARP服务器。</p><h1>ICMP：Internet控制报文协议</h1><h2 id="引言-v4">引言</h2><blockquote><p>ICMP（Internet Control Message Protocol）</p></blockquote><p>ICMP经常被认为是IP层的一个组成部分。它传递差错报文以及其他需要注意的信息。ICMP报文通常被IP层或更高层协议（TCP或UDP）使用。一些ICMP报文把差错报文返回给用户进程。</p><p>ICMP报文是在IP数据报内部被传输的，如图6-1所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E5%B0%81%E8%A3%85%E5%9C%A8IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%86%85%E9%83%A8.png" alt></p><p>ICMP报文的格式如图6-2所示。所有报文的前4个字节都是一样的，但是剩下的其他字节则互不相同。下面我们将逐个介绍各种报文格式。</p><p>类型字段可以有15个不同的值，以描述特定类型的ICMP报文。某些ICMP报文还使用代码字段的值来进一步描述不同的条件。</p><p>检验和字段覆盖整个ICMP报文。ICMP的检验和是必需的。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E6%8A%A5%E6%96%87.png" alt></p><h2 id="ICMP报文的类型">ICMP报文的类型</h2><p>各种类型的ICMP报文如图6-3所示，不同类型由报文中的类型字段和代码字段来共同决定。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B.png" alt></p><p>图中的最后两列表明ICMP报文是一份查询报文还是一份差错报文。因为对ICMP差错报文有时需要作特殊处理，因此我们需要对它们进行区分。例如，在对ICMP差错报文进行响应时，永远不会生成另一份ICMP差错报文（如果没有这个限制规则，可能会遇到一个差错产生另一个差错的情况，而差错再产生差错，这样会无休止地循环下去）。</p><p>当发送一份ICMP差错报文时，报文始终包含IP的首部和产生ICMP差错报文的IP数据报的前8个字节。这样，接收ICMP差错报文的模块就会把它与某个特定的协议（根据IP数据报首部中的协议字段来判断）和用户进程（根据包含在IP数据报前8个字节中的TCP或UDP报文首部中的TCP或UDP端口号来判断）联系起来。</p><p>下面各种情况都不会导致产生ICMP差错报文：</p><ol><li>ICMP差错报文（但是，ICMP查询报文可能会产生ICMP差错报文）。</li><li>目的地址是广播地址或多播地址（D类地址）的IP数据报。</li><li>作为链路层广播的数据报。</li><li>不是IP分片的第一片。</li><li>源地址不是单个主机的数据报。这就是说，源地址不能为零地址、环回地址、广播地址或多播地址。</li></ol><p>这些规则是为了防止过去允许ICMP差错报文对广播分组响应所带来的广播风暴。</p><h2 id="ICMP地址掩码请求与应答">ICMP地址掩码请求与应答</h2><p>ICMP地址掩码请求用于无盘系统在引导过程中获取自己的子网掩码。系统广播它的ICMP请求报文（这一过程与无盘系统在引导过程中用RARP获取IP地址是类似的）。无盘系统获取子网掩码的另一个方法是BOOTP协议。</p><p>ICMP地址掩码请求和应答报文的格式如图6-4所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E5%9C%B0%E5%9D%80%E6%8E%A9%E7%A0%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%BA%94%E7%AD%94%E6%8A%A5%E6%96%87.png" alt></p><p>ICMP报文中的标识符和序列号字段由发送端任意选择设定，这些值在应答中将被返回。这样，发送端就可以把应答与请求进行匹配。</p><h1>Ping程序</h1><p><strong>ping</strong><br>测试主机之间网络的连通性</p><p><strong>补充说明</strong><br>ping命令 用来测试主机之间网络的连通性。执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping(选项)(参数)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-d：使用Socket的SO_DEBUG功能；</span><br><span class="line">-c&lt;完成次数&gt;：设置完成要求回应的次数；</span><br><span class="line">-f：极限检测；</span><br><span class="line">-i&lt;间隔秒数&gt;：指定收发信息的间隔时间；</span><br><span class="line">-I&lt;网络界面&gt;：使用指定的网络界面送出数据包；</span><br><span class="line">-l&lt;前置载入&gt;：设置在送出要求信息之前，先行发出的数据包；</span><br><span class="line">-n：只输出数值；</span><br><span class="line">-p&lt;范本样式&gt;：设置填满数据包的范本样式；</span><br><span class="line">-q：不显示指令执行过程，开头和结尾的相关信息除外；</span><br><span class="line">-r：忽略普通的Routing Table，直接将数据包送到远端主机上；</span><br><span class="line">-R：记录路由过程；</span><br><span class="line">-s&lt;数据包大小&gt;：设置数据包的大小；</span><br><span class="line">-t&lt;存活数值&gt;：设置存活数值TTL的大小；</span><br><span class="line">-v：详细显示指令的执行过程。</span><br></pre></td></tr></table></figure><p><strong>参数</strong><br>目的主机：指定发送ICMP报文的目的主机。</p><h2 id="引言-v5">引言</h2><p>“ping”这个名字源于声纳定位操作。Ping程序由MikeMuuss编写，目的是为了测试另一台主机是否可达。该程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答（图6-3列出了所有的ICMP报文类型）。</p><p>一般来说，如果不能Ping到某台主机，那么就不能Telnet或者FTP到那台主机。反过来，如果不能Telnet到某台主机，那么通常可以用Ping程序来确定问题出在哪里。Ping程序还能测出到这台主机的往返时间，以表明该主机离我们有“多远”。</p><h2 id="Ping程序">Ping程序</h2><p>我们称发送回显请求的ping程序为客户，而称被ping的主机为服务器。大多数的TCP/IP实现都在内核中直接支持Ping服务器—这种服务器不是一个用户进程。</p><p>ICMP回显请求和回显应答报文如图7-1所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E5%9B%9E%E6%98%BE%E8%AF%B7%E6%B1%82%E5%92%8C%E5%9B%9E%E6%98%BE%E5%BA%94%E7%AD%94%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt></p><p>对于其他类型的ICMP查询报文，服务器必须响应标识符和序列号字段。另外，客户发送的选项数据必须回显，假设客户对这些信息都会感兴趣。</p><p>Unix系统在实现ping程序时是把ICMP报文中的标识符字段置成发送进程的ID号。这样即使在同一台主机上同时运行了多个ping程序实例，ping程序也可以识别出返回的信息。</p><p>序列号从0开始，每发送一次新的回显请求就加1。ping程序打印出返回的每个分组的序列号，允许我们查看是否有分组丢失、失序或重复。IP是一种最好的数据报传递服务，因此这三个条件都有可能发生。</p><p>旧版本的ping程序曾经以这种模式运行，即每秒发送一个回显请求，并打印出返回的每个回显应答。但是，新版本的实现需要加上-s选项才能以这种模式运行。默认情况下，新版本的ping程序只发送一个回显请求。如果收到回显应答，则输出“host is alive”；否则，在20秒内没有收到应答就输出“no answer（没有回答）”。</p><h3 id="LAN-WAN-输出">LAN/WAN 输出</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ping jiankunking.com</span><br><span class="line">PING jiankunking.com (139.199.31.69) 56(84) bytes of data.</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=1 ttl=63 time=0.336 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=2 ttl=63 time=0.288 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=3 ttl=63 time=0.295 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=4 ttl=63 time=0.295 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=5 ttl=63 time=0.323 ms</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=6 ttl=63 time=0.324 ms</span><br><span class="line">^C 键入中断来停止显示</span><br><span class="line">--- jiankunking.com ping statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 6510ms</span><br><span class="line">rtt min/avg/max/mdev = 0.288/0.310/0.336/0.020 ms</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><blockquote><p>默认情况下发送的ICMP报文有56个字节。再加上20个字节的IP首部和8个字节的ICMP首部，IP数据报的总长度为84字节。</p></blockquote><p>当返回ICMP回显应答时，要打印出序列号和TTL，并计算往返时间（TTL位于IP首部中的生存时间字段。当前的BSD系统中的ping程序每次收到回显应答时都打印出收到的TTL—有些系统并不这样做。）。</p><p>从上面的输出中可以看出，回显应答是以发送的次序返回的（0，1，2等）。</p><p>ping程序通过在ICMP报文数据中存放发送请求的时间值来计算往返时间。当应答返回时，用当前时间减去存放在ICMP报文中的时间值，即是往返时间。</p><p>通过广域网还有可能看到重复的分组（即相同序列号的分组被打印两次或更多次），失序的分组（序列号为N + 1的分组在序列号为N的分组之前被打印）。</p><h2 id="IP记录路由选项">IP记录路由选项</h2><p>ping程序为我们提供了查看IP记录路由（RR）选项的机会。大多数不同版本的ping程序都提供-R选项，以提供记录路由的功能。它使得ping程序在发送出去的IP数据报中设置IP RR选项（该IP数据报包含ICMP回显请求报文）。这样，每个处理该数据报的路由器都把它的IP地址放入选项字段中。当数据报到达目的端时，IP地址清单应该复制到ICMP回显应答中，这样返回途中所经过的路由器地址也被加入清单中。当ping程序收到回显应答时，它就打印出这份IP地址清单。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# ping -R jiankunking.com</span><br><span class="line">PING jiankunking.com (139.199.31.69) 56(124) bytes of data.</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=1 ttl=63 time=13.3 ms</span><br><span class="line">RR: 	VM_0_3_centos (172.21.0.3)</span><br><span class="line">	10.53.209.129 (10.53.209.129)</span><br><span class="line">	VM_0_3_centos (172.21.0.3)</span><br><span class="line">	VM_0_3_centos (172.21.0.3)</span><br><span class="line">	10.53.209.130 (10.53.209.130)</span><br><span class="line">	VM_0_3_centos (172.21.0.3)</span><br><span class="line"></span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=2 ttl=63 time=4.91 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=3 ttl=63 time=6.81 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=4 ttl=63 time=5.03 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=5 ttl=63 time=4.59 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=6 ttl=63 time=4.77 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=7 ttl=63 time=5.18 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=8 ttl=63 time=3.69 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=9 ttl=63 time=4.24 ms	(same route)</span><br><span class="line">64 bytes from 139.199.31.69 (139.199.31.69): icmp_seq=10 ttl=63 time=5.43 ms	(same route)</span><br><span class="line">^C</span><br><span class="line">--- jiankunking.com ping statistics ---</span><br><span class="line">11 packets transmitted, 11 received, 0% packet loss, time 10015ms</span><br><span class="line">rtt min/avg/max/mdev = 3.697/5.696/13.385/2.545 ms</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>但是，最大的问题是IP首部中只有有限的空间来存放IP地址。我们从图3-1可以看到，IP首部中的首部长度字段只有4bit，因此整个IP首部最长只能包括15个32bit长的字（即60个字节）。由于IP首部固定长度为20字节，RR选项用去3个字节（下面我们再讨论），这样只剩下37个字节（60-20-3）来存放IP地址清单，也就是说只能存放9个IP地址。对于早期的ARPANET来说，9个IP地址似乎是很多了，但是现在看来是非常有限的。除了这些缺点，记录路由选项工作得很好，为详细查看如何处理IP选项提供了一个机会。</p><p>IP数据报中的RR选项的一般格式如图7-3所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/IP%E9%A6%96%E9%83%A8%E4%B8%AD%E7%9A%84%E8%AE%B0%E5%BD%95%E8%B7%AF%E7%94%B1%E9%80%89%E9%A1%B9%E7%9A%84%E4%B8%80%E8%88%AC%E6%A0%BC%E5%BC%8F.png" alt></p><p>code是一个字节，指明IP选项的类型。对于RR选项来说，它的值为7。len是RR选项总字节长度，在这种情况下为39（尽管可以为RR选项设置比最大长度小的长度，但是ping程序是提供39字节的选项字段，最多可以记录9个IP地址。由于IP首部中留给选项的空间有限，它一般情况都设置成最大长度）。</p><p>ptr称作指针字段。它是一个基于1的指针，指向存放下一个IP地址的位置。它的最小值为4，指向存放第一个IP地址的位置。随着每个IP地址存入清单，ptr的值分别为8，12，16，最大到36。当记录下9个IP地址后，ptr的值为40，表示清单已满。</p><p>当路由器（根据定义应该是多穴的）在清单中记录IP地址时，它应该记录哪个地址呢？是入口地址还是出口地址？为此，RFC791[Postel1981a]指定路由器记录出口IP地址。我们在后面将看到，当原始主机（运行ping程序的主机）收到带有RR选项的ICMP回显应答时，它也要把它的入口IP地址放入清单中。</p><h2 id="小结-v4">小结</h2><p>ping程序是对两个TCP/IP系统连通性进行测试的基本工具。它只利用ICMP回显请求和回显应答报文，而不用经过传输层（TCP/UDP）。Ping服务器一般在内核中实现ICMP的功能。</p><h1>Traceroute程序</h1><p><strong>traceroute</strong><br>显示数据包到主机间的路径</p><p><strong>补充说明</strong><br>traceroute命令 用于追踪数据包在网络上的传输时的全部路径，它默认发送的数据包大小是40字节。</p><p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。</p><p>traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其ip地址。<br><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">traceroute(选项)(参数)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-d：使用Socket层级的排错功能；</span><br><span class="line">-f&lt;存活数值&gt;：设置第一个检测数据包的存活数值TTL的大小；</span><br><span class="line">-F：设置勿离断位；</span><br><span class="line">-g&lt;网关&gt;：设置来源路由网关，最多可设置8个；</span><br><span class="line">-i&lt;网络界面&gt;：使用指定的网络界面送出数据包；</span><br><span class="line">-I：使用ICMP回应取代UDP资料信息；</span><br><span class="line">-m&lt;存活数值&gt;：设置检测数据包的最大存活数值TTL的大小；</span><br><span class="line">-n：直接使用IP地址而非主机名称；</span><br><span class="line">-p&lt;通信端口&gt;：设置UDP传输协议的通信端口；</span><br><span class="line">-r：忽略普通的Routing Table，直接将数据包送到远端主机上。</span><br><span class="line">-s&lt;来源地址&gt;：设置本地主机送出数据包的IP地址；</span><br><span class="line">-t&lt;服务类型&gt;：设置检测数据包的TOS数值；</span><br><span class="line">-v：详细显示指令的执行过程；</span><br><span class="line">-w&lt;超时秒数&gt;：设置等待远端主机回报的时间；</span><br><span class="line">-x：开启或关闭数据包的正确性检验。</span><br></pre></td></tr></table></figure><p><strong>参数</strong><br>主机：指定目的主机IP地址或主机名。</p><h2 id="引言-v6">引言</h2><p>Traceroute程序可以让我们看到IP数据报从一台主机传到另一台主机所经过的路由。</p><h2 id="Traceroute程序的操作">Traceroute程序的操作</h2><p>在上节中，我们描述了IP记录路由选项（RR）。为什么不使用这个选项而另外开发一个新的应用程序？有三个方面的原因。首先，原先并不是所有的路由器都支持记录路由选项，因此该选项在某些路径上不能使用（Traceroute程序不需要中间路由器具备任何特殊的或可选的功能）。</p><p>其次，记录路由一般是单向的选项。发送端设置了该选项，那么接收端不得不从收到的IP首部中提取出所有的信息，然后全部返回给发送端。在上节中，我们看到大多数Ping服务器的实现（内核中的ICMP回显应答功能）把接收到的RR清单返回，但是这样使得记录下来的IP地址翻了一番（一来一回）。这样做会受到一些限制，这一点我们在下一段讨论（Traceroute程序只需要目的端运行一个UDP模块—其他不需要任何特殊的服务器应用程序）。</p><p>最后一个原因也是最主要的原因是，IP首部中留给选项的空间有限，不能存放当前大多数的路径。在IP首部选项字段中最多只能存放9个IP地址。在原先的ARPANET中这是足够的，但是对现在来说是远远不够的。</p><p>Traceroute程序使用ICMP报文和IP首部中的TTL字段（生存周期）。TTL字段是由发送端初始设置一个8bit字段。推荐的初始值由分配数字RFC指定，当前值为64。较老版本的系统经常初始化为15或32。我们从第7章中的一些ping程序例子中可以看出，发送ICMP回显应答时经常把TTL设为最大值255。</p><p>每个处理数据报的路由器都需要把TTL的值减1或减去数据报在路由器中停留的秒数。由于大多数的路由器转发数据报的时延都小于1秒钟，因此TTL最终成为一个跳站的计数器，所经过的每个路由器都将其值减1。</p><blockquote><p>RFC 1009 [Braden and Postel 1987]指出，如果路由器转发数据报的时延超过1秒，那么它将把TTL值减去所消耗的时间（秒数）。但很少有路由器这么实现。新的路由器需求文档RFC [Almquist 1993]为此指定它为可选择功能，允许把TTL看成一个跳站计数器。</p></blockquote><p><font color="DeepPink"><strong>TTL字段的目的是防止数据报在选路时无休止地在网络中流动。</strong></font>例如，当路由器瘫痪或者两个路由器之间的连接丢失时，选路协议有时会去检测丢失的路由并一直进行下去。在这段时间内，数据报可能在循环回路被终止。TTL字段就是在这些循环传递的数据报上加上一个生存上限。</p><p>当路由器收到一份IP数据报，如果其TTL字段是0或1，则路由器不转发该数据报（接收到这种数据报的目的主机可以将它交给应用程序，这是因为不需要转发该数据报。但是在通常情况下，系统不应该接收TTL字段为0的数据报）。相反，路由器将该数据报丢弃，并给信源机发一份ICMP“超时”信息。Traceroute程序的关键在于包含这份ICMP信息的IP报文的信源地址是该路由器的IP地址。</p><p><font color="DeepPink"><strong>我们现在可以猜想一下Traceroute程序的操作过程。它发送一份TTL字段为1的IP数据报给目的主机。处理这份数据报的第一个路由器将TTL值减1，丢弃该数据报，并发回一份超时ICMP报文。这样就得到了该路径中的第一个路由器的地址。然后Traceroute程序发送一份TTL值为2的数据报，这样我们就可以得到第二个路由器的地址。继续这个过程直至该数据报到达目的主机。但是目的主机哪怕接收到TTL值为1的IP数据报，也不会丢弃该数据报并产生一份超时ICMP报文，这是因为数据报已经到达其最终目的地。那么我们该如何判断是否已经到达目的主机了呢？</strong></font></p><p><font color="DeepPink"><strong>Traceroute程序发送一份UDP数据报给目的主机，但它选择一个不可能的值作为UDP端口号（大于30000），使目的主机的任何一个应用程序都不可能使用该端口。因为，当该数据报到达时，将使目的主机的UDP模块产生一份“端口不可达”错误的ICMP报文。这样，Traceroute程序所要做的就是区分接收到的ICMP报文是超时还是端口不可达，以判断什么时候结束。</strong></font></p><blockquote><p>Traceroute程序必须可以为发送的数据报设置TTL字段。并非所有与TCP/IP接口的程序都支持这项功能，同时并非所有的实现都支持这项能力，但目前大部分系统都支持这项功能，并可以运行Traceroute程序。这个程序界面通常要求用户具有超级用户权限，这意味着它可能需要特殊的权限以在你的主机上运行该程序。</p></blockquote><h2 id="IP源站选路选项">IP源站选路选项</h2><p>通常IP路由是动态的，即每个路由器都要判断数据报下面该转发到哪个路由器。应用程序对此不进行控制，而且通常也并不关心路由。它采用类似Traceroute程序的工具来发现实际的路由。</p><p>源站选路(source routing)的思想是由发送者指定路由。它可以采用以下两种形式：</p><ul><li>严格的源路由选择。发送端指明IP数据报所必须采用的确切路由。如果一个路由器发现源路由所指定的下一个路由器不在其直接连接的网络上，那么它就返回一个“源站路由失败”的ICMP差错报文。</li><li>宽松的源站选路。发送端指明了一个数据报经过的IP地址清单，但是数据报在清单上指明的任意两个地址之间可以通过其他路由器。</li></ul><h1>IP选路</h1><h2 id="引言-v7">引言</h2><p>选路是IP最重要的功能之一。需要进行选路的数据报可以由本地主机产生，也可以由其他主机产生。在后一种情况下，主机必须配置成一个路由器，否则通过网络接口接收到的数据报，如果目的地址不是本机就要被丢弃（例如，悄无声息地被丢弃）。</p><p><strong>netstat</strong><br>查看Linux中网络系统状态信息。</p><p><strong>补充说明</strong><br>netstat命令 用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat(选项)</span><br></pre></td></tr></table></figure><p><strong>选项</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-a或--all：显示所有连线中的Socket；</span><br><span class="line">-A&lt;网络类型&gt;或--&lt;网络类型&gt;：列出该网络类型连线中的相关地址；</span><br><span class="line">-c或--continuous：持续列出网络状态；</span><br><span class="line">-C或--cache：显示路由器配置的快取信息；</span><br><span class="line">-e或--extend：显示网络其他相关信息；</span><br><span class="line">-F或--fib：显示FIB；</span><br><span class="line">-g或--groups：显示多重广播功能群组组员名单；</span><br><span class="line">-h或--help：在线帮助；</span><br><span class="line">-i或--interfaces：显示网络界面信息表单；</span><br><span class="line">-l或--listening：显示监控中的服务器的Socket；</span><br><span class="line">-M或--masquerade：显示伪装的网络连线；</span><br><span class="line">-n或--numeric：直接使用ip地址，而不通过域名服务器；</span><br><span class="line">-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称；</span><br><span class="line">-o或--timers：显示计时器；</span><br><span class="line">-p或--programs：显示正在使用Socket的程序识别码和程序名称；</span><br><span class="line">-r或--route：显示Routing Table；</span><br><span class="line">-s或--statistice：显示网络工作信息统计表；</span><br><span class="line">-t或--tcp：显示TCP传输协议的连线状况；</span><br><span class="line">-u或--udp：显示UDP传输协议的连线状况；</span><br><span class="line">-v或--verbose：显示指令执行过程；</span><br><span class="line">-V或--version：显示版本信息；</span><br><span class="line">-w或--raw：显示RAW传输协议的连线状况；</span><br><span class="line">-x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同；</span><br><span class="line">--ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同。</span><br></pre></td></tr></table></figure><h2 id="选路的原理">选路的原理</h2><p>开始讨论IP选路之前，首先要理解内核是如何维护路由表的。路由表中包含的信息决定了IP层所做的所有决策。</p><p>IP搜索路由表的几个步骤：</p><ol><li>搜索匹配的主机地址；</li><li>搜索匹配的网络地址；</li><li>搜索默认表项（默认表项一般在路由表中被指定为一个网络表项，其网络号为0）。</li></ol><p>匹配主机地址步骤始终发生在匹配网络地址步骤之前。</p><p>IP层进行的选路实际上是一种选路机制，它搜索路由表并决定向哪个网络接口发送分组。这区别于选路策略，它只是一组决定把哪些路由放入路由表的规则。IP执行选路机制，而路由守护程序则一般提供选路策略。</p><h3 id="简单路由表">简单路由表</h3><p>首先来看一看一些典型的主机路由表。在主机上，我们先执行带-r选项的netstat命令列出路由表，然后以-n选项再次执行该命令，以数字格式打印出IP地址。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[jiankunking@VM_0_3_centos ~]# netstat -rn</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface</span><br><span class="line">0.0.0.0         172.21.0.1      0.0.0.0         UG        0 0          0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U         0 0          0 docker0</span><br><span class="line">172.21.0.0      0.0.0.0         255.255.240.0   U         0 0          0 eth0</span><br><span class="line">[jiankunking@VM_0_3_centos ~]#</span><br></pre></td></tr></table></figure><p>对于一个给定的路由器，可以打印出五种不同的标志（flag）：</p><table><thead><tr><th>标志</th><th>解释</th></tr></thead><tbody><tr><td>U</td><td>该路由可以使用。</td></tr><tr><td>G</td><td>该路由是到一个网关（路由器）。如果没有设置该标志，说明目的地是直接相连的。</td></tr><tr><td>H</td><td>该路由是到一个主机，也就是说，目的地址是一个完整的主机地址。如果没有设置该标志，说明该路由是到一个网络，而目的地址是一个网络地址：一个网络号，或者网络号与子网号的组合。</td></tr><tr><td>D</td><td>该路由是由重定向报文创建的。</td></tr><tr><td>M</td><td>该路由已被重定向报文修改。</td></tr></tbody></table><p>标志G是非常重要的，因为由它区分了间接路由和直接路由（对于直接路由来说是不设置标志G的）。其区别在于，发往直接路由的分组中不但具有指明目的端的IP地址，还具有其链路层地址。当分组被发往一个间接路由时，IP地址指明的是最终的目的地，但是链路层地址指明的是网关（即下一站路由器）。</p><p>理解G和H标志之间的区别是很重要的。G标志区分了直接路由和间接路由，如上所述。但是H标志表明，目的地址（netstat命令输出第一行）是一个完整的主机地址。没有设置H标志说明目的地址是一个网络地址（主机号部分为0）。当为某个目的IP地址搜索路由表时，主机地址项必须与目的地址完全匹配，而网络地址项只需要匹配目的地址的网络号和子网号就可以了。另外，大多数版本的netstat命令首先打印出所有的主机路由表项，然后才是网络路由表项。</p><h2 id="ICMP主机与网络不可达差错">ICMP主机与网络不可达差错</h2><p>当路由器收到一份IP数据报但又不能转发时，就要发送一份ICMP“主机不可达”差错报文。</p><h2 id="ICMP重定向差错">ICMP重定向差错</h2><p>当IP数据报应该被发送到另一个路由器时，收到数据报的路由器就要发送ICMP重定向差错报文给IP数据报的发送端。这在概念上是很简单的，正如图9-3所示的那样。只有当主机可以选择路由器发送分组的情况下，我们才可能看到ICMP重定向报文。</p><ol><li>我们假定主机发送一份IP数据报给R1。这种选路决策经常发生，因为R1是该主机的默认路由。</li><li>R1收到数据报并且检查它的路由表，发现R2是发送该数据报的下一站。当它把数据报发送给R2时，R1检测到它正在发送的接口与数据报到达接口是相同的（即主机和两个路由器所在的LAN）。这样就给路由器发送重定向报文给原始发送端提供了线索。</li><li>R1发送一份ICMP重定向报文给主机，告诉它以后把数据报发送给R2而不是R1。</li></ol><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/ICMP%E9%87%8D%E5%AE%9A%E5%90%91%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt></p><p>重定向一般用来让具有很少选路信息的主机逐渐建立更完善的路由表。主机启动时路由表中可以只有一个默认表项（在图9-3所示的例子中，为R1或R2）。一旦默认路由发生差错，默认路由器将通知它进行重定向，并允许主机对路由表作相应的改动。ICMP重定向允许TCP/IP主机在进行选路时不需要具备智能特性，而把所有的智能特性放在路由器端。</p><h2 id="小结-v5">小结</h2><p>系统产生的或转发的每份IP数据报都要搜索路由表，它可以被路由守护程序或ICMP重定向报文修改。系统在默认情况下不转发数据报，除非进行特殊的配置。用route命令可以进入静态路由，可以利用新ICMP路由器发现报文来初始化默认表项，并进行动态修改。主机在启动时只有一个简单的路由表，它可以被来自默认路由器的ICMP重定向报文动态修改。</p><h1>动态选路协议</h1><p>在前面各章中，我们讨论了静态选路。在配置接口时，以默认方式生成路由表项（对于直接连接的接口），并通过route命令增加表项（通常从系统自引导程序文件），或是通过ICMP重定向生成表项（通常是在默认方式出错的情况下）。</p><p>在网络很小，且与其他网络只有单个连接点且没有多余路由时（若主路由失败，可以使用备用路由），采用这种方法是可行的。如果上述三种情况不能全部满足，通常使用动态选路。</p><h2 id="动态选路">动态选路</h2><p>当相邻路由器之间进行通信，以告知对方每个路由器当前所连接的网络，这时就出现了动态选路。路由器之间必须采用选路协议进行通信，这样的选路协议有很多种。路由器上有一个进程称为路由守护程序（ routing daemon），它运行选路协议，并与其相邻的一些路由器进行通信。</p><p>路由守护程序将选路策略（routing policy）加入到系统中，选择路由并加入到内核的路由表中。如果守护程序发现前往同一信宿存在多条路由，那么它（以某种方法）将选择最佳路由并加入内核路由表中。如果路由守护程序发现一条链路已经断开（可能是路由器崩溃或电话线路不好），它可以删除受影响的路由或增加另一条路由以绕过该问题。</p><p>在像Internet这样的系统中，目前采用了许多不同的选路协议。Internet是以一组自治系统(AS，Autonomous System)的方式组织的，每个自治系统通常由单个实体管理。常常将一个公司或大学校园定义为一个自治系统。NSFNET的Internet骨干网形成一个自治系统，这是因为骨干网中的所有路由器都在单个的管理控制之下。</p><p>每个自治系统可以选择该自治系统中各个路由器之间的选路协议。这种协议我们称之为内部网关协议IGP（Interior Gateway Protocol）或域内选路协议（intradomain routing protocol）。最常用的IGP是选路信息协议RIP。一种新的IGP是开放最短路径优先OSPF（Open Shortest PathFirst）协议。它意在取代RIP。</p><blockquote><p>新的RFC[Almquist 1993]规定，实现任何动态选路协议的路由器必须同时支持OSPF和RIP，还可以支持其他IGP协议。</p></blockquote><h2 id="RIP：选路信息协议">RIP：选路信息协议</h2><h3 id="正常运行">正常运行</h3><p>让我们来看一下采用RIP协议的routed程序正常运行的结果。RIP常用的UDP端口号是520。</p><ul><li>初始化：在启动一个路由守护程序时，它先判断启动了哪些接口，并在每个接口上发送一个请求报文，要求其他路由器发送完整路由表。在点对点链路中，该请求是发送给其他终点的。如果网络支持广播的话，这种请求是以广播形式发送的。目的UDP端口号是520（这是其他路由器的路由守护程序端口号）。这种请求报文的命令字段为1，但地址系列字段设置为0，而度量字段设置为16。这是一种要求另一端完整路由表的特殊请求报文。</li><li>接收到请求。如果这个请求是刚才提到的特殊请求，那么路由器就将完整的路由表发送给请求者。否则，就处理请求中的每一个表项：如果有连接到指明地址的路由，则将度量设置成我们的值，否则将度量置为16（度量为16是一种称为“无穷大”的特殊值，它意味着没有到达目的的路由）。然后发回响应。</li><li>接收到响应。使响应生效，可能会更新路由表。可能会增加新表项，对已有的表项进行修改，或是将已有表项删除。</li><li>定期选路更新。每过30秒，所有或部分路由器会将其完整路由表发送给相邻路由器。发送路由表可以是广播形式的（如在以太网上），或是发送给点对点链路的其他终点的。</li><li>触发更新。每当一条路由的度量发生变化时，就对它进行更新。不需要发送完整路由表，而只需要发送那些发生变化的表项。</li></ul><p><font color="DeepPink"><strong>每条路由都有与之相关的定时器。如果运行RIP的系统发现一条路由在3分钟内未更新，就将该路由的度量设置成无穷大（16），并标注为删除。这意味着已经在6个30秒更新时间里没收到通告该路由的路由器的更新了。再过60秒，将从本地路由表中删除该路由，以保证该路由的失效已被传播开。</strong></font></p><h3 id="度量">度量</h3><p>RIP所使用的度量是以跳(hop)计算的。所有直接连接接口的跳数为1。考虑图10-4所示的路由器和网络。画出的4条虚线是广播RIP报文。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E8%B7%AF%E7%94%B1%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B.png" alt></p><p>路由器R1通过发送广播到N1通告它与N2之间的跳数是1（发送给N1的广播中通告它与N1之间的路由是无用的）。同时也通过发送广播给N2通告它与N1之间的跳数为1。同样，R2通告它与N2的度量为1，与N3的度量为1。</p><p>如果相邻路由器通告它与其他网络路由的跳数为1，那么我们与那个网络的度量就是2，这是因为为了发送报文到该网络，我们必须经过那个路由器。在我们的例子中，R2到N1的度量是2，与R1到N3的度量一样。</p><p>由于每个路由器都发送其路由表给邻站，因此，可以判断在同一个自治系统AS内到每个网络的路由。如果在该AS内从一个路由器到一个网络有多条路由，那么路由器将选择跳数最小的路由，而忽略其他路由。</p><p>跳数的最大值是15，这意味着RIP只能用在主机间最大跳数值为15的AS内。度量为16表示到无路由到达该IP地址。</p><h2 id="OSPF：开放最短路径优先">OSPF：开放最短路径优先</h2><p>OSPF是除RIP外的另一个内部网关协议。它克服了RIP的所有限制。RFC1247[Moy 1991]中对第2版OSPF进行了描述。</p><p>与采用距离向量的RIP协议不同的是，OSPF是一个链路状态协议。距离向量的意思是，RIP发送的报文包含一个距离向量（跳数）。每个路由器都根据它所接收到邻站的这些距离向量来更新自己的路由表。</p><p>在一个链路状态协议中，路由器并不与其邻站交换距离信息。它采用的是每个路由器主动地测试与其邻站相连链路的状态，将这些信息发送给它的其他邻站，而邻站将这些信息在自治系统中传播出去。每个路由器接收这些链路状态信息，并建立起完整的路由表。</p><p>从实际角度来看，二者的不同点是链路状态协议总是比距离向量协议收敛更快。收敛的意思是在路由发生变化后，例如在路由器关闭或链路出故障后，可以稳定下来。</p><p>OSPF与RIP（以及其他选路协议）的不同点在于，OSPF直接使用IP。也就是说，它并不使用UDP或TCP。对于IP首部的protocol字段，OSPF有其自己的值。</p><p>另外，作为一种链路状态协议而不是距离向量协议，OSPF还有着一些优于RIP的特点。</p><ol><li>OSPF可以对每个IP服务类型计算各自的路由集。这意味着对于任何目的，可以有多个路由表表项，每个表项对应着一个IP服务类型。</li><li>给每个接口指派一个无维数的费用。可以通过吞吐率、往返时间、可靠性或其他性能来进行指派。可以给每个IP服务类型指派一个单独的费用。</li><li>当对同一个目的地址存在着多个相同费用的路由时，OSPF在这些路由上平均分配流量。我们称之为流量平衡。</li><li>OSPF支持子网：子网掩码与每个通告路由相连。这样就允许将一个任何类型的IP地址分割成多个不同大小的子网。到一个主机的路由是通过全1子网掩码进行通告的。默认路由是以IP地址为0.0.0.0、网络掩码为全0进行通告的。</li><li>路由器之间的点对点链路不需要每端都有一个IP地址，我们称之为无编号网络。这样可以节省IP地址—现在非常紧缺的一种资源。</li><li>采用了一种简单鉴别机制。可以采用类似于RIP-2机制的方法指定一个明文口令。</li><li>OSPF采用多播，而不是广播形式，以减少不参与OSPF的系统负载。</li></ol><p>随着大部分厂商支持OSPF，在很多网络中OSPF将逐步取代RIP。</p><h2 id="BGP：边界网关协议">BGP：边界网关协议</h2><p>BGP系统与其他BGP系统之间交换网络可到达信息。这些信息包括数据到达这些网络所必须经过的自治系统AS中的所有路径。这些信息足以构造一幅自治系统连接图。然后，可以根据连接图删除选路环，制订选路策略。</p><p>首先，我们将一个自治系统中的IP数据报分成本地流量和通过流量。在自治系统中，本地流量是起始或终止于该自治系统的流量。也就是说，其信源IP地址或信宿IP地址所指定的主机位于该自治系统中。其他的流量则称为通过流量。在Internet中使用BGP的一个目的就是减少通过流量。</p><p>可以将自治系统分为以下几种类型：</p><ol><li>残桩自治系统(stub AS)，它与其他自治系统只有单个连接。 stub AS只有本地流量。</li><li>多接口自治系统(multihomed AS)，它与其他自治系统有多个连接，但拒绝传送通过流量。</li><li>转送自治系统(transit AS)，它与其他自治系统有多个连接，在一些策略准则之下，它可以传送本地流量和通过流量。</li></ol><p>这样，可以将Internet的总拓扑结构看成是由一些残桩自治系统、多接口自治系统以及转送自治系统的任意互连。残桩自治系统和多接口自治系统不需要使用BGP——它们通过运行EGP在自治系统之间交换可到达信息。</p><p>BGP允许使用基于策略的选路。由自治系统管理员制订策略，并通过配置文件将策略指定给BGP。制订策略并不是协议的一部分，但指定策略允许BGP实现在存在多个可选路径时选择路径，并控制信息的重发送。选路策略与政治、安全或经济因素有关。</p><p>BGP与RIP和OSPF的不同之处在于BGP使用TCP作为其传输层协议。两个运行BGP的系统之间建立一条TCP连接，然后交换整个BGP路由表。从这个时候开始，在路由表发生变化时，再发送更新信号。</p><p>BGP是一个距离向量协议，但是与（通告到目的地址跳数的）RIP不同的是，BGP列举了到每个目的地址的路由（自治系统到达目的地址的序列号）。这样就排除了一些距离向量协议的问题。采用16bit数字表示自治系统标识。</p><p>BGP通过定期发送keepalive报文给其邻站来检测TCP连接对端的链路或主机失败。两个报文之间的时间间隔建议值为30秒。应用层的keepalive报文与TCP的keepalive选项是独立的。</p><h2 id="CIDR：无类型域间选路">CIDR：无类型域间选路</h2><p>CIDR的基本观点是采用一种分配多个IP地址的方式，使其能够将路由表中的许多表项总和(summarization)成更少的数目。例如，如果给单个站点分配16个C类地址，以一种可以用总和的方式来分配这16个地址，这样，所有这16个地址可以参照Internet上的单个路由表表项。同时，如果有8个不同的站点是通过同一个Internet服务提供商的同一个连接点接入Internet的，且这8个站点分配的8个不同IP地址可以进行总和，那么，对于这8个站点，在Internet上，只需要单个路由表表项。</p><p>要使用这种总和，必须满足以下三种特性：</p><ol><li>为进行选路要对多个IP地址进行总和时，这些IP地址必须具有相同的高位地址比特。</li><li>路由表和选路算法必须扩展成根据 32 bit IP地址和32 bit掩码做出选路决策。</li><li>必须扩展选路协议使其除了32 bit地址外，还要有32 bit掩码。OSPF和RIP-2都能够携带第4版BGP所提出的32 bit掩码。</li></ol><p>CIDR同时还使用一种技术，使最佳匹配总是最长的匹配：即在32bit掩码中，它具有最大值。</p><h1>UDP：用户数据报协议</h1><h2 id="引言-v8">引言</h2><p>UDP是一个简单的面向数据报的运输层协议：进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。这与面向流字符的协议不同，如TCP，应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。</p><p>UDP数据报封装成一份IP数据报的格式如图11-1所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/UDP%E5%B0%81%E8%A3%85.png" alt></p><p>应用程序必须关心IP数据报的长度。如果它超过网络的MTU，那么就要对IP数据报进行分片。如果需要，源端到目的端之间的每个网络都要进行分片，并不只是发送端主机连接第一个网络才这样做。</p><h2 id="UDP首部">UDP首部</h2><p>UDP首部的各字段如图11-2所示。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/UDP%E9%A6%96%E9%83%A8.png" alt></p><p>UDP长度字段指的是UDP首部和UDP数据的字节长度。该字段的最小值为8字节（发送一份0字节的UDP数据报是OK）。这个UDP长度是有冗余的。IP数据报长度指的是数据报全长，因此UDP数据报长度是全长减去IP首部的长度。</p><h2 id="UDP检验和">UDP检验和</h2><p>UDP和TCP在首部中都有覆盖它们首部和数据的检验和。UDP的检验和是可选的，而TCP的检验和是必需的。</p><p>如果发送端没有计算检验和而接收端检测到检验和有差错，那么UDP数据报就要被悄悄地丢弃。不产生任何差错报文（当IP层检测到IP首部检验和有差错时也这样做）。UDP检验和是一个端到端的检验和。它由发送端计算，然后由接收端验证。其目的是为了发现UDP首部和数据在发送端到接收端之间发生的任何改动。</p><blockquote><p>注意，TCP发生检验和差错的比例与UDP相比要高得多。这很可能是因为在该系统中的TCP连接经常是“远程”连接（经过许多路由器和网桥等中间设备），而UDP一般为本地通信。</p></blockquote><h2 id="IP分片">IP分片</h2><p>物理网络层一般要限制每次发送数据帧的最大长度。任何时候IP层接收到一份要发送的IP数据报时，它要判断向本地哪个接口发送数据（选路），并查询该接口获得其MTU。IP把MTU与数据报长度进行比较，如果需要则进行分片。分片可以发生在原始发送端主机上，也可以发生在中间路由器上。</p><p>把一份IP数据报分片以后，只有到达目的地才进行重新组装（这里的重新组装与其他网络协议不同，它们要求在下一站就进行进行重新组装，而不是在最终的目的地）。重新组装由目的端的IP层来完成，其目的是使分片和重新组装过程对运输层（TCP和UDP）是透明的，除了某些可能的越级操作外。已经分片过的数据报有可能会再次进行分片（可能不止一次）。IP首部中包含的数据为分片和重新组装提供了足够的信息。</p><p>回忆IP首部（图3-1），下面这些字段用于分片过程。对于发送端发送的每份IP数据报来说，其标识字段都包含一个唯一值。该值在数据报分片时被复制到每个片中（我们现在已经看到这个字段的用途）。标志字段用其中一个比特来表示“更多的片”。除了最后一片外，其他每个组成数据报的片都要把该比特置1。片偏移字段指的是该片偏移原始数据报开始处的位置。另外，当数据报被分片后，每个片的总长度值要改为该片的长度值。</p><p>最后，标志字段中有一个比特称作“不分片”位。如果将这一比特置1，IP将不对数据报进行分片。相反把数据报丢弃并发送一个ICMP差错报文（“需要进行分片但设置了不分片比特”，见图6-3）给起始端。在下一节我们将看到出现这个差错的例子。</p><p>当IP数据报被分片后，每一片都成为一个分组，具有自己的IP首部，并在选择路由时与其他分组独立。这样，当数据报的这些片到达目的端时有可能会失序，但是在IP首部中有足够的信息让接收端能正确组装这些数据报片。</p><p>尽管IP分片过程看起来是透明的，但有一点让人不想使用它：即使只丢失一片数据也要重传整个数据报。为什么会发生这种情况呢？因为IP层本身没有超时重传的机制——由更高层来负责超时和重传（TCP有超时和重传机制，但UDP没有。一些UDP应用程序本身也执行超时和重传）。当来自TCP报文段的某一片丢失后，TCP在超时后会重发整个TCP报文段，该报文段对应于一份IP数据报。没有办法只重传数据报中的一个数据报片。事实上，如果对数据报分片的是中间路由器，而不是起始端系统，那么起始端系统就无法知道数据报是如何被分片的。就这个原因，经常要避免分片。文献[KentandMogul1987]对避免分片进行了论述。</p><blockquote><p>在一个以太网上，数据帧的最大长度是1500字节，其中1472字节留给数据，假定IP首部为20字节，UDP首部为8字节。</p></blockquote><p>IP数据报是指IP层端到端的传输单元（在分片之前和重新组装之后），分组是指在IP层和链路层之间传送的数据单元。一个分组可以是一个完整的IP数据报，也可以是IP数据报的一个分片。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/UDP%E5%88%86%E7%89%87%E4%B8%BE%E4%BE%8B.png" alt></p><h1>广播和多播</h1><h2 id="引言-v9">引言</h2><p>为了弄清广播和多播，需要了解主机对由信道传送过来帧的过滤过程。图12-1说明了这一过程。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%90%84%E5%B1%82%E5%AF%B9%E6%94%B6%E5%88%B0%E5%B8%A7%E7%9A%84%E8%BF%87%E6%BB%A4%E8%BF%87%E7%A8%8B.png" alt></p><p>首先，网卡查看由信道传送过来的帧，确定是否接收该帧，若接收后就将它传往设备驱动程序。通常网卡仅接收那些目的地址为网卡物理地址或广播地址的帧。另外，多数接口均被设置为混合模式，这种模式能接收每个帧的一个复制。作为一个例子，tcpdump使用这种模式。</p><p>目前，大多数的网卡经过配置都能接收目的地址为多播地址或某些子网多播地址的帧。对于以太网，当地址中最高字节的最低位设置为1时表示该地址是一个多播地址，用十六进制可表示为01:00:00:00:00:00（以太网广播地址ff:ff:ff:ff:ff:ff可看作是以太网多播地址的特例）。</p><p>如果网卡收到一个帧，这个帧将被传送给设备驱动程序（如果帧检验和错，网卡将丢弃该帧）。设备驱动程序将进行另外的帧过滤。首先，帧类型中必须指定要使用的协议（IP、ARP等等）。其次，进行多播过滤来检测该主机是否属于多播地址说明的多播组。设备驱动程序随后将数据帧传送给下一层，比如，当帧类型指定为IP数据报时，就传往IP层。IP根据IP地址中的源地址和目的地址进行更多的过滤检测。如果正常，就将数据报传送给下一层（如TCP或UDP）。</p><p>每次UDP收到由IP传送来的数据报，就根据目的端口号，有时还有源端口号进行数据报过滤。如果当前没有进程使用该目的端口号，就丢弃该数据报并产生一个ICMP不可达报文（TCP根据它的端口号作相似的过滤）。如果UDP数据报存在检验和错，将被丢弃。</p><p>使用广播的问题在于它增加了对广播数据不感兴趣主机的处理负荷。拿一个使用UDP广播应用作为例子。如果网内有50个主机，但仅有20个参与该应用，每次这20个主机中的一个发送UDP广播数据时，其余30个主机不得不处理这些广播数据报。一直到UDP层，收到的UDP广播数据报才会被丢弃。这30个主机丢弃UDP广播数据报是因为这些主机没有使用这个目的端口。</p><p>多播的出现减少了对应用不感兴趣主机的处理负荷。使用多播，主机可加入一个或多个多播组。这样，网卡将获悉该主机属于哪个多播组，然后仅接收主机所在多播组的那些多播帧。</p><h2 id="广播">广播</h2><h3 id="受限的广播">受限的广播</h3><p>受限的广播地址是255.255.255.255。该地址用于主机配置过程中IP数据报的目的地址，此时，主机可能还不知道它所在网络的网络掩码，甚至连它的IP地址也不知道。</p><p>在任何情况下，路由器都不转发目的地址为受限的广播地址的数据报，这样的数据报仅出现在本地网络中。</p><h3 id="指向网络的广播">指向网络的广播</h3><p>指向网络的广播地址是主机号为全1的地址。A类网络广播地址为netid.255.255.255，其中netid为A类网络的网络号。</p><p>一个路由器必须转发指向网络的广播，但它也必须有一个不进行转发的选择。</p><h3 id="指向子网的广播">指向子网的广播</h3><p>指向子网的广播地址为主机号为全1且有特定子网号的地址。作为子网直接广播地址的IP地址需要了解子网的掩码。例如，如果路由器收到发往128.1.2.255的数据报，当B类网络128.1的子网掩码为255.255.255.0时，该地址就是指向子网的广播地址；但如果该子网的掩码为255.255.254.0，该地址就不是指向子网的广播地址。</p><h3 id="指向所有子网的广播">指向所有子网的广播</h3><p>指向所有子网的广播也需要了解目的网络的子网掩码，以便与指向网络的广播地址区分开。指向所有子网的广播地址的子网号及主机号为全1。例如，如果目的子网掩码为255.255.255.0，那么IP地址128.1.255.255是一个指向所有子网的广播地址。然而，如果网络没有划分子网，这就是一个指向网络的广播。</p><h2 id="多播">多播</h2><p>IP多播提供两类服务：</p><ol><li>向多个目的地址传送数据。</li><li>客户对服务器的请求。例如，无盘工作站需要确定启动引导服务器。目前，这项服务是通过广播来提供的，但是使用多播可降低不提供这项服务主机的负担。</li></ol><h3 id="多播组地址">多播组地址</h3><p>图12-2显示了D类IP地址的格式。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/D%E7%B1%BBIP%E5%9C%B0%E5%9D%80%E6%A0%BC%E5%BC%8F.png" alt></p><p>多播组地址包括为1110的最高4bit和多播组号。它们通常可表示为点分十进制数，范围从224.0.0.0到239.255.255.255。</p><p>能够接收发往一个特定多播组地址数据的主机集合称为主机组(hostgroup)。一个主机组可跨越多个网络。主机组中成员可随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。</p><h2 id="小结-v6">小结</h2><p>广播是将数据报发送到网络中的所有主机（通常是本地相连的网络），而多播是将数据报发送到网络的一个主机组。这两个概念的基本点在于当收到送往上一个协议栈的数据帧时采用不同类型的过滤。每个协议层均可以因为不同的理由丢弃数据报。</p><p>目前有四种类型的广播地址：受限的广播、指向网络的广播、指向子网的广播和指向所有子网的广播。最常用的是指向子网的广播。受限的广播通常只在系统初始启动时才会用到。</p><p>试图通过路由器进行广播而发生的问题，常常是因为路由器不了解目的网络的子网掩码。结果与多种因素有关：广播地址类型、配置参数等等。</p><p>D类IP地址被称为多播组地址。通过将其低位23bit映射到相应以太网地址中便可实现多播组地址到以太网地址的转换。由于地址映射是不唯一的，因此需要其他的协议实现额外的数据报过滤。</p><h1>IGMP：Internet组管理协议</h1><h2 id="引言-v10">引言</h2><p><font color="DeepPink"><strong>本章将介绍用于支持主机和路由器进行多播的Internet组管理协议（IGMP）。它让一个物理网络上的所有系统知道主机当前所在的多播组。</strong></font>多播路由器需要这些信息以便知道多播数据报应该向哪些接口转发。</p><p>正如ICMP一样，IGMP也被当作IP层的一部分。IGMP报文通过IP数据报进行传输。不像我们已经见到的其他协议，IGMP有固定的报文长度，没有可选数据。图13-1显示了IGMP报文如何封装在IP数据报中。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/IGMP%E6%8A%A5%E6%96%87%E5%B0%81%E8%A3%85%E5%9C%A8IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E4%B8%AD.png" alt></p><p>IGMP报文通过IP首部中协议字段值为2来指明。</p><h2 id="IGMP报文">IGMP报文</h2><p>图13-2显示了长度为8字节的IGMP报文格式。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/IGMP%E6%8A%A5%E6%96%87%E7%9A%84%E5%AD%97%E6%AE%B5%E6%A0%BC%E5%BC%8F.png" alt></p><p>这是版本为1的IGMP。IGMP类型为1说明是由多播路由器发出的查询报文，为2说明是主机发出的报告报文。检验和的计算和ICMP协议相同。<br>组地址为D类IP地址。在查询报文中组地址设置为0，在报告报文中组地址为要参加的组地址。</p><h1>DNS：域名系统</h1><h2 id="引言-v11">引言</h2><p>域名系统（DNS）是一种用于TCP/IP应用程序的分布式数据库，它提供主机名字和IP地址之间的转换及有关电子邮件的选路信息。这里提到的分布式是指在Internet上的单个站点不能拥有所有的信息。</p><h2 id="DNS-基础">DNS 基础</h2><p>DNS的层次组织:</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/DNS%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%84%E7%BB%87.png" alt></p><p>每个问题有一个查询类型，而每个响应（也称一个资源记录，我们下面将谈到）也有一个类型。大约有20个不同的类型值，其中的一些目前已经过时。图14-7显示了其中的一些值。查询类型是类型的一个超集(superset)：图中显示的类型值中只有两个能用于查询类型。</p><p><img data-src="/images/tcp-ip-illustrated-volume-1-the-protocols/DNS%E9%97%AE%E9%A2%98%E5%92%8C%E5%93%8D%E5%BA%94%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%80%BC%E5%92%8C%E6%9F%A5%E8%AF%A2%E7%B1%BB%E5%9E%8B%E5%80%BC.png" alt></p><p>最常用的查询类型是A类型，表示期望获得查询名的IP地址。一个PTR查询则请求获得一个IP地址对应的域名。</p><p>查询类通常是1，指互联网地址（某些站点也支持其他非IP地址）。</p><h2 id="指针查询">指针查询</h2><p>DNS中一直难于理解的部分就是指针查询方式，即给定一个IP地址，返回与该地址对应的域名。</p><h2 id="小结-v7">小结</h2><p>应用程序通过名字解析器将一个主机名转换为一个IP地址，也可将一个IP地址转换为与之对应的主机名。名字解析器将向一个本地名字服务器发出查询请求，这个名字服务器可能通过某个根名字服务器或其他名字服务器来完成这个查询。</p><h1>TCP：传输控制协议</h1><h2 id="TCP的服务">TCP的服务</h2><p>TCP通过下列方式来提供可靠性：</p><ul><li>应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的数据报长度将保持不变。由TCP传递给IP的信息单位称为报文段或段（segment）。</li><li>当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。</li><li>当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。</li><li>TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）。</li><li>既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。</li><li>既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据。</li><li>TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。</li></ul><p>TCP对字节流的内容不作任何解释。TCP不知道传输的数据字节流是二进制数据，还是ASCII字符、EBCDIC字符或者其他类型数据。对字节流的解释由TCP连接双方的应用层解释。</p><blockquote><p>这种对字节流的处理方式与Unix操作系统对文件的处理方式很相似。Unix的内核对一个应用读或写的内容不作任何解释，而是交给应用程序处理。对Unix的内核来说，它无法区分一个二进制文件与一个文本文件。</p></blockquote><h1>未读章节</h1><p><font color="DeepPink"><strong>17章之后未读</strong></font></p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Network</tag>
        <tag>TCP</tag>
        <tag>IP</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Go 设计模式</title>
    <url>/go-solid-design.html</url>
    <content><![CDATA[<blockquote><p>Golang 代码设计及规范</p></blockquote><a id="more"></a><h1>代码评审</h1><p>为什么要代码评审？ 如果代码评审是要捕捉糟糕的代码，那么你如何知道你审查的代码是好的还是糟糕的？</p><p>我在找一些客观的方式来谈论代码的好坏属性。</p><h1>糟糕的代码</h1><p>你可能会在代码审查中遇到以下这些糟糕的代码：</p><ul><li>Rigid - 代码是否死板？它是否有强类型或参数以至于修改起来很困难？</li><li>Fragile - 代码是否脆弱？对代码做轻微的改变是否就会引起程序极大的破坏？</li><li>Immobile - 代码是否很难重构？</li><li>Complex - 代码是否过于复杂，是否过度设计？</li><li>Verbose - 代码是否过于冗长而使用起来很费劲？当查阅代码是否很难看出来代码在做什么？</li></ul><p>当你做代码审查的时候是否会很高兴看到这些词语？</p><p>当然不会。</p><h1>好的设计</h1><p>如果有一些描述优秀的设计属性的方式就更好了，不仅仅是糟糕的设计，是否能在客观条件下做？</p><h2 id="SOLID">SOLID</h2><p>在2002年，Robert Martin的《Agile Software Development, Principles, Patterns, and Practices》书中提到了五个可重用软件设计的原则 - “SOLID”（英文首字母缩略字）:</p><ul><li>Single Responsibility Principle - 单一功能原则</li><li>Open/Closed Principle - 开闭原则</li><li>Liskov Substitution Principle - 里氏替换原则</li><li>Interface Segregation Principle - 接口隔离原则</li><li>Dependency Inversion Principle - 依赖反转原则</li></ul><p>这本书有点点过时，使用的语言也是十多年前的。但是，或许SOLID原则的某些方面可以给我们一个有关如何谈论一个精心设计的Go语言程序的线索。</p><h3 id="Single-Responsibility-Principle">Single Responsibility Principle</h3><blockquote><p>A class should have one, and only one, reason to change. –Robert C Martin</p></blockquote><p>现在Go语言显然没有classses - 相反，我们有更为强大的组合的概念 - 但是如果你可以看到过去class的使用，我认为这里有其价值。</p><p>为什么一段代码应该只有一个原因改变如此重要？当然，和你自己的代码要修改比较起来，发现自己代码所依赖的代码要修改会更令人头疼。而且，当你的代码不得不要修改的时候，它应该对直接的刺激有反应，而不应该是一个间接伤害的受害者。</p><p>所以，代码有单一功能原则从而有最少的原因来改变。</p><h4 id="Coupling-Cohesion-耦合与内聚">Coupling&amp;Cohesion - 耦合与内聚</h4><p>这两个词语描绘了修改一段软件代码是何等的简单或困难。</p><p>Coupling - 耦合是两个东西一起改变 - 一个移动会引发另一个移动。<br>Cohesion - 内聚是相关联但又隔离，一种相互吸引的力量。</p><p>在软件方面，内聚是形容代码段自然吸引到另一个的属性。</p><p>要描述Go语言的耦合与内聚，我们可以要谈论一下functions和methods，当讨论单一功能原则时它们很常见，但是我相信它始于Go语言的package模型。</p><h4 id="Pakcage命名">Pakcage命名</h4><p>在Go语言中，所有的代码都在某个package中。好的package设计始于他的命名。package名字不仅描述了它的目的而且还是一个命名空间的前缀。Go语言标准库里有一些好的例子：</p><ul><li>net/http - 提供了http客户端和服务</li><li>os/exec - 执行外部的命令</li><li>encoding/json - 实现了JSON的编码与解码</li></ul><p>在你自己的项目中使用其他pakcage时要用import声明，它会在两个package之间建立一个源码级的耦合。</p><h4 id="糟糕的pakcage命名">糟糕的pakcage命名</h4><p>关注于命名并不是在卖弄。糟糕的命名会失去罗列其目的的机会。</p><p>比如说server、private、common、utils 这些糟糕的命名都很常见。这些package就像是一个混杂的场所，因为他们好多都是没有原因地经常改变。</p><h4 id="Go语言的UNIX哲学">Go语言的UNIX哲学</h4><p>以我的观点，涉及到解耦设计必须要提及Doug Mcllroy的Unix哲学：小巧而锋利的工具的结合解决更大的任务或者通常原创作者并没有预想到的任务。</p><p>我认为Go语言的Package体现了UNIX哲学精神。实际上每个package自身就是一个具有单一原则的变化单元的小型Go语言项目。</p><h3 id="Open-Closed-Principle">Open/Closed Principle</h3><p>Bertrand Meyer曾经写道：</p><blockquote><p>Software entities should be open for extension, but closed for modification. –Bertrand Meyer, Object-Oriented Software Construction</p></blockquote><p>该建议如何应用到现在的编程语言上：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">type A struct &#123;</span><br><span class="line">        year int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (a A) Greet() &#123; fmt.Println(&quot;Hello GolangUK&quot;, a.year) &#125;</span><br><span class="line"></span><br><span class="line">type B struct &#123;</span><br><span class="line">        A</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (b B) Greet() &#123; fmt.Println(&quot;Welcome to GolangUK&quot;, b.year) &#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">        var a A</span><br><span class="line">        a.year = 2016</span><br><span class="line">        var b B</span><br><span class="line">        b.year = 2016</span><br><span class="line">        a.Greet() // Hello GolangUK 2016</span><br><span class="line">        b.Greet() // Welcome to GolangUK 2016</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>typeA有一个year字段以及Greet方法。 typeB嵌入了A做为字段，从而，使B提供的Greet方法遮蔽了A的，调用时可以看到B的方法覆盖了A。</p><p>但是嵌入不仅仅是对于方法，它还能提供嵌入type的字段访问。如你所见，由于A和B都在同一个package内，B可以访问A的私有year字段就像B已经声明过。</p><p>因此嵌入是一个强大的工具，它允许Go语言type对扩展是开放的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">type Cat struct &#123;</span><br><span class="line">        Name string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c Cat) Legs() int &#123; return 4 &#125;</span><br><span class="line"></span><br><span class="line">func (c Cat) PrintLegs() &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type OctoCat struct &#123;</span><br><span class="line">        Cat</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (o OctoCat) Legs() int &#123; return 5 &#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">        var octo OctoCat</span><br><span class="line">        fmt.Println(octo.Legs()) // 5</span><br><span class="line">        octo.PrintLegs()         // I have 4 legs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上边这个例子中，typeCat有Legs方法来计算它有几条腿。我们嵌入Cat到一个新的typeOctoCat中，并声明Octocats有五条腿。然而，尽管OctoCat定义了自己有五条腿，但是PrintLegs方法被调用时会返回4。</p><p>这是因为PrintLegs在typeCat中定义。它会将Cat做为它的接收者，因此它会使用Cat的Legs方法。Cat并不了解已嵌入的type，因此它的嵌入方法不能被修改。</p><p>由此，我们可以说<font color="DeepPink"><strong>Go语言的types对扩展开放，但是对修改是关闭的。</strong></font></p><p>事实上，Go语言接收者的方法仅仅是带有预先声明形式的参数的function的语法糖而已：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (c Cat) PrintLegs() &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func PrintLegs(c Cat) &#123;</span><br><span class="line">        fmt.Printf(&quot;I have %d legs\n&quot;, c.Legs())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个function的接收者就是你传进去的参数，而且由于Go语言不知道重载，所以说OctoCats并不能替换普通的Cats，这就引出了接下来一个原则：</p><h3 id="Liskov-Substitution-Principle">Liskov Substitution Principle</h3><p>该原则由Barbara Liskov提出，大致上,它规定了两种类型如果调用者不能区分出他们行为的不同，那么他们是可替代的。</p><p>基于class的编程语言，里氏替换原则通常被解释为一个抽象基类的各种具体子类的规范。但是Go语言没有class或者inheritance（继承），因此就不能以抽象类的层次结构实现替换。</p><h4 id="Interfaces">Interfaces</h4><p>相反，Go语言的interface才有权替换。在Go语言中，type不需要声明他们具体要实现的某个interface，相反的，任何想要实现interface的type仅需提供与interface声明所匹配的方法。</p><p>就Go语言而言，隐式的interface要比显式的更令人满意，这也深刻地影响着他们使用的方式。</p><p><font color="DeepPink"><strong>精心设计的interface更可能是小巧的，流行的做法是一个interface只包含一个方法。逻辑上来讲小巧的interface使实现变得简单，反之就很难做到。</strong></font>这就导致了由常见行为连接的简单实现而组成的package。</p><h4 id="io-Reader">io.Reader</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Reader interface &#123;</span><br><span class="line">        // Read reads up to len(buf) bytes into buf.</span><br><span class="line">        Read(buf []byte) (n int, err error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我最喜爱的Go语言interface - io.Reader</p><p>interface io.Reader非常简单，Read读取数据到提供的buffer，并返回调用者读取数据的bytes的数量以及读取期间的任何错误。它看起来简单但是很强大。</p><p>因为io.Reader可以处理任何能转换为bytes流的数据，我们可以在任何事情上构建readers：string常量、byte数组、标准输入、网络数据流、gzip后的tar文件以及通过ssh远程执行的命令的标准输出。</p><p>所有这些实现对于另外一个都是可替换的，因为他们都履行了相同的简单合同。</p><p>因此，里氏替换原则在Go语言的应用，可以用 Jim Weirich 的格言来总结：</p><blockquote><p>Require no more, promise no less. –Jim Weirich</p></blockquote><p>接下来就到了”SOLID”第四个原则。</p><h3 id="Interface-Segregation-Principle">Interface Segregation Principle</h3><blockquote><p>Clients should not be forced to depend on methods they do not use. –Robert C. Martin</p></blockquote><p>在Go语言中，接口隔离原则的应用是指一个方法来完成其工作的孤立行为的过程。举个“栗子”，编写方法来保存一个文档结构到磁盘的任务。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Save writes the contents of doc to the file f.</span><br><span class="line">func Save(f *os.File, doc *Document) error</span><br></pre></td></tr></table></figure><p>我可以这样定义这个Save方法，使用*os.File做为保存Document的文件。但是这样做会有一些问题。</p><p>Save方法排除了保存数据到网络位置的选项。假如过后要加入网络储存的需求，那么该方法就需要修改也就意味着要影响到所有使用该方法的调用者。</p><p>因为Save直接地操作磁盘上的文件，测试起来很不方便。要验证其操作，测试不得不在文件被写入后读取其内容。另外测试必须确保f被写入一个临时的位置而且过后还要删除。</p><p>*os.File还包含了许多跟Save无关的方法，像读取路径以及检查路径是否是软连接。如果Save方法只使用*os.File相关的部分将会非常有用。</p><p>我们如何做呢？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied ReadWriterCloser.</span><br><span class="line">func Save(rwc io.ReadWriteCloser, doc *Document) error</span><br></pre></td></tr></table></figure><p>使用io.ReadWriteCloser来应用接口隔离原则，这样就重新定义了Save方法使用一个interface来描述更为通用的类型。</p><p>随着修改，任何实现了io.ReadWriteCloser接口的type都可以代替之前的*os.File。这使得Save不仅扩展了它的应用范围同时也给Save的调用者说明了type *os.File哪些方法是操作相关的。</p><p>做为Save的作者，我没有了在*os.File上调用无关的方法选项了，因为他们都被隐藏于io.ReadWriteCloser接口。我们可以进一步地应用接口隔离原则。</p><p>首先，Save方法不太可能会保持单一功能原则，因为它要读取的文件内容应该是另外一段代码的责任。因此我们可以缩小接口范围，只传入writing和closing。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied WriteCloser.</span><br><span class="line">func Save(wc io.WriteCloser, doc *Document) error</span><br></pre></td></tr></table></figure><p>其次，通过向Save提供一种机制来关闭它的数据流，会导致另外一个问题：wc会在什么情况下关闭。Save可能会无条件的调用Close或在成功的情况下调用Close。</p><p>如果它想要在写入document之后再写入额外的数据时会引起Save的调用者一个问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type NopCloser struct &#123;</span><br><span class="line">        io.Writer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Close has no effect on the underlying writer.</span><br><span class="line">func (c *NopCloser) Close() error &#123; return nil &#125;</span><br></pre></td></tr></table></figure><p>一个原始解决方案回事定义一个新的type，在其内嵌入io.Writer以及重写Close方法来阻止Save方法关闭底层数据流。</p><p>但是这样可能会违反里氏替换原则，如果NopCloser并没有关闭任何东西。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Save writes the contents of doc to the supplied Writer.</span><br><span class="line">func Save(w io.Writer, doc *Document) error</span><br></pre></td></tr></table></figure><p>一个更好的解决办法是重新定义Save只传入io.Writer，剥离它的所有责任除了写入数据到数据流。</p><p>通过对Save方法应用接口隔离原则，同时得到了最具体以及最通用的需求函数。我们现在可以使用Save方法来保存数据到任何实现了io.Writer的地方。</p><blockquote><p><font color="DeepPink"><strong>A great rule of thumb for Go is accept interfaces, return structs.</strong></font> –Jack Lindamood</p></blockquote><h3 id="Dependency-Inversion-Principle">Dependency Inversion Principle</h3><blockquote><p>High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions. –Robert C. Martin</p></blockquote><p>对于Go语言来讲，依赖反转意味着什么呢?</p><p>如果你应用以上所有的原则，代码已经被分解成离散的有明确责任和目的的package，你的代码应该描述了它的依赖interface以及这些interface应该只描述他们需要的功能行为。换句话说就是他们不会再过多的改变。</p><p>因此，我认为Martin所讲的在Go语言的应用是context，即你import graph（译注：后文用“导入图”代替）的结构。</p><p>在Go语言中，你的导入图必须是非循环。不遵守此非循环的需求会导致编译错误，但是更为严重的是它代表了一系列的设计错误。</p><p>所有条件都相同的情况下精心设计的导入图应该是广泛的以及相对平坦的，而不是又高又窄。如果你有一个package的函数在没有其他package的情况下就无法操作，也许这就表明了代码没有考虑pakcage的边界。</p><p>依赖反转原则鼓励你尽可能地像导入图一样在main package或者最高层级的处理程序内对具体细节负责，让低层级代码来处理抽象的接口。</p><h2 id="“SOLID”-Go语言设计">“SOLID” Go语言设计</h2><p>回顾一下，当应用到Go语言设计中，每个“SOLID”原则都是强有力的声明，但是加在一起他们有一个中心主题。</p><ul><li>单一功能原则鼓励你在package中构建functions、types以及方法表现出自然的凝聚力。types属于彼此，functions为单一目的服务。</li><li>开闭原则鼓励你使用嵌入将简单的type组合成更为复杂的。</li><li><font color="DeepPink"><strong>里氏替换原则鼓励你在package之间表达依赖关系时用interface，而非具体类型。</strong></font>通过定义小巧的interface，我们可以更有信心地切实满足其合约。</li><li>接口隔离原则鼓励你仅取决于所需行为来定义函数和方法。<font color="DeepPink"><strong>如果你的函数仅仅需要有一个方法的interface做为参数，那么它很有可能只有一个责任。</strong></font></li><li>依赖反转原则鼓励你在编译时将package所依赖的东西移除 - 在Go语言中我们可以看到这样做使得运行时用到的某个特定的package的import声明的数量减少。</li></ul><p>如果总结这个演讲（译注：该篇文章取自Dave大神在Golang UK Conference 2016的演讲文字内容，文章结尾处有YouTube链接）它可能会是： &gt; interfaces let you apply the SOLID principles to Go programs</p><p>因为interface描绘了他们的pakcage的规定，而不是如何规定的。换个说法就是“解耦”，这确实是我们的目标，因为解耦的软件修改起来更容易。</p><p>就像Sandi Metz提到的：</p><blockquote><p>Design is the art of arranging code that needs to work today, and to be easy to change forever. –Sandi Metz</p></blockquote><p>因为如果Go语言想要成为公司长期投资的编程语言，Go程序的维护，更容易的变更将是他们决定的关键因素。</p><h1>结尾</h1><p>Go语言程序员应当讨论更多的是设计而非框架。我们应当不惜一切代价地关注重用而非性能。</p><p>我想要看到是今天的人们谈论关于如何使用编程语言，无论是设计解决方案还是解决实际问题的选择和局限性。</p><p>我想要听到的是人们谈论如何通过精心设计、解耦、重用以及适应变化的方式来设计Go语言程序。</p><h1>…还有一点</h1><p>我们需要告诉世界优秀的软件该如何编写。告诉他们使用Go语言如何编写优秀的、可组合的及易于变化的软件。</p><p>原文链接：<a href="http://dave.cheney.net/2016/08/20/solid-go-design" target="_blank" rel="noopener">http://dave.cheney.net/2016/08/20/solid-go-design</a></p><blockquote><p>本文转载自：<br><a href="https://blog.gokit.info/post/go-solid-design/" target="_blank" rel="noopener">https://blog.gokit.info/post/go-solid-design/</a></p></blockquote>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Design</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 初始化顺序</title>
    <url>/golang-package-init-order.html</url>
    <content><![CDATA[<blockquote><p>golang package init order</p></blockquote><a id="more"></a><p>Go程序的初始化和执行总是从 main.main 函数开始的。但是如果 main 包里导入了其它的包，则会按照顺序将它们包含进 main 包里（这里的导入顺序依赖具体实现，一般可能是以文件名或包路径名的字符串顺序导入）。如果某个包被多次导入的话，在执行的时候只会导入一次。当一个包被导入时，如果它还导入了其它的包，则先将其它的包包含进来，然后创建和初始化这个包的常量和变量。然后就是调用包里的 init 函数，如果一个包有多个 init 函数的话，实现可能是以文件名的顺序调用，同一个文件内的多个 init 则是以出现的顺序依次调用（ init 不是普通函数，可以定义有多个，所以不能被其它函数调用）。最终，在 main 包的所有包常量、包变量被创建和初始化，并且 init 函数被执行后，才会进入 main.main 函数，程序开始正常执行。下图是Go程序函数启动顺序的示意图：</p><p><img data-src="/images/golang-package-init-order/init.png" alt></p><p>要注意的是，在 main.main 函数执行之前所有代码都运行在同一个Goroutine中，也是运行在程序的主系统线程中。如果某个 init 函数内部用go关键字启动了新的Goroutine的话，新的Goroutine和 main.main 函数是并发执行的。<br>因为所有的 init 函数和 main 函数都是在主线程完成，它们也是满足顺序一致性模型的。</p><blockquote><p>整理自：Go语言高级编程 作者：柴树杉、曹春晖<br>图片来自：beego官网router部分</p></blockquote>]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Init</tag>
        <tag>Order</tag>
      </tags>
  </entry>
  <entry>
    <title>Goroutine和系统线程</title>
    <url>/goroutine-and-system-threads.html</url>
    <content><![CDATA[<blockquote><p>goroutine and system threads</p></blockquote><a id="more"></a><p>Goroutine是Go语言特有的并发体，是一种轻量级的线程，由go关键字启动。在真实的Go语言的实现中，goroutine和系统线程也不是等价的。尽管两者的区别实际上只是一个量的区别，但正是这个量变引发了Go语言并发编程质的飞跃。</p><p>首先，每个系统级线程都会有一个固定大小的栈（一般默认可能是2MB），这个栈主要用来保存函数递归调用时参数和局部变量。固定了栈的大小导致了两个问题：一是对于很多只需要很小的栈空间的线程来说是一个巨大的浪费，二是对于少数需要巨大栈空间的线程来说又面临栈溢出的风险。针对这两个问题的解决方案是：要么降低固定的栈大小，提升空间的利用率；要么增大栈的大小以允许更深的函数递归调用，但这两者是没法同时兼得的。相反，<font color="DeepPink"><strong>一个Goroutine会以一个很小的栈启动（可能是2KB或4KB），当遇到深度递归导致当前栈空间不足时，Goroutine会根据需要动态地伸缩栈的大小（主流实现中栈的最大值可达到1GB）。</strong></font>因为启动的代价很小，所以我们可以轻易地启动成千上万个Goroutine。</p><p>Go的运行时还包含了其自己的调度器，这个调度器使用了一些技术手段，可以在n个操作系统线程上多工调度m个Goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的Goroutine。Goroutine采用的是半抢占式的协作调度，只有在当前Goroutine发生阻塞时才会导致调度；同时发生在用户态，调度器会根据具体函数只保存必要的寄存器，切换的代价要比系统线程低得多。运行时有一个 runtime.GOMAXPROCS 变量，用于控制当前运行正常非阻塞Goroutine的系统线程数目。</p><p>在Go语言中启动一个Goroutine不仅和调用函数一样简单，而且Goroutine之间调度代价也很低，这些因素极大地促进了并发编程的流行和发展。</p><blockquote><p>整理自：Go语言高级编程 作者：柴树杉、曹春晖</p></blockquote>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>Goroutine</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Go 密码学应用</title>
    <url>/golang-for-crypto-developers.html</url>
    <content><![CDATA[<blockquote><p>Go Crypto</p></blockquote><a id="more"></a><h1>视频信息</h1><p>Go for Crypto Developers<br>by George Tankersley<br>at GopherCon 2016</p><p><a href="https://www.youtube.com/watch?v=2r_KMzXB74w" target="_blank" rel="noopener">https://www.youtube.com/watch?v=2r_KMzXB74w</a></p><p>幻灯地址：<a href="https://speakerdeck.com/gtank/crypto-for-go-developers" target="_blank" rel="noopener">https://speakerdeck.com/gtank/crypto-for-go-developers</a><br>代码：<a href="https://github.com/gtank/cryptopasta" target="_blank" rel="noopener">https://github.com/gtank/cryptopasta</a></p><h1>Don’t write your own crypto</h1><p>很多人把这句话<font color="DeepPink"><strong>误解为</strong></font>不要使用加密、不要使用任何密码学的技术，因为你不够聪明。<font color="DeepPink"><strong>No。完全不是这个意思</strong></font>。</p><p>这句话是说<font color="DeepPink"><strong>不要试图去发明创造那些加密类的算法</strong></font>。因为你不大可能会创造一个超过 AES 的加密算法、也不大可能会创造一个比 SHA 更好的 hash 算法。所以自己闭门造的算法一般意味着安全性的大大降低。</p><p>全世界能干这件事情的人不超过5个，而且他们今天都不在这里。另外一半都是 <font color="DeepPink"><strong>Daniel J. Bernstein</strong></font> 干的（开个玩笑，不过这人很牛，今天我们在用的很多加密的东西都是他设计、实现的）。</p><p>表面上好像这是个限制，其实这是个优势。因为我们<font color="DeepPink"><strong>不需要</strong></font>编写自己的加密算法，一切痛苦的工作都已经由别人做好了。我们只需要和搭积木一样去使用这些密码学工具就好了。</p><h1>经常听到这样的建议</h1><ul><li>对传输中的数据用 TLS</li><li>对静止的数据用 GPG</li></ul><h2 id="TLS">TLS</h2><p>Go 可以很容易使用 TLS，因为必须的东西都内置了，从客户端到服务端。</p><p>客户端</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var minimalTLSConfig = &amp;tls.Config&#123;</span><br><span class="line">	MinVersion: tls.VersionTLS12,</span><br><span class="line">&#125;</span><br><span class="line">var tlsTransport = &amp;http.Transport&#123;</span><br><span class="line">	TLSClientConfig: minimalTLSConfig,</span><br><span class="line">&#125;</span><br><span class="line">var httpClient = &amp;http.Client&#123;</span><br><span class="line">	Transport: tlsTransport,</span><br><span class="line">	Timeout:   10 * time.Second,</span><br><span class="line">&#125;</span><br><span class="line">func MakeRequest() error &#123;</span><br><span class="line">	resp, err := httpClient.Get(&quot;https://www.google.com&quot;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	// have fun</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里最重要的是 tls.VersionTLS12，因为低于 1.2 的话，会导致 Go 使用一些不安全的低版本的实现，所以这里限定 1.2 比较安全。而且大部分网站也都支持。</p><p>服务端</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var minimalTLSConfig = &amp;tls.Config&#123;</span><br><span class="line">	MinVersion:               tls.VersionTLS12,</span><br><span class="line">	PreferServerCipherSuites: true,</span><br><span class="line">&#125;</span><br><span class="line">var srv = &amp;http.Server&#123;</span><br><span class="line">	Addr:      &quot;localhost:8080&quot;,</span><br><span class="line">	TLSConfig: minimalTLSConfig,</span><br><span class="line">&#125;</span><br><span class="line">func handleReq(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">	fmt.Fprintf(w, &quot;Hello, world&quot;)</span><br><span class="line">&#125;</span><br><span class="line">func main() &#123;</span><br><span class="line">	http.HandleFunc(&quot;/&quot;, handleReq)</span><br><span class="line">	err := srv.ListenAndServeTLS(&quot;cert.pem&quot;, &quot;key.pem&quot;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里和客户端一样，限定最小版本是 1.2，并且多了一个额外的参数，要求以服务器的 Cipher 优先，因此不按照客户端给的选择，而是按照Go服务端给的选择。因为 Go 的 TLS 包中有大量针对各种安全问题的调整，因此选择加密包的话，遵循 Go 内部的决定是最好的。</p><h2 id="GPG">GPG</h2><p>GPG 是为了人和人之间的交流信息，而不是机器和机器之间交流信息的。</p><p>那么如何安全的使用 GPG 呢？答案就是<font color="DeepPink"><strong>不用GPG</strong></font>。因为作者觉得 GPG 太过阴谋论了，陷入了很多本不需要过多注意的区域，即使那么做了，也不见得更安全。</p><h1>这个 Talk 不讲 TLS 和 GPG</h1><p>因为当你实现安全的信息系统的时候，通常不会用到这两个东西。TLS 和 GPG 有他们应用的场合，但是对于每天的密码学工作来说，基本都不用这两个工具：</p><ul><li>对文件计算散列</li><li>生成随机 ID</li><li>API 验证</li><li>网站密码存储</li><li>签名、加密 cookies</li><li>JWT</li><li>签名更新</li></ul><h1>在 Go 的 crypto 包里的算法可不都是好的算法</h1><h2 id="加密">加密</h2><p>下列划掉的算法都不应该再使用了：</p><ul><li><s>DES</s></li><li><pre><code class="language-3DES~~"></code></pre></li><li><s>RC4</s></li><li><s>TEA</s></li><li><s>XTEA</s></li><li><s>Blowfish</s></li><li>✔️ Twofish</li><li><s>CAST5</s></li><li>✔️ Salsa20</li><li>✔️ AES</li></ul><p>只有 Twofish、Salsa20 和 AES 还算是安全的加密算法，但是 AES 在大部分的计算机上都有硬件加速。因此只剩下一个 AES 是最佳加密算法。</p><h3 id="怎么使用-AES">怎么使用 AES</h3><p>要注意，aesCipher.Encrypt() <font color="DeepPink"><strong>只会加密前16个字节</strong></font>。不少人掉到这个坑里了，结果不知道为啥就前几个字符是密文，后面全都是明文。解决办法就是<font color="DeepPink"><strong>不直接用AES</strong></font>，通过 Mode 来使用。</p><p>Block cipher mode 一样有很多种选择：</p><ul><li><s>CBC</s></li><li><s>CFB</s></li><li><s>CTR</s></li><li><s>OFB</s></li><li>✔️ GCM</li></ul><p>这里只有 GCM 是<font color="DeepPink"><strong>验证的</strong></font>加密算法，因此别的都可以不选。</p><h4 id="加密-v2">加密</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;crypto/aes&quot;</span><br><span class="line">	&quot;crypto/cipher&quot;</span><br><span class="line">	&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func Encrypt(data []byte, key [32]byte) ([]byte, error) &#123;</span><br><span class="line">	//	初始化 block cipher</span><br><span class="line">	block, err := aes.NewCipher(key[:])</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	设置 block cipher mode</span><br><span class="line">	gcm, err := cipher.NewGCM(block)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	生成随机 nonce</span><br><span class="line">	nonce := make([]byte, gcm.NonceSize())</span><br><span class="line">	_, err = rand.Read(nonce)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	封装、返回</span><br><span class="line">	return gcm.Seal(nonce, nonce, data, nil), nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解密">解密</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;crypto/aes&quot;</span><br><span class="line">	&quot;crypto/cipher&quot;</span><br><span class="line">	&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func Decrypt(ciphertext []byte, key [32]byte) (plaintext []byte, err error) &#123;</span><br><span class="line">	//	初始化 block cipher</span><br><span class="line">	block, err := aes.NewCipher(key[:])</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	设置 block cipher mode</span><br><span class="line">	gcm, err := cipher.NewGCM(block)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	返回解开的包，注意这里的 nonce 是直接取的。</span><br><span class="line">	return gcm.Open(nil,</span><br><span class="line">		ciphertext[:gcm.NonceSize()],</span><br><span class="line">		ciphertext[gcm.NonceSize():],</span><br><span class="line">		nil,</span><br><span class="line">	)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="哈希散列">哈希散列</h2><p>将一大段数据使用 Hash 算法，希望得到一串数值，这串数值可以反映你的这段数据，任何数据变化，这串数值都不同。而且希望无法从这串数值反推数据。这就是密码学 Hash 函数要保证的。（<font color="DeepPink"><strong>注意：哈希不等于加密，很多人这点容易搞混</strong></font>）</p><p>同样 Hash 函数一样有很多选择，一样是大部分都不用：</p><ul><li><s>MD4</s></li><li><s>MD5</s></li><li><s>RIPEMD160</s></li><li><s>SHA1</s></li><li>✔️ SHA2</li><li>✔️ SHA3<br>选择 SHA3 并不是因为它比 SHA2 更新更好，而是因为它不同于 SHA1 和 SHA2。几年前密码学家已经开始担心，因为MD<font color="DeepPink"><strong>以及SHA</strong></font>的哈希算法本质太相似了，那么一旦这个依赖出现问题，就意味着这个体系的不再安全。因此开始寻找一种不同的算法。经过竞赛、挑选，最终 SHA3 脱颖而出。他本身是个很出色的 Hash 算法，同时其设计和之前的这几个算法完全不一样。</li></ul><p>但是由于 SHA3 并不被广泛支持，所以如果你明确知道你可以用 SHA3，那么就用 SHA3。其它情况用 SHA2。</p><p>但是和加密一样，我们<font color="DeepPink"><strong>不应该直接使用 Hash 算法</strong></font>。因为可能会面临一系列的攻击：</p><ul><li>Length extension</li><li>Rainbow tables</li><li>Small number of possibilities (phone numbers)</li><li>Salt? Peper?</li></ul><blockquote><p>我们应该使用 HMAC，而不要直接用 Hash</p></blockquote><h2 id="实现-Hash">实现 Hash</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;crypto/hmac&quot;</span><br><span class="line">	&quot;crypto/sha512&quot;</span><br><span class="line">)</span><br><span class="line">func Hash(tag string, data []byte) []byte &#123;</span><br><span class="line">	h := hmac.New(sha512.New512_256, []byte(tag))</span><br><span class="line">	h.Write(data)</span><br><span class="line">	return h.Sum(nil)</span><br><span class="line">&#125;</span><br><span class="line">func ExampleHash() error &#123;</span><br><span class="line">	tag := &quot;hashing file for storage key&quot;</span><br><span class="line">	contents, err := ioutil.ReadFile(&quot;testfile&quot;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return error</span><br><span class="line">	&#125;</span><br><span class="line">	digest := Hash(tag, contents)</span><br><span class="line">	fmt.Println(hex.EncodeToString(digest))</span><br><span class="line">&#125;</span><br><span class="line">//	Output:</span><br><span class="line">//	9f4c795d8ae5e207f19184ccebee6a606c1fdfe509c793614006d613580f03e1</span><br></pre></td></tr></table></figure><h2 id="Hash-密码">Hash 密码</h2><p>一般东西的 Hash 用刚才的就行了，但是<font color="DeepPink"><strong>除了密码Hash</strong></font>。密码 Hash 和数据 Hash 的特征完全不同。</p><ul><li><font color="DeepPink"><strong>数据</strong></font> Hash 希望的是 Hash 算法<font color="DeepPink"><strong>越快越好</strong></font></li><li>而<font color="DeepPink"><strong>密码</strong></font> Hash 则希望 Hash 算法<font color="DeepPink"><strong>越慢越好</strong></font></li></ul><blockquote><p>过快的密码哈希会导致暴力破解的成本降低。因此密码哈希需要特殊算法。</p></blockquote><h3 id="使用-bcrypt">使用 bcrypt</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;golang.org/x/crypto/bcrypt&quot;</span><br><span class="line">)</span><br><span class="line">func HashPassword(password []byte) ([]byte, error) &#123;</span><br><span class="line">	return bcrypt.GenerateFromPassword(password, 14)</span><br><span class="line">&#125;</span><br><span class="line">func CheckPasswordHash(hash, password []byte) error &#123;</span><br><span class="line">	return bcrypt.CompareHashAndPassword(hash, password)</span><br><span class="line">&#125;</span><br><span class="line">func Example() &#123;</span><br><span class="line">	myPassword := []byte(&quot;password&quot;)</span><br><span class="line">	hashed, err := HashPassword(myPassword)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(string(hashed))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>14 是计算量的复杂度，14 是个比较好的值，如果觉得性能无法接受，可以降到 12，但是不要再低了。</p><h2 id="签名">签名</h2><p>首先是有一对密钥，一个是公钥、一个是私钥。任何拥有私钥的人可以对一段信息签名，而所有拥有公钥的人都可以来验证这个消息确实是由那个人签名的。</p><p>通过签名可以确保两件事情：</p><ul><li>消息未曾被篡改</li><li>是谁发出的这个消息</li></ul><p>和前面一样，Go 有很多签名算法可以选择：</p><ul><li>RSA<ul><li><s>PKCS1v15</s></li><li>PSS</li></ul></li><li>ECDSA<ul><li>✔️ P256</li><li><s>P385</s></li><li><s>P521</s></li></ul></li><li>Ed25519</li></ul><p>这次和前面不同，签名算法的安全更多的<font color="DeepPink"><strong>不是取决于算法选择，而是取决于你是怎么使用的</strong></font>。</p><p>比如这里比较推荐使用 ECDSA/P256，但是要注意，当初 PS3 被黑，被解出私钥就是用的这个算法，当时是由于那个算法实现是非常烂的。幸运的是 Go 没这个问题。所以相对于其他语言，Go 可以使用这个比较安全的签名算法。</p><h3 id="实现">实现</h3><p>生成密钥</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;crypto/ecdsa&quot;</span><br><span class="line">	&quot;crypto/elliptic&quot;</span><br><span class="line">	&quot;crypto/rand&quot;</span><br><span class="line">)</span><br><span class="line">func NewSigningKey() (*ecdsa.PrivateKey, error) &#123;</span><br><span class="line">	return ecdsa.GenerateKey(elliptic.P256(), rand.Reader)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>签名数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func Sign(data []byte, priv *ecdsa.PrivateKey) ([]byte, error) &#123;</span><br><span class="line">	digest := sha256.Sum256(data)</span><br><span class="line">	r, s, err := ecdsa.Sign(rand.Reader, priv, digest[:])</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	//	encode the signature &#123;R, S&#125;</span><br><span class="line">	params := priv.Curve.Params()</span><br><span class="line">	curveByteSize := params.P.BitLen() / 8</span><br><span class="line">	rBytes, sBytes := r.Bytes(), s.Bytes()</span><br><span class="line">	signature := make([]byte, curveByteSize * 2)</span><br><span class="line">	copy(signature[curveByteSize - len(rBytes):], rBytes)</span><br><span class="line">	copy(signature[curveByteSize*2 - len(sBytes):], sBytes)</span><br><span class="line">	return signature, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>验证签名</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">	&quot;crypto/ecdsa&quot;</span><br><span class="line">	&quot;crypto/sha256&quot;</span><br><span class="line">	&quot;math/big&quot;</span><br><span class="line">)</span><br><span class="line">//	验证成功返回 true，否则 false</span><br><span class="line">func Verify(data, sig []byte, pub *ecdsa.PublicKey) bool &#123;</span><br><span class="line">	digest := sha256.Sum256(data)</span><br><span class="line">	curveByteSize := pub.Curve.Params().P.BitLen() / 8</span><br><span class="line">	r, s := new(big.Int), new(big.Int)</span><br><span class="line">	r.SetBytes(signature[:curveByteSize])</span><br><span class="line">	s.SetBytes(signature[curveByteSize:])</span><br><span class="line">	return ecdsa.Verify(pub, digest[:], r, s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>Crypto</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]gRPC 从学习到生产</title>
    <url>/golang-grpc-from-tutorial-to-production.html</url>
    <content><![CDATA[<blockquote><p>gRPC Practice<br>了解gRPC，更知REST</p></blockquote><a id="more"></a><h1>视频信息</h1><p>grpc: From Tutorial to Production<br>by Alan Shreve<br>at GopherCon 2017</p><p><a href="https://www.youtube.com/watch?v=7FZ6ZyzGex0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=7FZ6ZyzGex0</a></p><p>博文：<a href="https://about.sourcegraph.com/go/grpc-in-production-alan-shreve/" target="_blank" rel="noopener">https://about.sourcegraph.com/go/grpc-in-production-alan-shreve/</a></p><h1>微服务之间应该如何通讯？</h1><p>答案就是：<font color="DeepPink"><strong>SOAP</strong></font>……好吧，开个玩笑，当然不可能是 SOAP 了。</p><p>现在流行的做法是 <font color="DeepPink"><strong>HTTP + JSON (REST API)</strong></font></p><p>Alan 说“如果这辈子再也不写另一个 REST 客户端库的话，那就可以很幸福的死去了……😂”，因为这是最无聊的事情，一遍一遍的在做同样的事情。</p><h1>为什么 REST API 不好用？</h1><ul><li>实现 Stream 太难了</li><li>而双向的流就根本不可能</li><li>很难对操作建立模型</li><li>效率很差，文本表示对于网络来说并不是最好的选择</li><li>而且，其实服务内部根本不是 RESTful 的方式，这只是 HTTP endpoint</li><li>很难在一个请求中取得多个资源数据 （反例看 GraphQL）</li><li>没有正式的（机器可读的）API约束<ul><li>因此写客户端需要人类<ul><li>而且因为👷很贵，而且不喜欢写客户端</li></ul></li></ul></li></ul><h1>什么是 gRPC</h1><blockquote><p>gPRC 是高性能、开源、通用的 RPC 框架。</p></blockquote><p>与其讲解定义，不如来实际做个东西更清楚。</p><h1>建一个缓存服务</h1><p>使用 gRPC 这类东西，我们并非开始于写 Go 代码，我们是从撰写 gRPC 的 <a href="https://developers.google.com/protocol-buffers/docs/overview" target="_blank" rel="noopener">IDL</a> 开始的。</p><h2 id="app-proto">app.proto</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">syntax = &quot;proto3&quot;</span><br><span class="line">package rpc;</span><br><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message StoreReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br><span class="line">message StoreResp &#123;</span><br><span class="line">&#125;</span><br><span class="line">message GetReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">&#125;</span><br><span class="line">message GetResp &#123;</span><br><span class="line">  bytes val = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当写了这个文件后，我们立刻拥有了 <font color="DeepPink"><strong>9</strong></font> 种语言的客户端的库。</p><ul><li>C++</li><li>Java(and Android)</li><li>Python</li><li>Go</li><li>Ruby</li><li>C#</li><li>Javascript(node.js)</li><li>Objective-C (iOS!)</li><li>PHP</li></ul><p>同时，我们也拥有了 <font color="DeepPink"><strong>7</strong></font> 种语言的服务端的 API Stub：</p><ul><li>C++</li><li>Java</li><li>Python</li><li>Go</li><li>Ruby</li><li>C#</li><li>Javascript(node.js)</li></ul><h2 id="server-go">server.go</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func serverMain() &#123;</span><br><span class="line">  if err := runServer(); err != nil &#123;</span><br><span class="line">    fmt.Fprintf(os.Stderr, &quot;Failed to run cache server: %s\n&quot;, err)</span><br><span class="line">    os.Exit(1)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">func runServer() error &#123;</span><br><span class="line">  srv := grpc.NewServer()</span><br><span class="line">  rpc.RegisterCacheServer(srv, &amp;CacheService&#123;&#125;)</span><br><span class="line">  l, err := net.Listen(&quot;tcp&quot;, &quot;localhost:5051&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  //  block</span><br><span class="line">  return srv.Serve(l)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>暂时先不实现 CacheService，先放个空的，稍后再实现。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  return nil, fmt.Errorf(&quot;unimplemented&quot;)</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  return nil, fmt.Errorf(&quot;unimplemented&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="client-go">client.go</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func clientMain() &#123;</span><br><span class="line">  if err != runClient(); err != nil &#123;</span><br><span class="line">    fmt.Fprintf(os.Stderr, &quot;failed: %v\n&quot;, err)</span><br><span class="line">    os.Exit(1)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">func runClient() error &#123;</span><br><span class="line">  //  建立连接</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5053&quot;, grpc.WithInsecure())</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to dial server: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  cache := rpc.NewCacheClient(conn)</span><br><span class="line">  //  调用 grpc 的 store() 方法存储键值对 &#123; &quot;gopher&quot;: &quot;con&quot; &#125;</span><br><span class="line">  _, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  //  调用 grpc 的 get() 方法取回键为 `gopher` 的值</span><br><span class="line">  resp, err := cache.Get(context.Background(), &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to get: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  //  输出</span><br><span class="line">  fmt.Printf(&quot;Got cached value %s\n&quot;, resp.Val)</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="这不就是-WSDL-么？">这不就是 WSDL 么？</h2><p>或许有些人会认为这和 <font color="DeepPink"><strong>WSDL</strong></font> 也太像了，这么想没有错，因为 gRPC 在借鉴之前的 SOAP/WSDL 的错误基础上，也吸取了他们优秀的地方。</p><ul><li>和 XML 关系没那么紧(grpc 是可插拔式的，可以换成各种底层表述)</li><li>写过 XML/XSD 的人都知道这些服务定义太繁重了，gRPC 没有这个问题</li><li>WSDL这类有完全不必要的复杂度、和基本不需要的功能（两步 commit）</li><li>WSDL 不灵活、而且无法前向兼容（不像 <a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener">protobuf</a>）</li><li>SOAP/WSDL 性能太差，以及无法使用流</li><li>但是WSDL中的机器可以理解的API定义确实是个好东西</li></ul><h2 id="实现具体的-CacheService">实现具体的 CacheService</h2><p>server.go</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">  store map[string][]byte</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  val := s.store[req.Key]</span><br><span class="line">  return &amp;rpc.GetResp&#123;Val: val&#125;, nil</span><br><span class="line">&#125;</span><br><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  s.store[req.Key] = req.Val</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里没有锁，你可以想想他们中有，因为将来他们会被并发的调用的。</p><h2 id="错误处理">错误处理</h2><p>当然，gRPC 支持错误处理。假设改写上面的 Get()，对不存在的键进行报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Get(ctx context.Context, req *rpc.GetReq) (*rpc.GetResp, error) &#123;</span><br><span class="line">  val, ok := s.store[req.Key]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return nil, status.Errorf(code.NotFound, &quot;Key not found %s&quot;, req.Key)</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rpc.GetResp&#123;Val: val&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="加密传输">加密传输</h2><p>如果这样的代码打算去部署的话，一定会被 <a href="https://en.wikipedia.org/wiki/Site_reliability_engineering" target="_blank" rel="noopener">SRE</a> 拦截下来，因为所有通讯必须加密传输。</p><p>在 gRPC 中添加 TLS 加密传输很容易。比如我们修改 runServer() 添加 TLS 加密传输。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  tlsCreds, err := credentials.NewServerTLSFromFile(&quot;tls.crt&quot;, &quot;tls.key&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，我们也需要修改一下 runClient()。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  tlsCreds := credentials.NewTLS(&amp;tls.Config(InsecureSkipVerify: true))</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5051&quot;, grpc.WithTransportCredentials(tlsCreds))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1>生产环境如何使用 gRPC</h1><ul><li>HTTP/2</li><li>protobuf serialization (pluggable)</li><li>客户端会和 grpc 服务器打开一个长连接<ul><li>对于每一个 RPC 调用都将是一个新的 HTTP/2 stream</li><li>允许模拟飞行模式的 RPC 调用</li></ul></li><li>允许客户端 <font color="DeepPink"><strong>和</strong></font> 服务端 Streaming</li></ul><h2 id="gRPC-的实现">gRPC 的实现</h2><p>现在有3个高性能的、事件驱动的实现</p><ul><li>C<ul><li>Ruby, Python, Node.js, PHP, C#, Objective-C, C++ 都是对这个 C core 实现的绑定</li><li>PHP 则是通过 PECL 和这个实现的绑定</li></ul></li><li>Java<ul><li>Netty + BoringSSL 通过 JNI</li></ul></li><li>Go<ul><li>纯 Go 实现，使用了 Go 标准库的 crypto/tls</li></ul></li></ul><h2 id="gRPC-从哪来的">gRPC 从哪来的</h2><ul><li>最初是 Google 的一个团队创建的</li><li>更早期的是 Google 一个内部项目叫做 stubby</li><li>这个 gRPC 是其下一代开源项目，并且现在不仅仅是 Google 在使用，很多公司都在贡献代码<ul><li>当然，Google 还是主要代码贡献者</li></ul></li></ul><h2 id="生产环境案例：多租户">生产环境案例：多租户</h2><p>上线生产后，发现有一部分客户产生了大量的键值，询问得知，有的客户希望对所有东西都缓存，这显然不是对我们这个缓存服务很好的事情。</p><p>我们希望限制这种行为，但对于当前系统而言，无法满足这种需求，因此我们需要修改实现，对每个客户发放客户 token，那么我们就可以约束特定客户最多可以建立多少键值，避免系统滥用。这就成为了多租户的缓存服务。</p><p>和之前一样，我们还是从 IDL 开始，我们需要修改接口，增加 account_token 项。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">message StoreReq &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">  string account_token = 3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，我们需要有独立的服务针对账户服务，来获取账户所允许的缓存键数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service Accounts &#123;</span><br><span class="line">  rpc GetByToken(GetByTokenReq) return (GetByTokenResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message GetByTokenReq &#123;</span><br><span class="line">  string token = 1;</span><br><span class="line">&#125;</span><br><span class="line">message GetByTokenResp &#123;</span><br><span class="line">  Account account = 1;</span><br><span class="line">&#125;</span><br><span class="line">message Account &#123;</span><br><span class="line">  int64 max_cache_keys = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里建立了一个新的 Accounts 服务，并且有一个 GetByToken() 方法，给入 token，返回一个 Account 类型的结果，而 Account 内有 max_cache_keys 键对应最大可缓存的键值数。</p><p>现在我们进一步修改 <font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  cache := rpc.NewCacheClient(conn)</span><br><span class="line">  _, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;</span><br><span class="line">    AccountToken: &quot;inconshreveable&quot;,</span><br><span class="line">    Key:          &quot;gopher&quot;,</span><br><span class="line">    Val:          []byte(&quot;con&quot;),</span><br><span class="line">  &#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务端的改变要稍微大一些，但不过分。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type CacheService struct &#123;</span><br><span class="line">  accounts      rpc.AccountsClient</span><br><span class="line">  store         map[string][]byte</span><br><span class="line">  keysByAccount map[string]int64</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里的 accounts 是一个 grpc 的客户端，因为我们这个服务，同时也是另一个 grpc 服务的客户端。所以在接下来的 Store() 实现中，我们需要先通过 accounts 调用另一个服务取得账户信息。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  //  调用另一个服务取得账户信息，包含其键值限制</span><br><span class="line">  resp, err := s.accounts.GetByToken(context.Background(), &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return nil, err</span><br><span class="line">  &#125;</span><br><span class="line">  //  检查是否超量使用</span><br><span class="line">  if s.keysByAccount[req.AccountToken] &gt;= resp.Account.MaxCacheKeys &#123;</span><br><span class="line">    return nil, status.Errorf(codes.FailedPrecondition, &quot;Account %s exceeds max key limit %d&quot;, req.AccountToken, resp.Account.MaxCacheKeys)</span><br><span class="line">  &#125;</span><br><span class="line">  //  如果键不存在，需要新加键值，那么我们就对计数器加一</span><br><span class="line">  if _, ok := s.store[req.Key]; !ok &#123;</span><br><span class="line">    s.keysByAccount[req.AccountToken] += 1</span><br><span class="line">  &#125;</span><br><span class="line">  //  保存键值</span><br><span class="line">  s.store[req.Key] = req.Val</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：性能">生产环境案例：性能</h2><p>上面的问题解决了，我们服务又恢复了正常，不会有用户建立过多的键值了。但是很快，我们就又收到了其他用户发来的新的 issue，很多人反应说新系统变慢了，没有达到 <a href="https://en.wikipedia.org/wiki/Service-level_agreement" target="_blank" rel="noopener">SLA</a> 的要求。</p><p>可是我们根本不知道到底发生了什么，于是意识到了，我们的程序没有任何可观察性（Observability），换句话说，我们的程序没有任何计量系统来统计性能相关的数据。</p><p>我们先从最简单的做起，添加日志。</p><p>我们先从 <font color="DeepPink"><strong>client.go</strong></font> 开始，增加一些测量和计数以及日志输出。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">//  开始计时</span><br><span class="line">start := time.Now()</span><br><span class="line">_, err = cache.Store(context.Background(), &amp;rpc.StoreReq&#123;</span><br><span class="line">  AccountToken: &quot;inconshreveable&quot;,</span><br><span class="line">  Key:          &quot;gopher&quot;,</span><br><span class="line">  Val:          []byte(&quot;con&quot;),</span><br><span class="line">&#125;)</span><br><span class="line">//  计算 cache.Store() 调用时间</span><br><span class="line">log.Printf(&quot;cache.Store duration %s&quot;, time.Since(start))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">  return fmt.Errorf(&quot;failed to store: %v&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line">//  再次开始计时</span><br><span class="line">start = time.Now()</span><br><span class="line">//  调用 grpc 的 get() 方法取回键为 `gopher` 的值</span><br><span class="line">resp, err := cache.Get(context.Background(), &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">//  计算 cache.Get() 调用时间</span><br><span class="line">log.Printf(&quot;cache.Get duration %s&quot;, time.Since(start))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">  return fmt.Errorf(&quot;failed to get: %v&quot;, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，在服务端也这么处理。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  //  开始计时</span><br><span class="line">  start := time.Now()</span><br><span class="line">  //  调用另一个服务取得账户信息，包含其键值限制</span><br><span class="line">  resp, err := s.accounts.GetByToken(context.Background(), &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  //  输出 account.GetByToken() 的调用时间</span><br><span class="line">  log.Printf(&quot;accounts.GetByToken duration %s&quot;, time.Since(start))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过这些修改后，我们发现一样的事情在反反复复的做，那么有什么办法可以改变这种无聊的做法么？查阅 grpc 文档后，看到有一个叫做 <font color="DeepPink"><strong>Client Interceptor</strong></font> 的东西。</p><p>这相当于是一个中间件，但是是在客户端。当客户端进行 rpc 调用的时候，这个中间件先会被调用，因此这个中间件可以对调用进行一层包装，然后再进行调用。</p><p>为了实现这个功能，我们创建一个新的文件，叫做 interceptor.go：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func WithClientInterceptor() grpc.DialOption &#123;</span><br><span class="line">  return grpc.WithUnaryInterceptor(clientInterceptor)</span><br><span class="line">&#125;</span><br><span class="line">func clientInterceptor(</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  method string,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  reply interface&#123;&#125;,</span><br><span class="line">  cc *grpc.ClientConn,</span><br><span class="line">  invoker grpc.UnaryInvoker,</span><br><span class="line">  opts ...grpc.CallOption,</span><br><span class="line">) error &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  err := invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">  log.Printf(&quot;invoke remote method=%s duration=%s error=%v&quot;, method, time.Since(start), err)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们有了这个 WithClientInterceptor() 之后，可以在 grpc.Dial() 的时候注册进去。<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  conn, err := grpc.Dial(&quot;localhost:5051&quot;,</span><br><span class="line">    grpc.WithTransportCredentials(tlsCreds),</span><br><span class="line">    WithClientInterceptor())</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注册之后，所有的 grpc 调用都会经过我们注册的 clientInterceptor()，因此所有的时间就都有统计了，而不用每个函数内部反反复复的添加时间、计量、输出。</p><p>添加了客户端的这个计量后，自然而然就联想到服务端是不是也可以做同样的事情？经过查看文档，可以，有个叫做 <font color="DeepPink"><strong>Server Interceptor</strong></font> 的东西。</p><p>同样的做法，我们在服务端添加 interceptor.go，并且添加 ServerInterceptor() 函数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func ServerInterceptor() grpc.ServerOption &#123;</span><br><span class="line">  return grpc.UnaryInterceptor(serverInterceptor)</span><br><span class="line">&#125;</span><br><span class="line">func serverInterceptor(</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  info *grpc.UnaryServerInfo,</span><br><span class="line">  handler grpc.UnaryHandler,</span><br><span class="line">) (interface&#123;&#125;, error) &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  resp, err := handler(ctx, req)</span><br><span class="line">  log.Printf(&quot;invoke server method=%s duration=%s error=%v&quot;,</span><br><span class="line">    info.FullMethod,</span><br><span class="line">    time.Since(start),</span><br><span class="line">    err)</span><br><span class="line">  return resp, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和客户端一样，需要在 runServer() 的时候注册我们定义的这个中间件。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds), ServerInterceptor())</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：超时">生产环境案例：超时</h2><p>添加了日志后，我们终于在日志中发现，/rpc.Accounts/GetByToken/ 花了好长的时间。我们需要对这个操作设置超时。<br><font color="DeepPink"><strong>server.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  accountsCtx, _ := context.WithTimeout(context.Background(), 2 * time.Second)</span><br><span class="line">  resp, err := s.accounts.GetByToken(accountsCtx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里操作很简单，直接使用标准库中 context.WithTimeout() 就可以了。</p><h2 id="生产环境案例：上下文传递">生产环境案例：上下文传递</h2><p>经过上面修改后，客户依旧抱怨说没有满足 SLA，仔细一想也对。就算这里约束了 2 秒钟，客户端调用还需要时间，别的代码在中间也有时间开销。而且有的客户说，我们这里需要1秒钟，而不是2秒钟。</p><p>好吧，让我们把这个时间设定推向调用方。</p><p>首先我们要求在客户端进行调用时间约束的设定：<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ := context.WithTimeout(context.Background(), time.Second)</span><br><span class="line">  _, err = cache.Store(ctx, &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ = context.WithTimeout(context.Background(), 50*time.Millisecond)</span><br><span class="line">  resp, err := cache.Get(ctx, &amp;rpc.GetReq&#123;Key: &quot;gopher&quot;&#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在服务端，我们将上下文传递。直接取调用方的 ctx。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  resp, err := s.accounts.GetByToken(ctx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：GRPC-Metadata">生产环境案例：GRPC Metadata</h2><p>上面的问题都解决了，终于可以松一口气了。可是客户又提新的需求了……😅，说我们能不能增加一个 Dry Run 的标志，就是说我希望你做所有需要做的事情，除了真的修改键值库。</p><p>GRPC metadata，也称为 GRPC 的 Header。就像 HTTP 头一样，可以有一些 Metadata 信息传递过来。使用 metadata，可以让我们的 Dry Run 的实现变得更简洁，不必每个 RPC 方法内都实现一遍检查 Dry Run 标志的逻辑，我们可以独立出来。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Store(ctx context.Context, req *rpc.StoreReq) (*rpc.StoreResp, error) &#123;</span><br><span class="line">  resp, err := s.accounts.GetByToken(ctx, &amp;rpc.GetByTokenReq&#123;</span><br><span class="line">    Token: req.AccountToken,</span><br><span class="line">  &#125;)</span><br><span class="line">  if !dryRun(ctx) &#123;</span><br><span class="line">    if _, ok := s.store[req.Key]; !ok &#123;</span><br><span class="line">      s.keysByAccount[req.AccountToke] += 1</span><br><span class="line">    &#125;</span><br><span class="line">    s.store[req.Key] = req.Val</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rpc.StoreResp&#123;&#125;, nil</span><br><span class="line">&#125;</span><br><span class="line">func dryRun(ctx context.Context) bool &#123;</span><br><span class="line">  md, ok := metadata.FromContext(ctx)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  val, ok := md[&quot;dry-run&quot;]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  if len(val) &lt; 1 &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line">  return val[0] == &quot;1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，这么做是有妥协的，因为通用化后就失去了类型检查的能力。</p><p>在客户端调用的时候，则需要根据情况添加 dry-run 参数给 metadata。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  ctx, _ := context.WithTimeout(context.Background(), time.Second)</span><br><span class="line">  ctx = metadata.NewContext(ctx, metadata.Pairs(&quot;dry-run&quot;, &quot;1&quot;))</span><br><span class="line">  _, err = cache.Store(ctx, &amp;rpc.StoreReq&#123;Key: &quot;gopher&quot;, Val: []byte(&quot;con&quot;)&#125;)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：Retry">生产环境案例：Retry</h2><p>实现了 Dry Run 以为可以休息了，之前抱怨慢的客户又来抱怨了，虽然有超时控制，满足 SLA，但是服务那边还是慢，总超时不成功。检查了一下，发现是网络上的事情，我们没有太多可以做的事情。为了解决客户的问题，我们来添加一个重试的机制。</p><p>我们可以对每一个 gRPC 调用添加一个 Retry 机制，我们也可以像之前计时统计那样，使用 Interceptor 吧？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func clientInterceptor(...) error &#123;</span><br><span class="line">  var (</span><br><span class="line">    start     = time.Now()</span><br><span class="line">    attempts  = 0</span><br><span class="line">    err       error</span><br><span class="line">    backoff   retryBackOff</span><br><span class="line">  )</span><br><span class="line">  for &#123;</span><br><span class="line">    attempts += 1</span><br><span class="line">    select &#123;</span><br><span class="line">    case &lt;-ctx.Done():</span><br><span class="line">      err = status.Errorf(codes.DeadlineExceeded, &quot;timeout reached before next retry attempt&quot;)</span><br><span class="line">    case &lt;-backoff.Next():</span><br><span class="line">      startAttempt := time.Now()</span><br><span class="line">      err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">      if err != nil &#123;</span><br><span class="line">        log.Printf(...)</span><br><span class="line">        continue</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    break</span><br><span class="line">  &#125;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来还不错，然后就打算发布这个代码了。结果提交审核的时候被打回来了，说这个代码不合理，因为如果是<font color="DeepPink"><strong>非幂等（non-idempotent）</strong></font> 的操作，这样就会导致多次执行，改变期望结果了。</p><p>看来我们得针对幂等和非幂等操作区别对待了。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">silo.FireZeMissiles(NotIdempotent(ctx), req)</span><br></pre></td></tr></table></figure><p>嗯，当然，没这个东西。所以我们需要自己来创造一个标记，通过 context，来标明操作是否幂等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func NotIdempotent(ctx context.Context) context.Context &#123;</span><br><span class="line">  return context.WithValue(ctx, &quot;idempotent&quot;, false)</span><br><span class="line">&#125;</span><br><span class="line">func isIdempotent(ctx context.Context) bool &#123;</span><br><span class="line">  val, ok := ctx.Value(&quot;idempotent&quot;).(bool)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return true</span><br><span class="line">  &#125;</span><br><span class="line">  return val</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在我们的 clientInterceptor() 实现中加入 isIdempotent() 判断：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func clientInterceptor(...) error &#123;</span><br><span class="line">  var (</span><br><span class="line">    start     = time.Now()</span><br><span class="line">    attempts  = 0</span><br><span class="line">    err       error</span><br><span class="line">    backoff   retryBackOff</span><br><span class="line">  )</span><br><span class="line">  for &#123;</span><br><span class="line">    attempts += 1</span><br><span class="line">    select &#123;</span><br><span class="line">    case &lt;-ctx.Done():</span><br><span class="line">      err = status.Errorf(codes.DeadlineExceeded, &quot;timeout reached before next retry attempt&quot;)</span><br><span class="line">    case &lt;-backoff.Next():</span><br><span class="line">      startAttempt := time.Now()</span><br><span class="line">      err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">      if err != nil &amp;&amp; isIdempotent(ctx) &#123;</span><br><span class="line">        log.Printf(...)</span><br><span class="line">        continue</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    break</span><br><span class="line">  &#125;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样当调用失败后，客户端检查发现是幂等的情况，才重试，否则不重试。避免了非幂等操作的反复操作。</p><h2 id="生产环境案例：结构化错误">生产环境案例：结构化错误</h2><p>感觉没啥问题了，于是部署上线了。可是运行一段时间后，发现有些不对劲。所有成功的RPC调用，也就是说这个操作本身是正确的，都没有问题，超时重试也正常。但是所有失败的 RPC 调用都不对了，所有失败的 RPC 调用，都返回超时，而不是错误本身。这里说的失败，不是说网络问题导致超时啥的，而是说请求本身的失败，比如之前提到的，Get() 不存在的键，应该返回错误；或者 Store() 超过了配额，应该返回错误，这类错误在日志中都没看到，反而都对应了超时。</p><p>经过分析发现，服务端该报错都报错，没啥问题，但是客户端不对，本应该返回错误给调用方的地方，客户端代码反而又开始重试这个操作了。看来之前重试的代码还有问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">err = invoker(ctx, method, req, reply, cc, opts...)</span><br><span class="line">if err != nil &amp;&amp; isIdempotent(ctx) &#123;</span><br><span class="line">  log.Printf(...)</span><br><span class="line">  continue</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果仔细观察这部分代码，会发现，无论 err 是什么，只要非 nil，我们就重试。其实这是不对的，我们只有针对某些错误重试，比如网络问题之类的，而不应该对我们希望返回给调用方的错误重试，那没有意义。</p><p>那么问题就变成了，我们到底应该怎么对 err 判断来决定是否重试？</p><ul><li>可以使用不同的 Error Code，特定的 Code 需要 Retry，其它的不需要，那就需要自定义 gRPC 错误码；</li><li>我们也可以定义一个 Error 类型的数据，里面包含了某种标志位，来告知是否值得 retry</li><li>或者干脆把错误码放到 Response 的消息里，确保每个消息都有一个我们定义的错误码，来标明是否需要 retry。</li></ul><p>所以，我们需要的是一个完整的结构化的错误信息，而不是简单的一个 Error Code 和字符串。当然这条路不好走，但是我们已经做了这么多了，坚持一下还是可以克服的。</p><p>这里我们还是从 IDL 开始：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">message Error &#123;</span><br><span class="line">  int64 code = 1;</span><br><span class="line">  string messsage = 2;</span><br><span class="line">  bool temporary = 3;</span><br><span class="line">  int64 userErrorCode = 4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们实现这个 Error 类型。<br><font color="DeepPink"><strong>rpc/error.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (e *Error) Error() string &#123;</span><br><span class="line">  return e.Message</span><br><span class="line">&#125;</span><br><span class="line">func Errorf(code codes.Code, temporary bool, msg string, args ..interface&#123;&#125;) error &#123;</span><br><span class="line">  return &amp;Error&#123;</span><br><span class="line">    Code:      int64(code),</span><br><span class="line">    Message:   fmt.Sprintf(msg, args...),</span><br><span class="line">    Temporary: temporary,</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有这两个函数，我们可以显示和构造这个 Error 类型的变量了，但是我们该怎么把错误消息传回客户端呢？然后问题就开始变的繁琐起来了：<br><font color="DeepPink"><strong>rpc/error.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func MarshalError (err error, ctx context.Context) error &#123;</span><br><span class="line">  rerr, ok := err.(*Error)</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  pberr, marshalerr := pb.Marshal(rerr)</span><br><span class="line">  if marshalerr == nil &#123;</span><br><span class="line">    md := metadata.Pairs(&quot;rpc-error&quot;, base64.StdEncoding.EncodeToString(pberr))</span><br><span class="line">    _ = grpc.SetTrailer(ctx, md)</span><br><span class="line">  &#125;</span><br><span class="line">  return status.Errorf(codes.Code(rerr.Code), rerr.Message)</span><br><span class="line">&#125;</span><br><span class="line">func UnmarshalError(err error, md metadata.MD) *Error &#123;</span><br><span class="line">  vals, ok := md[&quot;rpc-error&quot;]</span><br><span class="line">  if !ok &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  buf, err := base64.StdEncoding.DecodeString(vals[0])</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  var rerr Error</span><br><span class="line">  if err := pb.Unmarshal(buf, &amp;rerr); err != nil &#123;</span><br><span class="line">    return nil</span><br><span class="line">  &#125;</span><br><span class="line">  return &amp;rerr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>interceptor.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func serverInterceptor (</span><br><span class="line">  ctx context.Context,</span><br><span class="line">  req interface&#123;&#125;,</span><br><span class="line">  info *grpc.UnaryServerInfo,</span><br><span class="line">  handler grpc.UnaryHandler,</span><br><span class="line">) (interface&#123;&#125;, error) &#123;</span><br><span class="line">  start := time.Now()</span><br><span class="line">  resp, err := handler(ctx, req)</span><br><span class="line">  err = rpc.MarshalError(err, ctx)</span><br><span class="line">  log.Print(...)</span><br><span class="line">  return resp, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>it’s ugly，but works.</p><p>这是在 gRPC 不支持高级 Error 的情况下，怎么去 work around 这个问题，并且凑合用起来。现在这么做，错误就可以跨主机边界传递了。</p><h2 id="生产环境案例：Dump">生产环境案例：Dump</h2><p>又有客户前来提需求了，有的客户说我们可以存、也可以取，但是如何才能把里面所有的数据都获取下来？于是有了需求，希望实现 Dump() 操作，可以取回所有数据。</p><p>现在已经轻车熟路了，我们先改 IDL，添加一个 Dump() 函数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">  rpc Dump(DumpReq) returns (DumpResp) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message DumpReq&#123;</span><br><span class="line">&#125;</span><br><span class="line">message DumpResp &#123;</span><br><span class="line">  repeated DumpItem items = 1;</span><br><span class="line">&#125;</span><br><span class="line">message DumpItem &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 DumpResp 里面用的是 repeated，因为 protobuf 里面不知道为啥不叫 array。</p><h2 id="生产环境案例：流量控制">生产环境案例：流量控制</h2><p>新功能 Dump 上线了，结果发现大家都很喜欢 Dump，有很多人在 Dump，结果服务器的内存开始不够了。于是我们需要一些限制手段，可以控制流量。</p><p>查阅了文档后，发现我们可以控制同时最大有多少并发可以访问，以及可以多频繁的来访问服务。<br><font color="DeepPink"><strong>server.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runServer() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  srv := grpc.NewServer(grpc.Creds(tlsCreds),</span><br><span class="line">    ServerInterceptor(),</span><br><span class="line">    grpc.MaxConcurrentStreams(64),</span><br><span class="line">    grpc.InTapHandle(NewTap().Handler))</span><br><span class="line">  rpc.RegisterCacheServer(srv, NewCacheService(accounts))</span><br><span class="line">  l, err := net.Listen(&quot;tcp&quot;, &quot;localhost:5051&quot;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return err</span><br><span class="line">  &#125;</span><br><span class="line">  l = netutil.LimitListener(l, 1024)</span><br><span class="line">  return srv.Serve(l)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了 netutil.LimitListener(l, 1024) 控制了总共可以有多少个连接，然后用 grpc.MaxConcurrentStreams(64) 指定了每个 grpc 的连接可以有多少个并发流(stream)。这两个结合起来基本控制了并发的总数。</p><p>但是 gRPC 里没有地方限定可以多频繁的访问。因此这里用了 grpc.InTapHandle(NewTap().Handler)) 来进行定制，这是在更靠前的位置执行的。</p><p><font color="DeepPink"><strong>tap.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Tap struct &#123;</span><br><span class="line">  lim *rate.Limiter</span><br><span class="line">&#125;</span><br><span class="line">func NewTap() *Tap &#123;</span><br><span class="line">  return &amp;Tap(rate.NewLimiter(150, 5))</span><br><span class="line">&#125;</span><br><span class="line">func (t *Tap) Handler(ctx context.Context, info *tap.Info) (context.Context, error) &#123;</span><br><span class="line">  if !t.lim.Allow() &#123;</span><br><span class="line">    return nil, status.Errorf(codes.ResourceExhausted, &quot;service is over rate limit&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  return ctx, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：Streaming">生产环境案例：Streaming</h2><p>之前的方案部署后，内存终于降下来了，但是还没休息，就发现大家越来越喜欢用这个缓存服务，内存又不够用了。这个时候我们就开始思考，是不是可以调整一下设计，不是每次 Dump 就立即在内存生成完整的返回数组，而是以流的形式，按需发回。<br><font color="DeepPink"><strong>app.proto</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">syntax = &quot;proto3&quot;;</span><br><span class="line">package rpc;</span><br><span class="line">service Cache &#123;</span><br><span class="line">  rpc Store(StoreReq) returns (StoreResp) &#123;&#125;</span><br><span class="line">  rpc Get(GetReq) returns (GetResp) &#123;&#125;</span><br><span class="line">  rpc Dump(DumpReq) returns (stream DumpItem) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">message DumpReq&#123;</span><br><span class="line">&#125;</span><br><span class="line">message DumpItem &#123;</span><br><span class="line">  string key = 1;</span><br><span class="line">  bytes val = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里不再使用数组性质的 repeated，而是用 stream，客户端请求 Dump() 后，将结果以流的形式发回去。<br><font color="DeepPink"><strong>server.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (s *CacheService) Dump(req *rpc.DumpReq, stream rpc.Cache_DumpServer) error &#123;</span><br><span class="line">  for k, v := range s.store &#123;</span><br><span class="line">    stream.Send(&amp;rpc.DumpItem&#123;</span><br><span class="line">      Key: k,</span><br><span class="line">      Val: v,</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们修改 Dump() 的实现，对于每个记录，利用 stream.Send() 发送到流。</p><p>注意这里我们没有 context，只有个 stream。<br><font color="DeepPink"><strong>client.go</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func runClient() error &#123;</span><br><span class="line">  ...</span><br><span class="line">  stream, err := cache.Dump(context.Background(), &amp;rpc.DumpReq&#123;&#125;)</span><br><span class="line">  if err != nil &#123;</span><br><span class="line">    return fmt.Errorf(&quot;failed to dump: %v&quot;, err)</span><br><span class="line">  &#125;</span><br><span class="line">  for &#123;</span><br><span class="line">    item, err := stream.Recv()</span><br><span class="line">    if err == io.EOF &#123;</span><br><span class="line">      break</span><br><span class="line">    &#125;</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">      return fmt.Errorf(&quot;failed to stream item: %v&quot;, err)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产环境案例：横向扩展、负载均衡">生产环境案例：横向扩展、负载均衡</h2><p>使用流后，服务器性能提高了很多，但是，我们的服务太吸引人了，用户越来越多，结果又内存不够了。这时候我们审查代码，感觉能做的事情都做了，或许是时候从单一服务器，扩展为多个服务器，然后之间使用负载均衡。</p><p>gRPC 是长连接性质的通讯，因此如果一个客户端连接了一个 gRPC Endpoint，那么他就会一直连接到一个固定的服务器，因此多服务器的负载均衡对同一个客户端来说是没有意义的，不会因为这个客户端有大量的请求而导致分散请求到不同的服务器上去。</p><p>如果我们希望客户端可以利用多服务器的机制，我们就需要更智能的客户端，让客户端意识到服务器存在多个副本，因此客户端建立多条连接到不同的服务器，这样就可以让单一客户端利用负载均衡的横向扩展能力。</p><h2 id="生产环境案例：多语言协作">生产环境案例：多语言协作</h2><p>在复杂的环境中，我们 gRPC 的客户端（甚至服务端）可能是不同语言平台的。这其实是 gRPC 的优势，可以比较容易的实现跨语言平台的通讯。</p><p>比如我们可以做一个 Python 客户端：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import grpc</span><br><span class="line">import rpc_pb2 as rpc</span><br><span class="line">channel = grpc.insecure_channel(&apos;localhost:5051&apos;)</span><br><span class="line">cache_svc = rpc.CacheStub(channel)</span><br><span class="line">resp = cache_svc.Get(rpc.GetReq(</span><br><span class="line">  key=&quot;gopher&quot;,</span><br><span class="line">))</span><br><span class="line">print resp.val</span><br></pre></td></tr></table></figure><p>一个不是很爽的地方是虽然 gRPC 的跨语言通讯很方便，但是各个语言的实现都比较随意，比如 Go 中叫做 CacheClient()，而 Python 中则叫做 CacheStub()。这里没有什么特别的原因非不一样的名字，就是由于不同的作者实现的时候按照自己的想法命名的。</p><h1>gRPC 尚不完美的地方</h1><ul><li>负载均衡</li><li>结构化的错误信息</li><li>还不支持浏览器的 JS （某种角度上讲，这是最常用的客户端）</li><li>还经常发生 API 改变（即使都1.0了）</li><li>某些语言实现的文档非常差</li><li>没有跨语言的标准化的做法</li></ul><h1>gRPC 在生产环境中的用例</h1><ul><li>ngrok，所有内部20多个通讯都走的是 gRPC</li><li>Square，将内部的通讯都换成了 gRPC，是最早使用 gRPC 的用户和贡献者</li><li>CoreOS，etcd v3 完全走的是 gRPC</li><li>Google，Google Cloud Service（PubSub, Speech Rec）走的是 gRPC</li><li>Netflix, Yik Yak, VSCO, Cockroach, …</li></ul><h1>gRPC 未来的变化</h1><ul><li>想了解未来的变化可以查看：<ul><li><a href="https://github.com/grpc/proposal" target="_blank" rel="noopener">grpc/proposal</a></li><li><a href="https://groups.google.com/forum/#!forum/grpc-io" target="_blank" rel="noopener">grpc-io 邮件列表</a></li></ul></li><li>新的语言支持（<a href="https://github.com/grpc/grpc-swift" target="_blank" rel="noopener">Swift</a> 和 <a href="https://github.com/grpc/grpc-haskell" target="_blank" rel="noopener">Haskell</a>正在试验阶段）</li><li>稳定性、可靠性、性能的提高</li><li>增加更多细化的 API 来支持自定义的行为（连接管理、频道跟踪）</li><li>浏览器的 JS</li></ul><blockquote><p>本文转载自：<br><a href="https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou</a></p></blockquote>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]给 Go 库作者的建议</title>
    <url>/golang-practice-advice-for-go-library-authors.html</url>
    <content><![CDATA[<blockquote><p>Golang Practice Advice</p></blockquote><a id="more"></a><h1>视频信息</h1><p>Practical Advice for Go Library Authors<br>by Jack Lindamood<br>at GopherCon 2016</p><p><a href="https://www.youtube.com/watch?v=5v2fqm_8jYI" target="_blank" rel="noopener">https://www.youtube.com/watch?v=5v2fqm_8jYI</a></p><p>幻灯地址：<br><a href="http://go-talks.appspot.com/github.com/cep21/go-talks/practical-advice-for-go-library-authors.slide#1" target="_blank" rel="noopener">http://go-talks.appspot.com/github.com/cep21/go-talks/practical-advice-for-go-library-authors.slide#1</a></p><h1>命名</h1><p>包名是将来使用过程中的一部分，所以避免重复包名和结构与函数。比如</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var h client.Client → var h http.Client</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">context.NewContext() =&gt; context.Background()</span><br></pre></td></tr></table></figure><h1>Object Creation</h1><p>golang 没有构造函数，因此创建对象一般有两种办法:</p><ul><li>默认的0值</li><li>单独的构造函数，NewSomething()</li></ul><p>推荐使用默认 0 值的构造方法</p><p>在默认0值的情况下，各个方法要处理好0值，比如有些东西发现是0值后，给入一个默认值。</p><p>New() 构造函数很灵活，可以做任何事情，因此对于代码阅读上不利，意味着隐藏了很多东西。</p><p>有些库使用私有 struct，公开接口的方法，authImpl struct and Auth interface，这是反模式，不推荐使用。</p><p>不推荐使用 <font color="DeepPink"><strong>Singleton</strong></font>，虽然标准库中大量使用了 <font color="DeepPink"><strong>Singleton</strong></font> 模式，但是 Jack 个人不喜欢这种模式。</p><p>使用高阶函数作为选项这种形式不推荐：NewSomething(WithThingA(), WithThingB())</p><h1>日志</h1><p>一些日志是直接打印到标准输出去，这是非常不好的设计，因为用户如果想关根本关不了。</p><p>建议</p><ul><li>确定一下作为<font color="DeepPink"><strong>库</strong></font>是不是真的需要打印日志，是不是应该把输出日志的工作交给调用方决定？</li><li>如果一定需要日志，那么使用回调函数方式</li><li>输出日志到一个 interface</li><li>不要假定传进来的就是标准库的 log ，有很多选择。</li><li>尊重 stdout 和 stderr</li><li>不要使用 singleton</li></ul><h1>interface vs struct</h1><p>接受 interface ，但返回的是 struct</p><p>这点和 Java 不同，Java 更倾向于所有东西都是通过 interface 操作。而 golang 不需要，golang 使用的是隐性interface。</p><h1>什么时候 panic</h1><p>最好都不 panic。如果非要 panic，可能最合适的地方是 init 的时候，因为刚一运行就能看到挂了，比较容易处理。但即使如此，也尽量不要 panic。</p><h1>检查 error</h1><p>问：我们是需要检查所有的 error 么？比如有些似乎不大容易出错。<br>答：需要，<font color="DeepPink"><strong>特别是你说的这些不大容易出错的</strong></font>！！</p><p>我们用 error 代替了 exception，所以不要忽略这个东西。</p><p>处理的办法</p><ul><li>最好的办法是 Bubble up，也就是传回调用方</li><li>但有的时候（比如 <font color="DeepPink"><strong>goroutine</strong></font>) 不适合，那就：<ul><li>做日志</li><li>或者增加某个计数器</li></ul></li></ul><p>什么时候应该返回错误比较合适？</p><ul><li>当不满足约定</li><li>当需要的答案无法得到</li></ul><h1>允许启用库的调试能力</h1><h1>为测试而设计</h1><ul><li>为了方便自己测试</li><li>为了方便库用户测试</li></ul><h1>并发</h1><h2 id="channels">channels</h2><p>虽然 <font color="DeepPink"><strong>channel</strong></font> 是 golang 一个处理并发很好地东西，但是并非所有场合都需要。比如标准库中就很少有在 API 中使用 channel 的。</p><ul><li>将使用 channel 的位置向上层移动。</li><li>可以使用回调函数。</li><li>不要混合使用 mutex 和 channel</li></ul><h2 id="什么时候发起-goroutine">什么时候发起 goroutine</h2><ul><li>有一些库的 New() 会发起他们的 goroutine，这是不好的。</li><li>标准库使用的是 Serve() 函数。以及对应的 Close() 函数</li><li>将 goroutine 向上层推</li></ul><h1>什么时候使用 context.Context</h1><ul><li>所有的阻塞、长时间的操作，都应该可以被 cancel</li><li>由于 context.Context 很容易存储东西，所以很容易被滥用。要尽力去避免使用 Context</li><li>Singleton 和 context.Value() 是同样性质的东西，像全局变量一样，对于程序状态来说是个黑箱。</li></ul><h1>其它注意事项</h1><ul><li>如果什么东西很难做，嗯，那就让别人去做吧</li><li>为了效率而升级<ul><li>但是，正确性要比效率重要，在正确性的前提下，注意效率</li></ul></li><li>不要在库中使用 /vendor （在 main 包中可以）</li><li>注意 build tag</li><li>保持干净<ul><li>尽量使用所有的静态分析工具来检查代码。</li></ul></li></ul><h1>原文</h1><p><a href="https://blog.lab99.org/post/golang-2017-09-21-video-practice-advice-for-go-library-authors.html" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-09-21-video-practice-advice-for-go-library-authors.html</a></p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>Practice</tag>
        <tag>Advice</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Golang 如何正确使用 Context</title>
    <url>/how-to-correctly-use-package-context.html</url>
    <content><![CDATA[<blockquote><p>Golang Context</p></blockquote><a id="more"></a><h1>视频信息</h1><p>How to correctly use package context<br>by Jack Lindamood<br>at Golang UK Conf. 2017</p><p>视频：<a href="https://www.youtube.com/watch?v=-_B5uQ4UGi0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=-_B5uQ4UGi0</a><br>博文：<a href="https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39" target="_blank" rel="noopener">https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39</a></p><h1>为什么需要 Context</h1><ul><li>每一个<font color="DeepPink"><strong>长请求</strong></font>都应该有个<font color="DeepPink"><strong>超时限制</strong></font></li><li>需要在调用中传递这个超时<ul><li>比如开始处理请求的时候我们说是 3 秒钟超时</li><li>那么在函数调用中间，这个超时还剩多少时间了？</li><li>需要在什么地方存储这个信息，这样请求处理中间可以停止</li></ul></li></ul><p>如果进一步考虑。<br><img data-src="/images/how-to-correctly-use-package-context/rpc-fails-1.svg" alt><br>如上图这样的 RPC 调用，开始调用 RPC 1 后，里面分别调用了 RPC 2, RPC 3, RPC 4，等所有 RPC 用成功后，返回结果。</p><p>这是正常的方式，但是如果 RPC 2 调用失败了会发生什么？<br><img data-src="/images/how-to-correctly-use-package-context/rpc-fails-2.svg" alt></p><p>RPC 2 失败后，如果没有 Context 的存在，那么我们可能依旧会等所有的 RPC 执行完毕，但是由于 RPC 2 败了，所以其实其它的 RPC 结果意义不大了，我们依旧需要给用户返回错误。因此我们白白的浪费了 10ms，完全没必要去等待其它 RPC 执行完毕。</p><p>那如果我们在 RPC 2 失败后，就直接给用户返回失败呢？<br><img data-src="/images/how-to-correctly-use-package-context/rpc-fails-3.svg" alt><br>用户是在 30ms 的位置收到了错误消息，可是 RPC 3 和 RPC 4 依然在没意义的运行，还在浪费计算和IO资源。<br><img data-src="/images/how-to-correctly-use-package-context/rpc-fails-4.svg" alt></p><p>所以理想状态应该是如上图，当 RPC 2 出错后，除了返回用户错误信息外，我们也应该有某种方式可以通知 RPC 3 和 RPC 4，让他们也停止运行，不再浪费资源。</p><p>所以解决方案就是：</p><ul><li>用信号的方式来通知请求该停了</li><li>包含一些关于什么时间请求可能会结束的提示（超时）</li><li>用 channel 来通知请求结束了</li></ul><p>那干脆让我们把变量也扔那吧。😈</p><ul><li>在 Go 中没有线程/go routine 变量<ul><li>其实挺合理的，因为这样就会让 goroutine 互相产生依赖</li></ul></li><li><font color="DeepPink"><strong>非常容易被滥用</strong></font></li></ul><h1>Context 实现细节</h1><p>context.Context：</p><ul><li>是不可变的(immutable)树节点</li><li>Cancel 一个节点，会连带 Cancel 其所有子节点 （<font color="DeepPink"><strong>从上到下</strong></font>）</li><li>Context values 是一个节点</li><li>Value 查找是回溯树的方式 （<font color="DeepPink"><strong>从下到上</strong></font>）</li></ul><h2 id="示例-Context-链">示例 Context 链</h2><p>完整代码：<a href="https://play.golang.org/p/ddpofBV1QS" target="_blank" rel="noopener">https://play.golang.org/p/ddpofBV1QS</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">func tree() &#123;</span><br><span class="line">  ctx1 := context.Background()</span><br><span class="line">  ctx2, _ := context.WithCancel(ctx1)</span><br><span class="line">  ctx3, _ := context.WithTimeout(ctx2, time.Second * 5)</span><br><span class="line">  ctx4, _ := context.WithTimeout(ctx3, time.Second * 3)</span><br><span class="line">  ctx5, _ := context.WithTimeout(ctx3, time.Second * 6)</span><br><span class="line">  ctx6 := context.WithValue(ctx5, &quot;userID&quot;, 12)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果这样构成的 Context 链，其形如下图：<br><img data-src="/images/how-to-correctly-use-package-context/context-chain-1.svg" alt><br>那么当 3 秒超时到了时候：<br><img data-src="/images/how-to-correctly-use-package-context/context-chain-2.svg" alt><br>可以看到 ctx4 超时退出了。</p><p>当 5秒钟 超时到达时：<br><img data-src="/images/how-to-correctly-use-package-context/context-chain-3.svg" alt><br>可以看到，不仅仅 ctx3 退出了，其所有子节点，比如 ctx5 和 ctx6 也都退出了。</p><h2 id="context-Context-API">context.Context API</h2><p>基本上是两类操作：</p><ul><li>3个函数用于<font color="DeepPink"><strong>限定什么时候你的子节点退出</strong></font>；</li><li>1个函数用于<font color="DeepPink"><strong>设置请求范畴的变量</strong></font></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Context interface &#123;</span><br><span class="line">  //  啥时候退出</span><br><span class="line">  Deadline() (deadline time.Time, ok bool)</span><br><span class="line">  Done() &lt;-chan struct&#123;&#125;</span><br><span class="line">  Err() error</span><br><span class="line">  //  设置变量</span><br><span class="line">  Value(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="什么时候应该使用-Context？">什么时候应该使用 Context？</h2><ul><li>每一个 RPC 调用都应该有<font color="DeepPink"><strong>超时退出</strong></font>的能力，这是比较合理的 API 设计</li><li><font color="DeepPink"><strong>不仅仅</strong></font> 是超时，你还需要有能力去结束那些不再需要操作的行为</li><li>context.Context 是 Go 标准的解决方案</li><li>任何函数可能被阻塞，或者需要很长时间来完成的，都应该有个 context.Context</li></ul><h2 id="如何创建-Context？">如何创建 Context？</h2><ul><li>在 RPC 开始的时候，使用 context.Background()<ul><li>有些人把在 main() 里记录一个 context.Background()，然后把这个放到服务器的某个变量里，然后请求来了后从这个变量里继承 context。这么做是<font color="DeepPink"><strong>不对的</strong></font>。直接每个请求，源自自己的 context.Background() 即可。</li></ul></li><li>如果你没有 context，却需要调用一个 context 的函数的话，用 context.TODO()</li><li>如果某步操作需要自己的超时设置的话，给它一个独立的 sub-context（如前面的例子）</li></ul><h2 id="如何集成到-API-里？">如何集成到 API 里？</h2><ul><li>如果有 Context，<font color="DeepPink"><strong>将其作为第一个变量</strong></font>。<ul><li>如 func (d* Dialer) DialContext(ctx context.Context, network, address string) (Conn, error)</li><li>有些人把 context 放到中间的某个变量里去，这很不合习惯，不要那么做，放到第一个去。</li></ul></li><li>将其作为<font color="DeepPink"><strong>可选的</strong></font>方式，用 request 结构体方式。<ul><li>如：func (r *Request) WithContext(ctx context.Context) *Request</li></ul></li><li>Context 的变量名请用 ctx（不要起一些诡异的名字😓）</li></ul><h2 id="Context-放哪？">Context 放哪？</h2><ul><li>把 Context 想象为一条河流流过你的程序（另一个意思就是说不要喝河里的水……🙊）</li><li>理想情况下，Context 存在于调用栈（Call Stack） 中</li><li>不要把 Context 存储到一个 struct 里<ul><li>除非你使用的是像 http.Request 中的 request 结构体的方式</li></ul></li><li>request 结构体应该以 Request 结束为生命终止</li><li>当 RPC 请求处理结束后，应该去掉对 Context 变量的引用（Unreference）</li><li>Request 结束，Context 就应该结束。（这俩是一对儿，不求同年同月同日生，但求同年同月同日死……💕）</li></ul><h2 id="Context-包的注意事项">Context 包的注意事项</h2><ul><li>要养成关闭 Context 的习惯<ul><li><font color="DeepPink"><strong>特别是</strong></font> 超时的 Contexts</li></ul></li><li>如果一个 context 被 GC 而不是 cancel 了，那一般是你做错了</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ctx, cancel := context.WithTimeout(parentCtx, time.Second * 2)</span><br><span class="line">defer cancel()</span><br></pre></td></tr></table></figure><ul><li>使用 Timeout 会导致内部使用 time.AfterFunc，从而会导致 context 在计时器到时之前都不会被垃圾回收。</li><li>在建立之后，立即 defer cancel() 是一个好习惯。</li></ul><h2 id="终止请求-Request-Cancellation">终止请求 (Request Cancellation)</h2><p>当你不再关心接下来获取的结果的时候，有可能会 Cancel 一个 Context？</p><p>以 <a href="http://golang.org/x/sync/errgroup" target="_blank" rel="noopener">golang.org/x/sync/errgroup</a> 为例，errgroup 使用 Context 来提供 RPC 的终止行为。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type Group struct &#123;</span><br><span class="line">	cancel  func()</span><br><span class="line">	wg      sync.WaitGroup</span><br><span class="line">	errOnce sync.Once</span><br><span class="line">	err     error</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个 group 和 context：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func WithContext(ctx context.Context) (*Group, context.Context) &#123;</span><br><span class="line">  ctx, cancel := context.WithCancel(ctx)</span><br><span class="line">  return &amp;Group&#123;cancel: cancel&#125;, ctx</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就返回了一个可以被提前 cancel 的 group。</p><p>而调用的时候，并不是直接调用 go func()，而是调用 Go()，将函数作为参数传进去，用高阶函数的形式来调用，其内部才是 go func() 开启 goroutine。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (g *Group) Go(f func() error) &#123;</span><br><span class="line">  g.wg.Add(1)</span><br><span class="line">  go func() &#123;</span><br><span class="line">    defer g.wg.Done()</span><br><span class="line">    if err := f(); err != nil &#123;</span><br><span class="line">      g.errOnce.Do(func() &#123;</span><br><span class="line">        g.err = err</span><br><span class="line">        if g.cancel != nil &#123;</span><br><span class="line">          g.cancel()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当给入函数 f 返回错误，则使用 sync.Once 来 cancel context，而错误被保存于 g.err 之中，在随后的 Wait() 函数中返回。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (g *Group) Wait() error &#123;</span><br><span class="line">  g.wg.Wait()</span><br><span class="line">  if g.cancel != nil &#123;</span><br><span class="line">    g.cancel()</span><br><span class="line">  &#125;</span><br><span class="line">  return g.err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里在 Wait() 结束后，调用了一次 cancel()。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">func DoTwoRequestsAtOnce(ctx context.Context) error &#123;</span><br><span class="line">  eg, egCtx := errgroup.WithContext(ctx)</span><br><span class="line">  var resp1, resp2 *http.Response</span><br><span class="line">  f := func(loc string, respIn **http.Response) func() error &#123;</span><br><span class="line">    return func() error &#123;</span><br><span class="line">      reqCtx, cancel := context.WithTimeout(egCtx, time.Second)</span><br><span class="line">      defer cancel()</span><br><span class="line">      req, _ := http.NewRequest(&quot;GET&quot;, loc, nil)</span><br><span class="line">      var err error</span><br><span class="line">      *respIn, err = http.DefaultClient.Do(req.WithContext(reqCtx))</span><br><span class="line">      if err == nil &amp;&amp; (*respIn).StatusCode &gt;= 500 &#123;</span><br><span class="line">        return errors.New(&quot;unexpected!&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">      return err</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  eg.Go(f(&quot;http://localhost:8080/fast_request&quot;, &amp;resp1))</span><br><span class="line">  eg.Go(f(&quot;http://localhost:8080/slow_request&quot;, &amp;resp2))</span><br><span class="line">  return eg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，同时发起了两个 RPC 调用，当任何一个调用超时或者出错后，会终止另一个 RPC 调用。这里就是利用前面讲到的 errgroup 来实现的，应对有很多并非请求，并需要集中处理超时、出错终止其它并发任务的时候，这个 pattern 使用起来很方便。</p><h2 id="Context-Value-Request-范畴的值">Context.Value - Request 范畴的值</h2><h3 id="context-Value-API-的万金油（duct-tape">context.Value API 的万金油（duct tape)</h3><p>胶带（duct tape) 几乎可以修任何东西，从破箱子，到人的伤口，到汽车引擎，甚至到NASA登月任务中的阿波罗13号飞船（Yeah! True Story)。所以在西方文化里，胶带是个“万能”的东西。在中文里，恐怕万金油是更合适的对应词汇，从头疼、脑热，感冒发烧，到跌打损伤几乎无所不治。</p><p>当然，<font color="DeepPink"><strong>治标不治本</strong></font>，这点东西方文化中的潜台词都是一样的。这里提及的 context.Value 对于 API 而言，就是这类性质的东西，啥都可以干，但是治标不治本。</p><ul><li>value 节点是 Context 链中的一个节点</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package context</span><br><span class="line">type valueCtx struct &#123;</span><br><span class="line">  Context</span><br><span class="line">  key, val interface&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123;</span><br><span class="line">  //  ...</span><br><span class="line">  return &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class="line">&#125;</span><br><span class="line">func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;</span><br><span class="line">  if c.key == key &#123;</span><br><span class="line">    return c.val</span><br><span class="line">  &#125;</span><br><span class="line">  return c.Context.Value(key)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，WithValue() 实际上就是在 Context 树形结构中，增加一个节点罢了。</p><p>Context 是 immutable 的。</p><h3 id="约束-key-的空间">约束 key 的空间</h3><p>为了防止树形结构中出现重复的键，建议约束键的空间。比如使用私有类型，然后用 GetXxx() 和 WithXxxx() 来操作私有实体。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type privateCtxType string</span><br><span class="line">var (</span><br><span class="line">  reqID = privateCtxType(&quot;req-id&quot;)</span><br><span class="line">)</span><br><span class="line">func GetRequestID(ctx context.Context) (int, bool) &#123;</span><br><span class="line">  id, exists := ctx.Value(reqID).(int)</span><br><span class="line">  return id, exists</span><br><span class="line">&#125;</span><br><span class="line">func WithRequestID(ctx context.Context, reqid int) context.Context &#123;</span><br><span class="line">  return context.WithValue(ctx, reqID, reqid)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用 WithXxx 而不是 SetXxx 也是因为 Context 实际上是 immutable 的，所以不是修改 Context 里某个值，而是产生新的 Context <font color="DeepPink"><strong>带某个值</strong></font>。</p><h3 id="Context-Value-是-immutable-的">Context.Value 是 immutable 的</h3><p>再多次的强调 Context.Value 是 <font color="DeepPink"><strong>immutable</strong></font> 的也不过分。</p><ul><li>context.Context 从设计上就是按照 immutable （不可变的）模式设计的</li><li>同样，Context.Value 也是 immutable 的</li><li>不要试图在 Context.Value 里存某个可变更的值，然后改变，期望别的 Context 可以看到这个改变<ul><li>更别指望着在 Context.Value 里存可变的值，最后多个 goroutine 并发访问没竞争冒险啥的，因为自始至终，就是按照不可变来设计的</li><li>比如设置了超时，就别以为可以改变这个设置的超时值</li></ul></li><li>在使用 Context.Value 的时候，一定要记住这一点</li></ul><h3 id="应该把什么放到-Context-Value-里？">应该把什么放到 Context.Value 里？</h3><ul><li>应该保存 Request 范畴的值<ul><li>任何关于 Context 自身的都是 Request 范畴的（这俩同生共死）</li><li>从 Request 数据衍生出来，并且随着 Request 的结束而终结</li></ul></li></ul><h3 id="什么东西不属于-Request-范畴？">什么东西不属于 Request 范畴？</h3><ul><li>在 Request 以外建立的，并且不随着 Request 改变而变化<ul><li>比如你 func main() 里建立的东西显然不属于 Request 范畴</li></ul></li><li>数据库连接<ul><li>如果 User ID 在连接里呢？(稍后会提及)</li></ul></li><li>全局 logger<ul><li>如果 logger 里需要有 User ID 呢？（稍后会提及）</li></ul></li></ul><h3 id="那么用-Context-Value-有什么问题？">那么用 Context.Value 有什么问题？</h3><ul><li>不幸的是，好像所有东西都是由请求衍生出来的</li><li>那么我们为什么还需要函数参数？然后干脆只来一个 Context 就完了？</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func Add(ctx context.Context) int &#123;</span><br><span class="line">  return ctx.Value(&quot;first&quot;).(int) + ctx.Value(&quot;second&quot;).(int)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>曾经看到过一个 API，就是这种形式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func IsAdminUser(ctx context.Context) bool &#123;</span><br><span class="line">  userID := GetUser(ctx)</span><br><span class="line">  return authSingleton.IsAdmin(userID)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里API实现内部从 context 中取得 UserID，然后再进行权限判断。但是从函数签名看，则完全无法理解这个函数具体需要什么、以及做什么。</p><blockquote><p>代码要以可读性为优先设计考虑。</p></blockquote><p>别人拿到一个代码，一般不是掉进函数实现细节里去一行行的读代码，而是会先浏览一下函数接口。所以清晰的函数接口设计，会更加利于别人（<font color="DeepPink"><strong>或者是几个月后的你自己</strong></font>）理解这段代码。</p><p>一个良好的 API 设计，应该从函数签名就清晰的理解函数的逻辑。如果我们将上面的接口改为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func IsAdminUser(ctx context.Context, userID string, authenticator auth.Service) bool</span><br></pre></td></tr></table></figure><p>我们从这个函数签名就可以清楚的知道：</p><ul><li>这个函数很可能可以提前被 cancel</li><li>这个函数需要 User ID</li><li>这个函数需要一个authenticator来</li><li>而且由于 authenticator 是传入参数，而不是依赖于隐式的某个东西，我们知道，测试的时候就很容易传入一个模拟认证函数来做测试</li><li>userID 是传入值，因此我们可以修改它，不用担心影响别的东西</li></ul><p>所有这些信息，都是从函数签名得到的，而无需打开函数实现一行行去看。</p><h3 id="那什么可以放到-Context-Value-里去？">那什么可以放到 Context.Value 里去？</h3><p>现在知道 Context.Value 会让接口定义更加模糊，似乎不应该使用。那么又回到了原来的问题，到底什么可以放到 Context.Value 里去？换个角度去想，什么不是衍生于 Request？</p><ul><li>Context.Value 应该是告知性质的东西，而不是控制性质的东西</li><li>应该永远都不需要写进文档作为必须存在的输入数据</li><li>如果你发现你的函数在某些 Context.Value 下无法正确工作，那就说明这个 Context.Value 里的信息不应该放在里面，而应该放在接口上。因为已经让接口太模糊了。</li></ul><h4 id="什么东西不是控制性质的东西？">什么东西不是控制性质的东西？</h4><ul><li>Request ID<ul><li>只是给每个 RPC 调用一个 ID，而没有实际意义</li><li>这就是个数字/字符串，反正你也不会用其作为逻辑判断</li><li>一般也就是日志的时候需要记录一下<ul><li>而 logger 本身不是 Request 范畴，所以 logger 不应该在 Context 里</li><li>非 Request 范畴的 logger 应该只是利用 Context 信息来修饰日志</li></ul></li></ul></li><li>User ID （如果仅仅是作为日志用）</li><li>Incoming Request ID</li></ul><h4 id="什么显然是控制性质的东西？">什么显然是控制性质的东西？</h4><ul><li>数据库连接<ul><li>显然会非常严重的影响逻辑</li><li>因此这应该在函数参数里，明确表示出来</li></ul></li><li>认证服务(Authentication)<ul><li>显然不同的认证服务导致的逻辑不同</li><li>也应该放到函数参数里，明确表示出来</li></ul></li></ul><h3 id="例子">例子</h3><h4 id="调试性质的-Context-Value-net-http-httptrace">调试性质的 Context.Value - net/http/httptrace</h4><p><a href="https://medium.com/@cep21/go-1-7-httptrace-and-context-debug-patterns-608ae887224a" target="_blank" rel="noopener">https://medium.com/@cep21/go-1-7-httptrace-and-context-debug-patterns-608ae887224a</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">func trace(req *http.Request, c *http.Client) &#123;</span><br><span class="line">  trace := &amp;httptrace.ClientTrace&#123;</span><br><span class="line">    GotConn: func(connInfo httptrace.GotConnInfo) &#123;</span><br><span class="line">      fmt.Println(&quot;Got Conn&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">    ConnectStart: func(network, addr string) &#123;</span><br><span class="line">      fmt.Println(&quot;Dial Start&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">    ConnectDone: func(network, addr string, err error) &#123;</span><br><span class="line">      fmt.Println(&quot;Dial done&quot;)</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;</span><br><span class="line">  req = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))</span><br><span class="line">  c.Do(req)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="net-http-是怎么使用-httptrace-的？">net/http 是怎么使用 httptrace 的？</h4><ul><li>如果有 trace 存在的话，就执行 trace 回调函数</li><li>这只是告知性质，而不是控制性质<ul><li>http 不会因为存在 trace 与否就有不同的执行逻辑</li><li>这里只是告知 API 的用户，帮助用户记录日志或者调试</li><li>因此这里的 trace 是存在于 Context 里的</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package http</span><br><span class="line">func (req *Request) write(w io.Writer, usingProxy bool, extraHeaders Header, waitForContinue func() bool) (err error) &#123;</span><br><span class="line">  //  ...</span><br><span class="line">  trace := httptrace.ContextClientTrace(req.Context())</span><br><span class="line">  //  ...</span><br><span class="line">  if trace != nil &amp;&amp; trace.WroteHeaders != nil &#123;</span><br><span class="line">    trace.WroteHeaders()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="回避依赖注入-github-com-golang-oauth2">回避依赖注入 - <a href="http://github.com/golang/oauth2" target="_blank" rel="noopener">github.com/golang/oauth2</a></h4><ul><li>这里比较诡异，使用 ctx.Value 来定位依赖</li><li><font color="DeepPink"><strong>不推荐这样做</strong></font><ul><li>这里这样做基本上只是为了满足测试需求</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">import &quot;github.com/golang/oauth2&quot;</span><br><span class="line">func oauth() &#123;</span><br><span class="line">  c := &amp;http.Client&#123;Transport: &amp;mockTransport&#123;&#125;&#125;</span><br><span class="line">  ctx := context.WithValue(context.Background(), oauth2.HTTPClient, c)</span><br><span class="line">  conf := &amp;oauth2.Config&#123; /* ... */ &#125;</span><br><span class="line">  conf.Exchange(ctx, &quot;code&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="人们滥用-Context-Value-的原因">人们滥用 Context.Value 的原因</h3><ul><li>中间件的抽象</li><li>很深的函数调用栈</li><li>混乱的设计</li></ul><blockquote><p>context.Value 并没有让你的 API 更简洁，那是假象，相反，它让你的 API 定义更加模糊。</p></blockquote><h2 id="总结-Context-Value">总结 Context.Value</h2><ul><li>对于调试非常方便</li><li>将必须的信息放入 Context.Value 中，会让接口定义更加不透明</li><li>如果可以尽量明确定义在接口</li><li>尽量不要用 Context.Value</li></ul><h1>总结 Context</h1><ul><li>所有的长的、阻塞的操作都需要 Context</li><li>errgroup 是构架于 Context 之上很好的抽象</li><li>当 Request 的结束的时候，Cancel Context</li><li>Context.Value 应该被用于<font color="DeepPink"><strong>告知性质</strong></font>的事物，而不是<font color="DeepPink"><strong>控制性质</strong></font>的事物</li><li>约束 Context.Value 的键空间</li><li>Context 以及 Context.Value 应该是不可变的（immutable），并且应该是线程安全</li><li>Context 应该随 Request 消亡而消亡</li></ul><h1>Q&amp;A</h1><h2 id="数据库的访问也用-Context-么？">数据库的访问也用 Context 么？</h2><p>之前说过长时间、可阻塞的操作都用 Context，数据库操作也是如此。不过对于超时 Cancel 操作来说，一般不会对写操作进行 cancel；但是对于读操作，一般会有 Cancel 操作。</p><h1>原文</h1><p><a href="https://blog.lab99.org/post/golang-2017-10-27-video-how-to-correctly-use-package-context.html" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-27-video-how-to-correctly-use-package-context.html</a></p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title>encrypted communication elasticsearch java rest client</title>
    <url>/encrypted-communication-elasticsearch-java-rest-client.html</url>
    <content><![CDATA[<blockquote><p>ElasticSearch 7.3.1<br>Java Rest Client HTTPS连接操作</p></blockquote><a id="more"></a><p>ElasticSearch版本7.3.1，elasticsearch.yml配置如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">xpack.security.transport.ssl.verification_mode: certificate</span><br><span class="line">xpack.security.transport.ssl.key: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.key</span><br><span class="line">xpack.security.transport.ssl.certificate: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.cer</span><br><span class="line">xpack.security.transport.ssl.certificate_authorities: [ &quot;/home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com_ca.crt&quot; ]</span><br><span class="line">xpack.security.http.ssl.enabled: true</span><br><span class="line">xpack.security.http.ssl.key:  /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.key</span><br><span class="line">xpack.security.http.ssl.certificate: /home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com.cer</span><br><span class="line">xpack.security.http.ssl.certificate_authorities: [ &quot;/home/jiankunking/elasticsearch-7.3.1/config/certs/_.jiankunking.com_ca.crt&quot; ]</span><br></pre></td></tr></table></figure><p>由于ElasticSearch Java client中的<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#KeyStore" target="_blank" rel="noopener">KeyStore Types</a>只支持以下几种：</p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>jceks</td><td>The proprietary keystore implementation provided by the SunJCE provider.</td></tr><tr><td>jks</td><td>The proprietary keystore implementation provided by the SUN provider.</td></tr><tr><td>dks</td><td>A domain keystore is a collection of keystores presented as a single logical keystore. It is specified by configuration data whose syntax is described in DomainLoadStoreParameter.</td></tr><tr><td>pkcs11</td><td>A keystore backed by a PKCS #11 token.</td></tr><tr><td>pkcs12</td><td>The transfer syntax for personal identity information as defined in PKCS #12.</td></tr></tbody></table><p>而我这边证书格式为cer，所以通过keytool进行转换：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -import -v -trustcacerts -file _.jiankunking.com.cer  -keystore my_keystore.jks -keypass password -storepass password</span><br></pre></td></tr></table></figure><p>证书转换完成后，操作代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package ssl;</span><br><span class="line"></span><br><span class="line">import org.apache.http.HttpHost;</span><br><span class="line">import org.apache.http.auth.AuthScope;</span><br><span class="line">import org.apache.http.auth.UsernamePasswordCredentials;</span><br><span class="line">import org.apache.http.client.CredentialsProvider;</span><br><span class="line">import org.apache.http.impl.client.BasicCredentialsProvider;</span><br><span class="line">import org.apache.http.ssl.SSLContexts;</span><br><span class="line">import org.elasticsearch.client.RequestOptions;</span><br><span class="line">import org.elasticsearch.client.RestClient;</span><br><span class="line">import org.elasticsearch.client.RestClientBuilder;</span><br><span class="line">import org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line">import org.elasticsearch.client.indices.CreateIndexRequest;</span><br><span class="line">import org.elasticsearch.client.indices.CreateIndexResponse;</span><br><span class="line">import org.elasticsearch.common.settings.Settings;</span><br><span class="line">import org.elasticsearch.common.xcontent.XContentType;</span><br><span class="line"></span><br><span class="line">import javax.net.ssl.SSLContext;</span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.security.KeyManagementException;</span><br><span class="line">import java.security.KeyStoreException;</span><br><span class="line">import java.security.NoSuchAlgorithmException;</span><br><span class="line">import java.security.cert.CertificateException;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @Author: jiankunking</span><br><span class="line"> * @Date: 2019/8/27 15:32</span><br><span class="line"> * @Description:</span><br><span class="line"> */</span><br><span class="line">public class es &#123;</span><br><span class="line">    public static void main(String[] args) throws KeyStoreException, IOException, NoSuchAlgorithmException, KeyManagementException, CertificateException &#123;</span><br><span class="line">        </span><br><span class="line">        CredentialsProvider credentialsProvider = new BasicCredentialsProvider();</span><br><span class="line">        credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(&quot;elastic&quot;, &quot;jiankunking&quot;));</span><br><span class="line"></span><br><span class="line">        SSLContext sslContext = SSLContexts.custom()</span><br><span class="line">                .loadTrustMaterial(new File(&quot;I:\\certs\\my_keystore.jks&quot;))</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        String host = &quot;es.jiankunking.com&quot;;</span><br><span class="line">        int port = 9200;</span><br><span class="line">        String scheme = &quot;https&quot;;</span><br><span class="line">        String indexName = &quot;twitter2&quot;;</span><br><span class="line"></span><br><span class="line">        RestClientBuilder restClientBuilder = RestClient.builder(new HttpHost(host, port, scheme)).setHttpClientConfigCallback(httpClientBuilder -&gt; httpClientBuilder</span><br><span class="line">                .setDefaultCredentialsProvider(credentialsProvider)</span><br><span class="line">                .setSSLContext(sslContext)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">		// 到这里RestHighLevelClient已经初始化完成，下面的创建索引是测试</span><br><span class="line">        RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder);</span><br><span class="line"></span><br><span class="line">        // 创建索引请求</span><br><span class="line">        CreateIndexRequest request = new CreateIndexRequest(indexName);</span><br><span class="line">        request.settings(Settings.builder()</span><br><span class="line">                .put(&quot;index.number_of_shards&quot;, 3)</span><br><span class="line">                .put(&quot;index.number_of_replicas&quot;, 2)</span><br><span class="line">        );</span><br><span class="line">        request.mapping(</span><br><span class="line">                &quot;&#123;\n&quot; +</span><br><span class="line">                        &quot;  \&quot;properties\&quot;: &#123;\n&quot; +</span><br><span class="line">                        &quot;    \&quot;message\&quot;: &#123;\n&quot; +</span><br><span class="line">                        &quot;      \&quot;type\&quot;: \&quot;text\&quot;\n&quot; +</span><br><span class="line">                        &quot;    &#125;\n&quot; +</span><br><span class="line">                        &quot;  &#125;\n&quot; +</span><br><span class="line">                        &quot;&#125;&quot;,</span><br><span class="line">                XContentType.JSON);</span><br><span class="line">        Map&lt;String, Object&gt; message = new HashMap&lt;&gt;();</span><br><span class="line">        message.put(&quot;type&quot;, &quot;text&quot;);</span><br><span class="line">        Map&lt;String, Object&gt; properties = new HashMap&lt;&gt;();</span><br><span class="line">        properties.put(&quot;message&quot;, message);</span><br><span class="line">        Map&lt;String, Object&gt; mapping = new HashMap&lt;&gt;();</span><br><span class="line">        mapping.put(&quot;properties&quot;, properties);</span><br><span class="line">        request.mapping(mapping);</span><br><span class="line">        CreateIndexResponse createIndexResponse;</span><br><span class="line">        try &#123;</span><br><span class="line">            createIndexResponse = restHighLevelClient.indices().create(request, RequestOptions.DEFAULT);</span><br><span class="line">            System.out.println(createIndexResponse);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>ElasticSearch</tag>
        <tag>Java</tag>
        <tag>Rest</tag>
        <tag>Client</tag>
        <tag>Encrypted</tag>
        <tag>Communication</tag>
      </tags>
  </entry>
  <entry>
    <title>Web性能权威指南 笔记</title>
    <url>/high-performance-browser-networking.html</url>
    <content><![CDATA[<p>本文整理自：《Web性能权威指南》 作者：Ilya Grigorik</p><p>出版时间：2014-04</p><a id="more"></a><h1>网络技术概览</h1><h2 id="带宽与延迟">带宽与延迟</h2><h3 id="延迟的最后一公里">延迟的最后一公里</h3><p>traceroute (Windows 系统下是tracert) 命令利用ICMP协议定位您的计算机和目标计算机之间的所有路由器。</p><h2 id="TCP的构成">TCP的构成</h2><p>因特网有两个核心协议：IP和TCP。IP，即 Internet Protocol（因特网协议），负责联网主机之间的路由选择和寻址；TCP，即 Transmission Control Protocol（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。</p><h3 id="三次握手">三次握手</h3><p>所有TCP连接一开始都要经过三次握手（见图 2-1）。客户端与服务器在交换应用数据之前，必须就起始分组序列号，以及其他一些连接相关的细节达成一致。出于安全考虑，序列号由两端随机生成。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE21%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt></p><ul><li>SYN<br>客户端选择一个随机序列号x，并发送一个SYN分组，其中可能还包括其他TCP标志和选项。</li><li>SYN ACK<br>服务器给x加1，并选择自己的一个随机序列号y，追加自己的标志和选项，然后返回响应。</li><li>ACK<br>客户端给x和y加1并发送握手期间的最后一个ACK分组。</li></ul><blockquote><p>SYN：同步序列编号（Synchronize Sequence Numbers）<br>ACK (Acknowledge character）即是确认字符</p></blockquote><p>三次握手完成后，客户端与服务器之间就可以通信了。<font color="DeepPink"><strong>客户端可以在发送ACK分组之后立即发送数据，而服务器必须等接收到ACK分组之后才能发送数据。</strong></font>这个启动通信的过程适用于所有TCP连接，因此对所有使用TCP的应用具有非常大的性能影响，因为每次传输应用数据之前，都必须经历一次完整的往返。</p><h3 id="队首阻塞">队首阻塞</h3><blockquote><p>丢包就丢包<br>事实上，丢包是让TCP达到最佳性能的关键。被删除的包恰恰是一种反馈机制，能够让接收端和发送端各自调整速度，以避免网络拥堵，同时保持延迟最短。另外，有些应用程序可以容忍丢失一定数量的包，比如语音和游戏状态通信，就不需要可靠传输或按序交付。<br>就算有个包丢了，音频编解码器只要在音频中插入一个小小的间歇，就可以继续处理后来的包。只要间歇够小，用户就注意不到，而等待丢失的包则可能导致音频输出产生无法预料的暂停。相对来说，后者的用户体验更糟糕。<br>类似地，更新3D游戏中角色的状态也一样：收到T时刻的包而等待T-1时刻的包通常毫无必要。理想情况下，应该可以接收所有状态更新，但为避免游戏延迟，间歇性的丢包也是可以接受的。</p></blockquote><h2 id="针对TCP的优化建议">针对TCP的优化建议</h2><p>TCP是一个自适应的、对所有网络节点一视同仁的、最大限制利用底层网络的协议。因此，优化TCP的最佳途径就是调整它感知当前网络状况的方式，根据它之上或之下的抽象层的类型和需求来改变它的行为。</p><h3 id="服务器配置调优">服务器配置调优</h3><p>在着手调整TCP的缓冲区、超时等数十个变量之前，最好先把主机操作系统升级到最新版本。TCP 的最佳实践以及影响其性能的底层算法一直在与时俱进，而且大多数变化都只在最新内核中才有实现。一句话，让你的服务器跟上时代是优化发送端和接收端TCP栈的首要措施。</p><p>有了最新的内核，我们推荐你遵循如下最佳实践来配置自己的服务器。</p><ul><li>增大TCP的初始拥塞窗口<br>加大起始拥塞窗口可以让TCP在第一次往返就传输较多数据，而随后的速度提升也会很明显。对于突发性的短暂连接，这也是特别关键的一个优化。</li><li>慢启动重启<br>在连接空闲时禁用慢启动可以改善瞬时发送数据的长TCP连接的性能。</li><li>窗口缩放<br>启用窗口缩放可以增大最大接收窗口大小，可以让高延迟的连接达到更好吞吐量。</li><li>TCP快速打开<br>在某些条件下，允许在第一个SYN分组中发送应用程序数据。TFO（TCP Fast Open，TCP 快速打开）是一种新的优化选项，需要客户端和服务器共同支持。为此，首先要搞清楚你的应用程序是否可以利用这个特性。</li></ul><blockquote><p>Linux用户可以使用ss来查看当前打开的套接字的各种统计信息。在命令行里运行ss --options --extended --memory --processes --info ，可以看到当前通信节点以及它们相应的连接设置。</p></blockquote><h2 id="UDP的构成">UDP的构成</h2><p>关于UDP的应用，最广为人知同时也是所有浏览器和因特网应用都赖以运作的，就是DNS（Domain Name System，域名系统）。</p><p>IETF和W3C工作组共同制定了一套新API WebRTC（Web Real-Time Communication，Web 实时通信）。WebRTC着眼于在浏览器中通过UDP实现原生的语音和视频实时通信，以及其他形式的 P2P（Peer-to-Peer，端到端）通信。</p><h3 id="无协议服务">无协议服务</h3><p>要理解为什么UDP被人称作“无协议”，必须从作为TCP和UDP下一层的IP协议说起。<font color="DeepPink"><strong>IP层的主要任务就是按照地址从源主机向目标主机发送数据报</strong></font>。为此，消息会被封装在一个IP分组内（图3-1），其中载明了源地址和目标地址，以及其他一些路由参数。注意，数据报这个词暗示了一个重要的信息：<font color="DeepPink"><strong>IP层不保证消息可靠的交付，也不发送失败通知，实际上是把底层网络的不可靠性直接暴露给了上一层</strong></font>。如果某个路由节点因为网络拥塞、负载过高或其他原因而删除了IP分组，那么在必要的情况下，IP 的上一层协议要负责检测、恢复和重发数据。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE31IPv4%E9%A6%96%E9%83%A8.png" alt></p><p>UDP协议会用自己的分组结构（图3-2）封装用户消息，它只增加 4个字段：<font color="DeepPink"><strong>源端口、目标端口、分组长度和校验和</strong></font>。这样，当IP把分组送达目标主机时，该主机能够拆开UDP分组，根据目标端口找到目标应用程序，然后再把消息发送过去。仅此而已。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE32UDP%E9%A6%96%E9%83%A8.png" alt></p><p>事实上，UDP数据报中的源端口和校验和字段都是可选的。IP分组的首部也有校验和，应用程序可以忽略UDP校验和。也就是说，所有错误检测和错误纠正工作都可以委托给上层的应用程序。说到底，<font color="DeepPink"><strong>UDP仅仅是在IP层之上通过嵌入应用程序的源端口和目标端口</strong></font>，提供了一个“应用程序多路复用”机制。明白了这一点，就可以总结一下UDP的无服务是怎么回事了。</p><ul><li>不保证消息交付<br>不确认，不重传，无超时。</li><li>不保证交付顺序<br>不设置包序号，不重排，不会发生队首阻塞。</li><li>不跟踪连接状态<br>不必建立连接或重启状态机。</li><li>不需要拥塞控制<br>不内置客户端或网络反馈机制。</li></ul><p>TCP是一个面向字节流的协议，能够以多个分组形式发送应用程序消息，且对分组中的消息范围没有任何明确限制。因此，连接的两端存在一个连接状态，每个分组都有序号，丢失还要重发，并且要按顺序交付。相对来说，<font color="DeepPink"><strong>UDP数据报有明确的限制：数据报必须封装在IP分组中，应用程序必须读取完整的消息。换句话说，数据报不能分片。</strong></font></p><h3 id="UDP与网络地址转换器">UDP与网络地址转换器</h3><p>作为监管全球IP地址分配的机构，IANA（Internet Assigned Numbers Authority，因特网号码分配机构）为私有网络保留了三段IP地址，这些IP地址经常可以在NAT设备后面的内网中看到。</p><p>保留的IP地址范围：</p><table><thead><tr><th>IP地址范围</th><th>地址数量</th></tr></thead><tbody><tr><td>10.0.0.0~10.255.255.255</td><td>16 777 216</td></tr><tr><td>172.16.0.0~172.31.255.255</td><td>1 048 576</td></tr><tr><td>192.168.0.0~192.168.255.255</td><td>65 536</td></tr></tbody></table><blockquote><p>为防止路由错误和引起不必要的麻烦，不允许给外网计算机分配这些保留的私有IP地址。</p></blockquote><h2 id="传输层安全（TLS）">传输层安全（TLS）</h2><p>SSL（Secure Sockets Layer，安全套接字层）协议最初是网景公司为了保障网上交易安全而开发的，该协议通过加密来保护客户个人资料，通过认证和完整性检查来确保交易安全。为达到这个目标，SSL协议在直接位于TCP上一层的应用层被实现（图 4-1）。SSL不会影响上层协议（如HTTP、电子邮件、即时通讯），但能够保证上层协议的网络通信安全。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE41%E4%BC%A0%E8%BE%93%E5%B1%82%E5%AE%89%E5%85%A8.png" alt></p><p>在正确使用SSL的情况下，第三方监听者只能推断出连接的端点、加密类型，以及发送数据的频率和大致数量，不能实际读取或修改任何数据。</p><h3 id="加密、身份验证与完整性">加密、身份验证与完整性</h3><blockquote><p><font color="DeepPink"><strong>Web 代理、中间设备、TLS 与新协议</strong></font><br><strong>HTTP 良好的扩展能力和获得的巨大成功，使得 Web 上出现了大量代理和中间设备：缓存服务器、安全网关、Web 加速器、内容过滤器，等等。有时候，我们知道这些设备的存在（显式代理），而有时候，这些设备对终端用户则完全不可见。</strong></p></blockquote><blockquote><p><strong>然而，这些服务器的存在及成功也给那些试图脱离 HTTP 协议的人带了一些不便。比如，有的代理服务器只会简单地转发自己无法解释的 HTTP 扩展或其他在线格式（wire format），而有的则不管是否必要都会对所有数据执行自己设定的逻辑，还有一些安全设备可能会把本来正常的数据误判成恶意通信。</strong></p></blockquote><blockquote><p><strong>换句话说，现实当中如果想脱离 HTTP 和 80 端口的语义行事，经常会遭遇各种部署上的麻烦。比如，某些客户端表现正常，另一些可能就会异常，甚至在某个网段表现正常的客户端到了另一个网段又会变得异常。</strong></p></blockquote><blockquote><p><strong>为解决这些问题，出现了一些新协议和对 HTTP 的扩展，比如 WebSocket、SPDY等。这些新协议一般要依赖于建立 HTTPS 信道，以绕过中间代理，从而实现可靠的部署，因为加密的传输信道会对所有中间设备都混淆数据。这样虽然解决了中间设备的问题，但却导致通信两端不能再利用这些中间设备，从而与这些设备提供的身份验证、缓存、安全扫描等功能失之交臂。</strong></p></blockquote><h3 id="信任链与证书颁发机构">信任链与证书颁发机构</h3><p>Web以及浏览器中的身份验证需要回答以下几个问题：我的浏览器信任谁？我在使用浏览器的时候信任谁？这个问题至少有三个答案。</p><ul><li>手工指定证书<br>所有浏览器和操作系统都提供了一种手工导入信任证书的机制。至于如何获得证书和验证完整性则完全由你自己来定。</li><li>证书颁发机构<br>CA（Certificate Authority，证书颁发机构）是被证书接受者（拥有者）和依赖证书的一方共同信任的第三方。</li><li>浏览器和操作系统<br>每个操作系统和大多数浏览器都会内置一个知名证书颁发机构的名单。因此，你也会信任操作系统及浏览器提供商提供和维护的可信任机构。</li></ul><p>实践中，保存并手工验证每个网站的密钥是不可行的（当然，如果你愿意，也可以）。现实中最常见的方案就是让证书颁发机构替我们做这件事（图 4-5）：浏览器指定可信任的证书颁发机构（根CA），然后验证他们签署的每个站点的责任就转移到了他们头上，他们会审计和验证这些站点的证书没有被滥用或冒充。持有CA证书的站点的安全性如果遭到破坏，那撤销该证书也是证书颁发机构的责任。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE45%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84%E7%AD%BE%E7%BD%B2%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6.png" alt></p><p>所有浏览器都允许用户检视自己安全连接的信任链，常见的访问入口就是地址栏头儿上的锁图标，点击即可查看。</p><h3 id="证书撤销">证书撤销</h3><h4 id="证书撤销名单（CRL）">证书撤销名单（CRL）</h4><p>CRL（Certificate Revocation List，证书撤销名单）是RFC 5280规定的一种检查所有证书状态的简单机制：每个证书颁发机构维护并定期发布已撤销证书的序列号名<br>单。这样，任何想验证证书的人都可以下载撤销名单，检查相应证书是否榜上有名。如果有，说明证书已经被撤销了。</p><p>CRL文件本身可以定期发布、每次更新时发布，或通过HTTP或其他文件传输协议来提供访问。这个名单同样由证书颁发机构签名，通常允许被缓存一定时间。实践中，这种机制效果很好，但也存在一些问题：</p><ul><li>CRL名单会随着要撤销的证书增多而变长，每个客户端都必须取得包含所有序列号的完整名单；</li><li>没有办法立即更新刚刚被撤销的证书序列号，比如客户端先缓存了CRL，之后某证书被撤销，那到缓存过期之前，该证书将一直被视为有效。</li></ul><h4 id="在线证书状态协议（OCSP）">在线证书状态协议（OCSP）</h4><p>为解决CRL机制的上述问题，RFC 2560定义了OCSP（Online Certificate Status Protocol，在线证书状态协议），提供了一种实时检查证书状态的机制。与CRL包含被撤销证书的序列号不同，OCSP 支持验证端直接查询证书数据库中的序列号，从而验证证书链是否有效。总之，OCSP 占用带宽更少，支持实时验证。</p><p>然而，没有什么机制是完美无缺的！实时OCSP查询也带了一些问题：</p><ul><li>证书颁发机构必须处理实时查询；</li><li>证书颁发机构必须确保随时随地可以访问；</li><li>客户端在进一步协商之前阻塞OCSP请求；</li><li>由于证书颁发机构知道客户端要访问哪个站点，因此实时OCSP请求可能会泄露客户端的隐私。</li></ul><blockquote><p>实践中，CRL和OCSP机制是互补存在的，大多数证书既提供指令也支持查询。<br>更重要的倒是客户端的支持和行为。有的浏览器会分发自己的CRL名单，有的浏览器从证书颁发机构取得并缓存CRL文件。类似地，有的浏览器会进行实时OCSP检查，但在OCSP请求失败的情况下行为又会有所不同。要了解具体的情况，可以检查浏览器和操作系统的证书撤销网络设置。</p></blockquote><h3 id="针对TLS的优化建议">针对TLS的优化建议</h3><h4 id="TLS记录大小">TLS记录大小</h4><p>不过对于在浏览器中运行的Web应用来说，倒是有一个值得推荐的做法：每个TCP分组恰好封装一个TLS记录，而TLS记录大小恰好占满TCP分配的MSS（Maximum Segment Size，最大段大小）。换句话说，一方面不要让TLS记录分成多个TCP分组，另一方面又要尽量在一条记录中多发送数据。以下数据可作为确定最优TLS记录大小的参考：</p><ul><li>IPv4 帧需要 20 字节，IPv6 需要 40 字节；</li><li>TCP 帧需要 20 字节；</li><li>TCP 选项需要 40 字节（时间戳、SACK 等）。</li></ul><p>假设常见的MTU为1500字节，则TLS记录大小在IPv4下是1420字节，在IPv6下是1400字节。为确保向前兼容，建议使用IPv6下的大小：1400字节。当然，如果MTU更小，这个值也要相应调小。</p><p>可惜的是，我们不能在应用层控制TLS记录大小。TLS记录大小通常是一个设置，甚至是TLS服务器上的编译时常量或标志。要了解具体如何设置这个值，请参考服务器文档。</p><blockquote><p>如果服务器要处理大量TLS连接，那么关键的优化是把每个连接占用的内存量控制在最小。默认情况下，OpenSSL等常用的库会给每个连接分配50KB空间，但正像设置记录大小一样，有必要查一查文档或者源代码，然后再决定如何调整这个值。谷歌的服务器把OpenSSL缓冲区的大小减少到了大约5KB。</p></blockquote><h4 id="TLS压缩">TLS压缩</h4><p>TLS还有一个内置的小功能，就是支持对记录协议传输的数据进行无损压缩。压缩算法在TLS握手期间商定，压缩操作在对记录加密之前执行。然而，出于如下原因，实践中往往需要禁用服务器上的TLS压缩功能：</p><ul><li>2012 年公布的“CRIME”攻击会利用TLS压缩恢复加密认证cookie，让攻击者实施会话劫持；</li><li>传输级的TLS压缩不关心内容，可能会再次压缩已经压缩过的数据（图像、视频等等）。</li></ul><p>双重压缩会浪费服务器和客户端的CPU时间，而且暴露的安全漏洞也很严重，因此请禁用TLS压缩。实践中，大多数浏览器会禁用TLS压缩，但即便如此你也应该在服务器的配置中明确禁用它，以保护用户的利益。</p><blockquote><p>虽然不能使用TLS压缩，但应该使用服务器的Gzip设置压缩所有文本资源，同时对图像、视频、音频等媒体采用最合适的压缩格式。</p></blockquote><h1>无线网络性能</h1><h2 id="移动网络的优化建议">移动网络的优化建议</h2><h3 id="消除周期性及无效的数据传输">消除周期性及无效的数据传输</h3><p>对推送而言，原生应用可以访问平台专有的推送服务，因此应该尽可能使用。对 Web 应用来说，可以使用SSE（Server Sent Events，服务器发送事件）和WebSocket以降低延迟时间和协议消耗，尽可能不使用轮询和更耗资源的XHR技术。</p><h3 id="消除不必要的长连接">消除不必要的长连接</h3><p>TCP或UDP连接的连接状态及生命期与设备的无线状态是相互独立的。换句话说，即便与运营商网络仍维持着（两端间）连接不中断，无线模块也可以处于低耗电状态。外部网络的分组到来时，运营商无线网络会通知设备，使其无线模块切换到连接状态，从而恢复数据传输。</p><p>明白了吗，应用不必让无线模块“活动”也可以保持连接不被断开。但不必要的长连接也有可能极大地消耗电量，而且由于人们对移动网络无线通信的误解，这种情况经常发生。</p><h3 id="预测网络延迟上限">预测网络延迟上限</h3><p>在移动网络中，一个HTTP请求很可能会导致一连串长达几百甚至上几千ms的网络延迟。这一方面是因为有往返延迟，另一方面也不能忘记DNS、TCP、TLS及控制面的延迟（图8-2）。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE82%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E7%9A%84%E6%9E%84%E6%88%90.png" alt></p><h1>HTTP</h1><h2 id="HTTP-简史">HTTP 简史</h2><h3 id="HTTP-1-0：迅速发展及参考性RFC">HTTP 1.0：迅速发展及参考性RFC</h3><p>今天，几乎所有Web服务器都支持，而且以后还会继续支持HTTP 1.0。除此之外，剩下的你都知道了。但HTTP 1.0对每个请求都打开一个新TCP连接严重影响性能。</p><h3 id="HTTP-1-1：互联网标准">HTTP 1.1：互联网标准</h3><p>HTTP 1.1 标准厘清了之前版本中很多有歧义的地方，而且还加入了很多重要的性能优化：<font color="DeepPink"><strong>持久连接、分块编码传输、字节范围请求、增强的缓存机制、传输编码及请求管道</strong></font>。</p><p>HTTP 1.1 改变了HTTP协议的语义，默认使用持久连接。换句话说，除非明确告知（通过Connection: close 首部），否则服务器默认会保持连接打开。</p><p>不过，这个功能也反向移植到了HTTP 1.0，可以通过Connection: Keep-Alive 首部来启用。实际上，如果你使用的是HTTP 1.1，从技术上说不需要Connection: Keep-Alive首部，但很多客户端还是选择加上它。</p><p>此外，HTTP 1.1 协议添加了内容、编码、字符集，甚至语言的协商机制，还添加了传输编码、缓存指令、客户端cookie 等十几个可以每次请求都协商的字段。</p><h3 id="HTTP-2-0：改进传输性能">HTTP 2.0：改进传输性能</h3><blockquote><p>HTTP（Hypertext Transfer Protocol）是一个应用层协议，可用于分布协作式的超媒体系统。它是一个通用、无状态的协议。除了超文本，通过扩展它的请求方式、错误编码及首部，还可以将它用于很多其他领域，比如域名服务器和分布式对象管理系统。HTTP的一个功能就是允许数据的类型变化和协商，从而允许系统独立于被传输的数据构建。——RFC 2616：HTTP/1.1（1999 年 6 月）</p></blockquote><blockquote><p>当前，出现了一种保持HTTP语义，但脱离HTTP/1.x消息分帧及语法的协议用法。这种用法被证明有碍于性能，并且是在鼓励滥用底层传输协议。本工作组将制定一个新规范，从有序、半双工流的角度重新表达当前HTTP的语义。与HTTP/1.x一样，主要将使用TCP作为传输层，不过也应该支持其他传输协议。——HTTP 2.0 纲领 （2012 年 1 月）</p></blockquote><p>HTTP 2.0 的主要目标是改进传输性能，实现低延迟和高吞吐量。主版本号的增加听起来像是要做大的改进，从性能角度说的确如此。但从另一方面看，HTTP的高层协议语义并不会因为这次版本升级而受影响。所有 HTTP 首部、值，以及它们的使用场景都不会变。</p><h2 id="Web性能要点">Web性能要点</h2><h3 id="剖析现代Web应用">剖析现代Web应用</h3><h4 id="速度、性能与用户期望">速度、性能与用户期望</h4><p>时间和用户感觉</p><table><thead><tr><th>时间</th><th>感觉</th></tr></thead><tbody><tr><td>0 ~100 ms</td><td>很快</td></tr><tr><td>100~300 ms</td><td>有一点点慢</td></tr><tr><td>300~1000 ms</td><td>机器在工作呢</td></tr><tr><td>&gt; 1000 ms</td><td>先干点别的吧</td></tr><tr><td>&gt; 10000 ms</td><td>不能用了</td></tr></tbody></table><blockquote><p>这个表格解释了Web性能社区总结的经验法则：必须250 ms内渲染页面，或者至少提供视觉反馈，才能保证用户不走开！</p></blockquote><h2 id="HTTP-1-x">HTTP 1.x</h2><p>HTTP 1.0的优化策略非常简单，就一句话：升级到HTTP 1.1。完了！</p><p>改进 HTTP 的性能是 HTTP 1.1 工作组的一个重要目标，后来这个版本也引入了大量增强性能的重要特性，其中一些大家比较熟知的有：</p><ul><li>持久化连接以支持连接重用；</li><li>分块传输编码以支持流式响应；</li><li>请求管道以支持并行请求处理；</li><li>字节服务以支持基于范围的资源请求；</li><li>改进的更好的缓存机制。</li></ul><h3 id="HTTP管道">HTTP管道</h3><p>HTTP 1.x 只能严格串行地返回响应。特别是，HTTP 1.x 不允许一个连接上的多个响应数据交错到达（多路复用），因而一个响应必须完全返回后，下一个响应才会开始传输。为说明这一点，我们可以看看服务器并行处理请求的情况（图 11-4）。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE114%E4%BD%BF%E7%94%A8HTTP%E7%AE%A1%E9%81%93%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E4%B8%94%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.png" alt></p><p>图 11-4 演示了如下几个方面：</p><ul><li>HTML 和 CSS 请求同时到达，但先处理的是 HTML 请求；</li><li>服务器并行处理两个请求，其中处理 HTML 用时 40 ms，处理 CSS 用时 20 ms；</li><li>CSS 请求先处理完成，但被缓冲起来以等候发送 HTML 响应；</li><li>发送完 HTML 响应后，再发送服务器缓冲中的 CSS 响应。</li></ul><p>HTTP 管道会导致 HTTP 服务器、代理和客户端出现很多微妙的，不见文档记载的问题：</p><ul><li>一个慢响应就会阻塞所有后续请求；</li><li>并行处理请求时，服务器必须缓冲管道中的响应，从而占用服务器资源，如果有个响应非常大，则很容易形成服务器的受攻击面；</li><li>响应失败可能终止 TCP 连接，从页强迫客户端重新发送对所有后续资源的请求，导致重复处理；</li><li>由于可能存在中间代理，因此检测管道兼容性，确保可靠性很重要；</li><li>如果中间代理不支持管道，那它可能会中断连接，也可能会把所有请求串联起来。</li></ul><p>今天，一些支持管道的浏览器，通常都将其作为一个高级配置选项，但大多数浏览器都会禁用它。换句话说，如果浏览器是 Web 应用的主要交付工具，那还是很难指望通过 HTTP 管道来提升性能。</p><p>要在你自己的应用中启用管道，要注意如下事项：</p><ul><li>确保 HTTP 客户端支持管道；</li><li>确保 HTTP 服务器支持管道；</li><li>应用必须处理中断的连接并恢复；</li><li>应用必须处理中断请求的幂等问题；</li><li>应用必须保护自身不受出问题的代理的影响。</li></ul><p>实践中部署 HTTP 管道的最佳途径，就是在客户端和服务器间使用安全通道（HTTPS）。这样，就能可靠地避免那些不理解或不支持管道的中间代理的干扰。</p><h3 id="使用多个TCP连接">使用多个TCP连接</h3><p>由于 HTTP 1.x 不支持多路复用，浏览器可以不假思索地在客户端排队所有 HTTP请求，然后通过一个持久连接，一个接一个地发送这些请求。然而，这种方式在实践中太慢。实际上，浏览器开发商没有别的办法，只能允许我们并行打开多个 TCP会话。多少个？现实中，大多数现代浏览器，包括桌面和移动浏览器，都支持每个主机打开 6 个连接。</p><blockquote><p>消耗客户端和服务器资源<br>限制每个主机最多 6 个连接，可以让浏览器检测出无意（或有意）的 DoS（Denial of Service）攻击。如果没有这个限制，客户端有可能消耗掉服务器的所有资源。讽刺的是，同样的安全检测在某些浏览器上却会招致反向攻击：如果客户端超过<br>了最大连接数，那么所有后来的客户端请求都将被阻塞。大家可以做个试验，在一个主机上同时打开 6 个并行下载，然后再打开第 7 个下载请求，这个请求会挂起，直到前面的请求完成才会执行。</p></blockquote><p>用足客户端连接的限制似乎是一个可以接受的安全问题，但<font color="DeepPink"><strong>对于需要实时交付数据的应用而言，这样做越来越容易造成部署上的问题。比如 WebSocket、ServerSent Event 和挂起 XHR，这些会话都会占用整整一个 TCP 流，而不管有无数据传输——记住，没有多路复用一说！</strong></font>实际上，如果你不注意，那很可能自己对自己的应用施加 DoS 攻击。</p><h3 id="域名分区">域名分区</h3><p>根据 HTTP Archive 的统计，目前平均每个页面都包含 90 多个独立的资源，如果这些资源都来自同一个主机，那么仍然会导致明显的排队等待。实际上，何必把自己只限制在一个主机上呢？我们不必只通过一个主机（例如 www.example.com）提供所有资源，而是可以手工将所有资源分散到多个子域名：{shard1,shardn}.example.com。由于主机名称不一样了，就可以突破浏览器的连接限制，实现更高的并行能力。域名分区使用得越多，并行能力就越强！</p><p>当然，天下没有免费的午餐，域名分区也不例外：每个新主机名都要求有一次额外的 DNS 查询，每多一个套接字都会多消耗两端的一些资源，而更糟糕的是，站点作者必须手工分离这些资源，并分别把它们托管到多个主机上。</p><blockquote><p>实践中，把多个域名（如 <a href="http://shard1.example.com" target="_blank" rel="noopener">shard1.example.com</a>、<a href="http://shard2.example.com" target="_blank" rel="noopener">shard2.example.com</a>）解析到同一个 IP 地址是很常见的做法。所有分区都通过 CNAME DNS 记录指向同一个服务器，而浏览器连接限制针对的是主机名，不是 IP 地址。另外，每个分区也可以指向一个 CDN 或其他可以访问到的服务器。</p></blockquote><blockquote><p>DNS 查询和 TCP 慢启动导致的额外消耗对高延迟客户端的影响最大。换句话说，移动（3G、4G）客户端经常是受过度域名分区影响最大的！</p></blockquote><blockquote><p><font color="DeepPink"><strong>Cookie 在很多应用中都是常见的性能瓶颈，很多开发者都会忽略它给每次请求增加的额外负担。</strong></font></p></blockquote><blockquote><p>计算图片对内存的需求<br>所有编码的图片经浏览器解析后都会以 RGBA 位图的形式保存于内存当中。每个RGBA 图片的像素需要占用 4 字节：红、绿、蓝通道各占 1 字节，Alpha（透明）通道占 1 字节。这样算下来，一张图片占用的内存量就是图片像素宽度 × 像素高度 ×4 字节。<br>举个例子，800×600 像素的位图会占多大内存呢？<br>800 × 600 × 4 B = 1 920 000 B ≈ 1.83 MB<br>在资源受限的设备，比如手机上，内存占用很快就会成为瓶颈。对于游戏等严重依赖图片的应用来说，这个问题就会更明显。</p></blockquote><blockquote><p>打包文件到底多大合适呢？可惜的是，没有理想的大小。然而，谷歌 PageSpeed团队的测试表明，30~50 KB（压缩后）是每个 JavaScript 文件大小的合适范围：既大到了能够减少小文件带来的网络延迟，还能确保递增及分层式的执行。具体的结果可能会由于应用类型和脚本数量而有所不同。</p></blockquote><h3 id="嵌入资源">嵌入资源</h3><p>嵌入资源是另一种非常流行的优化方法，把资源嵌入文档可以减少请求的次数。比如，JavaScript 和 CSS 代码，通过适当的 script 和 style 块可以直接放在页面中，而图片甚至音频或 PDF 文件，都可以通过数据 URI（data:[mediatype][;base64],data ）的方式嵌入到页面中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAA</span><br><span class="line">AAAAAACH5BAAAAAAALAAAAAABAAEAAAICTAEAOw==&quot;</span><br><span class="line">alt=&quot;1x1 transparent (GIF) pixel&quot; /&gt;</span><br></pre></td></tr></table></figure><blockquote><p>前面的例子是在文档中嵌入了一个 1×1 的透明 GIF 像素。而任何 MIME类型，只要浏览器能理解，都可以通过类似方式嵌入到页面中，包括PDF、音频、视频。不过，有些浏览器会限制数据 URI 的大小，比如 IE8最大只允许 32 KB。</p></blockquote><p>数据 URI 适合特别小的，理想情况下，最好是只用一次的资源。以嵌入方式放到页面中的资源，应该算是页面的一部分，不能被浏览器、CDN 或其他缓存代理作为单独的资源缓存。换句话说，如果在多个页面中都嵌入同样的资源，那么这个资源将<br>会随着每个页面的加载而被加载，从而增大每个页面的总体大小。另外，如果嵌入资源被更新，那么所有以前出现过它的页面都将被宣告无效，而由客户端重新从服务器获取。</p><p>最后，虽然 CSS 和 JavaScript 等基于文本的资源很容易直接嵌入页面，也不会带来多余的开销，但非文本性资源则必须通过 base64 编码，而这会导致开销明显增大：编码后的资源大小比原大小增大 33% ！</p><blockquote><p><font color="DeepPink"><strong>base64 编码使用 64 个 ASCII 符号和空白符将任意字节流编码为 ASCII字符串。编码过程中，base64 会导致被编码的流变成原来的 4/3，即增大33% 的字节开销。</strong></font></p></blockquote><p>实践中，常见的一个经验规则是只考虑嵌入 1~2 KB 以下的资源，因为小于这个标准的资源经常会导致比它自身更高的 HTTP 开销。然而，如果嵌入的资源频繁变更，又会导致宿主文档的无效缓存率升高。嵌入资源也不是完美的方法。如果你的应用要使用很小的、个别的文件，在考虑是否嵌入时，可以参照如下建议：</p><ul><li>如果文件很小，而且只有个别页面使用，可以考虑嵌入；</li><li>如果文件很小，但需要在多个页面中重用，应该考虑集中打包；</li><li>如果小文件经常需要更新，就不要嵌入了；</li><li>通过减少 HTTP cookie 的大小将协议开销最小化。</li></ul><h2 id="HTTP-2-0">HTTP 2.0</h2><p><font color="DeepPink"><strong>HTTP 2.0 的目的就是通过支持请求与响应的多路复用来减少延迟，通过压缩 HTTP首部字段将协议开销降至最低，同时增加对请求优先级和服务器端推送的支持。</strong></font></p><p>HTTP 2.0 不会改动 HTTP 的语义。HTTP 方法、状态码、URI 及首部字段，等等这些核心概念一如往常。但是，HTTP 2.0 修改了格式化数据（分帧）的方式，以及客户端与服务器间传输这些数据的方式。这两点统帅全局，通过新的组帧机制向我们的应用隐藏了所有复杂性。换句话说，所有原来的应用都可以不必修改而在新协议运行。这当然是好事。</p><h3 id="走向HTTP-2-0">走向HTTP 2.0</h3><p>在此，有必要回顾一下 HTTP 2.0 宣言草稿，因为这份宣言明确了该协议的范围和关键设计要求：</p><p>HTTP/2.0 应该满足如下条件：</p><ul><li>相对于使用 TCP 的 HTTP 1.1，用户在大多数情况下的感知延迟要有实质上、可度量的改进；</li><li>解决 HTTP 中的“队首阻塞”问题；</li><li>并行操作无需与服务器建立多个连接，从而改进 TCP 的利用率，特别是拥塞控制方面；</li><li>保持 HTTP 1.1 的语义，利用现有文档，包括（但不限于）HTTP 方法、状态码、URI，以及首部字段；</li><li>明确规定 HTTP 2.0 如何与 HTTP 1.x 互操作，特别是在中间介质上；</li><li>明确指出所有新的可扩展机制以及适当的扩展策略。</li></ul><p>之所以要递增一个大版本到 2.0，主要是因为它改变了客户端与服务器之间交换数据的方式。为实现宏伟的性能改进目标，HTTP 2.0增加了新的二进制分帧数据层，而这一层并不兼容之前的 HTTP 1.x 服务器及客户端——是谓 2.0。</p><blockquote><p>除非你在实现 Web 服务器或者定制客户端，需要使用原始的 TCP 套接字，否则你很可能注意不到 HTTP 2.0 技术面的实际变化：所有新的、低级分帧机制都是浏览器和服务器为你处理的。或许唯一的区别就是可选的 API多了一些，比如服务器推送！</p></blockquote><h3 id="设计和技术目标">设计和技术目标</h3><blockquote><p>HTTP/2.0 通过支持首部字段压缩和在同一连接上发送多个并发消息，让应用更有效地利用网络资源，减少感知的延迟时间。而且，它还支持服务器到客户端的主动推送机制。——HTTP/2.0，Draft 4</p></blockquote><h4 id="二进制分帧层">二进制分帧层</h4><p>HTTP 2.0 性能增强的核心，全在于新增的二进制分帧层（图 12-1），它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE121HTTP2.0%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%88%86%E5%B8%A7%E5%B1%82.png" alt></p><p>这里所谓的“层”，指的是位于套接字接口与应用可见的高层 HTTP API 之间的一个新机制：HTTP 的语义，包括各种动词、方法、首部，都不受影响，不同的是传输期间对它们的编码方式变了。<font color="DeepPink"><strong>HTTP 1.x 以换行符作为纯文本的分隔符，而 HTTP2.0 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。</strong></font></p><h4 id="流、消息和帧">流、消息和帧</h4><ul><li>流<br>已建立的连接上的双向字节流。</li><li>消息<br>与逻辑消息对应的完整的一系列数据帧。</li><li>帧<br>HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流。</li></ul><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE122HTTP2.0%E6%B5%81%E6%B6%88%E6%81%AF%E5%92%8C%E5%B8%A7.png" alt></p><p><font color="DeepPink"><strong>所有 HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。</strong></font></p><blockquote><p>HTTP 2.0 的所有帧都采用二进制编码，所有首部数据都会被压缩。因此，图 12-2 只是说明了数据流、消息和帧之间的关系，而非它们实际传输时的编码结果。</p></blockquote><p>要理解 HTTP 2.0，就必须理解流、消息和帧这几个基本概念。</p><ul><li>所有通信都在一个 TCP 连接上完成。</li><li>流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）。</li><li>消息是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。</li><li>帧是最小的通信单位，承载着特定类型的数据，如 HTTP 首部、负荷，等等。</li></ul><p>简言之，HTTP 2.0 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。相应地，很多流可以并行地在同一个 TCP 连接上交换消息。</p><h4 id="多向请求与响应">多向请求与响应</h4><p>在 HTTP 1.x 中，如果客户端想发送多个并行的请求以及改进性能，那么必须使用多个 TCP 连接。这是 HTTP 1.x 交付模型的直接结果，该模型会保证每个连接每次只交付一个响应（多个响应必须排队）。更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。</p><p>HTTP 2.0 中新的二进制分帧层突破了这些限制，实现了多向请求和响应：客户端和服务器可以把 HTTP 消息分解为互不依赖的帧（图 12-3），然后乱序发送，最后再在另一端把它们重新组合起来。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE123HTTP2.0%E5%9C%A8%E5%85%B1%E4%BA%AB%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%B8%8A%E5%90%8C%E6%97%B6%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.png" alt></p><p>图 12-3 中包含了同一个连接上多个传输中的数据流：客户端正在向服务器传输一个DATA 帧（stream 5），与此同时，服务器正向客户端乱序发送 stream 1 和 stream 3的一系列帧。此时，一个连接上有 3 个请求/响应并行交换！</p><p>总之，<font color="DeepPink"><strong>HTTP 2.0 的二进制分帧机制解决了 HTTP 1.x 中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。</strong></font></p><blockquote><p>支持多向请求与响应，可以省掉针对 HTTP 1.x 限制所费的那些脑筋和工作，比如拼接文件、图片精灵、域名分区。类似地，通过减少 TCP 连接的数量，HTTP 2.0 也会减少客户端和服务器的 CPU 及内存占用。</p></blockquote><h4 id="请求优先级">请求优先级</h4><p>把 HTTP 消息分解为很多独立的帧之后，就可以通过优化这些帧的交错和传输顺序，进一步提升性能。为了做到这一点，每个流都可以带有一个 31 比特的优先值：</p><ul><li>0 表示最高优先级；</li><li>2^31 -1 表示最低优先级。</li></ul><p>有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。具体来讲，服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。</p><blockquote><p>浏览器请求优先级与 HTTP 2.0<br>浏览器在渲染页面时，并非所有资源都具有相同的优先级：HTML 文档本身对构建 DOM 不可或缺，CSS 对构建 CSSOM 不可或缺，而 DOM 和 CSSOM 的构建都可能受到 JavaScript 资源的阻塞，其他资源（如图片）的优先级都可以降低。<br>为加快页面加载速度，所有现代浏览器都会基于资源的类型以及它在页面中的位置排定请求的优先次序，甚至通过之前的访问来学习优先级模式——比如，之前的渲染如果被某些资源阻塞了，那么同样的资源在下一次访问时可能就会被赋予更高的优先级。<br>在 HTTP 1.x 中，浏览器极少能利用上述优先级信息，因为协议本身并不支持多路复用，也没有办法向服务器通告请求的优先级。此时，浏览器只能依赖并行连接，且最多只能同时向一个域名发送 6 个请求。于是，在等连接可用期间，请求只能<br>在客户端排队，从而增加了不必要的网络延迟。理论上，HTTP 管道可以解决这个问题，只是由于缺乏支持而无法付诸实践。<br>HTTP 2.0 一举解决了所有这些低效的问题：浏览器可以在发现资源时立即分派请求，指定每个流的优先级，让服务器决定最优的响应次序。这样请求就不必排队了，既节省了时间，也最大限度地利用了每个连接。</p></blockquote><p>HTTP 2.0 没有规定处理优先级的具体算法，只是提供了一种赋予数据优先级的机制，而且要求客户端与服务器必须能够交换这些数据。这样一来，<font color="DeepPink"><strong>优先值作为提示信息，对应的次序排定策略可能因客户端或服务器的实现而不同：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据。</strong></font></p><p>在这个规定之下，尽管你可能无法控制客户端发送的优先值，但或许你可以控制服务器。因此，在选择 HTTP 2.0 服务器时，可以多留点心！为说明这一点，考虑下面几个问题。</p><ul><li>如果服务器对所有优先值视而不见怎么办？</li><li>高优先值的流一定优先处理吗？</li><li>是否存在不同优先级的流应该交错的情况？<br>如果服务器不理睬所有优先值，那么可能会导致应用响应变慢：浏览器明明在等关键的 CSS 和 JavaScript，服务器却在发送图片，从而造成渲染阻塞。不过，规定严格的优先级次序也可能带来次优的结果，因为这可能又会引入队首阻塞问题，即某<br>个高优先级的慢请求会不必要地阻塞其他资源的交付。</li></ul><p>服务器可以而且应该交错发送不同优先级别的帧。只要可能，高优先级流都应该优先，包括分配处理资源和客户端与服务器间的带宽。不过，为了最高效地利用底层连接，不同优先级的混合也是必需的。</p><h4 id="每个来源一个连接">每个来源一个连接</h4><p>有了新的分帧机制后，HTTP 2.0 不再依赖多个 TCP 连接去实现多流并行了。现在，每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别优先级。于是，<font color="DeepPink"><strong>所有HTTP 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接即可。</strong></font></p><blockquote><p>实验表明，客户端使用更少的连接肯定可以降低延迟时间。HTTP 2.0 发送的总分组数量比 HTTP 差不多要少 40%。而服务器处理大量并发连接的情况也变成了可伸缩性问题，因为 HTTP 2.0 减轻了这个负担。<br>——HTTP/2.0 Draft 2</p></blockquote><p>每个来源一个连接显著减少了相关的资源占用：连接路径上的套接字管理工作量少了，内存占用少了，连接吞吐量大了。此外，从上到下所有层面上也都获得了相应的好处：</p><ul><li>所有数据流的优先次序始终如一；</li><li>压缩上下文单一使得压缩效果更好；</li><li>由于 TCP 连接减少而使网络拥塞状况得以改观；</li><li>慢启动时间减少，拥塞和丢包恢复速度更快。</li></ul><blockquote><p><font color="DeepPink"><strong>大多数 HTTP 连接的时间都很短，而且是突发性的，但 TCP 只在长时间连接传输大块数据时效率才最高。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接。</strong></font></p></blockquote><blockquote><p>丢包、高 RTT 连接和 HTTP 2.0 性能<br>等一等，我听你说了一大堆每个来源一个 TCP 连接的好处，难道它就一点坏处都<br>没有吗？有，当然有。；</p></blockquote><ul><li>虽然消除了 HTTP 队首阻塞现象，但 TCP 层次上仍然存在队首阻塞;</li><li>如果 TCP 窗口缩放被禁用，那带宽延迟积效应可能会限制连接的吞吐量；</li><li>丢包时，TCP 拥塞窗口会缩小。</li></ul><blockquote><p>上述每一点都可能对 HTTP 2.0 连接的吞吐量和延迟性能造成不利影响。然而，除了这些局限性之外，实验表明一个 TCP 连接仍然是 HTTP 2.0 基础上的最佳部署策略。</p></blockquote><p><font color="DeepPink"><strong>总之，一定要知道 HTTP 2.0 与之前的版本一样，并不强制使用 TCP。UDP 等其他传输协议也并非不可以。</strong></font></p><h4 id="流量控制">流量控制</h4><p>在同一个 TCP 连接上传输多个数据流，就意味着要共享带宽。标定数据流的优先级有助于按序交付，但只有优先级还不足以确定多个数据流或多个连接间的资源分配。为解决这个问题，HTTP 2.0 为数据流和连接的流量控制提供了一个简单的机制：</p><ul><li>流量控制基于每一跳进行，而非端到端的控制；</li><li>流量控制基于窗口更新帧进行，即接收方广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节；</li><li>流量控制窗口大小通过WINDOW_UPDATE 帧更新，这个字段指定了流 ID 和窗口大小递增值；</li><li>流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口大小；</li><li>流量控制可以由接收方禁用，包括针对个别的流和针对整个连接。</li></ul><blockquote><p>HTTP 2.0 连接建立之后，客户端与服务器交换 SETTINGS 帧，目的是设置双向的流量控制窗口大小。除此之外，任何一端都可以选择禁用个别流或整个连接的流量控制。</p></blockquote><blockquote><p>优先级可以决定交付次序，而流量控制则可以控制 HTTP 2.0 连接中每个流占用的资源：接收方可以针对特定的流广播较低的窗口大小，以限制它的传输速度。</p></blockquote><h4 id="服务器推送">服务器推送</h4><p>HTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确地请求。</p><blockquote><p>建立 HTTP 2.0 连接后，客户端与服务器交换 SETTINGS 帧，借此可以限定双向并发的流的最大数量。因此，客户端可以限定推送流的数量，或者通过把这个值设置为 0 而完全禁用服务器推送。</p></blockquote><p>为什么需要这样一个机制呢？通常的 Web 应用都由几十个资源组成，客户端需要分析服务器提供的文档才能逐个找到它们。那为什么不让服务器提前就把这些资源推送给客户端，从而减少额外的时间延迟呢？服务器已经知道客户端下一步要请求什么资源了，这时候服务器推送即可派上用场。事实上，如果你在网页里嵌入过 CSS、JavaScript，或者通过数据 URI 嵌入过其他资源，那你就已经亲身体验过服务器推送了。</p><blockquote><p>所有推送的资源都遵守同源策略。换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。</p></blockquote><h4 id="首部压缩">首部压缩</h4><p>HTTP 的每一次通信都会携带一组首部，用于描述传输的资源及其属性。在 HTTP 1.x 中，这些元数据都是以纯文本形式发送的，通常会给每个请求增加 500~800 字节的负荷。如果算上 HTTP cookie，增加的负荷通常会达到上千字节。为减少这些开销并提升性能，HTTP 2.0 会压缩首部元数据：</p><ul><li><font color="DeepPink"><strong>HTTP 2.0 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</strong></font></li><li><font color="DeepPink"><strong>首部表在HTTP 2.0的连接存续期内始终存在，由客户端和服务器共同渐进地更新</strong></font>;</li><li><font color="DeepPink"><strong>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值</strong></font>。</li></ul><p>于是，HTTP 2.0 连接的两端都知道已经发送了哪些首部，这些首部的值是什么，从而可以针对之前的数据只编码发送差异数据（图 12-5）。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE125HTTP2.0%E9%A6%96%E9%83%A8%E7%9A%84%E5%B7%AE%E5%BC%82%E5%8C%96%E7%BC%96%E7%A0%81.png" alt></p><blockquote><p>请求与响应首部的定义在 HTTP 2.0 中基本没有改变，只是所有首部键必须全部小写，而且请求行要独立为 :method 、 :scheme 、 :host 和 :path 这些键－值对。</p></blockquote><p>在前面的例子中，第二个请求只需要发送变化了的路径首部（:path），其他首部没有变化，不用再发送了。这样就可以避免传输冗余的首部，从而显著减少每个请求的开销。通信期间几乎不会改变的通用键－值对（用户代理、可接受的媒体类型，等等）只需发送一次。事实上，如果请求中不包含首部（例如对同一资源的轮询请求），那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部！</p><h4 id="有效的HTTP-2-0升级与发现">有效的HTTP 2.0升级与发现</h4><p>通过常规非加密信道建立 HTTP 2.0 连接需要多做一点工作。因为 HTTP 1.0 和HTTP 2.0 都使用同一个端口（80），又没有服务器是否支持 HTTP 2.0 的其他任何信息，此时客户端只能使用 <font color="DeepPink"><strong>HTTP Upgrade 机制</strong></font>通过协调确定适当的协议：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /page HTTP/1.1</span><br><span class="line">Host: server.example.com</span><br><span class="line">Connection: Upgrade, HTTP2-Settings</span><br><span class="line">Upgrade: HTTP/2.0 ➊</span><br><span class="line">HTTP2-Settings: (SETTINGS payload) ➋</span><br><span class="line">HTTP/1.1 200 OK ➌</span><br><span class="line">Content-length: 243</span><br><span class="line">Content-type: text/html</span><br><span class="line">(... HTTP 1.1 response ...)</span><br><span class="line">(or)</span><br><span class="line">HTTP/1.1 101 Switching Protocols ➍</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: HTTP/2.0</span><br><span class="line">(... HTTP 2.0 response ...)</span><br></pre></td></tr></table></figure><p>➊ 发起带有 HTTP 2.0 Upgrade 首部的 HTTP 1.1 请求<br>➋ HTTP/2.0 SETTINGS 净荷的 Base64 URL 编码<br>➌ 服务器拒绝升级，通过 HTTP 1.1 返回响应<br>➍ 服务器接受 HTTP 2.0 升级，切换到新分帧</p><p>使用这种 Upgrade 流，如果服务器不支持 HTTP 2.0，就立即返回 HTTP 1.1 响应。否则，服务器就会以 HTTP 1.1 格式返回 101 Switching Protocols 响应，然后立即切换到 HTTP 2.0 并使用新的二进制分帧协议返回响应。无论哪种情况，都不需要额外往返。</p><blockquote><p>为确定服务器和客户端都有意使用 HTTP 2.0 对话，双方还必须发送“连接首部”，也就是一串标准的字节。这种信息交换本质上是一种“尽早失败”（fail-fast）的机制，可以避免客户端、服务器，以及中间设备偶尔接受请<br>求的升级却不理解新协议。而且，这种信息交换也不会带来额外的往返，只是在连接开始时要多传一些字节。</p></blockquote><p>最后，如果客户端因为自己保存有或通过其他手段（如 DNS 记录、手工配置等）获得了关于 HTTP 2.0 的支持信息，它也可以直接发送 HTTP 2.0 分帧，而不必依赖Upgrade 机制。有了这些信息，客户端可以一上来就通过非加密信道发送 HTTP 2.0 分帧，其他就不管了。最坏的情况，就是无法建立连接，客户端再回退一步，重新使用 Upgrade 首部，或者切换到带 ALPN 协商的 TLS 信道。</p><p><font color="DeepPink"><strong>服务器之前的 HTTP 2.0 支持信息并不能保证下一次就能可靠地建立连接。以这种方式通信的前提，就是各端都必须支持 HTTP 2.0。如果任何中间设备不支持，连接都不会成功。</strong></font></p><h3 id="二进制分帧简介">二进制分帧简介</h3><p>HTTP 2.0 的根本改进还是新增的长度前置的二进制分帧层。</p><p>建立了 HTTP 2.0 连接后，客户端与服务器会通过交换帧来通信，帧是基于这个新协议通信的最小单位。所有帧都共享一个 8 字节的首部（图 12-6），其中包含帧的长度、类型、标志，还有一个保留位和一个 31 位的流标识符。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE126%E5%85%B1%E6%9C%89%E7%9A%848%E5%AD%97%E8%8A%82%E5%B8%A7%E9%A6%96%E9%83%A8.png" alt></p><ul><li>16 位的长度前缀意味着一帧大约可以携带 64 KB 数据，不包括 8 字节首部。</li><li>8 位的类型字段决定如何解释帧其余部分的内容。</li><li>8 位的标志字段允许不同的帧类型定义特定于帧的消息标志。</li><li>1 位的保留字段始终置为 0。</li><li>31 位的流标识符唯一标识 HTTP 2.0 的流。</li></ul><blockquote><p>在调试 HTTP 2.0 通信时，有人会使用自己喜欢的十六进制查看器。其实，Wireshark 及其他类似的工具也有相应的插件，使用很简单，也很人性化。比如，谷歌 Chrome 就支持 chrome://internals#spdy ，通过它可以查看通信细节。</p></blockquote><p>知道了 HTTP 2.0 规定的这个共享的帧首部，就可以自己编写一个简单的解析器，通过分析 HTTP 2.0 字节流，根据每个帧的前 8 字节找到帧的类型、标志和长度。而且，由于每个帧的长度都是预先定义好的，解析器可以迅速而准确地跳到下一帧的开始，这也是相对于 HTTP 1.x 的一个很大的性能提升。</p><p>知道了帧类型，解析器就知道该如何解释帧的其余内容了。HTTP 2.0 规定了如下帧类型。</p><ul><li>DATA：用于传输 HTTP 消息体。</li><li>HEADERS：用于传输关于流的额外的首部字段。</li><li>PRIORITY：用于指定或重新指定引用资源的优先级。</li><li>RST_STREAM：用于通知流的非正常终止。</li><li>SETTINGS：用于通知两端通信方式的配置数据。</li><li>PUSH_PROMISE：用于发出创建流和服务器引用资源的要约。</li><li>PING：用于计算往返时间，执行“活性”检查。</li><li>GOAWAY：用于通知对端停止在当前连接中创建流。</li><li>WINDOW_UPDATE：用于针对个别流或个别连接实现流量控制。</li><li>CONTINUATION：用于继续一系列首部块片段。</li></ul><blockquote><p>服务器可以利用 GOAWAY 类型的帧告诉客户端要处理的最后一个流的 ID，从而消除一些请求竞争，而且浏览器也可以据此智能地重试或取消“悬着的”请求。这也是保证复用连接安全的一个重要和必要的功能！</p></blockquote><p>既然有了这个分帧层，即使它对我们的应用不可见，我们也应该更进一步，分析一下两种最常见的工作流：发起新流和交换应用数据。只有明白了一个请求或响应如何转换成一个一个的帧，才能理解 HTTP 2.0 对性能的提升来自哪里。</p><blockquote><p>固定长度与可变长度字段<br>HTTP 2.0 只使用固定长度字段，HTTP 2.0 帧占用带宽很少（帧首部是 8 字节）。采用可变长度编码的确可以节省一点带宽和时延，但却无法抵偿由此带来的分析复杂性。<br>即使可变长度编码能减少 50% 的带宽占用，那么在 1 Mbit/s 的连接上传输 1400 字节的分组，也只能节省 4 字节（0.3%）和每帧不到 100 纳秒的延迟时间。</p></blockquote><h4 id="发起新流">发起新流</h4><p>在发送应用数据之前，必须创建一个新流并随之发送相应的元数据，比如流优先级、HTTP 首部等。HTTP 2.0 协议规定客户端和服务器都可以发起新流，因此有两种可能：</p><ul><li>客户端通过发送HEADERS 帧来发起新流（图 12-7），这个帧里包含带有新流 ID 的公用首部、可选的 31 位优先值，以及一组 HTTP 键－值对首部；</li><li>服务器通过发送PUSH_PROMISE 帧来发起推送流，这个帧与 HEADERS 帧等效，但它包含“要约流 ID”，没有优先值。</li></ul><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE127%E5%B8%A6%E4%BC%98%E5%85%88%E5%80%BC%E7%9A%84HEADERS%E5%B8%A7.png" alt></p><p>这两种帧的类型字段都只用于沟通新流的元数据，净荷会在 DATA 帧中单独发送。同样，由于两端都可以发起新流，流计数器偏置：客户端发起的流具有偶数 ID，服务器发起的流具有奇数 ID。这样，两端的流 ID 不会冲突，而且各自持有一个简单的计数器，每次发起新流时递增 ID 即可。</p><blockquote><p>由于流的元数据与应用数据是单独发送的，因此客户端和服务器可以分别给它们设定不同的优先级。比如，“控制流量”的流优先级可以高一些，但只将其应用给 DATA 帧。</p></blockquote><h4 id="发送应用数据">发送应用数据</h4><p>创建新流并发送 HTTP 首部之后，接下来就是利用 DATA 帧（图 12-8）发送应用数据。应用数据可以分为多个 DATA 帧，最后一帧要翻转帧首部的 END_STREAM 字段。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE128DATA%E5%B8%A7.png" alt></p><p>数据净荷不会被另行编码或压缩。编码方式取决于应用或服务器，纯文本、gzip 压缩、图片或视频压缩格式都可以。既然如此，关于 DATA 帧再也没有什么新东西好说了！整个帧由公用的 8 字节首部，后跟 HTTP 净荷组成。</p><blockquote><p>从技术上说， DATA 帧的长度字段决定了每帧的数据净荷最多可达 2^16-1（65 535）字节。可是，为减少队首阻塞，HTTP 2.0 标准要求 DATA 帧不能超过 2^14 -1（16383）字节。长度超过这个阀值的数据，就得分帧发送。</p></blockquote><h4 id="HTTP-2-0帧数据流分析">HTTP 2.0帧数据流分析</h4><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE123HTTP2.0%E5%9C%A8%E5%85%B1%E4%BA%AB%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%B8%8A%E5%90%8C%E6%97%B6%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.png" alt></p><ul><li>有 3 个活动的流：stream 1、stream 3 和 stream 5。</li><li>3 个流的 ID 都是奇数，说明都是客户端发起的。</li><li>这里没有服务器发起的流。</li><li>服务器发送的 stream 1 包含多个DATA 帧，这是对客户端之前请求的响应数据。</li><li>这也说明在此之前已经发送过 HEADERS 帧了。</li><li>服务器在交错发送 stream 1 的DATA 帧和 stream 3 的 HEADERS 帧，这就是响应的多路复用！</li><li>客户端正在发送 stream 5 的DATA 帧，表明 HEADERS 帧之前已经发送过了。</li></ul><p>简言之，图 12-3 中连接正在并行传送 3 个数据流，每个流都处于各自处理周期的不同阶段。服务器决定帧的顺序，而我们不用关心每个流的类型或内容。stream 1 携带的数据量可能比较大，也许是视频，但它不会阻塞共享连接中的其他流！</p><h2 id="优化应用的交付">优化应用的交付</h2><p><font color="DeepPink"><strong>事实上，影响绝大多数 Web 应用性能的并非带宽，而是延迟。</strong></font>网速虽然越来越快，但不幸的是，延迟似乎并没有缩短。</p><blockquote><p>说到底，成功的、可持续的 Web 性能优化策略其实很简单：先度量，然后拿业务目标与性能指标进行比较，采取优化措施，紧了松点，松了紧点，如此反复。开发和购买合用的度量工具及选择恰当的度量手段具有最高优先级；</p></blockquote><h3 id="经典的性能优化最佳实践">经典的性能优化最佳实践</h3><p>无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优化最佳实践，是其他数十条性能准则的出发点。</p><ul><li>减少DNS查找<br>每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻塞后续请求。</li><li>重用TCP连接<br>尽可能使用持久连接，以消除 TCP 握手和慢启动延迟。</li><li>减少HTTP重定向<br>HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时；这里面既有额外的 DNS 查询、TCP 握手，还有其他延迟。最佳的重定向次数为零。</li><li>使用CDN（内容分发网络）<br>把数据放到离用户地理位置更近的地方，可以显著减少每次 TCP 连接的网络延迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容(比如：不缓存的原始获取)。</li><li>去掉不必要的资源<br>任何请求都不如没有请求快。</li></ul><blockquote><p>不缓存的原始获取<br>使用 CDN 或代理服务器取得资源的技术，如果要根据用户定制或者涉及隐私数据，则不能做到全球缓存，这种情况被称为“不缓存的原始获取”（uncached origin fetch）。<br>虽然只有把数据缓存到全球各地的服务器上 CDN 才能发挥最大的效用，但“不缓存的原始获取”仍然具有性能优势：客户端连接终止于附近的服务器，从而显著减少握手延迟。相应地，CDN 或你的代理服务器可以维护一个“热连接池”（warm connection pool），通过它将数据转发给原始服务器，同时做到对客户端快速响应。<br>事实上，作为附加的一个优化层，CDN 提供商在连接两端都会使用邻近服务器！客户端连接终止于邻近 CDN 节点，该节点将请求转发到与对端服务器邻近的 CDN节点，之后请求才会被路由到原始服务器。CDN 网络中多出来这一跳，可以让数据在优化的 CDN 骨干网中寻路，从而进一步减少客户端与服务器之间的延迟。</p></blockquote><ul><li>在客户端缓存资源<br>应该缓存应用资源，从而避免每次请求都发送相同的内容。</li><li>传输压缩过的内容<br>传输前应该压缩应用资源，把要传输的字节减至最少：确保对每种要传输的资源采用最好的压缩手段。</li><li>消除不必要的请求开销<br>减少请求的 HTTP 首部数据（比如 HTTP cookie），节省的时间相当于几次往返的延迟时间。</li><li>并行处理请求和响应<br>请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽视，但却会无谓地导致很长延迟。</li><li>针对协议版本采取优化措施<br>HTTP 1.x 支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而言，HTTP 2.0 只要建立一个连接就能实现最优性能，同时无需针对 HTTP 1.x 的那些优化方法。</li></ul><h4 id="在客户端缓存资源">在客户端缓存资源</h4><p>要说最快的网络请求，那就是不用发送请求就能获取资源。将之前下载过的数据缓存并维护好，就可以做到这一点。对于通过 HTTP 传输的资源，要保证首部包含适当的缓存字段：</p><ul><li>Cache-Control 首部用于指定缓存时间；</li><li>Last-Modified 和 ETag 首部提供验证机制。</li></ul><p>只要可能，就给每种资源都指定一个明确的缓存时间。这样客户端就可以直接使用本地副本，而不必每次都请求相同的内容。类似地，指定验证机制可以让客户端检查过期的资源是否有更新。没有更新，就没必要重新发送。</p><p>最后，还要注意应同时指定缓存时间和验证方法！只指定其中之一是最常见的错误，于是要么导致每次都在没有更新的情况下重发相同内容（这是没有指定验证），要么导致每次使用资源时都多余地执行验证检查（这是没有指定缓存时间）。</p><h4 id="压缩传输的数据">压缩传输的数据</h4><p>利用本地缓存可以让客户端避免每次请求都重复取得数据。不过，还是有一些资源是必须取得的，比如原来的资源过期了，或者有新资源，再或者资源不能缓存。对于这些资源，应该保证传输的字节数最少。因此要保证对它们进行最有效的压缩。</p><p>HTML、CSS 和 JavaScript 等文本资源的大小经过 gzip 压缩平均可以减少 60%~80%。而图片则需要仔细考量：</p><ul><li>图片一般会占到一个网页需要传输的总字节数的一半；</li><li>通过去掉不必要的元数据可以把图片文件变小；</li><li>要调整大小就在服务器上调整，避免传输不必要的字节；</li><li>应该根据图像选择最优的图片格式；</li><li>尽可能使用有损压缩。</li></ul><p>不同图片格式的压缩率迥然不同，因为不同的格式是分别为不同使用场景设计的。事实上，如果选错了图片格式（比如，使用了 PNG 而非 JPG 或 WebP），多产生几百甚至上千 KB 数据是轻而易举的事。建议大家多找一些工具和自动化手段，以确定最佳图片格式。</p><p>选定图片格式后，其次就是不要让图片超过它需要的大小。如果在客户端对超出需要大小的图片做调整，那么除了额外传输不必要的字节之外，还会浪费 CPU、GPU和内存资源。</p><p>最后，选择了正确的格式，确定了必需的大小，接下来就要研究使用哪一种有损图片格式，比如 JPEG 还是 WebP，以及压缩到哪个级别：较高压缩率可以明显减少字节数，同时图片品质不会有太大或太明显的损失，尤其是在较小（手机）的屏幕上看，不容易发现。</p><blockquote><p>WebP：Web 上的新图片格式<br>WebP 是谷歌开发的一种新图片格式，得到了 Chrome 和 Opera 浏览器支持。这种格式的无损压缩和有损压缩效能都有所提升：</p></blockquote><ul><li>WebP 的无损压缩图片比 PNG 的小 26%；</li><li>WebP 的有损压缩图片比 JPG 的小 25%~34%；</li><li>WebP 支持无损透明压缩，但因此仅增加 22% 的字节。</li></ul><blockquote><p>在现有网页平均 1 MB 大小，其中图片占一半的情况下，WebP 节省的 20%~30%，对每个页面而言就是几百 KB。这种格式需要客户端 CPU 多花点时间解码（大约相当于处理 JPG 的 1.4 倍），但字节的节省完全可以补偿处理时间的增长。此外，由于数据流量的限制和高速网络的存在，对很多用户而言，节省字节才是当务之急。<br>事实上，Chrome Data Compression Proxy 和 Opera Turbo 等工具为用户降低带宽占用的主要手段，就是重新把每张图片编码为 WebP 格式。正常情况下，Chrome Data Compression Proxy 的数据压缩率可以达到 50%，这说明我们自己的应用也有很多可以通过压缩提升性能的空间。</p></blockquote><h4 id="消除不必要的请求字节">消除不必要的请求字节</h4><p>HTTP 是一种无状态协议，也就是说服务器不必保存每次请求的客户端的信息。然而，很多应用又依赖于状态信息以实现会话管理、个性化、分析等功能。为了实现这些功能，HTTP State Management Mechanism（RFC 2965）作为扩展，允许任何网站针对自身来源关联和更新 cookie 元数据：浏览器保存数据，而在随后发送给来源的每一个请求的 Cookie 首部中自动附加这些信息。</p><p>上述标准并未规定 cookie 最大不能超过多大，但实践中大多数浏览器都将其限制为4 KB。与此同时，该标准还规定每个站点针对其来源可以有多个关联的 cookie。于是，一个来源的 cookie 就有可能多达几十 KB ！不用说，这么多元数据随请求传递，必然会给应用带来明显的性能损失：</p><ul><li>浏览器会在每个请求中自动附加关联的 cookie 数据；</li><li>在 HTTP 1.x 中，包括 cookie 在内的所有 HTTP 首部都会在不压缩的状态下传输；</li><li>在 HTTP 2.0 中，这些元数据经过压缩了，但开销依然不小；</li><li>最坏的情况下，过大的 HTTP cookie 会超过初始的 TCP 拥塞窗口，从而导致多余的网络往返。</li></ul><p>应该认真对待和监控 cookie 的大小，确保只传输最低数量的元数据，比如安全会话令牌。同时，还应该利用服务器上共享的会话缓存，从中查询缓存的元数据。更好的结果，则是完全不用cookie。比如，在请求图片、脚本和样式表等静态资源时，<br>浏览器绝大多数情况下不必传输特定于客户端的元数据。</p><blockquote><p>在使用 HTTP 1.x 的情况下，可以指定一个专门的“无需 cookie”的来源服务器。这个服务器可以用于交付那些不区分客户端的共用资源。</p></blockquote><h3 id="针对HTTP-1-x的优化建议">针对HTTP 1.x的优化建议</h3><p>针对 HTTP 1.x 的优化次序很重要：首先要配置服务器以最大限度地保证 TCP 和TLS 的性能最优，然后再谨慎地选择和采用移动及经典的应用最佳实践，之后再度量，迭代。</p><p>采用了经典的应用优化措施和适当的性能度量手段，还要进一步评估是否有必要为应用采取特定于 HTTP 1.x 的优化措施（其实是权宜之计）。</p><ul><li>利用HTTP管道<br>如果你的应用可以控制客户端和服务器这两端，那么使用管道可以显著减少网络延迟。</li><li>采用域名分区<br>如果你的应用性能受限于默认的每来源 6 个连接，可以考虑将资源分散到多个来源。</li><li>打包资源以减少HTTP请求<br>拼接和精灵图等技巧有助于降低协议开销，又能达成类似管道的性能提升。</li><li>嵌入小资源<br>考虑直接在父文档中嵌入小资源，从而减少请求数量。</li></ul><p>管道缺乏支持，而其他优化手段又各有各的利弊。事实上，这些优化措施如果过于激进或使用不当，反倒会伤害性能。总之，要有务实的态度，通过度量来评估各种措施对性能的影响，在此基础上再迭代改进。天底下就没有包治百病的灵丹妙药。</p><blockquote><p>对了，还有最后一招儿 —— 升级到 HTTP 2.0。仅此一招儿抵得上前面提到的大多数针对 HTTP 1.x 的优化手段！ HTTP 2.0 不光能让应用加载更快，还能让开发更简单。</p></blockquote><h3 id="针对HTTP-2-0的优化建议">针对HTTP 2.0的优化建议</h3><p>HTTP 2.0 的主要目标就是提升传输性能，实现客户端与服务器间较低的延迟和较高的吞吐量。显然，在 TCP 和 TLS 之上实现最佳性能，同时消除不必要的网络延迟，从来没有如此重要过。最低限度：</p><ul><li>服务器的初始cwnd 应该是 10 个分组；</li><li>服务器应该通过 ALPN（针对 SPDY 则为 NPN）协商支持 TLS；</li><li>服务器应该支持 TLS 恢复以最小化握手延迟。</li></ul><p>接下来，或许有点意外，那就是采用移动及其他经典的最佳做法：少发数据、削减请求，根据无线网络情况调整资源供给。不管使用什么版本的协议，减少传输的数据量和消除不必要的网络延迟，对任何应用都是最有效的优化手段。</p><p>最后，杜绝和忘记域名分区、文件拼接、图片精灵等不良的习惯，这些做法在HTTP 2.0 之上完全没有必要。事实上，继续使用这些手段反而有害！可以利用HTTP 2.0 内置的多路分发以及服务器推送等新功能。</p><h4 id="去掉对1-x的优化">去掉对1.x的优化</h4><p>针对 HTTP 2.0 和 HTTP 1.x 的优化策略没有什么重叠。因此，不仅不必担心 HTTP 1.x 协议的种种限制，而且要撤销原先那些必要的做法。</p><ul><li>每个来源使用一个连接<br>HTTP 2.0 通过将一个 TCP 连接的吞吐量最大化来提升性能。事实上，在 HTTP 2.0 之下再使用多个连接（比如域名分区）反倒成了一种反模式，因为多个连接会抵消新协议中首部压缩和请求优先级的效用。</li><li>去掉不必要的文件合并和图片拼接<br>打包资源的缺点很多，比如缓存失效、占用内存、延缓执行，以及增加应用复杂性。有了 HTTP 2.0，很多小资源都可以并行发送，导致打包资源的效率反而更低。<br>*利用服务器推送<br>之前针对 HTTP 1.x 而嵌入的大多数资源，都可以而且应该通过服务器推送来交付。这样一来，客户端就可以分别缓存每个资源，并在页面间实现重用，而不必把它们放到每个页面里了。</li></ul><p>要获得最佳性能，应该尽可能把所有资源都集中在一个域名之下。域名分区在 HTTP 2.0 之下属于反模式，对发挥协议的性能有害：分区是开始，之后影响会逐渐扩散。打包资源不会影响 HTTP 2.0 协议本身，但对缓存性能和执行速度有负面影响。</p><p>类似地，把嵌入资源改为服务器推送能提升客户端的缓存性能，又不会导致额外网络延迟。事实上，由于 3G 和 4G 网络的往返时间更长，因而服务器推送对移动应用来说效果更明显。</p><blockquote><p>HTTP 2.0 中的打包与协议开销<br>由于 HTTP 1.x 做不到多路复用，而且每次请求的协议开销很高，这才有了连接和拼合等打包技术。在 HTTP 2.0 之下，多路复用已经不成问题，首部压缩也可以降低每次 HTTP 请求要传输的元数据量，打包技术在多数情况下都不再需要了。<br>不过，请求开销只是减少了，并没有等于零。少数情况下，某些资源必须一块使用，而且更新也不频繁，此时使用打包技术仍然可以提升性能。但这些情况很少见，可以算作例外。具体措施可以通过性能度量确定。</p></blockquote><h4 id="双协议应用策略">双协议应用策略</h4><p>遗憾的是，升级到 HTTP 2.0 不会在一夜之间完成。因此，很多应用都需要认真考虑双协议并存的部署策略，即同一个应用既能通过 HTTP 1.x 交付，也能通过 HTTP2.0 交付，无需任何改动。然而，过于激进的 HTTP 1.x 优化可能伤害 HTTP 2.0 性能，反之亦然。</p><p>如果应用可以同时控制服务器和客户端，那倒简单了，因为它可以决定使用什么协议。但大多数应用不能也无法控制客户端，只有采用一种混合或自动策略，以适应两种协议并存的现实。下面我们就分析几种可能的情况。</p><ul><li>相同的应用代码，双协议部署<br>相同的应用代码可能通过 HTTP 1.x 也可能通过 HTTP 2.0 交付。可能任何一种协议之下都达不到最佳性能，但可以追求性能足够好。所谓足够好，需要通过针对每一种应用单独度量来保证。这种情况下，第一步可以先撤销域名分区以实现HTTP 2.0 交付。然后，随着更多用户迁移到 HTTP 2.0，可以继续撤销资源打包并尽可能利用服务器推送。</li><li>分离应用代码，双协议部署<br>根据协议不同分别交付不同版本的应用。这样会增加运维的复杂性，但实践中对很多应用倒是十分可行。比如，一台负责完成连接的边界服务器可以根据协商后的协议版本，把客户端请求引导至适当的服务器。</li><li>动态HTTP 1.x和HTTP 2.0优化<br>某些自动化的 Web 优化框架，以及开源及商业产品，都可以在响应请求时动态重写交付的应用代码（包括连接、拼合、分区，等等）。此时，服务器也可以考虑协商的协议版本，并动态采用适当的优化策略。</li><li>HTTP 2.0，单协议部署<br>如果应用可以控制服务器和客户端，那没理由不只使用 HTTP 2.0。事实上，如果真有这种可能，那就应该专一使用 HTTP 2.0。</li></ul><p>选择路线时，要看当前的基础设施、应用的复杂程度，以及用户的构成。让人哭笑不得的是，那些在 HTTP 1.x 优化上投资很大的应用，反倒在这种情况下最难办。如果你能控制客户端，有自动的应用优化策略，或者没有使用任何特定于 1.x 的优化，那么就可以专注于 HTTP 2.0，而没有后顾之忧了。</p><blockquote><p>使用 PageSpeed 实现动态优化<br>谷歌的 PageSpeed Optimization Libraries（PSOL）提供了 40 多种“Web 优化过滤器”的开源实现，可以集成到任何服务器运行时，动态应用各种优化策略。</p></blockquote><blockquote><p>在使用 PSOL 库的情况下， mod_pagespeed （Apache）和 ngx_pagespeed （Nginx）模块都可以基于指定的优化过滤器（如嵌入、压缩、拼接、分片等）实现动态重写，并优化资源交付方式。每次优化都在请求时动态应用（并被缓存），整个优化过程完全自动化了。<br>在动态优化下，服务器还可以根据所用协议，甚至用户代理的类型和版本调整优化策略。比如，可以配置 mod_pagespeed 模块，在客户端使用 HTTP 2.0 时跳过某些优化：</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#  对 SPDY/HTTP 2.0 客户端禁用拼接</span><br><span class="line">&lt;ModPagespeedIf spdy&gt;</span><br><span class="line">ModPagespeedDisableFilters combine_css,combine_javascript</span><br><span class="line">&lt;/ModPagespeedIf&gt;</span><br><span class="line">#  只对 HTTP 1.x 客户端使用域名分区</span><br><span class="line">&lt;ModPagespeedIf !spdy&gt;</span><br><span class="line">ModPagespeedShardDomain www.site.com s1.site.com,s2.site.com</span><br><span class="line">&lt;/ModPagespeedIf&gt;</span><br></pre></td></tr></table></figure><blockquote><p>使用 PageSpeed 这样的自动 Web 优化库，可以让我们省去不少麻烦，值得考虑。</p></blockquote><h4 id="1-x与2-0的相互转换">1.x与2.0的相互转换</h4><p>除了双协议优化策略，很多已部署的应用都需要在自己的应用服务器上采取一种折中方案：两端都是 HTTP 2.0 是追求最佳性能的目标，但（新增）一个转换层（图13-2）也可以让 1.x 服务器利用 HTTP 2.0。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE132HTTP20%E5%88%B01x%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%8D%B3%E5%B0%86%E6%B5%81%E8%BD%AC%E6%8D%A2%E4%B8%BA1x%E8%AF%B7%E6%B1%82.png" alt></p><p>一台居间服务器可以接受 HTTP 2.0 会话，处理之后再向既有基础设施分派 1.x 格式的请求。接到响应后，再将其转换成 HTTP 2.0 的流并返回客户端。通常，这是应用 HTTP 2.0 更新的最简单方式，因为这样可以重用已有的 1.x 基础设施，而且基本不用修改。</p><blockquote><p>大多数支持 HTTP 2.0 的 Web 服务器默认都提供 2.0 到 1.x 的转换机制：2.0 会话终止于服务器（Apache 或 Nginx），如果服务器被配置为反向代理，那么分派给具体应用服务器的就是 1.x 请求。</p></blockquote><p>然而，2.0 到 1.x 的这种简单策略并非长久之计。从很多方面来说，这种工作流实际是一种倒退。真正正确的做法，不是把优化的、可复用的会话转换成一系列 1.x请求，因基础设施而废优化，而是相反：把接收到的 1.x 客户端请求转换成 2.0 流，并把我们的基础设施标准化，使其在任何时候都处理 2.0 会话。</p><p>为获得最佳性能，同时实现低延迟和实时的 Web 应用，应该要求我们的内部基础设施达到如下标准：</p><ul><li><font color="DeepPink"><strong>负载均衡器和代理与应用的连接应该持久化</strong></font>；</li><li><font color="DeepPink"><strong>请求和响应流及多路复用应该是默认配置</strong></font>；</li><li><font color="DeepPink"><strong>与应用服务器的通信应该基于消息</strong></font>；</li><li><font color="DeepPink"><strong>客户端与应用服务器的通信应该是双向的</strong></font>。</li></ul><p><font color="DeepPink"><strong>端到端的 HTTP 2.0 会话符合上述所有条件，能实现对客户端以及数据中心内部的低延迟交付：无需定制的 RPC 层及相应机制，就能实现内部服务之间的通信，并获得理想的性能。</strong></font>简言之，不要把 2.0 降级到 1.x，这不是长久之计。长久之计是把1.x 升级到 2.0，这样才能求得最佳性能。</p><h4 id="评估服务器质量与性能">评估服务器质量与性能</h4><p>HTTP 2.0 服务器实现的质量对客户端性能影响很大。HTTP 服务器的配置当然是一个重要因素，但服务器实现逻辑的质量同样与优先级、服务器推送、多路复用等性能机制的发挥紧密相关。</p><ul><li>HTTP 2.0 服务器必须理解流优先级；</li><li>HTTP 2.0 服务器必须根据优先级处理响应和交付资源；</li><li>HTTP 2.0 服务器必须支持服务器推送；</li><li>HTTP 2.0 服务器应该提供不同推送策略的实现。</li></ul><p>HTTP 2.0 服务器的初级实现也能支持某些功能，但不能明确支持请求的优先级和服务器推送，可能导致次优性能。比如，发送大型、静态图片导致带宽饱和，而客户端又因为其他重要资源（如 CSS 或 JavaScript）被阻塞。</p><blockquote><p>为尽可能获得最佳性能，HTTP 2.0 客户端必须是个“乐观主义者”：尽可能早地发送所有请求，然后完全听凭服务器的优化。事实上，HTTP 2.0 客户端对服务器的依赖程度较之以前更甚。</p></blockquote><h4 id="2-0与TLS">2.0与TLS</h4><p>实践中，由于存在很多不兼容的中间代理，早期的 HTTP 2.0 部署必然依赖加密信道。这样一来，我们就面临两种可能出现 ALPN 协商和 TLS 终止的情况：</p><ul><li>TLS 连接可能会在 HTTP 2.0 服务器上终止；</li><li>TLS 连接可能会在上游（如负载均衡器）上终止。</li></ul><p>第一种情况要求 HTTP 2.0 服务器能够处理 TLS，除此之外就没有什么了。第二种情况复杂一些：TLS+ALPN 握手可能会在上游代理处终止（图 13-3），然后再从那里建立一条加密信道，或者直接将非加密的 HTTP 2.0 流发送到服务器。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE133%E6%94%AF%E6%8C%81TLSALPN%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8.png" alt></p><p>代理和应用服务器之间使用安全信道还是非加密信道，取决于应用：只要能控制中间设备，就可以保证未加密的帧不会被修改或丢弃。那么，虽然大多数 HTTP 2.0 服务器都应该支持 TLS+ALPN 协商，但它们同时也应该在不加密的情况下实现HTTP 2.0 通信。</p><p>另外，智能负载均衡器也可以使用 TLS+ALPN 协商机制，根据协商后的协议，选择性地将不同的客户端路由到不同的服务器。</p><h4 id="负载均衡器、代理及应用服务器">负载均衡器、代理及应用服务器</h4><p>根据现有基础设施以及应用的复杂程度和规模，你的基础设施中可能需要一台或多台负载均衡器（图 13-4）或者 HTTP 2.0 代理。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE134%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8%E4%B8%8ETLS%E7%BB%88%E6%AD%A2%E7%AD%96%E7%95%A5.png" alt></p><p>最简单的情况下，HTTP 2.0 服务器与客户端直接对话，并负责完成 TLS 连接，进行 ALPN 协商，以及处理所有请求。</p><p>然而，一台服务器对于大型应用是不够的。大型应用必须要添加一台负载均衡器，以分流大量请求。此时，负载均衡器可以终止 TLS 连接（参见 上节 “2.0 与TLS”），也可以经过配置作为 TCP 代理并直接将加密数据发送给应用服务器。</p><blockquote><p>很多云提供商也会提供负载均衡器服务。然而，这些负载均衡器大多支持TLS 终止，却不支持 ALPN 协商，而这对于通过 TLS 实现 HTTP 2.0 通信是必需的。在这种情况下，应该将负载均衡器配置为 TCP 代理，即通过它们将加密数据发送给应用服务器，让应用服务器完成 TLS+ALPN 协商。</p></blockquote><p>实践中，要回答的最重要的一个问题，就是你的基础设施中的哪个组件负责终止TLS 连接，以及它是否能够执行必要的 ALPN 协商？</p><ul><li>要在 TLS 之上实现 HTTP 2.0 通信，终端服务器必须支持 ALPN；</li><li>尽可能在接近用户的地方终止 TLS；</li><li>如果无法支持 ALPN，那么选择 TCP 负载均衡模式；</li><li>如果无法支持 ALPN 且 TCP 负载均衡也做不到，那么就退而求其次，在非加密</li><li>信道上使用 HTTP 的 Upgrade 流</li></ul><h1>浏览器API与协议</h1><h2 id="浏览器网络概述">浏览器网络概述</h2><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE141%E9%AB%98%E5%B1%82%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BD%91%E7%BB%9CAPI%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%9C%8D%E5%8A%A1.png" alt></p><h3 id="连接管理与优化">连接管理与优化</h3><p>运行在浏览器中的 Web 应用并不负责管理个别网络套接字的生命周期，这是好事。通过把这个任务委托给浏览器，可以自动化很多重要的性能优化任务，包括套接字重用、请求优先级排定、晚绑定、协议协商、施加连接数限制，等等。<font color="DeepPink"><strong>事实上，浏览器是有意把请求管理生命周期与套接字管理分开的。</strong></font>这一点很微妙，但却至关重要。</p><p>套接字是以池的形式进行管理的（图 14-2），即按照来源，每个池都有自己的连接限制和安全约束。挂起的请求是排好队的、有优先次序的，然后再适时把它们绑定到池中个别的套接字上。除非服务器有意关闭连接，否则同一个套接字可以自动用于多个请求！</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE142%E8%87%AA%E5%8A%A8%E7%AE%A1%E7%90%86%E7%9A%84%E5%A5%97%E6%8E%A5%E5%AD%97%E6%B1%A0%E5%9C%A8%E6%89%80%E6%9C%89%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BF%9B%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB.png" alt></p><ul><li>来源<br>由应用协议、域名和端口三个要件构成，比如 (http, <a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a>, 80) 与(https, <a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a>, 443) 就是两个不同的来源。</li><li>套接字池<br>属于同一个来源的一组套接字。实践中，所有主流浏览器的最大池规模都是 6 个套接字。</li></ul><p>自动化的套接字池管理会自动重用 TCP 连接，从而有效保障性能。除此之外，这种架构设计还提供了其他优化的机会：</p><ul><li>浏览器可以按照优先次序发送排队的请求；</li><li>浏览器可以重用套接字以最小化延迟并提升吞吐量；</li><li>浏览器可以预测请求提前打开套接字；</li><li>浏览器可以优化何时关闭空闲套接字；</li><li>浏览器可以优化分配给所有套接字的带宽。</li></ul><blockquote><p>谷歌 Chrome 的推测性网络优化<br>我们已经知道了，现代浏览器的网络组件并非一个套接字管理器那么简单。但是，即使如此有时候也足以客观地评价现代浏览器中的某些优化技术。<br>比如，你使用谷歌 Chrome 浏览器的次数越多，它的速度就会越快。Chrome 会学习访问过的站点的拓扑，以及常见的浏览模式，然后利用这些信息进行各种“推测性优化”，以预测用户下一步的操作，从而消除不必要的网络延迟：DNS 预解析、TCP 预连接、页面预渲染，等等。像鼠标悬停在链接上这么个简单的动作，就可以触发浏览器向其网络组件的“预测器”发送信号，后者则会依据过往的性能数据选择最佳的优化措施。<br>如果你对Chrome 浏览器的网络优化技术感兴趣，可以看看这篇文章“High Performance Networking in Google Chrome”：<a href="http://hpbn.co/chrome-networking" target="_blank" rel="noopener">http://hpbn.co/chrome-networking</a>。</p></blockquote><h3 id="网络安全与沙箱">网络安全与沙箱</h3><p><font color="DeepPink"><strong>将个别套接字的管理任务委托给浏览器还有另一个重要的用意：可以让浏览器运用沙箱机制，对不受信任的应用代码采取一致的安全与策略限制。</strong></font>比如，浏览器不允许直接访问原始网络套接字 API，因为这样给恶意应用向任意主机发起任意请求（端口扫描、连接邮件服务器或发送未知消息）提供可乘之机。</p><ul><li>连接限制<br>浏览器管理所有打开的套接字池并强制施加连接数限制，保护客户端和服务器的资源不会被耗尽。</li><li>请求格式化与响应处理<br>浏览器格式化所有外发请求以保证格式一致和符合协议的语义，从而保护服务器。类似地，响应解码也会自动完成，以保护用户。</li><li>TLS 协商<br>浏览器执行 TLS 握手和必要的证书检查。任何证书有问题（比如服务器正在使用自已签发的证书），用户都会收到通知。</li><li>同源策略<br>浏览器会限制应用只能向哪个来源发送请求。</li></ul><p>以上列出的安全限制机制只是一部分，但已经可以体现“最低特权”（least privilege）原则了。浏览器只向应用代码公开那些必要的 API 和资源：应用提供数据和 URL，浏览器执行请求并负责管理每个连接的整个生命周期。</p><blockquote><p>有必要提一句，并没有单独一条原则叫“同源策略”。实际上，这是一组相关的机制，涉及对 DOM 访问、cookie 和会话状态管理、网络及其他浏览器组件的限制。</p></blockquote><h3 id="资源与客户端状态缓存">资源与客户端状态缓存</h3><p>最好最快的请求是没有请求。在分派请求之前，浏览器会自动检查其资源缓存，执行必要的验证，然后在满足限制条件的情况下返回资源的本地副本。类似地，如果某本地资源不在缓存中，那么浏览器就会发送网络请求，将响应自动填充到缓存中，<br>以备后续访问使用。</p><ul><li>浏览器针对每个资源自动执行缓存指令。</li><li>浏览器会尽可能恢复失效资源的有效性。</li><li>浏览器会自动管理缓存大小及资源回收。</li></ul><p><font color="DeepPink"><strong>浏览器还有一个经常被人忽视的重要功能，那就是提供会话认证和 cookie 管理。浏览器为每个来源维护着独立的 cookie 容器，为读写新 cookie、会话和认证数据提供必要的应用及服务器 API，还会为我们自动追加和处理 HTTP 首部，让一切都自动化。</strong></font></p><blockquote><p>举一个简单但直观的例子，它能说明把会话状态管理委托给浏览器的好处：认证的会话可以在多个标签页或浏览器口间共享，反之亦然；如果用户在某个标签页中退出，那么其他所有打开窗口中的会话都将失效。</p></blockquote><h3 id="应用API与协议">应用API与协议</h3><p><img data-src="/images/high-performance-browser-networking/%E8%A1%A8141XHRSSE%E5%92%8CWebSocket%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7.png" alt></p><blockquote><p>我们在这个表中有意忽略了 WebRTC，因为那是一种端到端的交付模型，与 XHR、SSE 和 WebSocket 协议有着根本的不同。</p></blockquote><h2 id="XMLHttpRequest">XMLHttpRequest</h2><h3 id="XHR简史">XHR简史</h3><p>尽管名字里有 XML 的 X，XHR 也不是专门针对 XML 开发的。这只是因为 Internet Explorer 5 当初发布它的时候，把它放到 MSXML 库里，这才“继承”了这个 X。</p><h3 id="跨源资源共享（CORS）">跨源资源共享（CORS）</h3><p>XHR 是一个浏览器层面的 API，向我们隐藏了大量底层处理，包括缓存、重定向、内容协商、认证，等等。这样做有两个目的。第一，XHR 的 API 因此非常简单，开发人员可以专注业务逻辑。其次，浏览器可以采用沙箱机制，对应用代码强制施加一套安全限制。</p><p>XHR 接口强制要求每个请求都严格具备 HTTP 语义：应用提供数据和 URL，浏览器格式化请求并管理每个连接的完整生命周期。类似地，虽然 XHR API 允许应用添加自定义的 HTTP 首部（通过 setRequestHeader() 方法），同时也有一些首部是应用代码不能设定的：</p><ul><li>Accept-Charset、Accept-Encoding、Access-Control-*</li><li>Host、Upgrade、Connection、Referer、Origin</li><li>Cookie、Sec-*、Proxy-* 以及很多其他首部</li></ul><p><font color="DeepPink"><strong>浏览器会拒绝对不安全首部的重写，以此保证应用不能假扮用户代理、用户或请求来源。事实上，保护来源（Origin）首部特别重要，因为这是对所有 XHR 请求应用“同源策略”的关键。</strong></font></p><blockquote><p>一个“源”由应用协议、域名和端口这三个要件共同定义。比如，(http,<a href="http://example.com" target="_blank" rel="noopener">example.com</a>, 80) 和 (https, <a href="http://example.com" target="_blank" rel="noopener">example.com</a>, 443) 就是不同的源。</p></blockquote><p>同源策略的出发点很简单：浏览器存储着用户数据，比如认证令牌、cookie 及其他私有元数据，这些数据不能泄露给其他应用。如果没有同源沙箱，那么 <a href="http://example.com" target="_blank" rel="noopener">example.com</a> 中的脚本就可以访问并操纵 <a href="http://thirdparty.com" target="_blank" rel="noopener">thirdparty.com</a> 的用户数据！</p><p>为解决这个问题，XHR 的早期版本都限制应用只能执行同源请求，即新请求的来源必须与旧请求的来源一致：来自 <a href="http://example.com" target="_blank" rel="noopener">example.com</a> 的 XHR 请求，只能从 <a href="http://example.com" target="_blank" rel="noopener">example.com</a> 请求其他资源。如果后续请求不同源，浏览器就拒绝该 XHR 请求并报错。</p><p>可是，在某些必要的情况下，同源策略也会给更好地利用 XHR 带来麻烦：如果服务器想要给另一个网站中的脚本提供资源怎么办？这就是 Cross-Origin Resource Sharing（跨源资源共享，CORS）的来由！ CORS 针对客户端的跨源请求提供了安全的选择同意机制：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//  脚本来源： (http, example.com, 80)</span><br><span class="line">var xhr = new XMLHttpRequest();</span><br><span class="line">xhr.open(&apos;GET&apos;, &apos;/resource.js&apos;); ➊</span><br><span class="line">xhr.onload = function() &#123; ... &#125;;</span><br><span class="line">xhr.send();</span><br><span class="line">var cors_xhr = new XMLHttpRequest();</span><br><span class="line">cors_xhr.open(&apos;GET&apos;, &apos;http://thirdparty.com/resource.js&apos;); ➋</span><br><span class="line">cors_xhr.onload = function() &#123; ... &#125;;</span><br><span class="line">cors_xhr.send();</span><br></pre></td></tr></table></figure><p>➊ 同源 XHR 请求<br>➋ 跨源 XHR 请求</p><p>CORS 请求也使用相同的 XHR API，区别仅在于请求资源用的 URL 与当前脚本并不同源。在前面的例子中，当前执行的脚本来自 (http, <a href="http://example.com" target="_blank" rel="noopener">example.com</a>, 80)，而第二个XHR 请求访问的 resource.js 则来自 (http, <a href="http://thirdparty.com" target="_blank" rel="noopener">thirdparty.com</a>, 80)。</p><p>针对 CORS 请求的选择同意认证机制由底层处理：请求发出后，浏览器自动追加受保护的 Origin HTTP 首部，包含着发出请求的来源。相应地，远程服务器可以检查 Origin 首部，决定是否接受该请求，如果接受就返回 Access-Control-Allow-Origin 响应首部：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=&gt;  请求</span><br><span class="line">GET /resource.js HTTP/1.1</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com ➊</span><br><span class="line">...</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: http://example.com ➋</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>➊ Origin 首部由浏览器自动设置<br>➋ 选择同意首部由服务器设置</p><p>在前面的例子中，<a href="http://thirdparty.com" target="_blank" rel="noopener">thirdparty.com</a> 决定同意与 <a href="http://example.com" target="_blank" rel="noopener">example.com</a> 跨源共享资源，因此就在响应中返回了适当的访问控制首部。假如它选择不同意接受这个请求，那么只要不在响应中包含 Access-Control-Allow-Origin 首部即可。这样，客户端的浏览器就会自动将发出的请求作废。</p><blockquote><p>如果第三方服务器不支持 CORS，那么客户端请求同样会作废，因为客户端会验证响应中是否包含选择同意的首部。作为一个特例，CORS 还允许服务器返回一个通配值 ( Access-Control-Allow-Origin: * )，表示它允许来自任何源的请求。不过，在启用这个选项前，请大家务必三思！</p></blockquote><p>这就是全部了吧？准确地讲，不是。因为 CORS 还会提前采取一系列安全措施，以确保服务器支持 CORS：</p><ul><li>CORS 请求会省略 cookie 和 HTTP 认证等用户凭据；</li><li>客户端被限制只能发送“简单的跨源请求”，包括只能使用特定的方法（GET、POST 和 HEAD），以及只能访问可以通过 XHR 发送并读取的 HTTP 首部。</li></ul><p>要启用 cookie 和 HTTP 认证，客户端必须在发送请求时通过 XHR 对象发送额外的属性（ withCredentials ），而服务器也必须以适当的首部（Access-Control-Allow-Credentials）响应，表示它允许应用发送用户的隐私数据。类似地，如果客户端需要写或者读自定义的 HTTP 首部，或者想要使用“不简单的方法”发送请求，那么它必须首先要获得第三方服务器的许可，即向第三方服务器发送一个预备（preflight）请求：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=&gt;  预备请求</span><br><span class="line">OPTIONS /resource.js HTTP/1.1 ➊</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com</span><br><span class="line">Access-Control-Request-Method: POST</span><br><span class="line">Access-Control-Request-Headers: My-Custom-Header</span><br><span class="line">...</span><br><span class="line">&lt;= 预备响应</span><br><span class="line">HTTP/1.1 200 OK ➋</span><br><span class="line">Access-Control-Allow-Origin: http://example.com</span><br><span class="line">Access-Control-Allow-Methods: GET, POST, PUT</span><br><span class="line">Access-Control-Allow-Headers: My-Custom-Header</span><br><span class="line">...</span><br><span class="line">（正式的 HTTP 请求） ➌</span><br></pre></td></tr></table></figure><p>➊ 验证许可的预备 OPTIONS 请求<br>➋ 第三方源的成功预备响应<br>➌ 实际的 CORS 请求</p><p>W3C 官方的 CORS 规范规定了何时何地必须使用预备请求：“简单的”请求可以跳过它，但很多条件下这个请求都是必需的，因此也会为验证许可而增加仅有一次往返的网络延迟。好在，只要完成预备请求，客户端就会将结果缓存起来，后续请求就不必重复验证了。</p><blockquote><p>CORS 得到了所有现代浏览器支持，参见：<a href="http://caniuse.com/cors%E3%80%82%E8%A6%81%E5%85%A8%E9%9D%A2%E4%BA%86%E8%A7%A3CORS" target="_blank" rel="noopener">caniuse.com/cors。要全面了解CORS</a> 的各种策略及实现，请参考 W3C 官方标准（<a href="http://www.w3.org/TR/cors/" target="_blank" rel="noopener">http://www.w3.org/TR/cors/</a>）。</p></blockquote><h3 id="通过XHR下载数据">通过XHR下载数据</h3><p>浏览器可以自动解码的数据类型如下:</p><ul><li>ArrayBuffer<br>固定长度的二进制数据缓冲区。</li><li>Blob<br>二进制大对象或不可变数据。</li><li>Document<br>解析后得到的 HTML 或 XML 文档。</li><li>JSON<br>表示简单数据结构的 JavaScript 对象。</li><li>Text<br>简单的文本字符串。</li></ul><p>浏览器可以依靠 HTTP 的 content-type 首部来推断适当的数据类型（比如把application/json 响应解析为 JSON 对象），应用也可以在发起 XHR 请求时显式重写数据类型。</p><blockquote><p>这里的二进制大对象接口（ Blob ）属于 HTML5 的 File API，就像一个不透明的引用，可以指向任何数据块（二进制或文本）。这个对象本身没有太多功能，只能查询其大小、MIME 类型，或将它切分成更小的块。这个对象存在的真正目的，是作为各种 JavaScript API 之间的一种高效的互操作机制。</p></blockquote><blockquote><p>要估算传输完成的数据量，服务器必须在其响应中提供内容长度（Content-Length）首部。而对于分块数据，由于响应的总长度未知，因此就无法估计进度了。另外，XHR 请求默认没有超时限制，这意味着一个请求的“进度”可以无限长。作为最佳实践，一定要为应用设置合理的超时时间，并适当处理错误。</p></blockquote><h2 id="服务器发送事件">服务器发送事件</h2><p>Server-Sent Events（SSE）让服务器可以向客户端流式发送文本消息，比如服务器上生成的实时通知或更新。为达到这个目标，SSE 设计了两个组件：浏览器中的EventSource 和新的“事件流”数据格式。其中， EventSource 可以让客户端以 DOM 事件的形式接收到服务器推送的通知，而新数据格式则用于交付每一次更新。</p><p>EventSource API 和定义完善的事件流数据格式，使得 SSE 成为了在浏览器中处理实时数据的高效而不可或缺的工具：</p><ul><li>通过一个长连接低延迟交付；</li><li>高效的浏览器消息解析，不会出现无限缓冲；</li><li>自动跟踪最后看到的消息及自动重新连接；</li><li>消息通知在客户端以 DOM 事件形式呈现。</li></ul><p>实际上，SSE 提供的是一个高效、跨浏览器的 XHR 流实现，消息交付只使用一个长 HTTP 连接。然而，与我们自己实现 XHR 流不同，浏览器会帮我们管理连接、解析消息，从而让我们只关注业务逻辑。</p><h3 id="EventSource-API">EventSource API</h3><p>EventSource 接口通过一个简单的浏览器 API 隐藏了所有的底层细节，包括建立连接和解析消息。</p><blockquote><p>SSE 实现了节省内存的 XHR 流。与原始的 XHR 流在连接关闭前会缓冲接收到的所有响应不同，SSE 连接会丢弃已经处理过的消息，而不会在内存中累积。</p></blockquote><p><font color="DeepPink"><strong>值得一提的是， EventSource 接口还能自动重新连接并跟踪最近接收的消息：如果连接断开了， EventSource 会自动重新连接到服务器，还可以向服务器发送上一次接收到的消息 ID，以便服务器重传丢失的消息并恢复流。</strong></font></p><h3 id="Event-Stream协议">Event Stream协议</h3><p>SSE 事件流是以流式 HTTP 响应形式交付的：客户端发起常规 HTTP 请求，服务器以自定义的“text/event-stream”内容类型响应，然后交付 UTF-8 编码的事件数据。这么简单几句话似乎都有点说复杂了，看一个例子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=&gt;  请求</span><br><span class="line">GET /stream HTTP/1.1 ➊</span><br><span class="line">Host: example.com</span><br><span class="line">Accept: text/event-stream</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK ➋</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Type: text/event-stream</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">retry: 15000 ➌</span><br><span class="line">data: First message is a simple string. ➍</span><br><span class="line">data: &#123;&quot;message&quot;: &quot;JSON payload&quot;&#125; ➎</span><br><span class="line">event: foo ➏</span><br><span class="line">data: Message of type &quot;foo&quot;</span><br><span class="line">id: 42 ➐</span><br><span class="line">event: bar</span><br><span class="line">data: Multi-line message of</span><br><span class="line">data: type &quot;bar&quot; and id &quot;42&quot;</span><br><span class="line">id: 43 ➑</span><br><span class="line">data: Last message, id &quot;43&quot;</span><br></pre></td></tr></table></figure><p>➊ 客户端通过 EventSource 接口发起连接<br>➋ 服务器以 “text/event-stream” 内容类型响应<br>➌ 服务器设置连接中断后重新连接的间隔时间（15 s）<br>➍ 不带消息类型的简单文本事件<br>➎ 不带消息类型的 JSON 数据载荷<br>➏ 类型为 “foo” 的简单文本事件<br>➐ 带消息 ID 和类型的多行事件<br>➑ 带可选 ID 的简单文本事件</p><p>在接收端， EventSource 接口通过检查换行分隔符来解析到来的数据流。</p><blockquote><p><font color="DeepPink"><strong>SSE 中的 UTF-8 编码与二进制传输 EventSource 不会对实际载荷进行任何额外处理：从一或多个 data 字段中提取出来的消息，会被拼接起来直接交给应用。因此，服务器可以推送任何文本格式（例如，简单字符串、JSON，等等），应用必须自己解码。</strong></font></p></blockquote><blockquote><p>话虽如此，但所有事件源数据都是 UTF-8 编码的：SSE 不是为传输二进制载荷而设计的！如果有必要，可以把二进制对象编码为 base64 形式，然后再使用 SSE。但这样会导致很高（33%）的字节开销。</p></blockquote><blockquote><p>担心 UTF-8 编码也会造成高开销？ SSE 连接本质上是 HTTP 流式响应，因此响应是可以压缩的（如 gzip 压缩），就跟压缩其他 HTTP 响应一样，而且是动态压缩！虽然 SSE 不是为传输二进制数据而设计的，但它却是一个高效的机制——只要让你的服务器对 SSE 流应用 gzip 压缩。</p></blockquote><blockquote><p><font color="DeepPink"><strong>不支持二进制传输是有意为之的。SSE 的设计目标是简单、高效，作为一种服务器向客户端传送文本数据的机制。如果你想传输二进制数据，WebSocket 才是更合适的选择。</strong></font></p></blockquote><p>最后，除了自动解析事件数据，SSE 还内置支持断线重连，以及恢复客户端因断线而丢失的消息。默认情况下，如果连接中断，浏览器会自动重新连接。SSE 规范建议的间隔时间是 2~3 s，这也是大多数浏览器采用的默认值。不过，服务器也可以设置一个自定义的间隔时间，只要在推送任何消息时向客户端发送一个 retry 命令即可。</p><p>类似地，服务器还可以给每条消息关联任意 ID 字符串。浏览器会自动记录最后一次收到的消息 ID，并在发送重连请求时自动在 HTTP 首部追加“Last-Event-ID”值。下面看一个例子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">（既有 SSE 连接）</span><br><span class="line">retry: 4500 ➊</span><br><span class="line">id: 43 ➋</span><br><span class="line">data: Lorem ipsum</span><br><span class="line">（连接断开）</span><br><span class="line">（4500 ms 后）</span><br><span class="line">=&gt;  请求</span><br><span class="line">GET /stream HTTP/1.1 ➌</span><br><span class="line">Host: example.com</span><br><span class="line">Accept: text/event-stream</span><br><span class="line">Last-Event-ID: 43</span><br><span class="line">&lt;= 响应</span><br><span class="line">HTTP/1.1 200 OK ➍</span><br><span class="line">Content-Type: text/event-stream</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">id: 44 ➎</span><br><span class="line">data: dolor sit amet</span><br></pre></td></tr></table></figure><p>➊ 服务器将客户端的重连间隔设置为 4.5 s<br>➋ 简单文本事件，ID:43<br>➌ 带最后一次事件 ID 的客户端重连请求<br>➍ 服务器以 ‘text/event-stream’ 内容类型响应<br>➎ 简单文本事件，ID:44</p><p>客户端应用不必为重新连接和记录上一次事件 ID 编写任何代码。这些都由浏览器自动完成，然后就是服务器负责恢复了。值得注意的是，根据应用的要求和数据流，服务器可以采取不同的实现策略。</p><ul><li><p>如果丢失消息可以接受，就不需要事件 ID 或特殊逻辑，只要让客户端重连并恢复数据流即可。</p></li><li><p><font color="DeepPink"><strong>如果必须恢复消息，那服务器就需要指定相关事件的 ID，以便客户端在重连时报告最后接收到的 ID。</strong></font>同样，服务器也需要实现某种形式的本地缓存，以便恢复并向客户端重传错过的消息。</p></li></ul><h3 id="SSE使用场景及性能">SSE使用场景及性能</h3><blockquote><p>通过 TLS 实现 SSE 流<br>SSE 通过常规 HTTP 连接实现了简单便捷的实时传输机制，服务器端容易部署，客户端也容易打补丁。可是，现有网络中间设备，比如代理服务器和防火墙，都不支持 SSE，而这有可能带来问题：中间设备可能会缓冲事件流数据，导致额外延迟，甚至彻底毁掉 SSE 连接。</p></blockquote><blockquote><p>如果你碰到了这样或类似的问题，那么可以考虑通过 TLS 发送 SSE 事件流。</p></blockquote><h2 id="WebSocket">WebSocket</h2><p>WebSocket 可以实现客户端与服务器间双向、基于消息的文本或二进制数据传输。</p><h3 id="接收文本和二进制数据">接收文本和二进制数据</h3><p>WebSocket 协议不作格式假设，对应用的净荷也没有限制：文本或者二进制数据都没问题。从内部看，协议只关注消息的两个信息：净荷长度和类型（前者是一个可变长度字段），据以区别 UTF-8 数据和二进制数据。</p><p>浏览器接收到新消息后，如果是文本数据，会自动将其转换成 DOMString 对象，如果是二进制数据或 Blob 对象，会直接将其转交给应用。唯一可以（作为性能暗示和优化措施）多余设置的，就是告诉浏览器把接收到的二进制数据转换成 ArrayBuffer而非 Blob。</p><blockquote><p>用户代理可以将这个选项看作一个暗示，以决定如何处理接收到的二进制数据：如果这里设置为“blob”，那就可以放心地将其转存到磁盘上；而如果设置为“arraybuffer”，那很可能在内存里处理它更有效。自然地，我们鼓励用户代理使用更细微的线索，以决定是否将到来的数据放到内存里…… ——The WebSocket API W3C Candidate Recommendation</p></blockquote><p>Blob 对象一般代表一个不可变的文件对象或原始数据。如果你不需要修改它或者不需要把它切分成更小的块，那这种格式是理想的（比如，可以把一个完整的 Blob 对象传给 img 标签）。而如果你还需要再处理接收到的二进制数据，那么选择 ArrayBuffer 应该更合适。</p><h3 id="子协议协商">子协议协商</h3><p><font color="DeepPink"><strong>WebSocket 协议对每条消息的格式事先不作任何假设：仅用一位标记消息是文本还是二进制，以便客户端和服务器有效地解码数据，而除此之外的消息内容就是未知的。</strong></font></p><p>此外，与 HTTP 或 XHR 请求不同——它们是通过每次请求和响应的 HTTP 首部来沟通元数据，WebSocket 并没有等价的机制。因此，如果需要沟通关于消息的元数据，客户端和服务器必须达成沟通这一数据的子协议。</p><ul><li><p>客户端和服务器可以提前确定一种固定的消息格式，比如所有通信都通过 JSON编码的消息或者某种自定义的二进制格式进行，而必要的元数据作为这种数据结构的一个部分。</p></li><li><p>如果客户端和服务器要发送不同的数据类型，那它们可以确定一个双方都知道的消息首部，利用它来沟通说明信息或有关净荷的其他解码信息。</p></li><li><p>混合使用文本和二进制消息可以沟通净荷和元数据，比如用文本消息实现 HTTP首部的功能，后跟包含应用净荷的二进制消息。</p></li></ul><blockquote><p>子协议名由应用自己定义，且在初次 HTTP 握手期间发送给服务器。除此之外，指定的子协议对核心 WebSocket API 不会有任何影响。</p></blockquote><h3 id="WebSocket协议">WebSocket协议</h3><blockquote><p>WebSocket 协议尝试在既有 HTTP 基础设施中实现双向 HTTP 通信，因此也使用 HTTP 的 80 和 443 端口……不过，这个设计不限于通过 HTTP 实现WebSocket 通信，未来的实现可以在某个专用端口上使用更简单的握手，而<br>不必重新定义么一个协议。 ——WebSocket Protocol RFC 6455</p></blockquote><h4 id="二进制分帧层-v2">二进制分帧层</h4><p>客户端和服务器 WebSocket 应用通过基于消息的 API 通信：发送端提供任意 UTF-8或二进制的净荷，接收端在整个消息可用时收到通知。为此，WebSocket 使用了自定义的二进制分帧格式（图 17-1），把每个应用消息切分成一或多个帧，发送到目的地之后再组装起来，等到接收到完整的消息后再通知接收端。</p><p><img data-src="/images/high-performance-browser-networking/%E5%9B%BE171WebSocket%E5%B8%A7%E6%A0%BC%E5%BC%8F.png" alt></p><ul><li>帧<br>最小的通信单位，包含可变长度的帧首部和净荷部分，净荷可能包含完整或部分应用消息。</li><li>消息<br>一系列帧，与应用消息对等。</li><li>每一帧的第一位（FIN）表示当前帧是不是消息的最后一帧。一条消息有可能只对应一帧。</li><li>操作码（4 位）表示被传输帧的类型：传输应用数据时，是文本（1）还是二进制（2）；连接有效性检查时，是关闭（8）、呼叫（ping，9）还是回应（pong，10）。</li><li>掩码位表示净荷是否有掩码（只适用于客户端发送给服务器的消息）。</li><li>净荷长度由可变长度字段表示：<ul><li>如果是 0~125，就是净荷长度；</li><li>如果是 126，则接下来 2 字节表示的 16 位无符号整数才是这一帧的长度；</li><li>如果是 127，则接下来 8 字节表示的 64 位无符号整数才是这一帧的长度。</li></ul></li><li>掩码键包含 32 位值，用于给净荷加掩护。</li><li>净荷包含应用数据，如果客户端和服务器在建立连接时协商过，也可以包含自定义的扩展数据。</li></ul><blockquote><p>所有客户端发送帧的净荷都要使用帧首部中指定的值加掩码，这样可以防止客户端中运行的恶意脚本对不支持 WebSocket 的中间设备进行缓存投毒攻击（cache poisoning attack）。要了解这种攻击的细节，请参考 W2SP<br>2011 的论文“Talking to Yourself for Fun and Profit”（<a href="http://w2spconf.com/2011/papers/websocket.pdf" target="_blank" rel="noopener">http://w2spconf.com/2011/papers/websocket.pdf</a>）。</p></blockquote><p>算下来，服务器发送的每个 WebSocket 帧会产生 2~10 字节的分帧开销。而客户端必须发送掩码键，这又会增加 4 字节，结果就是 6~14 字节的开销。除此之外，没有其他元数据（比如首部字段或其他关于净荷的信息）：所有 WebSocket 通信都是通过交换帧实现的，而帧将净荷视为不透明的应用数据块。</p><blockquote><p>WebSocket 的多路复用及队首阻塞<br>WebSocket 很容易发生队首阻塞的情况：消息可能会被分成一或多个帧，但不同消息的帧不能交错发送，因为没有与 HTTP 2.0 分帧机制中“流 ID”对等的字段。<br>显然，如果一个大消息被分成多个 WebSocket 帧，就会阻塞其他消息的帧。如果你的应用不容许有交付延迟，那可以小心控制每条消息的净荷大小，甚至可以考虑把大消息拆分成多个小消息！<br><font color="DeepPink"><strong>WebSocket 不支持多路复用，还意味着每个 WebSocket 连接都需要一个专门的TCP 连接。对于 HTTP 1.x 而言，由于浏览器针对每个来源有连接数量限制，因此可能会导致问题。</strong></font><br>好 在，HyBi Working Group 正 着 手 制 定 的 新 的“Multiplexing Extension for WebSockets”（WebSockets 多路复用扩展）会解决这个问题：<br>这个扩展通过封装帧并加上信道 ID，可以让一个 TCP 连接支持多个虚拟 WebSocket 连接……这个多路复用扩展维护独立的逻辑信道，每个逻辑信道与独立的 WebSocket 连接没有差别，包括独立的握手首部。<br>——WebSocket Multiplexing（Draft 10）<br>有了这个扩展后，多个 WebSocket 连接（信道）就可能在同一个 TCP 连接上得到复用。可是，每个信道依旧容易产生队首阻塞问题！可能的解决方案是使用不同的信道，或者专用 TCP 连接，多路并行发送消息。<br>最后，注意前面的扩展仅对 HTTP 1.x 连接是必要的。虽然通过 HTTP 2.0 传输WebSocket 帧的官方规范尚未发布，但相对来说就容易多了。因为 HTTP 2.0 内置了流的多路复用，只要通过 HTTP 2.0 的分帧机制来封装 WebSocket 帧，多个WebSocket 连接就可以在一个会话中传输。</p></blockquote><h4 id="协议扩展">协议扩展</h4><p>WebSocket 规范允许对协议进行扩展：数据格式和 WebSocket 协议的语义可以通过新的操作码和数据字段扩展。虽然有些不同寻常，但这却是一个非常强大的特性，因为它允许客户端和服务器在基本的 WebSocket 分帧层之上实现更多功能，又不需要应用代码介入或协作。</p><p>要使用扩展，客户端必须在第一次的 Upgrade 握手中通知服务器，服务器必须选择并确认要在商定连接中使用的扩展。</p><h4 id="HTTP升级协商">HTTP升级协商</h4><p>WebSocket 协议提供了很多强大的特性：基于消息的通信、自定义的二进制分帧层、子协议协商、可选的协议扩展，等等。换句话说，在交换数据之前，客户端必须与服务器协商适当的参数以建立连接。</p><p>利用 HTTP 完成握手有几个好处。首先，让 WebSockets 与现有 HTTP 基础设施兼容：WebSocket 服务器可以运行在 80 和 443 端口上，这通常是对客户端唯一开放的端口。其次，让我们可以重用并扩展 HTTP 的 Upgrade 流，为其添加自定义的WebSocket 首部，以完成协商。</p><ul><li>Sec-WebSocket-Version<br>客户端发送，表示它想使用的 WebSocket 协议版本（“13”表示 RFC 6455）。如果服务器不支持这个版本，必须回应自己支持的版本。</li><li>Sec-WebSocket-Key<br>客户端发送，自动生成的一个键，作为一个对服务器的“挑战”，以验证服务器支持请求的协议版本。<br>Sec-WebSocket-Accept<br>服务器响应，包含 Sec-WebSocket-Key 的签名值，证明它支持请求的协议版本。</li><li>Sec-WebSocket-Protocol<br>用于协商应用子协议：客户端发送支持的协议列表，服务器必须只回应一个协议名。</li><li>Sec-WebSocket-Extensions<br>用于协商本次连接要使用的 WebSocket 扩展：客户端发送支持的扩展，服务器通过返回相同的首部确认自己支持一或多个扩展。</li></ul><p>有了这些协商字段，就可以在客户端和服务器之间进行 HTTP Upgrade 并协商新的WebSocket 连接了：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /socket HTTP/1.1</span><br><span class="line">Host: thirdparty.com</span><br><span class="line">Origin: http://example.com</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: websocket ➊</span><br><span class="line">Sec-WebSocket-Version: 13 ➋</span><br><span class="line">Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== ➌</span><br><span class="line">Sec-WebSocket-Protocol: appProtocol, appProtocol-v2 ➍</span><br><span class="line">Sec-WebSocket-Extensions: x-webkit-deflate-message, x-custom-extension ➎</span><br></pre></td></tr></table></figure><p>➊ 请求升级到 WebSocket 协议<br>➋ 客户端使用的 WebSocket 协议版本<br>➌ 自动生成的键，以验证服务器对协议的支持<br>➍ 可选的应用指定的子协议列表<br>➎ 可选的客户端支持的协议扩展列表<br>与浏览器中客户端发起的任何连接一样，WebSocket 请求也必须遵守同源策略：浏览器会自动在升级握手请求中追加 Origin 首部，远程服务器可能使用 CORS 判断接受或拒绝跨源请求。要完成握手，服务器必须返回一个成功的“Switching Protocols”（切换协议）响应，并确认选择了客户端发送的哪个选项：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 101 Switching Protocols ➊</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Access-Control-Allow-Origin: http://example.com ➋</span><br><span class="line">Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= ➌</span><br><span class="line">Sec-WebSocket-Protocol: appProtocol-v2 ➍</span><br><span class="line">Sec-WebSocket-Extensions: x-custom-extension ➎</span><br></pre></td></tr></table></figure><p>➊ 101 响应码确认升级到 WebSocket 协议<br>➋ CORS 首部表示选择同意跨源连接<br>➌ 签名的键值验证协议支持<br>➍ 服务器选择的应用子协议<br>➎ 服务器选择的 WebSocket 扩展</p><blockquote><p>所有兼容 RFC 6455 的 WebSocket 服务器都使用相同的算法计算客户端挑战的答案：将 Sec-WebSocket-Key 的内容与标准定义的唯一 GUID 字符串拼接起来，计算出 SHA1 散列值，结果是一个 base-64 编码的字符串，把这个字符串发给客户端即可。</p></blockquote><p>最低限度，成功的 WebSocket 握手必须是客户端发送协议版本和自动生成的挑战值，服务器返回 101 HTTP 响应码（Switching Protocols）和散列形式的挑战答案，确认选择的协议版本：</p><ul><li>客户端必须发送Sec-WebSocket-Version 和 Sec-WebSocket-Key ；</li><li>服务器必须返回Sec-WebSocket-Accept 确认协议；</li><li>客户端可以通过Sec-WebSocket-Protocol 发送应用子协议列表；</li><li>服务器必须选择一个子协议并通过Sec-WebSocket-Protocol 返回协议名；如果服务器不支持任何一个协议，连接断开；</li><li>客户端可以通过Sec-WebSocket-Extensions 发送协议扩展；</li><li>服务器可以通过Sec-WebSocket-Extensions 确认一或多个扩展；如果服务器没有返回扩展，则连接不支持扩展。</li></ul><p>最后，前述握手完成后，如果握手成功，该连接就可以用作双向通信信道交换WebSocket 消息。从此以后，客户端与服务器之间不会再发生 HTTP 通信，一切由WebSocket 协议接管。</p><blockquote><p>代理、中间设备与 WebSocket<br>实践中，考虑到安全和保密，很多用户都只开放有限的端口，通常只有 80（HTTP）和 443（HTTPS）。正因为如此，WebSocket 协商是通过 HTTP Upgrade流进行的，这样可以确保与现有网络策略及基础设施兼容。<br>不过，正如 “Web 代理、中间设备、TLS 与新协议”所说，很多现有的HTTP 中间设备可能不理解新的 WebSocket 协议，而这可能导致各种问题：盲目的连接升级、意外缓冲 WebSocket 帧、不明就里地修改内容、把 WebSocket 流量误当作不完整的 HTTP 通信，等等。<br>WebSocket 的 Key 和 Accept 握手可以解决其中一些问题：这是服务器的一个安全策略，而盲目“升级”连接的中间设备可能并不理解 WebSocket 协议。虽然这个预防措施对某些代理可以解决问题，但对于那些“透明代理”还是不行，它们可能会分析并意外地修改数据。<br>解决之道？建立一条端到端的安全通道。比如，使用 WSS ！在执行 HTTP Upgrade 握手之前，先协商一次 TLS 会话，在客户端与服务器之间建立一条加密通道，就可以解决前述所有问题。这个方案尤其适合移动客户端，因为它们的流量经常要穿越各种代理服务，这些代理服务很可能不认识 WebSocket。</p></blockquote><h3 id="WebSocket使用场景及性能">WebSocket使用场景及性能</h3><h4 id="请求和响应流">请求和响应流</h4><blockquote><p>把传输机制从 XHR 切换为 SSE 或 WebSocket 并不会减少客户端与服务器间的往返次数！不管什么传输机制，数据包的传播延迟都一样。不过，除了传播延迟，还有一个排队延迟——消息在被发送给另一端之前必须在客户端或服务器上等待的时间。</p></blockquote><h2 id="WebRTC">WebRTC</h2><p>略</p><p>PDF书籍下载地址：<a href="https://github.com/jiankunking/books-recommendation/tree/master/HTTP" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/HTTP</a></p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Network</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
        <tag>HTTP</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Java ForkJoin 解析</title>
    <url>/java-forkjoin.html</url>
    <content><![CDATA[<blockquote><p>本文主要想了解两个地方：如何窃取任务、task如何等待（join）<br>代码基于 OpenJDK 12</p></blockquote><a id="more"></a><h1>窃取算法（work-stealing）</h1><p>从<a href="/attachments/ForkJoin-Paper-DougLea.pdf" target="_blank">ForkJoin-Paper-DougLea</a>中可以看出:</p><ul><li>每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。</li><li>队列使用的是双端队列，支持LIFO、FIFO。</li><li>子任务会被放到线程（不一定是当前线程）的队列中。</li><li>工作线程按照LIFO的顺序处理自己队列中数据。</li><li>当一个工作线程处理完自己队列中数据的时候，会随机挑选一个工作线程，并“窃取”的该工作线程队列队尾的task。</li></ul><p><img data-src="/images/java-forkjoin/steal.png" alt></p><p>到了这里就可以知道，窃取任务从其他线程队列的尾部窃取的了。</p><h2 id="窃取算法优缺点">窃取算法优缺点</h2><p>工作窃取算法的优点：<font color="DeepPink"><strong>充分利用线程进行并行计算，减少了线程间的竞争。</strong></font><br>工作窃取算法的缺点：<font color="DeepPink"><strong>在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。</strong></font></p><h1>Task 等待（join）</h1><p>Join方法的主要作用是阻塞当前线程并等待获取结果。具体代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final V join() &#123;</span><br><span class="line">    int s;</span><br><span class="line">    if (((s = doJoin()) &amp; ABNORMAL) != 0)</span><br><span class="line">        reportException(s);</span><br><span class="line">    return getRawResult();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，它调用了doJoin()方法，通过doJoin()方法得到当前任务的状态来判断返回什么结果，任务状态有4种：已完成（NORMAL）、被取消（CANCELLED）、信号（SIGNAL）和出现异常（EXCEPTIONAL）。</p><ul><li>如果任务状态是已完成，则直接返回任务结果。</li><li>如果任务状态是被取消，则直接抛出CancellationException。</li><li>如果任务状态是抛出异常，则直接抛出对应的异常。</li></ul><p>让我们再来分析一下doJoin()方法的实现代码:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Implementation for join, get, quietlyJoin. Directly handles</span><br><span class="line"> * only cases of already-completed, external wait, and</span><br><span class="line"> * unfork+exec.  Others are relayed to ForkJoinPool.awaitJoin.</span><br><span class="line"> *</span><br><span class="line"> * @return status upon completion</span><br><span class="line"> */</span><br><span class="line">private int doJoin() &#123;</span><br><span class="line">    int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;</span><br><span class="line">    return </span><br><span class="line">        //已完成,返回status</span><br><span class="line">    	(s = status) &lt; 0 ? s :</span><br><span class="line">    	//未完成,如果当前线程是ForkJoinWorkerThread,从该线程中取出workQueue,并尝试将</span><br><span class="line">        //当前task出队然后执行,执行的结果是完成则返回状态,否则使用当线程池所在的ForkJoinPool的awaitJoin方法等待</span><br><span class="line">        ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?</span><br><span class="line">        (w = (wt = (ForkJoinWorkerThread)t).workQueue).tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) :</span><br><span class="line">        //当前线程不是ForkJoinWorkerThread,调用externalAwaitDone方法</span><br><span class="line">        //externalAwaitDone: Blocks a non-worker-thread until completion.</span><br><span class="line">        externalAwaitDone();</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Pops the given task only if it is at the current top.</span><br><span class="line"> */</span><br><span class="line">final boolean tryUnpush(ForkJoinTask&lt;?&gt; task) &#123;</span><br><span class="line">    boolean popped = false;</span><br><span class="line">    int s, cap; ForkJoinTask&lt;?&gt;[] a;</span><br><span class="line">    if ((a = array) != null &amp;&amp; (cap = a.length) &gt; 0 &amp;&amp;</span><br><span class="line">        (s = top) != base &amp;&amp;</span><br><span class="line">        (popped = QA.compareAndSet(a, (cap - 1) &amp; --s, task, null)))</span><br><span class="line">        TOP.setOpaque(this, s);</span><br><span class="line">    return popped;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Primary execution method for stolen tasks. Unless done, calls</span><br><span class="line"> * exec and records status if completed, but doesn&apos;t wait for</span><br><span class="line"> * completion otherwise.</span><br><span class="line"> *</span><br><span class="line"> * @return status on exit from this method</span><br><span class="line">*/</span><br><span class="line">final int doExec() &#123;</span><br><span class="line">    int s; boolean completed;</span><br><span class="line">    // 仅未完成的任务会运行,其他情况会忽略.</span><br><span class="line">    if ((s = status) &gt;= 0) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            //exec是abstract方法</span><br><span class="line">            //调用ForkJoinTask子类中exec</span><br><span class="line">            completed = exec();</span><br><span class="line">        &#125; catch (Throwable rex) &#123;</span><br><span class="line">            completed = false;</span><br><span class="line">            s = setExceptionalCompletion(rex);</span><br><span class="line">        &#125;</span><br><span class="line">        if (completed)</span><br><span class="line">            s = setDone();</span><br><span class="line">        &#125;</span><br><span class="line">        return s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在doJoin()方法里，首先通过查看任务的状态，看任务是否已经执行完成，如果执行完成，则直接返回任务状态；如果没有执行完，则从任务队列中取出任务并执行。如果任务顺利执行完成，则设置任务状态为NORMAL，如果出现异常，则记录异常，并将任务状态设置为EXCEPTIONAL。</p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>ForkJoin</tag>
      </tags>
  </entry>
  <entry>
    <title>Java ThreadLocal</title>
    <url>/java-threadlocal.html</url>
    <content><![CDATA[<blockquote><p>基于OpenJDK 12</p></blockquote><a id="more"></a><h1>引</h1><p>本文主要想了解两个地方：</p><ol><li>ThreadLocal实例看起来是在多个线程共享，但实际上是彼此独立的，这个是怎么实现的？</li><li>ThreadLocal使用不当真的会OOM吗？如果会，那么原因是啥？</li></ol><p>先看一下<a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/ThreadLocal.html" target="_blank" rel="noopener">ThreadLocal的官方API</a>解释为：</p><blockquote><p>该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或 set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本[原文：These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable.]。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。</p></blockquote><p>大概的意思有两点：</p><ul><li><font color="DeepPink"><strong>ThreadLocal提供了一种访问某个变量的特殊方式：访问到的变量属于当前线程，即保证每个线程的变量不一样，而同一个线程在任何地方拿到的变量都是一致的，这就是所谓的线程隔离。</strong></font></li><li><font color="DeepPink"><strong>如果要使用ThreadLocal，通常定义为private static类型，在我看来最好是定义为private static final类型。</strong></font></li></ul><p>看一段代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 代码来自：</span><br><span class="line">// http://tutorials.jenkov.com/java-concurrency/threadlocal.html</span><br><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            //注意这里 set的值是run函数的内部变量，如果是MyRunnable的全局变量</span><br><span class="line">            //则无法起到线程隔离的作用</span><br><span class="line">            threadLocal.set((int) (Math.random() * 100D));</span><br><span class="line">            try &#123;</span><br><span class="line">                //sleep两秒的作用是让thread2 set操作在thread1的输出之前执行</span><br><span class="line">                //如果线程之间是共用threadLocal，则thread2 set操作会覆盖掉thread1的set操作</span><br><span class="line">                //从而两者的输出都是thread2 set的值</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(threadLocal.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">38</span><br><span class="line">thread1 join</span><br><span class="line">78</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>MyRunnable run中sleep两秒的作用是让thread2 set操作在thread1的输出之前执行，如果线程之间是共用threadLocal，则thread2 set操作会覆盖掉thread1的set操作，两者的输出都是thread2 set的值，从而输出的应该是同一个值。</p><p>但从代码执行结果来看，thread1、thread2的threadLocal是不同的，也就是实现了线程隔离。</p><h1>ThreadLocal实例在线程间是如何独立的？</h1><p>看一眼ThreadLocal set方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void set(T value) &#123;</span><br><span class="line">    //currentThread是个native方法，会返回对当前执行线程对象的引用。</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    //getMap 返回线程自身的threadLocals</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    if (map != null) &#123;</span><br><span class="line">        //把value set到线程自身的ThreadLocalMap中了</span><br><span class="line">        map.set(this, value);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //线程自身的ThreadLocalMap未初始化，则先初始化，再set</span><br><span class="line">        createMap(t, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">ThreadLocalMap getMap(Thread t) &#123;</span><br><span class="line">    return t.threadLocals;</span><br><span class="line">&#125;</span><br><span class="line">//Thread类中</span><br><span class="line">//ThreadLocalMapset的set方法未执行深拷贝，需要注意传递值的类型</span><br><span class="line">ThreadLocal.ThreadLocalMap threadLocals = null;</span><br></pre></td></tr></table></figure><p>从代码中可以看到，在set的时候，会根据Thread对象的引用来将值添加到各自线程中。但set的值value还是同一个对象,既然传递的是同一个对象，那就涉及到另一个问题：参数值传递、引用传递的问题了。</p><h2 id="基本类型">基本类型</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        // MyRunnable 全局变量</span><br><span class="line">        int random;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            random = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(random);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(threadLocal.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值不同</span><br><span class="line">16</span><br><span class="line">thread1 join</span><br><span class="line">75</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出可以看出两者隔离了。</p><h2 id="引用类型">引用类型</h2><h3 id="全局引用">全局引用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        // MyRunnable 全局变量</span><br><span class="line">        Obj obj = new Obj();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            obj.value = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(obj);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(((Obj) threadLocal.get()).value);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        class Obj &#123;</span><br><span class="line">            int value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值相同</span><br><span class="line">36</span><br><span class="line">36</span><br><span class="line">thread1 join</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出结果来看，当set操作的值是MyRunnable的全局变量，并且是引用类型的时候，无法起到隔离的作用。</p><h3 id="局部引用">局部引用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ThreadLocalExample &#123;</span><br><span class="line">    public static class MyRunnable implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">        private ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        //Obj obj = new Obj();</span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            Obj obj = new Obj();</span><br><span class="line">            obj.value = (int) (Math.random() * 100D);</span><br><span class="line">            threadLocal.set(obj);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                System.out.println(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(((Obj) threadLocal.get()).value);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        class Obj &#123;</span><br><span class="line">            int value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        MyRunnable sharedRunnableInstance = new MyRunnable();</span><br><span class="line"></span><br><span class="line">        Thread thread1 = new Thread(sharedRunnableInstance);</span><br><span class="line">        Thread thread2 = new Thread(sharedRunnableInstance);</span><br><span class="line"></span><br><span class="line">        thread1.start();</span><br><span class="line">        System.out.println(&quot;thread1 start&quot;);</span><br><span class="line">        thread2.start();</span><br><span class="line">        System.out.println(&quot;thread2 start&quot;);</span><br><span class="line"></span><br><span class="line">        thread1.join(); //wait for thread 1 to terminate</span><br><span class="line">        System.out.println(&quot;thread1 join&quot;);</span><br><span class="line">        thread2.join(); //wait for thread 2 to terminate</span><br><span class="line">        System.out.println(&quot;thread2 join&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread1 start</span><br><span class="line">thread2 start</span><br><span class="line">//两个值不同</span><br><span class="line">12</span><br><span class="line">19</span><br><span class="line">thread1 join</span><br><span class="line">thread2 join</span><br></pre></td></tr></table></figure><p>从输出结果看，局部引用，可以相互隔离。</p><p><font color="DeepPink"><strong>到这里可以看出ThreadLocal，只是把set值或引用绑定到了当前线程，但却没有进行相应的深拷贝，所以ThreadLocal要想做的线程隔离，必须是基本类型或者run的局部变量。</strong></font></p><h1>ThreadLocal OOM ？</h1><p>看一下ThreadLocalMap内部Entry：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;</span><br><span class="line">    /** The value associated with this ThreadLocal. */</span><br><span class="line">    Object value;</span><br><span class="line"></span><br><span class="line">    Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;</span><br><span class="line">        super(k);</span><br><span class="line">        value = v;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码中看到，Entry继承了WeakReference，并将ThreadLocal设置为了WeakReference，value设置为强引用。也就是：当没有强引用指向ThreadLocal变量时，它可被回收。</p><p>但是，还有一个问题：<font color="DeepPink"><strong>ThreadLocalMap维护ThreadLocal变量与具体实例的映射，当ThreadLocal变量被回收后，该映射的key变为 null，而该Entry还是在ThreadLocalMap中，从而这些无法清理的Entry，会造成内存泄漏。</strong></font></p><blockquote><p>ThreadLocal自带的remove、set方法，都无法处理ThreadLocal自身为null的情况，因为代码中都直接取ThreadLocal的threadLocalHashCode属性了，所以如果ThreadLocal自身已经是null，这时调用remove、set会报空指针异常（java.lang.NullPointerException）的。</p></blockquote><p>所以，在使用ThreadLocal的时候，在使用完毕记得remove（remove方法会将Entry的value及Entry自身设置为null并进行清理）。</p><p>JDK 12 ThreadLocal代码地址：<br><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/lang/ThreadLocal.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/lang/ThreadLocal.java</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Java Concurrent Atomic Package详解</title>
    <url>/java-concurrent-atomic-package.html</url>
    <content><![CDATA[<blockquote><p>翻译自：Package java.util.concurrent.atomic</p></blockquote><a id="more"></a><blockquote><p>地址：<br><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html#package.description" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html#package.description</a><br>翻译JDK8而不是12的原因是JDK8对与内存语义部分讲解更加详细。</p></blockquote><p><strong>Package java.util.concurrent.atomic 对于单个变量支持无锁、线程安全操作的工具类。</strong></p><p>类摘要：</p><table><thead><tr><th>类名</th><th>描述</th></tr></thead><tbody><tr><td>AtomicBoolean</td><td>可以原子性更新的boolean值。</td></tr><tr><td>AtomicInteger</td><td>可以原子性更新的int值。</td></tr><tr><td>AtomicIntegerArray</td><td>一个int数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicIntegerFieldUpdater<t></t></td><td>基于反射，可以对指定类的指定 volatile int 字段进行原子更新。</td></tr><tr><td>AtomicLong</td><td>可以原子性更新的long值。</td></tr><tr><td>AtomicLongArray</td><td>一个long数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicLongFieldUpdater<t></t></td><td>基于反射，可以对指定类的指定 volatile long 字段进行原子更新。</td></tr><tr><td>AtomicMarkableReference<v></v></td><td>维护带有标记位的对象引用，可以原子方式对其进行更新。</td></tr><tr><td>AtomicReference<v></v></td><td>可以原子性更新的对象引用</td></tr><tr><td>AtomicReferenceArray<e></e></td><td>一个对象引用数组，其中的元素可以原子性更新。</td></tr><tr><td>AtomicReferenceFieldUpdater&lt;T,V&gt;</td><td>基于反射，可以对指定类的指定 volatile reference 字段进行原子更新。</td></tr><tr><td>AtomicStampedReference<v></v></td><td>维护带有整数版本标志的对象引用，可以原子方式对其进行更新。</td></tr><tr><td>DoubleAccumulator</td><td>One or more variables that together maintain a running double value updated using a supplied function.</td></tr><tr><td>DoubleAdder</td><td>One or more variables that together maintain an initially zero double sum.</td></tr><tr><td>LongAccumulator</td><td>One or more variables that together maintain a running long value updated using a supplied function.</td></tr><tr><td>LongAdder</td><td>One or more variables that together maintain an initially zero long sum.</td></tr></tbody></table><blockquote><p>DoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder 均是Striped64的子类，内部维护的是一个数组，当并发更新时，每个线程操作的是数组中的元素，从而降低锁的粒度。</p></blockquote><p>本质上，该package下的类扩展了volatile值、字段、数组元素的概念，提供以下形式的原子更新操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean compareAndSet(expectedValue, updateValue);</span><br></pre></td></tr></table></figure><p>该方法（在不同类中的参数类型不同）原子地将变量设置为updateValue，如果它当前持有expectedValue，更新成功返回true。该包中的类还包含获取和无条件设置（set）值的方法。</p><p>这些方法的规范使实现能够采用当代处理器上可用的高效机器级原子指令。然而，<font color="DeepPink"><strong>在某些平台上，支持可能需要某种形式的内部锁定。因此，这些方法不是严格保证是非阻塞的（线程可能在执行操作之前暂时阻塞）。</strong></font></p><p>AtomicBoolean、AtomicInteger、AtomicLong和AtomicReference类的实例都提供对对应类型的单个变量的访问和更新。每个类还提供了适用于该类型的实用方法。例如，类AtomicLong和AtomicInteger提供原子增量方法。 一个应用是生成序列号，如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Sequencer &#123;</span><br><span class="line">  private final AtomicLong sequenceNumber = new AtomicLong(0);</span><br><span class="line">  public long next() &#123;</span><br><span class="line">    return sequenceNumber.getAndIncrement();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原子性访问和更新内存效果，与volatiles遵循同样的规则，如<a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4" target="_blank" rel="noopener">The Java Language Specification (17.4 Memory Model)</a>所述：</p><ul><li>get与volatile读效果一样</li><li>set与volatile写效果一样</li><li>lazySet与写入(分配)volatile变量的效果一样【写操作不会与之前的任何写操作重新排序】，但它可能被后续操作重排【也就是，<font color="DeepPink"><strong>在volatile写或者同步操作之前，可能对于其它线程不可见</strong></font>】。</li><li>compareAndSet和所有其他读取和更新操作(如getAndIncrement)一样，与volatile变量读取和写入具有相同的内存效果。</li></ul><blockquote><p>lazySet是使用Unsafe.putOrderedObject方法，这个方法在对低延迟代码是很有用的，它能够实现非阻塞的写入，这些写入不会被Java的JIT重新排序指令(instruction reordering)，这样它使用快速的存储-存储(store-store) barrier, 而不是较慢的存储-加载(store-load) barrier, 后者总是用在volatile的写操作上，这种性能提升是有代价的，虽然便宜，也就是写后结果并不会被其他线程看到，甚至是自己的线程，通常是几纳秒后被其他线程看到，这个时间比较短，所以代价可以忍受。<br>设想如下场景: 设置一个 volatile 变量为 null，让这个对象被 GC 掉，volatile write 是消耗比较大（store-load 屏障）的，但是 putOrderedInt 只会加 store-store 屏障，损耗会小一些。</p></blockquote><p>添加lazySet方法的原因:<a href="https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6275329" target="_blank" rel="noopener">https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6275329</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">As probably the last little JSR166 follow-up for Mustang,</span><br><span class="line">we added a &quot;lazySet&quot; method to the Atomic classes</span><br><span class="line">(AtomicInteger, AtomicReference, etc). This is a niche</span><br><span class="line">method that is sometimes useful when fine-tuning code using</span><br><span class="line">non-blocking data structures. The semantics are</span><br><span class="line">that the write is guaranteed not to be re-ordered with any</span><br><span class="line">previous write, but may be reordered with subsequent operations</span><br><span class="line">(or equivalently, might not be visible to other threads) until</span><br><span class="line">some other volatile write or synchronizing action occurs).</span><br><span class="line"></span><br><span class="line">The main use case is for nulling out fields of nodes in</span><br><span class="line">non-blocking data structures solely for the sake of avoiding</span><br><span class="line">long-term garbage retention; it applies when it is harmless</span><br><span class="line">if other threads see non-null values for a while, but you&apos;d</span><br><span class="line">like to ensure that structures are eventually GCable. In such</span><br><span class="line">cases, you can get better performance by avoiding</span><br><span class="line">the costs of the null volatile-write. There are a few</span><br><span class="line">other use cases along these lines for non-reference-based</span><br><span class="line">atomics as well, so the method is supported across all of the</span><br><span class="line">AtomicX classes.</span><br><span class="line"></span><br><span class="line">For people who like to think of these operations in terms of</span><br><span class="line">machine-level barriers on common multiprocessors, lazySet</span><br><span class="line">provides a preceeding store-store barrier (which is either</span><br><span class="line">a no-op or very cheap on current platforms), but no</span><br><span class="line">store-load barrier (which is usually the expensive part</span><br><span class="line">of a volatile-write).</span><br></pre></td></tr></table></figure><blockquote><p>weakCompareAndSet JDK 9之后Deprecated，本文已跳过。</p></blockquote><p>除了表示单个值的类之外，package中还包含Updater类，可用于在类的volatile字段上执行compareAndSet操作。 AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater和AtomicLongFieldUpdater是基于反射的，可提供对相关字段类型的访问。这些主要用于原子数据结构，同一节点的几个volatile字段（例如，树节点的链接）独立地原子更新。<strong>这些类在如何以及何时使用原子更新方面提供了更大的灵活性，但代价是更加笨拙的基于反射的设置、更不方便的使用和更弱的保证。</strong></p><p>AtomicIntegerArray、AtomicLongArray和AtomicReferenceArray类进一步将原子操作支持扩展到这些类型的数组。这些类还<strong>提供了数组元素的volatile访问语义，这是普通数组不支持的。</strong></p><p>AtomicMarkableReference类将单个布尔值与引用相关联。 例如，该位可能在数据结构中使用，表示被引用的对象在逻辑上已被删除。 AtomicStampedReference类将整数值与引用相关联。 例如，这可以用于表示与一系列更新相对应的版本号。</p><p>原子类主要设计为用于实现非阻塞数据结构和相关基础结构类的构建。 compareAndSet方法不是锁定的一般替代方法。 仅当对象的关键更新仅限于单个变量时，它才适用。</p><p>原子类不是java.lang.Integer和相关类的通用替换。它们没有定义equals，hashCode和compareTo等方法（由于原子变量预期会发生变化，所以它们不适合作为哈希表键）。</p><blockquote><p>后续会出文章解析：AtomicLong、Striped64、LongAdder<br>本文的目的主要是从大体上了解atomic及其内存语义</p></blockquote><blockquote><p>JDK 12<br><a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/concurrent/atomic/package-summary.html" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/concurrent/atomic/package-summary.html</a></p></blockquote>]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Concurrent</tag>
        <tag>Atomic</tag>
      </tags>
  </entry>
  <entry>
    <title>Java JUC Atomic AtomicLong</title>
    <url>/java-juc-atomic-atomiclong.html</url>
    <content><![CDATA[<blockquote><p>基于OpenJDK 12<br>本文的目的是为后续文章解析LongAdder做一个引子，以便两者对比。</p></blockquote><a id="more"></a><p><a href="https://jiankunking.com/java-concurrent-atomic-package.html">Atomic Package解析参考（比如lazySet原理解析）</a></p><p>AtomicLong的常用方法如下：</p><ul><li>long addAndGet(long delta)：以原子方式将输入的数值与实例中的值（AtomicLong里的<br>value）相加，并返回结果。</li><li>compareAndSet(long expectedValue, long newValue)：如果输入的数值等于预期值，则以原子方<br>式将该值设置为输入的值。</li><li>long getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</li><li>void lazySet(long newValue)：最终会设置成newValue，<font color="DeepPink"><strong>使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值</strong></font>。</li><li>long getAndSet(long newValue)：以原子方式设置为newValue的值，并返回旧值。</li></ul><p>AtomicLong示例代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class AtomicLongTest &#123;</span><br><span class="line">    static AtomicLong ai = new AtomicLong(1);</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        System.out.println(ai.getAndIncrement());</span><br><span class="line">        System.out.println(ai.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td></tr></table></figure><p>那么getAndIncrement是如何实现原子操作的呢？让我们一起分析其实现原理，getAndIncrement的源码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final long getAndIncrement() &#123;</span><br><span class="line">   return U.getAndAddLong(this, VALUE, 1L);</span><br><span class="line">&#125;</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final long getAndAddLong(Object o, long offset, long delta) &#123;</span><br><span class="line">    long v;</span><br><span class="line">    do &#123;</span><br><span class="line">        v = getLongVolatile(o, offset);</span><br><span class="line">    &#125; while (!weakCompareAndSetLong(o, offset, v, v + delta));</span><br><span class="line">    return v;</span><br><span class="line">&#125;</span><br><span class="line">/** Volatile version of &#123;@link #getLong(Object, long)&#125;  */</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public native long getLongVolatile(Object o, long offset);</span><br><span class="line"></span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final boolean weakCompareAndSetLong(Object o, long offset,</span><br><span class="line">                                           long expected,</span><br><span class="line">                                           ong x) &#123;</span><br><span class="line">    return compareAndSetLong(o, offset, expected, x);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Atomically updates Java variable to &#123;@code x&#125; if it is currently</span><br><span class="line"> * holding &#123;@code expected&#125;.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;This operation has memory semantics of a &#123;@code volatile&#125; read</span><br><span class="line"> * and write.  Corresponds to C11 atomic_compare_exchange_strong.</span><br><span class="line"> *</span><br><span class="line"> * @return &#123;@code true&#125; if successful</span><br><span class="line"> */</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">public final native boolean compareAndSetLong(Object o, long offset,</span><br><span class="line">                                              long expected,</span><br><span class="line">                                              long x);</span><br></pre></td></tr></table></figure><blockquote><p>@HotSpotIntrinsicCandidate JDK的源码中，被@HotSpotIntrinsicCandidate标注的方法，在HotSpot中都有一套高效的实现，该高效实现基于CPU指令，运行时，HotSpot维护的高效实现会替代JDK的源码实现，从而获得更高的效率。</p></blockquote><p>源码getAndAddLong(Object o, long offset, long delta)中do while循环体是实现的关键所在，其逻辑是：<br>第一步先取得AtomicLong里存储的数值，<br>第二步对AtomicLong的当前数值进行加1操作，<br>第三步调用weakCompareAndSetLong方法来进行原子更新操作，该方法先检查当前数值是否等于v，等于意味着AtomicLong的值没有被其他线程修改过，则将weakCompareAndSetLong的当前数值更新成v+delta的值，如果不等于v，weakCompareAndSetLong方法会返回false，<font color="DeepPink"><strong>程序会进入do while循环重新进行</strong></font>weakCompareAndSetLong操作。</p><p><font color="DeepPink"><strong>这里隐含了一个问题，当对于共享变量（假设变量名字是a）的竞争非常激烈的时候，在当前线程读取a、改变a之间，a的值会被别的线程改变，从而导致当前线程一直重试（自旋），一直占用CPU。</strong></font></p><p><font color="DeepPink"><strong>这就引出另一个问题，对于锁抢占很激烈的时候，串行是最好的解决办法。比如使用synchronized。</strong></font></p><blockquote><p>java.util.concurrent.atomic中的原子操作基本是基于Unsafe或者VarHandle实现的。</p></blockquote><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/AtomicLong.java" target="_blank" rel="noopener">AtomicLong源码</a></p><blockquote><p>本文参考 《Java并发编程的艺术》 作者：方腾飞　魏鹏　程晓明</p></blockquote>]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Concurrent</tag>
        <tag>Atomic</tag>
        <tag>AtomicLong</tag>
      </tags>
  </entry>
  <entry>
    <title>Java JUC Atomic LongAdder</title>
    <url>/java-juc-atomic-longadder.html</url>
    <content><![CDATA[<blockquote><p>基于OpenJDK 12</p></blockquote><a id="more"></a><p>阅读本文前，推荐先阅读以下两篇文章，以便能更好的对比理解：</p><ul><li><a href="https://jiankunking.com/java-concurrent-atomic-package.html">译-Java-Concurrent-Atomic-Package-详解</a></li><li><a href="https://jiankunking.com/java-juc-atomic-atomiclong.html">Java-JUC-Atomic-AtomicLong</a></li></ul><p>LongAdder是JDK 1.8 新增的原子类，基于Striped64实现。 从官方文档看，LongAdder在高并发的场景下会比AtomicLong 具有更好的性能，代价是消耗更多的内存空间：</p><blockquote><p>This class is usually preferable to AtomicLong when multiple threads update a common sum that is used for purposes such as collecting statistics, not for fine-grained synchronization control. <font color="DeepPink"><strong>Under low update contention, the two classes have similar characteristics. But under high contention, expected throughput of this class is significantly higher, at the expense of higher space consumption.</strong></font></p></blockquote><p>那么LongAdder是怎么实现的？</p><p>先看一下LongAdder的类图：<br><img data-src="/images/java-juc-atomic-longadder/LongAdder%E7%B1%BB%E5%9B%BE.png" alt></p><p>基类Number，Number是一个抽象类其中没有任何逻辑，该类是byte、double、float、int、long、short的基类。</p><h1>Striped64</h1><h2 id="设计思想">设计思想</h2><p>该部分翻译自Striped64源码注释，可以略过，概括起来就是：</p><blockquote><p>分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p></blockquote><hr><p>从Striped64类注释可以看到：</p><blockquote><p>Striped64是package内使用的，对于在64位元素上动态分片提供统一实现（感觉有点像：AbstractQueuedSynchronizer）<br>Striped64继承了Number类，这也就是说具体实现的子类也必须实现相关的内容</p></blockquote><p>该类维护一个原子更新变量的延迟初始化表，以及一个额外的“base”字段。表的大小是2的幂。索引使用掩码下的每个线程的hash code。这个类中的几乎所有声明都是package私有的，由子类直接访问。</p><p>表格内的元素是Cell类，Cell类是一个为了减少缓存争用而填充的AtomicLong的变种。填充对于大多数原子来说是多余的，因为它们通常不规则地分散在内存中，因此彼此之间不会有太多的干扰。但是，驻留在数组中的原子对象往往是彼此相邻的，因此在没有这种预防措施的情况下，最常见的情况是共享高速缓存线(这对性能有很大的负面影响)。</p><p>在某种程度上，因为Cell类相对较大，只有他们真正被需要的时候，我们才创建。<font color="DeepPink"><strong>如果没有竞争，那么所有的更新操作将对base字段实现。当发生第一次争用（也就是说如果第一次对base字段的CAS操作失败），初始化为大小是2的表格。当进一步的争用发生的时候,表的大小会加倍，直到达到等于大于cpu的数量。表在未使用之前一直为null。</strong></font></p><p>利用一个自旋锁（cellsBusy）来初始化和调整表的大小，以及用新Cells填充slots。这个地方没有必要使用阻塞锁，如果锁不可达，线程可以尝试其他的slots，或者尝试base字段。在这些重试期间，竞争加剧，但是降低了局部性，这仍然比阻塞锁来得好。</p><p>通过ThreadLocalRandom维护的Thread.probe字段用作每个线程的哈希码。我们让它们保持未初始化（为零）(如果它们以这种方式出现)，直到它们在插槽0竞争。出现竞争后初始化为通常不会和其他的的值冲突的值，比如线程的哈希码。在执行更新时发生CAS操作失败意味着出现了争用或者表碰撞，或两者都有。在发生冲突时，如果表的大小小于容量，那么它的大小将加倍，除非其他线程持有锁。如果哈希后的slot为空，并且锁可用，则创建一个新单元格。如果存在了那么会进行CAS尝试。通过双重哈希进行重试，利用一个辅助哈希（Marsaglia XorShift随机数算法）来尝试寻找一个空闲的slot。</p><p><font color="DeepPink"><strong>表的大小是有上限的，因为当线程多于CPU时，假设每个线程都绑定到一个CPU，就会有一个完美的散列函数将线程映射到插槽，从而消除冲突。当我们达到容量时，我们通过随机改变冲突线程的哈希代码来搜索这个映射。因为搜索是随机的，冲突只有通过CAS失败才知道，收敛可能会很慢，而且因为线程通常不会永远绑定到CPU，所以根本不会发生。然而，尽管有这些限制，在这些情况下观察到的竞争率通常很低。</strong></font></p><p><font color="DeepPink"><strong>Cell可能会出现不可用的情况，包括进行哈希的线程终止，或者由于table扩容导致线程哈希不正确。我们不尝试检测或删除这样的单元格，假设对于长时间运行的实例，争用会再次发生，因此最终将再次需要这些单元格;而对于短时间运行的实例，花费时间去销毁又没有什么必要。</strong></font></p><hr><h2 id="Cell类">Cell类</h2><p>Atomiclong的变体，仅支持原始访问和CAS。</p><blockquote><p>Cell类被注解@jdk.internal.vm.annotation.Contended修饰。<br>Contended的作用（详细信息参见：<a href="http://openjdk.java.net/jeps/142" target="_blank" rel="noopener">JEP 142</a>）：<br>Define a way to specify that one or more fields in an object are likely to be highly contended across processor cores so that the VM can arrange for them not to share cache lines with other fields, or other objects, that are likely to be independently accessed.</p></blockquote><h2 id="示意图">示意图</h2><p><img data-src="/images/java-juc-atomic-longadder/%E7%83%AD%E7%82%B9%E5%88%86%E7%A6%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><h2 id="具体实现">具体实现</h2><p>Striped64的核心方法是longAccumulate、doubleAccumulate，两者类似，下面主要看一下longAccumulate，<strong>对于这种代码，个人建议是理解思路即可，毕竟咱们又不是过来修改JDK的，如果真的要修改了或者有类似的需求了，再回来细看即可。</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//x  元素</span><br><span class="line">//fn  更新函数，如果是add可以为null（这个约定避免了longadder中定义额外的变量或者函数）</span><br><span class="line">//wasUncontended 如果CAS在调用之前失败了，这个值为false</span><br><span class="line">final void longAccumulate(long x, LongBinaryOperator fn,</span><br><span class="line">                          boolean wasUncontended) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    //获取当前线程的probe值，如果为0，则需要初始化该线程的probe值</span><br><span class="line">    if ((h = getProbe()) == 0) &#123;</span><br><span class="line">    	ThreadLocalRandom.current(); // force initialization</span><br><span class="line">        h = getProbe();</span><br><span class="line">        wasUncontended = true;</span><br><span class="line">    &#125;</span><br><span class="line">    boolean collide = false;  // True if last slot nonempty</span><br><span class="line">    done: for (;;) &#123;</span><br><span class="line">        Cell[] cs; Cell c; int n; long v;</span><br><span class="line">        //Cells不为空，进行操作</span><br><span class="line">        if ((cs = cells) != null &amp;&amp; (n = cs.length) &gt; 0) &#123;</span><br><span class="line">            //通过（hashCode &amp; (length - 1)）这种算法来实现取模 有种看到HashMap代码的感觉</span><br><span class="line">            //如果当前位置为null说明需要初始化</span><br><span class="line">            if ((c = cs[(n - 1) &amp; h]) == null) &#123;</span><br><span class="line">                //判断锁状态</span><br><span class="line">                if (cellsBusy == 0) &#123;       // Try to attach new Cell</span><br><span class="line">                    Cell r = new Cell(x);   // Optimistically create</span><br><span class="line">                    //再次判断锁状态，同时获取锁</span><br><span class="line">                    if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">                        try &#123;               // Recheck under lock</span><br><span class="line">                            Cell[] rs; int m, j;</span><br><span class="line">                            if ((rs = cells) != null &amp;&amp;</span><br><span class="line">                                (m = rs.length) &gt; 0 &amp;&amp;</span><br><span class="line">                                rs[j = (m - 1) &amp; h] == null) &#123;</span><br><span class="line">                                rs[j] = r;</span><br><span class="line">                                //创建成功跳出</span><br><span class="line">                                break done;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; finally &#123;</span><br><span class="line">                            //释放锁</span><br><span class="line">                            cellsBusy = 0;</span><br><span class="line">                        &#125;</span><br><span class="line">                        continue;           // Slot is now non-empty</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                collide = false;</span><br><span class="line">            &#125;</span><br><span class="line">            //运行到此说明cell的对应位置上已经有相应的Cell了，</span><br><span class="line">            //不需要初始化了</span><br><span class="line">            //CAS操作已经失败了，出现了竞争</span><br><span class="line">            else if (!wasUncontended)       // CAS already known to fail</span><br><span class="line">                wasUncontended = true;      // Continue after rehash</span><br><span class="line">            //这里尝试将x值加到a的value上 </span><br><span class="line">            else if (c.cas(v = c.value,</span><br><span class="line">                           (fn == null) ? v + x : fn.applyAsLong(v, x)))</span><br><span class="line">                //如果尝试成功，跳出循环，方法退出</span><br><span class="line">                break;</span><br><span class="line">            //cell数组最大为cpu的数量，</span><br><span class="line">            //cells != as表明cells数组已经被更新了 </span><br><span class="line">            //标记为最大状态或者说是过期状态</span><br><span class="line">            else if (n &gt;= NCPU || cells != cs)</span><br><span class="line">                collide = false;            // At max size or stale</span><br><span class="line">            else if (!collide)</span><br><span class="line">                collide = true;</span><br><span class="line">            //扩容 当前容量 * 2</span><br><span class="line">            else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    if (cells == cs)        // Expand table unless stale</span><br><span class="line">                        cells = Arrays.copyOf(cs, n &lt;&lt; 1);</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    cellsBusy = 0;</span><br><span class="line">                &#125;</span><br><span class="line">                collide = false;</span><br><span class="line">                continue;                   // Retry with expanded table</span><br><span class="line">            &#125;</span><br><span class="line">            h = advanceProbe(h);</span><br><span class="line">        &#125;</span><br><span class="line">        //尝试获取锁之后扩大Cells</span><br><span class="line">        else if (cellsBusy == 0 &amp;&amp; cells == cs &amp;&amp; casCellsBusy()) &#123;</span><br><span class="line">            try &#123;                           // Initialize table</span><br><span class="line">                if (cells == cs) &#123;</span><br><span class="line">                    //初始化cell表，初始容量为2。 </span><br><span class="line">                    Cell[] rs = new Cell[2];</span><br><span class="line">                    rs[h &amp; 1] = new Cell(x);</span><br><span class="line">                    cells = rs;</span><br><span class="line">                    break done;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                //释放cellsBusy锁</span><br><span class="line">                cellsBusy = 0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //如果创建cell表由于竞争导致失败，尝试将x累加到base上</span><br><span class="line">        // Fall back on using base</span><br><span class="line">        else if (casBase(v = base,</span><br><span class="line">                         (fn == null) ? v + x : fn.applyAsLong(v, x)))</span><br><span class="line">            break done;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * CASes the cellsBusy field from 0 to 1 to acquire lock.</span><br><span class="line"> */</span><br><span class="line">final boolean casCellsBusy() &#123;</span><br><span class="line">    return CELLSBUSY.compareAndSet(this, 0, 1);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * CASes the base field.</span><br><span class="line"> */</span><br><span class="line">final boolean casBase(long cmp, long val) &#123;</span><br><span class="line">    return BASE.compareAndSet(this, cmp, val);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一段的核心是这样的：</p><ul><li>longAccumulate会根据当前线程来计算一个哈希值，然后根据(hashCode &amp; (length - 1))取模，以定位到该线程被分散到的Cell数组中的位置</li><li>如果Cell数组还没有被创建，那么就去获取cellBusy这个锁（相当于锁，但是更为轻量级），如果获取成功，则初始化Cell数组，初始容量为2，初始化完成之后将x包装成一个Cell，哈希计算之后分散到相应的index上。如果获取cellBusy失败，那么会试图将x累计到base上，更新失败会重新尝试直到成功。</li><li>如果Cell数组已经被初始化过了，那么就根据线程的哈希值分散到一个Cell数组元素上，获取这个位置上的Cell并且赋值给变量a，如果a为null，说明该位置还没有被初始化，那么就初始化，当然在初始化之前需要竞争cellBusy变量。</li><li>如果Cell数组的大小已经最大了（大于等于CPU的数量），那么就需要重新计算哈希，来重新分散当前线程到另外一个Cell位置上再走一遍该方法的逻辑，否则就需要对Cell数组进行扩容，然后将原来的计数内容迁移过去。由于Cell里面保存的是计数值，所以扩容后没有必要做其他处理，直接根据index将旧的Cell数组内容复制到新的Cell数组中。</li></ul><h1>LongAdder</h1><blockquote><p>LongAdder的基本思路就是分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p></blockquote><h2 id="说明">说明</h2><p>保持一个或者多个变量，初始值设置为零用于求和。当更新出现多个线程竞争时，变量集合动态增长以减少争用。最后当需要求和的时候或者说需要这个Long型的值时，可以通过把当前这些变量求和，合并后得出最终的和。</p><p><font color="DeepPink"><strong>LongAdder在一些高并发场景下表现要比AtomicLong好，比如多个线程同时更新一个求和的变量，比如统计集合的数量，但是不能用于细粒度同步控制，换句话说这个是可能有误差的（因为更新与读取是并行的）。在低并发场景场景下LongAdder和AtomicLong的性能表现没什么差别，但是当高并发竞争的时候，这个类将具备更好的吞吐性能，但是相应的也会耗费相当的空间。</strong></font></p><p>LongAdder继承了Number抽象类，但是并没有实现一些方法例如: equals、hashCode、compareTo，因为LongAdder实例的预期用途是进行一些比较频繁的变化，所以也不适合作为集合的key。</p><h2 id="具体实现-v2">具体实现</h2><p>看一下LongAdder有哪些方法：<br><img data-src="/images/java-juc-atomic-longadder/LongAdder%E5%87%BD%E6%95%B0%E5%88%97%E8%A1%A8.png" alt></p><p>下面主要解析LongAdder increment、sum方法，先看一下源码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Equivalent to &#123;@code add(1)&#125;.</span><br><span class="line"> */</span><br><span class="line">public void increment() &#123;</span><br><span class="line">	add(1L);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* Adds the given value.</span><br><span class="line">*</span><br><span class="line">* @param x the value to add</span><br><span class="line">*/</span><br><span class="line">public void add(long x) &#123;</span><br><span class="line">    Cell[] cs; long b, v; int m; Cell c;</span><br><span class="line">    if ((cs = cells) != null || !casBase(b = base, b + x)) &#123;</span><br><span class="line">    	//到了这里 表明cs不为null or 线程有并发冲突，导致caseBase失败</span><br><span class="line">        boolean uncontended = true;</span><br><span class="line">        if (cs == null || // cells 为null</span><br><span class="line">            (m = cs.length - 1) &lt; 0 || // cells 不为null 但只有一个元素</span><br><span class="line">            (c = cs[getProbe() &amp; m]) == null || //哈希取模 对应位置元素为null</span><br><span class="line">            !(uncontended = c.cas(v = c.value, v + x))) //cas 替换失败（并发竞争）</span><br><span class="line">            longAccumulate(x, null, uncontended);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">* CASes the base field (Striped64类中的方法)</span><br><span class="line">*/</span><br><span class="line">final boolean casBase(long cmp, long val) &#123;</span><br><span class="line">    return BASE.compareAndSet(this, cmp, val);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//当在sum的过程中，有可能别的线程正在操作cells（因为没有加锁）</span><br><span class="line">//sum取的值，不一定准确</span><br><span class="line">public long sum() &#123;</span><br><span class="line">     Cell[] cs = cells;</span><br><span class="line">     long sum = base;</span><br><span class="line">     if (cs != null) &#123;</span><br><span class="line">        for (Cell c : cs)</span><br><span class="line">            if (c != null)</span><br><span class="line">                sum += c.value;</span><br><span class="line">    &#125;</span><br><span class="line">    return sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="LongAdder-vs-AtomicLong-Performance">LongAdder vs AtomicLong Performance</h2><p><a href="http://blog.palominolabs.com/2014/02/10/java-8-performance-improvements-longadder-vs-atomiclong/" target="_blank" rel="noopener">Java 8 Performance Improvements: LongAdder vs AtomicLong</a></p><h1>对比LongAccumulator</h1><p>LongAdder类可以看做是LongAccumulator的一个特例，LongAccumulator提供了比LongAdder更强大、灵活的功能。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Creates a new instance using the given accumulator function</span><br><span class="line"> * and identity element.</span><br><span class="line"> * @param accumulatorFunction a side-effect-free function of two arguments</span><br><span class="line"> * @param identity identity (initial value) for the accumulator function</span><br><span class="line">*/</span><br><span class="line">public LongAccumulator(LongBinaryOperator accumulatorFunction,</span><br><span class="line">                           long identity) &#123;</span><br><span class="line">    this.function = accumulatorFunction;</span><br><span class="line">    base = this.identity = identity;</span><br><span class="line">&#125;</span><br><span class="line">@FunctionalInterface</span><br><span class="line">public interface LongBinaryOperator &#123;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Applies this operator to the given operands.</span><br><span class="line"> *</span><br><span class="line"> * @param left the first operand</span><br><span class="line"> * @param right the second operand</span><br><span class="line"> * @return the operator result</span><br><span class="line">*/</span><br><span class="line">long applyAsLong(long left, long right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构造函数其中accumulatorFunction一个双目运算接口，根据输入的两个参数返回一个计算值，identity则是LongAccumulator累加器的初始值。</p><p>accumulatorFunction主要用于Striped64 longAccumulate中使用，如果fn==null，则默认是相加，否则会调用fn.applyAsLong(v, x)</p><blockquote><p>LongAccumulator相比于LongAdder，可以为累加器提供非0的初始值，而LongAdder只能提供默认的0值。<br>另外，LongAccumulator还可以指定累加规则，比如累加或者相乘，只需要在构造LongAccumulator时，传入自定义的双目运算器即可，后者则内置累加规则。</p></blockquote><h1>Reference</h1><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/LongAdder.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/java/util/concurrent/atomic/LongAdder.java</a></p><p><a href="https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/jdk/internal/vm/annotation/Contended.java" target="_blank" rel="noopener">https://github.com/jiankunking/openjdk12/blob/master/src/java.base/share/classes/jdk/internal/vm/annotation/Contended.java</a></p><p><a href="https://www.jianshu.com/p/9a7de5644dd4" target="_blank" rel="noopener">https://www.jianshu.com/p/9a7de5644dd4</a></p><p><a href="http://openjdk.java.net/jeps/142" target="_blank" rel="noopener">http://openjdk.java.net/jeps/142</a></p><p><a href="http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html</a></p>]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Concurrent</tag>
        <tag>Atomic</tag>
        <tag>LongAdder</tag>
      </tags>
  </entry>
  <entry>
    <title>JRockit权威指南深入理解JVM 笔记</title>
    <url>/java-jrockit.html</url>
    <content><![CDATA[<p>本文整理自：《JRockit权威指南深入理解JVM》</p><p>作者：Marcus Hirt , Marcus Lagergren</p><p>出版时间：2018-12-10</p><a id="more"></a><h1>起步</h1><h2 id="将应用程序迁移到JRockit">将应用程序迁移到JRockit</h2><h3 id="命令行选项">命令行选项</h3><p>在<font color="DeepPink"><strong>JRockit JVM中,主要有3类命令行选项,分别是系统属性、标准选项(以-X开头)和非标准选项(以-XX开头)。</strong></font></p><p>1、系统属性</p><p>设置JVM启动参数的方式有多种。以-D开头的参数会作为系统属性使用,这些属性可以为Java类库(如RMI等)提供相关的配置信息。例如,在启动的时候,如果设置了-Dcom.Rockin.mc.debug=true参数,则JRockit Mission Control会打印出调试信息。不过,R28之后的JRockit JVM版本废弃了很多之前使用过的系统属性,转而采用非标准选项和类似 HotSpot中虚拟机标志(VM flag)的方式设置相关选项。</p><p>2、标准选项</p><p>以-X开头的选项是大部分JVM厂商都支持的通用设置。例如,用于设置堆大小最大值的选项-Xmx在包括 JRockit在内的大部分JVM中都是相同的。当然,也存在例外,如JRockit中的选项-Xverbose会打印出可选的子模块日志信息,而在 HotSpot中,类似的(但实际上有更多的限制)选项是-verbose。</p><p>3、非标准选项</p><p>以-XX开头的命令行选项是各个JVM厂商自己定制的。这些选项可能会在将来的某个版本中被废弃或修改。如果JVM的参数配置中包含了以-XX开头的命令行选项,则在将Java应用程序从一种JVM迁移到另一种时,应该在启动M之前去除这些非标准选项确定了新的VM选项后才可以启动Java应用程序。</p><h1>自适应代码生成</h1><h2 id="Java虚拟机">Java虚拟机</h2><h3 id="字节码格式">字节码格式</h3><p><a href="https://github.com/jiankunking/JVM-opcode" target="_blank" rel="noopener">Opcodes for the Java Virtual Machine</a></p><h4 id="常量池">常量池</h4><p>程序,包含数据和代码两部分,其中数据作为操作数使用。对于字节码程序来说,如果操作数非常小或者很常用(如常量0),则这些操作数是直接内嵌在字节码指令中的。</p><p>较大块的数据,例如常量字符串或比较大的数字,是存储在class文件开始部分的常量池(constant pool)中的。当使用这类数据作为操作数时,使用的是常量池中数据的索引位置,而不是实际数据本身。</p><p>此外,<font color="DeepPink"><strong>Java程序中的方法、属性和类的元数据等也作为clas文件的组成部分,存储在常量池中。</strong></font></p><h2 id="自适应代码生成">自适应代码生成</h2><h3 id="优化动态程序">优化动态程序</h3><p>在汇编代码中,方法调用是通过call指令完成的。不同平台上call指令的具体形式不尽相同,不同类型的call指令,其具体格式也不尽相同。</p><p><font color="DeepPink"><strong>在面向对象的语言中,虚拟方法分派通常被编译为对分派表(dispatch table)中地址的间接调用(indirect call,即需要从内存中读取真正的调用地址)。这是因为,根据不同的类继承结构分派虚拟调用时可能会有多个接收者。每个类中都有一个分派表,其中包含了其虚拟调用的接收者信息。静态方法和确知只有一个接收者的虚拟方法可以被编译为对固定调用地址的直接调用(direct call)。一般来说,这可以大大加快执行速度。</strong></font><br><img data-src="/images/java-jrockit/%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E8%99%9A%E6%8B%9F%E8%B0%83%E7%94%A8.png" alt></p><p>假设应用程序是使用C++开发的,对代码生成器来说,在编译时已经可以获取到程序的所有结构性信息。例如,由于在程序运行过程中,代码不会发生变化,所以在编译时就可以从代码中判断出,某个虚拟方法是否只有一种实现。正因如此,编译器不仅不需要因为废弃代码而记录额外的信息,还可以将那些只有一种实现的虚拟方法转化为静态调用。</p><p>假如应用程序是使用Java开发的,起初某个虚拟方法可能只有一种实现,但Java允许在程序运行过程中修改方法实现。当JIT编译器需要编译某个虚拟方法时,更喜欢的是那些永远只存在一种实现的,这样编译器就可以像前面提到的C++编译器一样做很多优化,例如将虚拟调用转化为直接调用。但是,由于Java允许在程序运行期间修改代码,如果某个方法没有声明final修饰符,那它就有可能在运行期间被修改,即使它看起来几乎不可能有其他实现,编译器也不能将之优化为直接调用。</p><p>在Java世界中,有一些场景现在看起来一切正常,编译器可以大力优化代码,但是如果某天程序发生了改变的话,就需要将相关的优化全部撤销。对于Java来说,为了能够媲美C++程序的执行速度,就需要一些特殊的优化措施。</p><p>JVM使用的策略就是“赌”。JVM代码生成策略的假设条件是,正在运行的代码永远不变。事实上,大部分时间里确实如此。但如果正在运行的代码发生了变化,违反了代码优化的假设条件,就会触发其簿记系统(bookkeeping system)的回调功能。此时,基于原先假设条件生成的代码就需要被废弃掉,重新生成,例如为已经转化为直接调用的虚拟调用重新生成相关代码。因此,“赌输”的代价是很大的,但如果“赌赢”的概率非常高,则从中获得的性能提升就会非常大,值得一试。</p><p>一般来说,JVM和JIT编译器所做的典型假设包括以下几点：</p><ul><li>虚拟方法不会被覆盖。由于某个虚拟方法只存在一种实现,就可以将之优化为一个直接调用。</li><li>浮点数的值永远不会是NaN。大部分情况下,可以使用硬件指令来替换对本地浮点数函数库的调用。</li><li>某些try语句块中几乎不会抛出异常。因此,可以将catch语句块中的代码作为冷方法对待。</li><li>对于大多数三角函数来说,硬件指令fsin都能够达到精度要求。如果真的达不到,就抛出异常,调用本地浮点数函数库完成计算。</li><li>锁竞争并不会太激烈,初期可以使用自旋锁(spinlock)替代。</li><li>锁可能会周期性地被同一个线程获取和释放,所以,可以将对锁的重复获取操作和重复释放操作直接省略掉。</li></ul><h2 id="深入JIT编译器">深入JIT编译器</h2><h3 id="优化字节码">优化字节码</h3><blockquote><p>有些时候,对Java源代码做优化会适得其反。绝大部分写出可读性很差的代码的人都声称是为了优化性能,其实就是照着一些基准测试报告的结论写代码,而这些性能测试往往只涉及了字节码解释执行,没有经过JIT编译器优化,所以并不能代表应用程序在运行时的真实表现。例如,某个服务器端应用程序中包含了大量对数组元素的迭代访问操作,程序员参考了那些报告中的结论,没有设置循环条件,而是写一个无限for循环,置于try语句块中,并在catch语句块中捕获ArrayIndexOutOfBoundsException异常。这种糟糕的写法不仅使代码可读性极差,而且一旦运行时对之优化编译的话,其执行效率反而比普通循环方式低得多。原因在于,JVM的基本假设之一就是“异常是很少发生的”。基于这种假设,JVM会做一些相关优化,所以当真的发生异常时,处理成本就很高。</p></blockquote><h2 id="代码流水线">代码流水线</h2><h3 id="代码生成概述">代码生成概述</h3><blockquote><p>在生成优化代码时,如何分配寄存器非常重要。编译器教材上都将寄存器分配问题作为图的着色问题处理,这是因为同时用到的两个变量不能共享同一个寄存器,从这点上讲,与着色问题相同。同时使用的多个变量可以用图中相连接的节点来表示,这样,寄存器分配问题就可以被抽象为“如何为图中的节点着色,才能使相连节点有不同的颜色”。这里可用颜色的数量等于指定平台上可用寄存器的数量。不过,遗憾的是,从计算复杂性上讲,着色问题是NP-hard的,也就是说现在还没有一个高效的算法(指可以在多项式时间内完成计算)能解决这个问题。但是,着色问题可以在线性对数时间内给出近似解,因此大多数编译器都使用着色算法的某个变种来处理寄存器分配问题。</p></blockquote><h1>自适应内存管理</h1><h2 id="堆管理基础">堆管理基础</h2><h3 id="对象的分配与释放">对象的分配与释放</h3><p><font color="DeepPink"><strong>一般来说,为对象分配内存时,并不会直接在堆上划分内存,而是先在线程局部缓冲(thread local buffer)或其他类似的结构中找地方放置对象,然后随着应用程序的运行、新对象的不断分配,垃圾回收逐次执行,这些对象可能最终会被提升到堆中保存,也有可能会当作垃圾被释放掉。</strong></font></p><p>为了能够在堆中给新创建的对象找一个合适的位置,内存管理系统必须知道堆中有哪些地方是空闲的,即还没有存活对象占用。内存管理系统使用空闲列表(free list)—串联起内存中可用内存块的链表,来管理内存中可用的空闲区域,并按照某个维度的优先级排序。</p><p>在空闲列表中搜索足够存储新对象的空闲块时,可以选择大小最适合的空闲块,也可以选择第一个放得下的空闲块。这其中会用到几种不同的算法去实现,各有优劣,后文会详细讨论。</p><h2 id="垃圾回收算法">垃圾回收算法</h2><p><font color="DeepPink"><strong>在后文中,根集合(root set)专指上述搜索算法的初始输入集合,即开始执行引用跟踪时的存活对象集合。一般情况下,根集合中包括了因为执行垃圾回收而暂停的应用程序的当前栈帧中所有的对象,包含了可以从当前线程上下文的用户栈和寄存器中能得到的所有信息。此外,根集合中还包含全局数据,例如类的静态属性。简单来说就是,根集合中包含了所有无须跟踪引用就可以得到的对象。</strong></font></p><p>Java使用的是准确式垃圾回收器(exact garbage collector),可以将对象指针类型数据和其他类型的数据区分开,只需要将元数据信息告知垃圾回收器即可,这些元数据信息,一般可以从Java方法的代码中得到。</p><p>近些年,使用信号来暂停线程的方式受到颇多争议。实践发现,在某些操作系统上,尤以Linux为例,应用程序对信号的使用和测试很不到位,还有一些第三方的本地库不遵守信号约定,导致信号冲突等事件的发生。因此,与信号相关的外部依赖已经不再可靠。</p><h3 id="分代垃圾回收">分代垃圾回收</h3><p>事实上,将堆划分为两个或多个称为代(generation)的空间,并分别存放具有不同长度生命周期的对象,可以提升垃圾回收的执行效率。<font color="DeepPink"><strong>在JRockit中,新创建(young)的对象存放在称为新生代(nursery)的空间中,一般来说,它的大小会比老年代(old collections)小很多,随着垃圾回收的重复执行,生命周期较长的对象会被提升(promote)到老年代中。</strong></font>因此,新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生,分别用于对各自空间中的对象执行垃圾回收。</p><p>新生代垃圾回收的速度比老年代快几个数量级,即使新生代垃圾回收的频率更高,执行效率也仍然比老年代垃圾回收强,这是因为大多数对象的生命周期都很短,根本无须提升到老年代。理想情况下,新生代垃圾回收可以大大提升系统的吞吐量,并消除潜在的内存碎片。</p><h4 id="写屏障">写屏障</h4><p>在实现分代式垃圾回收时,大部分JVM都是用名为写屏障(write barrier)的技术来记录执行垃圾回收时需要遍历堆的哪些部分。当对象A指向对象B时,即对象B成为对象A的属性的值时,就会触发写屏障,在完成属性域赋值后执行一些辅助操作。</p><p>写屏障的传统实现方式是将堆划分成多个小的连续空间(例如每块512字节),每块空间称为卡片(card),于是,堆被映射为一个粗粒度的卡表(card table)。当Java应用程序将某个对象赋值给对象引用时,会通过写屏障设置脏标志位(dirty bit),将该对象所在的卡片标记为脏。</p><p>这样,遍历从老年代指向新生代的引用时间得以缩短,垃圾回收器在做新生代垃圾回收时只需要检查老年代中被标记为脏的卡片所对应的内存区域即可。</p><h3 id="JRockit中的垃圾回收">JRockit中的垃圾回收</h3><h4 id="老年代垃圾回收">老年代垃圾回收</h4><p>JRockit不仅将卡表应用于分代式垃圾回收,还用在并发标记阶段结束时的清理工作,避免搜索整个存活对象图。这是因为JRockit需要找出在执行并发标记操作时,应用程序又创建了哪些对象。修改引用关系时通过写屏障可以更新卡表,存活对象图中的每个区域使用卡表中的一个卡片表示,卡片的状态可以是干净或者脏,有新对象创建或者对象引用关系修改了的卡片会被标记为脏。在并发标记阶段结束时,垃圾回收器只需要检查那些标记为脏的卡片所对应的堆中区域即可,这样就可以找到在并发标记期间新创建的和被更新过引用关系的对象。</p><h2 id="性能与伸缩性">性能与伸缩性</h2><h3 id="线程局部分配">线程局部分配</h3><p><font color="DeepPink"><strong>在JRockit中,使用了名为线程局部分配(thread local allocation)的技术来大幅加速对象的分配过程。正常情况下,在线程内的缓冲区中为对象分配内存要比直接在需要同步操作的堆上分配内存快得多。垃圾回收器在堆上直接分配内存时是需要对整个堆加锁的,对于多线程竞争激烈的应用程序来说,这将会是一场灾难。</strong></font>因此,如果每个Java线程能够有一块局部对象缓冲区那么绝大部分的对象分配操作只需要移动一下指针即可完成,在大多数硬件平台上,只需要一条汇编指令就行了。这块转为分配对象而保留的区域,就称为线程局部缓冲区(thread local area,TLA)。</p><p>为了更好地利用缓存,达到更高的性能,一般情况下,TLA的大小介于16KB到128KB之间,当然,也可以通过命令行参数显式指定。<font color="DeepPink"><strong>当TLA被填满时,垃圾回收器会将TLA中的内容提升到堆中。因此,可以将TLA看作是线程中的新生代内存空间</strong></font>。</p><p>当Java源代码中有new操作符,并且JIT编译器对内存分配执行高级优化之后,内存分配的伪代码如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">object allocateNewobject(Class objectclass)&#123;</span><br><span class="line">	Thread current getcurrentThread():</span><br><span class="line">	int objectSize=alignedSize(objectclass)</span><br><span class="line">	if(current.nextTLAOffset+objectSize&gt; TLA_SIZE)&#123;</span><br><span class="line">		current.promoteTLAToHeap();//慢,而且是同步操作</span><br><span class="line">		current.nextTLAOffset=0;</span><br><span class="line">	&#125;</span><br><span class="line">	Object ptr= current.TLAStart+current.nextTLAOffset:</span><br><span class="line">	current.nextTLAOffset + objectSize;</span><br><span class="line">	return ptr:	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>为了说明内存分配问題,在上面的伪代码中省略了很多其他关联操作。例如如果待分配的对象非常大,超过了某个阈值,或对象太大导致无法存放在TLA中,则会直接在堆中为对象分配内存。</p></blockquote><h3 id="NUMA架构">NUMA架构</h3><p>NUMA(non-uniform memory access,非统一内存访问模型)架构的出现为垃圾回收带来了更多挑战。<font color="DeepPink"><strong>在NUMA架构下,不同的处理器核心通常访问各自的内存地址空间,这是为了避免因多个CPU核心访问同一内存地址造成的总线延迟。</strong></font>每个CPU核心都配有专用的内存和总线，因此CPU核心在访问其专有内存时速度很快,而要访问相邻CPU核心的内存时就会相对慢些,CPU核心相距越远,访问速度越慢(也依赖于具体配置)传统上,多核CPU是按照UMA(uniform memory access,统一内存访问模型)架构运行的,所有的CPU核心按照统一的模式无差别地访问所有内存。</p><p>为了更好地利用NUMA架构,垃圾回收器线程的组织结构应该做相应的调整。如果某个CPU核心正在运行标记线程,那么该线程所要访问的那部分堆内存最好能够放置在该CPU的专有内存中,这样才能发挥NUMA架构的最大威力。在最坏情况下,如果标记线程所要访问的对象位于其他NUMA节点的专有内存中,这时垃圾回收器通常需要一个启发式对象移动算法。这是为了保证使用时间上相近的对象在存储位置上也能相近,如果这个算法能够正确工作,还是可以带来不小的性能提升的。这里所面临的主要问题是如何避免对象在不同NUMA节点的专有内存中重复移动。理论上,自适应运行时系统应该可以很好地处理这个问题。</p><h3 id="大内存页">大内存页</h3><p>内存分配是通过操作系统及其所使用的页表完成的。操作系统将物理内存划分成多个页来管理,从操作系统层面讲,页是实际分配内存的最小单位。传统上,页的大小是以4KB为基本单位划分的,页操作对进程来说是透明的,进程所使用的是虚拟地址空间,并非真正的物理地址。为了便于将虚拟页面转换为实际的物理内存地址,可使用名为旁路转换缓冲(translation lookaside buffer,TLB)的缓存来加速地址的转换操作。从实现上看,如果页面的容量非常小的话,会导致频繁出现旁路转换缓冲丢失的情况。</p><p>修复这个问题的一种方法就是将页面的容量调大几个数量级,例如以MB为基本单位。现代操作系统普遍倾向于支持这种大内存页机制。</p><p>很明显,当多个进程分别在各自的寻址空间中分配内存,而页面的容量又比较大时,随着使用的页面数量越来越多,碎片化的问题就愈发严重,像进程要分配的内存比页面容量稍微大一点的情况,就会浪费很多存储空间。对于在进程内自己管理内存分配回收、并有大量内存空间可用的运行时来说,这不算什么问题,因为运行时可以通过抽象出不同大小的虚拟页面来解决。</p><blockquote><p>通常情况下,对于那些内存分配和回收频繁的应用程序来说,使用大内存页可以使系统的整体性能至少提升10%。 JRockit对大内存页有很好的支持。</p></blockquote><h2 id="近实时垃圾回收">近实时垃圾回收</h2><h3 id="JRockit-Real-Time">JRockit Real Time</h3><p><font color="DeepPink"><strong>低延迟的代价是垃圾回收整体时间的延长</strong></font>。相比于并行垃圾回收,在程序运行的同时并发垃圾回收的难度更大,而频繁中断垃圾回收则可能带来更多的麻烦。事实上,这并非什么大问题,因为大多数使用JRockit Real Time的<font color="DeepPink"><strong>用户更关心系统的可预测性,而不是减少垃圾回收的总体时间。大多数用户认为暂停时间的突然增长比垃圾回收总体时间的延长更具危害性</strong></font>。</p><h4 id="软实时的有效性">软实时的有效性</h4><p>软实时是JRockit Real Time的核心机制。但<font color="DeepPink"><strong>非确定性系统如何提供指定程度的确定性,例如像垃圾回收器这样的系统如何保证应用程序的暂停时间不会超过某个阈值?严格来说,无法提供这样的保证</strong></font>,但由于这样的极端案例很少,所以也就无关紧要了。</p><p>当然,没有什么万全之策,确实存在无法保证暂停时间的场景。但实践证明,对于那些堆中存活对象约占30%-50%的应用程序来说, JRockit Real Time的表现可以满足服务需要,而且随着JRockit Real Time各个版本的发行,30%-50%这个阈值在不断提升,可支持的暂停时间阈值则不断降低。</p><h4 id="工作原理">工作原理</h4><ul><li>高效的并行执行</li><li>细分垃圾回收过程,将之变成几个可回滚、可中断的子任务(work packet)</li><li>高效的启发式算法</li></ul><p><font color="DeepPink"><strong>事实上,实现低延迟的关键仍是尽可能多让Java应用程序运行,保持堆的使用率和碎片化程度在一个较低的水平</strong></font>。在这一点上, JRockit Real Time使用的是贪心策略,即尽可能推迟STW式的垃圾回收操作,希望问题能够由应用程序自身解决,或者能够减少不得不执行STW式操作的情况,最好在具体执行的时候需要处理的对象也尽可能少一些。</p><p>JRockit Real Time中,垃圾回收器的工作被划分为几个子任务。如果在执行其中某个子任务时(例如整理堆中的某一部分内存),应用程序的暂停时间超过了阈值,那么就放弃该子任务恢复应用程序的执行。用户根据业务需要指定可用于完成垃圾回收的总体时间,有些时候,某些子任务已经完成,但没有足够的时间完成整个垃圾回收工作,这时为了保证应用程序的运行,不得不废弃还未完成的子任务,待到下次垃圾回收的时候再重新执行,指定的响应时间越短,则废弃的子任务可能越多。</p><p>前面介绍过的标记阶段的工作比较容易调整,可以与应用程序并发执行。但清理和整理阶段则需要暂停应用程序线程(STW)。幸运的是,标记阶段会占到垃圾回收总体时间的90%。如果暂停应用程序的时间过长,则不得不终止当前垃圾回收任务,重新并发执行,期望问题可以自动解决。之所以将垃圾回收划分为几个子任务就是为了便于这一目标的实现。</p><h2 id="内存操作相关API">内存操作相关API</h2><h3 id="析构方法">析构方法</h3><blockquote><p>Java中的析构函数的设计就是一个失误,应避免使用。</p></blockquote><p>这不仅仅是我们的意见,也是Java社区的一致意见。</p><h3 id="JVM的行为差异">JVM的行为差异</h3><p>对于JVM来说,一定谨记,编程语言只能提醒垃圾回收器工作。就Java而言,在设计上它本身并不能精确控制内存系统。例如,假设两个JVM厂商所实现软引用在缓存中具有相同的存活时间,这本就是不切实际的。</p><p>另外一个问题就是大量用户对System.gc()方法的错误使用。<font color="DeepPink"><strong>System.gc()方法仅仅是提醒运行时“现在可以做垃圾回收了”。在某些JVM实现中,频繁调用该方法导致了频繁的垃圾回收操作,而在某些JVM实现中,大部分时间忽略了该调用。</strong></font></p><p>我过去任职为性能顾问期间,多次看到该方法被滥用。很多时候,只是去掉对 System.gc方法的几次调用就可以大幅提升性能,这也是 JRock中会有命令行参数-xx:AllowSystemGC=False来禁用System,gc方法的原因。</p><h2 id="陷阱与伪优化">陷阱与伪优化</h2><p>部分开发人员在写代码时,有时会写一些“经过优化的”的代码,期望可以帮助完成垃圾回收的工作,但实际上,这只是他们的错觉。记住,过早优化是万恶之源。就Java来说,很难在语言层面控制垃圾回收的行为。这里的主要问题时,开发人员误以为垃圾回收器有固定的运行模式,并妄图去控制它。</p><p>除了垃圾回收外,对象池(object poll)也是Java中常见的伪优化(false optimization)。有人认为,保留一个存活对象池来重新使用已创建的对象可以提升垃圾回收的性能,但实际上,对象池不仅增加了应用程序的复杂度,还很容易出错。对于现代垃圾收集器来说,使用java.lang.ref.Reference系列类实现缓存,或者直接将无用对象的引用置为null就好了,不用多操心。</p><p>事实上,基于现代VM,如果能够合理利用书本上的技巧,例如正确使用java.lang.ref.Reference系列类,注意Java的动态特性,完全可以写出运行良好的应用程序。<font color="DeepPink"><strong>如果应用程序真的有实时性要求,那么一开始就不该用Java编写,而应该使用那些由程序员手动控制内存的静态编程语言来实现应用程序。</strong></font></p><h2 id="JRockit中的内存管理">JRockit中的内存管理</h2><p><font color="DeepPink"><strong>需要注意的是,花大力气鼓捣JVM参数并不一定会使应用程序性能有多么大的提升,而且反而可能会干扰JVM的正常运行。</strong></font></p><h1>线程与同步</h1><h2 id="基本概念">基本概念</h2><p>每个对象都持有与同步操作相关的信息,例如当前对象是否作为锁使用,以及锁的具体实现等。一般情况下,为了便于快速访问,这些信息被保存在每个对象的对象头的锁字(lock word)中。JRockit使用锁字中的一些位来存储垃圾回收状态信息,虽然其中包含了垃圾回收信息,但是本书还是称之为锁字。</p><p>对象头还包含了指向类型信息的指针,在 JRockit中,这称为类块(class block)下图是 JRockit中Java对象在不同的CPU平台上的内存布局。为了节省内存,并加速解引用操作,对象头中所有字的长度是32位。类块是一个32位的指针,指向另一个外部结构,该结构包含了当前对象的类型信息和虚分派表(virtual dispatch table)等信息。</p><p><img data-src="/images/java-jrockit/%E5%AF%B9%E8%B1%A1%E5%A4%B4%E5%B8%83%E5%B1%80.png" alt><br>就目前来看,在绝大部分JVM(包括JRockit)中,对象头是使用两个32位长的字来表示的。在JRockit中,偏移为0的对象指针指向当前对象的类型信息,接下来是4字节的锁字。在SPARC平台上,对象头的布局刚好反过来,因为在使用原子指令操作指针时,如果没有偏移的话,效率会更高。与锁字不同,类块并不为原子操作所使用,因此在SPARC平台上,类块被放在锁字后面。</p><blockquote><p>原子操作(atomic operation)是指全部执行或全部不执行的本地指令。当原子指令全部执行时,其操作结果需要对所有潜在访问者可见。</p></blockquote><p><font color="DeepPink"><strong>原子操作用于读写锁字,具有排他性,这是实现JVM中同步块的基础。</strong></font></p><h3 id="难以调试">难以调试</h3><blockquote><p>死锁是指两个线程都在等待对方释放自己所需的资源,结果导致两个线程都进入休眠状态。很明显,它们再也醒不过来了。活锁的概念与死锁类似,区别在于线程在竟争时会采取主动操作,但无法获取锁。这就像两个人面对面前进,在一个很窄的走廊相遇,为了能继续前进,他们都向侧面移动,但由于移动的方向相反导致还是无法前进。</p></blockquote><h2 id="Java-API">Java API</h2><h3 id="synchronized关键字">synchronized关键字</h3><p>在Java中,关键字synchronized用于定义一个临界区,既可以是一段代码块,也可以是个完整的方法,如下所示:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public synchronized void setGadget(Gadget g)&#123;</span><br><span class="line">	this.gadget = g;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的方法定义中包含synchronized关键字,因此每次只能有一个线程修改给定对象的gadget域。</p><p><font color="DeepPink"><strong>在同步方法中,监视器对象是隐式的,即当前对象this,而对静态同步方法来说,监视器对象是当前对象的类对象。</strong></font>上面的示例代码与下面的代码是等效的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void setGadget(Gadget g)&#123;</span><br><span class="line">	synchronized(this)&#123;</span><br><span class="line">		this.gadget = g;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="java-lang-Thread类">java.lang.Thread类</h3><p>Java中的线程也有优先级概念,但是否真的起作用取决于JVM的具体实现。setPriority方法用于设置线程的优先级,提示JVM该线程更加重要或不怎么重要。当然,对于大多数JVM来说,显式地修改线程优先级没什么大帮助。当运行时“有更好的方案”时, JRockit JVM甚至会忽略Java线程的优先级。</p><p>正在运行的线程可以通过调用yield方法主动放弃剩余的时间片,以便其他线程运行,自身休眠(调用wait方法)或等待其他线程结束再运行(调用join方法)。</p><h3 id="volatile-关键字">volatile 关键字</h3><p>在多线程环境下,对某个属性域或内存地址进行写操作后,其他正在运行的线程未必能立即看到这个结果。在某些场景中,要求所有线程在执行时需要得知某个属性最新的值,为此,Java提供了关键字volatile来解决此问题。</p><p><font color="DeepPink"><strong>使用volatile修饰属性后,可以保证对该属性域的写操作会直接作用到内存中。原本,数据操作仅仅将数据写到CPU缓存中,过一会再写到内存中,正因如此,在同一个属性域上,不同的线程可能看到不同的值。目前,JVM在实现volatile关键字时,是通过在写属性操作后插入内存屏障代码来实现的,只不过这种方法有一点性能损耗。</strong></font></p><p>人们常常难以理解“为什么不同的线程会在同一个属性域上看到不同的值”。<font color="DeepPink"><strong>一般来说,目前的机器的内存模型已经足够强,或者应用程序的本身结构就不容易使非volatile属性出现这个问题。但是,考虑到JIT优化编译器可能会对程序做较大改动,如果开发人员不留心的话,还是会出现问题的。</strong></font>下面的示例代码解释了在Java程序中,为什么内存语义如此重要,尤其是当问题还没表现出来的时候。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class My Thread extends Thread&#123;</span><br><span class="line">	private volatile boolean finished;</span><br><span class="line">	public void run()&#123;</span><br><span class="line">		while(!finished)&#123;</span><br><span class="line">   			//</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	public void signalDone()&#123;</span><br><span class="line">		this.finished = true</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果定义变量finished时没有加上volatile关键字,那么在理论上,JIT编译器在优化时,可能会将之修改为只在循环开始前加载一次finished的值,但这就改变了代码原本的含义如果finished的值是false,那么程序就会陷入无限循环,即使其他线程调用了signalDone方法也没用。<font color="DeepPink"><strong>Java语言规范指明,如果编译器认为合适的话,可以为非 volatile变量在线程内创建副本以便后续使用。</strong></font></p><blockquote><p>由于一般会使用内存屏障来实现volatile关键字的语义,会导致CPU缓存失效,降低应用程序整体性能,使用的时候要谨慎。</p></blockquote><h2 id="Java中线程与同步机制的实现">Java中线程与同步机制的实现</h2><h3 id="Java内存模型">Java内存模型</h3><p>现在CPU架构中,普遍使用了数据缓存机制以大幅提升CPU对数据的读写速度,减轻处理器总线的竞争程度。正如所有的缓存系统一样,这里也存在一致性问题,对于多处理器系统来说尤其重要,因为多个处理器有可能同时访问内存中同一位置的数据内存模型定义了不同的CPU,在同时访问内存中同一位置时,是否会看到相同的值的情况。</p><p>强内存模型(例如x86平台)是指,当某个CPU修改了某个内存位置的值后,其他的CPU几乎自动就可以看到这个刚刚保存的值。在这种内存模型之下,内存写操作的执行顺序与代码中的排列顺序相同。弱内存模型(例如IA-64平台)是指,当某个CPU修改了某个内存位置的值后其他的CPU不一定可以看到这个刚刚保存的值(除非CPU在执行写操作时附有特殊的内存屏障类指令),更普遍的说,所有由Java程序引起的内存访问都应该对其他所有CPU可见,但事实上却不能保证立即可见。</p><h3 id="同步的实现">同步的实现</h3><h4 id="原生机制">原生机制</h4><p>从计算机最底层CPU结构来说,同步是使用原子指令实现的,各个平台的具体实现可能有所不同。以x86平台为例,它使用了专门的锁前缀(lock prefix)来实现多处理器环境中指令的原子性。</p><p>在大多数CPU架构中,标准指令(例如加法和减法指令)都可以实现为原子指令。</p><p>在微架构( micro- architecture)层面,原子指令的执行方式在各个平台上不尽相同。一般情况下,它会暂停CPU流水线的指令分派,直到所有已有的指令都完成执行,并将操作结果刷入到内存中。此外,该CPU还会阻止其他CPU对相关缓存行的访问,直到该原子指令结束执行。在现代x86硬件平台上,如果屏障指令(fence instruction)中断了比较复杂的指令执行,则该原子指令可能需要等上很多个时钟周期才能完成执行。<font color="DeepPink"><strong>因此,不仅是过多的临界区会影响系统性能锁的具体实现也会影响性能,当频繁对较小的临界区执行加锁、解锁操作时,性能损耗更是巨大。</strong></font></p><h3 id="同步在字节码中的实现">同步在字节码中的实现</h3><p>Java字节码中有两条用于实现同步的指令,分别是monitorenter和monitorexit,它们都会从执行栈中弹出一个对象作为其操作数。使用javac编译源代码时,若遇到显式使用监视器对象的同步代码,则为之生成相应的monitorenter指令和monitorexit指令。</p><h2 id="对于线程与同步的优化">对于线程与同步的优化</h2><h3 id="锁膨胀与锁收缩">锁膨胀与锁收缩</h3><blockquote><p>默认情况下, JRockit使用一个小的自旋锁来实现刚膨胀的胖锁,只持续很短的时间。乍看之下,这不太符合常理,但这么做确实是很有益处的。如果锁的竟争确实非常激烈,而导致线程长时间自旋的话,可以使用命令行参数-XX:UseFatSpin=false禁用此方式。作为胖锁的一部分,自旋锁也可以利用自适应运行时获取到的反馈信息,这部分功能默认是禁用的,可以使用命令行参数-XX:UseAdaptiveFatSpin=true来开启。</p></blockquote><h3 id="延迟解锁">延迟解锁</h3><p>如何分析很多线程局部的解锁,以及重新加锁的操作只会降低程序执行效率?这是否是程序运行的常态?运行时是否可以假设每个单独的解锁操作实际上都是不必要的?</p><p>如果某个锁每次被释放后又立刻都被同一个线程获取,则运行时可以做上述假设。但只要有另外某个线程试图获取这个看起来像是未被加锁的监视器对象(这种情况是符合语义的),这种假设就不再成立了。这时为了使这个监视器对象看起来像是一切正常,原本持有该监视器对象的线程需要强行释放该锁。这种实现方式称为延迟解锁,在某些描述中也称为偏向锁(biased locking)。</p><p>即使某个锁完全没有竞争,执行加锁和解锁操作的开销仍旧比什么都不做要大。而使用原子指令会使该指令周围的Java代码都产生额外的执行开销。</p><p>从以上可以看出,假设大部分锁都只在线程局部起作用而不会出现竞争情况,是有道理的。在这种情况下,使用延迟解锁的优化方式可以提升系统性能。当然,天下没有免费的午餐,如果某个线程试图获取某个已经延迟解锁优化的监视器对象,这时的执行开销会被直接获取普通监视器对象大得多,因为这个看似未加锁的监视器对象必须要先被强行释放掉因此,不能一直假设解锁操作是不必要的,需要对不同的运行时行为做针对性的优化。</p><p>1.实现</p><p>实现延迟解锁的语义其实很简单。</p><p>实现 monitorenter指令。</p><ul><li><font color="DeepPink"><strong>如果对象是未锁定的,则加锁成功的线程将继续持有该锁,并标记该对象为延迟加锁的。</strong></font></li><li><font color="DeepPink"><strong>如果对象已经被标记为延迟加锁的</strong></font>：<ul><li><font color="DeepPink"><strong>如果对象是被同一个线程加锁的,则什么也不做(大体上是一个递归锁)</strong></font></li><li><font color="DeepPink"><strong>如果对象是被另一个线程加锁的,则暂停该线程对锁的持有状态,检查该对象真实的加锁状态,即是已加锁的还是未加锁的,这一步操作代价高昂,需要遍历调用栈。如果对象是已加锁的,则将该锁转换为瘦锁,否则强制释放该锁,以便可以被新线程获取到。</strong></font></li></ul></li></ul><p>实现monitorexit指令:如果是延迟加锁的对象,则什么也不做,保留其已加锁状态,即执行延迟解锁。</p><p>为了能解除线程对锁的持有状态,必须要先暂停该线程的执行,这个操作有不小的开销。在释放锁之后,锁的实际状态会通过检查线程栈中的锁符号来确定。延迟解锁使用自己的锁符号,以表示“该对象是被延迟锁定的”。</p><p>如果延迟锁定的对象从来也没有被撤销过,即所有的锁都只在线程局部内发挥作用,那么使用延迟锁定就可以大幅提升系统性能。但在实际应用中,如果我们的假设不成立,运行时就不得不一遍又一遍地释放已经被延迟加锁的对象,这种性能消耗实在承受不起。因此,运行时需要记录下监视器对象被不同线程获取到的次数,这部分信息存储在监视器对象的锁字中,称为转移位(transfer bit)。</p><p>如果监视器对象在不同的线程之间转移的次数过多,那么该对象、其类对象或者其类的所有实例都可能会被禁用延迟加锁,只会使用标准的胖锁和瘦锁来处理加锁或解锁操作。</p><p>正如之前介绍过的,对象首先是未加锁状态的,然后线程T1执行monitorenter指令,使之进入延迟加锁状态。但<font color="DeepPink"><strong>如果线程T1在该对象上执行了monitorexit指令,这时系统会假装已经解锁了,但实际上仍是锁定状态,锁对象的锁字中仍记录着线程T1的线程ID</strong></font>。在此之后线程T1如果再执行加锁操作,就不用再执行相关操作了。</p><p><font color="DeepPink"><strong>如果另一个线程T2试图获取同一个锁,则之前所做“该锁绝大部分被线T1程使用”的假设不再成立,会受到性能惩罚,将锁字中的线程ID由线程T1的ID替换为线程T2的</strong></font>。如果这情况经常出现,那么可能会禁用该对象作为延迟锁,并将该对象作为普通的瘦锁使用。</p><h2 id="陷阱与伪优化-v2">陷阱与伪优化</h2><h3 id="Thread-stop、Thread-resume和Thread-suspend">Thread.stop、Thread.resume和Thread.suspend</h3><p>永远不要使用Thread.stop方法、Thread.resume方法或Thread.suspend方法并小心处理使用这些方法的历史遗留代码。</p><p>普遍建议使用wait方法、notify方法或volatile变量来做线程间的同步处理。</p><h3 id="双检查锁">双检查锁</h3><p>如果对内存模型和CPU架构缺乏理解的话,即使使用平遇到问题。以下面的代码为例,其目的是实现单例模式。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Gadget Holder&#123;</span><br><span class="line">	private Gadget theGadget;	</span><br><span class="line">	public synchronized Gadget cetGadget()&#123;</span><br><span class="line">		if (this.theGadget == null)&#123;</span><br><span class="line">			this.theGadget = new Gadget();</span><br><span class="line">		&#125;</span><br><span class="line">		return this.theGadget;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码是线程安全的,因为getGadget方法是同步但当Gadget类的构造函数已经执行过一次之后,再执行同优化性能,将之改造为下面的代码。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public Gadget getGadget()&#123;</span><br><span class="line">	if (this.theGadget == null)&#123;</span><br><span class="line">		synchronized(this)&#123;</span><br><span class="line">			if(this.theGadget == null))&#123;</span><br><span class="line">				this.theGadget = new Gadget();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return this.theGadget;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码使用了一个看起来很“聪明”的技巧,如果行同步操作,而是直接返回已有的对象;如果对象还未创建值。这样可以保证“线程安全”。</p><p>上述代码就是所谓的双检查锁(double checked locking),下面分析一下这段代码的问题。<font color="DeepPink"><strong>假设某个线程经过内层的空值检查,开始初始化theGadget字段的值,该线程需要为新对象分配内存,并对theGadget字段赋值。可是,这一系列操作并不是原子的,且执行顺序无法保证。如果在此时正好发生线程上下文切换,则另一个线程看到的theGadget字段的值可能是未经完整初始化的,有可能会导致外层的控制检查失效,并返回这个未经完整初始化的对象。不仅仅是创建对象可能会出问题,处理其他类型数据时也要小心。例如,在32位平台上,写入一个long型数据通常需要执行两次32位数据的写操作,而写入int数据则无此顾虑。</strong></font></p><p>上述问题可以通过将 theGadget字段声明为 volatile来解决(注意,只在新版本的内存模型下才有效),增加的执行开销尽管比使用synchronized方法的小,但还是有的。如果不确定当前版本的内存模型是否实现正确,不要使用双检查锁。网上有很多文章介绍了为什么不应该使用双检查锁,不仅限于Java,其他语言也是。</p><p><font color="DeepPink"><strong>双检查锁的危险之处在于,在强内存模型下,它很少会使程序崩溃。Intel IA-64平台就是个典型示例,其弱内存模型臭名远扬,原本好好运行的Java应用程序却出现故障。如果某个应用程序在x86平台运行良好,在x64平台却出问题,人们很容易怀疑是JVM的bug,却忽视了有可能是Java应用程序自身的问题。</strong></font></p><p>使用静态属性来实现单例模式可以实现同样的语义,而无须使用双检查锁,如下所示:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class GadgetMaker&#123;</span><br><span class="line">	public static Gadget theGadget= new Gadget();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>Java语言保证类的初始化是原子操作, GadgetMaker类中没有其他的域,因此,在首次主动使用该类时会自动创建 Gadget类的实例。并赋值给theGadget字段。这种方法在新旧两种内存模型下均可正常工作。</strong></font></p><p>总之,使用Java做并行程序开发有很多需要小心的地方,如果能够正确理解Java内存模型那么是可以避开这些陷阱的。开发人员往往不太关心当前的硬件架构,但如果不能理解Java内存模型,迟早会搬起石头砸自己的脚。</p><h1>基准测试与性能调优</h1><h2 id="wait方法、notify方法与胖锁">wait方法、notify方法与胖锁</h2><h3 id="Java并非万能的">Java并非万能的</h3><p>Java是一门强大的通用编程语言,因其友好的语义和内建的内的开发进度,但Java不是万能的,这里来谈谈不宜使用Java解决的场景：</p><ul><li>要开发一个有近实时性要求的电信应用程序,并且其中会有其中会有成千上万的线程并发执行。</li><li>应用程序的数据库层所返回的数据经常是20MB的字节数组。</li><li>应用程序性能和行为的确定性,完全依赖于底层操作系统的调度器，即使调度器有微小变化也会对应用程序性能产生较大影响。</li><li>开发设备驱动程序。</li><li>使用 C/Fortran/COBOL等语言开发的历史遗留代码太多,目前团队手中还没有好用的工具可以将这些代码转换为Java代码。</li></ul><p>除了上面的示例外,还有其他很多场景不适宜使用Java。通过JVM对底层操作系统的抽象Java实现了“一次编写,到处运行”,也因此受到了广泛关注。但夸大一点说,ANSI C也能做到这一点,只不过在编写源代码时,要花很多精力来应对可移植性问题。因此要结合实际场景选择合适的工具。Java是好用,但也不要滥用。</p><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>JVM</tag>
        <tag>JRockit</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解JVM＆G1GC 笔记</title>
    <url>/java-jvm-gc-g1.html</url>
    <content><![CDATA[<p>本文整理自：《深入理解JVM＆G1GC》 作者：周明耀<br><strong>本书很一般，建议粗略的看看就行</strong><br>出版时间：2017-06-01</p><a id="more"></a><p>推荐阅读官方文档:<br><a href="https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-g1-garbage-collector1.html#GUID-3A99AE6C-F80A-4565-A27C-B4AEDF5CDF71" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-g1-garbage-collector1.html#GUID-3A99AE6C-F80A-4565-A27C-B4AEDF5CDF71</a></p><p>调优:<br><a href="https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-garbage-collector-tuning.html#GUID-4914A8D4-DE41-4250-B68E-816B58D4E278" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-garbage-collector-tuning.html#GUID-4914A8D4-DE41-4250-B68E-816B58D4E278</a></p><p>PDF版文档：<br><a href="/attachments/hotspot-virtual-machine-garbage-collection-tuning-guide-20.pdf" target="_blank">Hotspot Virtual Machine Garbage Collection Tuning Guide</a></p><h1>JVM GC基本知识</h1><h2 id="引言">引言</h2><p>G1内部主要有四个操作阶段：</p><ul><li>年轻代回收(A Young Collection)</li><li>运行在后台的并行循环(A Background，Concurrent Cycle)</li><li>混合回收(A Mixed Collection)</li><li>全量回收(A Full GC)</li></ul><h2 id="基本术语">基本术语</h2><h3 id="Java相关术语">Java相关术语</h3><h4 id="Interned-Strings">Interned Strings</h4><p><font color="DeepPink"><strong>在Java语言中有8种基本类型和一种比较特殊的类型 String这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。常量池就类似一个Java系统级别提供的缓存。</strong></font>8种基本类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种。</p><ul><li>直接使用双引号声明出来的String对象会直接存储在常量池中</li><li>如果不是用双引号声明的String对象，可以使用String提供的Intern方法。 intern方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。</li></ul><p>通俗点讲，Interned String就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。注意，这个值会被存放在字符串内部池(String Intern Pool)。</p><p>Java 7中Oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串池的位置调整到Java堆内，这个改动意味着你再也不会被固定的内存空间限制了。所有的字符串都保存在堆(Heap)中，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。字符串池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java7中使用 String intern()。</p><h3 id="Java-对象头">Java 对象头</h3><p>在HotSpot虚拟机中，对象在内存中的布局可以分成对象头、实例数据、对齐填充三部分。</p><ul><li>对象头:它主要包括对象自身的运行行元数据，比如哈希码、GC分代年龄、锁状态标志等，同时还包含一个类型指针，指向类元数据，表明该对象所属的类型。</li><li>实例数据:它是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段(包括从父类继承下来的和本身拥有的字段)。</li><li>对齐填充:它不是必要存在的，仅仅起着占位符的作用</li></ul><p>对象头大小在32位HotSpot VM和64位 HotSpot VM之间是不一样的，对象头在32位系统上占用8yte，在64位系统上占用16yte。我们可以通过Java对象布局工具获取头大小，这个工具简称为JOL。</p><h2 id="G1-涉及术语">G1 涉及术语</h2><h3 id="Metaspace">Metaspace</h3><p>JDK8 HotSpot JVM使用<font color="DeepPink"><strong>本地内存</strong></font>来存储类元数据信息并称为元空间(Metaspace)。</p><p><font color="DeepPink"><strong>默认情况下，大部分类元数据都在本地内存中分配，类元数据只受可用的本地内存限制(容量取决于是32位或是64位操作系统的可用虚拟内存大小)。新参数(MaxMetaspace Size)用于限制本地内存分配给类元数据的大小。如果没有指定这个参数，元空间会在运行时根据需要动态调整。</strong></font></p><p>一般情况下，适时地监控和调整元空间对于减小垃圾回收频率和减少延时是很有必要的。持续的元空间垃圾回收情况如果频繁发生，说明可能存在类、类加载器导致的内存泄漏或是大小设置不合适。</p><p>G1 GC与Metaspace相关的选项如下：</p><ul><li>-XX:MetaspaceSize:初始化元空间的大小(默认12 Mbytes在32bit client VM and 16 Mbytes在32bit server VM，在64 bit VM上会更大些)。</li><li>-XX:MaxMetaspaceSize:最大元空间的大小(默认本地内存)。</li><li>-XX:MinMetaspaceFreeRatio:扩大空间的最小比率，当GC后，内存占用超过这一比率，就会扩大空间。</li><li>-XX:MaxMetaspaceFreeRatio:缩小空间的最小比率，当GC后，内存占用低于这一比率，就会缩小空间。</li></ul><h3 id="Mixed-GC-Event">Mixed GC Event</h3><p>即混合GC事件，在这个事件内部，所有的年轻代Region和一部分老年代Region一起被回收。混合GC事件一定是跟在Minor GC之后的，并且混合GC只有在存活对象元数据存在的情况下才会触发。</p><h3 id="Reclaimable">Reclaimable</h3><p><font color="DeepPink"><strong>Gl GC为了能够回收，创建了一系列专门用于存放可回收对象的Region</strong></font>。这些Region都在个链表队列里面，这个队列只包含存活率小于-XX: G1MixedGCLiveThresholdPercent(默认85%)的Region。Region的值除以整个Java堆区，如果大于-XX:G1HeapWastePercen(默认5%)，则启动回收机制。</p><h3 id="Rset">Rset</h3><p><font color="DeepPink"><strong>全称Remembered Set，简称Rset，即跟踪指向某个堆区(Region)内的对象引用。</strong></font></p><p><font color="DeepPink"><strong>在标记存活对象时，G1使用RememberSet的概念，将每个分区外指向分区内的引用记录在该分区的RememberSet中，避免了对整个Heap的扫描，使得各个分区的GC更加独立。堆内存中的每个区都有一个RSet，Rset的作用是让堆区能并行独立地进行垃圾集合。</strong></font>RSet所占用的JVM内存小于总大小的5%。在这样的背景下，可以看出G1GC大大提高了触发 Full GC时的Heap占用率，同时也使得 Minor GC的暂停时间更加可控，对于内存较大的环境非常友好。</p><p>G1 GC引入了一些新的选项。G1RSetUpdatingPauseTimePercent设置STW阶段(独占阶段)为G1收集器指定更新RememberSet的时间占总STW时间的期望比例，默认为10。而G1ConcRefinementThreads则是在程序运行时维护RememberSet的线程数目。通过对这两个值的对应调整，我们可以把STW阶段的RememberSet更新工作压力更多地移到并行阶段。</p><h3 id="CSet">CSet</h3><p><font color="DeepPink"><strong>全称Collection Set，简称CSet，即收集集合，保存一次GC中将执行垃圾回收的区间(Region)。GC时在CSet中的所有存活数据(Live Data)都会被转移(复制/移动)。</strong></font>集合中的堆区可以是Eden， Survivor和/或Old Generation。CSets所占用的JVM内存小于总大小的1%。</p><p>从这里可以知道，实际上CSet相当于一个大圈，里面包含了很多的小圈(Rset)，这些圈圈都是需要被回收的信息。这样可以把CSet比作垃圾场，RSet是垃圾场里面一个个绿色的可回收垃圾桶。</p><h3 id="PLAB">PLAB</h3><p>全称为Promotion Local Allocation Buffers，它被用于年轻代回收。PLAB的作用是避免多线程竞争相同的数据，处理方式是每个线程拥有独立的PLAB，用于针对幸存者和老年空间。当应用开启的线程较多时，最好使用-XX:-ResizePlaB来关闭PLAB()的大小调整，以避免大量的线程通信所导致的性能下降。</p><h3 id="TLAB">TLAB</h3><p>全称为Thread Local Allocation Buffers，即线程本地分配缓存，是一个线程专用的内存分配区域。</p><p>总的来说，<font color="DeepPink"><strong>TLAB是为了加速对象分配而生的</strong></font>。由于对象一般会分配在堆上，而堆是全局共享的。因此在同一时间，可能会有多个线程在堆上申请空间。因此，每一次对象分配都必须要进行同步，而在竞争激烈的场合分配的效率又会进一步下降。考虑到对象分配几乎是Java最最常用的操作，所以JVM就使用了TLAB这种线程专属的区间来避免多线程冲突，提高对象分配的效率。<font color="DeepPink"><strong>TLAB本身占用了Eden区的空间</strong></font>，即JVM会为每一个Java线程分配一块TLAB空间。</p><p><font color="DeepPink"><strong>对于G1 GC来说，TLAB是Eden的一个Region，被一个单一线程用于分配资源。主要用途是让一个线程通过栈操作方式独享内存空间，用于对象分配，这样比多个线程之间共享资源要快很多。如果每个线程的分配内存不够，那么它会去全局内存池申请新的内存。这样也就是说，如果TLAB值设置过小，容易造成频繁申请，也就会造成GC性能下降。反之，如果设置过大，会造成TLAB使用不完，也就是说内存浪费。</strong></font></p><h3 id="Region">Region</h3><p>从字面上来说， Region表示一个区域，每个区域里面的字母代表不同的分代内存空间类型(如[E]Eden，[O]Old，[S]Survivor)，<font color="DeepPink"><strong>空白的区块不属于任何一个分区</strong></font>。G1可以在需要的时候任意指定这个区域属于Eden或是O区之类的。</p><h3 id="Ergonomics-Heuristic-Decision">Ergonomics Heuristic Decision</h3><p>在很多英文书里都能看到这串单词，特别是Ergonomics Heuristi，它们的字面意思是人体工程学，可以理解为适合人类理解的行为、习惯。GC日志里面看到Ergonomics这个单词，它后面一般跟着的是G1 GC相关的详细描述，比如堆内存日志、CSet划分等，通常采用选项-XX:+PrintAdaptiveSizePolicy时会看到这个单词。</p><h3 id="Top-at-mark-start">Top-at-mark-start</h3><p>每个区间记录着两个TAMS指针(Top-at-mark-start)，分别为prevTAMS和nextTAMS在TAMS以上的对象是新分配的，因而被视为隐式标记。</p><h1>JVM&amp;GC 深入知识</h1><h2 id="Java虚拟机内存模型">Java虚拟机内存模型</h2><p><img data-src="/images/java-jvm-gc-g1/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png" alt></p><h3 id="程序计数器">程序计数器</h3><p>程序计数器，英文全称Program Counter Register，它是一块很小的内存空间，它是运行速度最快的存储区域，这是因为它位于不同于其他存储区的地方—处理器内部。寄存器的数量极其有限，所以寄存器由编译器根据需求进行分配。实际上在Java应用程序内部不能直接控制寄存器，也不能在程序中感觉到寄存器存在的任何迹象。<font color="DeepPink"><strong>可以把程序计数器看作当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器的工作就是通过改变程序计数器的值来选择下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都要依赖这个计数器来完成。</strong></font></p><p>简单概括上面的描述，即在多线程环境下，为了让线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器，各个线程之间互不影响、独立存储，因此这块内存是线程私有的。<font color="DeepPink"><strong>JVM中的寄存器类似于物理寄存器的一种抽象模拟，正如前面说的，它是线程私有的，所以生命周期与线程的生命周期保持一致。</strong></font></p><p><font color="DeepPink"><strong>根据Java虚拟机定义来看，程序寄存器区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemory Error情况的区域。</strong></font></p><h3 id="虚拟机栈">虚拟机栈</h3><p>JVM的架构是基于栈的，即程序指令的每一个操作都要经过入栈和出栈这样的组合型操作才能完成。</p><p>总的来说，栈的优势是访问速度比堆要快，它仅次于寄存器，并且栈数据是可以被共享的。栈的缺点是存储在栈里面的数据大小与生存期必须是确定的，从这一点来看，栈明显缺乏灵活性。虚拟机栈内主要被用来存放一些基本类型的变量，例如int、 short、long、byte、foat、 double、boolea、char，以及对象引用。</p><p>前面说过，<font color="DeepPink"><strong>虚拟机栈有一个很重要的特殊性，就是存放在栈内的数据可以共享。</strong></font>假设同时定义:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int a=1;</span><br><span class="line">int b=1;</span><br></pre></td></tr></table></figure><p>对于上面的代码，虚拟机处理第一条语句，首先它会在栈内创建一个变量为a的引用，然后查找栈内是否有1这个值，如果没找到，就将1存放进来，然后将a指向1。接下来处理第二条语句，在创建完b的引用变量后，因为在栈内已经有1这个值，便将b直接指向1。这样，就出现了a与b同时均指向1的情况。这时，如果存在第三条语句，它针对a再次定义为a=4，那么编译器会重新搜索栈内是否有4值，如果没有，则将4存放进来，并令a指向4，如果已经有了，则直接将a指向这个地址，因此a值的改变不会影响到b的值。要注意这种数据的共享与两个对象的引用同时指向一个对象的这种共享的方式存在明显的不同，因为这种情况a的修改并不会影响到b，它是由虚拟机完成的，这样的做法有利于节省空间。而一个对象引用变量修改了这个对象的内部状态，会影响到另一个对象引用变量。</p><p>与程序计数器一样，<font color="DeepPink"><strong>Java虚拟机栈也是线程私有的内存空间，它和Java线程在同一时间创建，它保存方法的局部变量、部分结果，并参与方法的调用和返回</strong></font>。</p><p>虚拟机栈在运行时使用一种叫作栈帧的数据结构保存上下文数据，栈帧里面存放了方法的局部变量表、操作数栈、动态连接方法和返回地址等信息。每一个方法的调用都伴随着栈帧的入栈操作，相应地，方法的返回则表示栈帧的出栈操作。<br><img data-src="/images/java-jvm-gc-g1/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%E5%BC%95%E7%94%A8%E5%9B%BE.png" alt></p><blockquote><p>使用JClassLib工具可以查看Class文件中每个方法所分配的最大局部变量区的容量。JClassLib工具是开源软件，它可以用于查看 Class文件的结构，包括常量池、接口、属性、方法，还可以用于查看文件的字节码。</p></blockquote><h3 id="Java堆">Java堆</h3><p>Java堆区在JVM启动的时候即被创建，它只要求逻辑上是连续的，在物理空间上可以是不连续。所有的线程共享Java堆，在这里可以划分线程私有的缓冲区(Thread Local Allocation Buffer，TLAB)。</p><p>正是因为Java堆区是GC的重点回收区域，所以GC极有可能会在大内存的使用和频繁进行垃圾回收过程上成为系统性能瓶颈。为了解决这个问题，JVM的设计者们开始考虑是否一定需要将对象实例存储到Java堆区内。基于OpenJDK深度定制的TaobaoJVM，其中创新的GCIH(GC invisible heap)技术实现了off-heap，即将生命周期较长的Java对象从heap中移到heap之外，并且GC不能管理GCH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。</p><h3 id="方法区">方法区</h3><p><font color="DeepPink"><strong>方法区主要保存的信息是类的元数据</strong></font>。方法区与堆空间类似，它也是被JVM中所有的线程共享的区域。如下图所示，<font color="DeepPink"><strong>方法区中最为重要的是类的类型信息、常量池、域信息、方法信息。</strong></font>类型信息包括类的完整名称、父类的完整名称、类型修饰符(public/protected/private)和类型的直接接口类表。<br><img data-src="/images/java-jvm-gc-g1/%E6%96%B9%E6%B3%95%E5%8C%BA%E7%BB%84%E6%88%90%E5%9B%BE.png" alt></p><p><font color="DeepPink"><strong>常量池包括类方法、域等信息所引用的常量信息。域信息包括域名称、域类型和域修饰符。方法信息包括方法名称、返回类型、方法参数、方法修饰符、方法字节码、操作数栈和方法栈帧的局部变量区大小以及异常表。方法区是线程间共享的，当两个线程同时需要加载一个类型时，只有一个类会请求ClassLoader加载，另一个线程则会等待。总而言之，方法区内保存的信息大部分来自于Class件，是Java应用程序运行必不可少的重要数据。</strong></font></p><p>在Hotspot虚拟机中，方法区也被称为永久区，是一块独立于Java堆的内存空间。虽然被叫作永久区，但是在永久区中的对象同样也是可以被GC回收的，只是对于GC的对应策略与Java堆空间略有不同。</p><p>GC针对永久区的回收，通常主要从两个方面分析:一是GC对永久区常量池的回收，二是永久区对类元数据的回收。HotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。</p><h2 id="垃圾收集算法">垃圾收集算法</h2><h3 id="根搜索算法">根搜索算法</h3><p><font color="DeepPink"><strong>在HotSpot中，根对象集合中包含了5个元素，Java栈内的对象引用、本地方法栈内的对象引用、运行时常量池中的对象引用、方法区中类静态属性的对象引用以及与一个类对应的唯一数据类型的Class对象。</strong></font></p><blockquote><p>这部分了解一下就好<br>注意，在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程。如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize方法。当对象没有覆盖finalize方法，或者finalized方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由条由虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize方法中执行缓慢，或者发生了死循环(更极端的情况)，很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalized中成功拯救自己—只要重新与引用链上的任何一个对象建立关联即可，譬如把自己(this关键字)赋值给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合。如果对象这时候还没有逃脱，那它就真的离死不远了。</p></blockquote><h3 id="标记清除算法-Mark-Sweep">标记清除算法(Mark-Sweep)</h3><p>算法涉及几个概念，先来了解一下mutator和collector，这两个名词经常在垃圾收集算法中出现，<font color="DeepPink"><strong>collector指的就是垃圾收集器，而 mutator是指除了垃圾收集器之外的部分，比如说我们的应用程序本身。</strong></font>mutator的职责一般是NEW(分配内存)、READ(从内存中读取内容)、WRITE(将内容写入内存)，而collector则就是回收不再使用的内存来供mutator进行NEW操作的使用。mutator根对象一般指的是分配在堆内存之外，可以直接被mutator直接访问到的对象，一般是指静态/全局变量以及ThreadLocal变量。</p><h3 id="复制算法-Copying">复制算法(Copying)</h3><p>基于分代的概念，Java堆区如果还要更进一步细分的话，还可以划分为年轻代(YoungGen)和老年代(OldGen)，其中年轻代又可以被划分为Eden空间、From Survivor空间和To Survivor空间。<font color="DeepPink"><strong>在HotSpot中，Eden空间和另外两个Survivor空间默认所占的比例是8:1，当然开发人员可以通过选项“-XX:SurvivorRatio”调整这个空间比例</strong></font>。当执行一次Minor GC(年轻代的垃圾回收)，Eden空间中的存活对象会被复制到To空间内，并且之前已经经历过一次 Minor GC并在From空间中存活下来的对象如果还年轻的话同样也会被复制到To空间内。需要注意的是，在满足两种特殊情况下，Eden和From空间中的存活对象将不会被复制到To空间内。首先是如果存活对象的分代年龄超过选项“-XX:MaxTenuringThreshold”所指定的阈值时，将会直接晋升到老年代中。其次当To空间的容量达到阈值时，存活对象同样也是直接晋升到老年代中。当所有的存活对象都被复制到To空间或者晋升到老年代后，剩下的均为垃圾对象，这就意味着GC可以对这些已经死亡了的对象执行一次Minor GC，释放掉其所占用的内存空间。</p><h3 id="标记压缩算法-Mark-Compact">标记压缩算法(Mark-Compact)</h3><p>在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。简单来说，就是针对不同的代空间，从而结合使用不同的垃圾收集算法。<font color="DeepPink"><strong>为年轻代选择的垃圾收集算法通常是以速度优先，因为年轻代中所存储的瞬时对象生命周期非常短暂，可以有针对性地使用复制算法，因此执行Minor GC时，一定要保持高效和快速。而年轻代中的生存空间通常都比较小，所以回收年轻代时一定会非常频繁。但老年代通常使用更节省内存的回收算法，因为老年代中所存储的对象生命周期都非常长，并且老年代占据了大部分的堆空间，所以老年代的Full GC并不会跟年轻代的Minor GC一样频繁，不过一旦程序中发生一次Full GC，将会耗费更长的时间来完成，那么在老年代中使用标记-清除算法或者标记-压缩算法执行垃圾回收将会是不错的选择。</strong></font></p><h2 id="Garbage-Collection">Garbage Collection</h2><h3 id="GC-概念">GC 概念</h3><p>在许多情况下，GC不应该成为影响系统性能的瓶颈，可以根据以下六点来评估一款GC的性能。</p><ul><li>吞吐量：程序的运行时间(程序的运行时间+内存回收的时间)。</li><li>垃圾收集开销：吞吐量的补数，垃圾收集器所占时间与总时间的比例。</li><li>暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间。</li><li>收集频率：相对于应用程序的执行，收集操作发生的频率。</li><li>堆空间：Java堆区所占的内存大小。</li><li>快速：一个对象从诞生到被回收所经历的时间。</li></ul><h3 id="Parallel收集器">Parallel收集器</h3><p><font color="DeepPink"><strong>需要注意的是，垃圾收集器中吞吐量和低延迟这两个目标本身是相互矛盾的，因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。</strong></font></p><p>举个例子，在60s的JVM总运行时间里，GC的执行频率是20秒/次，那么60s内一共会执行3次内存回收，按照每次GC耗时100ms来计算，最终一共会有300ms(3×100)被用于执行垃圾回收。但是如果我们将选项“-XX:MaxGCPauseMills”的值调小后，年轻代的内存空间也会自动调整，内存空间越小就越容易被耗尽，也就越容易造成GC的执行频繁发生。之前在60s的JVM总运行时间里，最终会有300ms被用于执行内存回收，而如今GC的执行频率却是10s/次，60s内将会执行6次内存回收，按照每次GC耗时60ms来计算，虽然看上去暂停时间更短了，但最终会耗时360ms(6×60)用于执行内存回收，很明显程序的吞吐量下降了。所以大家在设置这两个选项时，一定需要注意控制在一个折中的范围之内。Parallel收集器还提供个“-XX:UseAdaptiveSizePolicy”选项用于设置GC的自动分代大小调节策略，一旦设置这个选项后，就意味着开发人员将不再需要显式地设置年轻代中的一些细节参数，JVM会根据自身当前的运行情况动态调整这些相关参数。</p><h3 id="Garbage-First-G1-GC">Garbage First (G1) GC</h3><p><font color="DeepPink"><strong>G1很重视老年代的垃圾回收，一旦整个堆空间占有率达到指定的阈值(启动时可配置)，G1会立即启动一个独占的并行初始标记阶段(initial-mark phase)进行垃圾回收。在G1 GC，判断的是整个Java堆内部老年代的占有率，足以见G1对老年代的重视。</strong></font></p><p>初始标记阶段一般和年轻代GC一起运行，一旦初始标记阶段结束，并行多线程的标记阶段就开始启动去标记所有老年代还存活的对象，注意这个标记阶段不是独占式的，它允许应用程序线程和它并行执行。当这个标记阶段运行完毕之后，为了再次确认是否有逃过扫描的对象，“启动一个独占式的再次标记阶段(remark phase)，尝试标记所有遗漏的对象。在这个再次标记阶段结束之后，G1就掌握了所有的老年代 Region的标记信息，这和国家的户口统计方式差不多。一旦老年代的某些Region内部不存在任何的存活对象，它就可以在下一个阶段，即清除阶段(cleanup phase)被清除了，就是可以销户了，又被放回了可用Region队列。同样地，再次标记阶段结束后就可以对一些老年代执行收集动作。</p><p>前面提到了CSet概念，一个CSet里面可以包含多少Region取决于多少空间可以被释放、G1停顿目标时间这两个因素。前面说起过混合GC(Mixed GC)，这里就要具体说明一下了。当CSet被确定之后，会在接下来的一个年轻代回收过程当中对CSet进行回收，通过年轻代GC的几个阶段，一部分的老年代Region会被回收并放入年轻代使用。这个概念很灵活，<font color="DeepPink"><strong>即G1只关注你有没有存活对象了，如果没有，无论你属于老年代，还是属于年轻代，你都会被回收并放入可用Region队列，下一次你被分配到哪里就不确定了。</strong></font>也正是因为Region、混合收集这些特性，让G1对老年代的垃圾收集方式有别于Serial GC、Parallel GC和CMS GC，G1采用Region方式让对象之间的联系存在于虚拟地址之上，这样就不需要针对老年代的压缩和回收动作对整个Java堆执行扫描，为老年代回收节约了时间。</p><h4 id="G1-设计思路">G1 设计思路</h4><p>Gl把整个Java堆划分为若干个区间(Region)。每个Region大小为2的倍数，范围在1MB~32MB之间，可能为1MB、2MB、4MB、8MB、16MB、32MB。<font color="DeepPink"><strong>所有的Region有一样的大小，在JVM生命周期内不会被改变。</strong></font></p><p>注意，在年轻代、混合代、Full GC这三个阶段，年轻代的Eden Region和Survivor Region的数量会随时变化。<font color="DeepPink"><strong>Humongous Region(大对象 Region)是老年代Region的一部分</strong></font>，里面的对象超过每个Region的50%空间，这一点有别于一般对象Region。</p><p>从之前的介绍我们知道没有必要去刻意区分Region的用途，因为G1设计Region的分配原则是很灵活的。一开始G1会从可用 Region队列里面挑选出Region并设置为Eden Region，一个Eden Region里面填满对象以后，又会从可用Region队列里再挑出一个。当所有的Eden Region都被填满时，一个年轻代GC收集就会开始执行了，在这个收集阶段，我们会收集Eden和Survivor Region，所有的存活对象要么进入到下一个Survivor region，要么进入老年代Region。</p><p><font color="DeepPink"><strong>G1提供了一个选项-XX:InitiatingHeapOccupancyPercent，默认值是Java堆空间的45%，这个选项决定了是否开始一次老年代回收动作，即年轻代GC结束之后，G1会评估剩余的对象是否达到了45%这个阈值。</strong></font></p><p>如果标记阶段(Marking Phase)结束后一个老年代的Region已经不存在对象，那么它会被放回可用Region队列，反之，它会被放入混合收集器。</p><p>由于标记阶段不是一个独占式的多线程并行程序，这样应用程序线程就会和它一起并行执行。<font color="DeepPink"><strong>为了避免标记阶段占用过多的CPU资源，G1采用时间片方式分段执行操作，即在时间片内全力运行，然后休息一段时间，这个休息时间就是让应用程序尽可能多地使用CPU资源运行。</strong></font></p><h4 id="大对象-Humongous-Object">大对象(Humongous Object)</h4><p>大对象Region属于老年代的一部分，它只包含一个对象。当并行标记阶段发现没有存活对象时，G1会回收这个大对象 Region，注意这个动作可以是一个批量回收。</p><h4 id="全垃圾收集-Full-Garbage-Collection">全垃圾收集(Full Garbage Collection)</h4><p>G1的Full GC和Serial GC的Full GC采用的是同一种算法。<font color="DeepPink"><strong>Full GC会对整个Java堆进行压缩。G1的Full GC是单线程的，会引起较长的停顿时间，因此G1的设计目标是减少Full GC的发生次数。</strong></font></p><h4 id="并行循环-Concurrent-Cycle">并行循环(Concurrent Cycle)</h4><p>一个G1并行循环包括几个阶段的活动:初始标记(Initial Marking)、并行Root区间扫描(Concurrent Root Region Scanning)、并行标记(Concurrent Marking)、重标记(Remarking)和清除(Cleanup)。除了最后的Cleanup阶段以外，其余阶段都属于标记存活对象阶段。</p><p>初始标记阶段的目的是收集所有GC根(Roots)。 Roots是一个对象的起源指针。为了收集根引用，从应用线程开始，应用线程必须停下来，所以初始标记阶段是一个独占式的。由于个年轻代GC必须收集所有的Roots，所以G1的初始标记在一个年轻代GC里完成。</p><p><font color="DeepPink"><strong>并行根区间扫描阶段必须扫描和标记所有幸存者区间的对象引用，这一阶段所有的应用程序线程都可以并行执行，唯一的约束是扫描必须在下一个GC开始前完成。这一约束的原因是个新的GC事件会产生一堆新的幸存者对象集合，这些对象和初始化标记阶段的幸存者对象不一样，容易发生混淆。</strong></font></p><p>并行标记阶段完成了几乎所有的标记工作。在这一阶段，利用多线程并行标记存活对象及对应的逻辑地图。这一阶段允许所有的Java线程并行执行，但是对应用程序来说总体的吞吐量可能会下降。其实任何一个系统都和人体循环一样，当没有外部干扰时，系统可以正常运行，如果受到外部干扰，人体系统也会出现混乱，甚至出现短时间的休克。</p><p>重标记阶段是一个独占式阶段，通常是一个很短的停顿，这个阶段会完成所有的标记工作。</p><p>最后一个并行标记步骤是清除阶段。在这个阶段，没有包含存活对象的Region会被回收，并随即被加入可用Region队列。这个阶段的重要意义是最终决定了哪些 Region可以进入混合GC。在G1内部，混合GC是非常重要的释放内存机制，避免了G1出现没有可用Region的情况发生，否则就会触发Full GC事件。</p><h4 id="堆大小（Heap-Sizing）">堆大小（Heap Sizing）</h4><p>G1在以下几种情况下可能会增大堆内存大小：</p><ul><li>Full GC阶段。</li><li>Young或Mixed GC发生时，G1计算GC花费的时间与Java线程的花费时间比例，如果-XX:GCTimeRatio设置GC花费时间很长，则堆大小会增大，这样的设计思路是希望G1发生GC的频率降低，这样GC花费时间和Java线程花费时间比例也会相应下降。<br>-XX:GCTimeRatio选项的默认值是9，所有其他HotSpot GC的默认值是99。这个值越大，代表Java堆空间大小增长越偏激，即越容易扩大堆空间大小，这样也是为了达到降低GC花费时间的设计目标。</li><li>如果一个对象分配失败，即便一个GC刚刚结束，G1采用的策略不是立即重复Full GC，而是通过增大堆内存大小，确保对象分配成功。这样的设计理念符合G1的避免Full GC发生的最初思想。</li><li>和第3条一样，如果出现一个大对象分配失败，前面说过，大对象需要几个连续的Region区间才能确保对象分配成功。如果发生这种分配失败的情况，采用的设计理念也不是调用Full GC，而是扩大堆内存。</li><li>当GC申请加入一个新的Region时。</li></ul><p>引用一段在StackOverfall.com上看到的经验分享，“我在一个真实的、较大规模的应用程序中使用过G1:大约分配有60GB-70GB内存，存活对象大约在20GB~50GB之间。服务器运行Linux操作系统，JDK版本为6u22。G1与PS/PS Old相比，最大的好处是停顿时间更加可控可预测。如果我在PS中设置一个很低的最大允许GC时间，譬如期望50ms内完成GC(-XX:MaxGCPauseMillis=50)，但在65GB的Java堆下有可能得到的直接结果是一次长达30s至2min的漫长的Stop-the-World过程。而Gl与CMS相比，它们都立足于低停顿时间，CMS仍然是我现在的选择，但是随着Oracle对G1的持续改进，我相信Gl会是最终的胜利者。如果你现在采用的收集器没有出现问题，那么就没有任何理由现在去选择G1;如果你的应用追求低停顿，那么G1现在己经可以作为一个可尝试的选择:如果你的应用追求吞吐量，那么G1并不会为你带来什么特别的好处。”</p><h1>G1 GC应用示例</h1><p>G1 GC给我们提供了很多的命令行选项，也就是参数，这些参数一类以布尔类型打头，“+”表示启用该选项，“-”表示关闭该选项。另一类采用数字赋值，不需要布尔类型打头。</p><h2 id="选项解释及应用">选项解释及应用</h2><p>首先在cmd命令行模式下输入java -X，，如C:Users\Administrator&gt; java -X，输出如代码如下：<br><img data-src="/images/java-jvm-gc-g1/javax%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA.png" alt></p><h3 id="XX-PrintGCDetails">-XX:+PrintGCDetails</h3><p>该选项用于记录GC运行时的详细数据信息并输出，是最基本、使用最普遍的一个选项这个选项适用于所有GC，输出内容主要包括新生成对象占用内存大小以及耗费时间、各个年龄代的情况、每次回收的对应数据等。</p><h3 id="Xloggc">-Xloggc</h3><p>如果想要以文件形式保存这些GC日志，可以在启动参数中输入-XX:+PrintGCDetails -verbose:gc -XLoggc:gc.log，运行后我们会发现生成了一个 gc.log文件。</p><blockquote><p>-Xloggc:example_gc.log （设置垃圾回收日志打印的文件，文件名称可以自定义）</p></blockquote><p>-XX:initialHeapSize和-XX:MaxHeapSize就是我们比较熟悉的-Xms和-Xmx，它们允许我们指定JVM的初始和最大堆内存大小-XX:+UseCompressedClassPointers、XX:+UseCompressedOops<br>以及-XX:-UseLargePagesIndividualAllocation这三个选项和OOP有关。OOP的全称是Ordinary Object Pointer，即普通对象指针。通常64位JVM消耗的内存会比32位的大1.5倍，这是因为对象指针在64位架构下，长度会翻倍(更宽的寻址)。对于那些将要从32位平台移植到64位的应用来说，平白无故多了1/2的内存占用，作为开发者一定不愿意看到这种场景。所以，从JDK1.6 update4开始，64 bit JVM正式支持了-XX:+UseCompressedOops这个可以压缩指针，起到节约内存占用的选项。CompressedOops的实现方式是在机器码中植入压缩与解压指令，可能会给JVM增加额外的开销。-XX:+UseCompressedClassPointers选项是在JDK8出现的，也是在永久区消失之后出现的新的选项，主要用于对类的元数据进行压缩。-XX:UseLargePagesIndividualAllocation和oops是一起使用的，在大页内存使用发生时这个选项也会自动启用。</p><h3 id="XX-PrintGCApplicationStoppedTime">-XX:+PrintGCApplicationStoppedTime</h3><p>打印垃圾回收期间程序暂停的时间，如果使用该选项，会输出GC造成应用程序暂停的时间。一般和-XX:+PrintGCApplicationConcurrentTime组合起来一起使用，这样比较有利于查看输出。</p><h3 id="XX-ConcGCThreads">-XX:ConcGCThreads</h3><p>这个选项用来设置与Java应用程序线程并行执行的GC线程数量，默认为GC独占时运行线程的1/4。这个选项设置过大会导致Java应用程序可以使用的CPU资源减少，如果小一点则会对应用程序有利，但是过小就会增加GC并行循环的执行时间，反过来减少Java应用程序的运行时间(因为独占期时间拉长)。</p><h3 id="XX-G1HeapRegionSize">-XX:G1HeapRegionSize</h3><p>这是G1GC独有的选项，它是专门针对Region这个概念的对应设置选项，后续GC应该会继续采用 Region这个概念。 Region的大小默认为堆大小的1/200，.也可以设置为1MB、2MB、4MB、8MB、16MB，以及32MB，这六个划分档次。</p><p>增大Region块的大小有利于处理大对象。前面介绍过，大对象没有按照普通对象方式进行管理和分配空间，如果增大Region块的大小，则一些原本走特殊处理通道的大对象就可以被纳入普通处理通道了。这就好比我们在机场安检，飞行员、空姐可以走特殊通道，乘客如果也搞特殊化，一部分人去特殊通道处理，那么特殊通道就得増加几个，相应的普通通道就得减少了，对效率就起了降低作用。反之，如果Region大小设置过小，则会降低G1的灵活性，对于各个年龄代的大小都会造成分配问题。</p><h3 id="XX-G1HeapWastePercent">-XX:G1HeapWastePercent</h3><p>这个选项控制G1 GC不会回收的空闲内存比例，默认是堆内存的5%。G1 GC在回收过程中会回收所有Region的内存，并持续地做这个工作直到空闲内存比例达到设置的这个值为止，所以对于设置了较大值的堆内存来说，需要采用比较低的比例，这样可以确保较小部分的内存不被回收。这个很容易理解，城市越大就越容易出现一些死角，出于性能的原因可以不去关注那里，但是这个比例不能大。</p><h3 id="XX-G1MixedGCCountTarget">-XX:G1MixedGCCountTarget</h3><p>老年代Region的回收时间通常来说比年轻代Region稍长一些，这个选项可以设置一个并行循环之后启动多少个混合GC，默认值是8个。设置一个比较大的值可以让G1 GC在老年代Region回收时多花一些时间，如果一个混合GC的停顿时间很长，说明它要做的事情很多，所以可以增大这个值的设置，但是如果这个值过大，也会造成并行循环等待混合GC完成的时间相应的增加。</p><blockquote><p>当占用内存超过InitiatingHeapOccupancyPercent阀值时， 最多通过多少次Mixed GC来将内存控制在阀值之下。</p></blockquote><h3 id="XX-G1PrintRegionLivenessInfo">-XX:+G1PrintRegionLivenessInfo</h3><p>由于开启这个选项会在标记循环阶段完成之后输出详细信息，专业一点的叫法是诊断选项，所以在使用前需要开启选项UnlockDiagnosticVMOptions。这个选项启用后会打印堆内存内部每个Region里面的存活对象信息，这些信息包括使用率、RSet大小、回收一个Region的价值(Region内部回收价值评估，即性价比)。</p><p>这个选项输出的信息对于调试堆内Region是很有效的，不过对于一个很大的堆内存来说，由于每个 Region信息都输出了，所以信息量也是挺大的。</p><h3 id="XX-G1ReservePercent">-XX:G1ReservePercent</h3><p>每个年龄代都会有一些对象可以进入下一个阶段，为了确保这个提升过程正常完成，我们允许G1GC保留一些内存，这样就可以避免出现“ to space exhausted”错误，这个选项就是为了这个用途。</p><p>这个选项默认保留堆内存的10%。注意，这个预留内存空间不能用于年轻代。</p><p>对于一个拥有大内存的堆内存来说，这个值不能过大，因为它不能用于年轻代，这就意味着年轻代可用内存降低了。减小这个值有助于给年轻代留出更大的内存空间、更长的GC时间，这对提升性能吞吐量有好处。</p><h3 id="XX-G1SummarizeRSetStats">-XX:+G1SummarizeRSetStats</h3><p>和GIPrintRegionLivenessInfo选项一样，这个选项也是一个诊断选项，所以也需要开启UnlockDiagnosticVMOptions选项后才能使用，这也就意味着-XX:+UnlockDiagnosticVMOptions选项需要放在-XX:+G1SummarizeRSetStats选项的前面。</p><p>这个选项和-XX:G1SummarizePeriod一起使用的时候会阶段性地打印RSets的详细信息，这有助于找到RSet里面存在的问题。</p><h3 id="XX-G1TraceConcRefinement">-XX:+G1TraceConcRefinement</h3><p>这是一个诊断选项。如果启动这个诊断选项，那么并行Refinement线程相关的信息会被打印。注意，线程启动和结束时的信息都会被打印。</p><p>这里提到了Refinement线程，我们来提前梳理这个概念。请看每一代GC对应的GC线程:</p><table><thead><tr><th>Garbage Collector</th><th>Worker Threads Used</th></tr></thead><tbody><tr><td>Parallel GC</td><td>ParallelGCThreads</td></tr><tr><td>CMS GC</td><td>ParallelGCThreads<br>ConcGCThreads</td></tr><tr><td>G1 GC</td><td>ParallelGCThreads<br>ConcGCThreads<br>G1ConcRefinementThreads</td></tr></tbody></table><p>上面列出了三类GC线程，分别是ParallelGCThreads、ConcGCThreads和G1ConcRefinementThreads。关于这三个线程的区别：</p><table><thead><tr><th>名称</th><th>选项控制</th><th>作用</th></tr></thead><tbody><tr><td>ParallelGC Thread</td><td>-XX:ParallelGCThreads</td><td>GC的并行工作线程，专门用于独占阶段的工作，比如拷贝存活对象</td></tr><tr><td>ParallelMarkingThreads</td><td>-XX:ConcGCThreads</td><td>并行标记阶段的并行线程，它由一个主控(Master)线程和一些工作(Worker)线程组成，可以和应用程序并行执行</td></tr><tr><td>G1ConcurrentRefinementThreads</td><td>-XX:G1ConcRefinementThreads</td><td>和应用程序一起运行，用于更新RSet，如果ConcurrentRefinementThreads没有设置，那么默认为ParallelGCThreads+1</td></tr></tbody></table><h3 id="XX-G1UseAdaptiveConcRefinement">-XX:+G1UseAdaptiveConcRefinement</h3><p>这个选项默认是开启的。它会动态地对每一次GC中XX:G1ConcRefinementGreenZone、-XX:G1ConcRefinementYellowZone、-XX:G1ConcRefinementRedZone的值进行重新计算。</p><p>并行Refinement线程是持续运行的，并且会随着update log buffer积累的数量而动态调节。前面说到的三个配置选项-XX:G1ConcRefinementGreenZone、-XX:G1ConcRefinementYellowZone、-XX:G1ConcRefinementRedZone，是被用来根据不同的 buffer使用不同的Refinement线程，目的就是为了保证 Refinement线程一定要尽可能地跟上update log buffer产生的步伐。但是这个Refinement线程不是无限增加的，一旦出现 Refinement线程跟不上update log buffer产生的速度、update log buffer开始出现积压的情况，Mutator线程(即应用业务线程)就会协助Refinement线程执行RSet的更新工作。这个 Mutator线程实际上就是应用业务线程，当业务线程去参与Rset修改时，系统性能一定会受到影响，所以需要尽力去避免这种状况。</p><h3 id="XX-GCTimeRatio">-XX:GCTimeRatio</h3><p>这个选项代表Java应用线程花费的时间与GC线程花费时间的比率。通过这个比率值可以调节Java应用线程或者GC线程的工作时间，保障两者的执行时间.</p><p>HotSpot VM转换这个值为一个百分比，公式是100/(1+GCTimeRatio)，默认值是9，表示花费在GC工作量上的时间占总时间的10%。</p><h3 id="XX-HeapDumpBeforeFullGC-XX-HeapDumpAfterFullGC">-XX:+HeapDumpBeforeFullGC/-XX:+HeapDumpAfterFullGC</h3><p>这个选项启用之后，在Full GC开始之前有一个hprof文件会被创建。建议这个选项和-XX:+HeapDumpAfterFullGC一起使用，可以通过对Full GC发生前后的Java堆内存进行对比，找出内存泄漏和其他问题。</p><blockquote><p>获取full GC前后的heap dump</p></blockquote><h3 id="XX-InitiatingHeapOccupancyPercent">-XX:InitiatingHeapOccupancyPercent</h3><p>该选项的默认值是45，表示G1 GC并行循环初始设置的堆大小值，这个值决定了一个并行循环是不是要开始执行。它的逻辑是在一次GC完成后，比较老年代占用的空间和整个Java堆之间的比例。如果大于这个值，则预约下一次GC开始一个并行循环回收垃圾，从初始标记阶段开始。这个值越小，GC越频繁，反之，值越大，可以让应用程序执行时间更长。不过在内存消耗很快的情况下，我认为早运行并行循环比晚运行要好，看病要趁早。</p><h3 id="XX-UseStringDeduplication">-XX:+UseStringDeduplication</h3><p>该选项启动Java String对象的去重工作。JDK8u20开始引入该选项，默认为不启用。我们知道一个判断Java String对象值是否一样的语句“Stringl equals(String2)tue”，如果开启了该选项，并且如果两个对象包含相同的内容，即返回“tue”，则两个String对象只会共享一个字符数组。这个选项是G1GC独有的，也可以和其他GC一起使用。</p><p>延伸一点我们的知识面，一个去重对象的必备条件有如下三点:</p><ul><li>Java.lang String对象的一个实例。</li><li>这个对象在年轻代堆区间。</li><li>这个对象的年龄达到去重年龄代，或者这个对象已经在老年代堆区间并且对象年龄比去重年龄小。选项-XX:StringDeduplicationAgeThreshold设置了这个年龄界限。</li></ul><p>前面介绍过的可修改和不可修改字符串的处理方式有所不同，不可修改字符串默认就是去重的，在插入到HotSpot VM的String Table时已经注明了是去重的，这样就避免了HotSpot服务器JIT编译优化措施。</p><h3 id="XX-StringDeduplicationAgeThreshold">-XX:StringDeduplicationAgeThreshold</h3><p>这个选项是针对-XX:+UseStringDeduplication选项的，默认值是3。它的意思是一个字符串对象的年龄超过设定的阈值，或者提升到G1 GC老年代Region之后，就会成为字符串去重的候选对象，去重操作只会有一次。</p><h3 id="XX-PrintStringDeduplicationStatistics">-XX:+PrintStringDeduplicationStatistics</h3><p>这个选项挺有用的，能够帮助我们通过读取输出的统计资料来了解是否字符串去重后节约了大量的堆内存空间，默认是关闭的，就是说不会输出字符串去重的统计资料。</p><h3 id="XX-G1UseAdaptiveIHOP">-XX:+G1UseAdaptiveIHOP</h3><p>JDK9提供的新的选项。<font color="DeepPink"><strong>这个选项的作用是通过动态调节标记阶段开始的时间，以达到提升应用程序吞吐量的目标，主要通过尽可能迟地触发标记循环方式来避免消耗老年代空间。</strong></font></p><p>这个选项的值在VM刚开始启动时和-XX:InitiatingHeapOccupancyPercent的值一样，如果出现标记循环阶段内存不够用，则它会自动调节大小，确保标记循环启用更多的堆内存。</p><p>注意，-XX:+G1UseAdaptiveIHOP这个选项会在JDK9里默认启用，即-XX:InitiatingHeapOccupancyPercent和XX:+GIUseAdaptivelHOP在JDK9之后只需要启用一个就可以了。</p><p>JDK8环境下运行该选项会输出:“Unrecognized VM option ‘G1UseAdaptivelHOP’&quot;</p><h3 id="XX-MaxGCPauseMills">-XX:+MaxGCPauseMills</h3><p>这个选项比较重要。它设置了G1的目标停顿时间，单位是ms，默认值为200ms。这个值是一个目标时间，而不是最大停顿时间。G1 GC尽最大努力确保年轻代的回收时间可以控制在这个目标停顿时间范围里面，在G1GC使用过程中，这个选项和-Xms、Xmx两个选项一起使用，它们三个也最好在JVM启动时就一起配置好。</p><h3 id="XX-MinHeapFreeRatio">-XX:+MinHeapFreeRatio</h3><p>这个选项设置堆内存里可以空闲的最小的内存空间大小，默认值为堆内存的40%。当空闲堆内存大小小于这个设置的值时，我们需要判断-Xms和-Xmx这两个值的初始化设置值，如果-Xms和-Xmx不一样，那么我们就有机会扩展堆内存，否则就无法扩展。</p><h3 id="XX-MaxHeapFreeRatio">-XX:+MaxHeapFreeRatio</h3><p>这个选项设置最大空闲空间大小，默认值为堆内存的70%。这个选项和上面那个最小堆内存空闲大小刚好相反，当大于这个空闲比率时，G1 GC会自动减少堆内存大小。需要判断-Xms和-Xmx这两个值的初始化设置值，如果-Xms和-Xmx不一样，那么就有机会减小堆内存，否则就无法减小。</p><h3 id="XX-PrintAdaptiveSizePolicy">-XX:+PrintAdaptiveSizePolicy</h3><p>这个选项决定是否开启堆内存大小变化的相应记录信息打印，即是否打印这些信息到GC日志里面。这个信息对于Parallel GC和G1 GC都很有用。</p><h3 id="XX-ResizePLAB">-XX:+ResizePLAB</h3><p>GC使用的本地线程分配缓存块采用动态值还是静态值进行设置是由这个选项决定的，它默认是开启的，这个设置对应的是GC在提升对象时是否会调整PLAB的大小。</p><p>这个选项大家还是慎用，据说会出现性能问题，启用后可能会增加GC的停顿时间。当应用开启的线程较多时，最好使用-XX:ResizePlaB来关闭PLAB()的大小调整，以避免大量的线程通信所导致的性能下降。</p><h3 id="XX-ResizeTLAB">-XX:+ResizeTLAB</h3><p>Java应用线程使用的本地线程分配缓存块采用动态值还是静态值进行设置是由这个选项决定的，它默认是开启的，即TLAB值会被动态调整。</p><h3 id="XX-ClassUnloadingWithConcurrentMark">-XX:+ClassUnloadingWithConcurrentMark</h3><p>这个选项开启在G1 GC并行循环阶段卸载类，尤其是在老年代的并行回收阶段，默认是开启的。这个选项开启后会在并行循环的重标记阶段卸载JVM没有用到的类，这些工作也可以放在Full GC里面去做，但是提前做了有很大的好处。但因为开启它意味着重标记阶段的GC停顿时间会拉长，这时候我们就要判断性价比了，如果GC停顿时间比我们设置的最大GC停顿目标时间还长，并且需要卸载的类也不多，那还是关闭这个选项吧。</p><h3 id="XX-ClassUnloading">-XX:+ClassUnloading</h3><p>默认值是Ture，决定了JVM是否会卸载所有无用的类，如果关闭了这个选项，无论是并行回收循环，还是Full GC，都不会再卸载这些类了，所以需谨慎关闭。</p><h3 id="XX-UnlockDiagnosticVMOptions">-XX:+UnlockDiagnosticVMOptions</h3><p>这个选项决定是否开启诊断选项，默认值是False，即不开启在GC里面有一些选项称之为诊断选项(Diagnostic Options)，通过-XX:+PrintFlagsFinal 和XX:+Unlock。DiagnosticVMOptions这两个选项组合起来运行，就可以输出并查看这些选项。</p><h3 id="XX-UnlockExperimentalVMOptions">-XX:+UnlockExperimentalVMOptions</h3><p>除了之前说的诊断选项以外，JVM还有一些叫作试验选项(Experimental Options)，这些选项也需要通过XX:+UnlockExperimentalVMOptions这个选项开启，默认是关闭的。</p><p>和诊断选项一样，也可以和-XX:+PrintFlagsFinal选项联合使用，即-XX:+PrintFlagsFinal和-XX:+UnlockExperimental VMOptions这两个选项联合使用时可以输出日志，输出的日志已经包含在了前一个选项-XX:+UnlockDiagnosticVMOptions的运行输出里，这里就不再重复。</p><p>总的来说，这些试验选项对整体应用性能可能会有些好处，但是它们并没有经历完整的测试环节，所以称为试验选项。</p><h3 id="XX-UnlockCommercialFeatures">-XX:+UnlockCommercialFeatures</h3><p>这个选项判断是否使用 Oracle特有的特性，默认是关闭的。</p><p>有一些属性是Oracle公司针对Oracle的Java运行时独有的，没有被包含在OpenJDK里面。举个例子，比如说 Oracle的监控和管理工具Java Mission Control，它有一个特性叫作Java Flight Recorder，这个特性作为Java Mission Control的一部分，属于事件回收框架，可以被用来显示应用程序和JVM的底层信息。</p><h1>深入G1 GC</h1><h2 id="G1-GC概念简介">G1 GC概念简介</h2><h3 id="背景知识">背景知识</h3><p>G1使用了全新的分区算法，其特点如下所示：</p><ul><li>并行性：G1在回收期间，可以有多个GC线程同时工作，可以有效利用多核的计算能力</li><li>并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况。</li><li>分代GC：G1依然是一个分代收集器，但是和之前的各类回收器不同，它同时兼顾了年轻代和老年代。对比其他回收器，它们或者工作在年轻代，或者工作在老年代。</li><li>空间整理：G1在回收过程中，会进行适当的对象移动，不像CMS那样只是简单地标记清理对象。在若干次GC后，CMS必须进行一次碎片整理。而G1不同，它每次回收都会有效地复制对象，减少空间碎片，进而提升内部循环速度。</li><li>可预见性：由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。</li></ul><p><font color="DeepPink"><strong>随着G1 GC的出现，GC从传统的连续堆内存布局逐渐走向了不连续内存块布局，这是通过引入Region概念实现的，也就是说，由一堆不连续的Region组成了堆内存。其实也不能说是不连续的，只是它从传统的物理连续逐渐改变为逻辑上的连续</strong></font>，这是通过Region的动态分配方式实现的，可以把一个Region分配给Eden、Surviⅳvor、老年代、大对象区间、空闲区间等区间的任意一个，而不是固定它的作用，因为越是固定，越是呆板。</p><h3 id="G1的区间设计灵感">G1的区间设计灵感</h3><p><font color="DeepPink"><strong>在G1中，堆被平均分成若干个大小相等的区域(Region)。每个Region都有个关联的Remembered Set(简称RS)，RS的数据结构是Hash表，里面的数据是Card Table(堆中每512byte映射在card table 1byte)。简单地说，RS里面存在的是Region中存活对象的指针。当Region中数据发生变化时，首先反映到Card Table中的一个或多个Card上，RS通过扫描内部的Card Table得知Region中内存使用情况和存活对象。在使用Region过程中，如果Region 被填满了，分配内存的线程会重新选择一个新的Region，空闲Region被组织到一个基于链表的数据结构(LinkedList里面，这样可以快速找到新的Region。</strong></font></p><h2 id="G1-GC分代管理">G1 GC分代管理</h2><h3 id="年轻代">年轻代</h3><p>除非我们显示地通过命令行方式声明了年轻代的初始化值和最大值的大小，否则，<strong>一般来说，初始化值默认是整个Java堆大小的5%(通过选项-XX:G1NewSizePercent设置)，最大值默认是整个Java堆大小的60%(通过选项-XX:G1MaxNewSizePercent设置)。</strong></p><h3 id="回收集合及其重要性">回收集合及其重要性</h3><p>任何一次垃圾回收都会释放CSet里面的所有区间。一个CSet由一系列的等待回收的区间所组成。在一次垃圾回收过程中，这些回收候选区间的存活对象会被整体评估，并且在回收结束后这些区间会被加入到空闲区间队列(LinkedList队列)。在一次年轻代回收过程中，CSet只会包含年轻代区间，而在一个混合回收过程中，CSet会在年轻代区间基础上再包含一些老年代区间，这就是新增的混合回收概念，不再对年轻代和老年代完全切分。</p><p>G1 GC提供了两个选项用于帮助选择进入CSet的候选老年代区间:</p><ul><li>-XX:G1MixedGCLiveThresholdPercent:JDK8u45默认值为一个G1 GC区间的85%。这个值是一个存活对象的阈值，并且起到了从混合回收的CSet里排除一些老年代区间的作用，即可以理解为G1 GC限制CSet仅包含低于这个阈值(默认85%)的老年代区间，这样可以减少垃圾回收过程中拷贝对象所消耗的时间。</li><li>-XX:G1OldCSetRegionThresholdPercent:JDK8u45默认值为整个Java堆区的10%。这个值设置了可以被用于一次混合回收暂停所回收的最大老年代区间数量。这个阈值取决于JVM进程所能使用的Java堆的空闲空间。</li></ul><h3 id="RSet及其重要性">RSet及其重要性</h3><p>一个RSet是一个数据结构，这个数据结构帮助维护和跟踪在它们单元内部的对象引用信息，在G1 GC里，这个单元就是区间(Region)，也就是说，G1 GC里每一个RSet对应的是一个区间内部的对象引用情况。有了RSet，就不需要扫描整个堆内存了，当G1 GC执行STW独占回收(年轻代、混合代回收)时，只需要扫描每一个区间内部的RSet就可以了。因为所有RSet都保存在CSet里面，即Region-RSet-CSet这样的概念，所以一旦区间内部的存活对象被移除，RSet里面保存的引用信息也会立即被更新。这样我们就能够理解RSet就是一张虚拟的对象引用表了，每个区间内部都有这么一张表存在，帮助对区间内部的对象存活情况、基本信息做有序高效的管理。</p><p>G1 GC的年轻代回收或者混合回收阶段，由于年轻代被尽可能地设计为最大量的回收，这样的设计方式减少了对于RSet的依赖，即减弱了对于年轻代里面存储的跟踪引用信息的依赖程度，进而减弱了多余RSet的消耗。G1 GC只在以下两个场景依赖RSet。</p><ul><li>老年代到年轻代的引用：G1 GC维护了从老年代区间到年轻代区间的指针，这个指针保存在年轻代的RSet里面。</li><li>老年代到老年代的引用：G1 GC维护了从老年代区间到老年代区间的指针，这个指针保存在老年代的RSet里面。</li></ul><p>每一个区间只会有一个RSet由于对于对象的引用是基于Java应用程序的需求的，所以有可能会出现RSet内部的“热点”，即一个区间出现很多次的引用更新，都出现在同一个位置的情况。</p><p>对于一个访问很频繁的区间来说，这样的方式会影响RSet的扫描时间。</p><p>注意，区间(Region)并不是最小单元，每个区间会被进一步划分为若干个块(Chunks)。在G1 GC区间里，最小的单元是一个512个字节的堆内存块(Card)。G1 GC为每个区间设置了一个全局内存块表来帮助维护所有的堆内存块，如下图所示：<br><img data-src="/images/java-jvm-gc-g1/%E5%85%A8%E5%B1%80%E5%8D%A1%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><p>当一个指针引用到了RSet里面的一个区间时，包含该指针的堆内存块就会在PRT里面被标记。如果需要快速地扫描一张数据表，最好的方式是建立索引，一个粗粒度的PRT就是基于哈希表建立的。对于一个细粒度的PRT来说，哈希表内部的每一个入口对应一个区间，而区间内部的内存块索引也是存储在位图里面的。当细粒度PRT的最大值被突破的时候，我们就会开始采用粗粒度方式处理PRT。</p><p>在垃圾回收过程中，当扫描RSet并且内存块确实存在于PRT里时，G1 GC会在全局堆内存块数据表里标记对应的入口，这种做法避免了重新扫描这个内存块。G1 GC会在回收循环阶段默认清除内存堆表，在GC线程的并行工作(主要包括根外部扫描、更新和扫描RSet、对象拷贝、终止协议等)完成之后紧跟着的就是清除堆内存表标记(Clear CT)阶段。Update RS和Scan RS对应的是RSet的更新和扫描动作。</p><p>RSet的作用是很明显的，但是在使用过程中我们也遇到了写保护和并行更新线程的维护成本。</p><p>OpenJDK HotSpot的并行老年代和CMS GC都在执行JVM的一个对象引用写操作时使用了写保护机制，如代码object field = some_other_object。还记得我们对于每个区间是采用针对最小单元堆内存块进行管理的吗?这个写保护机制也会通过更新一个类似于堆内存块表的数据结构来跟踪跨年代引用。堆内存表在最小垃圾回收时会被扫描。写保护算法基于Urs Holzle的快速写保护算法，这个算法减少了编译代码时的外部指令消耗。</p><p>当跨越区间的更新发生的时候，G1 GC会将这些对应的堆内存块放入一个缓存，我们可以称这个缓存为“更新日志缓存”，写入该缓存的方式和写入队列的方式一样。G1 GC会使用一个专门的线程组去维持RSet信息，它们的职责是扫描“更新日志缓存”，然后更新RSet。JDK8u45采用选项-XX:G1ConcRefinementThreads设置这个线程组的数量，如果你没有设置，那么默认采用-XX:ParallelGCThreads选项。</p><p>一旦“更新日志缓存”达到了最大可用，它会被放入全局化的满载队列并启用一个新的缓存块。一旦更新线程在全局满载队列里面发现了入口，它们就开始并行处理整个满载缓存队列。</p><p>G1 GC针对并行更新线程采用的是分层方法，为了保证更新速度会加入更多的线程，如果实在跟不上速度，Java应用程序线程也会加入战斗，但尽量不要出现这样的情况，这种情况是发生了线程窃取，会造成应用程序花费了本可以用于自身程序算法运行的能力。</p><h3 id="并行标记循环">并行标记循环</h3><p>并行标记循环的过程是初始标记阶段→根区间扫描阶段→并行标记阶段→重标记阶段→清除阶段，其中一部分是可以与应用程序并行执行的，一部分是独占式的。</p><h4 id="1-初始标记阶段">1.初始标记阶段</h4><p>这个阶段是独占式的，它会停止所有的Java线程，然后开始标记根节点可及的所有对象。这个阶段可以和年轻代回收同时执行，这样的设计方式主要是为了加快独占阶段的执行速度。</p><p>在这个阶段，每一个区间的NATMS值会被设置在区间的顶部。</p><h4 id="2-根区间扫描阶段">2.根区间扫描阶段</h4><p>设置了每个区间的TAMS值之后，Java应用程序线程重新开始执行，根区间扫描阶段也会和Java应用程序线程并行执行。基于标记算法原理，在年轻代回收的初始标记阶段拷贝到幸存者区间的对象需要被扫描并被当作标记根元素，相应地，G1 GC因此开始扫描幸存者区间。任何从幸存者区间过来的引用都会被标记，基于这个原理，幸存者区间也被称为根区间。</p><p>根区间扫描阶段必须在下一个垃圾回收暂停之前完成，这是因为所有从幸存者区间来的引用需要在整个堆区间扫描之前完成标记工作。</p><h4 id="3-并行标记阶段">3.并行标记阶段</h4><p>首先可以明确的是，并行标记阶段是一个并行的且多线程的阶段，可以通过选项-XX:ConcGCThreads来设置并行线程的数量。默认情况下，G1 GC设置并行标记阶段线程数量为选项-XX:ParallelGCThreads(并行GC线程)的1/4。并行标记线程一次只扫描一个区间，扫描完毕后会通过标记位方式标记该区间已经扫描完毕为了满足SATB并行标记算法的要求，G1 GC采用一个写前barrier执行相应的动作。</p><h4 id="4-重标记阶段">4.重标记阶段</h4><p>重标记阶段是整个标记阶段的最后一环。这个阶段是一个独占式阶段，在整个独占式过程中，G1 GC完全处理了遗留的SATB日志缓存、更新。这个阶段主要的目标是统计存活对象的数量，同时也对引用对象进行处理。</p><p>G1 GC采用多线程方式加快并行处理日志缓存文件，这样可以节省下来很多时间，通过选项-XX:ParallelGCThreads可以设置GC数量。</p><p>注意，如果你的应用程序使用了大量的引用对象，例如弱引用、软引用、虚引用、强引用，那么这个重标记阶段的耗时会有所增加。</p><h4 id="5-清除阶段">5.清除阶段</h4><p>前面各个阶段在做的主要事情就是为了标记对象，那么为什么需要针对每一个区间进行标记呢?这是因为如果我们知道了每个区间的存活对象数量，如果这个区间没有一个存活对象，那么就可以很快地清除RSet，并且立即放入空闲区间队列，而不是将这个区间放入排队序列，等待一个混合垃圾回收暂停阶段的回收。RSet也可以被用来帮助检测过期引用，例如，如果标记阶段发现所有在特定堆块上的对象都已经死亡，那么RSet可以快速清除这块堆块。</p><p>一句话总结，清除阶段会识别并清理完全空闲的区域。它是并发的清理，不会引起停顿。</p><h3 id="评估失败和完全回收">评估失败和完全回收</h3><p>如果在年轻代区间或者老年代区间执行拷贝存活对象操作的时候，找不到一个空闲的区间，那么这个时候就可以在GC日志里看到诸如“to-space exhausted”这样的错误日志打印。</p><p>发生这个错误的同时，G1 GC会尝试去扩展可用的Java堆内存大小。如果扩展失败，G1 GC会触发它的失败保护机制并且启动单线程的完全回收动作。</p><p>在这个完全回收阶段，单线程会针对整个堆内存里的所有区间进行标记、清除、压缩等动作。在完成回收后，堆内存就完全由存活对象填充，并且所有的年龄代对应的区间都已经完成了压缩任务。</p><p>也正是因为这个完全回收是单线程执行的，所以当堆内存很大时势必耗时很长，所以需要谨慎使用，最好不要让它经常发生，以避免不必要的长时间的应用程序暂停。</p><h2 id="G1-GC使用场景">G1 GC使用场景</h2><p>如果应用程序具有如下的一个或多个特征，那么将垃圾收集器从CMS或ParallelOldGC切换到G1将会大大提升性能:</p><ul><li>Full GC次数太频繁或者消耗时间太长</li><li>对象分配的频率或代数提升(promotion)显著变化。</li><li>受够了太长的垃圾回收或内存整理时间(超过0.5~1s)</li></ul><p>注意，如果正在使用CMS或ParallelOldGC，而应用程序的垃圾收集停顿时间并不长，那么继续使用现在的垃圾收集器是个好主意。</p><h1>G1 GC性能优化方案</h1><h2 id="G1的年轻代回收">G1的年轻代回收</h2><h3 id="External-Root-Regions">External Root Regions</h3><p><font color="DeepPink"><strong>外部根区间扫描指的是从根部开始扫描通过JNI中本地的类中调用Malloc函数分配出的内存。这个步骤是并行任务的第一个任务。这个阶段堆外(off-heap)根节点被开始扫描，这些扫描范围包括JVM系统字典、VM数据结构、JNI线程句柄、硬件注册器、全局变量，以及线程栈根部等，这个过程主要是为了找到并行暂停阶段是否存在指向当前收集集合(CSet)的指针。</strong></font></p><p>这里还有一个情况需要引起大家的重视，就是查看工作线程是否在处理一个单一的根节点时耗时过长，导致感觉类似挂起的现象。这个现象可以通过查看工作线程对应的“termination”日志看出来。如果存在这个现象，你需要去查看是否存在比较大的系统字典(JVM System Dictionary)，如果这个系统字典被当成了一个单一根节点进行处理，那么当存在大量的加载类时就会出现较长时间的耗时。</p><h3 id="Rememebered-Sets-and-Processed-Buffers">Rememebered Sets and Processed Buffers</h3><p>Rset帮助维护和跟踪指向G1区间的引用，而这些区间本身拥有这些RSet。还记得我们在第4章介绍过的并行Refinement线程吗?这些线程的任务是扫描更新日志缓存，并且更新区间的RSet。为了更加有效地支援这些Refinement线程的工作，在并行回收阶段，所有未被处理的缓存(已经有日志写在里面了)都会被工作线程拿来处理，这些缓存也被称为日志里面的处理缓存。</p><p>为了限制花费在更新RSet上的时间，G1通过选项-XX:MaxGCPauseMills设置了目标暂停时间，采用相对于整个停顿目标时间百分比的方式，限制了更新RSet花费的总时长，让评估暂停阶段把最大量的时候花费在拷贝存活对象上。这个目标时间默认为整个停顿时间的10%，例如整个停顿时间是10s，那么花费在更新RSet上的时间最大为ls。G1 GC的设计目标是让更多的停顿时间花费在拷贝存活对象上面，因此暂停时间的10%被用于更新RSet也是比较合理的，百分比大了，花在干具体业务(各阶段拷贝存活对象)上的时间也就少了。</p><p>如果你发现这个值不太准确或者不符合你的实际需求，这里可以通过更新选项-XX:G1RSetUpdatingPauseTimePercent来改变这个更新RSet的目标时间值。切记，如果你改变了花费在更新RSet上的时间，那你必须有把握工作线程可以在回收暂停阶段完成它们的工作，如果不能，那这部分工作会被放到并行Refinement线程里面去执行，这会导致并行工作量增加、并行回收次数增多。最坏的情况是如果并行Refinement线程也不能完成任务，那么Java应用程序就会被暂停，原本负责执行Java应用程序的资源就会直接接手任务，这个画面“太美”不敢看!大家要尽量避免这种情况发生。</p><p>注意，-XX:G1ConcRefinementThreads选项的值默认和-XX:ParallelGCThreads的值一样，这意味着对于-XX:ParallelGCThreads选项的修改会同样改变-XX:G1ConcRefinementThreads选项的值。</p><p>在当前CSet里面回收之前，CSet内部的每个区间的Rset都需要被扫描，主要目的是找到CSet区间内部的引用关系。一个有较多存活对象的区间容易导致Rset的粒度变细，即每个区间对应的表格会从粗粒度变为细粒度，也可以理解为里面对象增多后扫描一个Rset需要更长的扫描时间，这样你就会看到更多的时间被花费在了扫描RSet上面。也可以理解为扫描时间取决于RSet数据结构的粗细粒度。</p><h3 id="Summarizing-Remembered-Sets">Summarizing Remembered Sets</h3><p>XX:+G1SummarizeRSetStats选项用于统计RSet的密度数量(细粒度或者粗粒度)，这个密度帮助决定是否并行Refinement线程有能力去应对更新缓存的工作，并且收集更多关于Nmethods的信息。这个选项每隔n次GC暂停收集一次RSet的统计信息，这个n次由选项-XX:G1SummarizeRSetStatsPeriod=n决定，也是需要通过选项进行设置的。</p><p>注意，-XX:+G1SummarizeRSetStats选项是一个诊断选项，因此必须启用-XX:+UnlockDiagnosticVMOptions选项才可以启用-XX:+G1SummarizeRSetStats选项。</p><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>G1</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库索引设计与优化 笔记</title>
    <url>/relational-database-index-design-and-the-optimizers.html</url>
    <content><![CDATA[<p>本文整理自：《数据库索引设计与优化》 作者：Tapio Lahdenmaki，Michael Leach</p><p>出版时间：2015-06-01</p><a id="more"></a><h1>概述</h1><h2 id="索引误区">索引误区</h2><h3 id="误区1：索引层级不要超过5层">误区1：索引层级不要超过5层</h3><p>由于非叶子页通常都会留在内存或者读缓存中，所以通常索引任意一个叶子页的时间为10ms~20ms，这是固定的。所以，对索引层数的限制是没有什么意义的。</p><h3 id="误区2：单表的索引数不要超过6个">误区2：单表的索引数不要超过6个</h3><p>我建议不要给表的索引数目设置上限。</p><p>保证所有的SQL语句都能够流畅运行是设计的底线。我们总能找到一种方法来达到这一点。如果为了达到这一点需要在表上创建10个索引，那么你就应该在表上建立10个索引。</p><h3 id="误区3：不应该索引不稳定的列">误区3：不应该索引不稳定的列</h3><p><font color="DeepPink"><strong>索引行是按索引键的顺序存储的，所以当索引键中存一列被更新时，DBMS可能不得不把相应的行从旧的索引位置移到新的位置来保持这一顺序。这个新的位迓可能与旧的位置位于相同的叶子页上，在这种情况下，只有一个页会受到影响。然而，如果被修改的键是第一列或唯一的列，那么新的索引行可能必须被迁移到一个不同的叶子页上，即DBMS必须更新两个叶子页。三十年前，如果这个索引为一个4层索引，这也许需要6次磁盘随机读取：3次常规读取，即2次非叶子页读取和1次叶子页读取，加上新的位置所涉及的3次随机读取。当一次随机读取耗时30ms 时，迁移一个索引行可能会给该更新操作额外增加6 x 30ms =180ms 的响应时间。因此，不稳定的列很少被索引就不足为奇了。</strong></font></p><p><font color="DeepPink"><strong>现在，当四层索引中三个层级的非叶子页保留在内存中时，一次磁盘随机读取需要 l0 ms ，响应的时间变成了 2 x 10ms = 20ms 。此外，许多索引为多列索引，也称作复合或组合索引，它通常包含多列，以使得索引键值唯一。当不稳定的列为复合索引的尾列更新这个不稳定的列绝不会导致其迁移到新的叶子页。因此，在当前的磁盘条件下，更新一个不稳定的列只会对该更新操作增加10ms的响应时间。</strong></font></p><p>在当前磁盘条件下，只有在更新频率多于10次/秒的情况下，不稳定列才可能成为问题。</p><blockquote><p>创建索引的目的应该是在硬件容量限制的前提下保证所有的数据库调用运行的足够快。</p></blockquote><h2 id="系统化的索引设计">系统化的索引设计</h2><ul><li>找到由于索引不合适而导致运行<strong>太慢</strong>的查询语句<br>最差输入：导致执行时间最长的变量值</li><li>设计索引，使所有查询语句都运行的足够快<br>表的维护（插入、更新、删除）也必须足够快</li></ul><h1>表和索引结构</h1><p>DBMS 会意识到多个索引或表页需要被顺序地读取，且能识別出那些不在缓冲池中的页。随后，它将发出多页I/O请求，每次请求的页的数量由DBMS决定。<font color="DeepPink"><strong>只有那些不在缓冲池中的页会被从磁盘服务器上读取，因为那些已经在缓冲池中的页中可能包含了尚未被写人磁盘的更新数据。</strong></font></p><h1>SQL处理过程</h1><h2 id="谓词">谓词</h2><p>WHERE子句由一个或者多个<font color="DeepPink"><strong>谓词（搜索参数）</strong></font>组成。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># SQL 3.1</span><br><span class="line">WHERE SEX = &apos;M&apos;</span><br><span class="line">      AND</span><br><span class="line">      (WEIGHT &gt; 90</span><br><span class="line">      OR</span><br><span class="line">      HEIGHT &gt; 190)</span><br></pre></td></tr></table></figure><p>SQL 3.1中有三个简单谓词，它们是：</p><ul><li>SEX = ‘M’</li><li>WEIGHT &gt; 90</li><li>HEIGHT &gt; 190</li></ul><p>同样，它们也可以被认为是两个组合谓词：</p><ul><li>WEIGHT &gt; 90 OR HEIGHT &gt; 190</li><li>SEX = ‘M’ AND ( WEIGHT &gt; 90 OR HEIGHT &gt; 190 )</li></ul><p>谓词表达式是索引设计的主要入手点。如果一个索引能够满足SELECT查询语句的所有谓词表达式，那么优化器就很有可能建立起一个高效的访问路径。</p><p>核实确认访问路径（执行计划）<br><img data-src="/images/database-index-design-optimizers/%E4%BC%98%E5%8C%96%E5%99%A8%E4%BD%95%E6%97%B6%E9%80%89%E6%8B%A9%E8%AE%BF%E9%97%AE%E8%B7%AF%E5%BE%84.png" alt></p><h1>为SELETE语句创建理想的索引【重点】</h1><blockquote><p>很多调优人员（尽管没经验）认为，如果一个SQL语句使用了索引，那这个 SQL就是被很好地优化过的，我对此感到很惊讶。你应该总是问自己，“这是不是可用的最好的索引？” 或 “再添加另外一个索引能否提升响应性能？”，又或者 “全表扫描会不会更快地返回结果？”</p></blockquote><h2 id="三星索引">三星索引</h2><blockquote><p>三星索引：查询语句的理想索引。</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DECLARE CURSOR41 CURSOR FOR</span><br><span class="line">SELECT    CNO, FNAME</span><br><span class="line">FROM      CUST</span><br><span class="line">WHERE     LNAME = :LNAME</span><br><span class="line">          AND</span><br><span class="line">          CITY  = :CITY</span><br><span class="line">ORDER BY  FNAME</span><br></pre></td></tr></table></figure><p><img data-src="/images/database-index-design-optimizers/%E5%9B%BE4.2.png" alt></p><h2 id="星级是如何给定的">星级是如何给定的</h2><p>如果与一个查询相关的索引行是相邻的，或者至少相距足够靠近的话，那这个索引就可以被标记上第一颗星。这<font color="DeepPink"><strong>最小化</strong></font>了必须扫描的索引片的宽度。</p><p>如果索引行的顺序与查询语句的需求一致，则索引可以被标记上第二颗星。这<font color="DeepPink"><strong>排除了排序操作</strong></font>。</p><p>如果索引行包含的查询语句中的所有列，那么索引就可以被标记上第三颗星。这避免了访问表的操作：<font color="DeepPink"><strong>仅访问索引就可以了</strong></font>。</p><p><font color="DeepPink"><strong>对于这三颗星，第三颗通常是最重要的。将一个列排除在索引之外可能会导致许多速度较慢的磁盘随机读。</strong></font>我们把一个至少包含第三颗星的索引称为对应查询语句的宽索引。</p><blockquote><p>宽索引：宽索引是指一个至少满足第三颗星的索引。该索引包含了SELECT语句所涉及的所有列，因而能够使得查询只需访问索引而无需访问表。</p></blockquote><p><strong>为了满足第一颗星</strong><br>首先取出所有等值谓词的列（WHERE COL=…）。把这些列作为索引最开头的列——以任意顺序都可以。对于CURSOR41来说，三星索引可以以LNAME、CITY或者以CITY、LNAME开头。在这两种情况下，必须扫描的索引片宽度将被缩减至最窄。</p><p><strong>为了满足第二颗星</strong><br>将ORDER BY列加入到索引中。不要改变这些列的顺序，但是忽略那些在第一步中已经加入索引的列。例如，如果CURSOR41在ORDER BY 中有重复的列，如ORDER BY LNAME、FNAME或者是ORDER BY FNAME、CITY，只有FNAME需要在这步中被加入到索引中去。当FNAME是索引的第三列时，结果集中的记录无须排序就已经是以正确的顺序排列的了。第一次读取操作将返回FNAME值最小的那一行。</p><p><strong>为了满足第三颗星</strong><br>将查询语句中剩余的列加到索引中去，列在索引中添加的顺序对查询语句的性能没有影响，但是将易变的列放在最后能降低更新的成本。现在，索引已包含了满足无须回表的访问路径所需的所有列。</p><p>最终三星索引将会是：(LNAME, CITY, FNAME, CNO) 或 (CITY, LNAME, FNAME, CNO)</p><p>CURSOR41在以下方面是最为挑剔的：</p><ul><li>WHERE 条件不包含范围谓词（BETWEEN、&gt;、&gt;=等）</li><li>FROM 语句只涉及单表</li><li>所有谓词对于优化器来说都足够简单</li></ul><h2 id="范围谓词与三星索引">范围谓词与三星索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DECLARE CURSOR43 CURSOR FOR</span><br><span class="line">SELECT    CNO, FNAME</span><br><span class="line">FROM      CUST</span><br><span class="line">WHERE     LNAME BETWEEN :LNAME1 AND :LNAME2</span><br><span class="line">          AND</span><br><span class="line">          CITY  = :CITY</span><br><span class="line">          ORDER BY  FNAME</span><br></pre></td></tr></table></figure><p>让我们尝试为这个 CURSOR 设计一个三星索引。大部分的推论与 CURSOR41 相同，但是“BETWEEN 谓词”将“=谓词”替代后将会有很大的影响。我们将会以相反的顺序依次考虑三颗星，按理说，这代表了理解的难度。</p><p>首先是最简单的星（虽然非常重要），第三颗星。按照先前所述，<strong>确保查询语句中的所有列都在索引中就能满足第三颗星。这样不需要访问表，那么同步读也就不会造成问题。</strong></p><p>添加 ORDER BY 列能使索引满足第二颗星，但是这个仅在将其放在 BETWEEN 谓词列 LNAME 之前的情况下才成立，如索引 (CITY, FNAME, LNAME)。由于 CITY 的值只有一个（=谓词），所以使用这个索引可以使结果集以 FNAME 的顺序排列，而不需要额外的排序。但是如果 ORDER BY 字段加在 BETWEEN 谓词列 LNAME 后面，如索引 (CITY, LNAME, FNAME)，那么索引行不是按 FNAME 顺序排列的，因而就需要进行排序操作。因此，为了满足第二颗星，FNAME 必须在 BETWEEN 谓词列 LNAME 前面，如索引 (FNAME, …) 或索引 (CITY, FNAME, …)。</p><p>再考虑第一颗星，如果 CITY 是索引的第一个列，那我们将会有一个相对较窄的索引片需要扫描（MC=1），这取决于 CITY 的过滤因子。但是如果用索引 (CITY, LNAME, …) 的话，索引片会更窄，这样在有两个匹配列的情况下我们只需要访问真正需要的索引行。但是，为了做到这样，并从一个很窄的索引片中获益，其他列（如 FNAME）就不能放在这两列之间。</p><blockquote><p>MC:match column（匹配列）</p></blockquote><p>所以我们的理想索引会有几颗星呢？首先它一定能有第三颗星，但是，正如我们刚才所说，我们只能有第一颗星或者第二颗星，而不能同时拥有两者！换句话说，我们只能二选一：</p><ul><li>避免排序 — 拥有第二颗星</li><li>拥有可能的最窄索引片，不仅将需要处理的索引行数降至最低，而且将后续处理量，特别是表中数据行的同步读，减少到最少 — 拥有第一颗星</li></ul><p>在这个例子中，BETWEEN 谓词或者任何其他范围谓词的出现，意味着我们不能同时拥有第一颗星和第二颗星。也就是说我们不能拥有一个三星索引。这就意味着我们需要在第一颗星和第二颗星中做出选择。通常这不是一个困难的选择，<strong>因为第一颗星一般比第二颗星更重要，虽然并不总是这样</strong>。</p><h2 id="为查询语句设计最佳索引的算法">为查询语句设计最佳索引的算法</h2><p><font color="DeepPink"><strong>根据以上的讨论，理想的索引是一个三星索引。然而，正如我们所见，当存在范围谓词时，这是不可能实现的。我们（也许）不得不牺牲第二颗星来满足一个更窄的索引片（第一颗星），这样，最佳索引就只拥有两颗星。这也就是为什么我们需要仔细区分理想和最佳。</strong></font>在这个例子中理想索引是不可能实现的。将这层因素考虑在内，我们可以对所有情况下创建最佳索引（也许不是理想索引）的过程公式化。创建出的索引将拥有三颗星或者两颗星。</p><p><strong>首先设计一个索引片尽可能窄（第一颗星）的宽索引（第三颗星）。如果查询使用这个索引时不需要排序（第二颗星），那这个索引就是三星索引。否则这个索引只能是二星索引，牺牲第二颗星。或者采用另一种选择，避免排序，牺牲第一颗星保留第二颗星。这种二星索引中的一个将会是相应查询语句的最佳索引。</strong></p><h3 id="为查询语句创建最佳索引的算法">为查询语句创建最佳索引的算法</h3><h4 id="候选-A">候选 A</h4><ol><li>取出对于优化器来说不过分复杂的等值谓词列。将这些列作为索引的前导列(以任意顺序皆可)。</li><li>将选择性最好的范围谓词作为索引的下一个列，如果存在的话。最好的选择性是指对于最差的输入值有最低的过滤因子。只考虑对于优化器来说不过分复杂的范围谓词。</li><li>以正确的顺序添加ORDER BY语列，忽略在第一步或者第二步已添加的列。</li><li>以任意顺序将 SELECT 语句中其余的列添加至索引中（但是需要以不易变的列开始）。</li></ol><p>举例：CURSOR43</p><p>候选 A 为 (CITY, LNAME, FNAME, NCNO)。</p><p>由于 FNAME 在范围谓词列 LNAME 的后面，候选 A 引起了 CURSOR43 的一次排序操作。</p><h4 id="候选-B">候选 B</h4><p>如果候选 A 引起了所给查询语句的一次排序操作，那么还可以设计候选 B。根据定义，对于候选 B 来说第二颗星比第一颗星更重要。</p><ol><li>取出对于优化器来说不过分复杂的等值谓词列。将这些列作为索引的前导列(以任意顺序皆可)。</li><li>以正确顺序添加 ORDER BY 列（如果 ORDER BY 列有 DESC 的话，加上 DESC）。忽略在第1步中已经添加的列。</li><li>以任意顺序将 SELECT 语句中其余的列添加至索引中（但是需要以不易变的列开始）。</li></ol><p>举例：CURSOR43</p><p>候选 B 为 (CITY, FNAME, LNAME, CNO)。</p><blockquote><p>需要注意的是，到目前为止，我们所做的只是设计理想索引或是最佳索引。但是这是否是实际可行的，我们在这个阶段还不好说。</p></blockquote><h1>前瞻性的索引设计</h1><h2 id="基本概念">基本概念</h2><h3 id="访问">访问</h3><p>根据定义，DBMS读取一个索引行或一个表行的成本称为一次访问 : 索引访问或表访问。如果DBMS扫描索引或表的一个片段(被读取的行在物理上是彼此相邻的)，那么第一行的读取即为一次随机访问。对于后续行的读取，每行都是一次顺序访问。在当前的硬件条件下，顺序访问的成本比随机访问的成本低得多。一次索引访问的成本与一次表访问的成本基本上是相同的。</p><h3 id="读取一组连续的索引行">读取一组连续的索引行</h3><p>物理上彼此相邻是什么意思?</p><p>索引上的所有行都通过指针链接在一起，链接的先后顺序由索引的键值严格定义。当几个索引行的键值相同时，就根据索引行存储的指针值进行链接。在传统的索引设计(从某个角度看，是理想化的)中，链表从LP1(叶子页1)开始，随后链接LP2，以此类推。这样(假设每个磁道可以放12个叶子页，当前的硬件通常可以容纳更多)，叶子页就组成了一个连续的文件，LP1至LP12存储在磁盘柱面的第一个磁道，LP13至LP24存储在下一个磁道，如此继续，当第一个柱面存满后，下一组LP就会被存储在下一个柱面的首个磁道上。换句话说，就是叶子页之间没有其他页。</p><p>现在，读取一个连续的索引行(即一个索引片，或者包含了单个键值或者一个范围的键值所对应的索引行)就非常快了。一次磁盘旋转会将多个叶子页读取进内存中，而且只有在磁盘指针移到下一个柱面时才需要进行一次短暂的寻址、</p><p>不过，这个完美的顺序还是会被打破的，至少有以下三个影响因素 :</p><ol><li>如果一个叶子页没有足够的空间存储新插入的索引行，那么叶子页就必须被分裂。之后链表仍会按照正确的顺序链接索引行，但是这与底层的物理存储顺序就不再一致了，一些按道理应该是顺序的访问就变成随机访问了。不过索引的充足可以再次恢复最理想的顺序。</li><li>意向不到的数据增长可能会填满原本连续的空间(区或类似的概念)。操作系统于是就会寻找另外有一个连续的空间，并将它连接到原来空间的后面。这时候从第一个区跨到第二个区访问就会产生一次随机访问，不过这种情况影响不大。<br>3.RAID 5条带会将前几个叶子页存储在一个驱动器上，将后面的叶子页存放在另外的驱动器上。这就会产生额外的随机读，但实际上条带的积极作用要大过随机读带来的性能恶化，一个智能的磁盘服务器可以将后续的叶子页并行的从多个驱动器上读取至磁盘缓存中，从而大大降低了单个叶子页的I/O时间。此外，在RAID 5条带策略下，一个被频繁访问的索引的不太可能导致某一个磁盘负载过高，因为I/O请求会被均匀低分布到RAID 5阵列内的多个磁盘驱动器。</li></ol><p>忽略上述情况，我们仍然假设，如果两个索引行在链表上彼此相邻(或者在唯一索引中，相同键值的行指针意味着彼此相邻)，那么我们就认为这两行在物理上也相邻。这就意味着QUBE认为所有的索引都有最理想的顺序。</p><h3 id="读取一组连续的表行">读取一组连续的表行</h3><p>读取一组连续的表行有如下两种情况：</p><ol><li>全表扫描<br>从TP1(表页1)开始，读取该页上所有的记录，然后再访问TP2，一次类推。按照记录在表页中存储的顺序进行读取，没有其他特殊的顺序。</li><li>聚簇索引扫描<br>读取索引片上第一个索引行，然后获取相应的表行，再访问第二个索引行，以此类推。如果索引行与对应的表行记录顺序完全一致(聚簇率为100%)，那么除了第一次之外的所有表访问就都是顺序访问。表记录的链接方式跟索引不一样。单个表页中记录的顺序无关紧要，只要访问的下一个表记录在同一个表页或者相邻的下一个表页内就可以了。</li></ol><p>同索引一样，存储表的传统方式也是将所有表页保留在一个连续的空间内。引起顺序杂乱或碎片化的因素也和索引中的相似，但又两个地方不同：</p><ol><li>如果往表中插入的记录在聚簇索引所定义的主页中装不下，则通常不会移动现有的行，而是会将新插入的记录存储到离主页尽可能近的表页中。对第二个页的随机I/O会使聚簇索引扫描变得更慢，但是如果这条记录离主页很近，这些额外的开销就可以被避免，因为顺预读功能会一次性将多个表页装载到数据库缓存中。即使顺序预读功能没有使用，也只有当该页在数据库缓存被覆盖的情况下才会发生额外的随机I/O。</li><li>一条记录被更新后，可能因为表行过长导致其无法再存储于当前的表页中。这是DBMA就必须将该行记录迁移至另外一个表页中，同时在原有的表页中存储指向新表页的指针。当该行被访问时，会引入额外的随机访问。<br>表可以通过重组来还原行记录的顺序，从而减少不必要的随机访问。</li></ol><h2 id="计算访问次数">计算访问次数</h2><h3 id="随机访问">随机访问</h3><p>我们首先思考一下磁盘读与访问的区别。**一次磁盘读所访问的对象是一个页，而一次访问的访问对象则是一行。**一次随机磁盘读会将一整页(通常会包含很多行)读取至数据库的缓冲池中，但是根据定义，前后两次随机读不太可能会访问到同一个页。</p><h2 id="使用满足需求的成本最低的索引还是所能达到的最有索引">使用满足需求的成本最低的索引还是所能达到的最有索引</h2><p><font color="DeepPink"><strong>当有多个等值谓词作为匹配列时，我们需要考虑这些列在索引上的先后顺序。经常变化的列应当尽可能的排在后面。</strong></font></p><blockquote><p>更改现有索引列的顺序和在现有索引列之间添加新列同样危险。在这两种情况下，现有的select的执行速度都可能会急剧下降，因为匹配列减少了，或者引入了排序(导致过早产生结果集)</p></blockquote><h2 id="半宽索引-最大化索引过滤">半宽索引(最大化索引过滤)</h2><p>在现有索引的末端添加缺少的谓词列可以消除大量的随机访问，因为这样能引入索引过滤过程。</p><h1>影响索引设计过程的因素</h1><p>I/O时间估算:</p><ul><li>随机读取 10ms(页的大小为4KB或8KB)</li><li>顺序读取 40MB/s</li></ul><p>这些数据是假定系统使用当前硬件并在一个合理的负载下运行时的值。一些系统可能运行的更慢或处理超负荷状态。</p><h2 id="困难谓词">困难谓词</h2><p>大体上，假设一个谓词的判定结果为false，而这时如果不检查其他谓词就不能确定地将一行记录排除在外，那么这类谓词对优化器而言就是太过困难的。</p><h2 id="过滤因子隐患">过滤因子隐患</h2><p>当以下三个条件同时满足时，这种过滤因子隐患可能会产生 :</p><ul><li>访问路径中没有排序</li><li>第一屏结果一建立就回应</li><li>不是所有的谓词字段都参与定义带扫描的索引片–换句话说就是，不是所有的字段都是匹配字段。</li></ul><h1>被动式索引设计</h1><blockquote><p>被动式的方法与莱特兄弟创造守架飞机的经历非常相似。本质上就是把查询放在一起，推下悬崖，然后看他能否起飞。换句话说，就是为应用设计一个没有索引的原型，然后开始运行一些查询。又或者，创建原始索引集，然后通过运行应用来看那些索引被用到，那些没有被用到。即使是一个小型的数据库系统，运行速度慢的查询也会被很快凸显出来。</p><p>被动式调优的方法也被用来理解和调优一个性能没有满足预期的已有应用。</p></blockquote><h2 id="对结果集排序">对结果集排序</h2><p>除了全表扫描和全索引扫描，结果集的排序就是最有用的警示信号了。引起排序的原因可能有以下两种:</p><ul><li>没有可使查询语句避免排序的索引。</li><li>优化器所选择的访问路径包含了一次多余的排序。</li></ul><blockquote><p>有很多数据库顾问将排序视为敌人。我们认为，哪些强调随机I/O带来致命影响的顾问更值得信任。</p></blockquote><h2 id="成本估算">成本估算</h2><p>一些数据库管理系统的EXPLAIN功能显示了优化器对所选访问路径的本地响应时间的估算，或至少显示了对CPU时间的估算。</p><p>不幸的是，以下两个严重问题限制了使用成本估算方法的价值:</p><ul><li>优化器所做出的的本地响应时间估算可能与实际相差很大</li><li>当谓词使用绑定变量时(显然这是很普遍的)，优化器对过滤因子的估算是基于平均输入值的，或更差情况下，基于默认值。为了获取更有价值的最差情况估值，EXPLAIN中的绑定变量必须用最差情况下的输入值来代替。这是一个需要应用知识的累人操作。</li></ul><h1>为表连接设计索引</h1><h2 id="预测表的访问顺序">预测表的访问顺序</h2><p>在大部分情况下，可以使用以下经验法则来预测最佳的表访问顺序 : 将包含<strong>最低数量本地行</strong>的表作为外层表。</p><blockquote><p>本地行的数量是指最大过滤因子过滤本地谓词之后所剩余的行数。</p></blockquote><p>经验法则忽略了以下因素:</p><ol><li>排序。</li><li>很小的表。<font color="DeepPink"><strong>非常小的表及其索引可能长期存在于数据库的缓冲池中</strong></font>，至少在一个连接查询中，没有页会被读取多次。在这样的表和索引上进行随机读取所耗费的时间小于0.1ms，至少在页被第一次读取之后是这样的。所以，当这样的表不是外层表时，对其大量的随机读取也不会称为问题。</li><li>聚簇比例。索引中行的顺序和表中行的顺序的关联性(对于聚簇索引而言，该关联性在表重组后为100%)，可能会影响对最佳访问顺序的选择，当然，除非索引是宽索引。</li></ol><p>最好的基于成本的优化器在进行路径选择时会把这些因素考虑进来。因此，他找出的访问顺序可能比我们基于本地行的数量的经验所得出的结果更优。</p><h2 id="合并扫描连接和哈希连接">合并扫描连接和哈希连接</h2><h3 id="合并扫描连接">合并扫描连接</h3><p>执行过程如下</p><ul><li>执行表或索引扫描以找出满足本地谓词的所有行。</li><li>随后可能会进行排序，如果这些扫描未按所要求的顺序提供结果集。</li><li>对前两者生成的临时表进行合并。</li></ul><p>在以下情况下，合并扫描会比嵌套循环快。</p><ol><li>用于连接的字段上没有可用的索引。在这种情况下，若使用嵌套循环，那么内层表可能需要被扫描很多次。在实际情况中，用于连接的列上面没有索引的情况很少见，因为大部分连接谓词都是基于“主键等于外键”这一条件的。</li><li>结果表很大。在这种情况下，若使用嵌套循环连接，可能会导致相同的页被不断的重复访问。</li><li>连接查询中不止一张表的过滤因子很低。如我们所见，嵌套循环可能导致对内层表(或者内层表索引)的大量随机访问。</li></ol><p>例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DECLARE CURSOR81 CURSOR FOR</span><br><span class="line">SELECT CNAME, CTYPE, INO, IEUR</span><br><span class="line">FROM CUST, INVOICE</span><br><span class="line">WHERE CUST.CTYPE = :CTYPE</span><br><span class="line">      AND</span><br><span class="line">      IDATE &gt; :IDATE</span><br><span class="line">      AND</span><br><span class="line">      CUST.CNO = INVOICE.CNO</span><br></pre></td></tr></table></figure><h3 id="哈希连接">哈希连接</h3><p>哈希连接本质上是用哈希算法代替排序算法的合并扫描连接。首先，对较小的结果集用哈希算法计算其连接字段，并将其保存在一个临时表中；然后，再扫描其他的表(或索引片)，并通过(计算得到的)哈希值将满足本地谓词条件的每一行记录与临时表中相应的行进行匹配。</p><p>若结果行集已在索引中满足了所要求的顺序，那么合并扫描的速度将更快。若合并扫描需要进行排序，那么哈希连接的速度可能更快，尤其是当其中一个行集能够全部留在内存中时(对一个哈希表进行一次随机访问所花费的CPU时间，通常会比排序和合并一行所花费的时间少)。如果两个行集很大，那么哈希表会根据可用内存的大小对哈希表进行分区(同一时间内存中只有一个分区)，而另外一个行集会被扫描多次。</p><h2 id="为什么连接的性能表现较差">为什么连接的性能表现较差</h2><h3 id="模糊的索引设计">模糊的索引设计</h3><p>“在连接字段上建索引”是最古老的索引建议之一。事实上，这是基于建议的一个扩展 : “<strong>为主键创建一个索引，并且为每一个外键创建一个由此外键作为前导列的索引</strong>”。在连接谓词上建索引使得嵌套循环称为一个可行的方案，但包含连接谓词列并不一定能够提供完全可接受的响应时间。连接谓词列上的索引和本地谓词上的索引通常都需要是宽索引。而且，不同的表访问顺序可能导致完全不同的索引需求。</p><h2 id="为子查询设计索引">为子查询设计索引</h2><p>从性能的角度看，子查询与连接十分相似。**实际上，现今的优化器通常会在进行访问路径的选择之前，先将子查询重写为一个连接。**若优化器没有进行重写，那么子查询的类型本身可能就决定了表访问顺序。内外层无关联的子查询通常会从最内层的SELECT开始执行。结果集被保存在一张临时表中，等待下一个SELECT的访问。内外层有关联的子查询通常会从最内层的SELECT开始执行。无论是何种情况，同连接一样，应当基于能够形成最快访问路径的表访问顺序进行索引设计。若最佳的表访问顺序未被选中，那么程序开发人员可能需要对语句进行重写，在某些情况下还可能要使用连接。</p><h2 id="为UNION语句设计索引">为UNION语句设计索引</h2><p>通过UNION或UNION ALL连接的SELECT语句是逐个分别进行优化和指向的。因此，应该为每个独立的SELECT设计合适的索引。需要注意一点，带ORDER BY的UNION可能会导致提前物化。</p><h2 id="对于表设计的思考">对于表设计的思考</h2><h3 id="冗余数据">冗余数据</h3><p>有两种通过冗余数据优化连接速度的方法：</p><ol><li>将某列拷贝至依赖表(向下反范式法)。</li><li>将汇总数据添加至父表(向上反范式法)。</li></ol><h3 id="向下反范式化">向下反范式化</h3><p>不过，总体而言，当我们考虑引入向下反范式化时，需要预测一下冗余字段更新时可能会导致最差情况下的索引随机访问次数。</p><h3 id="反范式化的成本">反范式化的成本</h3><p>考虑性能时最令人关注的通常是，为了更新表及索引上的冗余字段锁带来的I/O时间。在向下反范式化中，这可能需要移动大量的索引行，从而导致一个简单的UPDATE运行的很慢。向上反范式化不太可能因为一次简单的更新操作而引发I/O剧增。不过INSERT，UPDATE和DELETE可能导致父表及其索引上的一些额外I/O。在极端情况下，如每秒10次以上的INSERT或UPDATE，由这些I/O带来的磁盘负载可能会成为问题。</p><h2 id="嵌套循环连接和合并扫描连接-哈希连接-VS-反范式化">嵌套循环连接和合并扫描连接/哈希连接 VS 反范式化</h2><p>许多数据库专家不愿意将冗余列添加至事务型表上，这是可以理解的。反范式化不仅仅是查询速度和更新速度之间的一个权衡，在某种程度上，他还是性能和数据完整性之间的一个权衡，即使在使用触发器来维护冗余数据的情况下。然而，当嵌套循环引入了过多的随机访问，且MS/HJ耗费了过多的CPU时间时，反范式化可能成为唯一的选择。尽管如此，在决定采用这一极端的方案之前，我们必须确保所有能够避免这一方案的方法都已经考虑过了。</p><h2 id="无意识的表设计">无意识的表设计</h2><p>从性能的角度看，我们非常难以理解为何有那么多的数据库中存在具有1 : 1或1: C(C = 有条件的;即0或1)关系的表。</p><p>为何要建四张表而非只建一张CUST表？只要关系永远不会变成1 : M，那么灵活性就不会成为问题。在本例中，客户要么是公司，要么是个人，且不会有客户死亡两次!</p><p>将这四张表合成一张部分字段为空的表(对于每一行，要么公司相关的字段为空，要么个人相关的字段为空；同样，所有活着的客户的死亡相关的字段为空)，这是存储空间和性能(随机访问的次数)之间的权衡。为空的数据并不违反范式。</p><p>在不考虑硬件性能的情况下设计表可能会有如下问题 :</p><ul><li>即便是在最佳索引条件下，随机访问的次数仍可能会很高。</li><li>复杂连接可能使得索引设计变得非常困难。</li><li>优化器可能对复杂连接做出错误的访问路径选择。</li></ul><h1>星型连接</h1><h2 id="介绍">介绍</h2><p>星型连接与普通连接的差别主要有两个方面：</p><ol><li>如下图所示，位于星型结构中心位置的表称为<strong>事实表</strong>，它的数据量远大于它周围的表—<strong>维度表</strong>。</li><li>最佳的访问路径通常是包含维度表的<strong>笛卡尔积</strong>，这意味着他们<strong>没有相同的冗余列</strong>，满足本地谓词的维度表数据行都会参与连接。</li></ol><p><img data-src="/images/database-index-design-optimizers/%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F.png" alt></p><p>SALES 销售记录<br>STORE 出售的店铺<br>ITEM 出售的商品<br>DATE 出售的时间<br>CUST 出售的客户</p><p>在星型连接中，事实表的数据量通过都比较大。在这种情况下，至少依据经验法则，事实表应该作为嵌套循环连接方式中最内层的表。一般情况下未读表都没有共同的列，所以这种链接顺序意味着是笛卡尔连接。</p><h2 id="事实表的索引">事实表的索引</h2><p>事实上，宽索引通常比事实表还大，原因有两个 :</p><ol><li>表通常都进行了压缩处理，而索引没有。</li><li>新增一条记录通常都追加到表的尾部，因此事实表并不需要分散的空闲空间。但插入到索引(除了聚簇索引)上的位置是随机的。为了避免频繁的索引重组，在当前硬件条件下，通常10亿行的表将花费几个小时，大多数的索引在叶子节点上都需要留出足够的空闲空间，可能为30% ~ 40%。</li></ol><h2 id="汇总表">汇总表</h2><p>即使是在理想索引的情况下，一些针对10亿条记录的事实表进行的查询也会导致大量的I/O访问。提高这类查询的性能的唯一方式就是使用汇总表(查询表)。这类表是反范式化的事实表。如果表不是特别大(比如只包含几百万行数据)，那么这是一个比较可行的方案，因为反模式化查询只需针对汇总表，而不需要多表关联。</p><p>如果频繁查询每周的销售情况，那么可以针对每周的消费记录建立一张汇总表。比较好的汇总表设计是根据周，商品，商店汇总一条记录。汇总表根据周和商品进行汇总后，数据量可以大幅度减少。在这种情况下，查询的响应时间可能降低到不到1秒钟。</p><p>汇总表上的索引通常会比较小，他唯一的显示因素就是刷新此表所需的时间。如同所有新鲜事物一样，汇总表的方案也会带来新的问题。</p><ol><li>如果用户的查询需求多样，汇总表的设计会比索引的设计更困难，不过，已经有一些工具基于查询日志来协助汇总表的设计。</li><li>如果优化器不能选择正确的汇总表，那么汇总表的意义就不大；我们不能指望用户来指定查询使用某个合适的汇总表。最好的优化器已经在试着访问合适的表了，虽然SELECT语句实际上查询的是事实表。如果优化器不具备这个能力，或者它的正确率不够高，那么可能就不得不强制指定每个用户只能访问一个汇总表。用户不得不自己选择要使用的汇总表。优化器能自动识别的汇总表通常被称为自动汇总表或物化视图。</li></ol><h1>多索引访问</h1><h2 id="简介">简介</h2><p>许多数据库管理系统支持从一张表的多个索引处收集制作，或是从单个索引的几个索引片收集，然后比较这些指针集并访问满足WHERE语句中所有谓词条件的数据行。这一能力被称为多索引访问，或被称为索引与(索引交集)和索引或(索引并集)。</p><blockquote><p>多索引访问的思想是：对表中数据分别使用各个索引，最后将满足条件的进行交集或并集操作。</p></blockquote><h1>索引和索引重组</h1><h2 id="DBMS如何查找索引行">DBMS如何查找索引行</h2><p><font color="DeepPink"><strong>在当前的硬件条件下，非叶子页很可能已经被缓存在数据库缓冲池中，或者至少在磁盘的读缓存中，因为它们经常被频繁的访问。</strong></font></p><h2 id="插入一行会发生什么？">插入一行会发生什么？</h2><p>如果一张表有一个聚簇索引，那么DBMS会根据聚簇索引的键值尝试将插入的记录放在它所属的表页(主页)中。如果这行记录在主页里放不下，或者当前页被锁住，那么DBMS将会检查邻近的页。在最坏的情况下，新的行会被插入到标的最坏一页。<font color="DeepPink"><strong>依赖于DBMS和表的类型，已经插入的行通常都不会被移动，否则这将意味着更新表上已经建立的所有索引上的相关指针。</strong></font>当有许多表行未能存在在主页中时，如果表行的顺序很重要，则需要对这个表进行重组—对于那些涉及多张大表的大规模批处理任务而言，通常需要这么做。</p><p>当往表中插入一条记录时，DBMS会尝试将索引行添加至其索引建所属的叶子页上，但是该索引页可能没有足够的空闲空间来存放这个索引行，在这种情况下，DBMS将会分裂该叶子页。其中一半的行将被移动到一个新的叶子页上，并尽可能地靠近被分裂的页，但是在最坏的情况下，这个索引页可能会被放置在索引的末尾。除了在每个叶子页上预留部分比例的空闲空间外，也许可以在索引被创建或重组时，每n个页面预留一个空页—当索引分裂无法避免时，这会是一个不错的办法。</p><p><font color="DeepPink"><strong>当一个索引有一个不断增长的键值时，新行将被添加到索引页的最后，索引页可能永远也不会进行分裂,这样的索引可能不需要任何空闲空间。</strong></font></p><h2 id="叶子页的分裂严重吗？">叶子页的分裂严重吗？</h2><p>分裂一个索引页只需一次额外的同步读，约10ms。除了两个叶子页以外，DBMS通常还必须更新一个非叶子页，而它很可能已经在内存或者读缓存中了。</p><p>在叶子页分裂后，查询任何一条索引行的速度很可能同之前一样快。在最坏情况下，一次分裂会创建一个新的索引层级，但是如果不是从磁盘读取非叶子页的话，这只会增加很少的CPU时间。</p><p>然而，叶子页的分裂会导致一个索引片变得更慢。目前为止，我们在所有的场景中都假设串联索引行的链指针总是指向同一页或者下一页，这些页可能已被DBMS预读取。在索引被创建或者重组后，这种假设是接近真实情况的，但是索引片上的每处叶子页分裂都可能会增加额外的两次随机访问—一次是为了查找索引行被移动至的索引页，一次是为了返回到扫描的原始位置。其中第一次随机访问很可能会导致一次磁盘的随机读取(10ms)。</p><h2 id="什么时候应该对索引进行重组？">什么时候应该对索引进行重组？</h2><h3 id="插入模式">插入模式</h3><p>索引重组是为了恢复索引行正确的物理位置，他对于索引片扫描和全索引扫描的性能而言很重要。因为插入模式的不同，增加的索引行可能会以无序的方式来创建。我们需要记住，更新一个列意味着需要删除旧的索引行，并增加一个新的索引行，新索引行的位置由新的索引键值来确定。</p><p>下文对三种基本插入模式的讨论基于如下假设</p><ol><li>索引是唯一索引。</li><li>被删除的索引行锁腾出的空间在重组之前可以被新的索引行重用。</li></ol><h3 id="新索引行被添加至索引的尾部-永远递增的键">新索引行被添加至索引的尾部(永远递增的键)</h3><p>假设插入了一个索引行，其索引键值比任何已经存在的索引键值都要大，则DBMS就不会分类最后的叶子页，那么就不需要空闲的空间或者进行索引重组了。然而，如果在索引前面的索引行被定期地删除，那么为了回收空闲的空间，索引可能不得不进行重组(一个“爬行”的索引)。</p><h3 id="随机插入模式">随机插入模式</h3><p>我们稍后将会看到，尽管考虑了空闲空间和重组，对于不同的索引行长度(短，中，长)的处理也是不同的。越长的索引行越难处理，越短的越好处理。</p><p>有一个重要的例外场景 : 如果索引行是变长的，那么就需要有空闲的空间去适应任何索引行的增长。</p><h2 id="索引重组的代价">索引重组的代价</h2><p>一个索引可以以多种方式进行重组：</p><ol><li>全索引扫描（随机访问且无须排序，或者顺序访问并排序）。</li><li>全表扫描（类似 CREATE INDEX; 顺序访问及一次排序）。</li></ol><p>由索引重组产生的锁等待依赖于具体的数据库和选项。如果使用的是简易的工具,那么当表或者索引正在被扫描吋，整个表可能被加上一个S锁(更新操作会被阻塞）。如果工具能在扫描期间将更新操作保存下来，并在排序前将它们应用到数据行上，那么锁等待的时间将会缩短很多。</p><p>有些时候，大的索引可能不得不在不合适的时间被重组。在最坏情况下，锁的问题可能会导致频繁的重组无法实现。在这种情况下 ， 一些易变的索引可能必需被强制缓存在内存中（将其固定在内存中）。</p><h1>数据库管理系统相关的索引限制</h1><h2 id="索引列的数量">索引列的数量</h2><p>能够复制到索引上的列的个数上限在16至64之间。并非每个人都将这视为一个问题。 Gulutzan 和 Pelzer提出了一个出人意料的<br>建议，如下:</p><blockquote><p>针对所有数据库管理系统的总体建议为：在一个复合索引中最多使用5列。虽然你能够确定数据库管理系统至少能够支持16列，但是5列是一些专家所认为的合理上限。</p></blockquote><h2 id="索引列的总长度">索引列的总长度</h2><p>复制到索引的列的总长度存在一个上限，该上限的值取决于数据库管理系统。随着宽索引变得越来越流行，这一上限在数据库筲理系统的新版本中在变大。</p><h2 id="单表索引数量上限">单表索引数量上限</h2><p>在单表索引数量限制方面，许多数据库产品要么没有上限，要么上限太高以至于无关紧要。</p><h2 id="索引大小上限">索引大小上限</h2><p>典型的索引大小上限为几GB,而且这一上限正在持续增大。就像大表一样，大索引通常是分区的，这样能够使执行维护程序的成本最小化，并且能将索引分散到多个磁盘驱动器或RAID组上。</p><h2 id="索引锁定">索引锁定</h2><p>从更新的时间点到提交的时间点内，如果数据库管理系统给一个索引页或者一个索引页的一部分（如一个子页）加了锁，那么该索引页或子页很能会成为瓶颈，因为插入操作将会变为顺序的。例如，SQL Server 2000就是这样做的，但如果上锁的粒度仅为一行，那么这不可能会成一个问题。</p><p>在DB2数据库的z/OS版本中，使用闩锁来保证索引页的物理完幣性。当用闩锁对一个缓冲池中的页加锁时，实际上是在数据库缓冲池中进行了一次置位操作，当释放闩锁时再进行重置。一个页只有在读取或修改时才会被加上闩锁，在当前的处理器条件下耗费时间不到一微秒。而数据完幣性是通过对索引行所指向的表页或表行加上普通锁来保证的（仅对数据上锁）。当程序修改一个表行或表页。这些锁一直不会释放，直至修改被提交。</p><h1>数据库索引选项</h1><p>索引键决定了这一索引行在索引结构中的位置。当索引键被修改后,DBMS会删除原来的索引行，并将其插入到新的位置上。在最差情况下，索引行会被移动到其他的叶子页上。</p><h1>其他评估事项</h1><h2 id="宽索引还是理想索引">宽索引还是理想索引</h2><p>单纯从响应时间来看，理想的索引并非具有完全的优势，我们给出了如下结论 :</p><blockquote><p>虽然三星索引有一定的优势，尤其是在结果集为空的情况下，但是这个优势并不也别明显，而且会带来与新增索引相关的额外开销。</p></blockquote><h1>组织索引设计过程</h1><h2 id="简介-v2">简介</h2><p>在大公司里，一个合理的折中方案是聘用50/50的专家，他们会将50%的时间用来应用程序开发，另外50%的时间用于协助同事进行索引评估及其他性能问题的处理（比如根据EXPLAIN的输出内容解决某个优化器问题）。经验显示，为每5至10位应用开发者配一名50/50专家的方式效果很好。</p><p>索引设计需要同事掌握技术技能以及应用系统知识。相比让数据库专家熟悉应用系统的细节而言，教会开发人员索引技能是更容易的。</p><hr><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Database" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Database</a></p>]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>Design</tag>
        <tag>Database</tag>
        <tag>Oracle</tag>
        <tag>SQL Server</tag>
        <tag>DB2</tag>
        <tag>Index</tag>
        <tag>Optimizers</tag>
      </tags>
  </entry>
  <entry>
    <title>Java性能优化权威指南 笔记</title>
    <url>/java-performance.html</url>
    <content><![CDATA[<p>本文整理自：《Java性能优化权威指南》</p><p>作者：Charlie Hunt / Binu John</p><p>出版时间：2014-03</p><a id="more"></a><h1>操作系统性能监控</h1><h2 id="CPU使用率">CPU使用率</h2><p>大多数的操作系统的CPU使用率分为用户态CPU使用率和系统态CPU使用率。</p><p>用户态CPU使用率是指执行应用程序代码的时间占总CPU时间的百分比。</p><p>系统态CPU使用率是指应用执行操作系统调用的时间占总CPU时间的百分比。<font color="DeepPink"><strong>系统态CPU使用率高意味着共享资源有竞争或者I/O设备之间有大量的交互。</strong></font></p><p>既然原本用于执行操作系统内核调用的CPU周期也可以用来执行应用代码，所以理想情况下，应用达到最高性能和扩展性时，它的系统态CPU使用率为0%，所以提高应用性能和扩展性的一个目标是尽可能降低系统态CPU使用率。</p><p>对于计算密集型应用来说，不仅要监控用户态和系统态CPU使用率，还要进一步监控每时钟指令数（Instructions Per Clock，IPC）或每指令时钟周期（Cycles Per Instruction，CPI）等指标。这两个指标对于计算密集型应用来说很重要，因为<font color="DeepPink"><strong>现代操作系统自带的CPU使用率监控工具只能报告CPU使用率，而没有CPU执行指令占用CPU时钟周期的百分比，这意味着，即便CPU在等待着内存中的数据，操作系统工具仍然会报告CPU繁忙。这种情况通常被称为停滞。当CPU执行指令所用的操作数据不在寄存器或者缓存中时，就会发生停滞，由于指令执行前必须等待数据从内存中装入CPU寄存器，所以一旦发生停滞，就会浪费时钟周期。</strong></font>CPU停滞通常会等待好几百个时钟周期，因此提高计算密集型应用性能的策略就是减少停滞或者改善CPU高速缓存使用率，从而减少CPU在等待内存数据时浪费的时钟周期。</p><h2 id="CPU调度程序运行队列">CPU调度程序运行队列</h2><p>监控CPU调度程序运行队列对于分辨系统是否满负荷也有重要意义。<font color="DeepPink"><strong>运行队列中就是那些已准备好运行、正等待可用CPU的轻量级进程。如果准备运行的轻量级进程数超过系统所能处理的上限，运行队列就会很长。</strong></font>运行队列长表明系统负载可能饱和。系统运行队列长度等于虚拟机处理器的个数时，用户不会明显感觉到性能下降。此处虚拟处理器的个数就是系统硬件线程的个数，也是Java API Runtime.availableProcessors()的返回值。当运行队列长度达到虚拟处理的4倍或者更多时，系统的响应就非常迟缓了。</p><p>一般性的指导原则是：如果在很长一段时间里，运行队列的长度一直都超过虚拟处理器个数的1倍，就需要关注了，只是暂时还不需要立刻采取行动。<font color="DeepPink"><strong>如果在很长一段时间里，运行队列长度达到虚拟处理器个数的3~4倍或更高，则需要立刻引起注意和采取行动。</strong></font></p><h2 id="内存使用率">内存使用率</h2><p>系统在进行页面交换或者使用虚拟内存时，Java应用或JVM会表现出明显的性能问题。当应用运行所需的内存超过可用物理内存时，就会发生页面交换。为了应对这种可能出现的情况，通常要为系统配置swap空间。swap空间一般会在一个独立的磁盘分区上。当应用耗尽内存时，操作系统会将应用的一部分置换到磁盘上的swap空间。通常是应用中最少运行的部分，以免影响整个应用或者应用最忙的那部分。当访问应用中被置换出去的部分时，就必须将它从磁盘置换进内存，而这种置换活动会对应用的响应性和吞吐量造成很大影响。</p><p><font color="DeepPink"><strong>JVM垃圾收集器在系统页面交换时的性能也很差，这是由于垃圾收集器为了回收不可达对象所占用的空间，需要访问大量的内存。如果Java堆得一部分被置换出去，就必须先置换进内存以便垃圾收集器扫描存活对象，这会增加垃圾收集的持续时间。</strong></font>垃圾收集是一种Stop-The-World操作，即停止所有正在运行的应用线程，如果此时系统正在进行页面交换，则会引起JVM长时间的停顿。</p><h3 id="监控抢占式上下文切换">监控抢占式上下文切换</h3><p>让步式上下文切换时指执行线程主动释放CPU，抢占式上下文切换时指线程因为分配的时间片用尽而被迫放弃CPU或者被其他优先级更高的线程锁抢占。pidstat的输出结果中<font color="DeepPink"><strong>cswch/s</strong></font>是每秒的让步式上下文切换，<font color="DeepPink"><strong>nvccswch/s</strong></font>是抢占式上下文切换。</p><h3 id="监控线程迁移">监控线程迁移</h3><p>我们发现，待运行线程在处理器之前的迁移也会导致性能的下降。大多数操作系统的CPU调度程序会将待运行线程分配给上次运行它的虚拟处理器。如果这个虚拟处理器忙，调度程序就会将待处理线程迁移到其他可用的虚拟处理器。<font color="DeepPink"><strong>线程迁移会对应用性能造成影响，这是因为新的虚拟处理器缓存中可能没有待运行线程所需的数据或状态信息。</strong></font>多核系统上运行Java应用可能会发生大量的线程迁移，减少迁移的策略是创建处理器组并将应用分配给这些处理器组。一般性准则是，<font color="DeepPink"><strong>如果横跨多核或虚拟处理器的Java应用每秒迁移超过500次，将Java应用绑定在处理器组上就有好处。</strong></font></p><h2 id="网络I-O使用率">网络I/O使用率</h2><h3 id="应用性能改进的考虑">应用性能改进的考虑</h3><p>单次读写数据量小而网络读写量大的应用会消耗大量的系统态CPU，产生大量的系统调用。对于这类应用，减少系统态CPU的策略是减少网络读写的系统调用。此外，使用非阻塞的Java NIO而不是阻塞的java.net.Socket，减少处理请求和发送相应的线程数，也可以改善应用性能。</p><p>从非阻塞Socket中读取数据的策略是，应用在每次读请求时尽可能多地读取数据。同样，当往Socket中写数据时，每个写调用应该尽可能多地写。</p><h1>JVM概览</h1><h2 id="HotSpot-运行时">HotSpot 运行时</h2><h3 id="命令行选项">命令行选项</h3><p>HotSpot VM 命令行选项有3类：</p><ul><li>标准选项（Standard option）：标准选项是Java virtual Machine Specification要求所有java JVM 都必须实现的选项。</li><li>非标准选项（NonStandard option）：非标准选项(以–X为前缀)，不保证也不强制所有JVM实现都必须支持。</li><li>非稳定选项（Developer option）：非稳定选项(以-XX为前缀),通常为了特定需要而对JVM的运行进行矫正。选项名称前+代表 true启用，-代表false关闭。</li></ul><h3 id="VM生命周期">VM生命周期</h3><p>启动器启动HotSpot VM时会执行一系列操作。步骤概述如下：</p><ol><li>解析命令行选项</li><li>设置堆的大小和JIT编译器<br>如果命令行没有明确设置堆的大小和JIT编译器，启动器则通过自动优化进行设置。</li><li>设定环境变量如：LD_LIBRARY_PATH和CLASSPATH</li><li>如果命令行有-jar选项，启动器则从指定JAR的manifest中查找Main-Class，否则从命令行读取Main-Class</li><li>使用标准Java本地接口（Java Native Interface，JNI）方法JNI_CreateJavaVM在新创建的线程中创建HotSpot VM</li><li>一旦创建并初始化号HotSpot VM，就会加载Java Main-Class，启动器也会从Java Main-Class中取得Java main方法的参数</li><li>HotSpot VM通过JNI方法CallStartVoidMethod调用Java main方法，并将命令行选项传给它</li></ol><h3 id="VM类加载阶段">VM类加载阶段</h3><h4 id="类加载阶段">类加载阶段</h4><p>对于给定的Java类或接口，类加载时会依据它的名字找到Java类的二进制类文件，定义Java类，然后创建代表这个类或者接口的java.lang.Class对象。如果没有找到Java类或接口的二进制表示就会抛出NoClassDefFound。此外，类加载阶段会对类的格式进行语法检查，如果有错，则会抛出ClassFormatError或UnsupportedClassVersionError。Java类加载前，HotSpot VM必须先加载它的所有超类和超接口，如果类的继承层次有错，例如Java类是它自己的超类或超接口（类层次递归）,HotSpot VM则会抛出ClassCircularityError。如果所引用的直接超接口本身并不是接口，或者直接超类实际上是接口，HotSpot VM则会抛出IncompatibleClassChangeError。</p><p>链接的第一步是验证，检查类文件的语义、常量池符号以及类型。如果检查有错，就会抛出VerifyError。链接的下一步是准备，它会创建静态字段，初始化为标准默认值，以及分配方法表。请注意，此时还没有执行任何Java代码。接下来解析符号引用，这一步是可选的。然后初始化类，运行类构造器。这是迄今为止，类中运行的第一段Java代码。值得注意的是，<font color="DeepPink"><strong>初始化类需要首先初始化超类（不会初始化超接口）</strong></font>。</p><blockquote><p>如：int的标准默认值为0；public static int value=123，准备阶段将其初始化为0而不是123，value=123的赋值操作在类构造器&lt;clinit&gt;()中。<br>public static final int value=123，编译时会为value在字段属性表中生成ConstantValue，从而在准备阶段就被初始化成123。</p></blockquote><p>Java Virtual Machine Specification规定首次使用类时进行类初始化，而Java Language Specification则允许在链接阶段符号解析时灵活处理，只要保持语言的语义不变，JVM依次执行加载、链接和初始化，保证及时抛出错误即可。出于性能优化的考虑，通常直到类初始化时HotspotVM才会加载和链接类。<font color="DeepPink"><strong>这意味着，类A引用类B。加载A不一定导致加载B（除非B需要验证）。执行B的第一条指令会导致初始化B，从而加载和链接B。</strong></font></p><h4 id="类加载器委派">类加载器委派</h4><p>当请求类加载器查找和加载某个类时，该类加载器可以转而请求别的类加载器来加载。这被称为类加载器委派。类的首个类加找器称为初始类加载器（Initiating ClassLoader)，最终定义类的类加载器称为定义类加载器（Defining ClassLoader）。<font color="DeepPink"><strong>就字节码解析而言，某个类的初始类加载器是指对该类进行常量池符号解析的类加载器。</strong></font></p><p>类加载器之间是层级化关系，每个类加载器都可以委派给上一级类加载器。这种委派关系定义了二进制类的查找顺序。<font color="DeepPink"><strong>Java SE类加载器的层级查找顺序为启动类加载器、扩展类加载器及系统类加载器。</strong></font>系统类加载器是默认的应用程序类加载器，它加载Java类的main方法并从classpath上加载类。<font color="DeepPink"><strong>应用程序类加载器可以是Java SE系统自带的类加载器，或者由应用程序开发人员提供。扩展类加载器则JavaSE系统实现，它负责从JRE(Java Runtime Environment,Java运行环境）的lib/ext目录下加载类。</strong></font></p><h4 id="启动类加载器">启动类加载器</h4><p><font color="DeepPink"><strong>启动类加载器是由HotSpot VM实现的，负责加载BOOTCLASSPATH路径中的类，如包含Java SE类库的rt.jar。</strong></font>为了加快启动速度，Client模式的HotSpot VM可以通过称为类教据共享（Class Data Sharing）的特性使用已经预加载的类。这个特性默认为开启，可由HotSpot VM命令行开关-Xshare:on开启，-Xshare:off关闭。到本书编写时为止，Server模式的HotSpot VM还不支持类数据共享，而且即便是Client模式，也只有使用Serial收集器时才支持该机制。</p><h4 id="类型安全">类型安全</h4><p>Java类或接口的名字为全限定名（包括包名）。Java的类型由全限定名和类加载器唯一确定。</p><h4 id="HotSpot类元数据">HotSpot类元数据</h4><p>类加载时，HotSpot VM会在永久代创建类的内部表示instanceKlass或arrayKlass。instanceKlass应用了与之对应的java.lang.Class实例，后者是前者的Java镜像。HotSpot VM内部使用称为klassOop的数据结构访问instanceKlass。后缀“Oop”表示普通对象指针，所以klassOop是应用java.lang.Class的HotSpot内部抽象，它是指向Klass（与Java类对应的内部表示）的普通对象指针。</p><h4 id="内部的类加载数据">内部的类加载数据</h4><p>类加载过程中，HotSpot VM维护了3张散列表。SystemDictionary包含已加载的类，它将建立类名/类加载器（包括初始类加载器和定义类加载器）与klassOop对象之间的映射。目前只有在安全点事才能移除SystemDictionary中的元素。Placeholder-Table包含当前正在加载的类，它用于检查ClassCircularityError，多线程类加载器并行加载类时也会用到它。LoaderConstraintTable用于追踪类型安全检查的约束条件。<font color="DeepPink"><strong>这些散列表都需要加锁保证访问安全，在HotSpot VM中，这个锁称为SystemDictionary_lock。通常，HotSpot VM借助类加载器对象锁对加载类的过程进行序列化。</strong></font></p><h3 id="字节码验证">字节码验证</h3><p>Java是一门类型安全语言，官方标准的Java编译器（javac）可以生成合法的类文件和类型安全的字节码，但Java虚拟机无法确保字节码一定是由可信的javac编译器产生的，所以在链接时必须进行字节码验证以保障类型安全。</p><h3 id="类数据共享">类数据共享</h3><p>类数据共享是Java 5引人的特性，以缩短Java程序（特別是小程序）的启动时间，同时也能减少它们的内存占用。使用Java HotSpot JRE安装程序在32位平台上安装Java运行环境（JRE)时，安装程序会加载系统jar中的部分类，变成私有的内部表示并转储成文件，称为共享文档(Shared Archive)。如果过没有使用Java HotSpot JRE安装程序，也可以手工生成该文件。之后调用Java虚拟机时，共享文档会映射到JVM内存中，从而减少减少加载这些类的开销，也使得这些类的大部分JVM允数椐能在多个JVM进程间共享。</p><h3 id="解释器">解释器</h3><p>HotSpot VM解释器是一种基于模板的解释器。JVM启动时，HotSpot VM运行时系统利用内部TemplateTable中的信息在内存中生成解析器。TemplateTable包含于每个字节码对应的机器代码，每个模板描述一个字节码。</p><p>HotSpot VM解释器堪于模板的设计要好于传统的switch语句循环方式。switch语句需要重复执行比较操作，最差情况需要和所冇字节码比较。此外，switch语句必须使用单独的软件栈传递 Java 参数。HotSpot VM使用本地C栈传递 Java 参数。一些存储在C变量中的HotSpot VM内部变量，例如Java线程的程序计数器或栈指针，并不能保证总是存储在底层硬件寄存器中。结果，管理这些软件解释器数据结构就会占去总执行时间的相当大一部分。不过总体来说，HotSpot解释器显著缩短HotSpot VM和实体机之间的性能差距，解释速度也明显变快了，然而代价是大量与机器相关的代码。例如，Intel X86平台特定的代码大约有10000行，SPARC平台专用的代码大约打14000行。由于需要支持动态代码生成（JIT编译），整体的代码量和复杂度也显著变大。并且调 试动态生成的机器码（ JIT编译代码）比调试静态代码困难多了。虽然这些不利于运行时系统的改善，但也并非不可能完成的任务。</p><h3 id="异常处理">异常处理</h3><p>当与Java的语义约束冲突时，Java虚拟机会用异常通知程序。异常处理由HotSpot VM解释器、JIT编译器和其他HotSpot VM组件一起协作实现。异常处理主要有两种情形，同一方法中抛出和捕获异常，或由调用方法捕获异常。异常可以由抛出字节码、VM内部调用返回、JNI调用返回或Java调用返回所引发。</p><h3 id="线程管理">线程管理</h3><p><font color="DeepPink"><strong>HotSpot VM通过协作、轮询的机制创建安全点</strong></font>。简中来说，线程会经常询问：“我该在安全点停住么？ ”高效地询问这个问题并不是件容易的事。线程在状态变迁的过程中，会经常询问这个问题，但并非所有的状态变迁都会如此询问，比如线程离开HotSpot VM进入本地代码的情况。此外，JIT编译代码从java方法中返回或正作循环迭代的某个阶段时，线程也会询问“我该在安全点停住吗？ ”。正在执行解释代码的线程通常不会询问它们是否该在安全点停住。相反，当解释器切换到不同的分配表时，会请求安全点。切换操作中包含一部分代码，用以询问何时离开安全点。当离开安全点时，分配表会再次切换回来。一旦请求了安全点，VMThread就必须在继续执行VM操作前等待，直到确定所行线程都已进入安全点保全状态为止。在安全点时，VMThread用Threads_lock阻塞所有正在运行的线程，VM操作完成后 , VMThread释放Threads_lock。</p><h3 id="Java本地接口（JNI）">Java本地接口（JNI）</h3><p>切记，一旦在应用中使用JNI，就意味着丧失了Java平台的两个好处。首先，依赖JNI的Java应用难以在多种异构的硬件平台上运行。即便应用中Java语言编写的部分可以移植到多种硬件平台，采用本地编程语言的部分也需要重新编译。换句话说，一旦使用JNI就失去了Java承诺的特性，即“一次编写，到处运行”。其次，Java是强类型和安全的语言,本地语言如C或C++则不是。因此，Java开发者用JNI编写应用时必须格外小心。误用本地方法可能破坏整个应用。鉴于此，在调JNI方法前，Java应用常常需要安仝检查。额外的安全检查以及HotSpot VM在Java与JNI之间的数据复制会降低应用的性能。</p><p>HotSpot VM追踪正在执行本地方法的线程时必须特別小心。在HotSpot VM的某些活动过程中，尤其是垃圾收集的某些阶段，线程必须在安全点时暂停，以保证Java内存堆不被更改，确保垃圾收集的准确性。当HotSpot VM线程执行本地代码到达安全点时，线程可以继续执行本地代码，直到它Java代码或者发起JNI调用为止。</p><h3 id="VM致命错误处理">VM致命错误处理</h3><p>HotSpot内部使用信号进行通信。当无法识别信号时，将调用致命错误处理程序。在无法识别的情况下，它可能来自应用程序JNI代码，OS本地库，JRE本地库或JVM本身的错误。</p><h2 id="HotSpot-VM垃圾收集器">HotSpot VM垃圾收集器</h2><h3 id="分代垃圾收集">分代垃圾收集</h3><p>垃圾收集器不需要扫描整个（可能比新生代更大）老年代就能识别新生代中的存活对象，从而缩短Minor GC的时间。<font color="DeepPink"><strong>HotSpot VM的垃圾收集器使用称为卡表（CardTable)的数据结构来达到这个目的。老年代以512字节为块划分成若十张卡（Card)。卡表是个单字节数组，每个数组元素对应堆中的一张卡。每次老年代对象中某个引用新生代的字段发生变化时，HotSpot VM就必须将该卡所对位的卡表元素设置为适当的值，从而将该引用字段所在的卡标记为脏。在Minor GC过程中，垃圾收集器只会在脏卡中扫描查找老年代-新生代引用。</strong></font></p><p><img data-src="/images/java-performance/%E5%9B%BE3-3.png" alt></p><p><font color="DeepPink"><strong>HotSpot VM的字节码解释器和JIT编译器使用写屏障(Write Barrier)维护卡表。</strong></font>写屏障是一小段将卡状态设罝为脏的代码。解释器每次执行更新引用的字节码时，都会执行一段写屏障；JIT 编译器在生成更新引用的代码后，也会生成一段写屏障。虽然写屏障使得应用线程增加了一些性能开销，但Minor GC变快了许多，整天的垃圾收集效率也提高了许多。通常应用的吞吐量也会有所改善。</p><h3 id="新生代">新生代</h3><p>需要指出的是，<font color="DeepPink"><strong>在Minor GC过程中，Survivor可能不足以容纳Eden和另一个Survivor中的存活对象。如果Survivor 中的存活对象溢出，多余的对象将被移到老年代。这称为过早提升(Premature Promotion)</strong></font>。这会导致老年代中短期存活对象的增长，可能会引发严重的性能问题。再进一步说，在Minor GC过程中，如果老年代满了而无法容纳更多的对象，Minor GC之后通常就会进行Full GC,这将导致遍历整个Java堆。这称为提升失败（Promotion Failure）。</p><h3 id="快速内存分配">快速内存分配</h3><p>对象内存分配器的操作需要和垃圾收集器紧密配合。垃圾收集器必须记录它回收的空间，而分配器在重用堆空间之前需要找到可以满足其分配需求的空闲空间。垃圾收集器以复制方式回收HotSpot VM新生代，其好处在于回收以后Eden总为空，在Eden中运用被称为指计碰撞(Bump-the-Pointer)的技术就可以有效地分配空间。这种技术追踪最后一个分配的对象（常称为top),当有新的分配请求时，分配器只需要检查top和eden未端之间的空间是否能容纳。如果能容纳，top则跳到新近分配对象的未端。</p><p><font color="DeepPink"><strong>重要的Java应用大多是多线程的，因此内存分配的操作需要考虑多线程安全。如果只用全局锁，在Eden中的分配操作就会成为瓶颈而降低性能。HotSpot VM没有采用这种方式，而是以一种称为线程本地分配缓冲区（thread-Local Allocation Buffer,TLAB)的技术，为每个线程设置各自的缓冲区(即Eden的一小块），以此改善多线程分配的吞吐量。因为每个TLAB都只有一个线程从中分配对象，所以可以使用指针碰撞技术快速分配而不需要任何锁。然而当线程的TLAB填满需要获取新的空间时（不常见），它就需要采用多线程安全的方式了。大部分时候，HotSpot VM的new Object()操作只需要大约十条指令。垃圾收集器清空Eden区域，然后就可以支持快速内存分配了。</strong></font></p><h2 id="HotSpot-VM-JIT编译器">HotSpot VM JIT编译器</h2><p>经典的寄存器分配策略是图着色算法，通常可以使机器寄存器的使用率达到最高，而且多余的值很少会卸载到栈中。图表示的是同时有哪些变量在使用．以及哪些寄存器可以存放这些变量。如果同时存活的变量数超过了可用的寄存器数，重要性最低的变量将被移到栈中，使得其他变量可以使用寄存器。指派某个变量给寄存器通常需要来回几次构建图和着色。这也导致了它的不足，图着色算法花费的时间、数据结构所需的空间都比较昂贵。</p><h1>JVM性能监控</h1><h2 id="垃圾收集">垃圾收集</h2><h3 id="重要的垃圾收集数据">重要的垃圾收集数据</h3><p>重要的垃圾收集数据包括：</p><ul><li>当前使用的垃圾收集器</li><li>Java堆的大小</li><li>新生代和老年代的大小</li><li>永久代的大小</li><li>Minor GC的持续时间</li><li>Minor GC的频率</li><li>Minor GC的空间回收量</li><li>Full GC的持续时间</li><li>Full GC的频率</li><li>每个并发垃圾收集周期内的空间回收量</li><li>垃圾收集前后Java堆的占用量</li><li>垃圾收集前后新生代和老年代的占用量</li><li>垃圾收集前后永久代的占用量</li><li>是否老年代或永久代的占用触发了 Full GC</li><li>应用是否显式调用了 System.gc()</li></ul><h3 id="垃圾回收报告">垃圾回收报告</h3><h3 id="JIT编译器">JIT编译器</h3><p>可以使用-XX:+PrintCompilation监控HotSpot JIT编译器。-XX:+PrintCompilation为每次编译生成一行日志。</p><p>日志样例如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">7		java. lang String: indexOf (151 bytes)</span><br><span class="line">8% !		sun. awt. image. PNGImageDecoder: produceImage a 960 (1920 bytes)</span><br><span class="line">9  !		sun awt. image. PNGImageDecoder: produceImage (1920 bytes)</span><br><span class="line">10		java. lang. AbstractStringBuilder: append(40 bytes)</span><br><span class="line">11	n	java. lang System: arraycopy (static)</span><br><span class="line">12	s	java util. Hashtable: get (69 bytes)</span><br><span class="line">13	b	java util. HashMap: indexFor (6 bytes)</span><br><span class="line">14	made zombie java. awt. geom. Path2DSIterator: isDone (20 bytes)</span><br></pre></td></tr></table></figure><h1>JVM性能调优入门</h1><h2 id="应用程序的系统需求">应用程序的系统需求</h2><h3 id="吞吐量">吞吐量</h3><p><font color="DeepPink"><strong>吞吐量是对单位时间内处理工作量的度量</strong></font>。设计吞吐量需求时,我们一般不考虑它对延迟或者响应时间的影响。通常情况下,增加吞吐量的代价是延迟的增加或内存使用的增加。</p><p>吞吐量性能需求的一个典型例子是,应用程序每秒需要完成2500次事务。</p><h3 id="延迟或响应性">延迟或响应性</h3><p><font color="DeepPink"><strong>延迟,或者响应性,是对应用程序收到指令开始工作直到完成该工作所消耗时间的度量。</strong></font></p><p>定义延迟或响应性需求时并不考虑程序的吞吐量。通常情况下,提高响应性或缩小延迟的代价是更低的吞吐量、或者更多的内存消耗(或者二者同时发生)</p><p>延迟或响应需求的一个典型例子是,应用程序应该在60毫秒内完成交易请求的处理工作。</p><h3 id="内存占用">内存占用</h3><p><font color="DeepPink"><strong>内存占用指在同等程度的吞吐量、延迟、可用性和可管理性前提下,运行应用程序所需的内存大小。</strong></font>内存占用通常以运行应用程序需要的Java堆大小或者运行应用程序需要的总内存大小来表述。一般情况下,通过增大Java堆的方式增加可用内存能够提高吞吐量、降低延迟或者兼顾二者。应用程序的可用内存减少时,吞吐量和延迟通常都会受到影响。应用程序的内存占用限制了固定内存的机器上能同时运行的应用程序实例数。</p><p>内存占用需求的一个典型例子是,应用程序需要在拥有8GB内存的系统上以单个实例方式运行或者在24GB内存的系统上以3个应用程序实例方式运行。</p><h2 id="性能收集调优基础">性能收集调优基础</h2><h3 id="性能属性">性能属性</h3><ul><li>吞吐量:是评价垃圾收集器能力的重要指标之一,指不考虑垃圾收集引起的停顿时间或内存消耗,垃圾收集器能支撑应用程序达到的最高性能指标。</li><li>延迟:也是评价垃圾收集器能力的重要指标,度量标准是缩短由于垃圾收集引起的停顿时间或完全消除因垃圾收集所引起的停顿,避免应用程序运行时发生抖动。</li><li>内存占用:垃圾收集器流畅运行所需要的内存数量。</li></ul><p><font color="DeepPink"><strong>这其中任何一个属性性能的提高几乎都是以另一个或两个属性性能的损失作代价的。换句话说,某一个属性上的性能提高总会牺牲另一个或两个属性。然而,对大多数的应用而言,极少出现这三个属性的重要程度都同等的情况。很多时候,某一个或两个属性的性能要比另一个重要。</strong></font></p><p>我们需要了解对应用程序而言哪些系统需求是最重要的,也需要知道对应用程序而言这三个性能属性哪些是最重要的。确定哪些属性最重要,并将其映射到应用程序的系统需求,对应用程序而言非常重要。</p><h3 id="原则">原则</h3><p>谈到JVM垃圾收集器调优也有三个需要理解的基本原则。</p><ul><li>每次Minor GC都尽可能多地收集垃圾对象。我们把这称作“<font color="DeepPink"><strong>Minor GC回收原则</strong></font>”。遵守这原则可以减少应用程序发生 Full GC的频率。Full GC的持续时间总是最长的,是应用程序无法达到其延迟或吞吐量要求的罪魁祸首。</li><li>处理吞吐量和延迟问题时,垃圾处理器能使用的内存越大,即Java堆空间越大,垃圾收集的效果越好,应用程序运行也越流畅。我们称之为“<font color="DeepPink"><strong>GC内存最大化原则</strong></font>”。</li><li>在这三个性能属性(吞吐量、延迟、内存占用)中任意选择两个进行JVM垃圾收集器调优。我们称之为“<font color="DeepPink"><strong>GC调优的3选2原则</strong></font>”。</li></ul><p>调优JVM垃圾收集的过程中谨记这三条原则能帮助你更轻松地调优垃圾收集,达到应用程序的性能要求。</p><h2 id="确定内存占用">确定内存占用</h2><h3 id="HotSpot-VM堆布局">HotSpot VM堆布局</h3><p>通过-Xmn可以很方便地设定新生代空间的初始值和最大值。有一点需要特别注意,如果-Xms和-Xmx并没有设定为同一个值,使用-Xmn选项时,Java堆的大小变化不会影响新生代空间,即新生代空间的大小总保持恒定,而不是随着Java堆大小的扩展或缩减做相应的调整。因此,请注意,<font color="DeepPink"><strong>只有在-Xms与-Xmx设定为同一值时才使用-Xmn选项。</strong></font></p><p>老年代空间的大小会根据新生代的大小隐式设定。老年代空间的初始值为-Xmx的值减去XX:	NewSize的值。老年代空间的最小值为-Xmx的值减去-XX:MaxNewSize的值。如果-Xms与Xmx设置为同一值,同时使用了-Xmn,或者-XX:NewSize与-XX:MaxNewsize一样,则老年代的大小为-Xmx(或-Xms)的值减去-Xmn。</p><p>实际上,当HotSpot VM发现当前可用空间不足以容纳下一次Minor GC提升的对象时就会进行Full GC。与因空间问题导致的Minor GC过程中的对象提升失败比较起来,这种方式的代价要小得多。从失败的对象提升中恢复是一个很昂贵的操作。永久代没有足够的空间存储新的VM或类元数据时也会发生Full GC。</p><p>如果Full GC缘于老年代空间已满,即使永久代空间并没有用尽,老年代和永久代都会进行垃圾收集。同样,如果Full GC由永久代空间用尽引起,老年代和永久代也都会进行垃圾收集,无论老年代是否还有空闲空间。开启-XX:+UseParallelGC或-XX:+UseParallelOldGC时,如果关闭-XX:-ScavengeBeforeFullGC, HotSpot VM在Full GC之前不会进行Minor GC,但Full GC过程中依然会收集新生代;如果开启-XX:+ScavengeBeforeFullGC, HotSpot VM在Full GC前会先做一次Minor GC,分担一部分Full GC原本要做的工作。</p><h3 id="堆大小调优着眼点">堆大小调优着眼点</h3><p>如果你使用的HotSpot VM不接受-XX:+UseParallelOldGC选项,可以使用-XX:+UseParallelGC代替。如果你很清楚Java应用程序要使用多大的Java堆空间,可以将Java堆大小作为调优的入手点,使用-Xmx和-Xms设置Java堆的大小。如果你不清楚Java应用程序到底需要使用多大的Java堆,可以利用HotSpot VM自动选取Java堆的大小。启动Java应用程序时不指定-Xmx或-Xms的值, HotSpot VM会自动设定Java堆大小的初始值。换句话说,这是一个起始点。随着调优过程,后面会逐渐调整Java堆的大小。</p><p>通过HotSpot命令行选项-XX:+PrintCommandLineFlags还可以查看堆的初始值及最大值。-XX:+PrintCommandlineFlags选项可以输出HotSpot VM初始化时使用-XX:InitialHeapSize=&lt;n&gt; -XX:MaxHeapSize=&lt;m&gt;指定的堆的初始值及最大值,其中&lt;n&gt;是以字节为单位的初始Java堆大小,&lt;m&gt;是以字节为单位的堆的最大值。</p><h3 id="计算活跃数据大小">计算活跃数据大小</h3><p><font color="DeepPink"><strong>活跃数据大小是应用程序运行于稳定态时,长期存活的对象在Java堆中占用的空间大小。换句话说,活跃数据大小是应用程序运行于稳定态,Full GC之后Java堆中老年代和永久代占用的空间大小。</strong></font></p><p>Java应用的活跃数据大小可以通过GC日志收集。活跃数据大小包括下面的内容:</p><ul><li>应用程序运行于稳定态时,老年代占用的Java堆大小;</li><li>应用程序运行于稳定态时,永久代占用的Java堆大小。</li></ul><p>除了活跃数据大小,稳定态的Full GC也会对延迟带来严重影响。</p><p>为了更好地度量应用程序的活跃数据大小,最好在多次Full GC之后再查看Java堆的占用情况。另外,需要确保Full GC发生时,应用程序正处于稳定态。</p><p>如果应用程序没有发生Full GC或者不经常发生Full GC,你可以使用JVM监控工具Visual VM或JConsole人工触发Full GC。你也可以使用HotSpot JDK发行版中提供的jmap命令,通过命令行强制进行Full GC。为了实现这个目的,jmap需要使用- histo:live命令行选项及JVM进程号。JVM进程号可以通过JDK的js命令获得。例如,Java应用程序的JM进程号是348,使用jmap触发Full GC的命令行如下:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -histo: live 348</span><br></pre></td></tr></table></figure><p>jmap命令触发 Full GC的同时也生成一份包含对象分配信息的堆分析文件。为了专注本步操作,你可以忽略生成的堆分析文件。</p><h3 id="初始化堆大小配置">初始化堆大小配置</h3><p>推荐的做法是基于最差延迟进行估算。</p><table><thead><tr><th>空间</th><th>命令行选项</th><th>占用倍数</th></tr></thead><tbody><tr><td>Java堆</td><td>-Xms和-Xmx</td><td>3-4倍Full GC后的老年代空间占用量</td></tr><tr><td>永久代</td><td>-XX:Permsize<br>-XX:MaxPermSize</td><td>1.2-1.5倍Full GC后的永久代空间占用量</td></tr><tr><td>新生代</td><td>-Xmn</td><td>1~1.5倍 Full GC后的老年代空间占用量</td></tr><tr><td>老年代</td><td>Java堆大小减新生代大小</td><td>2-3倍Full GC后的老年代空间占用量</td></tr></tbody></table><h2 id="调优延迟-响应性">调优延迟/响应性</h2><h3 id="输入">输入</h3><p>这一步调优有多个输入,都源于应用程序的系统性需求。</p><ul><li>应用程序可接受的平均停滞时间。平均停滞时间将与测量出的Minor GC持续时间进行比较。</li><li>可接受的Minor GC(会导致延迟)频率。 Minor GC的频率将与可容忍的值进行比较。对应用程序干系人而言,GC持续的时间往往比GC发生的频率更重要。</li><li>应用程序干系人可接受的应用程序的最大停顿时间。最大停顿时间将与最差情况下Full GC的持续时间进行比较。</li><li>应用程序干系人可接受的最大停顿发生的频率。最大停顿发生的频率基本上就是Full GC的频率。同样,对于大多数应用程序干系人而言,相对于GC的频率,他们更关心GC持续的平均停顿时间和最大停顿时间。</li></ul><h3 id="优化新生代的大小">优化新生代的大小</h3><p>调整新生代空间时,需要谨记下面几个准则：</p><ul><li><font color="DeepPink"><strong>老年代空间大小不应该小于活跃数据大小的1.5倍。</strong></font></li><li><font color="DeepPink"><strong>新生代空间至少应为Java堆大小的10%</strong></font>,通过Xmx和-Xms可以设定该值。新生代过小可能适得其反,会导致频繁的Minor GC。</li><li>增大Java堆大小时,需要注意不要超过JVM可用的物理内存数。堆占用过多内存将导致底层系统交换到虚拟内存,反而会造成垃圾收集器和应用程序的性能低下。</li></ul><h3 id="监控晋升阈值">监控晋升阈值</h3><p>最大晋升阈值可以通过HotSpot VM的命令行选项-XX: MaxTenuringThreshold=&lt;n&gt;设置。使用HotSpot VM的命令行选项</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX: +PrintTenuringDistribution</span><br></pre></td></tr></table></figure><p>可以监控晋升的分布或者对象年龄分布,并以此为依据确定最优的最大晋升阈值值。</p><p>通过-XX:+PrintTenuringDistribution命令行选项可以观察Survivor空间中的对象是如何老化的。在-XX:+PrintTenuringDistribution生成的输出中,我们需要关注的是随着对象年龄的增加,各对象年龄上字节数减少的情况,以及 HotSpot VM计算出的晋升阈值是否等于或接近设置的最大晋升阈值。</p><p>XX:+PrintTenuringDistribution会输出每次Minor GC时晋升分布的情况。它也可以和其他的垃圾收集命令行选项,例如-XX:+PrintGCDateStamps、-XX:+PrintGcTime Stamps或-XX:+PrintgCDetails配合使用。对Survivor空间的有效对象老化进行微调时,应该使用选项XX:+PrintTenuringDistribution在垃圾收集日志中包含晋升分布的统计信息。同样,如果需要在生产环境中判断一个应用程序事件是否源于一次Stop-The-World压缩式垃圾收集,往往也需要获取晋升分布的日志信息,使用该选项是非常有帮助的。</p><blockquote><p><font color="DeepPink"><strong>通常情况下,观察到新的晋升阈值持续小于最大晋升阈值,或者观察到 Survivor空间大小小于总的存活对象大小都表明 Survivor空间过小。</strong></font></p></blockquote><h3 id="调整-Survivor空间的容量">调整 Survivor空间的容量</h3><p>调整Survivor空间容量一个应该谨记于心的重要原则:<font color="DeepPink"><strong>调整Survivor空间容量时,如果新生代空间大小不变,增大Survivor空间会减少Eden空间;而减少Eden空间会增加Minor GC的频率。</strong></font>因此,为了同时满足应用程序Minor GC频率的要求,就需要增大当前新生代空间的大小;即增大Survivor空间大小时,Eden空间的大小应该保持不变。换句话说,每当 Survivor空间增加时,新生代空间都应该增大。如果可以增大Minor GC的频率,你可以选择用一部分Eden空间来增大Survivor空间,或者直接增大新生代空间大小。如果内存足够,相对于减少Eden空间.增加新生代大小通常是更好的选择。保持Eden空间大小恒定, Minor GC的频率就不会由于Survivor空间增大而发生变化。</p><blockquote><p>如果你观察到垃圾收集中晋升分布极少出现对象年龄为15的情况,并且也没有发生Survivor空间溢出,那么应该设置最大晋升阈值为其默认值15。这种场景下,对象都不是长期存活对象,在年龄很小的时候就被回收了,根本不会生存到最大晋升年限的年龄15。</p></blockquote><h4 id="调整目标Survivor空间占用">调整目标Survivor空间占用</h4><p>目标Survivor空间占用是HotSpot VM尝试在Minor GC之后仍然维持的Survivor空间占用。通过 HotSpot VM的命令行选项-XX:TargetSurvivorRatio=&lt;percent&gt;可以对该值进行调整。通过命令行选项指定的参数实际上是Survivor空间占用的百分比而不是一个比率。它的默认值是50。</p><p>HotSpot VM研发团队对不同类型的应用程序进行了大量的负荷测试,结果表明50%的目标Survivor空间占用能适应大多数的应用程序,这是因为它能应对Minor GC时存活对象的急速增加。</p><p>极少发生需要对目标Survivor空间占用进行调优的情况。但是,如果应用程序有一个相对稳定的对象分配速率,可以考虑提高目标Survivor空间占用到80~90。这样可以减少用于老化对象的Survivor空间的数量。将-XX:TargetSurvivorRatio=&lt;percent&gt;设置得大于默认值会带来的问题是不能很好的适应迅速上涨的对象分配速率,导致提升对象的时机比预期更早。使用CMS时,如果对象提升过快会导致老年代占用增大,由于提升了一些非长期存活的对象,这些对象在将来的并发垃圾收集周期中一定会被回收,导致出现内存碎片的概率较高。碎片是我们要尽量避免的,因为它最终会导致Stop-The-World压缩式垃圾收集。</p><p><font color="DeepPink"><strong>成功的CMS收集器调优要能以对象从新生代提升到老年代的同等速度对老年代中的对象进行垃圾收集。达不到这个标准则称之为“失速”(Lost the Race)失速的结果就会发生Stop-The-World压缩式垃圾收集。避免失速的关键是要结合足够大的老年代空间和足够快地初始化CMS垃圾收集周期,让它以比提升速率更快的速度回收空间。</strong></font></p><p><font color="DeepPink"><strong>CMS周期的初始化基于老年代空间的占用情况。如果CMS周期开始得太晚,就会发生失速。如果它无法以足够快的速度回收对象,就无法避免老年代空间用尽。但是CMS周期开始得过早又会引起无用的消耗,影响应用程序的吞吐量。通常,早启动CMS周期要比晚启动CMS好,因为启动太晚的结果比启动过早的结果要恶劣得多。</strong></font></p><p>如果GC日志中发现concurrent mode failures字样,可以通过下面的命令行选项通知HotSpot在更早的时间启动CMS垃圾收集周期。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX: CMSInitiatingOccupancyFraction=&lt;percent&gt;</span><br></pre></td></tr></table></figure><p>设定的值是CMS垃圾收集周期在老年代空间占用达到多少百分比时启动。例如,如果你希望CMS周期在老年代空间占用达到65%时开始,可以设置-XX:CMSInitiatingOccupancyFraction=65。</p><p>另一个可以与-XX:CMSInitiatingOccupancyFraction=&lt;percent&gt;一起使用另一个Hotspot命令行选项是</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseCMSInitiatingOccupancyOnly</span><br></pre></td></tr></table></figure><p>-XX:+UseCMSInitiatingOccupancyOnly告知HotSpot VM总是使用-XX:CMSInitiatingOccupancyFraction设定的值作为启动CMS周期的老年代空间占用阈值。不使用-XX:+UseRs InitiatingOccupancyOnly, HotSpot VM仅在启动的第一个CMS周期里使用-XX:CMSInitiatingOccupancyFraction设定的值作为占用比率,之后的周期中又转向自适应地启动CMS周期,即第一次CMS周期之后就不再使用-XX:CMSInitiatingoccupancy Fraction设定的值。</p><blockquote><p>过选项设置何时启动CMS周期时,最好同时使用-XX:CMSInitiatingOccupancyFraction=&lt;percent&gt;和-XX:+UseCMSInitiatingOccupancyOnly</p></blockquote><p><font color="DeepPink"><strong>选项-XX:CMSInitiatingOccupancyFraction设定的空间占用值应该大于老年代占用空间和活跃数据大小之比。应用程序的活跃数据大小就是一次Full GC之后堆所占用的空间大小。如果使用-XX:CMSInitiatingOccupancyFraction设置的值小于活跃数据的占用百分比,CMS收集器一直运行陷入死循环。因此-XX:CMSInitiatingoccupancyFraction设置的一个通用原则是老年代占用百分比应该至少应该是活跃数据大小的1.5倍。</strong></font></p><p><font color="DeepPink"><strong>何时(提前或推迟)启动CMS周期取决于对象从新生代提升至老年代的速率,即老年代空间的增长率。如果老年代空间消耗得比较慢,可以在稍晩的时候启动CMS周期。如果老年代空间消耗迅速,你应该在较早的时候启动CMS周期,但是也不应低于活跃数据的占用的比率。</strong></font>不应该将启动CMS周期的值设置得比活跃数据的大小低,解决这个问题更好的方法是增大老年代空间的大小。</p><h3 id="显式的垃圾收集">显式的垃圾收集</h3><p>使用CMS时,如果你观察到由显式调用System.gc()触发的Full GC,有2种处理的方法。</p><p>1、可以使用如下的 HotSpot VM命令行选项,指定 HotSpot VM以CMS垃圾收集周期的方式执行</p><p>-XX:+ExplicitGCInvokesConcurrent</p><p>或者</p><p>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses</p><p>前者需要Java6及以上版本。后者需要Java6 Update4及以上版本。如果你的JDK版本支持,最好使用-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses选项。</p><p>2、也可以使用下面的命令行通知HotSpot VM忽略显式的 System.gc()调用</p><p>-XX:+DisableExplicitGC</p><p>要留意的是,使用这个命令行选项也会导致其他 HotSpot VM的垃圾收集器忽略显式的System.gc()调用。</p><p>禁用显式的垃圾收集时应该慎重,它可能会对应用程序的性能造成较大影响。还有可能出现这样的场景,你需要及时对对象引用做处理,但与之对应的垃圾收集却跟不上其节奏。使用Java RMI的应用程序尤其容易碰到这种问题。我们建议除非有非常明确的理由,否则不要轻易地禁用显式的垃圾收集。与此同时,也建议只在有明确理由的情况下才在应用程序中使用System.gc()。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2010-12-16T23:04:39.452-0600:[Full GC(System)</span><br><span class="line">CMS:418061K-&gt;428608K(16384K),0.2539726 secs</span><br><span class="line">418749K-&gt;4288608K(31168K),</span><br><span class="line">[CMS Perm:32428K-&gt;32428K(65536K)],</span><br><span class="line">0.2540393 secs]</span><br><span class="line">[Times: user=0. 12 sys=0. 01, real=0. 25 secs]</span><br></pre></td></tr></table></figure><p>请留意Full GC之后的(System)标签,它表明System.gc()触发了本次 Full GC。如果在垃圾收集日志中发现了显式的Full GC,你需要先判断为什么它会发生,之后再决定是否要禁用,是否要把该调用从代码中移除,或者是否有必要指定一个条件来触发CMS并发垃圾收集周期。</p><h2 id="应用程序吞吐量调优">应用程序吞吐量调优</h2><blockquote><p>一个通用原则是使用 Throughput收集器时,垃圾收集的开销应该小于5%。如果可以将垃圾收集的开销减少到1%甚至更少,那基本上就已经到了极限,进一步优化花费的代价很大。</p></blockquote><h3 id="调优并行垃圾收集线程">调优并行垃圾收集线程</h3><p>并行垃圾收集器使用的线程数也应该依据系统上运行的应用程序数以及底层的硬件平台进行相应的调优。多个应用程序运行于同一个系统上时,建议通过命令行选项-XX:ParallelGCThreads=&lt;n&gt;将并行垃圾收集的线程数设置为小于其默认值。</p><p>否则,由于大量的垃圾收集线程同时运行,其他应用程序的性能将受到严重影响。截至Java6 Update23,默认情况下并行垃圾收集的线程数等于Java API Runtime.availableProcessors()的返回值(如果该返回值小于等于8),否则其等于8+(Runtime.availableProcessors()-8)*5/8。<font color="DeepPink">多个应用程序运行于同一系统上时设置并行垃圾收集线程的一个通用原则是用虚拟处理器的数目 (Runtime.availableProcessors()的返回值)除以该系统上运行的应用程序数。</font>这里我们假设这些应用程序的负荷及堆大小的情况相差不大。如果应用程序的负荷及Java堆大小差异很大,那么为每个Java应用设置不同权重,并据此设置并行垃圾线程数是一个比较好的方法。</p><h3 id="在NUMA系统上部署">在NUMA系统上部署</h3><p>如果应用程序需要在NUMA(非一致性内存架构)系统上部署,还有一个可以与Throughput收集器一起使用的HotSpot命令行选项是:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseNUMA</span><br></pre></td></tr></table></figure><p>该命令行选项根据CPU与内存位置的关系在分配线程运行的本地内存中分配对象。这里依据的假设是分配对象的线程是近期最有可能访问该对象的线程。相对于远程的内存而言,在同一线程的本地内存中分配对象用更短的时间即能访问该对象的内容。</p><p>只有当JVM的部署跨CPU、不同CPU访问内存的拓扑有所不同,导致访问时间也有所差别的环境下才选择使用-XX:+UseNUMA选项。例如,虽然JVM部署到NUMA系统的一个处理器集上,但是这个处理器集并不存在跨CPU访问内存的拓扑,没有访问时间的差别,那么就不应该使用-XX:+UseNUMA选项。</p><blockquote><p>简而言之,支持NUMA的VM会根据NUMA节点划分堆,线程创建新的对象时,只会在该线程运行所在核的NUMA节点上分配对象,后续该线程如果需要使用这个对象,就直接从本地内存中访问。通常情况下,如果没有使用命令,臂如RHEL下使用numactl,设置CPU的亲和性(Affinity),默认就跨多个内存节点,满足-XX:+UseNUMA的使用条件。</p></blockquote><blockquote><p>注：Throughput garbage collector,实际指的是Parallel收集器</p></blockquote><h2 id="其它性能命令行选项">其它性能命令行选项</h2><h3 id="大页面支持">大页面支持</h3><p>计算机系统的内存被划分成称为“页”的固定大小的块。程序访问内存的过程中会将虚拟内存地址转换成物理内存地址。虚拟地址到物理地址的转换是通过表完成的。为了减少每次内存访问时访问页表的代价,通常的做法是使用一块快速缓存,对虚拟地址到物理地址的转换进行缓存。这块缓存被称为转译快查缓存(TLB)。</p><p>使用TLB完成从虚拟地址到物理地址的映射比遍历整个页表的方式要快得多。TLB通常只能容纳固定数量的条目。TLB中的一条记录就是按页面大小统计的一块内存地址区间的映射。因此系统的页面越大,每个条目能映射的内存地址区间越大,每个TLB能管理的空间也越大。TLB代表的地址区间越大,地址转译请求在TLB中失效的可能性就越小。当一个地址转译请求无法在TLB中找到匹配项时,我们称之发生了“TLB失效”。TLB失效事件发生时常常需要遍历内存中的页表,査找虚拟地址到物理地址的映射。与在TLB中查找地址映射比较起来,遍历页表是一项非常昂贵的操作。由此可见,<font color="DeepPink"><strong>使用大页面的好处是其减小了TLB失效的几率。</strong></font></p><p>HotSpot虚拟机在Oracle solaris(这之后称为Solaris)、 Linux和 Windows上都支持大页面。页面大小还可能随着处理器的不同有所不同。另外,为了使用大页面还可能需要对操作系统进行配置。</p><h1>Java 应用的基准测试</h1><h2 id="基准测试所面临的挑战">基准测试所面临的挑战</h2><h3 id="基准测试的预热阶段">基准测试的预热阶段</h3><p>执行基准测试时使用HotSpot VM命令行选项-XX:+PrintCompilation是一个好习惯,使用该命令行选项的输岀可以判断JIT编译器何时完成了预热阶段,确保在 HotSpot编译器到达稳定态后,即已经完成它的优化工作(生成了适合基准测试的优化机器码)后再开始基准数据采样。-XX:+PrintCompilation选项通知VM为每个它优化或逆优化的函数输出一条日志。下面是在一段微基准测试中使用-XX:+PrintCompilation选项输出的日志片段:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">11	java.util.Random:: nextInt (60 bytes)</span><br><span class="line">12	java.util.Random: next (47 bytes</span><br><span class="line">13	java.util.concurrent atomic Atomi CLong: get (5 bytes)</span><br><span class="line">14	java.util.HashSet: contains (9 bytes)</span><br><span class="line">15	java.util.HashMap: transfer (83 bytes)</span><br><span class="line">16	java.util.Arrays SArrayList: set (16 bytes)</span><br><span class="line">17	java.util.Arrays SArrayList: set (16 bytes)</span><br><span class="line">18	java.util.Collections: swap (25 bytes)</span><br><span class="line">19	java.util.Arrays SArrayList: get (7 bytes)</span><br><span class="line">20	java.lang.Long: &lt;init&gt; (10 bytes)</span><br><span class="line">21	java.lang.Integer: longvalue (6 bytes)</span><br><span class="line">22	java.lang.Long: valueOf (36 bytes)</span><br><span class="line">23	java.lang.Integer: stringSize (21 bytes)</span><br><span class="line">24	java.lang.Integer: getChars (131 bytes)</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>观察日志中已经不再有-XX:+PrintCompilation输出的信息(表明JIT编译器的优化工作已经完成)之后才正式开始采样数据。此外,基准测试还应该在不使用-XX:+PrintCompilation选项的情况下运行几次,比较其性能与使用-XX:+ PrintCompilation选项的结果是否一致。如果二者不一致,可能在创建基准测试或微基准测试时受到了其他因素的影响。</strong></font></p><blockquote><p>微基准测试中有一个惯例,即在开始采样间隔开始计时之前,先调用几次 System.gc()。多次调用 System.gc()的目的是希望通过Java对象的终结方法释放内存,而这往往需要进行多次垃圾收集才能完成。此外,当对象不可达,导致终结方法一直处于等待队列,或者部分执行队列中,调用System.runFinalization()接口可以请求JVM执行其fina1ize()方法,完成垃圾收集。</p></blockquote><h3 id="使用Java-Time接口">使用Java Time接口</h3><p>引入新的System.nanoTime()接口之前,大多数的Java基准测试或微基准测试都使用System.currentTimeMillis()接口获取采样间隔的开始和终止时间,根据终止时间与开始时间的间隔得到运行关注的代码所消耗的时间使用Java的System.currentTimeMillis()和System.nanoTime()接口都有一定程度的精度问题。虽然 System.currentTimeMillis()的返回值是以亳秒计的当前时间,但毫秒级的精度却取决于操作系统。Java API Specification中对于System.currentTimeMillis()有明确的陈述:虽然该接口的返回值是毫秒,但返回值的粒度取决于底层的操作系统。这一规范为操作系统使用自身的亳秒级系统接口提供了方便,但是可能存在这样的情况,尽管使用的是毫秒计数器,但是更新间隔却过大,譬如每30毫秒更新一次。这个规范有意地规定得比较宽松,试图让Java API尽可能地支持更多的操作系统,其中就包含一些无法提供毫秒级时钟精度的操作系统。使用Java API System. nanoTime()也有类似的问题。<font color="DeepPink"><strong>虽然该方法提供了纳秒级的精度,但接口并不保证提供纳秒级的精度: System.nanoTime()的 Java API Specification中明确提到不保证System.nanoTime()返回值的更新频度。</strong></font></p><p>因此,使用System.currentTimeMillis()计算时间消耗时,采样的时间间隔应该足够大,尽量减少System, currentTimeMillis()精度带来的影响。也即是说,采样的时间间隔需要比毫秒大(譬如几秒、或者尽可能几分钟)同样的原则也适用于 System.nanoTime()。根据Java API Specification,System.nanoTime()依赖底层的操作系统,返回系统中可用的最精确时钟的当前值。然而,最精确的可用系统时钟可能也没有纳秒级的精度。进行基准测试时,建议首先摸清楚这两个Java API在对应平台或操作系统上的粒度或精度。如果你不是很清楚,但手里有源代码,可以通过查看这两个API的底层实现,了解其粒度和精度。如果你使用System.currentTimeMillis()或System.nanoTime()。而且采样时间间隔很短(相对于毫秒或纳秒来讲),要特别注意这个问题。</p><blockquote><p>微基准测试时,使用System.nanoTime()获取启动和终止时间计算采样间隔是一种好方法。接着计算终止与启动的时间差就可以得到微基准测试的耗时,以及每次操作选代所消耗的纳秒数或者每秒所发生的迭代次数。<font color="DeepPink"><strong>最重要的是要确保微基准测试运行的时间要足够长,确保应用程序运行已达稳定态且采样的时间也足够长。</strong></font></p></blockquote><h3 id="剔除无效代码">剔除无效代码</h3><p>为了避免微基准测试中的代码被定性为无效代码,引发过度简化的问题,可以采用下面的编程实践：</p><ul><li><font color="DeepPink"><strong>让该方法变得必不可少</strong></font></li><li><font color="DeepPink"><strong>在釆样阶段结束时直接输出计算的结果,或者保存该计算结果,在采样阶段结束后输出该值</strong></font></li></ul><p>要使计算有意义,就要向被测方法传入参数,并从被测方法返回计算结果。此外,在基准测试采样阶段内或在多个不同的基准测试采样阶段间变换迭代次数也是一个不错的方法,然后比较每毫秒内发生的迭代次数,判断迭代次数是否保持恒定,同时使用-XX:+PrintCompilation选项追踪记录JIT编译器的状态。</p><h3 id="内联">内联</h3><p>HotSpot VM的Client和Server JIT编译器都能对方法进行内联。这意味着调用过程中,目标方法会被展开到调用方法中。这个过程是由JIT编译器完成的,JIT编译器通过降低方法调用的开销提升执行性能。此外,内联的代码可能提供更多的优化机会,整合后的代码可能更简单,或者消除了无效调用,而这些在不内联的情况下是无法实现的。内联在微基准测试中还可能实现让人眼前一亮的性能提升。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+PrintInlining</span><br><span class="line">-XX:MaxInlineSize=N</span><br></pre></td></tr></table></figure><h3 id="逆优化">逆优化</h3><p>JIT编译器以其执行优化的能力而著称于世。但是,某些场景下JIT编译器也会进行“逆优化”。譬如,Java应用一旦开始运行,方法调用变得频繁;JIT编译器就可以根据从程序过程中了解到的信息做出优化决策。有些时候,优化的决策在后续可能被证明是错误的。当JIT编译器发现之前的优化作了错误的优化决策时就会进行逆优化。很多时候,在JIT编译器逆优化不久之后(一旦达到一定的执行次数阈值)就会接着再次进行优化。忽视发生的逆优化可能得出错误的性能结论。</p><blockquote><p>使用-XX:+PrintCompilation选项可以帮助确定是否发生了逆优化。-XX:+Printcompilation选项的输出中如果包含“mad not entrant”,即表明之前的编译优化被丢弃了,方法将通过解释器运行,直到该方法执行足够的次数再触发优化。</p></blockquote><p><font color="DeepPink"><strong>软件开发者应该专注于优秀的软件架构、设计以及实现,没有必要过度担忧现代JIT编译器的影响。如果对软件架构、设计或实现的修改是为了克服JIT编译器的一些性质,就应该考虑这是JIT编译器的缺陷或不足。</strong></font></p><h3 id="创建微基准测试的注意事项">创建微基准测试的注意事项</h3><ol><li>明确你需要了解的性能指标是什么,设计相应的实验回答你需要解决的回题。不要受些无关痛痒的因素影响而忽略了你真正需要解决的问题。</li><li>确保采样阶段中每次使用同样的工作量。</li><li>计算并收集多种性能指标,譬如消耗时间、单位时间迭代次数或每次迭代的消耗时间用在预热阶段之后,采样阶段期间记录的性能指标。留意度量时间的精度和粒度,特别是使用了System.currentTimeMi1lis()和System.nanoTime()的情况。多次运行试验,并变换采样的周期数或釆样的持续时间。之后再比较其所消耗的时间,密切注意单位时间迭代次数或每迭代消耗时间指标的变化。微基准测试经历了足够的预热、达到稳定态时,后一个指标几乎应该与釆样阶段持续时间的变化保持一致。</li><li>开始釆样之前确认微基准测试已经到达稳定态。可遵循的一条通用原则是,确保微基准测试至少运行10秒以上。使用 HotSpot的-XX:+PrintCompilation选项通过插入表示微基准测试执行阶段的工具可以帮助确认基准测试已经到达稳定态。这一步的日的是确保在开始采样之前,微基准测试经过充分预热,在采样阶段不会发生进一步的优化或逆优化事件。</li><li>多次运行基准测试以确保观测的结果是可重复的。多次运行可以为你最终的结论提供有力支持。</li><li>运行实验及观测结果时特别要留意得到的结果是否合理。如果碰到无法解释或可疑的结果,要花时间去研究、回顾实验的设计,确保观察的结果合理。</li><li>通过传递随时变化的参数到关注的方法中、返回关注方法的执行结果、在采样周期之外打印输出计算结果使计算更有意义,避免在微基准测试中创建无效代码。</li><li>留意内联可能对微基准测试产生的影响。如果对结果存疑,可以通过XX:+PrintInlining和-XX:+PrintCompilation命令行选项,利用HotSpot Debug VM观察HotSpot JIT编译器进行内联决策的过程。</li><li>确保执行微基准测试时其他的应用程序不会对系统造成影响。执行微基准测试时即使向桌面窗口管理器中添加很小或者很简单的应用程序(譬如天气应用或者股票行情记录软件),都会对系统性能造成影响。</li><li>当你需要很明确地了解JIT编译器生成了什么样的优化代码时,可以使用Oracle Solaris Studio Performance Analyzer或者HotSpot Debug VM(使用-XX:+PrintOptoAssembly选项)查看生成的汇编代码。</li><li>采用小数据集或数据结构的微基准测试受缓存的影响很大。微基准测试的结果可能每次执行都不一样,在不同的机器上运行结果也差别很大。</li><li>对于采用多线程的微基准测试需要意识到线程调度可能不是确定性的,特别是在负荷较重的情况下。</li></ol><p>PDF书籍下载地址：<br><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>读书笔记</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员常用词汇</title>
    <url>/coder-vocabulary.html</url>
    <content><![CDATA[<blockquote><p>下面是工作中，经常用到的一些词汇，持续更新</p></blockquote><a id="more"></a><p>在线：<a href="/attachments/words.txt" target="_blank">程序员常用词汇</a></p>]]></content>
      <categories>
        <category>Words</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Words</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]ZGC: 一个可伸缩的低延迟垃圾收集器</title>
    <url>/zgc-a-scalable-low-latency-garbage-collector.html</url>
    <content><![CDATA[<blockquote><p>翻译自：JEP 333<br>地址：<a href="https://openjdk.java.net/jeps/333" target="_blank" rel="noopener">https://openjdk.java.net/jeps/333</a></p></blockquote><a id="more"></a><h1>一、摘要</h1><p>Z垃圾收集器，也称为ZGC，是一个可伸缩的低延迟垃圾收集器。</p><h1>二、目标</h1><ul><li>GC暂停时间不超过10ms</li><li>能处理大小从相对较小(几百MB)到非常大(TB级)的堆</li><li>与使用G1相比，应用程序吞吐量减少不超过15%</li><li>方便日后在此基础上利用彩色指针和内存屏障进一步优化收集器及实现新特性。【原文：Lay a foundation for future GC features and optimizations leveraging colored pointers and load barriers】</li><li>支持平台:Linux/x64</li></ul><blockquote><p>注：此处及下文中的内存屏障即load barrier，在ZGC中用的是读屏障。</p></blockquote><h1>三、动机</h1><p>垃圾收集是Java的主要优势之一。但是，当垃圾收集暂停太长时，就会对应用程序的响应时间产生负面影响。通过大幅度缩短停顿时间，我们可以让Java适用于更多类型的应用程序。</p><p>此外，现代系统中可用的内存数量还在继续增长。<strong>用户和应用程序开发人员希望JVM能够以一种有效的方式充分利用这种内存，并且不会出现很长的GC暂停时间。</strong></p><h1>四、 描述</h1><p>ZGC是一个并发的、单代（不再区分新生代和老年代）的、基于region的、支持numa的压缩收集器。Stop-the-world阶段仅限于根扫描，所以GC暂停时间不会随着堆或存活对象的多少而增加。</p><p><font color="DeepPink"><strong>ZGC的一个核心设计原则是结合使用内存屏障和彩色对象指针。这使得ZGC能够在运行Java应用程序线程时执行并发操作，比如对象重定位。从Java线程的角度来看，在Java对象中加载引用字段的行为受到内存屏障的限制。除了对象地址之外，有色对象指针还包含内存屏障需要的信息，用于确定在允许Java线程使用该指针之前是否需要采取某些操作。</strong></font>例如，对象可能已经被重新定位，在这种情况下，内存屏障将检测情况并采取适当的操作。</p><p>与其他技术相比，我们认为颜色指针方案提供了一些非常吸引人的特性。特别是:</p><ul><li><p>这允许我们在移动对象/整理内存阶段，在指向可回收/重用区域的指针确定之前回收/重用这部分内存【原文：It allows us to reclaim and reuse memory during the relocation/compaction phase, before pointers pointing into the reclaimed/reused regions have been fixed. 】。这有助于降低堆开销。这还意味着不需要实现单独的标记压缩算法来处理完整的GC。</p></li><li><p>这允许我们使用相对较少且简单的GC屏障。这有助于降低运行时开销。这还意味着在解释器和JIT编译器中更容易实现、优化和维护GC barrier代码。</p></li><li><p>我们目前将标记和重新定位相关信息存储在彩色指针中。然而，此方案的通用性允许我们存储任何类型的信息(只要我们能将其放入指针中)，并允许内存屏障根据该信息采取它想要采取的任何操作。我们相信这将为将来的许多特性打下基础。举一个例子，在异构内存环境中，这可以用来跟踪堆访问模式，以指导GC重新定位决策，将很少使用的对象移动到冷存储(不常访问的内存区域)中【原文：To pick one example, in a heterogeneous memory environment, this could be used to track heap access patterns to guide GC relocation decisions to move rarely used objects to cold storage.】。</p></li></ul><h1>五、性能</h1><p>我们已经使用SPECjbb 2015[1]做了常规性能测试。从吞吐量和延迟角度来看，性能都很好。下面是使用128G堆在复合模式下比较ZGC和G1的典型基准分数(以百分比为单位，根据ZGC的max-jOPS进行标准化)【原文：Below are typical benchmark scores (in percent, normalized against ZGC’s max-jOPS), comparing ZGC and G1, in composite mode using a 128G heap.】：</p><blockquote><p>越高越好</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ZGC</span><br><span class="line">       max-jOPS: 100%</span><br><span class="line">  critical-jOPS: 76.1%</span><br><span class="line"></span><br><span class="line">G1</span><br><span class="line">       max-jOPS: 91.2%</span><br><span class="line">  critical-jOPS: 54.7%</span><br></pre></td></tr></table></figure><p>下面是来自相同基准测试的GC暂停时间。ZGC设法保持远低于10ms的目标。注意，确切的数字可能会根据使用的机器和设置而变化(上下都有，但不是很明显)。</p><blockquote><p>越低越好</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ZGC</span><br><span class="line">                avg: 1.091ms (+/-0.215ms)</span><br><span class="line">    95th percentile: 1.380ms</span><br><span class="line">    99th percentile: 1.512ms</span><br><span class="line">  99.9th percentile: 1.663ms</span><br><span class="line"> 99.99th percentile: 1.681ms</span><br><span class="line">                max: 1.681ms</span><br><span class="line"></span><br><span class="line">G1</span><br><span class="line">                avg: 156.806ms (+/-71.126ms)</span><br><span class="line">    95th percentile: 316.672ms</span><br><span class="line">    99th percentile: 428.095ms</span><br><span class="line">  99.9th percentile: 543.846ms</span><br><span class="line"> 99.99th percentile: 543.846ms</span><br><span class="line">                max: 543.846ms</span><br></pre></td></tr></table></figure><p>我们还对其他各种SPEC®基准测试和内部工作负载进行了特别的性能测量。一般情况下，ZGC能够维护个位数的毫秒暂停时间。</p><h1>六、 局限性</h1><p>ZGC的初始实验版本将不支持类卸载。默认情况下，classunload和ClassUnloadingWithConcurrentMark选项将被禁用。即便你启用也是不生效的。</p><p>此外，ZGC最初不支持JVMCI(即Graal)。如果启用EnableJVMCI选项，将打印一条错误消息。</p><p>这些限制将在本项目的后期解决。</p><h1>七、 构建和使用</h1><p>按照惯例，构建系统默认禁用JVM中的实验性特性。ZGC是一个实验性特性，因此不会出现在JDK构建中，除非在编译时使用configure选项:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--with-jvm-features=zgc</span><br></pre></td></tr></table></figure><p>显式地启用它。</p><p>(ZGC将出现在Oracle发布的所有Linux/x64 JDK版本中)</p><p>JVM中的实验特性还需要在运行时显式地解锁。因此，要启用/使用ZGC，需要以下JVM选项:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+ unlockexperimental alvmoptions -XX:+UseZGC</span><br></pre></td></tr></table></figure><p>有关如何设置和调优ZGC的更多信息，请参阅ZGC项目Wiki（wiki地址：<a href="https://wiki.openjdk.java.net/display/zgc/Main%EF%BC%89%E3%80%82" target="_blank" rel="noopener">https://wiki.openjdk.java.net/display/zgc/Main）。</a></p><p>ZGC paper可以参考Azul Pauseless GC Algorithm：</p><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/Azul_Pauseless_GC_Algorithm.pdf" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/Azul_Pauseless_GC_Algorithm.pdf</a></p><p>ZGC 简介PPT:</p><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/ZGC-FOSDEM-2018.pdf" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/blob/master/GC/ZGC/ZGC-FOSDEM-2018.pdf</a></p>]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>翻译</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>JVM</tag>
        <tag>ZGC</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]ElasticSearch 查询的秘密</title>
    <url>/elasticsearch-query-secret.html</url>
    <content><![CDATA[<p>最近在参与一个基于Elasticsearch作为底层数据框架提供大数据量(亿级)的实时统计查询的方案设计工作，花了些时间学习Elasticsearch的基础理论知识，整理了一下，希望能对Elasticsearch感兴趣/想了解的同学有所帮助。同时也希望有发现内容不正确或者有疑问的地方，望指明，一起探讨，学习，进步。</p><h2 id="介绍">介绍</h2><blockquote><p>Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎.</p></blockquote><p>Elasticsearch 是一个建立在全文搜索引擎 Apache Lucene™ 基础上的搜索引擎.<br>当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:</p><ul><li>分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。</li><li>实时分析的分布式搜索引擎。</li><li>可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。</li></ul><h3 id="基本概念">基本概念</h3><p>先说Elasticsearch的文件存储，Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用JSON作为文档序列化的格式，比如下面这条用户数据：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span> :     <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"sex"</span> :      <span class="string">"Male"</span>,</span><br><span class="line">    <span class="attr">"age"</span> :      <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"birthDate"</span>: <span class="string">"1990/05/01"</span>,</span><br><span class="line">    <span class="attr">"about"</span> :    <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">    <span class="attr">"interests"</span>: [ <span class="string">"sports"</span>, <span class="string">"music"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用Mysql这样的数据库存储就会容易想到建立一张User表，有balabala的字段等，在Elasticsearch里这就是一个<em>文档</em>，当然这个文档会属于一个User的<em>类型</em>，各种各样的类型存在于一个<em>索引</em>当中。这里有一份简易的将Elasticsearch和关系型数据术语对照表:</p><p>关系数据库 ⇒ 数据库 ⇒ 表 ⇒ 行 ⇒ 列(Columns)</p><p>Elasticsearch ⇒ 索引 ⇒ 类型 ⇒ 文档 ⇒ 字段(Fields)</p><p>一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。</p><p>Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT /megacorp/employee/1</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span> :     <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"sex"</span> :      <span class="string">"Male"</span>,</span><br><span class="line">    <span class="attr">"age"</span> :      <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"about"</span> :    <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">    <span class="attr">"interests"</span>: [ <span class="string">"sports"</span>, <span class="string">"music"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更新，查询也是类似这样的操作，具体操作手册可以参见<a href="http://www.learnes.net/data/README.html" target="_blank" rel="noopener">Elasticsearch权威指南</a></p><hr><h2 id="索引">索引</h2><p>Elasticsearch最关键的就是提供强大的索引能力了，其实InfoQ的这篇<a href="http://www.infoq.com/cn/articles/database-timestamp-02?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank" rel="noopener">时间序列数据库的秘密(2)——索引</a>写的非常好，我这里也是围绕这篇结合自己的理解进一步梳理下，也希望可以帮助大家更好的理解这篇文章。</p><p>Elasticsearch索引的精髓：</p><blockquote><p>一切设计都是为了提高搜索的性能</p></blockquote><p>另一层意思：为了提高搜索的性能，难免会牺牲某些其他方面，比如插入/更新，否则其他数据库不用混了:)</p><p>前面看到往Elasticsearch里插入一条记录，其实就是直接PUT一个json的对象，这个对象有多个fields，比如上面例子中的<em>name, sex, age, about, interests</em>，那么在插入这些数据到Elasticsearch的同时，Elasticsearch还默默的为这些字段建立索引–倒排索引，因为Elasticsearch最核心功能是搜索。</p><blockquote><p>Elasticsearch默认会为每个字段根据value的类型分别建立索引，如果不想为某些字段建立索引或者不做分词分析的话，需要通过FieldMapping注明。</p></blockquote><h3 id="Elasticsearch是如何做到快速索引的">Elasticsearch是如何做到快速索引的</h3><p>InfoQ那篇文章里说Elasticsearch使用的倒排索引比关系型数据库的B-Tree索引快，为什么呢？</p><h4 id="什么是B-Tree索引">什么是B-Tree索引?</h4><p>上大学读书时老师教过我们，二叉树查找效率是logN，同时插入新的节点不必移动全部节点，所以用树型结构存储索引，能同时兼顾插入和查询的性能。</p><p>因此在这个基础上，再结合磁盘的读取特性(顺序读/随机读)，传统关系型数据库采用了B-Tree/B+Tree这样的数据结构：</p><p><img data-src="/images/elasticsearch-query-secret/b-tree.png" alt></p><p>为了提高查询的效率，减少磁盘寻道次数，将多个值作为一个数组通过连续区间存放，一次寻道读取多个数据，同时也降低树的高度。</p><h4 id="什么是倒排索引">什么是倒排索引?</h4><p><img data-src="/images/elasticsearch-query-secret/inverted-index.png" alt></p><p>继续上面的例子，假设有这么几条数据(为了简单，去掉about, interests这两个field):</p><table><thead><tr><th>ID</th><th style="text-align:center">Name</th><th style="text-align:right">Age</th><th style="text-align:right">Sex</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">Kate</td><td style="text-align:right">24</td><td style="text-align:right">Female</td></tr><tr><td>2</td><td style="text-align:center">John</td><td style="text-align:right">24</td><td style="text-align:right">Male</td></tr><tr><td>3</td><td style="text-align:center">Bill</td><td style="text-align:right">29</td><td style="text-align:right">Male</td></tr></tbody></table><p>ID是Elasticsearch自建的文档id，那么Elasticsearch建立的索引如下:</p><p><strong>Name:</strong></p><table><thead><tr><th>Term</th><th style="text-align:center">Posting List</th></tr></thead><tbody><tr><td>Kate</td><td style="text-align:center">1</td></tr><tr><td>John</td><td style="text-align:center">2</td></tr><tr><td>Bill</td><td style="text-align:center">3</td></tr></tbody></table><p><strong>Age:</strong></p><table><thead><tr><th>Term</th><th style="text-align:center">Posting List</th></tr></thead><tbody><tr><td>24</td><td style="text-align:center">[1,2]</td></tr><tr><td>29</td><td style="text-align:center">3</td></tr></tbody></table><p><strong>Sex:</strong></p><table><thead><tr><th>Term</th><th style="text-align:center">Posting List</th></tr></thead><tbody><tr><td>Female</td><td style="text-align:center">1</td></tr><tr><td>Male</td><td style="text-align:center">[2,3]</td></tr></tbody></table><h5 id="Posting-List">Posting List</h5><p>Elasticsearch分别为每个field都建立了一个倒排索引，Kate, John, 24, Female这些叫term，而[1,2]就是<strong>Posting List</strong>。Posting list就是一个int的数组，存储了所有符合某个term的文档id。</p><p>看到这里，不要认为就结束了，精彩的部分才刚开始…</p><p>通过posting list这种索引方式似乎可以很快进行查找，比如要找age=24的同学，爱回答问题的小明马上就举手回答：我知道，id是1，2的同学。但是，如果这里有上千万的记录呢？如果是想通过name来查找呢？</p><h5 id="Term-Dictionary">Term Dictionary</h5><p>Elasticsearch为了能快速找到某个term，将所有的term排个序，二分法查找term，logN的查找效率，就像通过字典查找一样，这就是<strong>Term Dictionary</strong>。现在再看起来，似乎和传统数据库通过B-Tree的方式类似啊，为什么说比B-Tree的查询快呢？</p><h5 id="Term-Index">Term Index</h5><p><code>B-Tree通过减少磁盘寻道次数来提高查询性能，Elasticsearch也是采用同样的思路，直接通过内存查找term，不读磁盘，但是如果term太多，term dictionary也会很大，放内存不现实，于是有了<strong>Term Index</strong>，就像字典里的索引页一样，A开头的有哪些term，分别在哪页，可以理解term index是一颗树</code>：<br><img data-src="/images/elasticsearch-query-secret/term-index.png" alt></p><p>这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。<br><img data-src="/images/elasticsearch-query-secret/index.png" alt></p><p>所以term index不需要存下所有的term，而仅仅是他们的一些前缀与Term Dictionary的block之间的映射关系，再结合FST(Finite State Transducers)的压缩技术，可以使term index缓存到内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘随机读的次数。</p><p>这时候爱提问的小明又举手了:“那个FST是神马东东啊?”</p><p>一看就知道小明是一个上大学读书的时候跟我一样不认真听课的孩子，数据结构老师一定讲过什么是FST。但没办法，我也忘了，这里再补下课：</p><blockquote><p>FSTs are finite-state machines that <strong>map</strong> a <strong>term (byte sequence)</strong> to an arbitrary <strong>output</strong>.</p></blockquote><p>假设我们现在要将mop, moth, pop, star, stop and top(term index里的term前缀)映射到序号：0，1，2，3，4，5(term dictionary的block位置)。最简单的做法就是定义个Map&lt;String, Integer&gt;，大家找到自己的位置对应入座就好了，但从内存占用少的角度想想，有没有更优的办法呢？答案就是：<strong>FST</strong>(<a href="http://www.cs.nyu.edu/~mohri/pub/fla.pdf" target="_blank" rel="noopener">理论依据在此，但我相信99%的人不会认真看完的</a>)</p><p><img data-src="/images/elasticsearch-query-secret/fst.png" alt></p><p>⭕️表示一种状态</p><p>–&gt;表示状态的变化过程，上面的字母/数字表示状态变化和权重</p><p>将单词分成单个字母通过⭕️和–&gt;表示出来，0权重不显示。如果⭕️后面出现分支，就标记权重，最后整条路径上的权重加起来就是这个单词对应的序号。</p><blockquote><p>FSTs are finite-state machines that map a term (<strong>byte sequence</strong>) to an arbitrary output.</p></blockquote><p>FST以字节的方式存储所有的term，这种压缩方式可以有效的缩减存储空间，使得term index足以放进内存，但这种方式也会导致查找时需要更多的CPU资源。</p><p>后面的更精彩，看累了的同学可以喝杯咖啡……</p><hr><blockquote><p><a href="http://examples.mikemccandless.com/fst.py" target="_blank" rel="noopener">http://examples.mikemccandless.com/fst.py</a><br>Amazon DynamoDB<br>Cassandra<br>Elasticsearch<br>Hive<br>MongoDB<br>MySQL<br>PostgreSQL<br>SQLite</p></blockquote><h4 id="压缩技巧">压缩技巧</h4><p>Elasticsearch里除了上面说到用FST压缩term index外，对posting list也有压缩技巧。<br>小明喝完咖啡又举手了:“posting list不是已经只存储文档id了吗？还需要压缩？”</p><p>嗯，我们再看回最开始的例子，如果Elasticsearch需要对同学的性别进行索引(这时传统关系型数据库已经哭晕在厕所……)，会怎样？如果有上千万个同学，而世界上只有男/女这样两个性别，每个posting list都会有至少百万个文档id。<br>Elasticsearch是如何有效的对这些文档id压缩的呢？</p><h5 id="Frame-Of-Reference">Frame Of Reference</h5><blockquote><p>增量编码压缩，将大数变小数，按字节存储</p></blockquote><p>首先，Elasticsearch要求posting list是有序的(为了提高搜索的性能，再任性的要求也得满足)，这样做的一个好处是方便压缩，看下面这个图例：<br><img data-src="/images/elasticsearch-query-secret/frameOfReference.png" alt></p><p>如果数学不是体育老师教的话，还是比较容易看出来这种压缩技巧的。</p><p><font color="DeepPink"><strong>原理就是通过增量，将原来的大数变成小数仅存储增量值，再精打细算按bit排好队，最后通过字节存储</strong></font>，而不是大大咧咧的尽管是2也是用int(4个字节)来存储。</p><h5 id="Roaring-bitmaps">Roaring bitmaps</h5><p>说到Roaring bitmaps，就必须先从bitmap说起。Bitmap是一种数据结构，假设有某个posting list：</p><p>[1,3,4,7,10]</p><p>对应的bitmap就是：</p><p>[1,0,1,1,0,0,1,0,0,1]</p><p>非常直观，用0/1表示某个值是否存在，比如10这个值就对应第10位，对应的bit值是1，这样用一个字节就可以代表8个文档id，旧版本(5.0之前)的Lucene就是用这样的方式来压缩的，但这样的压缩方式仍然不够高效，如果有1亿个文档，那么需要12.5MB的存储空间，这仅仅是对应一个索引字段(我们往往会有很多个索引字段)。于是有人想出了Roaring bitmaps这样更高效的数据结构。</p><p>Bitmap的缺点是存储空间随着文档个数线性增长，Roaring bitmaps需要打破这个魔咒就一定要用到某些指数特性：</p><p>将posting list按照65535为界限分块，比如第一块所包含的文档id范围在0 ~ 65535之间，第二块的id范围是65536 ~ 131071，以此类推。再用&lt;商，余数&gt;的组合表示每一组id，这样每组里的id范围都在0 ~ 65535内了，剩下的就好办了，既然每组id不会变得无限大，那么我们就可以通过最有效的方式对这里的id存储。</p><p><img data-src="/images/elasticsearch-query-secret/Roaringbitmaps.png" alt></p><p>细心的小明这时候又举手了:“为什么是以65535为界限?”</p><p>程序员的世界里除了1024外，65535也是一个经典值，因为它=2^16-1，正好是用2个字节能表示的最大数，一个short的存储单位，注意到上图里的最后一行“If a block has more than 4096 values, encode as a bit set, and otherwise as a simple array using 2 bytes per value”，如果是大块，用节省点用bitset存，小块就豪爽点，2个字节我也不计较了，用一个short[]存着方便。</p><p>那为什么用4096来区分采用数组还是bitmap的阀值呢？</p><p>这个是从内存大小考虑的，当block块里元素超过4096后，用bitmap更剩空间：<br>采用bitmap需要的空间是恒定的: 65536/8 = 8192bytes<br>而如果采用short[]，所需的空间是: 2*N(N为数组元素个数)<br>小明手指一掐N=4096刚好是边界:</p><p><img data-src="/images/elasticsearch-query-secret/block-memory.png" alt></p><hr><h4 id="联合索引">联合索引</h4><p>上面说了半天都是单field索引，如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？</p><ul><li>利用跳表(Skip list)的数据结构快速做“与”运算，或者</li><li>利用上面提到的bitset按位“与”</li></ul><p>先看看跳表的数据结构：</p><p><img data-src="/images/elasticsearch-query-secret/skiplist.png" alt></p><p>将一个有序链表level0，挑出其中几个元素到level1及level2，每个level越往上，选出来的指针元素越少，查找时依次从高level往低查找，比如55，先找到level2的31，再找到level1的47，最后找到55，一共3次查找，查找效率和2叉树的效率相当，但也是用了一定的空间冗余来换取的。</p><p>假设有下面三个posting list需要联合索引：</p><p><img data-src="/images/elasticsearch-query-secret/combineIndex.png" alt></p><p>如果使用跳表，对最短的posting list中的每个id，逐个在另外两个posting list中查找看是否存在，最后得到交集的结果。</p><p>如果使用bitset，就很直观了，直接按位与，得到的结果就是最后的交集。</p><hr><h3 id="总结和思考">总结和思考</h3><p>Elasticsearch的索引思路:</p><blockquote><p>将磁盘里的东西尽量搬进内存，减少磁盘随机读取次数(同时也利用磁盘顺序读特性)，结合各种奇技淫巧的压缩算法，用及其苛刻的态度使用内存。</p></blockquote><p>所以，对于使用Elasticsearch进行索引时需要注意:</p><ul><li>不需要索引的字段，一定要明确定义出来，因为默认是自动建索引的</li><li>同样的道理，对于String类型的字段，不需要analysis的也需要明确定义出来，因为默认也是会analysis的</li><li>选择有规律的ID很重要，随机性太大的ID(比如java的UUID)不利于查询</li></ul><p>看一下filebeat收集日志后，elasticsearch自动生成的id，如图：<br><img data-src="/images/elasticsearch-query-secret/filebeat_log_id.png" alt></p><p>关于最后一点，个人认为有多个因素:</p><p>其中一个(也许不是最重要的)因素: 上面看到的压缩算法，都是对Posting list里的大量ID进行压缩的，那如果ID是顺序的，或者是有公共前缀等具有一定规律性的ID，压缩比会比较高；</p><p>另外一个因素: 可能是最影响查询性能的，应该是最后通过Posting list里的ID到磁盘中查找Document信息的那步，因为Elasticsearch是分Segment存储的，根据ID这个大范围的Term定位到Segment的效率直接影响了最后查询的性能，如果ID是有规律的，可以快速跳过不包含该ID的Segment，从而减少不必要的磁盘读次数，具体可以参考这篇<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html" target="_blank" rel="noopener">如何选择一个高效的全局ID方案</a>(评论也很精彩)</p><p>后续再结合实际开发及调优工作分享更多内容，敬请期待！</p><hr><h2 id="拓展">拓展</h2><h3 id="倒排索引：ES倒排索引底层原理及FST算法的实现过程">倒排索引：ES倒排索引底层原理及FST算法的实现过程</h3><h4 id="字典树：Trie（Prefix-Tree）原理">字典树：Trie（Prefix Tree）原理</h4><p>一直以来，数据结构的“小”而“快”是每个追求更好性能的developer孜孜不倦追求的目标，所谓“快”即检索速度快，“小”即通用最小化算法。上一节我们介绍了倒排表的数据压缩原理和过程，自本节开始，我们分几部分详细介绍一下Lucene中对倒排索引Term DIctionary以及Term Index的数据压缩和优化算法。<br><img data-src="/images/elasticsearch-query-secret/words.png" alt></p><p>我们已经了解到，Term Dictionary是字典序非重复的 K-V 结构的，而通常搜索引擎级别的倒排索引，Term Dictionary 动辄以“亿”起步，这势必要求我们在做数据存储时对其数据结构有极其高的要求。以图4-1为例，假设途中英汉词典片段就是我们要存储的词项字典，为了遵循“通用最小化算法”对其进行数据压缩，我们就必须要考虑如何以最小的代价换区最高的效率。通过观察不难发现，无论任何一个Term，无外乎由26个英文字母组成，这也就意味越多的词项就会造成的越多的数据“重复”。这里所说的重复指的是词项之间会有很多个公共部分，如“abandon”和“abandonment”就共享了公共前缀“abandonment”。我们是否可以像Java开发过程中对代码的封装那样，重复利用这一部分公共内容呢？答案是肯定的！Lucene在存储这种有重复字符的数据的时候，只会存储一次，也就是哪怕有一亿个以abandon为前缀的词项，“abandom”这个前缀也只会存储一次。这里就用到了一种我们经常用到的一种数据结构：Trie即字典树，也叫前缀树（Prefix Tree）。下面我们以Term Dictionary：（msb、msbtech、msn、wltech）为例，演示一下Trie是如何存储Term Dictionary的。<br><img data-src="/images/elasticsearch-query-secret/Term_Dictionary.png" alt></p><p>如上图4-2所示，我们按照每个Term一步来演示Trie是如何存储Term Dictionary的。图中我们以圆形标识节点，箭头代表节点的出度，出度存储了当前节点对应的字符。当输入词项“msb”的时候，如果图中第一步所示，图中以加粗的圆圈标识当前节点是一个终止节点。当输入第二个词项“msbtech”的时候，复用了“msb”，当输入“msn”的时候，节点2添加了第二个出度，至此我们已经实现了对重复关键字的复用。但是问题也就随之而来了，当最后一个Term输入的时候，节点0产生了第二个出度。</p><h4 id="FST的构建原理">FST的构建原理</h4><p>细心的你应该已经发现了，在使用字典树存储Term Dictionary的案例中，字符“tech”也属于重复部分，但是未被合理复用，导致了空间浪费。为了解决这个问题，Lucene采用了另一种数据结构：FST（Finite State Transducer），即“有限状态转换机”。FST是本章内容难点，也是倒排索引的核心数据结构。</p><p>通常我们在计算机的语言中标示一件事物，都会通过某种数学模型来描述。假如现在我们要描述一件事：张三一天的所有活动。这里我们采用了一种叫做FSM（Finite State Machine）的抽象模型，如图5-1所示，这种模型使用原型的节点标示某个“状态”，状态之间可以互相转换，但是转换过程是无向的。比如睡觉醒了可以去工作，工作累了可以去玩手机；或者工作中想去上厕所等等。在这个模型中，标示状态的节点是有限多个的，但状态的转换的情况是无限多的，同一时刻只能处于某一个状态，并且状态的转换是无序切循环的。</p><p><img data-src="/images/elasticsearch-query-secret/Finite_State_Machine.png" alt></p><p>显然这种模型并不适用于描述Term Dictionary这样的数据结构，但是我们之所以提他，是为了方便读者理解这种具化事务抽象化描述的方式。虽然FSM并不适合，但是在他的基础上演化出了FSA（Finite State Acceptor）,我们仍然以图 4-2 中的Term Dictionary数据为例，演示一下FSA是如何在Trie的基础上进行优化的。</p><p><img data-src="/images/elasticsearch-query-secret/FSA_1.png" alt></p><p>如上图5-2所示，相较于FSM，FSA增加了Entry和Final的概念，也就是由状态转换的不确定性变为了确定，由闭环变为了单向有序，这一点和Trie是类似的，但是不同的是，FSA的Final节点是唯一的，也是因为这个原因，FSA在录入和Trie相同的Term Dictionary数据的时候，从第三步开始才表现出了区别，即尾部复用。如果在第三步的时候还不太明显，那第四步中就可以清楚的看到FSA在后缀的处理上更加高效。</p><p>至此，FSA已经满足了对Term Dictionary数据高效存储的基本要求，但是仍然不满足的一个问题就是，FSA无法存储key-value的数据类型，所以FST在此基础上为每一个出度添加了一个output属性，用来表示每个term的value值。下面以Term Dictionary：（msb/10、msbtech/5、msn/2、wltech/8、wth/16）为例，演示一下FST的构建原理，斜线后面的数字代表每个term的输出值。</p><p><img data-src="/images/elasticsearch-query-secret/FST_1.png" alt></p><p>通用最小化算法的应用面非常广泛，这里其实也是遵循了这样的规则。可复用的不仅仅Term的字符，输出值之所以被存储了最靠前的位置上，目的也是为了让更多的Term复用，如果输出值产生了冲突，再去处理冲突问题，最终生成最小化FST。</p><p>如上图5-3所示，当第一个term:msb被写入FST中，其输出值被保存在了其第一个节点的出度上，在数据从FST中读取的时候， 计算其每个节点对应的出度的输出值以及终止节点的final output值的累加和，从而得出输出值，此时msb的输出值就是10+0+0+0=10，但是这里我用0来标识没有输出值，但实际情况没有输出值就是空而不是0，这里写0只是为了方便你去理解，这一点是需要注意的。</p><p>当第二个term:msbteach被写入的时候，其输出值5与msb的输出值10发生了冲突，这时，通用最小化算法法则再次发挥了功效。数字虽然不能像字符那样以前缀作为复用手段，但是数字是可以累加的，10可以拆成两个数字5，这样10和5就产生了公共部分，即5，所以这个时候m的输出值就需要改成5，那另一个5就需要找一个合适的位置，然而把它存放在任何一个节点的出度上似乎都会影响msbtech的计算结果，为了避免这个问题，可以把这个多出来的属于msb的输出值存入msb的final节点的final output中，节点的final output只会在当前出度是输入值的最后一个字符并且出度的target指向的是final节点的时候，才会参与计算。因此此时的msb和msbtech就各自把输出值存入了合适的位置，互不影响而且做到了“通用最小化”原则。</p><p><img data-src="/images/elasticsearch-query-secret/FST_2.png" alt></p><p>输入第三个term:msn，节点2产生了第二个出度：n，2 &lt; 5，根据&quot;通用最小化&quot;法则，2和5有公共部分：2，5倍拆分成了2和3，此时公共前缀为“ms”，前面以“ms”为前缀的所有term都讲重新计算出度output，此时3需要满足：不能存放在公共前缀“ms”上，并且也不能在第二条出度“n”上，因此只能存放在出度b上，因为b在当前节点2第一条出度的链路上是最靠前的位置。这里FST和Trie最大的区别就是FST不仅使用了公共前缀，而且还计算了公共后缀，“msn”的最终节点会指向节点7，和节点6的出度h共享终止节点。</p><p>其实到这里还不能很好的提现“公共后缀”，但是输入wltech的时候，此时就产生了公共后缀“tech”，节点2的出度b和节点8的出度t共同指向了节点3。</p><p>输入最后一个term:wth，公共前缀为w，公共后缀为h，最终生成的FST如上图5-4所示。</p><blockquote><p>摘自:<a href="https://blog.csdn.net/wlei0618/article/details/125846561" target="_blank" rel="noopener">https://blog.csdn.net/wlei0618/article/details/125846561</a></p></blockquote><h3 id="为什么Elasticsearch比MySQL的检索快？">为什么Elasticsearch比MySQL的检索快？</h3><p>对比MySQL的B+Tree索引原理，可以发现：</p><ol><li><p><code>Lucene的Term index和Term Dictionary其实对应的就是MySQL的B+Tree的功能，为关键字key提供索引。Lucene的inverted index可以比MySQL的b-tree检索更快。</code></p></li><li><p><code>Term index在内存中是以FST（finite state transducers）的形式保存的，其特点是非常节省内存。所以Lucene搜索一个关键字key的速度是非常快的，而MySQL的B+Tree需要读磁盘比较。</code></p></li><li><p><code>Term dictionary在磁盘上是以分block的方式保存的，一个block内部利用公共前缀压缩，比如都是Ab开头的单词就可以把Ab省去。这样Term dictionary可以比B-tree更节约磁盘空间。</code></p></li><li><p><code>Lucene对不同的数据类型采用了不同的索引方式，上面分析是针对field为字符串的，比如针对int，有TrieIntField类型，针对经纬度，就可以用GeoHash编码。</code></p></li><li><p><code>在 Mysql中给两个字段独立建立的索引无法联合起来使用，必须对联合查询的场景建立复合索引，而Lucene可以任何AND或者OR组合使用索引进行检索。</code></p></li></ol><blockquote><p>摘自：<a href="https://www.cnblogs.com/luxiaoxun/p/5452502.html" target="_blank" rel="noopener">https://www.cnblogs.com/luxiaoxun/p/5452502.html</a></p></blockquote><h3 id="倒排检索加速-工业界如何利用跳表、哈希表、位图进行加速">倒排检索加速_工业界如何利用跳表、哈希表、位图进行加速?</h3><p><a href="/attachments/检索技术核心20讲/倒排检索加速_工业界如何利用跳表、哈希表、位图进行加速.pdf" target="_blank">倒排检索加速_工业界如何利用跳表、哈希表、位图进行加速？</a></p><p>这里其实就是多字段检索比MySQL快的原因;<br>es通过FST找到倒排索引的位置获取文档id列表,再通过跳表等来快速合并文档列表。</p><blockquote><p>其实FST、跳表合并这些都是Lucene实现的</p></blockquote><h2 id="原文">原文</h2><p><a href="https://neway6655.github.io/elasticsearch/2015/09/11/elasticsearch-study-notes.html" target="_blank" rel="noopener">Elasticsearch 读书笔记</a></p>]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ElasticSearch</tag>
        <tag>Query</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Epoll 的本质是什么？</title>
    <url>/epoll-principle.html</url>
    <content><![CDATA[<p>从事服务端开发，少不了要接触网络编程。epoll 作为 Linux 下高性能网络服务器的必备技术至关重要，nginx、Redis、Skynet 和大部分游戏服务器都使用到这一多路复用技术。</p><p>epoll 很重要，但是 epoll 与 select 的区别是什么呢？epoll 高效的原因是什么？</p><p><img data-src="/images/linux-epoll/%E9%A6%96%E9%A1%B5%E5%9B%BE.jpg" alt></p><p>网上虽然也有不少讲解 epoll的文章，但要么是过于浅显，或者陷入源码解析，很少能有通俗易懂的。笔者于是决定编写此文，让缺乏专业背景知识的读者也能够明白 epoll 的原理。</p><p><font color="DeepPink"><strong>文章核心思想是：要让读者清晰明白 epoll 为什么性能好。</strong></font></p><p><font color="DeepPink"><strong>本文会从网卡接收数据的流程讲起，串联起 CPU 中断、操作系统进程调度等知识；再一步步分析阻塞接收数据、select 到 epoll 的进化过程；最后探究 epoll 的实现细节。</strong></font></p><h1>一、从网卡接收数据说起</h1><p>下边是一个典型的计算机结构图，计算机由 CPU、存储器（内存）与网络接口等部件组成，了解 epoll 本质的第一步，要从硬件的角度看计算机怎样接收网络数据。<br><img data-src="/images/linux-epoll/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%9B%BE.jpg" alt><br><em>计算机结构图（图片来源：Linux内核完全注释之微型计算机组成结构）</em></p><p>下图展示了网卡接收数据的过程。</p><ul><li>在 ① 阶段，网卡收到网线传来的数据；</li><li>经过 ② 阶段的硬件电路的传输；</li><li>最终 ③ 阶段将数据写入到内存中的某个地址上。</li></ul><p>这个过程涉及到 DMA 传输、IO 通路选择等硬件有关的知识，但我们只需知道：<font color="DeepPink"><strong>网卡会把接收到的数据写入内存</strong></font>。</p><p><img data-src="/images/linux-epoll/%E7%BD%91%E5%8D%A1%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E7%A8%8B.jpg" alt><br><em>网卡接收数据的过程</em></p><p>通过硬件传输，网卡接收的数据存放到内存中，操作系统就可以去读取它们。</p><h1>二、如何知道接收了数据？</h1><p>了解 epoll 本质的第二步，要从 CPU 的角度来看数据接收。理解这个问题，要先了解一个概念——<font color="DeepPink"><strong>中断</strong></font>。</p><p>计算机执行程序时，会有优先级的需求。比如，当计算机收到断电信号时，它应立即去保存数据，保存数据的程序具有较高的优先级（电容可以保存少许电量，供 CPU 运行很短的一小段时间）。</p><p><font color="DeepPink"><strong>一般而言，由硬件产生的信号需要 CPU 立马做出回应，不然数据可能就丢失了，所以它的优先级很高。CPU 理应中断掉正在执行的程序，去做出响应；当 CPU 完成对硬件的响应后，再重新执行用户程序。</strong></font>中断的过程如下图，它和函数调用差不多，只不过函数调用是事先定好位置，而中断的位置由“信号”决定。<br><img data-src="/images/linux-epoll/%E4%B8%AD%E6%96%AD%E7%A8%8B%E5%BA%8F%E8%B0%83%E7%94%A8.jpg" alt><br><em>中断程序调用</em></p><p>以键盘为例，当用户按下键盘某个按键时，键盘会给 CPU 的中断引脚发出一个高电平，CPU能够捕获这个信号，然后执行键盘中断程序。下图展示了各种硬件通过中断与 CPU 交互的过程。<br><img data-src="/images/linux-epoll/CPU%E4%B8%AD%E6%96%AD.jpg" alt><br><em>CPU 中断（图片来源：<a href="http://net.pku.edu.cn" target="_blank" rel="noopener">net.pku.edu.cn</a>）</em></p><p>现在可以回答“<strong>如何知道接收了数据？</strong>”这个问题了：<font color="DeepPink"><strong>当网卡把数据写入到内存后，网卡向 CPU 发出一个中断信号，操作系统便能得知有新数据到来，再通过网卡中断程序去处理数据。</strong></font></p><h1>三、进程阻塞为什么不占用 CPU 资源？</h1><p>了解 epoll 本质的第三步，要从操作系统进程调度的角度来看数据接收。<font color="DeepPink"><strong>阻塞是进程调度的关键一环，指的是进程在等待某事件（如接收到网络数据）发生之前的等待状态，recv、select 和 epoll 都是阻塞方法</strong></font>。下边分析一下进程阻塞为什么不占用 CPU 资源？</p><p>为简单起见，我们从普通的 recv 接收开始分析，先看看下面代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//创建socket</span><br><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);   </span><br><span class="line">//绑定</span><br><span class="line">bind(s, ...)</span><br><span class="line">//监听</span><br><span class="line">listen(s, ...)</span><br><span class="line">//接受客户端连接</span><br><span class="line">int c = accept(s, ...)</span><br><span class="line">//接收客户端数据</span><br><span class="line">recv(c, ...);</span><br><span class="line">//将数据打印出来</span><br><span class="line">printf(...)</span><br></pre></td></tr></table></figure><p>这是一段最基础的网络编程代码，先新建 socket 对象，依次调用 bind、listen 与 accept，最后调用 recv 接收数据。recv 是个阻塞方法，当程序运行到 recv 时，它会一直等待，直到接收到数据才往下执行。</p><p>那么阻塞的原理是什么？</p><h2 id="工作队列">工作队列</h2><p><font color="DeepPink"><strong>操作系统为了支持多任务，实现了进程调度的功能，会把进程分为“运行”和“等待”等几种状态。运行状态是进程获得 CPU 使用权，正在执行代码的状态；等待状态是阻塞状态，比如上述程序运行到 recv 时，程序会从运行状态变为等待状态，接收到数据后又变回运行状态。</strong></font>操作系统会分时执行各个运行状态的进程，由于速度很快，看上去就像是同时执行多个任务。</p><p>下图的计算机中运行着 A、B 与 C 三个进程，其中进程 A 执行着上述基础网络程序，一开始，这 3 个进程都被操作系统的工作队列所引用，处于运行状态，会分时执行。<br><img data-src="/images/linux-epoll/%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E4%B8%AD%E6%9C%89ABC%E4%B8%89%E4%B8%AA%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>工作队列中有 A、B 和 C 三个进程</em></p><h2 id="等待队列">等待队列</h2><p>当进程 A 执行到创建 socket 的语句时，操作系统会创建一个由文件系统管理的 socket 对象（如下图）。这个 socket 对象包含了发送缓冲区、接收缓冲区与等待队列等成员。等待队列是个非常重要的结构，它指向所有需要等待该 socket 事件的进程。<br><img data-src="/images/linux-epoll/%E5%88%9B%E5%BB%BAsocket.jpg" alt><br><em>创建 socket</em></p><p><strong>当程序执行到 recv 时，操作系统会将进程 A 从工作队列移动到该 socket 的等待队列中</strong>（如下图）。由于工作队列只剩下了进程 B 和 C，依据进程调度，CPU 会轮流执行这两个进程的程序，不会执行进程 A 的程序。所以进程 A 被阻塞，不会往下执行代码，也不会占用 CPU 资源。<br><img data-src="/images/linux-epoll/socket%E7%9A%84%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97.jpg" alt><br><em>socket 的等待队列</em></p><blockquote><p>注：操作系统添加等待队列只是添加了对这个“等待中”进程的引用，以便在接收到数据时获取进程对象、将其唤醒，而非直接将进程管理纳入自己之下。上图为了方便说明，直接将进程挂到等待队列之下。</p></blockquote><h2 id="唤醒进程">唤醒进程</h2><p><strong>当 socket 接收到数据后，操作系统将该 socket 队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。同时由于 socket 的接收缓冲区已经有了数据，recv 可以返回接收到的数据。</strong></p><h1>四、内核接收网络数据全过程</h1><p>这一步，贯穿网卡、中断与进程调度的知识，叙述阻塞 recv 下，内核接收数据的全过程。</p><p>如下图所示，进程在 recv 阻塞期间，计算机收到了对端传送的数据（步骤①），数据经由网卡传送到内存（步骤②），然后网卡通过中断信号通知 CPU 有数据到达，CPU 执行中断程序（步骤③）。</p><p>此处的中断程序主要有两项功能，先将网络数据写入到对应 socket 的接收缓冲区里面（步骤④），再唤醒进程 A（步骤⑤），重新将进程 A 放入工作队列中。<br><img data-src="/images/linux-epoll/%E5%86%85%E6%A0%B8%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E5%85%A8%E8%BF%87%E7%A8%8B.jpg" alt><br><em>内核接收数据全过程</em></p><p>唤醒进程的过程如下图所示：<br><img data-src="/images/linux-epoll/%E5%94%A4%E9%86%92%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>唤醒进程</em></p><p>以上是内核接收数据全过程，这里我们可能会思考两个问题：</p><ul><li>其一，<strong>操作系统如何知道网络数据对应于哪个 socket？</strong></li><li>其二，<strong>如何同时监视多个 socket 的数据？</strong></li></ul><p>第一个问题：<font color="DeepPink"><strong>因为一个 socket 对应着一个端口号，而网络数据包中包含了 ip 和端口的信息，内核可以通过端口号找到对应的 socket。当然，为了提高处理速度，操作系统会维护端口号到 socket 的索引结构，以快速读取。</strong></font></p><p>第二个问题是多路复用的重中之重，也正是本文后半部分的重点。</p><h1>五、同时监视多个 socket 的简单方法</h1><p>服务端需要管理多个客户端连接，而 recv 只能监视单个 socket，这种矛盾下，人们开始寻找监视多个 socket 的方法。<font color="DeepPink"><strong>epoll的要义就是高效地监视多个 socket</strong></font>。</p><p>从历史发展角度看，必然先出现一种不太高效的方法，人们再加以改进，正如 select 之于 epoll。</p><p>先理解不太高效的 select，才能够更好地理解 epoll 的本质。</p><p>假如能够预先传入一个 socket 列表，如果列表中的 socket 都没有数据，挂起进程，直到有一个 socket 收到数据，唤醒进程。这种方法很直接，也是 select 的设计思想。</p><p>为方便理解，我们先复习 select 的用法。在下边的代码中，先准备一个数组 fds，让 fds 存放着所有需要监视的 socket。然后调用 select，如果 fds 中的所有 socket 都没有数据，select 会阻塞，直到有一个 socket 接收到数据，select 返回，唤醒进程。用户可以遍历 fds，通过 FD_ISSET 判断具体哪个 socket 收到数据，然后做出处理。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);  </span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...);</span><br><span class="line">int fds[] =  存放需要监听的socket;</span><br><span class="line">while(1)&#123;</span><br><span class="line">    int n = select(..., fds, ...)</span><br><span class="line">    for(int i=0; i &lt; fds.count; i++)&#123;</span><br><span class="line">        if(FD_ISSET(fds[i], ...))&#123;</span><br><span class="line">            //fds[i]的数据处理</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="select-的流程">select 的流程</h2><p>select 的实现思路很直接，假如程序同时监视如下图的 sock1、sock2 和 sock3 三个 socket，那么在调用 select 之后，操作系统把进程 A 分别加入这三个 socket 的等待队列中。<br><img data-src="/images/linux-epoll/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8A%8A%E8%BF%9B%E7%A8%8BA%E5%88%86%E5%88%AB%E5%8A%A0%E5%85%A5%E8%BF%99%E4%B8%89%E4%B8%AAsocket%E7%9A%84%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E4%B8%AD.jpg" alt><br><em>操作系统把进程 A 分别加入这三个 socket 的等待队列中</em></p><p>当任何一个 socket 收到数据后，中断程序将唤起进程。下图展示了 sock2 接收到了数据的处理流程：</p><blockquote><p>注：recv 和 select 的中断回调可以设置成不同的内容。</p></blockquote><p><img data-src="/images/linux-epoll/sock2%E6%8E%A5%E6%94%B6%E5%88%B0%E4%BA%86%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%96%AD%E7%A8%8B%E5%BA%8F%E5%94%A4%E8%B5%B7%E8%BF%9B%E7%A8%8BA.jpg" alt><br><em>sock2 接收到了数据，中断程序唤起进程 A</em></p><p>所谓唤起进程，就是将进程从所有的等待队列中移除，加入到工作队列里面，如下图所示：<br><img data-src="/images/linux-epoll/%E5%B0%86%E8%BF%9B%E7%A8%8BA%E4%BB%8E%E6%89%80%E6%9C%89%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E4%B8%AD%E7%A7%BB%E9%99%A4%E5%86%8D%E5%8A%A0%E5%85%A5%E5%88%B0%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E9%87%8C%E9%9D%A2.jpg" alt><br><em>将进程 A 从所有等待队列中移除，再加入到工作队列里面</em></p><p>经由这些步骤，当进程 A 被唤醒后，它知道至少有一个 socket 接收了数据。程序只需遍历一遍 socket 列表，就可以得到就绪的 socket。</p><p>这种简单方式行之有效，在几乎所有操作系统都有对应的实现。</p><p>但是简单的方法往往有缺点，主要是：</p><p>其一，<strong>每次调用 select 都需要将进程加入到所有监视 socket 的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个 fds 列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定 select 的最大监视数量，默认只能监视 1024 个 socket。</strong></p><p>其二，<strong>进程被唤醒后，程序并不知道哪些 socket 收到数据，还需要遍历一次。</strong></p><p>那么，<font color="DeepPink"><strong>有没有减少遍历的方法？有没有保存就绪 socket 的方法？这两个问题便是 epoll 技术要解决的。</strong></font></p><blockquote><p>补充说明： 本节只解释了 select 的一种情形。当程序调用 select 时，内核会先遍历一遍 socket，如果有一个以上的 socket 接收缓冲区有数据，那么 select 直接返回，不会阻塞。这也是为什么 select 的返回值有可能大于 1 的原因之一。如果没有 socket 有数据，进程才会阻塞。</p></blockquote><h1>六、epoll 的设计思路</h1><p>epoll 是在 select 出现 N 多年后才被发明的，是 select 和 poll（poll 和 select 基本一样，有少量改进）的增强版本。epoll 通过以下一些措施来改进效率：</p><h2 id="措施一：功能分离">措施一：功能分离</h2><p>select 低效的原因之一是将“维护等待队列”和“阻塞进程”两个步骤合二为一。如下图所示，每次调用 select 都需要这两步操作，然而大多数应用场景中，需要监视的 socket 相对固定，并不需要每次都修改。epoll 将这两个操作分开，先用 epoll_ctl 维护等待队列，再调用 epoll_wait 阻塞进程。显而易见地，效率就能得到提升。<br><img data-src="/images/linux-epoll/%E7%9B%B8%E6%AF%94selectepoll%E6%8B%86%E5%88%86%E4%BA%86%E5%8A%9F%E8%83%BD.jpg" alt></p><p><em>相比 select，epoll 拆分了功能</em></p><p>为方便理解后续的内容，我们先了解一下 epoll 的用法。如下的代码中，先用 epoll_create 创建一个 epoll 对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到 epfd 中，最后调用 epoll_wait 等待数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int s = socket(AF_INET, SOCK_STREAM, 0);   </span><br><span class="line">bind(s, ...)</span><br><span class="line">listen(s, ...)</span><br><span class="line"></span><br><span class="line">int epfd = epoll_create(...);</span><br><span class="line">epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中</span><br><span class="line"></span><br><span class="line">while(1)&#123;</span><br><span class="line">    int n = epoll_wait(...)</span><br><span class="line">    for(接收到数据的socket)&#123;</span><br><span class="line">        //处理</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>功能分离，使得 epoll 有了优化的可能。</p><h2 id="措施二：就绪列表">措施二：就绪列表</h2><p>select 低效的另一个原因在于程序不知道哪些 socket 收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的 socket，就能避免遍历。如下图所示，计算机共有三个 socket，收到数据的 sock2 和 sock3 被就绪列表 rdlist 所引用。当进程被唤醒后，只要获取 rdlist 的内容，就能够知道哪些 socket 收到数据。<br><img data-src="/images/linux-epoll/%E5%B0%B1%E7%BB%AA%E5%88%97%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt><br><em>就绪列表示意图</em></p><h1>七、epoll 的原理与工作流程</h1><p>本节会以示例和图表来讲解 epoll 的原理和工作流程。</p><h2 id="创建-epoll-对象">创建 epoll 对象</h2><p>如下图所示，当某个进程调用 epoll_create 方法时，内核会创建一个 eventpoll 对象（也就是程序中 epfd 所代表的对象）。eventpoll 对象也是文件系统中的一员，和 socket 一样，它也会有等待队列。<br><img data-src="/images/linux-epoll/%E5%86%85%E6%A0%B8%E5%88%9B%E5%BB%BAeventpoll%E5%AF%B9%E8%B1%A1.jpg" alt><br><em>内核创建 eventpoll 对象</em></p><p>创建一个代表该 epoll 的 eventpoll 对象是必须的，因为内核要维护“就绪列表”等数据，“就绪列表”可以作为 eventpoll 的成员。</p><h2 id="维护监视列表">维护监视列表</h2><p>创建 epoll 对象后，可以用 epoll_ctl 添加或删除所要监听的 socket。以添加 socket 为例，如下图，如果通过 epoll_ctl 添加 sock1、sock2 和 sock3 的监视，内核会将 eventpoll 添加到这三个 socket 的等待队列中。<br><img data-src="/images/linux-epoll/%E6%B7%BB%E5%8A%A0%E6%89%80%E8%A6%81%E7%9B%91%E5%90%AC%E7%9A%84socket.jpg" alt><br><em>添加所要监听的 socket</em></p><p>当 socket 收到数据后，中断程序会操作 eventpoll 对象，而不是直接操作进程。</p><h2 id="接收数据">接收数据</h2><p>当 socket 收到数据后，中断程序会给 eventpoll 的“就绪列表”添加 socket 引用。如下图展示的是 sock2 和 sock3 收到数据后，中断程序让 rdlist 引用这两个 socket。<br><img data-src="/images/linux-epoll/%E7%BB%99%E5%B0%B1%E7%BB%AA%E5%88%97%E8%A1%A8%E6%B7%BB%E5%8A%A0%E5%BC%95%E7%94%A8.jpg" alt><br><em>给就绪列表添加引用</em></p><p>eventpoll 对象相当于 socket 和进程之间的中介，socket 的数据接收并不直接影响进程，而是通过改变 eventpoll 的就绪列表来改变进程状态。</p><p>当程序执行到 epoll_wait 时，如果 rdlist 已经引用了 socket，那么 epoll_wait 直接返回，如果 rdlist 为空，阻塞进程。</p><h2 id="阻塞和唤醒进程">阻塞和唤醒进程</h2><p>假设计算机中正在运行进程 A 和进程 B，在某时刻进程 A 运行到了 epoll_wait 语句。如下图所示，内核会将进程 A 放入 eventpoll 的等待队列中，阻塞进程。<br><img data-src="/images/linux-epoll/epoll_wait%E9%98%BB%E5%A1%9E%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>epoll_wait 阻塞进程</em></p><p>当 socket 接收到数据，中断程序一方面修改 rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态（如下图）。也因为 rdlist 的存在，进程 A 可以知道哪些 socket 发生了变化。<br><img data-src="/images/linux-epoll/epoll%E5%94%A4%E9%86%92%E8%BF%9B%E7%A8%8B.jpg" alt><br><em>epoll 唤醒进程</em></p><h1>八、epoll 的实现细节</h1><p>至此，相信读者对 epoll 的本质已经有一定的了解。但我们还需要知道 eventpoll 的数据结构是什么样子？</p><p>此外，就绪队列应该应使用什么数据结构？eventpoll 应使用什么数据结构来管理通过 epoll_ctl 添加或删除的 socket？</p><p>如下图所示，eventpoll 包含了 lock、mtx、wq（等待队列）与 rdlist 等成员，其中 rdlist 和 rbr 是我们所关心的。<br><img data-src="/images/linux-epoll/epoll%E5%8E%9F%E7%90%86%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt><br><em>epoll 原理示意图，图片来源：《深入理解Nginx：模块开发与架构解析(第二版)》，陶辉</em></p><h2 id="就绪列表的数据结构">就绪列表的数据结构</h2><p>就绪列表引用着就绪的 socket，所以它应能够快速的插入数据。</p><p>程序可能随时调用 epoll_ctl 添加监视 socket，也可能随时删除。当删除时，若该 socket 已经存放在就绪列表中，它也应该被移除。所以就绪列表应是一种能够快速插入和删除的数据结构。</p><p>双向链表就是这样一种数据结构，epoll 使用双向链表来实现就绪队列（对应上图的 rdllist）。</p><h2 id="索引结构">索引结构</h2><p>既然 epoll 将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的 socket，至少要方便地添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是O(log(N))，效率较好，epoll 使用了红黑树作为索引结构（对应上图的 rbr）。</p><p>注：因为操作系统要兼顾多种功能，以及由更多需要保存的数据，rdlist 并非直接引用 socket，而是通过 epitem 间接引用，红黑树的节点也是 epitem 对象。同样，文件系统也并非直接引用着 socket。为方便理解，本文中省略了一些间接结构。</p><h1>九、小结</h1><p>epoll 在 select 和 poll 的基础上引入了 eventpoll 作为中间层，使用了先进的数据结构，是一种高效的多路复用技术。这里也以表格形式简单对比一下 select、poll 与 epoll，结束此文。希望读者能有所收获。</p><p><img data-src="/images/linux-epoll/%E5%B0%8F%E7%BB%93.jpg" alt></p><p>原文地址：<a href="https://my.oschina.net/editorial-story/blog/3052308" target="_blank" rel="noopener">https://my.oschina.net/editorial-story/blog/3052308</a></p>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Epoll</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 原子操作的实现原理</title>
    <url>/java-atomic-operation-principle.html</url>
    <content><![CDATA[<blockquote><p>本文整理自《Java并发编程的艺术》第二章 作者：方腾飞　魏鹏　程晓明</p></blockquote><a id="more"></a><p>原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。让我们一起来聊一聊在Intel处理器和Java里是如何实现原子操作的。</p><h1>术语定义</h1><p>在了解原子操作的实现原理前，先要了解一下相关的术语:</p><style>table th:first-of-type{width:100px}table th:nth-of-type(2){width:150px}</style><table><thead><tr><th>术语名称</th><th>英文</th><th>解释</th></tr></thead><tbody><tr><td>缓存行</td><td>Cache line</td><td>缓存的最小操作单位</td></tr><tr><td>比较并交换</td><td>Compare and Swap</td><td>CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。</td></tr><tr><td>CPU流水线</td><td>CPU pipeline</td><td>CPU流水线的工作方式就像工业生产上的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度</td></tr><tr><td>内存顺序冲突</td><td>Memory order violation</td><td>内存顺序冲突一般是由假共享引起的，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线</td></tr></tbody></table><h1>处理器如何实现原子操作</h1><p>32位IA-32处理器使用<font color="DeepPink"><strong>基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作</strong></font>。首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。</p><blockquote><p>在Intel 2019年的文档中，该部分阐述基本不变，具体可以查考文末Intel文档的2957页 8.1 LOCKED ATOMIC OPERATIONS</p></blockquote><h2 id="使用总线锁保证原子性">使用总线锁保证原子性</h2><p>第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图2-3所示。</p><p><img data-src="/images/java-atomic-operation-principle/%E5%9B%BE23.png" alt></p><p>原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。<font color="DeepPink"><strong>所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。</strong></font></p><blockquote><p>Intel文档的2959页 8.1.2 Bus Locking</p></blockquote><h2 id="使用缓存锁保证原子性">使用缓存锁保证原子性</h2><p>第二个机制是通过缓存锁定来保证原子性。<font color="DeepPink"><strong>在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。</strong></font></p><p>频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。<font color="DeepPink"><strong>所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效</strong></font>，在如图2-3所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能同时缓存i的缓存行。</p><p>但是有两种情况下处理器不会使用缓存锁定：</p><ul><li>第一种情况是：<font color="DeepPink"><strong>当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。</strong></font></li><li>第二种情况是：<font color="DeepPink"><strong>有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。</strong></font>针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。</li></ul><blockquote><p>Intel文档的2961页 8.1.4 Effects of a LOCK Operation on Internal Processor Caches</p></blockquote><h1>Java如何实现原子操作</h1><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。</p><h2 id="使用循环CAS实现原子操作">使用循环CAS实现原子操作</h2><p>JVM中的CAS操作正是利用了处理器提供的CMPXCHG(Compare and Exchange)指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器方法safeCount和一个非线程安全的计数器count。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private AtomicInteger atomicI = new AtomicInteger(0);</span><br><span class="line">private int i = 0;</span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">    final Counter cas = new Counter();</span><br><span class="line">    List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600);</span><br><span class="line">    long start = System.currentTimeMillis();</span><br><span class="line">    for (int j = 0; j &lt; 100; j++) &#123;</span><br><span class="line">        Thread t = new Thread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                for (int i = 0; i &lt; 10000; i++) &#123;</span><br><span class="line">                    cas.count();</span><br><span class="line">                    cas.safeCount();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        ts.add(t);</span><br><span class="line">    &#125;</span><br><span class="line">    for (Thread t : ts) &#123;</span><br><span class="line">        t.start();</span><br><span class="line">    &#125;</span><br><span class="line">    // 等待所有线程执行完成</span><br><span class="line">    for (Thread t : ts) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            t.join();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(cas.i);</span><br><span class="line">    System.out.println(cas.atomicI.get());</span><br><span class="line">    System.out.println(System.currentTimeMillis() - start);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 使用CAS实现线程安全计数器</span><br><span class="line"> */</span><br><span class="line">private void safeCount() &#123;</span><br><span class="line">    for (; ; ) &#123;</span><br><span class="line">        int i = atomicI.get();</span><br><span class="line">        boolean suc = atomicI.compareAndSet(i, ++i);</span><br><span class="line">        if (suc) &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 非线程安全计数器</span><br><span class="line"> */</span><br><span class="line">private void count() &#123;</span><br><span class="line">    i++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和自减1。</p><h2 id="CAS实现原子操作的三大问题">CAS实现原子操作的三大问题</h2><p>在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如LinkedTransferQueue类的Xfer方法。CAS虽然很高效地解决了原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作。</p><ol><li><font color="DeepPink"><strong>ABA问题</strong></font>。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。<font color="DeepPink"><strong>在变量前面追加上版本号，每次变量更新的时候把版本号加1</strong></font>，那么A→B→A就会变成1A→2B→3A。从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</li></ol><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public boolean compareAndSet(</span><br><span class="line">		V expectedReference, 	// 预期引用</span><br><span class="line">		V newReference, 		// 更新后的引用</span><br><span class="line">		int expectedStamp, 		// 预期标志</span><br><span class="line">		int newStamp 			// 更新后的标志</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="2"><li><p><font color="DeepPink"><strong>循环时间长开销大</strong></font>。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而提高CPU的执行效率。</p></li><li><p><font color="DeepPink"><strong>只能保证一个共享变量的原子操作</strong></font>。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p></li></ol><h2 id="使用锁机制实现原子操作">使用锁机制实现原子操作</h2><p>锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。</p><h1>推荐阅读</h1><p><a href="https://github.com/jiankunking/books-recommendation/blob/master/CPU/Intel%C2%AE%2064%20and%20IA-32%20architectures%20software%20developer%E2%80%99s%20manual.pdf" target="_blank" rel="noopener">Intel® 64 and IA-32 architectures software developer’s manual</a></p>]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Concurrent</tag>
        <tag>Atomic</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]阿里分布式事务解决方案 Fescar 解析</title>
    <url>/alibaba-seata-design.html</url>
    <content><![CDATA[<blockquote><p>通过Fescar（Seata）了解分布式事务框架设计思路</p></blockquote><a id="more"></a><p>Fescar 是 <strong>阿里巴巴</strong> 开源的 <strong>分布式事务</strong>中间件，以 <strong>高效</strong> 并且对业务 <strong>0 侵入</strong> 的方式，解决 <strong>微服务</strong> 场景下面临的分布式事务问题。</p><h1>什么是微服务化带来的分布式事务问题？</h1><p>首先，设想一个传统的单体应用（Monolithic App），通过 3 个 Module，在同一个数据源上更新数据来完成一项业务。</p><p>很自然的，整个业务过程的数据一致性由本地事务来保证。</p><p><img data-src="/images/alibaba-seata-design/monolithic_architecture.png" alt></p><p>随着业务需求和架构的变化，单体应用被拆分为微服务：原来的 3 个 Module 被拆分为 3 个独立的服务，分别使用独立的数据源（<a href="http://microservices.io/patterns/data/database-per-service.html" target="_blank" rel="noopener">Pattern: Database per service</a>）。业务过程将由 3 个服务的调用来完成。</p><p><img data-src="/images/alibaba-seata-design/microservices_architecture.png" alt></p><p>此时，每一个服务内部的数据一致性仍由本地事务来保证。而整个业务层面的全局数据一致性要如何保障呢？这就是微服务架构下面临的，典型的分布式事务需求：我们需要一个分布式事务的解决方案保障业务全局的数据一致性。</p><p><img data-src="/images/alibaba-seata-design/fescar_solution.png" alt></p><h1>Fescar 的发展历程</h1><p>阿里是国内最早一批进行应用分布式（微服务化）改造的企业，所以很早就遇到微服务架构下的分布式事务问题。</p><p>2014 年，阿里中间件团队发布 <strong>TXC（Taobao Transaction Constructor）</strong>，为集团内应用提供分布式事务服务。</p><p>2016 年，TXC 经过产品化改造，以 <strong>GTS（Global Transaction Service）</strong> 的身份登陆阿里云，成为当时业界唯一一款云上分布式事务产品，在阿云里的公有云、专有云解决方案中，开始服务于众多外部客户。</p><p>2019 年起，基于 TXC 和 GTS 的技术积累，阿里中间件团队发起了开源项目 <strong>Fescar（Fast &amp; EaSy Commit And Rollback, FESCAR）</strong>，和社区一起建设这个分布式事务解决方案。</p><p>TXC/GTS/Fescar 一脉相承，为解决微服务架构下的分布式事务问题交出了一份与众不同的答卷。</p><h2 id="设计初衷">设计初衷</h2><p>高速增长的互联网时代，<strong>快速试错</strong> 的能力对业务来说是至关重要的：</p><ul><li>一方面，不应该因为技术架构上的微服务化和分布式事务支持的引入，给业务层面带来额外的研发负担。</li><li>另一方面，引入分布式事务支持的业务应该基本保持在同一量级上的性能表现，不能因为事务机制显著拖慢业务。</li></ul><p>基于这两点，我们设计之初的最重要的考量就在于：</p><ul><li><strong>对业务无侵入：</strong> 这里的 <strong>侵入</strong> 是指，因为分布式事务这个技术问题的制约，要求应用在业务层面进行设计和改造。这种设计和改造往往会给应用带来很高的研发和维护成本。我们希望把分布式事务问题在 <strong>中间件</strong> 这个层次解决掉，不要求应用在业务层面做额外的工作。</li><li><strong>高性能：</strong> 引入分布式事务的保障，必然会有额外的开销，引起性能的下降。我们希望把分布式事务引入的性能损耗降到非常低的水平，让应用不因为分布式事务的引入导致业务的可用性受影响。</li></ul><h2 id="既有的解决方案为什么不满足？">既有的解决方案为什么不满足？</h2><p>既有的分布式事务解决方案按照对业务侵入性分为两类，即：对业务无侵入的和对业务有侵入的。</p><h3 id="业务无侵入的方案">业务无侵入的方案</h3><p>既有的主流分布式事务解决方案中，对业务无侵入的只有基于 XA 的方案，但应用 XA 方案存在 3 个方面的问题：</p><ol><li>要求数据库提供对 XA 的支持。如果遇到不支持 XA（或支持得不好，比如 MySQL 5.7 以前的版本）的数据库，则不能使用。</li><li>受协议本身的约束，事务资源（数据记录、数据库连接）的锁定周期长。长周期的资源锁定从业务层面来看，往往是不必要的，而因为事务资源的管理器是数据库本身，应用层无法插手。这样形成的局面就是，基于 XA 的应用往往性能会比较差，而且很难优化。</li><li>已经落地的基于 XA 的分布式解决方案，都依托于重量级的应用服务器（Tuxedo/WebLogic/WebSphere 等)，这是不适用于微服务架构的。</li></ol><h3 id="侵入业务的方案">侵入业务的方案</h3><p>实际上，最初分布式事务只有 XA 这个唯一方案。XA 是完备的，但在实践过程中，由于种种原因（包含但不限于上面提到的 3 点）往往不得不放弃，转而从业务层面着手来解决分布式事务问题。比如：</p><ul><li>基于可靠消息的最终一致性方案</li><li>TCC</li><li>Saga</li></ul><p>都属于这一类。这些方案的具体机制在这里不做展开，网上这方面的论述文章非常多。总之，这些方案都要求在应用的业务层面把分布式事务技术约束考虑到设计中，通常每一个服务都需要设计实现正向和反向的幂等接口。这样的设计约束，往往会导致很高的研发和维护成本。</p><h2 id="理想的方案应该是什么样子？">理想的方案应该是什么样子？</h2><p>不可否认，侵入业务的分布式事务方案都经过大量实践验证，能有效解决问题，在各行各业的业务应用系统中起着重要作用。但回到原点来思考，这些方案的采用实际上都是 <strong>迫于无奈</strong>。设想，如果基于 XA 的方案能够不那么 <strong>重</strong>，并且能保证业务的性能需求，相信不会有人愿意把分布式事务问题拿到业务层面来解决。</p><p>一个理想的分布式事务解决方案应该：像使用 <strong>本地事务</strong> 一样简单，业务逻辑只关注业务层面的需求，不需要考虑事务机制上的约束。</p><h1>原理和设计</h1><p>我们要设计一个对业务无侵入的方案，所以从业务无侵入的 XA 方案来思考：</p><p>是否可以在 XA 的基础上演进，解决掉 XA 方案面临的问题呢？</p><h2 id="如何定义一个分布式事务？">如何定义一个分布式事务？</h2><p>首先，很自然的，我们可以把一个分布式事务理解成一个包含了若干 <strong>分支事务</strong> 的 <strong>全局事务</strong>。<strong>全局事务</strong> 的职责是协调其下管辖的 <strong>分支事务</strong> 达成一致，要么一起成功提交，要么一起失败回滚。此外，通常 <strong>分支事务</strong> 本身就是一个满足 ACID 的 <strong>本地事务</strong>。这是我们对分布式事务结构的基本认识，与 XA 是一致的。</p><p><img data-src="/images/alibaba-seata-design/global_branch_transaction.png" alt></p><p>其次，与 XA 的模型类似，我们定义 3 个组件来协议分布式事务的处理过程。</p><p><img data-src="/images/alibaba-seata-design/fescar_model.png" alt></p><ul><li><strong>Transaction Coordinator (TC)：</strong> 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。</li><li><strong>Transaction Manager ™：</strong> 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。</li><li><strong>Resource Manager (RM)：</strong> 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。</li></ul><p>一个典型的分布式事务过程：</p><ol><li>TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID。</li><li>XID 在微服务调用链路的上下文中传播。</li><li>RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖。</li><li>TM 向 TC 发起针对 XID 的全局提交或回滚决议。</li><li>TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</li></ol><p><img data-src="/images/alibaba-seata-design/architecture.png" alt></p><p>至此，Fescar 的协议机制总体上看与 XA 是一致的。</p><h3 id="与-XA-的差别在什么地方？">与 XA 的差别在什么地方？</h3><h4 id="架构层次">架构层次</h4><p><img data-src="/images/alibaba-seata-design/rm_in_architecture.png" alt></p><p>XA 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身（通过提供支持 XA 的驱动程序来供应用使用）。</p><p>而 <font color="DeepPink"><strong>Fescar 的 RM 是以二方包的形式作为中间件层部署在应用程序这一侧的，不依赖与数据库本身对协议的支持，当然也不需要数据库支持 XA 协议。</strong></font>这点对于微服务化的架构来说是非常重要的：应用层不需要为本地事务和分布式事务两类不同场景来适配两套不同的数据库驱动。</p><p>这个设计，剥离了分布式事务方案对数据库在 <strong>协议支持</strong> 上的要求。</p><h4 id="两阶段提交">两阶段提交</h4><p>先来看一下 XA 的 2PC 过程。</p><p><img data-src="/images/alibaba-seata-design/xa_2pc.png" alt></p><p>无论 Phase2 的决议是 commit 还是 rollback，事务性资源的锁都要保持到 Phase2 完成才释放。</p><p>设想一个正常运行的业务，大概率是 90% 以上的事务最终应该是成功提交的，我们是否可以在 Phase1 就将本地事务提交呢？这样 90% 以上的情况下，可以省去 Phase2 持锁的时间，整体提高效率。</p><p><img data-src="/images/alibaba-seata-design/seata_2pc.png" alt></p><ul><li>分支事务中数据的 <strong>本地锁</strong> 由本地事务管理，在分支事务 Phase1 结束时释放。</li><li>同时，随着本地事务结束，<strong>连接</strong> 也得以释放。</li><li>分支事务中数据的 <strong>全局锁</strong> 在事务协调器侧管理，在决议 Phase2 全局提交时，全局锁马上可以释放。只有在决议全局回滚的情况下，<strong>全局锁</strong> 才被持有至分支的 Phase2 结束。</li></ul><p>这个设计，极大地减少了分支事务对资源（数据和连接）的锁定时间，给整体并发和吞吐的提升提供了基础。</p><p>当然，你肯定会问：Phase1 即提交的情况下，Phase2 如何回滚呢？</p><h2 id="分支事务如何提交和回滚？">分支事务如何提交和回滚？</h2><p>首先，<font color="DeepPink"><strong>应用需要使用 Fescar 的 JDBC 数据源代理，也就是 Fescar 的 RM。</strong></font></p><p><img data-src="/images/alibaba-seata-design/data_sourc_proxy.png" alt></p><p><strong>Phase1：</strong></p><p><font color="DeepPink">Fescar 的 JDBC 数据源代理通过对业务 SQL 的解析，把业务数据在更新前后的数据镜像组织成回滚日志，利用 <strong>本地事务</strong> 的 ACID 特性，将业务数据的更新和回滚日志的写入在同一个 <strong>本地事务</strong> 中提交。</font></p><p>这样，可以保证：<font color="DeepPink"><strong>任何提交的业务数据的更新一定有相应的回滚日志存在。</strong></font></p><p><img data-src="/images/alibaba-seata-design/branch_transaction_with_undo_log.png" alt></p><p>基于这样的机制，分支的本地事务便可以在全局事务的 Phase1 提交，马上释放本地事务锁定的资源。</p><p><strong>Phase2：</strong></p><ul><li><font color="DeepPink"><strong>如果决议是全局提交，此时分支事务此时已经完成提交，不需要同步协调处理（只需要异步清理回滚日志），Phase2 可以非常快速地完成。</strong></font></li></ul><p><img data-src="/images/alibaba-seata-design/global_commit.png" alt></p><ul><li><font color="DeepPink"><strong>如果决议是全局回滚，RM 收到协调器发来的回滚请求，通过 XID 和 Branch ID 找到相应的回滚日志记录，通过回滚记录生成反向的更新 SQL 并执行，以完成分支的回滚。</strong></font></li></ul><p><img data-src="/images/alibaba-seata-design/global_rollback.png" alt></p><h2 id="事务传播机制">事务传播机制</h2><p>XID 是一个全局事务的唯一标识，事务传播机制要做的就是把 XID 在服务调用链路中传递下去，并绑定到服务的事务上下文中，这样，服务链路中的数据库更新操作，就都会向该 XID 代表的全局事务注册分支，纳入同一个全局事务的管辖。</p><p>基于这个机制，Fescar 是可以支持任何微服务 RPC 框架的。只要在特定框架中找到可以透明传播 XID 的机制即可，比如，Dubbo 的 Filter + RpcContext。</p><p>对应到 Java EE 规范和 Spring 定义的事务传播属性，Fescar 的支持如下：</p><ul><li><strong>PROPAGATION_REQUIRED：</strong> 默认支持</li><li><strong>PROPAGATION_SUPPORTS：</strong> 默认支持</li><li>PROPAGATION_MANDATORY：应用通过 API 来实现</li><li>PROPAGATION_REQUIRES_NEW：应用通过 API 来实现</li><li>PROPAGATION_NOT_SUPPORTED：应用通过 API 来实现</li><li>PROPAGATION_NEVER：应用通过 API 来实现</li><li>PROPAGATION_NESTED：不支持</li></ul><h2 id="隔离性">隔离性</h2><p>全局事务的隔离性是建立在分支事务的本地隔离级别基础之上的。</p><p>在数据库本地隔离级别 <strong>读已提交</strong> 或以上的前提下，Fescar 设计了由事务协调器维护的 <strong>全局写排他锁</strong>，来保证事务间的 <strong>写隔离</strong>，将全局事务默认定义在 <strong>读未提交</strong> 的隔离级别上。</p><p>我们对隔离级别的共识是：微服务场景产生的分布式事务，绝大部分应用在 <strong>读已提交</strong> 的隔离级别下工作是没有问题的。而实际上，这当中又有绝大多数的应用场景，实际上工作在 <strong>读未提交</strong> 的隔离级别下同样没有问题。</p><p>在极端场景下，应用如果需要达到全局的 <strong>读已提交</strong>，Fescar 也提供了相应的机制来达到目的。默认，Fescar 是工作在 <strong>读未提交</strong> 的隔离级别下，保证绝大多数场景的高效性。</p><p><img data-src="/images/alibaba-seata-design/isolation.png" alt><br>事务的 ACID 属性在 Fescar 中的体现是一个比较复杂的话题，我们会有专门的文章来深入分析，这里不做进一步展开。</p><h1>适用场景分析</h1><p>前文所述的 <font color="DeepPink">Fescar 的核心原理中有一个 <strong>重要前提</strong>：分支事务中涉及的资源，<strong>必须</strong> 是支持 <strong>ACID 事务</strong>的 <strong>关系型数据库</strong>。分支的提交和回滚机制，都依赖于本地事务的保障。所以，如果应用使用的数据库是不支持事务的，或根本不是关系型数据库，就不适用。</font></p><p>另外，目前 Fescar 的实现还存在一些局限，比如：事务隔离级别最高支持到 <strong>读已提交</strong> 的水平，SQL 的解析还不能涵盖全部的语法等。</p><p>为了覆盖 Fescar 原生机制暂时不能支持应用场景，我们定义了另外一种工作模式。</p><p>上面介绍的 Fescar 原生工作模式称为 AT（Automatic Transaction）模式，这种模式是对业务无侵入的。与之相应的另外一种工作模式称为 MT（Manual Transaction）模式，这种模式下，分支事务需要应用自己来定义业务本身及提交和回滚的逻辑。</p><h2 id="分支的基本行为模式">分支的基本行为模式</h2><p>作为全局事务一部分的分支事务，除本身的业务逻辑外，都包含 4 个与协调器交互的行为：</p><ul><li><strong>分支注册：</strong> 在分支事务的数据操作进行之前，需要向协调器注册，把即将进行的分支事务数据操作，纳入一个已经开启的全局事务的管理中去，在分支注册成功后，才可以进行数据操作。</li><li><strong>状态上报：</strong> 在分支事务的数据操作完成后，需要向事务协调器上报其执行结果。</li><li><strong>分支提交</strong>：响应协调器发出的分支事务提交的请求，完成分支提交。</li><li><strong>分支回滚</strong>：响应协调器发出的分支事务回滚的请求，完成分支回滚。</li></ul><p><img data-src="/images/alibaba-seata-design/how_does_rm_talk_to_tc.png" alt></p><h2 id="AT-模式分支的行为模式">AT 模式分支的行为模式</h2><p>业务逻辑不需要关注事务机制，分支与全局事务的交互过程自动进行。</p><p><img data-src="/images/alibaba-seata-design/at_branch.png" alt></p><h2 id="MT-模式分支的行为模式">MT 模式分支的行为模式</h2><p>业务逻辑需要被分解为 Prepare/Commit/Rollback 3 部分，形成一个 MT 分支，加入全局事务。</p><p><img data-src="/images/alibaba-seata-design/mt_branch.png" alt></p><p>MT 模式一方面是 AT 模式的补充。另外，更重要的价值在于，通过 MT 模式可以把众多非事务性资源纳入全局事务的管理中。</p><h2 id="混合模式">混合模式</h2><p>因为 AT 和 MT 模式的分支从根本上行为模式是一致的，所以可以完全兼容，即，一个全局事务中，可以同时存在 AT 和 MT 的分支。这样就可以达到全面覆盖业务场景的目的：AT 模式可以支持的，使用 AT 模式；AT 模式暂时支持不了的，用 MT 模式来替代。另外，自然的，MT 模式管理的非事务性资源也可以和支持事务的关系型数据库资源一起，纳入同一个分布式事务的管理中。</p><h2 id="应用场景的远景">应用场景的远景</h2><p>回到我们设计的初衷：一个理想的分布式事务解决方案是不应该侵入业务的。MT 模式是在 AT 模式暂时不能完全覆盖所有场景的情况下，一个比较自然的补充方案。我们希望通过 AT 模式的不断演进增强，逐步扩大所支持的场景，MT 模式逐步收敛。未来，我们会纳入对 XA 的原生支持，用 XA 这种无侵入的方式来覆盖 AT 模式无法触达的场景。</p><p><img data-src="/images/alibaba-seata-design/roadmap_of_transaction_mode.png" alt></p><h1>扩展点</h1><h2 id="微服务框架的支持">微服务框架的支持</h2><p>事务上下文在微服务间的传播需要根据微服务框架本身的机制，订制最优的，对应用层透明的解决方案。有兴趣在这方面共建的开发者可以参考内置的对 Dubbo 的支持方案，来实现对其他微服务框架的支持。</p><h2 id="所支持的数据库类型">所支持的数据库类型</h2><p>因为 AT 涉及 SQL 的解析，所以在不同类型的数据库上工作，会有一些特定的适配。有兴趣在这方面共建的开发者可以参考内置的对 MySQL 的支持方案，来实现对其他数据库的支持。</p><h2 id="配置和服务注册发现">配置和服务注册发现</h2><p>支持接入不同的配置和服务注册发现解决方案。比如：Nacos、Eureka、ZooKeeper 等。</p><h2 id="MT-模式的场景拓展">MT 模式的场景拓展</h2><p>MT 模式的一个重要作用就是，可以把非关系型数据库的资源，通过 MT 模式分支的包装，纳入到全局事务的管辖中来。比如，Redis、HBase、RocketMQ 的事务消息等。有兴趣在这方面共建的开发者可以在这里贡献一系列相关生态的适配方案。</p><h2 id="事务协调器的分布式高可用方案">事务协调器的分布式高可用方案</h2><p>针对不同场景，支持不同的方式作为事务协调器 Server 端的高可用方案。比如，针对事务状态的持久化，可以是基于文件的实现方案，也可以是基于数据库的实现方案；集群间的状态同步，可以是基于 RPC 通信的方案，也可以是基于高可用 KV 存储的方案。</p><h1>Roadmap</h1><h2 id="Lanscape">Lanscape</h2><p><img data-src="/images/alibaba-seata-design/landscape.png" alt></p><p><strong>The green</strong> part is already open sourced, <strong>the yellow</strong> part will open source by Alibaba/AntFinancial, <strong>the blue</strong> part we want co-building with out community:</p><ul><li>Developers can refer to Seata implementation of MySQL support if you want to support different databases transaction</li><li>Developers can refer to Seata implementation of Dubbo support if you want to support different microservices</li><li>Developers can refer to Seata implementation of TCC support if you want to support different data source(such as MQ, NoSQL)</li><li>Developers can refer to Seata implementation of TCC support if you want to support different data source(such as MQ, NoSQL)</li><li>Developers can easily support configuration/registry services with just a little work</li><li><strong>The blue</strong> part is warmly welcome you, join it and contribute excellent solution</li><li>We will support XA which is the standard of distributed transaction in our product roadmap</li></ul><h2 id="Roadmap">Roadmap</h2><h3 id="v0-1-0">v0.1.0</h3><ul><li>Microservice framework support: Dubbo</li><li>Database support: MySQL</li><li>Spring AOP annotation Support</li><li>Transaction coordinator: Stand-alone Server</li></ul><h3 id="v0-5-x">v0.5.x</h3><ul><li>Rename Fescar to Seata</li><li>Microservice framework support: SOFA, Spring Cloud</li><li>Support TCC(Try Confirm Cancel) transaction mode</li><li>Dynamic configuration</li><li>Services discovery</li></ul><h3 id="v0-6-x">v0.6.x</h3><ul><li>Transaction coordinator: Cluster Server with HA</li></ul><h3 id="v0-8-x">v0.8.x</h3><ul><li>Promethus support</li><li>Management console: Monitor, Deployment, Upgrating, etc.</li></ul><h3 id="v1-0-0">v1.0.0</h3><ul><li>Production ready</li></ul><h3 id="v1-5-x">v1.5.x</h3><ul><li>Database support: Oracle, PostgreSQL, OceanBase</li><li>Optimization of conflict datas</li><li>Independent of Spring Annotation</li><li>Multiple source of data transaction support: MessageQueue(RocketMQ), HBase, Redis, etc.</li></ul><h3 id="v2-0-0">v2.0.0</h3><ul><li>XA transaction mode support</li></ul><p>当然，项目迭代演进的过程，我们最重视的是社区的声音，路线图会和社区充分交流及时进行调整。</p><h1>相关链接</h1><ul><li><a href="https://github.com/alibaba/fescar" target="_blank" rel="noopener">FESCAR on GitHub</a></li><li><a href="https://help.aliyun.com/product/48444.html?spm=5176.doc55547.3.1.Gg1hcs" target="_blank" rel="noopener">GTS on Aliyun</a></li></ul>]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>Fescar</tag>
        <tag>Seata</tag>
        <tag>Distributed</tag>
        <tag>Transaction</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>异地多活高可用架构设计</title>
    <url>/multi-live-high-available-architecture-design.html</url>
    <content><![CDATA[<blockquote><p>如何构建应用的异地多活？</p></blockquote><a id="more"></a><h1>概要</h1><p>随着业务的快速发展，对于很多公司来说，构建于单地域的技术体系架构，会面临诸如下面的多种问题：基础设施的有限性限制了业务的可扩展性；机房、城市级别的故障灾害，影响服务的可持续性。</p><p>为解决遇到的这些问题，公司可以选择构建异地多活架构，在同城/异地构建多个单元(业务中心)。各个业务单元可以分布在不同的地域，从而有效解决了单地域部署带来的基础设施的扩展限制、服务可持续性。</p><p>异地多活是近几年比较热门的一个话题，那么在实际业务中什么时候需要去做这件事？如何去做？做的时候需要考虑什么？</p><h2 id="何时去做？">何时去做？</h2><p>个人感觉取决于以下几个方面：</p><ul><li>业务发展</li><li>基础设施状况</li><li>技术积淀</li></ul><h2 id="如何做？">如何做？</h2><p>目前在网上搜索到的异地多活方案来看，基本都是阿里、饿了么、京东、微博这些互联网大厂的实践，这些大厂的方案有一个共同点就是：大量的自研组件，来做相关的数据同步，业务切分等等，那么，对于很多传统企业或者相对小一些的企业，应该如何来做这件事？</p><ul><li>根据业务特性借助合适的公有云服务</li></ul><h2 id="做的时候，需要注意什么？">做的时候，需要注意什么？</h2><ul><li>真正需要做异地多活的业务有哪些？</li><li>基础设施如何？</li><li>对于不可用时间的容忍程度是多少？</li></ul><h1>业务背景</h1><ul><li>在所有的系统中用户中心都是核心业务，因为它是进入其它很多业务前提。</li><li>我们这边IDC不是很稳定，之前发生过几次机房大规模故障，比如机房网络挂了，整个机房对外不可用了。</li></ul><p>以上两点是我们这次要做用户中心异地容灾的出发点，以便在面对机房级别故障时，保证服务可用性。</p><h1>业务梳理</h1><p>用户中心从整体来看，对外主要提供：注册、登陆、查询用户信息等服务。这些服务又有以下几个特点：</p><ul><li>登陆的优先级最高</li><li>事务性要求低</li></ul><p>涉及的公共组件主要有：</p><ul><li>MySQL：用户数据存储</li><li>Redis：Authorization Code、短信验证码、账号锁定、access token等的存储</li><li>Zookeeper：Dubbo依赖</li></ul><h1>方案</h1><p>用户中心是通过外包的形式进行开发的，目前已上线并交付给另一个外包商运维，所以在考虑容灾一期方案的时候，需要考虑尽量不动代码。</p><h2 id="目标">目标</h2><h3 id="一期目标">一期目标</h3><p>当北京机房出现故障的时候，可以一定时间内把流量切到青岛机房这边，保证用户中心核心服务的基本可用。</p><h3 id="二期目标">二期目标</h3><p>用户中心通过异地多活，实现高可用（需要集团智能DNS支持）。</p><h2 id="架构设计">架构设计</h2><h3 id="一期架构">一期架构</h3><p>当北京机房发生故障的时候，可以把流量快速切换到青岛这边，以保障用户中心核心服务可用。</p><p>具体方案如下：</p><ul><li>通过otter近实时的将北京机房核心业务数据同步到青岛机房。</li><li>青岛机房部署Redis、ZooKeeper等中间件。</li><li>青岛机房部署用户中心的核心应用（实例正常部署、运行，只是平时不会有访问）。</li></ul><p>具体架构如下：<br><img data-src="/images/multi-live-high-available-architecture-design/%E4%B8%80%E6%9C%9F%E6%9E%B6%E6%9E%84.png" alt></p><p>可以达到的效果：</p><ul><li>当北京机房出现故障的时候，可以在一定时间内把流量切到青岛机房这边，保证用户中心核心服务的基本可用，但此时已登录用户需要重新登录。</li><li>一定时间：取决于DNS修改ip时间+DNS TTL时间，目前来看TTL是10分钟，人工修改ip应该很快，所以一定时间是10~20分钟。</li></ul><p>存在的缺点：</p><ul><li>北京机房非故障期间，青岛机房的机器，仅做数据库同步，存在一定的资源浪费。</li><li>当北京机房出现故障，流量切换到青岛机房后，只能保证登陆这一核心服务的可用。对于注册等需要修改数据库的服务，均不支持，如果在此期间访问这类服务，会发生异常。</li></ul><h3 id="二期架构">二期架构</h3><p>二期的目的就是修正一期架构的缺点，通过异地多活，实现高可用。</p><p>二期青岛机房会替换为阿里云机房。</p><p>具体方案如下：</p><ul><li>通过阿里云DTS服务实现两地机房数据库同步，保证北京、阿里云数据的近实时一致性。</li><li>北京、阿里云两地机房均提供在线服务，提高资源利用率。</li><li>梳理服务优先级，修改应用代码，支持服务降级。</li><li>当某个机房（阿里云或者北京）出现故障的时候，通过DNS服务把流量切换到另一个机房。<ul><li>如果两地部署的时候，没有冗余一定硬件资源，则需要实施服务降级。</li><li>目前集团DNS解析，无法提供自动检测服务是否可用的功能，也就无法自动进行切换。<ul><li>服务可用性，可以通过我们这边的多点拨测进行监控，当多点拨测不可用的时候，发送告警通知给相关人员，以便人工介入。</li><li>多点拨测告警，应该会提供两类：1、某个拨测点不通的时候 2、所有拨测点均不可用的时候。</li></ul></li><li>目前集团DNS解析，TTL生效最短时间是10分钟，无法自定义TTL时间。</li></ul></li></ul><p>具体架构如下：<br><img data-src="/images/multi-live-high-available-architecture-design/%E4%BA%8C%E6%9C%9F%E6%9E%B6%E6%9E%84%E6%99%BA%E8%83%BDDNS.png" alt></p><p>可以达到的效果：</p><ul><li>如果集团DNS可以提供，类似阿里云云解析的网站监控功能并能灵活设置TTL时间，这时当北京机房或者阿里云机房出现故障后，就可以在很短的时间（部分服务最大异常时间）内自动进行流量切换。</li></ul><blockquote><p>此处只是以阿里云云解析示例，只要能提供类似的服务均可。</p></blockquote><ul><li>如果集团DNS无法提供类似阿里云云解析的网站监控及灵活设置TTL时间的功能，则部分服务最大异常时间还是取决于DNS修改ip时间+DNS TTL时间。</li></ul><h4 id="名词解释">名词解释</h4><h5 id="什么是网站监控？">什么是网站监控？</h5><p>HTTP/HTTPS实时探测域名解析记录，支持自定义端口，实时发现宕机立即告警；<br>全网分布式监控，在中国各个地区模拟用户端真实请求，监控结果真实可靠；<br>支持宕机暂停、容灾切换，最大限度的解决服务中断对您的业务带来的损失；<br>容灾切换支持A记录、CNAME域名，满足各种场景的容灾切换需求；</p><h5 id="什么情况会被网站监控判断为宕机并发送告警通知？">什么情况会被网站监控判断为宕机并发送告警通知？</h5><p>监控结果中，HTTP/HTTPS的返回码大于500的服务器错误情况，才会报警通知。<br>举例说明：如果设置了四个探测点 北京联通、深圳阿里巴巴、上海电信、重庆联通。<br>场景一：四个探测点中50%的监控点无法收到您服务器的响应，或50%的监控点收到返回码大于等于500时，才会判断您的网站为宕机情况。<br>场景二：四个探测点中有50%以上的探测点探测您的网站返回码是小于500的情况，则不会判断您的网站为宕机。</p><h5 id="云解析DNS“流量管理”">云解析DNS“流量管理”</h5><p>云解析“流量管理”可以在您设置的每条解析线路下，根据权重比例轮询返回解析结果。当线路下的IP宕机时可以通过监控自动发现，并将宕机IP从当前线路下摘除，直到监控IP正常时会恢复解析。同时，当一条解析线路下的所有IP都宕机时，可以切换至其他正常线路。最大程度保证您的网站服务高可用，减小损失。</p><h5 id="部分服务最大异常时间">部分服务最大异常时间</h5><p>比如北京机房出现异常，这时转发到阿里云机房的流量是可以正常访问，只有转发到北京机房的流量是异常的。</p><p>这时如果使用网站监控或者类似服务，进行监控，并设置拨测间隔为1分钟，TTL生效时间为1秒，那么最多有60+1秒部分服务异常时间，之后DNS会自动把北京机房的ip自动踢掉，流量全部切到阿里云。</p><h2 id="补充">补充</h2><ol><li><p>一期、二期方案的实现均强依赖于集团的DNS服务</p></li><li><p>用户中心通过ip暴露的服务，一但出现机房级别的故障，一期、二期方案均无法保证该部分服务可用。</p></li><li><p>其实除了DNS这种方案，还有一种方案就是用类似F5这种设备，作跨机房负载，但必须是gslb，而且两端必须是相同的设备。</p></li></ol><h1>小结</h1><p>对于，非一线互联网大厂的公司而言，是实现异地容灾的时候，借助公有云是很有必要的，比如：</p><ul><li><p>数据跨机房同步，可以使用阿里云的DTS(Data Transmission Service) 服务，目前DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。<br><img data-src="/images/multi-live-high-available-architecture-design/%E9%98%BF%E9%87%8C%E4%BA%91DTS%E6%9C%8D%E5%8A%A1.jpg" alt></p></li><li><p>跨机房分布式数据库，可以使用OceanBase。金融环境下通常对数据可靠性有更高的要求，OceanBase每一次事务提交，对应日志总是会在多个数据中心实时同步，并持久化。即使是数据中心级别的灾难发生，总是可以在其他的数据中心恢复每一笔已经完成的交易，实现了真正金融级别的可靠性要求。</p></li><li><p>异地多活由于各个公司的业务、基础设施及要解决的问题皆不尽相同，所以选择适合自己的就好。</p></li><li><p>或者直接使用云数据库RDS MySQL 版<br><img data-src="/images/multi-live-high-available-architecture-design/%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%89%88.png" alt></p></li></ul>]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>原创</tag>
        <tag>Multi-Live</tag>
        <tag>High-Available</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]Otter数据一致性</title>
    <url>/otter-data-consistency.html</url>
    <content><![CDATA[<blockquote><p>Otter数据一致性实现思路分析</p></blockquote><a id="more"></a><h1>技术选型分析</h1><p>需要处理一致性的业务场景：</p><ul><li>多地修改 (双A机房)</li><li>同一记录，同时变更</li></ul><p>同一记录定义：具体到某一张表，某一条pk，某一字段</p><p>同时变更定义：A地写入的数据在B地还未可见的一段时间范围</p><p>基本思路</p><ul><li>事前控制：比如paoxs协议，在多地数据写入各自数据存储之前，就已经决定好最后保留哪条记录</li><li>事后处理：指A/B两地修改的数据，已经保存到数据库之后，通过数据同步后保证两数据的一致性</li></ul><h1>事前控制</h1><p>paxos协议，相信大家研究的人也比较多，但是它有一些局限性，就拿zookeeper来说，它使用了paxos的一个变种，但基本原理还是相似的。</p><p>我们拿zookeeper的几种部署模式来看：</p><h2 id="1-先看：-A地部署leader-follower集群，B地部署observer">1. 先看： A地部署leader/follower集群，B地部署observer.</h2><p>此时A地收到数据后，需要的网络操作基本为同机房的leader/follower的paxos协议，耗时基本可控</p><p>此时B地收到数据后，需要的网络操作为：</p><ul><li>B地接收到请求，转发给A地，一次机房网络</li><li>地接收到请求，由leader转发给follower进行投票决策，同机房网络</li><li>A地leader将投票的结构，反馈给B地，一次机房网络.</li></ul><p>这样一来，也就是说，事务时间 = 一次异地机房RTT + 同机房paxos算法耗时. 比如中美网络延迟200ms，那事务时间基本就是200ms+ 。 但此时，B地机房基本是一个只读镜像，读数据也有延迟，其系统写扩展性全在A机房，某一天当A机房不够用时，A机房进行拆分，就会遇到下一个问题。</p><h2 id="2-再看：A地和B地组成leader-follower">2. 再看：A地和B地组成leader/follower</h2><p>此时A地收到数据后，需要的网络操作为：(假如A不是leader，B是leader)</p><ul><li>首先需要发送数据到B，一次机房网络</li><li>B收到A的提议数据后，发起一个投票到A，一次机房网络</li><li>A收到提议后，返回一个投票结果到B，一次机房网络</li><li>B收到大部分投票结果，做出决定之后，将结果反馈给A，一次网络交互.</li></ul><p>这种理想无冲突的情况，总共会有2次RTT，如果优化A发起的提议自己默认投票，不返回给A进行投票，可以优化为1次RTT. 针对中美网络延迟200ms，那事务时间基本是200ms+. 如果A地和B地同时写入，那事务时间可能会翻倍。</p><p>总结：如果你能接受事务时间的影响(比如你A地和B地的网络延迟只有10ms)，那是可以考虑选择paxos协议. 但目前otter所要解决的需求为中美200ms的RTT，暂时无法接收paxos协议来解决一致性问题.</p><h1>事后处理</h1><p><font color="DeepPink"><strong>针对事后处理，不管哪种方案，一定会是一个最终一致性，因为在你做处理前，A地和B地的数据内容已经不一致了，你不论选择任何一个版本，对另一边来说都是一个数据版本丢失，最终一致性。</strong></font></p><p>针对数据最终一致性处理，GoldenGate文档中提到了几种case :</p><ul><li>trusted source. 信任站点，数据出现冲突时，永远以某一边为准覆盖另一边</li><li>timestamp，基于数据的修改时间戳，修改时间新的覆盖旧的数据</li><li>数据类型merge， 比如针对库存信息，A地库存减一，B地库存减二，两边同步之后A地和B地的数据应该是减三，合并两者减一和减二的操作</li></ul><p>针对trusted source/timestamp模型，一定需要建立一个冲突数据kv表，(比如trusted source场景，如果B地修改了记录，而A地没修改此记录，那B地可以覆盖A地，即使A地是trusted source) ，对应冲突数据KV表的插入和删除，如果插入和删除不及时，就会有各种各样的误判，导致数据不一致。</p><p>举个插入不及时的case: 比如A地和B地进行双向同步，同时修改了同一记录，但A地的binlog解析器因为异常挂起了，导致构建冲突数据KV表数据延迟了，而此时B地的数据就会认为无冲突，直接覆盖了A，即使A地是trusted source，然后A地数据解析恢复后，同步到B地时，因为A是trusted source，就会覆盖B地的数据，最后就是A和B两地各为两边之前的版本，导致数据不一致。</p><p>因为GoldenGate外部文档针对双A机房同步，数据一致性处理描述的比较少，我只能推测到这，基本结论是风险太大，所以otter需要有一种完全可靠的数据一致性方案，这也是本文讨论的重点。</p><h1>单向回环补救 (基于trusted source的改进版)</h1><p><img data-src="/images/otter-data-consistency/%E5%8D%95%E5%90%91%E5%9B%9E%E7%8E%AF.png" alt></p><p>思路：最终一致性</p><p>适用场景： A地和B地数据不对等，比如A地为主，写入量比较高，B地有少量的数据写入</p><p>单向回环流程：(比如图中以HZ为trusted source站点)</p><ul><li>us-&gt;hz同步的数据，会再次进入hz-&gt;us队列，形成一次单向回环</li><li>hz-&gt;us同步的数据，不会进入us-&gt;hz队列(回环终止，保证不进入死循环)</li></ul><p>存在的问题：存在同步延迟时，会出现版本丢失高/数据交替性变化</p><ul><li>比如US同一条记录变更了10个版本，而且很快同步到了HZ，而HZ因为同步数据大，同步延迟，后续单向回环中将10个版本又在US进行了一次重放，导致出现数据交替</li><li>比如HZ同一条记录变更了10个版本，而且很快同步到了US，而US因为同步延迟，将一个比较早的版本同步到了HZ，后续通过单向回环，将此记录重放到了US，导致之前HZ到US的10个版本丢失.</li></ul><p>解决方案：</p><ul><li>反查数据库同步 (以数据库最新版本同步，解决交替性，比如设置一致性反查数据库延迟阀值为60秒，即当同步过程中发现数据延迟超过了60秒，就会基于PK反查一次数据库，拿到当前最新值进行同步，减少交替性的问题)</li><li>字段同步 (降低冲突概率)</li><li>同步效率 (同步越快越好，降低双写导致版本丢失概率，不需要构建冲突数据KV表)</li><li>同步全局控制 (比如HZ-&gt;US和US-&gt;HZ一定要一起启动，一起关闭，保证不会出现一边数据一直覆盖另一边，造成比较多的版本丢失)</li></ul><p>同步全局控制方案：(分布式Permit)</p><p><img data-src="/images/otter-data-consistency/%E5%88%86%E5%B8%83%E5%BC%8FPermit.png" alt></p><p>注意：A,B,C三点状态都正常才允许进行同步(解决数据单向覆盖)。 任何一边的canal不正常工作，都应该停掉整个双向同步，及时性越高越好。</p><h1>时间交集补救</h1><p><img data-src="/images/otter-data-consistency/%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86%E8%A1%A5%E6%95%91.jpg" alt></p><p>算法描述：</p><ol><li>首先定义两个时间概念</li></ol><ul><li>数据变更时间A ：代表业务数据在A地数据库中产生的时间，即图中的时间A</li><li>数据同步时间B：代表数据变更载入到B地数据库的时间，即图中的时间B</li></ul><ol start="2"><li><p>针对每条或者一批数据都记录变更时间A和同步时间B，同时保留历史同步过的数据记录</p></li><li><p>图中纵轴为时间轴，Aa代表从数据库A同步到数据库B的一个同步过程，Ba代表从数据库B到同步到的数据库A的一个同步过程,每个同步过程在纵轴上会有两个点，分别代表变更时间A和同步时间B.</p></li><li><p>根据同一时间的定义，在两边数据库的各自同步过程中，以数据库A为例，在数据库B的同步过程找到与Aa有时间交集的批次，比如这里就是Aa 与 (Ba , Bb , Bc)有时间交集</p></li><li><p>针对步骤４中的批次，根据同一数据的定义，在交集的每个批次中，比如首先拿Aa和Ba的历史同步数据记录，根据同一数据定义进行查找，然后再是Aa和Bb，依次类推。</p></li><li><p>针对步骤５中找到的同一数据，最后确定为需要进行单向回环的一致性算法的数据。</p></li></ol><p>此方案相比于单向回环方案：减少单向回环同步的数据量，解决A和B地数据对等的case，不过目前开源版本暂未实现。</p><p><a href="https://github.com/alibaba/otter/wiki" target="_blank" rel="noopener">otter wiki</a></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Otter</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 垃圾回收算法之G1</title>
    <url>/java-gc-g1.html</url>
    <content><![CDATA[<blockquote><p>有可能是全网最全的G1总结</p></blockquote><a id="more"></a><p>推荐阅读文章：<br><a href="/attachments/java-gc-g1/22G1GC：分区回收算法说的是什么？.pdf" target="_blank">G1GC：分区回收算法说的是什么？</a></p><p>推荐阅读官方文档:<br><a href="https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-g1-garbage-collector1.html#GUID-3A99AE6C-F80A-4565-A27C-B4AEDF5CDF71" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-g1-garbage-collector1.html#GUID-3A99AE6C-F80A-4565-A27C-B4AEDF5CDF71</a></p><p>调优:<br><a href="https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-garbage-collector-tuning.html#GUID-4914A8D4-DE41-4250-B68E-816B58D4E278" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/20/gctuning/garbage-first-garbage-collector-tuning.html#GUID-4914A8D4-DE41-4250-B68E-816B58D4E278</a></p><p>PDF版文档：<br><a href="/attachments/hotspot-virtual-machine-garbage-collection-tuning-guide-20.pdf" target="_blank">Hotspot Virtual Machine Garbage Collection Tuning Guide</a></p><p>G1(Garbage-First)回收器是在JDK1.7中正式使用的全新垃圾回收器，G1拥有独特的垃圾回收策略，从分代上看，G1依然属于分代垃圾回收器，它会区分年代和老年代，依然有eden和survivor区，但从堆的结构上看，它并不要求整个eden区、年清代或者老年代都连续。它使用了全新的分区算法。</p><p>其特点如下：</p><ul><li><p>并行性：G1在回收期间，可以由多个GC线程同时工作，有效利用多核计算能力。</p></li><li><p>并发性：G1拥有与应用程序交替执行的能力，因此一般来说，不会在整个回收期间完全阻塞应用程序。</p></li><li><p>分代GC：与之前回收器不同，其他回收器，它们要么工作在年轻代要么工作在老年代。G1可以同时兼顾年轻代与老年代。</p></li><li><p>空间整理：G1在回收过程中，会进行适当的对象移动，不像CMS，只是简单的标记清除，在若干次GC后CMS必须进行一次碎片整理，G1在每次回收时都会有效的复制对象，减少空间碎片。</p></li><li><p>可预见性：由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收范围，因此对于全局停顿也能得到更好的控制。</p></li></ul><h1>一、G1的内存划分和主要收集过程</h1><p>G1收集回收器将堆进行分区，划分为一个个的区域，每次收集的时候，只收集其中几个区域，以此来控制垃圾回收产生一次停顿时间。</p><p>G1的收集过程可能有4个阶段：</p><ul><li><p>新生代GC</p></li><li><p>并发标记周期</p></li><li><p>混合收集</p></li><li><p>（如果需要）进行Full GC。</p></li></ul><h1>二、G1的新生代GC</h1><p>新生代GC的主要工作是回收eden区和survivor区。</p><p>一旦eden区被占满，新生代GC就会启动。新生代GC收集前后的堆数据如下图所示，其中E表示eden区，S表示survivor区，O表示老年代。</p><p><img data-src="/images/java-gc-g1/%E6%96%B0%E7%94%9F%E4%BB%A3.png" alt></p><p>可以看到，新生代GC只处理eden和survivor区，回收后，所有的eden区都应该被清空，而survivor区会被收集一部分数据，但是应该至少仍然存在一个survivor区，类比其他的新生代收集器，这一点似乎并没有太大变化。另一个重要的变化是老年代的区域增多，因为部分survivor区或者eden区的对象可能会晋升到老年代。</p><h1>三、G1并发标记周期</h1><p>G1的并发阶段和CMS有些类似，它们都是为了降低一次停顿时间，而将可以和应用程序并发执行的部分单独提取出来执行。</p><blockquote><p>并发标记周期针对老年代</p></blockquote><p>并发标记周期可分为以下几步：</p><ul><li><p>初始标记：标记从根节点直接可达的对象。这个阶段会伴随一次新生代GC，它是会产生<font color="DeepPink"><strong>全局停顿</strong></font>的，应用程序在这个阶段必须停止执行。</p></li><li><p>根区域扫描：由于初始标记必然会伴随一次新生代GC，所以在初始化标记后，eden被清空，并且存活对象被移到survivor区。在这个阶段，将扫描由survivor区直接可达的老年代区域，并标记这些直接可达的对象。这个过程是可以和应用程序并发执行的。但是根区域扫描不能和新生代GC同时发生（因为根区域扫描依赖survivor区的对象，而新生代GC会修改这个区域），故如果恰巧此时需要新生代GC，GC就需要等待根区域扫描结束后才能进行，如果发生这种情况，这次新生代GC的时间就会延长。</p></li><li><p>并发标记：G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断。</p></li><li><p>重新标记：和CMS一样，重新标记也是会使<font color="DeepPink"><strong>应用程序停顿</strong></font>，由于在并发标记过程中，应用程序依然运行，因此标记结果可能需要修正，所以在此阶段对上一次标记进行补充。在G1中，这个过程使用SATB（Snapshot-At-The-Begining）算法完成，即G1会在标记之初为存活对象创建一个快照，这个快照有助于加速重新标记的速度。</p></li><li><p>独占清理：顾名思义，这个阶段会引起<font color="DeepPink"><strong>停顿</strong></font>。它将计算各个区域的存活对象和GC回收比例并进行排序，识别可供混合回收的区域。在这个阶段，还会更新记忆集。该阶段给出了需要被混合回收的区域并进行了标记，在混合回收阶段，需要这些信息。</p></li><li><p>并发清理阶段：识别并清理完全空闲的区域。它是并发的清理，不会引起停顿。</p></li></ul><blockquote><p>SATB全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态：白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。灰：对象被标记了，但是它的field还没有被标记或标记完。黑：对象被标记了，且它的所有field也被标记完了。</p></blockquote><blockquote><p>SATB 利用 write barrier 将所有即将被删除的引用关系的旧引用记录下来，最后以这些旧引用为根 Stop The World 地重新扫描一遍即可避免漏标问题。 因此G1 Remark阶段 Stop The World 与 CMS了的remark有一个本质上的区别，那就是这个暂停只需要扫描有 write barrier 所追中对象为根的对象， 而 CMS 的remark 需要重新扫描整个根集合，因而CMS remark有可能会非常慢。</p></blockquote><h1>四、混合回收</h1><p><strong>在并发标记周期中，虽有部分对象被回收，但是回收的比例是非常低的。但是在并发标记周期后，G1已经明确知道哪些区域含有比较多的垃圾对象，在混合回收阶段，就可以专门针对这些区域进行回收。当然G1会优先回收垃圾比例较高的区域（回收这些区域的性价比高），这正是G1名字的由来（Garbage First Garbage Collector：译为垃圾优先的垃圾回收器），这里的垃圾优先（Garbage First）指的是回收时优先选取垃圾比例最高的区域。</strong></p><p>这个阶段叫做混合回收，是因为在这个阶段，即会执行正常的年轻代GC,又会选取一些被标记的老年代区域进行回收，同时处理了新生代和老年代。</p><p><font color="DeepPink"><strong>混合回收会被执行多次，直到回收了足够多的内存空间</strong></font>，然后，它会触发一次新生代GC。新生代GC后，又可能会发生一次并发标记周期的处理，最后又会引起混合回收，因此整个过程可能是如下图：</p><p><img data-src="/images/java-gc-g1/%E5%9B%9E%E6%94%B6%E5%BE%AA%E7%8E%AF.png" alt></p><h1>五、必要时的Full GC</h1><p>和CMS类似，并发收集让应用程序和GC线程交替工作，因此在特别繁忙的情况下无可避免的会发生回收过程中内存不足的情况，当遇到这种情况，G1会转入一个Full GC 进行回收。</p><p>以下4种情况会触发这类的Full GC：</p><h2 id="1、并发模式失效">1、并发模式失效</h2><p>G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。</p><p>GC日志如下的示例：</p><p><img data-src="/images/java-gc-g1/%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F%E5%A4%B1%E6%95%88.png" alt></p><p>解决办法：发生这种失败意味着堆的大小应该增加了，或者G1收集器的后台处理应该更早开始，或者需要调整周期，让它运行得更快（如，增加后台处理的线程数）。</p><h2 id="2、晋升失败">2、晋升失败</h2><p>（to-space exhausted或者to-space overflow）</p><p>G1收集器完成了标记阶段，开始启动混合式垃圾回收，清理老年代的分区，不过，老年代空间在垃圾回收释放出足够内存之前就会被耗尽。（G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用），由此触发了Full GC。</p><p>下面日志中（可以在日志中看到(to-space exhausted)或者（to-space overflow）），反应的现象是混合式GC之后紧接着一次Full GC。</p><p><img data-src="/images/java-gc-g1/%E6%99%8B%E5%8D%87%E5%A4%B1%E8%B4%A5.png" alt></p><p>这种失败通常意味着混合式收集需要更迅速的完成垃圾收集：每次新生代垃圾收集需要处理更多老年代的分区。</p><p>解决这种问题的方式是：</p><ul><li><p>增加 -XX:G1ReservePercent选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p></li><li><p>通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。</p></li><li><p>也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。</p></li></ul><h2 id="3、疏散失败">3、疏散失败</h2><p>（to-space exhausted或者to-space overflow）</p><p>进行新生代垃圾收集是，Survivor空间和老年代中没有足够的空间容纳所有的幸存对象。这种情形在GC日志中通常是：</p><p><img data-src="/images/java-gc-g1/%E7%96%8F%E6%95%A3%E5%A4%B1%E8%B4%A5.png" alt></p><p>这条日志表明堆已经几乎完全用尽或者碎片化了。G1收集器会尝试修复这一失败，但可以预期，结果会更加恶化：G1收集器会转而使用Full GC。</p><p>解决这种问题的方式是：</p><ul><li><p>增加 -XX:G1ReservePercent选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p></li><li><p>通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。</p></li><li><p>也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。</p></li></ul><h2 id="4、Humongous-Object-分配失败">4、Humongous Object 分配失败</h2><p>当Humongous Object 找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。</p><blockquote><p>对于Humongous Object 的处理还有一种方式就是切换GC算法到ZGC，因为ZGC中对于Humongous Object 的回收不会特殊处理（比如不会延迟收集）。</p></blockquote><h1>六、巨型对象</h1><p>Humongous Object：巨型对象<br>Humongous regions：巨型区域</p><p>对于G1而言，只要超过regin大小的一半，就被认为是巨型对象。巨型对象直接被分配到老年代中的“巨型区域”。这些巨型区域是一个连续的区域集。StartsHumongous 标记该连续集的开始，ContinuesHumongous 标记它的延续。</p><p>在分配巨型对象之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 Full GC。</p><p>对于巨型对象，有以下几个点需要注意：</p><ul><li><p>没有被引用的巨型对象会在标记清理阶段或者Full GC时被释放掉。</p></li><li><p>为了减少拷贝负载，只有在Full GC的时候，才会压缩大对象region。</p></li><li><p>每一个region中都只有一个巨型对象，该region剩余的部分得不到利用，会导致堆碎片化。</p></li><li><p>如果看到由于大对象分配导致频繁的并发回收，需要把大对象变为普通的对象，建议增大Region size。（或者切换到ZGC）</p></li></ul><blockquote><p>对于增大Region size有一个负面影响就是：减少了可用region的数量。因此，对于这种情况，你需要进行相应的测试，以查看是否实际提高了应用程序的吞吐量或延迟。</p></blockquote><h2 id="当巨型对象对象大于region的时候如何处理？">当巨型对象对象大于region的时候如何处理？</h2><p>Humongous objects always take up a number of regions. If a humongous object is smaller than one region then it takes up the whole region. If a humongous object is larger than N regions and smaller than (N+1) regions then it takes up (N+1) regions. No allocations are allowed in the free space, if any, of the last region.</p><blockquote><p><a href="https://openjdk.org/jeps/278" target="_blank" rel="noopener">https://openjdk.org/jeps/278</a></p></blockquote><h1>七、常见调优参数</h1><h2 id="1、-XX-MaxGCPauseMillis-N">1、-XX:MaxGCPauseMillis=N</h2><p>默认200毫秒</p><p>前面介绍过使用GC的最基本的参数：</p><blockquote><p>-XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200</p></blockquote><p>前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。</p><ul><li><p>Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。</p></li><li><p>Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。</p></li></ul><p>在理解了这些后，我们再设置最大暂停时间就有了方向。首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。</p><h2 id="2、-XX-G1HeapRegionSize-n">2、-XX:G1HeapRegionSize=n</h2><p>设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。</p><ul><li><p>-XX:ParallelGCThreads=n（调整G1垃圾收集的后台线程数）<br>设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。<br>如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。</p></li><li><p>-XX:ConcGCThreads=n（调整G1垃圾收集的后台线程数）<br>设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。</p></li></ul><h2 id="3、-XX-InitiatingHeapOccupancyPercent-45（调整G1垃圾收集运行频率）">3、 -XX:InitiatingHeapOccupancyPercent=45（调整G1垃圾收集运行频率）</h2><p>设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</p><p>该值设置太高：会陷入Full GC泥潭之中，因为并发阶段没有足够的时间在剩下的堆空间被填满之前完成垃圾收集。</p><p>如果该值设置太小：应用程序又会以超过实际需要的节奏进行大量的后台处理。</p><p>避免使用以下参数：避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。</p><h1>八、细节</h1><h2 id="1、G1-mixed-GC时机？">1、G1 mixed GC时机？</h2><p>mixed gc中也有一个阈值参数 -XX:InitiatingHeapOccupancyPercent，当老年代大小占整个堆大小百分比达到该阈值时，会触发一次mixed gc.</p><p>在分配humongous object之前先检查是否超过 initiating heap occupancy percent, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 Full GC。</p><p>为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。</p><p>一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。</p><h2 id="2、XX：G1-HeapRegionSize-默认值？">2、XX：G1 HeapRegionSize 默认值？</h2><p>默认把堆内存按照2048份均分，最后得到一个合理的大小。</p><h2 id="3、直接内存配置">3、直接内存配置</h2><p>Q: 什么时候用直接内存？</p><p>A: 读写频繁的场合，出于性能考虑，可以考虑使用直接内存。</p><p>直接内存也是 Java 程序中非常重要的组成部分，特别是 NIO 被广泛使用之后，直接内存可以跳过 Java 堆，使 Java 程序可以直接访问原生堆空间。因此可以在一定程度上加快内存的访问速度。直接内存可以用 -XX:MaxDirectMemorySize 设置，默认值为最大堆空间，也就是 -Xmx。当直接内存达到最大值的时候，也会触发垃圾回收，如果垃圾回收不能有效释放空间，直接内存溢出依然会引起系统的 OOM。</p><p>一般而言直接内存在访问读写上直接内存有较大优势（速度较快），但是在内存空间申请的时候，直接内存毫无优势而言。</p><h2 id="4、RSet">4、RSet</h2><p>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p><p>RSet究竟是怎么辅助GC的呢？</p><p>在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。</p><h1>九、JDK 12中G1的新特性</h1><h2 id="1、可中断-mixed-GC">1、可中断 mixed GC</h2><p>如果 Mixed GC 的 G1 存在超出暂停目标的可能性，则使其可被中止。</p><h2 id="2、G1未使用分配内存即时返回">2、G1未使用分配内存即时返回</h2><p>增强 G1垃圾收集器，以便在空闲时自动将 Java 堆内存返回给操作系统。</p><h1>十、GC 发展趋势</h1><p>其实可以看到Java 垃圾回收器的趋势，就是在大内存堆的前提下尽 GC 可能的降低对应用程序的影响；从 CMS 的分阶段增量标记，到 G1 通过 SATB 算法改正 remark 阶段的 Stop The World 的影响，再到 ZGC/C4甚至在标记阶段无需 Stop The World，莫不如此。</p><h1>十一、结尾</h1><p>推荐几种学习这种GC的方式：</p><ul><li><p>看JEP（JDK Enhancement Proposal）知道它的来龙去脉。</p></li><li><p>看相应算法的paper（之前看Shenandoah GC Paper的时候，就有一种收获很大的感觉，因为Shenandoah GC的处理方式，介于G1跟ZGC之间，所以看了Shenandoah GC Paper感觉对于G1、ZGC的理解也更加深入了）。</p></li></ul><p>会在文章结束，补充上JEP官网地址跟我收集的一些GC资料（包含部分paper）github地址。</p><p>补一个我自己归纳的GC图：</p><p><img data-src="/images/java-gc-g1/GC%E8%84%89%E7%BB%9C.png" alt></p><p>各种GC算法都是围绕着，图中内容展开的，只是各自的处理方式不同而已。</p><p>资料推荐：</p><p>1、GC算法及paper</p><p><a href="https://github.com/jiankunking/books-recommendation/tree/master/GC" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/GC</a></p><p>2、Java相关书籍推荐</p><p><a href="https://github.com/jiankunking/books-recommendation/tree/master/Java" target="_blank" rel="noopener">https://github.com/jiankunking/books-recommendation/tree/master/Java</a></p><p>参考文献</p><p>1、实战JAVA虚拟机 JVM故障诊断与性能优化</p><p>2、jeps</p><p>3、其它</p><p><a href="https://www.oracle.com/technetwork/articles/java/g1gc-1984535.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/articles/java/g1gc-1984535.html</a></p><p><a href="https://plumbr.io/handbook/gc-tuning-in-practice/other-examples/humongous-allocations" target="_blank" rel="noopener">https://plumbr.io/handbook/gc-tuning-in-practice/other-examples/humongous-allocations</a></p>]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>GC</tag>
        <tag>G1</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]分布式缓存的一致性Hash算法</title>
    <url>/distributed-cache-consistent-hash-algorithm.html</url>
    <content><![CDATA[<p>本文整理自：《大型网站技术架构：核心原理与案例分析》<br>作者：李智慧<br>出版时间：2013-09</p><a id="more"></a><h1>一、一致性哈希算法</h1><p>一致性Hash算法通过一个叫做一致性Hash环的数据结构实现Key到缓存服务器的Hash映射，如图6.11所示：<br><img data-src="/images/distributed-cache-consistent-hash-algorithm/611.png" alt></p><p>算法过程如下：</p><p>先构造一个长度为2<sup>32的整数环(这个环被称为一致性Hash环)，根据节点名称的Hash值(其分布为[0，2</sup>32-1])将缓存服务器节点放置在这个Hash环上，然后根据需要缓存的数据的Key值计算得到其Hash值(其分布也为[0，2^32-1])，然后在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。</p><p>假设NODE1的Hash值为3,594,963,423，NODE2的Hash值为1,845,328,979，而KEY0的Hash值为2,534,256,785，那么KEY0在环上顺时计查找，找到的最近的节点就是NODE1。</p><p>当缓存服务器集群要扩容的时候，只需要将新加入的节点名称(NODE3)的Hash 值放入一致性Hash环中，由于KEY是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一小段。如图6.12中深色一段。<br><img data-src="/images/distributed-cache-consistent-hash-algorithm/612.png" alt></p><p>假设NODE3的Hash是2,790,324,235，那么加入NODE3后，KEY0(Hash值 2,534,256,785)顺时针查找得到的节点就是NODE3。</p><p>图6.12中，加入新节点NODE3后，原来的KEY大部分还能继续计算到原来的节点。只有KEY3、KEY0从原来的NODE1重新计算到NODE3。这样就能保证大部分被缓存的数据还可以继续命中。3台服务器扩容至4台服务器。可以继续命中原有缓存数据的概率是75%，远高于余数Hash的25%。而且随着集群规模越大。继续命中原有缓存数据的槪率也逐渐增大，100台服务器扩容增加1台服务器。继续命中的槪率是99%，虽然仍有小部分数据缓存在服务器中不能被读到，但是这个比例足够小。通过访问数据库获取也不会对数据库造成致命的负载压力。</p><p>具体应用中，这个长度为2^32 的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉査找树中查找不小于査找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。</p><p>从增加节点和减少节点的例子中觉察到了问题：新增一个节点时，除了新增的节点外，只有一个节点受影响，这个新增节点和受影响的节点的负载是明显比其他节点低的；减少一个节点时，除了减去的节点外，只有一个节点受影响，它要承担自己原来的和减去的节点的工作，压力明显比其他节点要高。如果4台机器的性能是一样的，那么这种结果显然不是我们需要的。这似乎要增加一倍节点或减去一半节点才能保持各个节点的负载均衡。如果真是这样，一致性哈希的优势就不明显了。</p><h1>二、虛拟节点对一致性哈希的改进(解决负载不均衡问题)</h1><p>计算机领域有句话：计算机的任何问题都可以通过增加一个虚拟层来解决。计算机硬件、计算机网络、计算机软件都莫不如此。计算机网络的7层协议，每一层都可以看作是下一层的虚拟层；计算机操作系统可以看作是计算机硬件的虚拟层；Java虚拟机可以看作是操作系统的虚拟层；分层的计算机软件架构事实上也是利用虚拟层的概念。</p><p>解决上述一致性Hash算法带来的负载不均衡问题，也可以通过使用虚拟层的手段： <font color="DeepPink"><strong>将每个节点虚拟为一组虚拟节点，将虚拟节点的Hash值放置在Hash环上，KEY在环上先找到虚拟节点，再得到物理节点的信息。</strong></font></p><p>这样新加入物理节点时，是将一组虚拟节点加入环中，如果虚拟节点的数目足够多，这组虚拟节点将会影响同样多数目的已经在环上存在的虚拟节点，这些已经存在的虚拟节点又对应不同的物理节点。最终的结果是：新加入一个物理节点，将会较为均匀地影响原来集群中已经存在的所有节点，也就是说分摊原有节点在集群中所有节点的一小部分负载，其总的影响范围和上面讨论过的相同。如图6.13所示。</p><p>在图6.13中，新加入节点NODE3对应的一组虚拟节点为V30，V31，V32，加入到 —致性Hash环上后，影响V01， V12， V22三个虚拟节点，而这三个虚拟节点分别对应 NODE0 NODE1， NODE2三个物理节点。最终集群中加入一个节点，但是同时影响到集群中已存在的三个物理节点，在理想情况下，每个物理节点受影响的数据量 为其节点缓存数据最的1/4(X/(N+X))，N为原有物理节点数，X为新加入物理节点数)，也就是集群中已经被缓存的数据有75%可以被继续命中，和未使用虚拟节点的一致性Hash算法结果相同，只是解决的负载均衡的问题。<br><img data-src="/images/distributed-cache-consistent-hash-algorithm/613.png" alt></p><p><font color="DeepPink"><strong>显然每个物理节点对应的虚拟节点越多，各个物理节点之间的负载越均衡，新加入物理服务器对原有的物理服务器的影响越保持一致(这就是一致性Hash这个名称的由来)。</strong></font>那么在实践中，一台物理服务器虚拟为多少个虚拟服务器节点合适呢？太多会影响性能，太少又会导致负载不均衡，一般说来，经验值是150，当然根据集群规模和负载均衡的精度需求，这个值应该根据具体情况具体对待。</p><blockquote><p>要解决的问题：就是增减缓存集群机器的时候，仍然尽量保持较好的缓存命中率及较均衡的机器负载。</p></blockquote>]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Architecture</tag>
        <tag>Distributed</tag>
        <tag>Cache</tag>
        <tag>Consistent</tag>
      </tags>
  </entry>
  <entry>
    <title>SOFAMosn 如何提高 GoLang 的转发性能</title>
    <url>/sofamosn-golang-performance.html</url>
    <content><![CDATA[<blockquote><p>通过SOFAMosn了解goroutine只能在一定并发量级上降低并发编程的难度(goroutine内存占用2kb+)<br>高并发的场景还是NIO比较适合</p></blockquote><a id="more"></a><p>GoLang 的转发性能比起 C++ 肯定是稍有逊色的，为了尽可能的提高 MOSN 的转发性能，我们在线程模型上进行优化，当前 MOSN 支持两种线程模型，用户可根据场景选择开启适用的模型。</p><h1>模型一</h1><p>如下图所示，使用 GoLang 默认的 epoll 机制，对每个连接分配独立的读写协程进行阻塞读写操作，proxy 层做转发时，使用常驻 worker 协程池负责处理 Stream Event</p><p><img data-src="/images/sofamosn-golang-performance/MOSNThreadModelStage1.png" alt></p><ul><li>此模型在 IO 上使用 GoLang 的调度机制，适用于连接数较少的场景，例如：mosn 作为 sidecar、与 client 同机部署的场景</li></ul><h1>模型二</h1><p>如下图所示，基于 <a href="https://godoc.org/github.com/mailru/easygo/netpoll" target="_blank" rel="noopener">Netpoll</a> 重写 epoll 机制，将 IO 和 PROXY 均进行池化，downstream connection 将自身的读写事件注册到 netpoll 的 epoll/kqueue wait 协程，epoll/kqueue wait 协程接受到可读事件，触发回调，从协程池中挑选一个执行读操作。</p><p><img data-src="/images/sofamosn-golang-performance/MOSNThreadModelStage2.png" alt></p><ul><li>使用自定义 Netpoll IO 池化操作带来的好处是：<ul><li>当可读事件触发时，从协程池中获取一个 goroutine 来执行读处理，而不是新分配一个 goroutine，以此来控制高并发下的协程数量</li><li>当收到链接可读事件时，才真正为其分配 read buffer 以及相应的执行协程。这样 GetBytes() 可以降低因为大量空闲链接场景导致的额外协程和 read buffer 开销</li></ul></li><li>此模型适用于连接数较多、可读连接数量受限的情况，例如：mosn 作为 api gateway 的场景</li></ul><blockquote><p>本文整理自SOFAMosn官方文档</p></blockquote>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Performance</tag>
        <tag>Go</tag>
        <tag>SOFAMosn</tag>
      </tags>
  </entry>
  <entry>
    <title>ReentrantReadWriteLock原理解析</title>
    <url>/java-reentrantreadwritelock.html</url>
    <content><![CDATA[<blockquote><p>Java JDK 11 ReentrantReadWriteLock 原理分析</p></blockquote><a id="more"></a><h1>1、前言</h1><p>希望在阅读本文之前，建议先看一下以下三篇文章：</p><p>1、<a href="https://jiankunking.com/java-aqs.html">面试必备：Java AQS 实现原理（图文）分析</a></p><p>2、<a href="https://jiankunking.com/java-aqs-condition.html">面试必备：Java AQS Condition的实现分析</a></p><p>3、<a href="https://jiankunking.com/java-volatile-aqs.html">面试必备：Java Volatile的内存语义与AQS锁内存可见性</a></p><p>读完了以上三篇文章，先看一下ReentrantReadWriteLock的代码路径：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package java.util.concurrent.locks;</span><br></pre></td></tr></table></figure><p>来先猜一下ReentrantReadWriteLock会如何实现？</p><p>都在java.util.concurrent包下，那么可以明确一点，那就是关于锁的实现，应该用的就是AQS，那么，读锁、写锁会不会对应的就是AQS中的共享模式与独占模式？</p><h1>2、读写锁使用场景</h1><p>读是多于写（比如cache）</p><blockquote><p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。</p></blockquote><h1>3、读写锁接口：ReadWriteLock</h1><p>代码地址：<a href="https://github.com/jiankunking/openjdk11/blob/master/src/java.base/share/classes/java/util/concurrent/locks/ReadWriteLock.java" target="_blank" rel="noopener">ReadWriteLock</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface ReadWriteLock &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Returns the lock used for reading.</span><br><span class="line">     *</span><br><span class="line">     * @return the lock used for reading</span><br><span class="line">     */</span><br><span class="line">    Lock readLock();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Returns the lock used for writing.</span><br><span class="line">     *</span><br><span class="line">     * @return the lock used for writing</span><br><span class="line">     */</span><br><span class="line">    Lock writeLock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、读写锁的接口与示例</p><p>ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现：ReentrantReadWriteLock，除了接口方法之外，还提供了一些便于外界监控其内部工作状态的方法，这些方法以及描述如表所示：</p><p><img data-src="/images/java-reentrantreadwritelock/ReadWriteLock%E6%8E%A5%E5%8F%A3.png" alt><br>接下来，通过一个缓存示例说明读写锁的使用方式，示例代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public class Cache &#123;</span><br><span class="line">    static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();</span><br><span class="line">    static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();</span><br><span class="line">    static Lock r = rwl.readLock();</span><br><span class="line">    static Lock w = rwl.writeLock();</span><br><span class="line"></span><br><span class="line">    // 获取一个key对应的value</span><br><span class="line">    public static final Object get(String key) &#123;</span><br><span class="line">        r.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            return map.get(key);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            r.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 设置key对应的value，并返回旧的value</span><br><span class="line">    public static final Object put(String key, Object value) &#123;</span><br><span class="line">        w.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            return map.put(key, value);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            w.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 清空所有的内容</span><br><span class="line">    public static final void clear() &#123;</span><br><span class="line">        w.lock();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            map.clear();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            w.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述示例中，Cache组合一个非线程安全的HashMap作为缓存的实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。在读操作get(String key)方法中，需要获取读锁，这使得并发访问该方法时不会被阻塞。写操作put(String key,Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性，同时简化了编程方式。</p><h1>5、ReentrantReadWriteLock脉络梳理</h1><p>代码地址：<a href="https://github.com/jiankunking/openjdk11/blob/master/src/java.base/share/classes/java/util/concurrent/locks/ReentrantReadWriteLock.java" target="_blank" rel="noopener">ReentrantReadWriteLock</a></p><p>先看一下继承结构：</p><p><img data-src="/images/java-reentrantreadwritelock/%E8%AF%BB%E5%86%99%E9%94%81%E6%8E%A5%E5%8F%A3%E7%BB%A7%E6%89%BF%E5%85%B3%E7%B3%BB.png" alt><br>再看一下代码结构：</p><p><img data-src="/images/java-reentrantreadwritelock/%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png" alt><br>图中可以看出ReentrantReadWriteLock的实现还是比较复杂的，所以接下来主要分析ReentrantReadWriteLock实现关键点，包括：</p><ul><li>读写状态的设计</li><li>写锁的获取与释放</li><li>读锁的获取与释放</li><li>锁降级</li></ul><h2 id="5-1-读写状态的设计">5.1 读写状态的设计</h2><p>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。</p><p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如下图所示:</p><p><img data-src="/images/java-reentrantreadwritelock/32%E4%BD%8D%E8%AF%BB%E5%86%99%E6%A0%87%E8%AF%86.png" alt></p><p>当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？</p><p>答案是通过位运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。</p><blockquote><p>1、0x0000FFFF=00000000000000001111111111111111（16个0 16个1）</p></blockquote><blockquote><p>2、&gt;&gt;&gt;： 无符号右移，忽略符号位，空位都以0补齐</p></blockquote><blockquote><p>3、0x00010000=10000000000000000（1个1 16个0）</p></blockquote><p>根据状态的划分能得出一个推论：S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</p><h2 id="5-2-写锁的获取与释放">5.2 写锁的获取与释放</h2><p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码如代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Walkthrough:</span><br><span class="line">             * 1. If read count nonzero or write count nonzero</span><br><span class="line">             *    and owner is a different thread, fail.</span><br><span class="line">             * 2. If count would saturate, fail. (This can only</span><br><span class="line">             *    happen if count is already nonzero.)</span><br><span class="line">             * 3. Otherwise, this thread is eligible for lock if</span><br><span class="line">             *    it is either a reentrant acquire or</span><br><span class="line">             *    queue policy allows it. If so, update state</span><br><span class="line">             *    and set owner.</span><br><span class="line">             */</span><br><span class="line">            Thread current = Thread.currentThread();</span><br><span class="line">            int c = getState();</span><br><span class="line">            int w = exclusiveCount(c);</span><br><span class="line">            if (c != 0) &#123;</span><br><span class="line">               // 存在读锁或者当前获取线程不是已经获取写锁的线程</span><br><span class="line">                if (w == 0 || current != getExclusiveOwnerThread())</span><br><span class="line">                    return false;</span><br><span class="line">                if (w + exclusiveCount(acquires) &gt; MAX_COUNT)</span><br><span class="line">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">                // Reentrant acquire</span><br><span class="line">                setState(c + acquires);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            if (writerShouldBlock() ||</span><br><span class="line">                !compareAndSetState(c, c + acquires))</span><br><span class="line">                return false;</span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。<font color="DeepPink"><strong>如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</strong></font></p><p><font color="DeepPink"><strong>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</strong></font></p><h2 id="5-3-读锁的获取与释放">5.3 读锁的获取与释放</h2><p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。获取读锁的实现从Java 5到Java 6变得复杂许多，主要原因是新增了一些功能，例如getReadHoldCount()方法，作用是返回当前线程获取读锁的次数。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护，这使获取读锁的实现变得复杂。因此，这里将获取读锁的代码做了删减，保留必要的部分，如代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected final int tryAcquireShared(int unused) &#123;</span><br><span class="line">          for (;;) &#123;</span><br><span class="line">                  int c = getState();</span><br><span class="line">                  int nextc = c + (1 &lt;&lt; 16);</span><br><span class="line">                  if (nextc &lt; c)</span><br><span class="line">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">                  if (exclusiveCount(c) != 0 &amp;&amp; owner != Thread.currentThread())</span><br><span class="line">                    return -1;</span><br><span class="line">                  if (compareAndSetState(c, nextc))</span><br><span class="line">                    return 1;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。<font color="DeepPink"><strong>如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。</strong></font></p><p>读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1&lt;&lt;16）。</p><h2 id="5-4-锁降级">5.4 锁降级</h2><p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</p><p>接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作，如代码如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public void processData() &#123;</span><br><span class="line">        readLock.lock();</span><br><span class="line">        if (!update) &#123;</span><br><span class="line">            // 必须先释放读锁</span><br><span class="line">            readLock.unlock();</span><br><span class="line">            // 锁降级从写锁获取到开始</span><br><span class="line">            writeLock.lock();</span><br><span class="line">            try &#123;</span><br><span class="line">                if (!update) &#123;</span><br><span class="line">                    // 准备数据的流程（略）</span><br><span class="line">                    update = true;</span><br><span class="line">                &#125;</span><br><span class="line">                readLock.lock();</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                writeLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">            // 锁降级完成，写锁降级为读锁</span><br><span class="line">        &#125;</span><br><span class="line">        try &#123;</span><br><span class="line">            // 使用数据的流程（略）</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            readLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>上述示例中，当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。</p><p><font color="DeepPink"><strong>锁降级中读锁的获取是否必要呢？答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。</strong></font></p><p><font color="DeepPink"><strong>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</strong></font></p><h1>6、小结</h1><p>RentrantReadWriteLock的具体流程梳理完了，回过头来想一下前言的问题，好像并没有得到答案，那么来到ReentrantReadWriteLock代码中，此处主要看一下读锁的获取、释放是否对应AQS中的共享模式。</p><h2 id="6-1-读锁的获取、释放">6.1 读锁的获取、释放</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void lock() &#123;</span><br><span class="line">         //看到这里是不是就明白了，我们的猜想是正确的</span><br><span class="line">         sync.acquireShared(1);</span><br><span class="line">     &#125;</span><br><span class="line">    public void unlock() &#123;</span><br><span class="line">         //看到这里是不是就明白了，我们的猜想是正确的</span><br><span class="line">         sync.releaseShared(1);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><p>先来看一下ReadLock的具体实现，在ReentrantReadWriteLock初始化的时候，会在构造函数中初始化ReadLock、WriteLock，具体代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public ReentrantReadWriteLock() &#123;</span><br><span class="line">       this(false);</span><br><span class="line">   &#125;</span><br><span class="line">   public ReentrantReadWriteLock(boolean fair) &#123;</span><br><span class="line">       sync = fair ? new FairSync() : new NonfairSync();</span><br><span class="line">       readerLock = new ReadLock(this);</span><br><span class="line">       writerLock = new WriteLock(this);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>从ReentrantReadWriteLock构造函数的代码中，可以看到ReadLock初始化的参数是ReentrantReadWriteLock，那么ReadLock需要ReentrantReadWriteLock来做什么呢？</p><p>来看一下ReadLock：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private final Sync sync;</span><br><span class="line">    protected ReadLock(ReentrantReadWriteLock lock) &#123;</span><br><span class="line">        sync = lock.sync;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>从ReadLock的构造函数中，可以看出，ReadLock需要获取到Sync，那么Sync是谁，又是用来做什么的？</p><blockquote><p>其实，如果看过JUC下面代码的话，看到Sync，就明白它应该就是AQS的实现类，通过它来实现相关锁的操作。</p></blockquote><p>来看一下代码验证一下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Synchronization implementation for ReentrantReadWriteLock.</span><br><span class="line">     * Subclassed into fair and nonfair versions.</span><br><span class="line">     */</span><br><span class="line">    abstract static class Sync extends AbstractQueuedSynchronizer &#123;</span><br><span class="line">    //具体代码略</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>看到这里可以大体得出这么一个结果：ReadLock获取锁的时候，是通过ReentrantReadWriteLock 内部Sync类来获取的共享锁，也就是读锁的获取是对应AQS中的共享模式。</p><p>点进 sync.acquireShared(1)方法，可以看到是调用Sync的父类AQS中方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void acquireShared(int arg) &#123;</span><br><span class="line">        if (tryAcquireShared(arg) &lt; 0)</span><br><span class="line">            doAcquireShared(arg);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>看到这里，也就明白为啥AQS子类需要重写：</p><ul><li>tryAcquire</li><li>tryRelease</li><li>tryReleaseShared</li><li>isHeldExclusively</li></ul><p>等方法了。</p><h1>7、参考资料</h1><p>本文第4、5小节整理自：《Java并发编程的艺术》</p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
        <tag>ReentrantReadWriteLock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java AQS Condition的实现分析</title>
    <url>/java-aqs-condition.html</url>
    <content><![CDATA[<blockquote><p>本文整理自《Java并发编程的艺术》第五章 作者：方腾飞　魏鹏　程晓明</p></blockquote><a id="more"></a><p>AQS:AbstractQueuedSynchronizer</p><p>ConditionObject是同步器AQS的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。<font color="DeepPink"><strong>每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。</strong></font></p><p>下面将分析Condition的实现，主要包括：等待队列、等待和通知，下面提到的Condition如果不加说明均指的是ConditionObject。</p><h1>1、等待队列</h1><p><strong>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。</strong></p><p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列，等待队列的基本结构如图5-9所示。<br><img data-src="/images/java-juc-aqs-condition/59.png" alt></p><p>如图所示，Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于<font color="DeepPink">调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</font></p><p>在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而<font color="DeepPink">并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列</font>，其对应关系如图5-10所示。</p><p><img data-src="/images/java-juc-aqs-condition/510.png" alt></p><h1>2、等待</h1><p><font color="DeepPink"><strong>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</strong></font></p><p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。</p><p>Condition的await()方法，如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void await() throws InterruptedException &#123;</span><br><span class="line">        if (Thread.interrupted())</span><br><span class="line">            throw new InterruptedException();</span><br><span class="line">        // 当前线程加入等待队列</span><br><span class="line">        Node node = addConditionWaiter();</span><br><span class="line">        // 释放同步状态，也就是释放锁</span><br><span class="line">        int savedState = fullyRelease(node);</span><br><span class="line">        int interruptMode = 0;</span><br><span class="line">        while (!isOnSyncQueue(node)) &#123;</span><br><span class="line">            LockSupport.park(this);</span><br><span class="line">            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)</span><br><span class="line">                break;</span><br><span class="line">        &#125;</span><br><span class="line">        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)</span><br><span class="line">            interruptMode = REINTERRUPT;</span><br><span class="line">        if (node.nextWaiter != null)</span><br><span class="line">            unlinkCancelledWaiters();</span><br><span class="line">        if (interruptMode != 0)</span><br><span class="line">            reportInterruptAfterWait(interruptMode);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。</p><p>当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p><p>如果从队列的角度去看，当前线程加入Condition的等待队列，该过程如图5-11示。</p><p>如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p><h1>3、通知</h1><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p><p>Condition的signal()方法，如代码清单5-23所示。<br><img data-src="/images/java-juc-aqs-condition/511.png" alt><br>代码清单5-23　ConditionObject的signal方法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void signal() &#123;</span><br><span class="line">       //isHeldExclusively() AQS 子类实现</span><br><span class="line">       if (!isHeldExclusively())</span><br><span class="line">           throw new IllegalMonitorStateException();</span><br><span class="line">       Node first = firstWaiter;</span><br><span class="line">       if (first != null)</span><br><span class="line">           doSignal(first);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。</strong></font>接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p><p>节点从等待队列移动到同步队列的过程如图5-12所示。</p><p><img data-src="/images/java-juc-aqs-condition/512.png" alt><br>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p><p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p><p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p><p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
        <tag>Condition</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL InnoDB存储引擎：外键与锁</title>
    <url>/mysql-innodb-foreign-key-lock.html</url>
    <content><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版</p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p>外键主要用于引用完整性的约束检查<font color="DeepPink"><strong>在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎会自动对其加一个索引，因为这样可以避免表锁。</strong></font> 这比Oracle数据库做得好，Oracle数据库不会自动添加索引，用户必须自己手动添加，这也导致了Oracle数据库中可能产生死锁。</p><p><font color="DeepPink"><strong>对于外键值的插入或更新，首先需要检查父表中的记录，既SELECT父表。但是对于父表的SELECT操作，不是使用一致性非锁定读的方式，因为这会发生数据不一致的问题，因此这时使用的是SELECT…LOCK IN SHARE MODE方式，即主动对父表加一个S锁。</strong></font>如果这时父表上已经这样加X锁，子表上的操作会被阻塞，如下：<br><img data-src="/images/mysql-innodb-foreign-key-lock/%E5%A4%96%E9%94%AE%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png" alt><br>在上述的例子中，两个会话中的事务都没有进行COMMIT或ROLLBACK操作，而会话B的操作会被阻塞。这是因为 id为3的父表在会话 A中已经加了一个X锁，而此时在会话 B中用户又需要对父表中 id为3的行加一个 S锁，这时 INSERT的操作会被阻塞。设想如果访问父表时，使用的是一致性的非锁定读，这时Session B会读到父表有id=3的记录，可以进行插入操作。但是如果会话A对事务提交了，则父表中就不存在id为3的记录。数据在父、子表就会存在不一致的情况。</p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL InnoDB存储引擎：行锁的3种算法</title>
    <url>/mysql-innodb-row-lock-algorithm.html</url>
    <content><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版</p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><h1>行锁的三种算法</h1><p>InnoDB存储引擎有3种行锁的算法，其分别是：</p><ul><li>Record Lock：单个行记录上的范围</li><li><font color="DeepPink"><strong>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</strong></font></li><li><font color="DeepPink"><strong>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身</strong></font></li></ul><p>Record Lock总是会锁住索引记录，如果InnoDB存储引擎建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定。</p><p><font color="DeepPink"><strong>Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，innodb对于行的查询都是采用这种锁定算法。</strong></font>例如一个索引有9,11,13,20这4个值，那么该索引可能被Next-Key Locking的范围为（左开右闭 ）：<br>(- &amp;，9]<br>(9,11]<br>(13,20]<br>(20,+ &amp;)</p><p>采用Next-Key Lock的锁定技术称为Next-Key Locking。这种设计的目的是为了解决幻读（Phantom Problem）。利用这种锁定技术，锁定的不是单个值，而是一个范围。</p><blockquote><p>当查询的索引含有唯一属性时，innodb存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即锁住索引记录本身，而不再是范围。<br>对于唯一索引，其加上的是Record Lock，仅锁住记录本身。但也有特别情况，那就是唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么加锁的情况依然是Next-key lock。</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DROP TABLE</span><br><span class="line">IF EXISTS t;</span><br><span class="line"></span><br><span class="line">CREATE TABLE t (a INT PRIMARY KEY);</span><br><span class="line"></span><br><span class="line">INSERT INTO t</span><br><span class="line">VALUES</span><br><span class="line">	(1),</span><br><span class="line">	(2),</span><br><span class="line">	(5);</span><br></pre></td></tr></table></figure><p><img data-src="/images/mysql-innodb-row-lock-algorithm/%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E9%94%81%E5%AE%9A%E7%A4%BA%E4%BE%8B.png" alt><br>表t中共有1、2、5三个值。在上面的例子中，在会话A中首先对a=5进行X锁定。而由于a是主键且唯一，因此锁定的仅是5这个值，而不是(2,5)这个范围，这样在会话B中插入值4而不会阻塞，可以立即插入并返回。即锁定由Next-Key Lock算法降级为了Record Lock，从而提高应用的并发性。正如前面所介绍的，<font color="DeepPink"><strong>Next-Key降级为Record Lock仅在查询的列是唯一索引的情况下。若是辅助索引，则情况会完全不同。</strong></font>同样，首先根据如下代码创建测试表Z：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE Z (</span><br><span class="line">	a INT,</span><br><span class="line">	b INT,</span><br><span class="line">	PRIMARY KEY (a),</span><br><span class="line">	KEY (b)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO Z</span><br><span class="line">VALUES</span><br><span class="line">	(1, 1),</span><br><span class="line">	(3, 1),</span><br><span class="line">	(5, 3),</span><br><span class="line">	(7, 6),</span><br><span class="line">	(10, 8);</span><br></pre></td></tr></table></figure><p>表Z的列b是辅助索引，若在<strong>会话A</strong>中执行下面的SQL语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM Z WHERE b=3 FOR UPDATE;</span><br></pre></td></tr></table></figure><p>很明显，这时SQL语句通过索引列b进行查询，因此其使用传统的Next-Key Locking技术加锁，并且由于<strong>有两个索引，其需要分别进行锁定</strong>。<strong>对于聚集索引，其仅对列a等于5的索引加上Record Lock。而对于辅助索引，其加上的是Next-Key Locking，锁定的范围是(1,3)</strong>,特别需要注意的是，<font color="DeepPink"><strong>InnoDB存储引擎会对辅助索引下一个键值加上gap lock，即还有一个辅助索引范围为(3,6)的锁</strong></font>。 因此，若在新<strong>会话B</strong>中运行下面的SQL语句，都会被阻塞：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM Z WHERE a=5 LOCK IN SHARE MODE;</span><br><span class="line">INSERT INTO Z SELECT 4,2;</span><br><span class="line">INSERT INTO Z SELECT 6,5;</span><br></pre></td></tr></table></figure><p>第一个SQL语句不能执行，因为在会话A中执行的SQL语句已经聚集索引中列a=5的值加上X锁，因此执行会被阻塞。第二个SQL语句，主键插入4，没有问题，但是插入的辅助索引值2在锁定的范围（1，3）中因此执行同样会被阻塞。第三个SQL语句，插入的主键6没有被锁定，5也不在范围（1，3）之间。但插入的值5在另一个锁定范围（3，6）中，故同样需要等待。而下面的SQL语句，不会被阻塞，可以立即执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INSERT INTO Z SELECT 8,6;</span><br><span class="line">INSERT INTO Z SEELCT 2,0;</span><br><span class="line">INSERT INTO Z SELECT 6,7;</span><br></pre></td></tr></table></figure><p>从上面的例子中可以看到，<font color="DeepPink"><strong>Gap Lock的作用是为了阻止多个事务将记录插入到同一个范围内，而这会导致Phantom Problem问题的产生。</strong></font> 例如在上面的例子中，会话A中用户已经锁定了b=3的记录。若此时没有Gap Lock锁定（3，6），那么用户可以插入索引b列为3的记录，这会导致会话A中的用户再次执行同样查询时会返回不同的记录，导致Phantom Problem问题的产生。</p><p>用户可以通过以下两种方式来显式地关闭Gap Lock：</p><ul><li>将事务的隔离级别设置为READ COMMITTED</li><li>将参数innodb_locks_unsafe_for_binlog设置为1</li></ul><p>在上述的配置下，除了外键约束和唯一性检查依然需要的Gap Lock，其余情况仅使用Record Lock进行锁定。但需要牢记的是，上述设置破坏了事务的隔离性，并且对于replication，可能会导致主从数据的不一致。此外，从性能上来看，READ COMMITTED也不会优于默认的事务隔离级别READ REPEATABLE。</p><p>在InnoDB存储引擎中，对于INSERT的操作，其会检查插入记录的下一条记录是否被锁定，若已被锁定，则不允许查询。对于上面的例子，会话A已经锁定了表z中b=3的记录，即已经锁定了（1，3）的范围，这时若在其他会话中进行如下的插入同样会导致阻塞：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INSERT INTO Z SELECT 2,2;</span><br></pre></td></tr></table></figure><p>因为在辅助索引列b上插入值为2的记录时，会监测到下一个记录3已经被索引。而将插入修改为如下的值，可以立即执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INSERT INTO Z SELECT 2,0;</span><br></pre></td></tr></table></figure><blockquote><p>最后再次提醒的是，对于唯一键值的锁定,Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引一列。若唯一索引由多个列组成，而查询是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询故InnoDB存储引擎依然使用Next-Key Lock进行锁定。</p></blockquote><h1>解决 Phantom Problem</h1><p>在默认的事务隔离级别下，即REPEATABLE READ下，InnoDB存储引擎采用<br>Next-Key Locking机制来避免Phantom Problem (幻像问题）。这点可能不同于与其他的数据库，如Oracle数据库，因为其可能需要在SERIALIZABLE的事务隔离级别下才能解决 Phantom Problem。</p><p><strong>Phantom Problem是指在<font color="DeepPink">同一事务</font>下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。</strong></p><p>下面将演示这个例子，使用前一小节所创建的表t。表t由1、2、5这三个值组成：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DROP TABLE</span><br><span class="line">IF EXISTS t;</span><br><span class="line"></span><br><span class="line">CREATE TABLE t (a INT PRIMARY KEY);</span><br><span class="line"></span><br><span class="line">INSERT INTO t</span><br><span class="line">VALUES</span><br><span class="line">	(1),</span><br><span class="line">	(2),</span><br><span class="line">	(5);</span><br></pre></td></tr></table></figure><p>若这时事务T1执行如下的SQL语句:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM t WHERE a&gt; 2 FOR UPDATE;</span><br></pre></td></tr></table></figure><p>注意这时事务T1并没有进行提交操作，上述应该返回5这个结果。若与此同时,另一个事务T2插入了 4这个值，并且数据库允许该操作，那么事务T1再次执行上述SQL语句会得到结果4和5。这与第一次得到的结果不同，违反了事务的隔离性，即当前事务能够看到其他事务的结果。其过程如表6-13所示：<br><img data-src="/images/mysql-innodb-row-lock-algorithm/%E5%B9%BB%E8%AF%BB%E9%97%AE%E9%A2%98%E6%BC%94%E7%A4%BA.png" alt><br>InnoDB存储引擎采用Next-Key Locking的算法避免Phantom Problem。对于上述的SQL语句SELECT * FROM t WHERE a&gt;2 FOR UPDATE,其锁住的不是5这单个值，而是对（2, +〇〇)这个范围加了 X锁。因此任何对于这个范围的插入都是不被允许的，从而避免 Phantom Problem。</p><p>InnoDB存储引擎默认的事务隔离级别是REPEATABLE READ,在该隔离级别下,<br>其采用Next-Key Locking的方式来加锁。而在事务隔离级别READ COMMITTED下,其仅采用Record Lock，因此在上述的示例中，会话A需要将事务的隔离级别设置为READ COMMITTED。</p><p>此外，<font color="DeepPink"><strong>用户可以通过InnoDB存储引擎的Next-Key Locking机制在应用层面实现唯一性的检查。</strong></font> 例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM table WHERE col=xxx LOCK IN SHARE MODE;</span><br><span class="line">If not found any row:</span><br><span class="line"># unique for insert value</span><br><span class="line">INSERT INTO table VALUES (...);</span><br></pre></td></tr></table></figure><p>如果用户通过索引査询一个值，并对该行加上一个SLock，那么即使査询的值不在，其锁定的也是一个范围，因此若没有返回任何行，那么新插人的值一定是唯一的。也许有读者会有疑问，如果在进行第一步SELECT •••LOCK IN SHARE MODE操作时，有多个事务并发操作，那么这种唯一性检査机制是否存在问题。其实并不会，因为这时会导致死锁，只有一个事务的插人操作会成功，而其余的事务会抛出死锁的错误，如表6-14所示。<br><img data-src="/images/mysql-innodb-row-lock-algorithm/%E5%94%AF%E4%B8%80%E6%80%A7%E6%A3%80%E6%9F%A5.png" alt></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL InnoDB存储引擎：分区表</title>
    <url>/mysql-innodb-partition-table.html</url>
    <content><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版</p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><h1>MySQL分区表介绍</h1><p>分区是一种表的设计模式，正确的分区可以极大地提升数据库的查询效率，完成更高质量的SQL编程。但是如果错误地使用分区，那么分区可能带来毁灭性的的结果。</p><p><font color="DeepPink"><strong>分区功能并不是在存储引擎层完成的，因此不只有InnoDB存储引擎支持分区，常见的存储引擎MyISAM、NDB等都支持分区。</strong></font> 但是并不是所有的存储引擎都支持，如CSV、FEDORATED、MERGE等就不支持分区。在使用此分区功能前，应该对选择的存储引擎对分区的支持有所了解。</p><p>MySQL数据库在5.1版本时添加了对分区的支持，<font color="DeepPink"><strong>分区的过程是将一个表或索引分解为多个更小、更可管理的部分。就访问数据库的应用而言，从逻辑上讲，只有一个表或一个索引，但是在物理上这个表或索引可能由数十个物理分区组成。每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。</strong></font></p><p>MySQL数据库支持的分区类型为<font color="DeepPink"><strong>水平分区</strong></font>（指将同一个表中不同行的记录分配到不同的物理文件中），并不支持垂直分区（指将同一表中不同列的记录分配到不同的物理文件中）。此外，<font color="DeepPink"><strong>MySQL数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。</strong></font>而全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。目前，MySQL数据库还不支持全局分区。</p><p>可以通过以下命令来查看当前数据库是否启用了分区功能：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; show global variables like &apos;%partition%&apos;;</span><br><span class="line">+-------------------+-------+</span><br><span class="line">| Variable_name     | Value |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">| have_partitioning | YES   |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">1 row in set (0.04 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show plugins</span><br><span class="line">*************************** 43. row ***************************</span><br><span class="line">   Name: partition</span><br><span class="line"> Status: ACTIVE</span><br><span class="line">   Type: STORAGE ENGINE</span><br><span class="line">Library: NULL</span><br><span class="line">License: GPL</span><br></pre></td></tr></table></figure><p>有时候可能会有这么一种误区，只要启用了分区，数据库就会运行的更快。这个结论结论是存在很多问题的，就经验来看，分区可能会给某些SQL语句性能带来提高，但是分区主要用于数据库高可用性的管理。在OLTP应用中，对于分区的使用应该非常小心，总之，如果只是一味地使用分区，而不理解分区是如何工作的，也不清楚你的应用如何使用分区，那么分区极有可能会对性能产生负面的影响。</p><h1>MySQL分区类型</h1><h2 id="RANGE分区">RANGE分区</h2><p>RANGE分区，是最常用的一种分区类型，基于属于一个给定连续区间的列值，把多行分配给分区。这些区间要连续且不能相互重叠，使用VALUES LESS THAN操作符来进行定义。</p><h2 id="LIST分区">LIST分区</h2><p>LIST分区和RANGE分区类似，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择，而非连续的。</p><p>LIST分区通过使用“PARTITION BY LIST(expr)”来实现，其中“expr” 是某列值或一个基于某个列值、并返回一个整数值的表达式，然后通过“VALUES IN (value_list)”的方式来定义每个分区，其中“value_list”是一个通过逗号分隔的整数列表。</p><h2 id="HASH分区">HASH分区</h2><p>HASH分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区的数据量大致都是一样的。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中；而在HASH分区中，MySQL自动完成这些工作，用户所要做的只是基于将要进行哈希分区的列值指定一个列值或表达式，以及指定被分区的表将要被分隔成的分区数量。</p><p>要使用HASH分区来分割一个表，要在CREATE TABLE 语句上添加一个“PARTITION BY HASH (expr)”子句，其中“expr”是一个返回一个整数的表达式。它可以仅仅是字段类型为MySQL 整型的一列的名字。此外，你很可能需要在后面再添加一个“PARTITIONS num”子句，其中num是一个非负的整数，它表示表将要被分割成分区的数量，如果没有包括一个PARTITIONS子句，那么分区的数量将默认为1。</p><h2 id="LINER-HASH">LINER HASH</h2><p>MySQL还支持线性哈希功能，它与常规哈希的区别在于，线性哈希功能使用的一个线性的2的幂（powers-of-two）运算法则，而常规哈希使用的是求哈希函数值的模数。<br>线性哈希分区和常规哈希分区在语法上的唯一区别在于，在“PARTITION BY” 子句中添加“LINEAR”关键字。</p><h2 id="KEY分区">KEY分区</h2><p>KEY分区和HASH分区相似，不同之处在于HASH分区使用用户定义的函数进行分区，支持字符串HASH分区，KEY分区使用MySQL数据库提供的函数进行分区，这些函数基于与PASSWORD()一样的运算法则。</p><h2 id="COLUMNS">COLUMNS</h2><p>在前面说了RANGE、LIST、HASH和KEY这四种分区中，分区的条件是：数据必须为整形（interger），如果不是整形，那应该需要通过函数将其转化为整形，如YEAR()，TO_DAYS()，MONTH()等函数。MySQL5.5版本开始支持COLUMNS分区，可视为RANGE分区和LIST分区的一种进化。COLUMNS分区可以直接使用非整形的数据进行分区，分区根据类型直接比较而得，不需要转化为整形。此外，RANGE COLUMNS分区可以对多个列的值进行分区。</p><p>COLUMNS分区支持以下的数据类型：</p><ul><li>所有的整形类型，如INT、SMALLINT、TINYINT和BIGINT。而FLOAT和DECIMAL则不予支持。</li><li>日期类型，如DATE何DATETIME。其余的日期类型不予支持。</li><li>字符串类型，如CHAR、VARCHAR、BINARY和VARBINARY。而BLOB和TEXT类型不予支持。</li></ul><h1>分区中的NULL值</h1><p>MySQL数据库允许对NULL值做分区，但是处理的方法与其他数据库可能完全不同。MySQL数据库的分区总是视NULL值小于任何的一个非NULL值，这和MySQL数据库中处理NULL值的ORDER BY操作是一样的。 因此对于不同的分区类型，MySQL数据库对于NULL值的处理也是各不相同。</p><ul><li>对于RANGE分区，如果向分区列插入了NULL值，则MySQL数据库会将该值放入最左边的分区。</li><li>对于LIST分区，如果向分区列插入了NULL值，则必须显示地指出哪个分区放入NULL值，否则会报错。对于LIST分区，如果向分区列插入了NULL值，则必须显示地指出哪个分区放入NULL值，否则会报错。</li><li>对于HASH和KEY分区，对于NULL值的处理方法和RANGE分区、LIST分区不一样。任何分区函数都会将含有NULL值的记录返回为0。</li></ul><h1>分区和性能</h1><p>分区真的会加快数据库的查询吗？实际上可能根本感觉不到查询速度的提升，甚至会发现查询速度急剧下降，因此在合理使用分区之前，必须了解分区的使用环境。</p><p>数据库的应用分为两类：一类是OLTP（在线事务处理），如Blog、电子商务、网络游戏等；另一类是OLAP（在线分析处理），如数据仓库、数据集市。对于OLAP的应用，分区的确是可以很好地提高查询的性能，因为OLAP应用大多数查询需要频繁地扫描一张很大的表。假设有一张1亿行的表，其中有一个时间戳属性列。用户的查询需要从这张表中获取一年的数据。如果按时间戳进行分区，则只需要扫描相应的分区即可。这就是前面介绍的分区修剪技术。</p><p><font color="DeepPink"><strong>对于OLTP的应用，分区应该非常小心。在这种应用下，通常不可能会获取一张大表10%的数据，大部分都是通过索引返回几条记录即可。而根据B+树索引的原理可知，对于一张大表，一般的B+树需要2~3次的磁盘IO。因此B+树可以很好地完成操作，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。</strong></font></p><p>如很多开发团队会认为含有1000w行的表是一张非常巨大的表，所以他们往往会选择采用分区，如对主键做10个HASH的分区，这样每个分区就只有100w的数据了，因此查询应该变得更快了。如select * from table where pk=@pk。但是有没有考虑过这样一种情况：100w和1000w行的数据本身构成的B+树的层次都是一样的，可能都是2~3层。那么上述走主键分区的索引并不会带来性能的提高。好的，如果1000w的B+树高度是3,100w的B+树高度是2，那么上述按主键分区的索引可以避免1次IO，从而提高查询的效率。这没问题，但是这张表只有主键索引，没有任何其他的列需要查询的。如果还有类似如下的SQL：select * from table where key=@key，这时对于key的查询需要扫描所有的10个分区，即使每个分区的查询开销为2次IO，则一共需要20次IO。而对于原来单表的设计，对于KEY的查询只需要2~3次IO。</p><p>由以上结论可以看出，对于在OLTP场景中使用分区一定要特别小心了。</p><h1>MySQL 5.7对分区的改进</h1><p>在MySQL 5.6里面，分区的信息是在MySQL Server层维护的（在.par文件里面），InnoDB引擎层是不知道有分区这个概念的，InnoDB引擎层把每一个分区都当成一张普通的InnoDB表。在打开一个分区表时，会打开很多个分区，打开这些分区表就相当于打开了同等数量的InnoDB表，这需要更多内存存放InnoDB表的元数据和各种与ibd文件打开相关的各种cache与handler的信息。在MySQL 5.7里面，InnoDB引入了Native Partitioning，它把分区的信息从Server层移到了InnoDB层，打开一个分区表和打开一个InnoDB表的内存开销基本是一样的。</p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL InnoDB存储引擎：一致性锁定读</title>
    <url>/mysql-innodb-consistent-locking-read.html</url>
    <content><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版</p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p>在<a href="https://jiankunking.com/mysql-innodb-consistent-nonlocking-read.html">前一小节</a>中讲到，在默认配置下，即事务的隔离级别为 REPEATABLE READ 模式下， InnoDB 存储引擎的 SELECT 操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read)操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT......FOR UPDATE</span><br><span class="line">SELECT......LOCK IN SHARE MODE</span><br></pre></td></tr></table></figure><p><font color="DeepPink"><strong>SELECT…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。</strong></font><br><font color="DeepPink"><strong>SELECT…LOCK IN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</strong></font></p><p>对于一致性非锁定读，即使读取的行已被执行了 SELECT…FOR UPDATE,也是可以进行读取的，这和之前讨论的情况一样。此外，SELECT…FOR UPDATE, SELECT…LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN,START TRANSACTION 或者SET AUTOCOMMIT =0 。</p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL InnoDB存储引擎：一致性非锁定读</title>
    <url>/mysql-innodb-consistent-nonlocking-read.html</url>
    <content><![CDATA[<p>本文整理自：《MySQL技术内幕:InnoDB存储引擎》 第二版</p><p>作者：姜承尧</p><p>出版时间：2013-05</p><a id="more"></a><p><strong>一致性的非锁定行读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE、UPDATE操作，这是读取操作不会因此而会等待行上锁的释放，相反，InnoDB会去读取行的一个快照数据。</strong></p><p>下图直观展示了一致性的非锁定行读：<br><img data-src="/images/mysql-innodb-consistent-nonlocking-read/%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E9%94%81%E5%AE%9A%E8%A1%8C%E8%AF%BB.png" alt></p><p><strong>之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo段用来在此事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。</strong></p><p>可以看到，非锁定读机制极大地提髙了数据库的并发性。<strong>在InnoDB存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁。但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同。</strong></p><p>通过图6-4可以知道，快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。就图6-4所显示的，<strong>一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（MultiVersionConcurrencyControl MVCC）。</strong></p><p>在事务隔离级别READ COMMITTED和REPEATABLE READ(InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。<font color="DeepPink"><strong>在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本（关键在于事务之间的隔离性）。</strong></font>来看下面的一个例子，首先在当前MySQL数据库的连接会话A中执行如下SQL语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Session A</span><br><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">Sql&gt; SELECT * FROM parent WHERE id =1;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1 |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>会话A中已通过显式地执行命令BEGIN开启了一个事务，并读取了表parent中id为1的数据，但是事务并没有结束。与此同时，用户再开启另一个会话B，这样可以模拟并发的情况，然后对会话B做如下的操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE parent SET id=3 WHERE id=l;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1 Changed: 1 warnings: 0</span><br></pre></td></tr></table></figure><p>在会话B中将事务表parent中id为1的记录修改为id=3，但是事务同样没有提交，这样id=1的行其实加了一个X锁。这时如果在会话A中再次读取id为1的记录，根据InnoDB存储引擎的特性，即在READ COMMITTED和REPEATETABLE READ的事务隔离级别下会使用非锁定的一致性读。回到之前的会话A,接着上次未提交的事务，执行SQL语句SELECT * FROM parent WHERE id=1的操作，这时不管使用READ COMMITTED还是REPEATABLE READ的事务隔离级别，显示的数据应该都是：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT FROM parent WHERE id =l;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1  |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>由于当前id=1的数据被修改了1次，因此只有一个行版本的记录。接着，在会话B中提交上次的事务。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Session B</span><br><span class="line">mysql&gt; commit</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure><p>在会话B提交事务后，这时在会话A中再运行SELECT * FROM parent WHERE id=1的SQL语句，在READ COMMITTED和REPEATABLE事务隔离级别下得到结果 就不一样了。对于READ COMMITTED的事务隔离级别，它总是读取行的最新版本，如果行被锁定了，则读取该行版本的最新一个快照（fresh snapshot）。在上述例子中，因为会话B已经提交了事务，所以READ COMMITTED事务隔离级别下会得到如下结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt;SELECT @@tx_isolation\G;</span><br><span class="line">**************************** 1.row ****************************</span><br><span class="line">@@tx_isolation: READ-COMMITTED</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT FROM parent WHERE id=1:</span><br><span class="line">Empty set (0.00 sec)</span><br></pre></td></tr></table></figure><p>而对于REPEATETABLE 的事务隔离级别，总是读取事务开始时的行数据。因此对于REPEATETABLE READ事务隔离级别,其得到的结果如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT @@tx_isolation\G;</span><br><span class="line">**************************** 1.row ****************************</span><br><span class="line">@@tx_isolation: REPEATABLE-READ</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT FROM parent WHERE id=1;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">| 1  |</span><br><span class="line">+----+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>下面将从时间的角度展现上述演示的示例过程，如表6-8所示。需要特别注意的是，对于READ COMMITTED 的事务隔离级别而言，从数据库理论的角度来看，其违反了事务ACID中的I的特性，即隔离性。<br><img data-src="/images/mysql-innodb-consistent-nonlocking-read/%E8%A1%A868.png" alt></p>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]当你在浏览器中输入 google.com 并且按下回车之后发生了什么？</title>
    <url>/what-happens-when.html</url>
    <content><![CDATA[<blockquote><p>当你在浏览器中输入 <a href="http://google.com" target="_blank" rel="noopener">google.com</a> 并且按下回车之后发生了什么？<br>整理自 <a href="https://github.com/skyline75489/what-happens-when-zh_CN" target="_blank" rel="noopener">https://github.com/skyline75489/what-happens-when-zh_CN</a></p></blockquote><a id="more"></a><h1>当···时发生了什么？</h1><p>这个仓库试图回答一个古老的面试问题：当你在浏览器中输入 <a href="http://google.com" target="_blank" rel="noopener">google.com</a> 并且按下回车之后发生了什么？</p><p>不过我们不再局限于平常的回答，而是想办法回答地尽可能具体，不遗漏任何细节。</p><h1>目录</h1><h2 id="按下-g-键">按下&quot;g&quot;键</h2><p>接下来的内容介绍了物理键盘和系统中断的工作原理，但是有一部分内容却没有涉及。当你按下“g”键，浏览器接收到这个消息之后，会触发自动完成机制。浏览器根据自己的算法，以及你是否处于隐私浏览模式，会在浏览器的地址框下方给出输入建议。大部分算法会优先考虑根据你的搜索历史和书签等内容给出建议。你打算输入&quot;<a href="http://google.com" target="_blank" rel="noopener">google.com</a>&quot;，因此给出的建议并不匹配。但是输入过程中仍然有大量的代码在后台运行，你的每一次按键都会使得给出的建议更加准确。甚至有可能在你输入之前，浏览器就将&quot;<a href="http://google.com" target="_blank" rel="noopener">google.com</a>&quot; 建议给你。</p><h2 id="回车键按下">回车键按下</h2><p>为了从零开始，我们选择键盘上的回车键被按到最低处作为起点。在这个时刻，一个专用于回车键的电流回路被直接地或者通过电容器间接地闭合了，使得少量的电流进入了键盘的逻辑电路系统。这个系统会扫描每个键的状态，对于按键开关的电位弹跳变化进行噪音消除(debounce)，并将其转化为键盘码值。在这里，回车的码值是13。键盘控制器在得到码值之后，将其编码，用于之后的传输。现在这个传输过程几乎都是通过通用串行总线(USB)或者蓝牙(Bluetooth)来进行的，以前是通过PS/2或者ADB连接进行。</p><p><em>USB键盘：</em></p><ul><li>键盘的USB元件通过计算机上的USB接口与USB控制器相连接，USB接口中的第一号针为它提供了5V的电压</li><li>键码值存储在键盘内部电路一个叫做&quot;endpoint&quot;的寄存器内</li><li>USB控制器大概每隔10ms便查询一次&quot;endpoint&quot;以得到存储的键码值数据，这个最短时间间隔由键盘提供</li><li>键值码值通过USB串行接口引擎被转换成一个或者多个遵循低层USB协议的USB数据包</li><li>这些数据包通过D+针或者D-针(中间的两个针)，以最高1.5Mb/s的速度从键盘传输至计算机。速度限制是因为人机交互设备总是被声明成&quot;低速设备&quot;（USB 2.0 compliance）</li><li>这个串行信号在计算机的USB控制器处被解码，然后被人机交互设备通用键盘驱动进行进一步解释。之后按键的码值被传输到操作系统的硬件抽象层</li></ul><p><em>虚拟键盘（触屏设备）：</em></p><ul><li>在现代电容屏上，当用户把手指放在屏幕上时，一小部分电流从传导层的静电域经过手指传导，形成了一个回路，使得屏幕上触控的那一点电压下降，屏幕控制器产生一个中断，报告这次“点击”的坐标</li><li>然后移动操作系统通知当前活跃的应用，有一个点击事件发生在它的某个GUI部件上了，现在这个部件是虚拟键盘的按钮</li><li>虚拟键盘引发一个软中断，返回给OS一个“按键按下”消息</li><li>这个消息又返回来向当前活跃的应用通知一个“按键按下”事件</li></ul><h2 id="产生中断-非USB键盘">产生中断[非USB键盘]</h2><p>键盘在它的中断请求线(IRQ)上发送信号，信号会被中断控制器映射到一个中断向量，实际上就是一个整型数。CPU使用中断描述符表(IDT)把中断向量映射到对应函数，这些函数被称为中断处理器，它们由操作系统内核提供。当一个中断到达时，CPU根据IDT和中断向量索引到对应的中断处理器，然后操作系统内核出场了。</p><h2 id="Windows-一个-WM-KEYDOWN-消息被发往应用程序">(Windows)一个 <code>WM_KEYDOWN</code> 消息被发往应用程序</h2><p>HID把键盘按下的事件传送给 <code>KBDHID.sys</code>驱动，把HID的信号转换成一个扫描码(Scancode)，这里回车的扫描码是<br><code>VK_RETURN(0x0d)</code>。 <code>KBDHID.sys</code> 驱动和 <code>KBDCLASS.sys</code>(键盘类驱动,keyboard class driver)进行交互，这个驱动负责安全地处理所有键盘和小键盘的输入事件。之后它又去调用<code>Win32K.sys</code>，在这之前有可能把消息传递给安装的第三方键盘过滤器。这些都是发生在内核模式。</p><p><code>Win32K.sys</code> 通过 <code>GetForegroundWindow()</code>API函数找到当前哪个窗口是活跃的。这个API函数提供了当前浏览器的地址栏的句柄。Windows系统的&quot;message pump&quot;机制调用 <code>SendMessage(hWnd, WM_KEYDOWN, VK_RETURN, lParam)</code> 函数，<code>lParam</code>是一个用来指示这个按键的更多信息的掩码，这些信息包括按键重复次数（这里是0），实际扫描码（可能依赖于OEM厂商，不过通常不会是<code>VK_RETURN</code> ），功能键（alt, shift, ctrl）是否被按下（在这里没有），以及一些其他状态。</p><p>Windows的 <code>SendMessage</code> API直接将消息添加到特定窗口句柄 <code>hWnd</code>的消息队列中，之后赋给 <code>hWnd</code> 的主要消息处理函数 <code>WindowProc</code>将会被调用，用于处理队列中的消息。</p><p>当前活跃的句柄 <code>hWnd</code> 实际上是一个edit control控件，这种情况下，<code>WindowProc</code> 有一个用于处理 <code>WM_KEYDOWN</code><br>消息的处理器，这段代码会查看 <code>SendMessage</code> 传入的第三个参数 <code>wParam</code>，因为这个参数是 <code>VK_RETURN</code> ，于是它知道用户按下了回车键。</p><h2 id="Mac-OS-X-一个-KeyDown-NSEvent被发往应用程序">(Mac OS X)一个 <code>KeyDown</code> NSEvent被发往应用程序</h2><p>中断信号引发了I/O Kit Kext键盘驱动的中断处理事件，驱动把信号翻译成键码值，然后传给OS X的<code>WindowServer</code> 进程。然后， <code>WindowServer</code>将这个事件通过Mach端口分发给合适的（活跃的，或者正在监听的）应用程序，这个信号会被放到应用程序的消息队列里。队列中的消息可以被拥有足够高权限的线程使用<code>mach_ipc_dispatch</code> 函数读取到。这个过程通常是由 <code>NSApplication</code>主事件循环产生并且处理的，通过 <code>NSEventType</code> 为 <code>KeyDown</code> 的 <code>NSEvent</code>。</p><h2 id="GNU-Linux-Xorg-服务器监听键码值">(GNU/Linux)Xorg 服务器监听键码值</h2><p>当使用图形化的 X Server 时，X Server会按照特定的规则把键码值再一次映射，映射成扫描码。当这个映射过程完成之后，X Server 把这个按键字符发送给窗口管理器(DWM，metacity,i3等等)，窗口管理器再把字符发送给当前窗口。当前窗口使用有关图形API把文字打印在输入框内。</p><h2 id="解析URL">解析URL</h2><ul><li><p>浏览器通过 URL 能够知道下面的信息：</p><blockquote><ul><li><p><code>Protocol</code> “http”<br>: 使用HTTP协议</p></li><li><p><code>Resource</code> “/”<br>: 请求的资源是主页(index)</p></li></ul></blockquote></li></ul><h2 id="输入的是-URL-还是搜索的关键字？">输入的是 URL 还是搜索的关键字？</h2><p>当协议或主机名不合法时，浏览器会将地址栏中输入的文字传给默认的搜索引擎。大部分情况下，在把文字传递给搜索引擎的时候，URL会带有特定的一串字符，用来告诉搜索引擎这次搜索来自这个特定浏览器。</p><h2 id="转换非-ASCII-的-Unicode-字符">转换非 ASCII 的 Unicode 字符</h2><ul><li>浏览器检查输入是否含有不是 <code>a-z</code>， <code>A-Z</code>，<code>0-9</code>， <code>-</code> 或者 <code>.</code> 的字符</li><li>这里主机名是 <code>google.com</code>，所以没有非ASCII的字符；如果有的话，浏览器会对主机名部分使用<a href="https://en.wikipedia.org/wiki/Punycode" target="_blank" rel="noopener">Punycode</a> 编码</li></ul><h2 id="检查-HSTS-列表">检查 HSTS 列表</h2><ul><li>浏览器检查自带的“预加载 HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站</li><li>如果网站在这个列表里，浏览器会使用 HTTPS 而不是 HTTP协议，否则，最初的请求会使用HTTP协议发送</li><li>注意，一个网站哪怕不在 HSTS 列表里，也可以要求浏览器对自己使用 HSTS 政策进行访问。浏览器向网站发出第一个HTTP请求之后，网站会返回浏览器一个响应，请求浏览器只使用 HTTPS 发送请求。然而，就是这第一个HTTP请求，却可能会使用户受到downgrade attack_ 的威胁，这也是为什么现代浏览器都预置了 HSTS 列表。</li></ul><h2 id="DNS-查询">DNS 查询</h2><ul><li>浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开<a href="chrome://net-internals/#dns" target="_blank" rel="noopener"><a href="chrome://net-internals/#dns" target="_blank" rel="noopener">chrome://net-internals/#dns</a></a>）。</li><li>如果缓存中没有，就去调用 <code>gethostbyname</code>库函数（操作系统不同函数也不同）进行查询。</li><li><code>gethostbyname</code> 函数在试图进行DNS解析之前首先检查域名是否在本地Hosts 里，Hosts 的位置<a href="https://en.wikipedia.org/wiki/Hosts_%28file%29#Location_in_the_file_system" target="_blank" rel="noopener">不同的操作系统有所不同</a></li><li>如果 <code>gethostbyname</code> 没有这个域名的缓存记录，也没有在 <code>hosts</code>里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。</li><li>查询本地 DNS 服务器</li><li>如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询</li><li>如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询</li></ul><h2 id="ARP-过程">ARP 过程</h2><p>要想发送 ARP（地址解析协议）广播，我们需要有一个目标 IP地址，同时还需要知道用于发送 ARP 广播的接口的 MAC 地址。</p><ul><li>首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC</li></ul><p>如果缓存没有命中：</p><ul><li>查看路由表，看看目标 IP 地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。</li><li>查询选择的网络接口的 MAC 地址</li><li>我们发送一个二层（ OSI 模型_ 中的数据链路层）ARP 请求：</li></ul><p><code>ARP Request</code>:</p><pre><code>Sender MAC: interface:mac:address:here
Sender IP: interface.ip.goes.here
Target MAC: FF:FF:FF:FF:FF:FF (Broadcast)
Target IP: target.ip.goes.here
</code></pre><p>根据连接主机和路由器的硬件类型不同，可以分为以下几种情况：</p><p>直连：</p><ul><li>如果我们和路由器是直接连接的，路由器会返回一个 <code>ARP Reply</code>（见下面）。</li></ul><p>集线器：</p><ul><li>如果我们连接到一个集线器，集线器会把 ARP 请求向所有其它端口广播，如果路由器也“连接”在其中，它会返回一个 <code>ARP Reply</code> 。</li></ul><p>交换机：</p><ul><li>如果我们连接到了一个交换机，交换机会检查本地 CAM/MAC 表，看看哪个端口有我们要找的那个 MAC地址，如果没有找到，交换机会向所有其它端口广播这个 ARP 请求。</li><li>如果交换机的 MAC/CAM 表中有对应的条目，交换机会向有我们想要查询的 MAC 地址的那个端口发送 ARP 请求</li><li>如果路由器也“连接”在其中，它会返回一个 <code>ARP Reply</code></li></ul><p><code>ARP Reply</code>:</p><pre><code>Sender MAC: target:mac:address:here
Sender IP: target.ip.goes.here
Target MAC: interface:mac:address:here
Target IP: interface.ip.goes.here
</code></pre><p>现在我们有了 DNS 服务器或者默认网关的 IP 地址，我们可以继续 DNS 请求了：</p><ul><li>使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议</li><li>如果本地/ISP DNS服务器没有找到结果，它会发送一个递归查询请求，一层一层向高层DNS服务器做查询，直到查询到起始授权机构，如果找到会把结果返回</li></ul><h2 id="使用套接字">使用套接字</h2><p>当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数<code>socket</code> ，请求一个 TCP流套接字，对应的参数是 <code>AF_INET/AF_INET6</code> 和<code>SOCK_STREAM</code> 。</p><ul><li>这个请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range)</li><li>TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet。</li><li>这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame 头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。</li></ul><p>到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输：</p><ul><li><a href="http://en.wikipedia.org/wiki/IEEE_802.3" target="_blank" rel="noopener">以太网</a></li><li><a href="https://en.wikipedia.org/wiki/IEEE_802.11" target="_blank" rel="noopener">WiFi</a></li><li><a href="https://en.wikipedia.org/wiki/Cellular_data_communication_protocol" target="_blank" rel="noopener">蜂窝数据网络</a></li></ul><p>对于大部分家庭网络和小型企业网络来说，封包会从本地计算机出发，经过本地网络，再通过调制解调器把数字信号转换成模拟信号，使其适于在电话线路，有线电视光缆和无线电话线路上传输。在传输线路的另一端，是另外一个调制解调器，它把模拟信号转换回数字信号，交由下一个<a href="https://en.wikipedia.org/wiki/Computer_network#Network_nodes" target="_blank" rel="noopener">网络节点</a>处理。节点的目标地址和源地址将在后面讨论。</p><p>大型企业和比较新的住宅通常使用光纤或直接以太网连接，这种情况下信号一直是数字的，会被直接传到下一个<a href="https://en.wikipedia.org/wiki/Computer_network#Network_nodes" target="_blank" rel="noopener">网络节点</a>进行处理。</p><p>最终封包会到达管理本地子网的路由器。在那里出发，它会继续经过自治区域(autonomous system, 缩写<br>AS)的边界路由器，其他自治区域，最终到达目标服务器。一路上经过的这些路由器会从IP数据报头部里提取出目标地址，并将封包正确地路由到下一个目的地。IP数据报头部time to live (TTL)域的值每经过一个路由器就减1，如果封包的TTL变为0，或者路由器由于网络拥堵等原因封包队列满了，那么这个包会被路由器丢弃。</p><p>上面的发送和接受过程在 TCP 连接期间会发生很多次：</p><ul><li><p>客户端选择一个初始序列号(ISN)，将设置了 SYN 位的封包发送给服务器端，表明自己要建立连接并设置了初始序列号</p></li><li><p>服务器端接收到 SYN 包，如果它可以建立连接：<br>- 服务器端选择它自己的初始序列号<br>- 服务器端设置 SYN 位，表明自己选择了一个初始序列号<br>- 服务器端把 (客户端ISN + 1) 复制到 ACK 域，并且设置 ACK 位，表明自己接收到了客户端的第一个封包</p></li><li><p>客户端通过发送下面一个封包来确认这次连接：<br>- 自己的序列号+1<br>- 接收端 ACK+1<br>- 设置 ACK 位</p></li><li><p>数据通过下面的方式传输：<br>- 当一方发送了N个 Bytes 的数据之后，将自己的 SEQ 序列号也增加N<br>- 另一方确认接收到这个数据包（或者一系列数据包）之后，它发送一个 ACK包，ACK的值设置为接收到的数据包的最后一个序列号</p></li><li><p>关闭连接时：<br>- 要关闭连接的一方发送一个 FIN 包<br>- 另一方确认这个 FIN 包，并且发送自己的 FIN 包<br>- 要关闭的一方使用 ACK 包来确认接收到了 FIN</p></li></ul><h2 id="TLS-握手">TLS 握手</h2><ul><li>客户端发送一个 <code>ClientHello</code> 消息到服务器端，消息中同时包含了它的Transport Layer Security (TLS) 版本，可用的加密算法和压缩算法。</li><li>服务器端向客户端返回一个 <code>ServerHello</code>消息，消息中包含了服务器端的TLS版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（Certificate Authority，缩写CA）签发的服务器公开证书，证书中包含了公钥。客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥</li><li>客户端根据自己的信任CA列表，验证服务器端的证书是否可信。如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它。这串随机数会被用于生成新的对称密钥</li><li>服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥</li><li>客户端发送一个 <code>Finished</code>消息给服务器端，使用对称密钥加密这次通讯的一个散列值</li><li>服务器端生成自己的 hash 值，然后解密客户端发送来的信息，检查这两个值是否对应。如果对应，就向客户端发送一个<code>Finished</code> 消息，也使用协商好的对称密钥加密</li><li>从现在开始，接下来整个 TLS 会话都使用对称秘钥进行加密，传输应用层（HTTP）内容</li></ul><h2 id="HTTP-协议">HTTP 协议</h2><p>如果浏览器是 Google 出品的，它不会使用 HTTP 协议来获取页面信息，而是会与服务器端发送请求，商讨使用 SPDY 协议。</p><p>如果浏览器使用 HTTP 协议而不支持 SPDY 协议，它会向服务器发送这样的一个请求:</p><pre><code>GET / HTTP/1.1
Host: google.com
Connection: close
[其他头部]
</code></pre><p>“其他头部”包含了一系列的由冒号分割开的键值对，它们的格式符合HTTP协议标准，它们之间由一个换行符分割开来。（这里我们假设浏览器没有违反HTTP协议标准的bug，同时假设浏览器使用<code>HTTP/1.1</code> 协议，不然的话头部可能不包含 <code>Host</code> 字段，同时 <code>GET</code>请求中的版本号会变成 <code>HTTP/1.0</code> 或者 <code>HTTP/0.9</code> 。）</p><p>HTTP/1.1 定义了“关闭连接”的选项&quot;close&quot;，发送者使用这个选项指示这次连接在响应结束之后会断开。例如：</p><blockquote><p>Connection:close</p></blockquote><p>不支持持久连接的 HTTP/1.1 应用必须在每条消息中都包含 “close” 选项。</p><p>在发送完这些请求和头部之后，浏览器发送一个换行符，表示要发送的内容已经结束了。</p><p>服务器端返回一个响应码，指示这次请求的状态，响应的形式是这样的:</p><pre><code>200 OK
[响应头部]
</code></pre><p>然后是一个换行，接下来有效载荷(payload)，也就是 <code>www.google.com</code>的HTML内容。服务器下面可能会关闭连接，如果客户端请求保持连接的话，服务器端会保持连接打开，以供之后的请求重用。</p><p>如果浏览器发送的HTTP头部包含了足够多的信息（例如包含了 Etag 头部），以至于服务器可以判断出，浏览器缓存的文件版本自从上次获取之后没有再更改过，服务器可能会返回这样的响应:</p><pre><code>304 Not Modified
[响应头部]
</code></pre><p>这个响应没有有效载荷，浏览器会从自己的缓存中取出想要的内容。</p><p>在解析完 HTML之后，浏览器和客户端会重复上面的过程，直到HTML页面引入的所有资源（图片，CSS，favicon.ico等等）全部都获取完毕，区别只是头部的<code>GET / HTTP/1.1</code> 会变成 <code>GET /$(相对www.google.com的URL) HTTP/1.1</code> 。</p><p>如果HTML引入了 <code>www.google.com</code>域名之外的资源，浏览器会回到上面解析域名那一步，按照下面的步骤往下一步一步执行，请求中的<code>Host</code> 头部会变成另外的域名。</p><h2 id="HTTP-服务器请求处理">HTTP 服务器请求处理</h2><p>HTTPD(HTTP Daemon)在服务器端处理请求/响应。最常见的 HTTPD 有 Linux上常用的 Apache 和 nginx，以及 Windows 上的 IIS。</p><ul><li><p>HTTPD 接收请求</p></li><li><p>服务器把请求拆分为以下几个参数：<br>- HTTP 请求方法(<code>GET</code>, <code>POST</code>, <code>HEAD</code>, <code>PUT</code>, <code>DELETE</code>,<br><code>CONNECT</code>, <code>OPTIONS</code>, 或者 <code>TRACE</code>)。直接在地址栏中输入 URL<br>这种情况下，使用的是 GET 方法<br>- 域名：<a href="http://google.com" target="_blank" rel="noopener">google.com</a><br>- 请求路径/页面：/ (我们没有请求google.com下的指定的页面，因此<br>/ 是默认的路径)</p></li><li><p>服务器验证其上已经配置了 <a href="http://google.com" target="_blank" rel="noopener">google.com</a> 的虚拟主机</p></li><li><p>服务器验证 <a href="http://google.com" target="_blank" rel="noopener">google.com</a> 接受 GET 方法</p></li><li><p>服务器验证该用户可以使用 GET 方法(根据 IP 地址，身份信息等)</p></li><li><p>如果服务器安装了 URL 重写模块（例如 Apache 的 mod_rewrite 和 IIS 的URL Rewrite），服务器会尝试匹配重写规则，如果匹配上的话，服务器会按照规则重写这个请求</p></li><li><p>服务器根据请求信息获取相应的响应内容，这种情况下由于访问路径是 “/”,会访问首页文件（你可以重写这个规则，但是这个是最常用的）。</p></li><li><p>服务器会使用指定的处理程序分析处理这个文件，假如 Google 使用PHP，服务器会使用 PHP 解析 index文件，并捕获输出，把 PHP的输出结果返回给请求者</p></li></ul><h2 id="浏览器背后的故事">浏览器背后的故事</h2><p>当服务器提供了资源之后（HTML，CSS，JS，图片等），浏览器会执行下面的操作：</p><ul><li>解析 —— HTML，CSS，JS</li><li>渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制</li></ul><h2 id="浏览器">浏览器</h2><p>浏览器的功能是从服务器上取回你想要的资源，然后展示在浏览器窗口当中。资源通常是HTML 文件，也可能是<br>PDF，图片，或者其他类型的内容。资源的位置通过用户提供的 URI(Uniform Resource Identifier) 来确定。</p><p>浏览器解释和展示 HTML 文件的方法，在 HTML 和 CSS的标准中有详细介绍。这些标准由 Web 标准组织 W3C(World Wide Web Consortium) 维护。</p><p>不同浏览器的用户界面大都十分接近，有很多共同的 UI 元素：</p><ul><li>一个地址栏</li><li>后退和前进按钮</li><li>书签选项</li><li>刷新和停止按钮</li><li>主页按钮</li></ul><p><strong>浏览器高层架构</strong></p><p>组成浏览器的组件有：</p><ul><li><strong>用户界面</strong> 用户界面包含了地址栏，前进后退按钮，书签菜单等等，除了请求页面之外所有你看到的内容都是用户界面的一部分</li><li><strong>浏览器引擎</strong> 浏览器引擎负责让 UI 和渲染引擎协调工作</li><li><strong>渲染引擎</strong> 渲染引擎负责展示请求内容。如果请求的内容是HTML，渲染引擎会解析 HTML 和 CSS，然后将内容展示在屏幕上</li><li><strong>网络组件</strong> 网络组件负责网络调用，例如 HTTP请求等，使用一个平台无关接口，下层是针对不同平台的具体实现</li><li><strong>UI后端</strong> UI 后端用于绘制基本 UI 组件，例如下拉列表框和窗口。UI后端暴露一个统一的平台无关的接口，下层使用操作系统的 UI 方法实现</li><li><strong>Javascript 引擎</strong> Javascript 引擎用于解析和执行 Javascript 代码</li><li><strong>数据存储</strong> 数据存储组件是一个持久层。浏览器可能需要在本地存储各种各样的数据，例如Cookie 等。浏览器也需要支持诸如 localStorage，IndexedDB，WebSQL 和 FileSystem 之类的存储机制</li></ul><h2 id="HTML-解析">HTML 解析</h2><p>浏览器渲染引擎从网络层取得请求的文档，一般情况下文档会分成8kB大小的分块传输。</p><p>HTML 解析器的主要工作是对 HTML 文档进行解析，生成解析树。</p><p>解析树是以 DOM 元素以及属性为节点的树。DOM是文档对象模型(Document Object Model)的缩写，它是 HTML 文档的对象表示，同时也是 HTML 元素面向外部(如Javascript)的接口。树的根部是&quot;Document&quot;对象。整个 DOM 和HTML 文档几乎是一对一的关系。</p><p><strong>解析算法</strong></p><p>HTML不能使用常见的自顶向下或自底向上方法来进行分析。主要原因有以下几点:</p><ul><li>语言本身的“宽容”特性</li><li>HTML本身可能是残缺的，对于常见的残缺，浏览器需要有传统的容错机制来支持它们</li><li>解析过程需要反复。对于其他语言来说，源码不会在解析过程中发生变化，但是对于HTML 来说，动态代码，例如脚本元素中包含的 document.write()方法会在源码中添加内容，也就是说，解析过程实际上会改变输入的内容</li></ul><p>由于不能使用常用的解析技术，浏览器创造了专门用于解析 HTML的解析器。解析算法在 HTML5标准规范中有详细介绍，算法主要包含了两个阶段：标记化（tokenization）和树的构建。</p><p><strong>解析结束之后</strong></p><p>浏览器开始加载网页的外部资源（CSS，图像，Javascript 文件等）。</p><p>此时浏览器把文档标记为可交互的（interactive），浏览器开始解析处于“推迟（deferred）”模式的脚本，也就是那些需要在文档解析完毕之后再执行的脚本。之后文档的状态会变为“完成（complete）”，浏览器会触发“加载（load）”事件。</p><p>注意解析 HTML 网页时永远不会出现“无效语法（Invalid Syntax）”错误，浏览器会修复所有错误内容，然后继续解析。</p><h2 id="CSS-解析">CSS 解析</h2><ul><li>根据 <a href="http://www.w3.org/TR/CSS2/grammar.html" target="_blank" rel="noopener">CSS词法和句法</a>分析CSS文件和 <code>&lt;style&gt;</code> 标签包含的内容以及 style 属性的值</li><li>每个CSS文件都被解析成一个样式表对象（<code>StyleSheet object</code>），这个对象里包含了带有选择器的CSS规则，和对应CSS语法的对象</li><li>CSS解析器可能是自顶向下的，也可能是使用解析器生成器生成的自底向上的解析器</li></ul><h2 id="页面渲染">页面渲染</h2><ul><li>通过遍历DOM节点树创建一个“Frame树”或“渲染树”，并计算每个节点的各个CSS样式值</li><li>通过累加子节点的宽度，该节点的水平内边距(padding)、边框(border)和外边距(margin)，自底向上的计算&quot;Frame树&quot;中每个节点的首选(preferred)宽度</li><li>通过自顶向下的给每个节点的子节点分配可行宽度，计算每个节点的实际宽度</li><li>通过应用文字折行、累加子节点的高度和此节点的内边距(padding)、边框(border)和外边距(margin)，自底向上的计算每个节点的高度</li><li>使用上面的计算结果构建每个节点的坐标</li><li>当存在元素使用 <code>floated</code>，位置有 <code>absolutely</code> 或 <code>relatively</code> 属性的时候，会有更多复杂的计算，详见<a href="http://dev.w3.org/csswg/css2/" target="_blank" rel="noopener">http://dev.w3.org/csswg/css2/</a> 和 <a href="http://www.w3.org/Style/CSS/current-work" target="_blank" rel="noopener">http://www.w3.org/Style/CSS/current-work</a></li><li>创建layer(层)来表示页面中的哪些部分可以成组的被绘制，而不用被重新栅格化处理。每个帧对象都被分配给一个层</li><li>页面上的每个层都被分配了纹理(?)</li><li>每个层的帧对象都会被遍历，计算机执行绘图命令绘制各个层，此过程可能由CPU执行栅格化处理，或者直接通过D2D/SkiaGL在GPU上绘制</li><li>上面所有步骤都可能利用到最近一次页面渲染时计算出来的各个值，这样可以减少不少计算量</li><li>计算出各个层的最终位置，一组命令由Direct3D/OpenGL发出，GPU命令缓冲区清空，命令传至GPU并异步渲染，帧被送到Window Server。</li></ul><h2 id="GPU-渲染">GPU 渲染</h2><ul><li>在渲染过程中，图形处理层可能使用通用用途的<code>CPU</code>，也可能使用图形处理器 <code>GPU</code></li><li>当使用 <code>GPU</code>用于图形渲染时，图形驱动软件会把任务分成多个部分，这样可以充分利用<code>GPU</code> 强大的并行计算能力，用于在渲染过程中进行大量的浮点计算。</li></ul><h2 id="Window-Server">Window Server</h2><h2 id="后期渲染与用户引发的处理">后期渲染与用户引发的处理</h2><p>渲染结束后，浏览器根据某些时间机制运行JavaScript代码(比如Google Doodle动画)或与用户交互(在搜索栏输入关键字获得搜索建议)。类似Flash和Java的插件也会运行，尽管Google主页里没有。这些脚本可以触发网络请求，也可能改变网页的内容和布局，产生又一轮渲染与绘制。</p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Network</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Volatile的内存语义与AQS锁内存可见性</title>
    <url>/java-volatile-aqs.html</url>
    <content><![CDATA[<p>提到volatile首先想到就是：</p><ul><li>保证此变量对所有线程的可见性，这里的 “可见性”是指当一个线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。</li><li>禁止指令重排序优化。</li></ul><p>到这里大家感觉自己对volatile理解了吗？</p><p>如果理解了，大家考虑这么一个问题：ReentrantLock（或者其它基于AQS实现的锁）是如何保证代码段中变量（变量主要是指共享变量，存在竞争问题的变量）的可见性？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static ReentrantLock reentrantLock = new ReentrantLock();</span><br><span class="line">private static int count = 0;</span><br><span class="line">//...</span><br><span class="line">// 多线程 run 如下代码</span><br><span class="line">reentrantLock.lock();</span><br><span class="line">try</span><br><span class="line">&#123;</span><br><span class="line">    count++;</span><br><span class="line">&#125; </span><br><span class="line">finally</span><br><span class="line">&#123;</span><br><span class="line">    reentrantLock.unlock();</span><br><span class="line">&#125;</span><br><span class="line">//...</span><br></pre></td></tr></table></figure><p>既然提到了可见性，那就先熟悉几个概念：</p><h1>JMM</h1><p>JMM：Java Memory Model 即 Java 内存模型</p><blockquote><p>The Java Memory Model describes what behaviors are legal in multithreaded code, and how threads may interact through memory.</p></blockquote><blockquote><p>It describes the relationship between variables in a program and the low-level details of storing and retrieving them to and from memory or registers in a real computer system.</p></blockquote><blockquote><p>It does this in a way that can be implemented correctly using a wide variety of hardware and a wide variety of compiler optimizations.</p></blockquote><p><font color="DeepPink"><strong>Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。</strong></font>此处的变量主要是指共享变量，存在竞争问题的变量。Java内存模型规定所有的变量都存储在主内存中，而每个线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（<font color="DeepPink"><strong>根据Java虚拟机规范的规定，volatile变量依然有共享内存的拷贝，但是由于它特殊的操作顺序性规定——从工作内存中读写数据前，必须先将主内存中的数据同步到工作内存中，所有看起来如同直接在主内存中读写访问一般，因此这里的描述对于volatile也不例外</strong></font>）。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值得传递均需要通过主内存来完成。</p><h1>重排序</h1><p>在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：</p><ul><li>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</li><li>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li><li>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</li></ul><p>从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序：</p><p><img data-src="/images/java-aqs-voliate/%E9%87%8D%E6%8E%92%E5%BA%8F.png" alt></p><p>对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。</p><p>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。</p><h1>happens-before</h1><ul><li>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</li><li>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</li><li>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。（对一个volatile变量的读，总是能看到【任意线程】对这个volatile变量最后的写入）</li><li>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</li></ul><blockquote><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。</p></blockquote><h1>内存屏障</h1><ul><li>硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。</li><li><font color="DeepPink"><strong>对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；</strong></font></li><li><font color="DeepPink"><strong>对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。</strong></font></li><li>内存屏障有两个作用：<ul><li>阻止屏障两侧的指令重排序；</li><li>强制把写缓冲区/高速缓存中的数据等写回主内存，让缓存中相应的数据失效。</li></ul></li></ul><h1>volatile的内存语义</h1><p>从JSR-133开始（即从JDK5开始），volatile变量的写-读可以实现线程之间的通信。</p><p><font color="DeepPink"><strong>从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果</strong></font>：</p><ul><li>volatile写和锁的释放有相同的内存语义；</li><li>volatile读与锁的获取有相同的内存语义。</li></ul><blockquote><p>volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。</p></blockquote><p>volatile变量自身具有下列特性：</p><ul><li>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</li><li>原子性：对任意单个volatile变量的读/写具有原子性，即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读/写就具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。</li></ul><p>volatile写和volatile读的内存语义：</p><ul><li><font color="DeepPink"><strong>线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。</strong></font></li><li><font color="DeepPink"><strong>线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。</strong></font></li><li><font color="DeepPink"><strong>线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。</strong></font></li></ul><p>JMM针对编译器制定的volatile重排序规则表</p><p><img data-src="/images/java-aqs-voliate/JMM%E9%92%88%E5%AF%B9%E7%BC%96%E8%AF%91%E5%99%A8%E5%88%B6%E5%AE%9A%E7%9A%84volatile%E9%87%8D%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99%E8%A1%A8.png" alt></p><ul><li><font color="DeepPink"><strong>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</strong></font></li><li><font color="DeepPink"><strong>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</strong></font></li><li><font color="DeepPink"><strong>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</strong></font></li></ul><p>为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。<strong>对于编译器来说，发现一个最优布置来最小化插入屏障几乎是不可能的。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。</strong></p><ul><li>在每个volatile写操作的前面插入一个StoreStore屏障。</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadStore屏障。</li></ul><blockquote><p>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</p></blockquote><blockquote><p>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</p></blockquote><blockquote><p>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。<br>上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。</p></blockquote><p>下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图.</p><p><img data-src="/images/java-aqs-voliate/volatile%E5%86%99%E6%8F%92%E5%85%A5%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%90%8E%E7%94%9F%E6%88%90%E7%9A%84%E6%8C%87%E4%BB%A4%E5%BA%8F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><p>图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为<strong>StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。</strong></p><p>这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。</p><p>下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图:<br><img data-src="/images/java-aqs-voliate/volatile%E8%AF%BB%E6%8F%92%E5%85%A5%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%90%8E%E7%94%9F%E6%88%90%E7%9A%84%E6%8C%87%E4%BB%A4%E5%BA%8F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt><br>图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。</p><p>上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。</p><h1>AQS</h1><p>对于AQS需要了解这么几点：</p><ul><li>锁的状态通过volatile int state来表示。</li><li>获取不到锁的线程会进入AQS的队列等待。</li><li>子类需要重写tryAcquire、tryRelease等方法。</li></ul><p>AQS 详解参见：<a href="https://jiankunking.com/java-aqs.html">面试必备：Java AQS 实现原理（图文）分析</a></p><h1>ReentrantLock</h1><p>以公平锁为例，看看 ReentrantLock 获取锁 &amp; 释放锁的关键代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The synchronization state.</span><br><span class="line"> */</span><br><span class="line">private volatile int state;</span><br><span class="line">/**</span><br><span class="line"> * Returns the current value of synchronization state.</span><br><span class="line"> * This operation has memory semantics of a &#123;@code volatile&#125; read.</span><br><span class="line"> * @return current state value</span><br><span class="line"> */</span><br><span class="line">protected final int getState() &#123;</span><br><span class="line">    return state;</span><br><span class="line">&#125;</span><br><span class="line">// 释放锁</span><br><span class="line">protected final boolean tryRelease(int releases) &#123;</span><br><span class="line">    int c = getState() - releases;</span><br><span class="line">    if (Thread.currentThread() != getExclusiveOwnerThread())</span><br><span class="line">        throw new IllegalMonitorStateException();</span><br><span class="line">    boolean free = false;</span><br><span class="line">    if (c == 0) &#123;</span><br><span class="line">        free = true;</span><br><span class="line">        setExclusiveOwnerThread(null);</span><br><span class="line">    &#125;</span><br><span class="line">    setState(c);// 释放锁的最后，写volatile变量state</span><br><span class="line">    return free;</span><br><span class="line">&#125;</span><br><span class="line">// 获取锁</span><br><span class="line">protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">    final Thread current = Thread.currentThread();</span><br><span class="line">    int c = getState();// 获取锁的开始，首先读volatile变量state</span><br><span class="line">    if (c == 0) &#123;</span><br><span class="line">        if (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">            compareAndSetState(0, acquires)) &#123;</span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        int nextc = c + acquires;</span><br><span class="line">        if (nextc &lt; 0)</span><br><span class="line">            throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>通过ReentrantLock实例调用lock()、unlock()时，acquires、releases的值都是1。</p></blockquote><p><font color="DeepPink"><strong>公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。从而保证了代码段中变量（变量主要是指共享变量，存在竞争问题的变量）的可见性。</strong></font></p><h1>小结</h1><p>如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。</p><ul><li>首先，<font color="DeepPink"><strong>声明共享变量为volatile。</strong></font></li><li>然后，<font color="DeepPink"><strong>使用CAS的原子条件更新来实现线程之间的同步。</strong></font></li><li>同时，<font color="DeepPink"><strong>配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。</strong></font></li></ul><blockquote><p>前文我们提到过，编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。</p></blockquote><p>推荐阅读：</p><p><a href="https://jiankunking.com/java-volatile-keyword.html">https://jiankunking.com/java-volatile-keyword.html</a></p><p>本文参考：</p><p>1、《Java并发编程的艺术》 方腾飞　魏鹏　程晓明　著</p><p>2、<a href="https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247485795&amp;idx=2&amp;sn=73d5bcd83378f6176f9593d33dc402dc&amp;chksm=eb538c55dc240543df3cd113cb3e586e98d3ccd0a93c6a87829a04e296b990a554596338046e#rd" target="_blank" rel="noopener">Java 可重入锁内存可见性分析</a></p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
        <tag>Volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Lambda表达式 实现原理分析</title>
    <url>/java-lambda.html</url>
    <content><![CDATA[<blockquote><p>本文分析基于JDK 9</p></blockquote><a id="more"></a><h1>一、目标</h1><p>本文主要解决两个问题：</p><p>1、函数式接口 到底是什么？</p><p>2、Lambda表达式是怎么实现的？</p><p>先介绍一个jdk的bin目录下的一个字节码查看工具及反编译工具：javap</p><p><img data-src="/images/java-lambda/javap.png" alt></p><h1>二、函数式接口</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过javap 反编译IFunctionTest.class 可以看到如下信息:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt;javap -p IFunctionTest.class</span><br><span class="line">Compiled from &quot;FunctionTest.java&quot;</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">  public abstract void print(T);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到函数式接口编译完之后依然是一个接口，这个接口具有唯一的一个抽像方法。</p><p>为什么说需要是唯一一个抽象方法？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">    public void print22(T x,int rr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="/images/java-lambda/javac-FunctionTest.png" alt></p><p>虽然不能在函数式接口中定义多个方法，但可以定义默认方法、静态方法、定义java.lang.Object里的public方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">    default void doSomeMoreWork1()&#123;</span><br><span class="line">        // Method body</span><br><span class="line">    &#125;</span><br><span class="line">    static void printHello()&#123;</span><br><span class="line">        System.out.println(&quot;Hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    boolean equals(Object obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>反编译文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt;javap -p IFunctionTest.class</span><br><span class="line">Compiled from &quot;FunctionTest.java&quot;</span><br><span class="line">interface IFunctionTest&lt;T&gt; &#123;</span><br><span class="line">  public abstract void print(T);</span><br><span class="line">  public void doSomeMoreWork1();</span><br><span class="line">  public static void printHello();</span><br><span class="line">  public abstract boolean equals(java.lang.Object);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1>三、Lambda</h1><h2 id="3-1-示例代码">3.1 示例代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void printString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        printString(&quot;test&quot;, (x) -&gt; System.out.println(x));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过javac编译LambdaTest.java文件，会生成LambdaTest.class、Print.class两个class文件。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">javac LambdaTest.java</span><br></pre></td></tr></table></figure><p><img data-src="/images/java-lambda/javac-LambdaTest.png" alt></p><h2 id="3-2-对于lambda实现的猜测">3.2 对于lambda实现的猜测</h2><p>那么编译器对Lambda 都做了什么？反编译一下代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\Code\Java\study&gt;javap -p LambdaTest.class</span><br><span class="line">Compiled from &quot;LambdaTest.java&quot;</span><br><span class="line">public class LambdaTest &#123;</span><br><span class="line">  public LambdaTest();</span><br><span class="line">  public static void printString(java.lang.String, Print&lt;java.lang.String&gt;);</span><br><span class="line">  public static void main(java.lang.String[]);</span><br><span class="line">  private static void lambda$main$0(java.lang.String);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由上面的代码可以看出编译器会根据Lambda表达式生成一个私有的静态函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static void lambda$main$0(java.lang.String);</span><br></pre></td></tr></table></figure><p>为了验证上面的转化是否正确? 我们在代码中定义一个lambda$main$0这个的函数，最终代码如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void printString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        printString(&quot;test&quot;, (x) -&gt; System.out.println(x));</span><br><span class="line">    &#125;</span><br><span class="line">    private static void lambda$main$0(String s) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码在编译时会报错，错误信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\Code\Java\study&gt;javac LambdaTest.java</span><br><span class="line">LambdaTest.java:8: 错误: 符号lambda$main$0(String)与LambdaTest中的 compiler-synt</span><br><span class="line">hesized 符号冲突</span><br><span class="line">    private static void lambda$main$0(String s) &#123;</span><br><span class="line">                        ^</span><br><span class="line">LambdaTest.java:1: 错误: 符号lambda$main$0(String)与LambdaTest中的 compiler-synt</span><br><span class="line">hesized 符号冲突</span><br><span class="line">public class LambdaTest &#123;</span><br><span class="line">^</span><br><span class="line">2 个错误</span><br></pre></td></tr></table></figure><p>有了上面的内容，可以知道的是Lambda表达式在Java 9中首先会生成一个私有的静态函数，这个私有的静态函数干的就是Lambda表达式里面的内容，那么又是如何调用的生成的私有静态函数（lambda$main$0(String s)）呢？</p><h2 id="3-3-反编译代码详解">3.3 反编译代码详解</h2><p>查看更加详细的反编译结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$C:\Users\Code\Java\study&gt; javap -p -v -c LambdaTest.class</span><br><span class="line">Classfile /C:/Users/Code/Java/study/LambdaTest.class</span><br><span class="line">  Last modified 2018-4-5; size 1184 bytes</span><br><span class="line">  MD5 checksum b144b5a936a04a7c975eae93c7370174</span><br><span class="line">  Compiled from &quot;LambdaTest.java&quot;</span><br><span class="line">public class LambdaTest</span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 52</span><br><span class="line">  flags: ACC_PUBLIC, ACC_SUPER</span><br><span class="line">Constant pool:</span><br><span class="line">   #1 = Methodref          #9.#24         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">   #2 = InterfaceMethodref #25.#26        // Print.print:(Ljava/lang/Object;)V</span><br><span class="line">   #3 = String             #27            // test</span><br><span class="line">   #4 = InvokeDynamic      #0:#33         // #0:print:()LPrint;</span><br><span class="line">   #5 = Methodref          #8.#34         // LambdaTest.printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">   #6 = Fieldref           #35.#36        // java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">   #7 = Methodref          #37.#38        // java/io/PrintStream.println:(Ljava/lang/String;)V</span><br><span class="line">   #8 = Class              #39            // LambdaTest</span><br><span class="line">   #9 = Class              #40            // java/lang/Object</span><br><span class="line">  #10 = Utf8               &lt;init&gt;</span><br><span class="line">  #11 = Utf8               ()V</span><br><span class="line">  #12 = Utf8               Code</span><br><span class="line">  #13 = Utf8               LineNumberTable</span><br><span class="line">  #14 = Utf8               printString</span><br><span class="line">  #15 = Utf8               (Ljava/lang/String;LPrint;)V</span><br><span class="line">  #16 = Utf8               Signature</span><br><span class="line">  #17 = Utf8               (Ljava/lang/String;LPrint&lt;Ljava/lang/String;&gt;;)V</span><br><span class="line">  #18 = Utf8               main</span><br><span class="line">  #19 = Utf8               ([Ljava/lang/String;)V</span><br><span class="line">  #20 = Utf8               lambda$main$0</span><br><span class="line">  #21 = Utf8               (Ljava/lang/String;)V</span><br><span class="line">  #22 = Utf8               SourceFile</span><br><span class="line">  #23 = Utf8               LambdaTest.java</span><br><span class="line">  #24 = NameAndType        #10:#11        // &quot;&lt;init&gt;&quot;:()V</span><br><span class="line">  #25 = Class              #41            // Print</span><br><span class="line">  #26 = NameAndType        #42:#43        // print:(Ljava/lang/Object;)V</span><br><span class="line">  #27 = Utf8               test</span><br><span class="line">  #28 = Utf8               BootstrapMethods</span><br><span class="line">  #29 = MethodHandle       #6:#44         // invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #30 = MethodType         #43            //  (Ljava/lang/Object;)V</span><br><span class="line">  #31 = MethodHandle       #6:#45         // invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">  #32 = MethodType         #21            //  (Ljava/lang/String;)V</span><br><span class="line">  #33 = NameAndType        #42:#46        // print:()LPrint;</span><br><span class="line">  #34 = NameAndType        #14:#15        // printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">  #35 = Class              #47            // java/lang/System</span><br><span class="line">  #36 = NameAndType        #48:#49        // out:Ljava/io/PrintStream;</span><br><span class="line">  #37 = Class              #50            // java/io/PrintStream</span><br><span class="line">  #38 = NameAndType        #51:#21        // println:(Ljava/lang/String;)V</span><br><span class="line">  #39 = Utf8               LambdaTest</span><br><span class="line">  #40 = Utf8               java/lang/Object</span><br><span class="line">  #41 = Utf8               Print</span><br><span class="line">  #42 = Utf8               print</span><br><span class="line">  #43 = Utf8               (Ljava/lang/Object;)V</span><br><span class="line">  #44 = Methodref          #52.#53        // java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #45 = Methodref          #8.#54         // LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">  #46 = Utf8               ()LPrint;</span><br><span class="line">  #47 = Utf8               java/lang/System</span><br><span class="line">  #48 = Utf8               out</span><br><span class="line">  #49 = Utf8               Ljava/io/PrintStream;</span><br><span class="line">  #50 = Utf8               java/io/PrintStream</span><br><span class="line">  #51 = Utf8               println</span><br><span class="line">  #52 = Class              #55            // java/lang/invoke/LambdaMetafactory</span><br><span class="line">  #53 = NameAndType        #56:#60        // metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #54 = NameAndType        #20:#21        // lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line"></span><br><span class="line">  #55 = Utf8               java/lang/invoke/LambdaMetafactory</span><br><span class="line">  #56 = Utf8               metafactory</span><br><span class="line">  #57 = Class              #62            // java/lang/invoke/MethodHandles$Lookup</span><br><span class="line">  #58 = Utf8               Lookup</span><br><span class="line">  #59 = Utf8               InnerClasses</span><br><span class="line">  #60 = Utf8               (Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  #61 = Class              #63            // java/lang/invoke/MethodHandles</span><br><span class="line">  #62 = Utf8               java/lang/invoke/MethodHandles$Lookup</span><br><span class="line">  #63 = Utf8               java/lang/invoke/MethodHandles</span><br><span class="line">&#123;</span><br><span class="line">  public LambdaTest();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=1, args_size=1</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">         4: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 1: 0</span><br><span class="line"></span><br><span class="line">  public static void printString(java.lang.String, Print&lt;java.lang.String&gt;);</span><br><span class="line">    descriptor: (Ljava/lang/String;LPrint;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=2, args_size=2</span><br><span class="line">         0: aload_1</span><br><span class="line">         1: aload_0</span><br><span class="line">         2: invokeinterface #2,  2            // InterfaceMethod Print.print:(Ljava/lang/Object;)V</span><br><span class="line">         7: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 3: 0</span><br><span class="line">        line 4: 7</span><br><span class="line">    Signature: #17                          // (Ljava/lang/String;LPrint&lt;Ljava/lang/String;&gt;;)V</span><br><span class="line"></span><br><span class="line">  public static void main(java.lang.String[]);</span><br><span class="line">    descriptor: ([Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: ldc           #3                  // String test</span><br><span class="line">         2: invokedynamic #4,  0              // InvokeDynamic #0:print:()LPrint;</span><br><span class="line">         7: invokestatic  #5                  // Method printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">        10: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 6: 0</span><br><span class="line">        line 7: 10</span><br><span class="line"></span><br><span class="line">  private static void lambda$main$0(java.lang.String);</span><br><span class="line">    descriptor: (Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PRIVATE, ACC_STATIC, ACC_SYNTHETIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: getstatic     #6                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">         3: aload_0</span><br><span class="line">         4: invokevirtual #7                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V</span><br><span class="line">         7: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 6: 0</span><br><span class="line">&#125;</span><br><span class="line">SourceFile: &quot;LambdaTest.java&quot;</span><br><span class="line">InnerClasses:</span><br><span class="line">     public static final #58= #57 of #61; //Lookup=class java/lang/invoke/MethodHandles$Lookup of class java/lang/invoke/MethodHandles</span><br><span class="line">BootstrapMethods:</span><br><span class="line">  0: #29 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;Method arguments:</span><br><span class="line">      #30 (Ljava/lang/Object;)V</span><br><span class="line">      #31 invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">      #32 (Ljava/lang/String;)V</span><br></pre></td></tr></table></figure><p>这个 class 文件展示了三个主要部分：常量池、构造器方法和 printString、main、lambdamainmain0方法还有lambda表达式生成的内部类。</p><h3 id="3-3-1-动态链接">3.3.1 动态链接</h3><p>每个栈帧都有一个运行时常量池的引用。这个引用指向栈帧当前运行方法所在类的常量池。通过这个引用支持动态链接（dynamic linking）。</p><p>C/C++ 代码一般被编译成对象文件，然后多个对象文件被链接到一起产生可执行文件或者 dll。在链接阶段，每个对象文件的符号引用被替换成了最终执行文件的相对偏移内存地址。在 Java中，链接阶段是运行时动态完成的。</p><p><font color="DeepPink"><strong>当 Java 类文件编译时，所有变量和方法的引用都被当做符号引用存储在这个类的常量池中。符号引用是一个逻辑引用，实际上并不指向物理内存地址。JVM 可以选择符号引用解析的时机，一种是当类文件加载并校验通过后，这种解析方式被称为饥饿方式。另外一种是符号引用在第一次使用的时候被解析，这种解析方式称为惰性方式。无论如何 ，JVM 必须要在第一次使用符号引用时完成解析并抛出可能发生的解析错误。绑定是将对象域、方法、类的符号引用替换为直接引用的过程。绑定只会发生一次。一旦绑定，符号引用会被完全替换。如果一个类的符号引用还没有被解析，那么就会载入这个类。每个直接引用都被存储为相对于存储结构（与运行时变量或方法的位置相关联的）偏移量。</strong></font></p><h3 id="3-3-2-常量池">3.3.2 常量池</h3><p>JVM 维护了一个按类型区分的常量池，一个类似于符号表的运行时数据结构。尽管它包含更多数据。Java 字节码需要数据。这个数据经常因为太大不能直接存储在字节码中，取而代之的是存储在常量池中，字节码包含这个常量池的引用。</p><p>常量池中可以存储多种类型的数据：</p><ul><li>数字型</li><li>字符串型</li><li>类引用型</li><li>域引用型</li><li>方法引用</li></ul><h3 id="3-3-3-方法">3.3.3 方法</h3><p>每一个方法包含四个区域：</p><ul><li>签名和访问标签</li><li>字节码</li><li>LineNumberTable：为调试器提供源码中的每一行对应的字节码信息</li><li>LocalVariableTable：列出了所有栈帧中的局部变量</li></ul><table><thead><tr><th>操作码</th><th>作用</th></tr></thead><tbody><tr><td>aload0</td><td>这个操作码是aload格式操作码中的一个。它们用来把对象引用加载到操作码栈。表示正在被访问的局部变量数组的位置，但只能是0、1、2、3 中的一个。还有一些其它类似的操作码用来载入非对象引用的数据，如iload, lload, float 和 dload。其中 i 表示 int，l 表示 long，f 表示 float，d 表示 double。局部变量数组位置大于 3 的局部变量可以用 iload, lload, float, dload 和 aload 载入。这些操作码都只需要一个操作数，即数组中的位置。</td></tr><tr><td>ldc</td><td>这个操作码用来将常量从运行时常量池压栈到操作数栈。</td></tr><tr><td>getstatic</td><td>这个操作码用来把一个静态变量从运行时常量池的静态变量列表中压栈到操作数栈。</td></tr><tr><td>return</td><td>这个操作码属于ireturn、lreturn、freturn、dreturn、areturn 和 return 操作码组。每个操作码返回一种类型的返回值，其中 i 表示 int，l 表示 long，f 表示 float，d 表示 double，a 表示 对象引用。没有前缀类型字母的 return 表示返回 void。</td></tr></tbody></table><table><thead><tr><th>函数调用操作码</th><th>作用</th></tr></thead><tbody><tr><td>invokestatic</td><td>调用类方法（静态绑定，速度快）</td></tr><tr><td>invokevirtual</td><td>指令调用一个对象的实例方法（动态绑定）</td></tr><tr><td>invokespecial</td><td>指令调用实例初始化方法、私有方法、父类方法。（静态绑定，速度快）</td></tr><tr><td>invokeinterface</td><td>调用引用类型为interface的实例方法（动态绑定）</td></tr><tr><td>invokedynamic</td><td>JDK 7引入的，主要是为了支持动态语言的方法调用</td></tr></tbody></table><h3 id="3-3-4-代码分析">3.3.4 代码分析</h3><p>注意反编译后main方法部分：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main(java.lang.String[]);</span><br><span class="line">    descriptor: ([Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         // ldc 这个操作码用来将常量从运行时常量池压栈到操作数栈</span><br><span class="line">         0: ldc           #3                  // String test</span><br><span class="line">         // 注意下面两句：通过实例调用 print</span><br><span class="line">         2: invokedynamic #4,  0              // InvokeDynamic #0:print:()LPrint;        </span><br><span class="line">         //调用静态方法 printString</span><br><span class="line">         7: invokestatic  #5                  // Method printString:(Ljava/lang/String;LPrint;)V</span><br><span class="line">        10: return</span><br></pre></td></tr></table></figure><p>那么，既然是调用实例方法，那么实例在哪？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">InnerClasses:</span><br><span class="line">     public static final #58= #57 of #61; //Lookup=class java/lang/invoke/MethodHandles$Lookup of class java/lang/invoke/MethodHandles</span><br><span class="line">BootstrapMethods:</span><br><span class="line">  0: #29 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;</span><br><span class="line">  Method arguments:</span><br><span class="line">      //对象类型终结符为 L 和 ;</span><br><span class="line">      //Object V</span><br><span class="line">      #30 (Ljava/lang/Object;)V</span><br><span class="line">      #31 invokestatic LambdaTest.lambda$main$0:(Ljava/lang/String;)V</span><br><span class="line">      #32 (Ljava/lang/String;)V</span><br></pre></td></tr></table></figure><p>可以在运行时加上-Djdk.internal.lambda.dumpProxyClasses，加上这个参数后，运行时，会将生成的内部类class码输出到一个文件中。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -Djdk.internal.lambda.dumpProxyClasses LambdaTest</span><br></pre></td></tr></table></figure><p><img data-src="/images/java-lambda/dumpProxyClasses.png" alt><br>通过jad反编译LambdaTest$$Lambda$1.class文件，内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Decompiled by Jad v1.5.8g. Copyright 2001 Pavel Kouznetsov.</span><br><span class="line">// Jad home page: http://www.kpdus.com/jad.html</span><br><span class="line">// Decompiler options: packimports(3) </span><br><span class="line">final class LambdaTest$$Lambda$1 implements Print &#123;</span><br><span class="line">    private LambdaTest$$Lambda$1() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void print(Object obj) &#123;</span><br><span class="line">        LambdaTest.lambda$main$0((String) obj);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3-5-代码还原">3.3.5 代码还原</h3><p>至此，我们可以推断出最终执行代码应该是这样的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class LambdaTest &#123;</span><br><span class="line">    public static void PrintString(String s, Print&lt;String&gt; print) &#123;</span><br><span class="line">        print.print(s);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        PrintString(&quot;test&quot;, new LambdaTest$$Lambda$1());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void lambda$main$0(String x) &#123;</span><br><span class="line">        System.out.println(x);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static final class LambdaTest$$Lambda$1 implements Print &#123;</span><br><span class="line">        public void print(Object obj) &#123;</span><br><span class="line">            LambdaTest.lambda$main$0((String) obj);</span><br><span class="line">        &#125;</span><br><span class="line">        private LambdaTest$$Lambda$1() &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@FunctionalInterface</span><br><span class="line">interface Print&lt;T&gt; &#123;</span><br><span class="line">    public void print(T x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1>四、总结</h1><ul><li>在类编译时，会生成一个私有静态方法+一个内部类；</li><li>在内部类中实现了函数式接口，在实现接口的方法中，会调用编译器生成的静态方法；</li><li>在使用lambda表达式的地方，通过传递内部类实例，来调用函数式接口方法。</li></ul><blockquote><p>就是传递个函数指针，在Java中搞得这么复杂。。。。。。</p></blockquote><p>参考资料：</p><p><a href="https://www.cnblogs.com/WJ5888/p/4667086.html" target="_blank" rel="noopener">https://www.cnblogs.com/WJ5888/p/4667086.html</a></p><p><a href="https://www.jianshu.com/p/57bffc6e7acd" target="_blank" rel="noopener">https://www.jianshu.com/p/57bffc6e7acd</a></p><p><a href="http://www.importnew.com/17770.html" target="_blank" rel="noopener">http://www.importnew.com/17770.html</a></p>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title>Java AQS 实现原理（图文）分析</title>
    <url>/java-aqs.html</url>
    <content><![CDATA[<p>AQS：AbstractQueuedSynchronizer</p><h1>1、AQS设计简介</h1><ul><li>AQS的实现是基于一个FIFO的等待队列。</li><li><font color="DeepPink"><strong>使用单个原子变量来表示获取、释放锁状态（final int）改变该int值使用的是CAS。</strong></font>（思考：为什么一个int值可以保证内存可见性？）</li><li><font color="DeepPink"><strong>子类应该定义一个非公开的内部类继承AQS，并实现其中方法。</strong></font></li><li>AQS支持exclusive与shared两种模式。</li><li>内部类ConditionObject用于支持子类实现exclusive模式</li><li>子类需要重写：<ul><li>tryAcquire</li><li>tryRelease</li><li>tryReleaseShared</li><li>isHeldExclusively等方法，并确保是线程安全的。</li></ul></li></ul><p>贯穿全文的图（核心）：</p><p><img data-src="/images/java-juc-aqs/AQS%E5%9B%BE%E8%A7%A3.png" alt></p><blockquote><p>模板方法设计模式：定义一个操作中算法的骨架，而将一些步骤的实现延迟到子类中。</p></blockquote><h1>2、类结构</h1><ul><li>ConditionObject类</li><li>Node类</li><li>N多方法</li></ul><p><img data-src="/images/java-juc-aqs/AQS%E7%B1%BB%E7%BB%93%E6%9E%84.png" alt></p><h1>3、FIFO队列</h1><p>等待队列是CLH（Craig, Landin, and Hagersten）锁队列。</p><p><strong>通过节点中的“状态”字段来判断一个线程是否应该阻塞。当该节点的前一个节点释放锁的时候，该节点会被唤醒。</strong></p><p><img data-src="/images/java-juc-aqs/AQS%E9%98%9F%E5%88%97.png" alt></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private transient volatile Node head;</span><br><span class="line">private transient volatile Node tail;</span><br><span class="line">//The synchronization state.</span><br><span class="line">//在互斥锁中它表示着线程是否已经获取了锁，0未获取，1已经获取了，大于1表示重入数。</span><br><span class="line">private volatile int state;</span><br></pre></td></tr></table></figure><p>AQS维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。</p><p>state的访问方式有三种:</p><ul><li>getState()</li><li>setState()</li><li>compareAndSetState()</li></ul><p>AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。</p><p>不同的自定义同步器争用共享资源的方式也不同。<font color="DeepPink"><strong>自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可</strong></font>，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p><p>自定义同步器实现时主要实现以下几种方法：</p><ul><li>isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。</li><li>tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。</li><li>tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。</li><li>tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</li><li>tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。</li></ul><p>以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，<font color="DeepPink"><strong>获取多少次就要释放多么次，这样才能保证state是能回到零态的。</strong></font></p><p>再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后续动作。</p><p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现：</p><ul><li>tryAcquire-tryRelease</li><li>tryAcquireShared-tryReleaseShared</li></ul><p>中的一种即可。</p><p>当然AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。</p><blockquote><p>以下部分来自源码注释：</p></blockquote><p>每次进入CLH队列时，需要对尾节点进入队列过程，是一个原子性操作。在出队列时，我们只需要更新head节点即可。在节点确定它的后继节点时， 需要花一些功夫，用于处理那些，由于等待超时时间结束或中断等原因， 而取消等待锁的线程。</p><p>节点的前驱指针，主要用于处理，取消等待锁的线程。如果一个节点取消等待锁，则此节点的前驱节点的后继指针，要指向，此节点后继节点中，非取消等待锁的线程（有效等待锁的线程节点）。</p><p>我们用next指针连接实现阻塞机制。每个节点均持有自己线程，节点通过节点的后继连接唤醒其后继节点。</p><p>CLH队列需要一个傀儡结点作为开始节点。我们不会再构造函数中创建它，因为如果没有线程竞争锁，那么，努力就白费了。取而代之的方案是，当有第一个竞争者时，我们才构造头指针和尾指针。</p><p>线程通过同一节点等待条件，但是用另外一个连接。条件只需要放在一个非并发的连接队列与节点关联，因为只有当线程独占持有锁的时候，才会去访问条件。当一个线程等待条件的时候，节点将会插入到条件队列中。当条件触发时，节点将会转移到主队列中。用一个状态值，描述节点在哪一个队列上。</p><h1>4、Node</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static final class Node &#123;</span><br><span class="line">    //该等待节点处于共享模式</span><br><span class="line">    static final Node SHARED = new Node();</span><br><span class="line">    //该等待节点处于独占模式</span><br><span class="line">    static final Node EXCLUSIVE = null;</span><br><span class="line">    </span><br><span class="line">    //表示节点的线程是已被取消的</span><br><span class="line">    static final int CANCELLED =  1;</span><br><span class="line">    //表示当前节点的后继节点的线程需要被唤醒</span><br><span class="line">    static final int SIGNAL    = -1;</span><br><span class="line">    //表示线程正在等待某个条件</span><br><span class="line">    static final int CONDITION = -2;</span><br><span class="line">    //表示下一个共享模式的节点应该无条件的传播下去</span><br><span class="line">    static final int PROPAGATE = -3;</span><br><span class="line"></span><br><span class="line">    //状态位 ，分别可以使CANCELLED、SINGNAL、CONDITION、PROPAGATE、0 </span><br><span class="line">    volatile int waitStatus;</span><br><span class="line"></span><br><span class="line">    volatile Node prev;//前驱节点</span><br><span class="line">    volatile Node next;//后继节点</span><br><span class="line">    volatile Thread thread;//等待锁的线程</span><br><span class="line"></span><br><span class="line">    //ConditionObject链表的后继节点或者代表共享模式的节点。</span><br><span class="line">    //因为Condition队列只能在独占模式下被能被访问,我们只需要简单的使用链表队列来链接正在等待条件的节点。</span><br><span class="line">    //然后它们会被转移到同步队列（AQS队列）再次重新获取。</span><br><span class="line">    //由于条件队列只能在独占模式下使用，所以我们要表示共享模式的节点的话只要使用特殊值SHARED来标明即可。</span><br><span class="line">    Node nextWaiter;</span><br><span class="line">    //Returns true if node is waiting in shared mode</span><br><span class="line">    final boolean isShared() &#123;</span><br><span class="line">            return nextWaiter == SHARED;</span><br><span class="line">    &#125;</span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>waitStatus不同值含义：</p><ul><li>SIGNAL(-1)：当前节点的后继节点已经 (或即将)被阻塞（通过park） , 所以当当前节点释放或则被取消时候，一定要unpark它的后继节点。为了避免竞争，获取方法一定要首先设置node为signal，然后再次重新调用获取方法，如果失败，则阻塞。</li><li>CANCELLED(1)：当前节点由于超时或者被中断而被取消。一旦节点被取消后，那么它的状态值不在会被改变，且当前节点的线程不会再次被阻塞。</li><li>CONDITION(-2) ：该节点的线程处于等待条件状态,不会被当作是同步队列上的节点,直到被唤醒(signal),设置其值为0,重新进入阻塞状态.</li><li>PROPAGATE(-3：)共享模式下的释放操作应该被传播到其他节点。该状态值在doReleaseShared方法中被设置的。</li><li>0：以上都不是</li></ul><p>该状态值为了简便使用，所以使用了数值类型。非负数值意味着该节点不需要被唤醒。所以，大多数代码中不需要检查该状态值的确定值。</p><p>一个正常的Node，它的waitStatus初始化值是0。如果想要修改这个值，可以使用AQS提供CAS进行修改。</p><h1>5、独占模式与共享模式</h1><p>在锁的获取时，并不一定只有一个线程才能持有这个锁（或者称为同步状态），所以此时有了独占模式和共享模式的区别，也就是在Node节点中由nextWaiter来标识。比如ReentrantLock就是一个独占锁，只能有一个线程获得锁，而WriteAndReadLock的读锁则能由多个线程同时获取，但它的写锁则只能由一个线程持有。</p><h2 id="5-1、独占模式">5.1、独占模式</h2><h3 id="5-1-1-独占模式同步状态的获取">5.1.1 独占模式同步状态的获取</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//忽略中断的（即不手动抛出InterruptedException异常）独占模式下的获取方法。</span><br><span class="line">//该方法在成功返回前至少会调用一次tryAcquire()方法(该方法是子类重写的方法，如果返回true则代表能成功获取).</span><br><span class="line">//否则当前线程会进入队列排队，重复的阻塞和唤醒等待再次成功获取后返回, </span><br><span class="line">//该方法可以用来实现Lock.lock</span><br><span class="line">public final void acquire(int arg) &#123;</span><br><span class="line">       if (!tryAcquire(arg) &amp;&amp;</span><br><span class="line">            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line">            selfInterrupt();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>该方法首先尝试获取锁(tryAcquire(arg)的具体实现定义在了子类中),如果获取到,则执行完毕,否则通过addWaiter(Node.EXCLUSIVE), arg)方法把当前节点添加到等待队列末尾,并设置为独占模式。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private Node addWaiter(Node mode) &#123;</span><br><span class="line">        //把当前线程包装为node,设为独占模式</span><br><span class="line">        Node node = new Node(Thread.currentThread(), mode);</span><br><span class="line">        // 尝试快速入队，即无竞争条件下肯定成功。如果失败，则进入enq自旋重试入队</span><br><span class="line">        Node pred = tail;</span><br><span class="line">        if (pred != null) &#123;</span><br><span class="line">            node.prev = pred;</span><br><span class="line">            //CAS替换当前尾部。成功则返回</span><br><span class="line">            if (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">                pred.next = node;</span><br><span class="line">                return node;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        enq(node);</span><br><span class="line">        return node;</span><br><span class="line">    &#125;</span><br><span class="line">//插入节点到队列中，如果队列未初始化则初始化，然后再插入。</span><br><span class="line">private Node enq(final Node node) &#123;</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            Node t = tail;</span><br><span class="line">            if (t == null) &#123; // Must initialize</span><br><span class="line">                if (compareAndSetHead(new Node()))</span><br><span class="line">                    tail = head;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                node.prev = t;</span><br><span class="line">                if (compareAndSetTail(t, node)) &#123;</span><br><span class="line">                    t.next = node;</span><br><span class="line">                    return t;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>如果tail节点为空,执行enq(node);重新尝试,最终把node插入.在把node插入队列末尾后,它并不立即挂起该节点中线程,因为在插入它的过程中,前面的线程可能已经执行完成,所以它会先进行自旋操作acquireQueued(node, arg),尝试让该线程重新获取锁!当条件满足获取到了锁则可以从自旋过程中退出，否则继续。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final boolean acquireQueued(final Node node, int arg) &#123;</span><br><span class="line">        boolean failed = true;</span><br><span class="line">        try &#123;</span><br><span class="line">            boolean interrupted = false;</span><br><span class="line">            for (;;) &#123;</span><br><span class="line">                final Node p = node.predecessor();</span><br><span class="line">                //如果它的前继节点为头结点,尝试获取锁,获取成功则返回           </span><br><span class="line">                if (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = null; // help GC</span><br><span class="line">                    failed = false;</span><br><span class="line">                    return interrupted;</span><br><span class="line">                &#125;</span><br><span class="line">                //判断当前节点的线程是否应该被挂起，如果应该被挂起则挂起。</span><br><span class="line">                //等待release唤醒释放</span><br><span class="line">                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    interrupted = true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (failed)</span><br><span class="line">                //在队列中取消当前节点</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>如果没获取到锁,则判断是否应该挂起,而这个判断则得通过它的前驱节点的waitStatus来确定:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;</span><br><span class="line">        int ws = pred.waitStatus;</span><br><span class="line">        //该节点如果状态如果为SIGNAL。则返回true，然后park挂起线程</span><br><span class="line">        if (ws == Node.SIGNAL)</span><br><span class="line">            return true;</span><br><span class="line">       //表明该节点已经被取消，向前循环重新调整链表节点</span><br><span class="line">        if (ws &gt; 0) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Predecessor was cancelled. Skip over predecessors and</span><br><span class="line">             * indicate retry.</span><br><span class="line">             */</span><br><span class="line">            do &#123;</span><br><span class="line">                node.prev = pred = pred.prev;</span><br><span class="line">            &#125; while (pred.waitStatus &gt; 0);</span><br><span class="line">            pred.next = node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            //执行到这里代表节点是0或者PROPAGATE，然后标记他们为SIGNAL，但是</span><br><span class="line">            //还不能park挂起线程。需要重试是否能获取，如果不能，则挂起。</span><br><span class="line">            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">//挂起当前线程，且返回线程的中断状态</span><br><span class="line">private final boolean parkAndCheckInterrupt() &#123;</span><br><span class="line">        LockSupport.park(this);</span><br><span class="line">        return Thread.interrupted();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>最后,我们对获取独占式锁过程对做个总结:</p><p>AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后-&gt;将线程构造成Node节点(addWaiter)-&gt;将Node节点添加到同步队列对尾(addWaiter)-&gt;节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点单获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。</p><p><font color="DeepPink"><strong>获取锁的过程：</strong></font></p><ul><li><font color="DeepPink"><strong>当线程调用acquire()申请获取锁资源，如果成功，则进入临界区。</strong></font></li><li><font color="DeepPink"><strong>当获取锁失败时，则进入一个FIFO等待队列，然后被挂起等待唤醒。</strong></font></li><li><font color="DeepPink"><strong>当队列中的等待线程被唤醒以后就重新尝试获取锁资源，如果成功则进入临界区，否则继续挂起等待。</strong></font></li></ul><h3 id="5-1-2-独占模式同步状态的释放">5.1.2 独占模式同步状态的释放</h3><p>既然是释放,那肯定是持有锁的该线程执行释放操作,即head节点中的线程释放锁.</p><p>AQS中的release释放同步状态和acquire获取同步状态一样，都是模板方法，tryRelease释放的具体操作都有子类去实现，父类AQS只提供一个算法骨架。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final boolean release(int arg) &#123;</span><br><span class="line">    if (tryRelease(arg)) &#123;</span><br><span class="line">        Node h = head;</span><br><span class="line">        if (h != null &amp;&amp; h.waitStatus != 0)</span><br><span class="line">            unparkSuccessor(h);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line">//如果node的后继节点不为空且不是作废状态,则唤醒这个后继节点,</span><br><span class="line">//否则从末尾开始寻找合适的节点,如果找到,则唤醒</span><br><span class="line">private void unparkSuccessor(Node node) &#123;</span><br><span class="line">        int ws = node.waitStatus;</span><br><span class="line">        if (ws &lt; 0)</span><br><span class="line">            compareAndSetWaitStatus(node, ws, 0);</span><br><span class="line">        Node s = node.next;</span><br><span class="line">        if (s == null || s.waitStatus &gt; 0) &#123;</span><br><span class="line">            s = null;</span><br><span class="line">            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)</span><br><span class="line">                if (t.waitStatus &lt;= 0)</span><br><span class="line">                    s = t;</span><br><span class="line">        &#125;</span><br><span class="line">        if (s != null)</span><br><span class="line">            LockSupport.unpark(s.thread);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>过程：首先调用子类的tryRelease()方法释放锁，然后唤醒后继节点，在唤醒的过程中，需要判断后继节点是否满足情况，如果后继节点不为空且不是作废状态，则唤醒这个后继节点，否则从tail节点向前寻找合适的节点，如果找到，则唤醒。</p><p><font color="DeepPink"><strong>释放锁过程：</strong></font></p><ul><li><font color="DeepPink"><strong>当线程调用release()进行锁资源释放时，如果没有其他线程在等待锁资源，则释放完成。</strong></font></li><li><font color="DeepPink"><strong>如果队列中有其他等待锁资源的线程需要唤醒，则唤醒队列中的第一个等待节点（先入先出）。</strong></font></li></ul><h2 id="5-2、共享模式">5.2、共享模式</h2><h3 id="5-2-1-共享模式同步状态的获取">5.2.1 共享模式同步状态的获取</h3><ul><li><font color="DeepPink"><strong>当线程调用acquireShared()申请获取锁资源时，如果成功，则进入临界区。</strong></font></li><li><font color="DeepPink"><strong>当获取锁失败时，则创建一个共享类型的节点并进入一个FIFO等待队列，然后被挂起等待唤醒。</strong></font></li><li><font color="DeepPink"><strong>当队列中的等待线程被唤醒以后就重新尝试获取锁资源，如果成功则唤醒后面还在等待的共享节点并把该唤醒事件传递下去，即会依次唤醒在该节点后面的所有共享节点，然后进入临界区，否则继续挂起等待。</strong></font></li></ul><h3 id="5-2-2-共享模式同步状态的释放">5.2.2 共享模式同步状态的释放</h3><ul><li><font color="DeepPink"><strong>当线程调用releaseShared()进行锁资源释放时，如果释放成功，则唤醒队列中等待的节点，如果有的话。</strong></font></li></ul><h1>6. AQS小结</h1><p>java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。<font color="DeepPink"><strong>AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。</strong></font></p><p>JDK中AQS被广泛使用，基于AQS实现的同步器包括：</p><ul><li>ReentrantLock</li><li>Semaphore</li><li>ReentrantReadWriteLock（后续会出文章讲解）</li><li>CountDownLatch</li><li>FutureTask</li></ul><p>每一个基于AQS实现的同步器都会包含两种类型的操作，如下：</p><ul><li>至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。</li><li>至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。</li></ul><p><font color="DeepPink"><strong>基于“复合优先于继承”的原则，基于AQS实现的同步器一般都是：声明一个内部私有的继承于AQS的子类Sync，对同步器所有公有方法的调用都会委托给这个内部子类。</strong></font></p><h1>7.后续</h1><p>后面会推出以下有关AQS的文章，已加深对于AQS的理解</p><ul><li><a href="https://jiankunking.com/java-aqs-condition.html">AQS ConditionObject对象解析</a></li><li><a href="https://jiankunking.com/java-reentrantreadwritelock.html">AQS 应用案例 ReentrantReadWriteLock解析</a></li><li><a href="https://jiankunking.com/java-volatile-aqs.html">Java Volatile的内存语义与AQS锁内存可见性</a></li></ul><h1>8.思考</h1><h2 id="多人抢锁">多人抢锁</h2><p>多个线程同时取争取一个锁（在争取之前资源未被锁定），这时候如何保证，只有一个人能获取到？<br>下面以非公平锁来看一下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    /**</span><br><span class="line">     * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class="line">     * subclasses, but both need nonfair try for trylock method.</span><br><span class="line">     */</span><br><span class="line">    @ReservedStackAccess</span><br><span class="line">    final boolean nonfairTryAcquire(int acquires) &#123;</span><br><span class="line">        final Thread current = Thread.currentThread();</span><br><span class="line">        int c = getState();</span><br><span class="line">        if (c == 0) &#123;</span><br><span class="line">            if (compareAndSetState(0, acquires)) &#123;</span><br><span class="line">                setExclusiveOwnerThread(current);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">            int nextc = c + acquires;</span><br><span class="line">            if (nextc &lt; 0) // overflow</span><br><span class="line">                throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">            setState(nextc);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line"> * Atomically sets synchronization state to the given updated</span><br><span class="line"> * value if the current state value equals the expected value.</span><br><span class="line"> * This operation has memory semantics of a &#123;@code volatile&#125; read</span><br><span class="line"> * and write.</span><br><span class="line"> *</span><br><span class="line"> * @param expect the expected value</span><br><span class="line"> * @param update the new value</span><br><span class="line"> * @return &#123;@code true&#125; if successful. False return indicates that the actual</span><br><span class="line"> *         value was not equal to the expected value.</span><br><span class="line"> */</span><br><span class="line">protected final boolean compareAndSetState(int expect, int update) &#123;</span><br><span class="line">    return STATE.compareAndSet(this, expect, update);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line"> * Atomically sets the value of a variable to the &#123;@code newValue&#125; with the</span><br><span class="line"> * memory semantics of &#123;@link #setVolatile&#125; if the variable&apos;s current value,</span><br><span class="line"> * referred to as the &lt;em&gt;witness value&lt;/em&gt;, &#123;@code ==&#125; the</span><br><span class="line"> * &#123;@code expectedValue&#125;, as accessed with the memory semantics of</span><br><span class="line"> * &#123;@link #getVolatile&#125;.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;The method signature is of the form &#123;@code (CT1 ct1, ..., CTn ctn, T expectedValue, T newValue)boolean&#125;.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;The symbolic type descriptor at the call site of &#123;@code</span><br><span class="line"> * compareAndSet&#125; must match the access mode type that is the result of</span><br><span class="line"> * calling &#123;@code accessModeType(VarHandle.AccessMode.COMPARE_AND_SET)&#125; on</span><br><span class="line"> * this VarHandle.</span><br><span class="line"> *</span><br><span class="line"> * @param args the signature-polymorphic parameter list of the form</span><br><span class="line"> * &#123;@code (CT1 ct1, ..., CTn ctn, T expectedValue, T newValue)&#125;</span><br><span class="line"> * , statically represented using varargs.</span><br><span class="line"> * @return &#123;@code true&#125; if successful, otherwise &#123;@code false&#125; if the</span><br><span class="line"> * witness value was not the same as the &#123;@code expectedValue&#125;.</span><br><span class="line"> * @throws UnsupportedOperationException if the access mode is unsupported</span><br><span class="line"> * for this VarHandle.</span><br><span class="line"> * @throws WrongMethodTypeException if the access mode type does not</span><br><span class="line"> * match the caller&apos;s symbolic type descriptor.</span><br><span class="line"> * @throws ClassCastException if the access mode type matches the caller&apos;s</span><br><span class="line"> * symbolic type descriptor, but a reference cast fails.</span><br><span class="line"> * @see #setVolatile(Object...)</span><br><span class="line"> * @see #getVolatile(Object...)</span><br><span class="line"> */</span><br><span class="line">public final native</span><br><span class="line">@MethodHandle.PolymorphicSignature</span><br><span class="line">@HotSpotIntrinsicCandidate</span><br><span class="line">boolean compareAndSet(Object... args);</span><br></pre></td></tr></table></figure><p>从代码中可以看出通过compareAndSetState来保证只会有一个线程获取到锁。</p><h2 id="LockSupport-park-unpark">LockSupport(park/unpark)</h2><h3 id="实现">实现</h3><p>Unsafe.park和Unsafe.unpark的底层实现原理<br>在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。<br>mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。</p><h3 id="Object类的wait-notify和LockSupport-park-unpark-s的区别">Object类的wait/notify和LockSupport(park/unpark)s的区别</h3><p>park函数是将当前调用Thread阻塞，而unpark函数则是将指定线程Thread唤醒。</p><p>与Object类的wait/notify机制相比，park/unpark有两个优点：</p><ul><li>以thread为操作对象更符合阻塞线程的直观定义</li><li>操作更精准，可以准确地唤醒某一个线程。</li></ul><p>区别是:notify随机唤醒一个线程，notifyAll唤醒所有等待的线程,增加了灵活性</p><h3 id="synchronized-实现">synchronized 实现</h3><p>可以参考下这个：</p><p><a href="https://xiaomi-info.github.io/2020/03/24/synchronized/" target="_blank" rel="noopener">https://xiaomi-info.github.io/2020/03/24/synchronized/</a></p><h1>9.感谢</h1><p>本文很多内容整理自网络，参考文献：<br><a href="https://segmentfault.com/a/1190000011376192" target="_blank" rel="noopener">https://segmentfault.com/a/1190000011376192</a><br><a href="https://segmentfault.com/a/1190000011391092" target="_blank" rel="noopener">https://segmentfault.com/a/1190000011391092</a><br><a href="https://zhuanlan.zhihu.com/p/27134110" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27134110</a><br><a href="https://blog.csdn.net/wojiaolinaaa/article/details/50070031" target="_blank" rel="noopener">https://blog.csdn.net/wojiaolinaaa/article/details/50070031</a><br><a href="https://www.cnblogs.com/waterystone/p/4920797.html" target="_blank" rel="noopener">https://www.cnblogs.com/waterystone/p/4920797.html</a></p><p>FIFO队列:<a href="https://www.cnblogs.com/waterystone/p/4920797.html" target="_blank" rel="noopener">https://www.cnblogs.com/waterystone/p/4920797.html</a></p>]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>AQS</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP与UDP 笔记</title>
    <url>/tcp-and-udp-notes.html</url>
    <content><![CDATA[<p>本文整理自：《图解TCP/IP 第5版》<br>作者：[日] 竹下隆史，[日] 村山公保，[日] 荒井透，[日] 苅田幸雄 著<br>译者：乌尼日其其格<br>出版时间：2013-07</p><a id="more"></a><p><img data-src="/images/tcp-and-udp-note/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82.png" alt></p><h1>传输层的作用</h1><p>TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。</p><h2 id="两种传输层协议TCP和UDP">两种传输层协议TCP和UDP</h2><h3 id="TCP">TCP</h3><p>TCP是面向连接的、可靠的流协议。流就是指不间断的数据结构，你可以把它想象成排水管道中的水流。TCP为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。</p><h3 id="UDP">UDP</h3><p>UDP是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。UDP情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。</p><h2 id="TCP与UDP区分">TCP与UDP区分</h2><p>TCP用于在传输层有必要实现可靠性传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的。所以它可以为应用提供可靠传输。</p><p>UDP主要用于那些对高速传输和实时性有较高要求的通信或广播通信。举一个IP电话进行通话的例子。如果使用TCP，数据在传送途中如果丢失会被重发，但是这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是影响某一小部分的通话。此外，在多播与广播通信中也使用UDP而不是TCP。RIP、DHCP等基于广播的协议也要依赖于UDP。</p><h1>端口号</h1><h2 id="端口号定义">端口号定义</h2><p><font color="DeepPink"><strong>数据链路和IP中的地址，分别指的是MAC地址和IP地址。前者用来识别同一链路中不同的计算机，后者用来识别TCP/IP网络中互连的主机和路由器。传输层也有类似概念，就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。</strong></font></p><h2 id="通过IP地址、端口号、协议号进行通信识别">通过IP地址、端口号、协议号进行通信识别</h2><p><font color="DeepPink"><strong>TCP/IP或UDP/IP通信中通常采用5个信息来识别一个通信。它们是“源IP地址”、“目标IP地址”、“协议号”、“源端口号”、“目标端口号”。</strong></font>只要其中某一项不同，则被认为是其他通信。</p><h2 id="端口号与协议">端口号与协议</h2><p><font color="DeepPink"><strong>端口号由其使用的传输层协议决定。因此，不同的传输协议可以使用相同的端口号。</strong></font>例如，TCP与UDP使用同一个端口号，但使用目的各不相同。</p><p>数据到达IP层后，会先检查IP首部中的协议号，再传给相应协议的模块。传给TCP或UDP去做端口号处理。即使是同一个端口号，由于传输协议是各自独立地进行处理，因此相互之间不会影响。</p><h1>UDP</h1><p>UDP是User Datagram Protocol的缩写，即用户数据包协议。</p><p>UDP不提供复杂控制机制，利用IP提供面向无连接的通信服务。且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。</p><p>UDP面向无连接，可以随时发送数据。它常用于几个方面：</p><ul><li>包总量较少的通信（DNS、SNMP等）</li><li>视频、音频等多媒体通信（即时通信）</li><li>限定于LAN等特定网络中的应用通信</li><li>广播通信（广播、多播）</li></ul><h1>TCP</h1><p>TCP是Transmission Control Protocol的缩写，传输控制协议。</p><p>TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。</p><blockquote><p>连接<br>连接是指各种设备、线路,或网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信线路,也叫做虚拟电路。<br>一旦建立了连接,进行通信的应用程序只是用这个虚拟的通信线路发送和接收数据,就可以保障信息的传输。应用程序不用顾虑IP网络上可能发生的各种问题,依然可以转发数据。TCP则负责控制链接的建立、断开、保持等管理工作。<br><img data-src="/images/tcp-and-udp-note/%E8%BF%9E%E6%8E%A5.png" alt></p></blockquote><h2 id="TCP的特点及其目的">TCP的特点及其目的</h2><p>为了通过数据包实现可靠性传输,需要考虑很多事情,例如数据的破坏、丢包、重复记忆分片顺序混乱等问题。如不能解决这些问题,也就无从谈起可靠传输。</p><p><font color="DeepPink"><strong>TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。</strong></font></p><h2 id="通过序列号与确认应答提高可靠性">通过序列号与确认应答提高可靠性</h2><p>在TCP中，当发送端数据到达接受主机时，接收端主机会返回一个已收到的消息的通知。这个消息叫做确认应答（ACK Positive Acknowledgement）。</p><p>TCP通过肯定的确认应答（ACK）实现可靠的数据传输。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。</p><p>在一定时间内没有等到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。</p><p>未确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。</p><p>为了防止出现随意重发的情况，就需要引入一种机制，它能够识别是否已经接收数据，又能判断是否需要接收。</p><p>这些确认应答处理、重发控制以及重复控制等功能都可以通过序列号实现。<font color="DeepPink"><strong>序列号是按照顺序给发送数据的每个字节（8位字节）都标上号码的编号（序列号的初始值并非为0。而是在建立连接以后由随机数生成。而后面的计算则是对每一字节加一）。接收端查询接收数据TCP首部中序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。这样，通过序列号和确认应答号，TCP可以实现可靠传输。</strong></font></p><p><img data-src="/images/tcp-and-udp-note/%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.png" alt></p><h2 id="重发超时如何确定">重发超时如何确定</h2><p>重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过了这个时间仍未收到确认应答，发送端将进行数据重发。那么这个重发超时的具体时间长度又是如何确定的呢？</p><p>最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。然而这个时间长短随着数据包途径的网络环境的不同而有所变化。例如在高速的LAN中时间相对较短，而在长距离的通信当中应该比LAN要长一些。即使是在同一个网络中，根据不同时段的网络堵塞程度时间的长短也会发生变化。TCP要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差相加重发超时的时间，就是比这个总和要稍大一点的值。</p><p><img data-src="/images/tcp-and-udp-note/%E5%BE%80%E8%BF%94%E6%97%B6%E9%97%B4%E7%9A%84%E8%AE%A1%E7%AE%97%E4%B8%8E%E9%87%8D%E5%8F%91%E8%B6%85%E6%97%B6%E7%9A%84%E6%97%B6%E9%97%B4%E6%8E%A8%E7%A7%BB.png" alt></p><p>在BSD的Unix以及Windows系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，由于最初的数据包还不知道往返时间，所以其重发超时一般设置为6秒左右。数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。</p><h2 id="连接管理">连接管理</h2><p>TCP提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好通信两端之间的准备工作。</p><p>UDP是一种面向无连接的通信协议，因此不检查对端是否可以通信，直接将UDP包发出去。TCP与此相反，它会在数据通信之前，通过TCP首部发送一个SYN包作为建立连接的请求等待确认应答（<font color="DeepPink"><strong>TCP中发送第一个SYN包的一方叫客户端，接收这个的一方叫服务端</strong></font>）。如果对端发来确认应答，则认为可以进行数据通信。如果对端的确认应答未能到达，就不会进行数据通信。此外，在通信结束时会进行断开连接的处理（FIN包）。</p><p>可以使用TCP首部用于控制的字段来管理TCP连接（也叫控制域）。一个连接的建立与断开，正常过程至少需要来回发送7个包才能完成。（建立一个TCP连接需要发送3个包，这个过程也称为3次握手）</p><p><img data-src="/images/tcp-and-udp-note/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B%E4%B8%8E%E6%96%AD%E5%BC%80.png" alt></p><h2 id="TCP以段为单位发送数据">TCP以段为单位发送数据</h2><p><font color="DeepPink"><strong>在建立TCP连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS：Maximum Segment Size）。</strong></font> 最理想的情况是，最大消息长度正好是IP中不会被分片处理的最大数据长度。</p><p>TCP在传输大量数据时，是以MSS的大小将数据进行分割发送的。进行重发时也是以MSS为单位。</p><p>MSS是在三次握手的时候，在两端主机之间被计算得出。<font color="DeepPink"><strong>两端的主机在发出建立连接的请求时，会在TCP首部中写入MSS选项，告诉对方自己的接口能够适应的MSS的大小（为附加MSS选项，TCP首部将不再是20字节，而是4字节的整数倍）。然后会在两者之间选择一个较小的值投入使用。</strong></font></p><p><img data-src="/images/tcp-and-udp-note/%E6%8E%A5%E5%85%A5%E4%BB%A5%E5%A4%AA%E7%BD%91%E4%B8%BB%E6%9C%BA%E4%B8%8E%E6%8E%A5%E5%85%A5FDDI%E4%B8%BB%E6%9C%BA%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84%E6%83%85%E5%86%B5.png" alt></p><blockquote><p>SYN(synchronous建立联机) ACK(acknowledgement 确认) FIN(finish结束)</p></blockquote><h2 id="利用窗口控制提高速度">利用窗口控制提高速度</h2><p>TCP以1个段为单位，每发一个段进行一次确认应答的处理，如下图，这样传输的缺点是，包的往返时间越长通信性能就越低。</p><p><img data-src="/images/tcp-and-udp-note/%E6%8C%89%E6%95%B0%E6%8D%AE%E5%8C%85%E8%BF%9B%E8%A1%8C%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94.png" alt></p><p>为解决这个问题，TCP引入了窗口这个概念。如下图，确认应答不再是以每个分段，而是以更大的单位进行确认时，转发时间将会被大幅度的缩短。就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。</p><p><font color="DeepPink"><strong>窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。</strong></font> 如下图中，窗口大小为4个段。</p><p>这个机制实现了使用大量的缓冲区（Buffer 在此处标识临时保存收发数据的场所。通常是在计算机内存中开辟的一部分空间），通过对多个段同时进行确认应答的功能。</p><p>用滑动窗口方式并行处理：</p><p><img data-src="/images/tcp-and-udp-note/%E7%94%A8%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%96%B9%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.png" alt></p><p>下面的图中发送数据中高亮圈起的部分正是前面所提到的窗口。在这个窗口内的数据即便没有收到确认应答也可以发送出去。此外，<font color="DeepPink"><strong>从该窗口中能看到的数据因其某种数据已在传输中丢失，所以发送端才能收到确认应答，这种情况也需要重发。为此，发送端主机在等到确认应答返回之前，必须在缓冲区中保留这部分数据。</strong></font></p><p>在滑动窗口以外的部分包括尚未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再重发，此时数据皆可以从缓冲区清除。</p><p><font color="DeepPink"><strong>收到确认应答，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也被称为滑动窗口控制。</strong></font></p><p>滑动窗口方式：</p><p><img data-src="/images/tcp-and-udp-note/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%96%B9%E5%BC%8F.png" alt></p><h2 id="窗口控制与重发控制">窗口控制与重发控制</h2><p>使用窗口控制中， 如果出现段丢失怎么办？</p><p>首先考虑确认应答未能返回的情况。这种情况下，数据已经达到对端，是不需要进行重发的。然而，在没有使用窗口控制的时候，没有收到确认应答的数据会被重发。而使用了窗口控制，如下图，某些确认应答即便丢失也无需重发。</p><p><img data-src="/images/tcp-and-udp-note/%E6%B2%A1%E6%9C%89%E7%A1%AE%E8%AE%A4%E5%BA%94%E7%AD%94%E4%B9%9F%E4%B8%8D%E5%8F%97%E5%BD%B1%E5%93%8D.png" alt></p><p>其次，考虑一下某个报文段丢失的情况。如下图，接收主机如果收到一个自己应该接收的序号以外的数据时，会针对当前位置收到数据返回确认应答（不过<font color="DeepPink"><strong>即使接收端主机收到的包序号并不连续，也不会将数据丢弃而是暂时保存至缓冲区中</strong></font>）。</p><p>当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，这个确认应答好像在提醒发送端“我想接收的是从1001开始的数据”。因此，在窗口比较大，又出现报文段丢失的情况下，同一个序号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答（之所以连续收到3次而不是两次的理由是因为，即使数据段的序号被替换两次也不会触发重发机制）。就会将其所对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称作高速重发控制。</p><p><img data-src="/images/tcp-and-udp-note/%E9%AB%98%E9%80%9F%E9%87%8D%E5%8F%91%E6%8E%A7%E5%88%B6.png" alt></p><h2 id="流控制">流控制</h2><p>发送端根据自己的实际情况发送数据。但是，接收端可能收到的是一个毫无关系的数据包有可能会在处理其他问题上花费一些时间。因此在为这个数据包做其他处理时会耗费一些时间，甚至在高负荷情况下无法接收任何数据。如此一来，如果接收端将本应该接收的数据丢弃的话，就又会触发重发机制，从而导致网络流量的浪费。</p><p>为了防止这种现象发生，<font color="DeepPink"><strong>TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的流控制。它的具体操作时，接收端主机向发送端主机通知自己可以接收数据的大小，于是发送端会发送不超过这个限制的数据。该大小限度就被称为窗口大小。</strong></font></p><p><font color="DeepPink"><strong>TCP首部中，专门有一个字段用来通知窗口大小。接收主机将自己的可以接收的缓冲区大小放入这个字段通知给发送端。这个值越大，说明网络的吞吐量越高。</strong></font></p><p><font color="DeepPink"><strong>不过，接收端这个缓冲区一旦面临数据溢出时，窗口大小的值也会随之被设置为一个更小的值通知给发送端，从而控制数据发送量。就是说，发送端主机会根据接收端主机的指示，对发送数据的量进行控制。这也形成了一个完整的TCP流控制（流量控制）。</strong></font></p><p>根据窗口大小控制流量过程示例：</p><p><img data-src="/images/tcp-and-udp-note/%E6%B5%81%E6%8E%A7%E5%88%B6.png" alt></p><p>当接收端收到从3001号开始的数据段后其缓冲区即满，不得不暂时停止接收数据。之后，在收到发送窗口更新通知后通信才得以继续进行。如果这个窗口更新通知在传输途中丢失，可能会导致无法继续通信。为避免此类问题，发送端主机会时不时发送一个叫做窗口探测的数据段，此数据段仅含一个字节以获取最新的窗口大小信息。</p><h2 id="拥塞控制">拥塞控制</h2><p>有了TCP窗口控制，收发主机之间即使不再以一个数据段为单位发送确认应答，也能够连续发送大量数据包。然而，如果在通信刚开始就发送大量数据，也可能会引发其他问题。</p><p>TCP为了防止该问题的出现，在通信一开始就会通过一个叫做慢启动的算法得出的数值，对发送数据量进行控制。</p><p><font color="DeepPink"><strong>首先，为了在发送端调节所要发送数据的量，定义了一个叫做“拥塞窗口”的概念。于是在慢启动的时候，将这个拥塞窗口的大小设置为1个数据段（1MSS）发送数据，之后每收到一次确认应答（ACK），拥塞窗口的值就加1。在发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还要小的数据量。</strong></font></p><p><img data-src="/images/tcp-and-udp-note/%E6%85%A2%E5%90%AF%E5%8A%A8.png" alt></p><p>如果重发采用超时机制,那么拥塞窗口的初始值可以设置为1以后再进行慢启动修正。有了上述这些机制,就可以有限的减少通信开始时连续发包导致的网络拥堵,还可以避免网络拥塞情况的发生。</p><p>不过,随着包的每次往返,拥塞窗口也会以1、2、4等指数函数的增长,拥堵状况激增甚至导致网络拥塞的发生。为了防止这些,引入了慢启动阀值的概念。只要拥塞窗口的值超出这个阀值,在每收到一次确认应答时,只允许以下面这种比例方法拥塞窗口:</p><p><img data-src="/images/tcp-and-udp-note/%E6%8B%A5%E5%A1%9E%E8%B0%83%E6%95%B4%E5%85%AC%E5%BC%8F.png" alt></p><p><img data-src="/images/tcp-and-udp-note/TCP%E7%9A%84%E7%AA%97%E5%8F%A3%E5%8F%98%E5%8C%96.png" alt></p><p>拥塞窗口越大，确认应答的数目也会增加，不过随着每收到一个确认应答，其涨幅也会逐渐减少，甚至小过比一个数据段还要小的字节数。所以，拥塞窗口的大小会呈直线上升的趋势。</p><p>TCP通信开始时，并没有设置相应的慢启动阈值（与窗口的最大值相同)，而是在超时重发时才会设置为当时拥塞窗口一半的大小。</p><p>由重发确认应答而触发的高速重发与超时重发机制的处理多少有些不同。因为前者要求至少3次的确认应答数据段到达对方主机后才会触发，相比后者网络的拥堵要轻一些。</p><p>而由重复确认应答进行高速重发控制时，慢启动阈值的大小被设置为当时窗口大小的一半（严格来说，是设置为“实际已发送但未收到确认应答的数据量”的一半）。然后将窗口的大小设置为该慢启动阈值+3个数据段的大小。</p><p>有了这样一种控制，TCP的拥塞窗口如上图所示发生变化。由于窗口的大小会直接影响数据被转发的吞吐量，所以一般情况下，窗口越大，越会形成高吞吐量的通信。</p><p>当TCP通信开始以后,网络吞吐量会逐渐上升,但是随着网络拥堵的发生吞吐量也会急剧下降。于是会再次进入吞吐量慢慢上升的过程。因此所谓TCP的吞吐量的特点就好像是在逐步占领网络带宽的感觉。</p><h1>UDP首部的格式</h1><p>下图展示了UDP首部的格式。除去数据的部分正式UDP的首部。UDP首部由源端口号，目标端口号，包长和校验和组成。</p><p><img data-src="/images/tcp-and-udp-note/UDP%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%A0%BC%E5%BC%8F.png" alt></p><h2 id="源端口号（Source-Port）">源端口号（Source Port）</h2><p>表示发送端端口号，字段长16位。该字段是可选项，有时可能不会设置源端口号。没有源端口号的时候该字段的值设置为0。可用于不需要返回的通信中。</p><h2 id="目标端口号（Destination-Port）">目标端口号（Destination Port）</h2><p>表示接收端端口，字段长度16位。</p><h2 id="包长度（Length）">包长度（Length）</h2><p>该字段保存了UDP首部的长度跟数据的长度之和。单位为字节（8位字节）。</p><h2 id="校验和（Checksum）">校验和（Checksum）</h2><p>校验和是为了提供可靠的UDP首部和数据而设计。在计算校验和时，附加在UDP伪首部与UDP数据报之前。通过在最后一位增加一个“0”将全长增加16倍。此时将UDP首部的校验和字段设置为“0”。然后以16比特为单位进行1的补码和，并将所得到的1的补码和写入校验和字段。</p><p><img data-src="/images/tcp-and-udp-note/%E6%A0%A1%E9%AA%8C%E5%92%8C%E8%AE%A1%E7%AE%97%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84UDP%E4%BC%AA%E9%A6%96%E9%83%A8.png" alt></p><p>接收主机在收到UDP数据报以后，从IP首部获知IP地址信息构造UDP伪首部，再进行校验和计算。校验和制度按的值是校验和字段以外余下部分的1的补码和。因此，包括校验和字段在内的所有数据之和结果为“16位全部为1”时，才会被认为所收到的数据时正确的。</p><p>另外，UDP也可有可能不用校验和。此时，校验和字段中填入0。这种情况下，由于不进行校验和计算，协议处理的开销（在处理实际数据之外，为了进行通信控制的处理而不得不付出的必要的消耗部分）就会降低，从而提高数据转发的速度。然而，如果UDP首部的端口号或是IP首部的IP地址遇到损坏，那么可能会对其他通信造成不好的影响。因此，在互联网中比较推荐使用校验和检查。</p><blockquote><p>校验和计算中计算UDP伪首部的理由<br>TCP/IP中识别一个通信的应用需要5大要素，它们分别是“源IP地址”、“目标IP地址”、“源端口”、“目标端口”、“协议号”。然而，在UDP的首部中只包含它们当中的两项（源端口和目标端口），余下的3项都包含在IP首部里。<br>假定其他3项都被破坏？显然，这极有可能会导致应该收包的应用收不到包，不该收到包的应用却收到了包。<br>为了避免这类问题，有必要验证一个通信中必要的5项识别码是否正确。为此，在校验和的计算中就引入和伪首部的概念。<br>此外，IPv6中的IP首部没有检验和字段。TCP和UDP通过伪首部，得以对5项数字进行校验，从而实现即使在IP首部并不可靠的情况下仍然能够提供可靠的通信传输。</p></blockquote><h1>TCP首部格式</h1><p><img data-src="/images/tcp-and-udp-note/TCP%E6%95%B0%E6%8D%AE%E6%AE%B5%E6%A0%BC%E5%BC%8F.png" alt></p><p>TCP中没有表示包长度和数据长度的字段。可由IP层获知TCP的包长，由TCO的包长可知数据的长度。</p><h2 id="源端口号（Source-Port）-v2">源端口号（Source Port）</h2><p>表示发送端端口号，字段长16位。</p><h2 id="目标端口号（Destination-Port）-v2">目标端口号（Destination Port）</h2><p>表示接收端端口号，字段长度16位。</p><h2 id="序列号（Sequence-Number）">序列号（Sequence Number）</h2><p>字段长32位。序列号（序号）是指发送数据的位置，每发送一次数据，就累加一次该数据字节数的大小。</p><p><font color="DeepPink"><strong>序列号不会从0或1开始，而是建立连接时由计算机生成的随机数作为其初始值，通过SYN包传给接收端主机。</strong></font>然后再将每转发过去的字节数累加到初始值上表示数据的位置。此外，在建立连接和断开连接时发送的SYN包和FIN包虽然并不携带数据，但是也会作为一个字节增加对应的序列号。</p><h2 id="确认应答号（Acknowledgement-Number）">确认应答号（Acknowledgement Number）</h2><p>确认应答号字段长度32位。是指下一次应该受到的数据的序列号。实际上，它是指已收到确认应答号减一为止的数据。发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。</p><h2 id="数据偏移（Data-Offset）">数据偏移（Data Offset）</h2><p>该字段表示TCP所传输的数据部分应该从TCP包的哪个位开始计算，当然也可以把它看做TCP首部的长度。该字段长4位，单位为4字节（即32位）。</p><h2 id="保留（Reserved）">保留（Reserved）</h2><p>该字段主要是为了以后扩展时使用，其长度为4位。一般设置为0，但即使收到的包在该字段不为0，此包也不会被丢弃。</p><h2 id="控制位（Control-Flag）">控制位（Control Flag）</h2><p>字段长为8位，每一位从左至右分别为CWR、ECE、URG、ACK、PSH、RST、SYN、FIN。这些控制标志也叫作控制位。</p><p><img data-src="/images/tcp-and-udp-note/%E6%8E%A7%E5%88%B6%E4%BD%8D.png" alt></p><h3 id="CWR（Congestion-Window-Reduced）">CWR（Congestion Window Reduced）</h3><p>CWR标志与后面的ECE标志都用于IP首部的ECN字段。ECE标志为1时，则通知对方已将拥塞窗口缩小。</p><h3 id="ECE（ECN-Echo）">ECE（ECN-Echo）</h3><p>ECE标志表示ECN-Echo。置为1会通知通信对方，从对方到这边的网络有拥塞。在收到数据包的IP首部中ECN为1时将TCP首部中的ECE设置为1。</p><h3 id="URG（Urgent-Flag）">URG（Urgent Flag）</h3><p>该位为1时，确认应答的字段变为有效。TCP规定除了最初建立连接时的SYN包之外该位必须设置为1。</p><h3 id="PSH（Push-Flag）">PSH（Push Flag）</h3><p>该位为1时，表示需要将受到的数据立即传给上层应用协议。PSH为0时，则不需要立即传而是先进性缓存。</p><h3 id="RST（Reset-Flag）">RST（Reset Flag）</h3><p>该位为1时表示TCP连接中出现异常必须强制断开连接。</p><h3 id="SYN（Synchronize-Flag）">SYN（Synchronize Flag）</h3><p>用于建立连接。SYN为1 表示希望建立连接，并在其序列号的字段进行序列号初始值的设定。</p><h3 id="FIN（Fin-Flag）">FIN（Fin Flag）</h3><p>该位为1时，表示今后不会再有数据发送，希望断开连接。<br>窗口大小（Window Size）</p><h2 id="窗口大小（Window-Size）">窗口大小（Window Size）</h2><p>该字段长为16位。用于通知从相同TCP首部的确认应答号所指位置开始能够接收的数据大小（8位字节）。TCP不允许发送超过此处所示大小的数据。不过，如果窗口为0，则表示可以发送窗口探测，以了解最新的窗口大小。但这个数据必须是1个字节。</p><h2 id="校验和（Checksum）-v2">校验和（Checksum）</h2><p>TCP的校验和与UDP相似，区别在于TCP的校验和无法关闭。<br>TCP和UDP一样在计算校验和的时候使用TCP伪首部。</p><p>接收端在收到TCP数据段以后，从IP首部获取IP地址信息构造TCP伪首部，再进行校验和计算。由于校验和字段里保存着除本字段以外洽谈部分的和的补码值，一次如果计算校验和字段在内的所有数据的16位和以后，得出的结果是“16位全部为1”说明所收到数据是正确的。</p><h2 id="紧急指针（Urgent-Pointer）">紧急指针（Urgent Pointer）</h2><p>略</p><h2 id="选项（Options）">选项（Options）</h2><p>略</p>]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Network</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>[转]理解 Go Channels</title>
    <url>/go-channels.html</url>
    <content><![CDATA[<blockquote><p>Golang Channel</p></blockquote><a id="more"></a><h1>一、视频信息</h1><h2 id="1、视频观看地址">1、视频观看地址</h2><p><a href="https://www.youtube.com/watch?v=KBZlN0izeiY" target="_blank" rel="noopener">https://www.youtube.com/watch?v=KBZlN0izeiY</a></p><h2 id="2、PPT下载地址">2、PPT下载地址</h2><p><a href="http://download.csdn.net/download/xunzaosiyecao/10212884" target="_blank" rel="noopener">http://download.csdn.net/download/xunzaosiyecao/10212884</a></p><h2 id="3、博文">3、博文</h2><p><a href="https://about.sourcegraph.com/go/understanding-channels-kavya-joshi/" target="_blank" rel="noopener">https://about.sourcegraph.com/go/understanding-channels-kavya-joshi/</a></p><h1>二、Go 的并发特性</h1><ul><li>goroutines: 独立执行每个任务，并可能<font color="DeepPink"><strong>并行执行</strong></font></li><li>channels: 用于 goroutines 之间的通讯、同步</li></ul><h2 id="1、一个简单的事务处理的例子">1、一个简单的事务处理的例子</h2><p>对于下面这样的非并发的程序：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">  tasks := getTasks()</span><br><span class="line">  // 处理每个任务</span><br><span class="line">  for _, task := range tasks &#123;</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将其转换为 Go 的并发模式很容易，使用典型的 Task Queue 的模式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">  //  创建带缓冲的 channel</span><br><span class="line">  ch := make(chan Task, 3)</span><br><span class="line">  //  运行固定数量的 workers</span><br><span class="line">  for i := 0; i &lt; numWorkers; i++ &#123;</span><br><span class="line">    go worker(ch)</span><br><span class="line">  &#125;</span><br><span class="line">  //  发送任务到 workers</span><br><span class="line">  hellaTasks := getTasks()</span><br><span class="line">  for _, task := range hellaTasks &#123;</span><br><span class="line">    ch &lt;- task</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">func worker(ch chan Task) &#123;</span><br><span class="line">  for &#123;</span><br><span class="line">    //  接收任务</span><br><span class="line">    task := &lt;-ch</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2、channels-的特性">2、channels 的特性</h2><ul><li>goroutine-safe，多个 goroutine 可以同时访问一个 channel。</li><li>可以用于在 goroutine 之间存储和传递值</li><li>其语义是先入先出（FIFO）</li><li>可以导致 goroutine 的 block 和 unblock</li></ul><h1>三、解析</h1><h2 id="1、构造-channel">1、构造 channel</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//  带缓冲的 channel</span><br><span class="line">ch := make(chan Task, 3)</span><br><span class="line">//  无缓冲的 channel</span><br><span class="line">ch := make(chan Task)</span><br></pre></td></tr></table></figure><p>回顾前面提到的 channel 的特性，特别是前两个。如果忽略内置的 channel，让你设计一个具有 goroutines-safe 并且可以用来存储、传递值的东西，你会怎么做？很多人可能觉得或许可以用一个带锁的队列来做。没错，事实上，channel 内部就是一个带锁的队列。<br><a href="https://golang.org/src/runtime/chan.go" target="_blank" rel="noopener">https://golang.org/src/runtime/chan.go</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type hchan struct &#123;</span><br><span class="line">  ...</span><br><span class="line">  buf      unsafe.Pointer // 指向一个环形队列</span><br><span class="line">  ...</span><br><span class="line">  sendx    uint   // 发送 index</span><br><span class="line">  recvx    uint   // 接收 index</span><br><span class="line">  ...</span><br><span class="line">  lock     mutex  //  互斥量</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>buf 的具体实现很简单，就是一个环形队列的实现。sendx 和 recvx 分别用来记录发送、接收的位置。然后用一个 lock 互斥锁来确保无竞争冒险。</p><p>对于每一个 ch := make(chan Task, 3) 这类操作，都会在<font color="DeepPink"><strong>堆</strong></font>中，分配一个空间，建立并初始化一个 hchan 结构变量，而 ch 则是指向这个 hchan 结构的<font color="DeepPink"><strong>指针</strong></font>。</p><p>因为 ch 本身就是个指针，所以我们才可以在 goroutine 函数调用的时候直接将 ch 传递过去，而不用再 &amp;ch 取指针了，所以所有使用同一个 ch 的 goroutine 都指向了同一个实际的内存空间。</p><h2 id="2、发送、接收">2、发送、接收</h2><p>为了方便描述，我们用 G1 表示 main() 函数的 goroutine，而 G2 表示 worker 的 goroutine。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// G1</span><br><span class="line">func main() &#123;</span><br><span class="line">  ...</span><br><span class="line">  for _, task := range tasks &#123;</span><br><span class="line">    ch &lt;- task</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">// G2</span><br><span class="line">func worker(ch chan Task) &#123;</span><br><span class="line">  for &#123;</span><br><span class="line">    task :=&lt;-ch</span><br><span class="line">    process(task)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-1-简单的发送、接收">2.1 简单的发送、接收</h3><p>那么 G1 中的 ch &lt;- task0 具体是怎么做的呢？</p><ul><li>获取锁</li><li>enqueue(task0)（这里是内存复制 task0）</li><li>释放锁</li></ul><p>这一步很简单，接下来看 G2 的 t := &lt;- ch 是如何读取数据的。</p><ul><li>获取锁</li><li>t = dequeue()（同样，这里也是内存复制）</li><li>释放锁</li></ul><p>这一步也非常简单。但是我们从这个操作中可以看到，所有 goroutine 中共享的部分只有这个 hchan 的结构体，而所有通讯的数据都是<font color="DeepPink"><strong>内存复制</strong></font>。这遵循了 Go 并发设计中很核心的一个理念：</p><blockquote><p>Do not communicate by sharing memory;instead, share memory by communicating</p></blockquote><p>内存复制指的是：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// typedmemmove copies a value of type t to dst from src.</span><br><span class="line">// Must be nosplit, see #16026.</span><br><span class="line">//go:nosplit</span><br><span class="line">func typedmemmove(typ *_type, dst, src unsafe.Pointer) &#123;</span><br><span class="line">    if typ.kind&amp;kindNoPointers == 0 &#123;</span><br><span class="line">        bulkBarrierPreWrite(uintptr(dst), uintptr(src), typ.size)</span><br><span class="line">    &#125;</span><br><span class="line">    // There&apos;s a race here: if some other goroutine can write to</span><br><span class="line">    // src, it may change some pointer in src after we&apos;ve</span><br><span class="line">    // performed the write barrier but before we perform the</span><br><span class="line">    // memory copy. This safe because the write performed by that</span><br><span class="line">    // other goroutine must also be accompanied by a write</span><br><span class="line">    // barrier, so at worst we&apos;ve unnecessarily greyed the old</span><br><span class="line">    // pointer that was in src.</span><br><span class="line">    memmove(dst, src, typ.size)</span><br><span class="line">    if writeBarrier.cgo &#123;</span><br><span class="line">        cgoCheckMemmove(typ, dst, src, 0, typ.size)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3、阻塞和恢复">3、阻塞和恢复</h2><h3 id="3-1-发送方被阻塞">3.1 发送方被阻塞</h3><p>假设 G2 需要很长时间的处理，在此期间，G1 不断的发送任务：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ch &lt;- task1</span><br><span class="line">ch &lt;- task2</span><br><span class="line">ch &lt;- task3</span><br></pre></td></tr></table></figure><p>但是当再一次 ch &lt;- task4 的时候，由于 ch 的缓冲只有 3 个，所以没有地方放了，于是 G1 被 block 了，当有人从队列中取走一个 Task 的时候，G1 才会被恢复。这是我们都知道的，不过我们今天关心的不是发生了什么，而是如何做到的？</p><h3 id="3-2-goroutine-的运行时调度">3.2 goroutine 的运行时调度</h3><p>首先，goroutine <font color="DeepPink"><strong>不是操作系统线程</strong></font>，而是 <font color="DeepPink"><strong>用户空间线程</strong></font>。因此 goroutine 是由 Go runtime 来创建并管理的，而不是 OS，所以要比操作系统线程轻量级。</p><p>当然，goroutine 最终还是要运行于某个线程中的，控制 goroutine 如何运行于线程中的是 Go runtime 中的 scheduler （调度器）。</p><p>Go 的运行时调度器是 M:N 调度模型，既 N 个 goroutine，会运行于 M 个 OS 线程中。换句话说，一个 OS 线程中，可能会运行多个 goroutine。</p><p>Go 的 M:N 调度中使用了3个结构：</p><ul><li>M: OS 线程</li><li>G: goroutine</li><li>P: 调度上下文<ul><li>P 拥有一个运行队列，里面是所有可以运行的 goroutine 及其上下文</li></ul></li></ul><h3 id="3-3-goroutine-被阻塞的具体过程">3.3 goroutine 被阻塞的具体过程</h3><p>那么当 ch &lt;- task4 执行的时候，channel 中已经满了，需要 <font color="DeepPink"><strong>pause</strong></font> G1。这个时候：</p><ol><li>G1 会调用运行时的 gopark</li><li>然后 Go 的运行时调度器就会接管</li><li>将 G1 的状态设置为 waiting</li><li>断开 G1 和 M 之间的关系（switch out)，因此 G1 脱离 M，换句话说，M 空闲了，可以安排别的任务了。</li><li>从 P 的运行队列中，取得一个可运行的 goroutine G</li><li>建立新的 G 和 M 的关系（Switch in)，因此 G 就准备好运行了。</li><li>当调度器返回的时候，新的 G 就开始运行了，而 G1 则不会运行，也就是 block 了。</li></ol><p>从上面的流程中可以看到，<font color="DeepPink"><strong>对于 goroutine 来说，G1 被阻塞了，新的 G 开始运行了；而对于操作系统线程 M 来说，则根本没有被阻塞。</strong></font></p><p>我们知道 OS 线程要比 goroutine 要沉重的多，因此这里尽量避免 OS 线程阻塞，可以提高性能。</p><h3 id="3-4-goroutine-恢复执行的具体过程">3.4 goroutine 恢复执行的具体过程</h3><p>前面理解了阻塞，那么接下来理解一下如何恢复运行。不过，在继续了解如何恢复之前，我们需要先进一步理解 hchan 这个结构。因为，当 channel 不在满的时候，调度器是如何知道该让哪个 goroutine 继续运行呢？而且 goroutine 又是如何知道该从哪取数据呢？</p><p>在 hchan 中，除了之前提到的内容外，还定义有 sendq 和 recvq 两个队列，分别表示等待发送、接收的 goroutine，及其相关信息。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type hchan struct &#123;</span><br><span class="line">  ...</span><br><span class="line">  buf      unsafe.Pointer // 指向一个环形队列</span><br><span class="line">  ...</span><br><span class="line">  sendq    waitq  // 等待发送的队列</span><br><span class="line">  recvq    waitq  // 等待接收的队列</span><br><span class="line">  ...</span><br><span class="line">  lock     mutex  //  互斥量</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 waitq 是一个链表结构的队列，每个元素是一个 sudog 的结构，其定义大致为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type sudog struct &#123;</span><br><span class="line">  g          *g //  正在等候的 goroutine</span><br><span class="line">  elem       unsafe.Pointer // 指向需要接收、发送的元素</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://golang.org/src/runtime/runtime2.go?h=sudog#L270" target="_blank" rel="noopener">https://golang.org/src/runtime/runtime2.go?h=sudog#L270</a></p><p>所以在之前的阻塞 G1 的过程中，实际上：</p><ol><li>G1 会<font color="DeepPink"><strong>给自己</strong></font>创建一个 sudog 的变量</li><li>然后追加到 sendq 的等候队列中，方便将来的<font color="DeepPink"><strong>receiver</strong></font> 来使用这些信息恢复 G1。</li></ol><p>这些都是<font color="DeepPink"><strong>发生在调用调度器之前</strong></font>。</p><p>那么现在开始看一下如何恢复。</p><p>当 G2 调用 t := &lt;- ch 的时候，channel 的状态是，缓冲是满的，而且还有一个 G1 在等候发送队列里，然后 G2 执行下面的操作：</p><ol><li>G2 先执行 dequeue() 从缓冲队列中取得 task1 给 t</li><li>G2 从 sendq 中弹出一个等候发送的 sudog</li><li>将弹出的 sudog 中的 elem 的值 enqueue() 到 buf 中</li><li>将弹出的 sudog 中的 goroutine，也就是 G1，状态从 waiting 改为 runnable<ol><li>然后，G2 需要通知调度器 G1 已经可以进行调度了，因此调用 goready(G1)。</li><li>调度器将 G1 的状态改为 runnable</li><li>调度器将 G1 压入 P 的运行队列，因此在将来的某个时刻调度的时候，G1 就会开始恢复运行。</li><li>返回到 G2</li></ol></li></ol><blockquote><p>注意，这里是由 G2 来负责将 G1 的 elem 压入 buf 的，这是一个优化。这样将来 G1 恢复运行后，就不必再次获取锁、enqueue()、释放锁了。这样就避免了多次锁的开销。</p></blockquote><h3 id="3-5-如果接收方先阻塞呢？">3.5 如果接收方先阻塞呢？</h3><p>更酷的地方是接收方先阻塞的流程。</p><p>如果 G2 先执行了 t := &lt;- ch，此时 buf 是空的，因此 G2 会被阻塞，他的流程是这样：</p><ol><li>G2 给自己创建一个 sudog 结构变量。其中 g 是自己，也就是 G2，而 elem 则指向 t</li><li>将这个 sudog 变量压入 recvq 等候接收队列</li><li>G2 需要告诉 goroutine，自己需要 pause 了，于是调用 gopark(G2)<ol><li>和之前一样，调度器将其 G2 的状态改为 waiting</li><li>断开 G2 和 M 的关系</li><li>从 P 的运行队列中取出一个 goroutine</li><li>建立新的 goroutine 和 M 的关系</li><li>返回，开始继续运行新的 goroutine</li></ol></li></ol><p>这些应该已经不陌生了，那么当 G1 开始发送数据的时候，流程是什么样子的呢？</p><p>G1 可以将 enqueue(task)，然后调用 goready(G2)。不过，我们可以更聪明一些。</p><p>我们根据 hchan 结构的状态，已经知道 task 进入 buf 后，G2 恢复运行后，会读取其值，复制到 t 中。那么 G1 可以根本不走 buf，<font color="DeepPink"><strong>G1 可以直接把数据给 G2</strong></font>。</p><p>Goroutine 通常都有自己的栈，互相之间不会访问对方的栈内数据，<font color="DeepPink"><strong>除了 channel</strong></font>。这里，由于我们已经知道了 t 的地址（通过 elem指针），而且由于 G2 不在运行，所以我们可以很安全的直接赋值。当 G2 恢复运行的时候，既不需要再次获取锁，也不需要对 buf 进行操作。从而节约了内存复制、以及锁操作的开销。</p><h2 id="4、总结">4、总结</h2><ul><li>goroutine-safe<ul><li>hchan 中的 lock mutex</li></ul></li><li>存储、传递值，FIFO<ul><li>通过 hchan 中的环形缓冲区来实现</li></ul></li><li>导致 goroutine 的阻塞和恢复<ul><li>hchan 中的 sendq和recvq，也就是 sudog 结构的链表队列</li><li>调用运行时调度器 (gopark(), goready())</li></ul></li></ul><h1>四、其它 channel 的操作</h1><h2 id="1、无缓冲-channel">1、无缓冲 channel</h2><p>无缓冲的 channel 行为就和前面说的<font color="DeepPink"><strong>直接发送</strong></font>的例子一样：</p><ul><li>接收方阻塞 → 发送方<font color="DeepPink"><strong>直接写入接收方的栈</strong></font></li><li>发送方阻塞 → 接受法<font color="DeepPink"><strong>直接从发送方的 sudog 中读取</strong></font></li></ul><h2 id="2、select">2、select</h2><p><a href="https://golang.org/src/runtime/select.go" target="_blank" rel="noopener">https://golang.org/src/runtime/select.go</a></p><ol><li>先把所有需要操作的 channel 上锁</li><li>给自己创建一个 sudog，然后添加到所有 channel 的 sendq或recvq（取决于是发送还是接收）</li><li>把所有的 channel 解锁，然后 pause 当前调用 select 的 goroutine（gopark()）</li><li>然后当有任意一个 channel 可用时，select 的这个 goroutine 就会被调度执行。</li><li>resuming mirrors the pause sequence</li></ol><h1>五、为什么 Go 会这样设计？</h1><h2 id="1、Simplicity">1、Simplicity</h2><p>更倾向于带锁的队列，而不是无锁的实现。</p><p>性能提升不是凭空而来的，是随着复杂度增加而增加的。</p><p>dvyokov<br>后者虽然性能可能会更好，但是这个优势，并不一定能够战胜随之而来的实现代码的复杂度所带来的劣势。</p><h2 id="2、Performance">2、Performance</h2><ul><li>调用 Go 运行时调度器，这样可以保持 OS 线程不被阻塞跨 goroutine 的栈读、写。</li><li>可以让 goroutine 醒来后不必获取锁。</li><li>可以避免一些内存复制。</li></ul><p>当然，<font color="DeepPink"><strong>任何优势都会有其代价</strong></font>。这里的代价是实现的复杂度，所以这里有更复杂的内存管理机制、垃圾回收以及栈收缩机制。</p><p>在这里性能的提高优势，要比复杂度的提高带来的劣势要大。</p><p>所以在 channel 实现的各种代码中，我们都可以见到这种<font color="DeepPink"><strong>simplicity vs performance</strong></font> 的权衡后的结果。</p><blockquote><p>本文转载自：<br><a href="https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou" target="_blank" rel="noopener">https://blog.lab99.org/post/golang-2017-10-04-video-understanding-channels.html#fa-song-jie-shou</a></p></blockquote>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Go</tag>
        <tag>Channel</tag>
      </tags>
  </entry>
  <entry>
    <title>Go 1.9 Sync Map</title>
    <url>/go-sync-map.html</url>
    <content><![CDATA[<blockquote><p>基于Go 1.9 解析Sync Map</p></blockquote><a id="more"></a><h1>概要</h1><h2 id="Package">Package</h2><p><img data-src="/images/go-sync-map/package.png" alt></p><p>本文主要阐述：Load、Store、Delete，更加详细的阐述可以参考源码描述（建议先大体浏览一下Map源码）。</p><h2 id="实现思路">实现思路</h2><ul><li>空间换时间。 通过冗余的两个数据结构(read、dirty),实现加锁对性能的影响。</li><li>使用只读数据(read)，避免读写冲突。</li><li>动态调整，miss次数多了之后，将dirty数据提升为read。</li><li>double-checking。</li><li>延迟删除。 删除一个键值只是打标记（会将key对应value的pointer置为nil，但read中仍然有这个key:key;value:nil的键值对），只有在提升dirty的时候才清理删除的数据。</li><li>优先从read读取、更新、删除，因为对read的读取不需要锁。</li><li>虽然read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的。</li></ul><h1>数据结构</h1><h2 id="Map">Map</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Map is a concurrent map with amortized-constant-time loads, stores, and deletes.</span><br><span class="line">// It is safe for multiple goroutines to call a Map&apos;s methods concurrently.</span><br><span class="line">//</span><br><span class="line">// It is optimized for use in concurrent loops with keys that are</span><br><span class="line">// stable over time, and either few steady-state stores, or stores</span><br><span class="line">// localized to one goroutine per key.</span><br><span class="line">//</span><br><span class="line">// For use cases that do not share these attributes, it will likely have</span><br><span class="line">// comparable or worse performance and worse type safety than an ordinary</span><br><span class="line">// map paired with a read-write mutex.</span><br><span class="line">//</span><br><span class="line">// The zero Map is valid and empty.</span><br><span class="line">//</span><br><span class="line">// A Map must not be copied after first use.</span><br><span class="line"></span><br><span class="line">//该 Map 是线程安全的，读取，插入，删除也都保持着常数级的时间复杂度。</span><br><span class="line">//多个 goroutines 协程同时调用 Map 方法也是线程安全的。该 Map 的零值是有效的，</span><br><span class="line">//并且零值是一个空的 Map 。线程安全的 Map 在第一次使用之后，不允许被拷贝。</span><br><span class="line">type Map struct &#123;</span><br><span class="line">	mu Mutex</span><br><span class="line"></span><br><span class="line">	// read contains the portion of the map&apos;s contents that are safe for</span><br><span class="line">	// concurrent access (with or without mu held).</span><br><span class="line">	//</span><br><span class="line">	// The read field itself is always safe to load, but must only be stored with</span><br><span class="line">	// mu held.</span><br><span class="line">	//</span><br><span class="line">	// Entries stored in read may be updated concurrently without mu, but updating</span><br><span class="line">	// a previously-expunged entry requires that the entry be copied to the dirty</span><br><span class="line">	// map and unexpunged with mu held.</span><br><span class="line">	</span><br><span class="line">	 // 一个只读的数据结构，因为只读，所以不会有读写冲突。</span><br><span class="line">    // 所以从这个数据中读取总是安全的。</span><br><span class="line">    // 实际上，实际也会更新这个数据的entries,如果entry是未删除的(unexpunged), 并不需要加锁。如果entry已经被删除了，需要加锁，以便更新dirty数据。</span><br><span class="line">	read atomic.Value // readOnly</span><br><span class="line"></span><br><span class="line">	// dirty contains the portion of the map&apos;s contents that require mu to be</span><br><span class="line">	// held. To ensure that the dirty map can be promoted to the read map quickly,</span><br><span class="line">	// it also includes all of the non-expunged entries in the read map.</span><br><span class="line">	//</span><br><span class="line">	// Expunged entries are not stored in the dirty map. An expunged entry in the</span><br><span class="line">	// clean map must be unexpunged and added to the dirty map before a new value</span><br><span class="line">	// can be stored to it.</span><br><span class="line">	//</span><br><span class="line">	// If the dirty map is nil, the next write to the map will initialize it by</span><br><span class="line">	// making a shallow copy of the clean map, omitting stale entries.</span><br><span class="line"></span><br><span class="line">	// dirty数据包含当前的map包含的entries,它包含最新的entries(包括read中未删除的数据,虽有冗余，但是提升dirty字段为read的时候非常快，不用一个一个的复制，而是直接将这个数据结构作为read字段的一部分),有些数据还可能没有移动到read字段中。</span><br><span class="line">    // 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争。</span><br><span class="line">    // 当dirty为空的时候， 比如初始化或者刚提升完，下一次的写操作会复制read字段中未删除的数据到这个数据中。</span><br><span class="line">	dirty map[interface&#123;&#125;]*entry</span><br><span class="line"></span><br><span class="line">	// misses counts the number of loads since the read map was last updated that</span><br><span class="line">	// needed to lock mu to determine whether the key was present.</span><br><span class="line">	//</span><br><span class="line">	// Once enough misses have occurred to cover the cost of copying the dirty</span><br><span class="line">	// map, the dirty map will be promoted to the read map (in the unamended</span><br><span class="line">	// state) and the next store to the map will make a new dirty copy.</span><br><span class="line">	// 当从Map中读取entry的时候，如果read中不包含这个entry,会尝试从dirty中读取，这个时候会将misses加一，</span><br><span class="line">    // 当misses累积到 dirty的长度的时候， 就会将dirty提升为read,避免从dirty中miss太多次。因为操作dirty需要加锁。</span><br><span class="line">	misses int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="readOnly">readOnly</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// readOnly is an immutable struct stored atomically in the Map.read field.</span><br><span class="line">type readOnly struct &#123;</span><br><span class="line">	m       map[interface&#123;&#125;]*entry</span><br><span class="line">	// true if the dirty map contains some key not in m.</span><br><span class="line">	// 如果Map.dirty有些数据不在中的时候，这个值为true</span><br><span class="line">	amended bool </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="entry">entry</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// An entry is a slot in the map corresponding to a particular key.</span><br><span class="line">type entry struct &#123;</span><br><span class="line">	// p points to the interface&#123;&#125; value stored for the entry.</span><br><span class="line">	//</span><br><span class="line">	// If p == nil, the entry has been deleted and m.dirty == nil.</span><br><span class="line">	//</span><br><span class="line">	// If p == expunged, the entry has been deleted, m.dirty != nil, and the entry</span><br><span class="line">	// is missing from m.dirty.</span><br><span class="line">	//</span><br><span class="line">	// Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty</span><br><span class="line">	// != nil, in m.dirty[key].</span><br><span class="line">	//</span><br><span class="line">	// An entry can be deleted by atomic replacement with nil: when m.dirty is</span><br><span class="line">	// next created, it will atomically replace nil with expunged and leave</span><br><span class="line">	// m.dirty[key] unset.</span><br><span class="line">	//</span><br><span class="line">	// An entry&apos;s associated value can be updated by atomic replacement, provided</span><br><span class="line">	// p != expunged. If p == expunged, an entry&apos;s associated value can be updated</span><br><span class="line">	// only after first setting m.dirty[key] = e so that lookups using the dirty</span><br><span class="line">	// map find the entry.</span><br><span class="line"></span><br><span class="line">	//p有三种值：</span><br><span class="line">	//nil: entry已被删除了，并且m.dirty为nil</span><br><span class="line">	//expunged: entry已被删除了，并且m.dirty不为nil，而且这个entry不存在于m.dirty中</span><br><span class="line">	//其它： entry是一个正常的值</span><br><span class="line">	p unsafe.Pointer // *interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Value">Value</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// A Value provides an atomic load and store of a consistently typed value.</span><br><span class="line">// Values can be created as part of other data structures.</span><br><span class="line">// The zero value for a Value returns nil from Load.</span><br><span class="line">// Once Store has been called, a Value must not be copied.</span><br><span class="line">//</span><br><span class="line">// A Value must not be copied after first use.</span><br><span class="line">type Value struct &#123;</span><br><span class="line">	noCopy noCopy</span><br><span class="line"></span><br><span class="line">	v interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="/images/go-sync-map/map%E7%BB%93%E6%9E%84%E5%85%B3%E7%B3%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt></p><h1>Load</h1><p>据指定的key,查找对应的值value,如果不存在，通过ok反映。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123;</span><br><span class="line">	read, _ := m.read.Load().(readOnly)</span><br><span class="line">	e, ok := read.m[key]</span><br><span class="line">	// 如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁</span><br><span class="line">	if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">		m.mu.Lock()</span><br><span class="line">		// Avoid reporting a spurious miss if m.dirty got promoted while we were</span><br><span class="line">		// blocked on m.mu. (If further loads of the same key will not miss, it&apos;s</span><br><span class="line">		// not worth copying the dirty map for this key.)</span><br><span class="line">		//double check,避免加锁的时候m.dirty提升为m.read,这个时候m.read可能被替换了。</span><br><span class="line">		read, _ = m.read.Load().(readOnly)</span><br><span class="line">		e, ok = read.m[key]</span><br><span class="line">		if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">			e, ok = m.dirty[key]</span><br><span class="line">			// Regardless of whether the entry was present, record a miss: this key</span><br><span class="line">			// will take the slow path until the dirty map is promoted to the read</span><br><span class="line">			// map.</span><br><span class="line">			m.missLocked()</span><br><span class="line">		&#125;</span><br><span class="line">		m.mu.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line">	if !ok &#123;</span><br><span class="line">		return nil, false</span><br><span class="line">	&#125;</span><br><span class="line">	return e.load()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (m *Map) missLocked() &#123;</span><br><span class="line">	m.misses++</span><br><span class="line">	if m.misses &lt; len(m.dirty) &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	m.read.Store(readOnly&#123;m: m.dirty&#125;)</span><br><span class="line">	m.dirty = nil</span><br><span class="line">	m.misses = 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="/images/go-sync-map/get%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt></p><h1>Store</h1><p>更新或者新增一个entry</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Store sets the value for a key.</span><br><span class="line">func (m *Map) Store(key, value interface&#123;&#125;) &#123;</span><br><span class="line">	read, _ := m.read.Load().(readOnly)</span><br><span class="line">	// 从 read map 中读取 key 成功并且取出的 entry 尝试存储 value 成功，直接返回</span><br><span class="line">	if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	m.mu.Lock()</span><br><span class="line">	read, _ = m.read.Load().(readOnly)</span><br><span class="line">	if e, ok := read.m[key]; ok &#123;</span><br><span class="line">		if e.unexpungeLocked() &#123;//确保未被标记成删除，即e 指向的是非 nil 的</span><br><span class="line">			// The entry was previously expunged, which implies that there is a</span><br><span class="line">			// non-nil dirty map and this entry is not in it.</span><br><span class="line">			//m.dirty中不存在这个键，所以加入m.dirty</span><br><span class="line">			m.dirty[key] = e</span><br><span class="line">		&#125;</span><br><span class="line">		e.storeLocked(&amp;value)</span><br><span class="line">	&#125; else if e, ok := m.dirty[key]; ok &#123;</span><br><span class="line">		e.storeLocked(&amp;value)</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		if !read.amended &#123;</span><br><span class="line">			// We&apos;re adding the first new key to the dirty map.</span><br><span class="line">			// Make sure it is allocated and mark the read-only map as incomplete.</span><br><span class="line">			m.dirtyLocked()</span><br><span class="line">			m.read.Store(readOnly&#123;m: read.m, amended: true&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">		m.dirty[key] = newEntry(value)</span><br><span class="line">	&#125;</span><br><span class="line">	m.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// tryStore stores a value if the entry has not been expunged.</span><br><span class="line">//</span><br><span class="line">// If the entry is expunged, tryStore returns false and leaves the entry</span><br><span class="line">// unchanged.</span><br><span class="line">func (e *entry) tryStore(i *interface&#123;&#125;) bool &#123;</span><br><span class="line">	p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">	if p == expunged &#123;</span><br><span class="line">		return false</span><br><span class="line">	&#125;</span><br><span class="line">	for &#123;</span><br><span class="line">		if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) &#123;</span><br><span class="line">			return true</span><br><span class="line">		&#125;</span><br><span class="line">		p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">		if p == expunged &#123;</span><br><span class="line">			return false</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">func (m *Map) dirtyLocked() &#123;</span><br><span class="line">	if m.dirty != nil &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	read, _ := m.read.Load().(readOnly)</span><br><span class="line">	m.dirty = make(map[interface&#123;&#125;]*entry, len(read.m))</span><br><span class="line">	for k, e := range read.m &#123;</span><br><span class="line">		if !e.tryExpungeLocked() &#123;</span><br><span class="line">			m.dirty[k] = e</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (e *entry) tryExpungeLocked() (isExpunged bool) &#123;</span><br><span class="line">	p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">	for p == nil &#123;</span><br><span class="line">		 // 将已经删除标记为nil的数据标记为expunged</span><br><span class="line">		if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) &#123;</span><br><span class="line">			return true</span><br><span class="line">		&#125;</span><br><span class="line">		p = atomic.LoadPointer(&amp;e.p)</span><br><span class="line">	&#125;</span><br><span class="line">	return p == expunged</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// unexpungeLocked ensures that the entry is not marked as expunged.</span><br><span class="line">// If the entry was previously expunged, it must be added to the dirty map</span><br><span class="line">// before m.mu is unlocked.</span><br><span class="line"></span><br><span class="line">// unexpungeLocked 函数确保了 entry 没有被标记成已被清除。</span><br><span class="line">// 如果 entry 先前被清除过了，那么在 mutex 解锁之前，它一定要被加入到 dirty map 中</span><br><span class="line"></span><br><span class="line">//如果 entry 的 unexpungeLocked 返回为 true，那么就说明 entry </span><br><span class="line">//之前被标记成了 expunged，并经过 CAS 操作成功把它置为 nil。</span><br><span class="line">func (e *entry) unexpungeLocked() (wasExpunged bool) &#123;</span><br><span class="line">	return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="/images/go-sync-map/store%E6%B5%81%E7%A8%8B%E5%9B%BE.bmp" alt></p><h1>Delete</h1><p>删除一个键值</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Delete deletes the value for a key.</span><br><span class="line">func (m *Map) Delete(key interface&#123;&#125;) &#123;</span><br><span class="line">	read, _ := m.read.Load().(readOnly)</span><br><span class="line">	e, ok := read.m[key]</span><br><span class="line">	if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">		m.mu.Lock()</span><br><span class="line">		read, _ = m.read.Load().(readOnly)</span><br><span class="line">		e, ok = read.m[key]</span><br><span class="line">		if !ok &amp;&amp; read.amended &#123;</span><br><span class="line">			delete(m.dirty, key)</span><br><span class="line">		&#125;</span><br><span class="line">		m.mu.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line">	if ok &#123;</span><br><span class="line">		e.delete()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (e *entry) delete() (hadValue bool) &#123;</span><br><span class="line">	for &#123;</span><br><span class="line">		p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">		// 已标记为删除</span><br><span class="line">		if p == nil || p == expunged &#123;</span><br><span class="line">			return false</span><br><span class="line">		&#125;</span><br><span class="line">		// 原子操作，e.p标记为nil</span><br><span class="line">		if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) &#123;</span><br><span class="line">			return true</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="/images/go-sync-map/delete%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt></p><h1>疑问</h1><h2 id="已经删除的key-再次Load的时候，会怎么样？">已经删除的key,再次Load的时候，会怎么样？</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (e *entry) load() (value interface&#123;&#125;, ok bool) &#123;</span><br><span class="line">	p := atomic.LoadPointer(&amp;e.p)</span><br><span class="line">	if p == nil || p == expunged &#123;</span><br><span class="line">		return nil, false</span><br><span class="line">	&#125;</span><br><span class="line">	return *(*interface&#123;&#125;)(p), true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Map Load方法中调用e.load()时，load方法会识别该值是否已被删除</p><h1>Reference</h1><p><a href="https://studygolang.com/articles/10511" target="_blank" rel="noopener">https://studygolang.com/articles/10511</a><br><a href="http://www.jianshu.com/p/43e66dab535b" target="_blank" rel="noopener">http://www.jianshu.com/p/43e66dab535b</a></p>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Go</tag>
        <tag>Sync</tag>
        <tag>Map</tag>
      </tags>
  </entry>
  <entry>
    <title>cs-interview</title>
    <url>/cs-interview.html</url>
    <content><![CDATA[<h1>Java部分</h1><ol><li>java比较 icompare</li><li>tomcat 热部署 加载方式与双亲委派模型？</li><li>java io api 过滤器模式？</li><li>threadLocal 实现原理？</li><li>tcp ip协议</li><li>服务端如何确定seesion是同一个？</li><li>内存屏障（Memory Barriers）</li><li>lock synchronized ReentrantLock</li><li>jvm JVM的年轻代分为哪几代？年轻代什么时候会进入老年代？</li><li>jvm JVM 垃圾回收算法？（注意年轻代与老年代是不一样的）?</li><li>jvm内存模型 一个变量初始化 怎么分配内存 分配到什么地方？</li><li>不使用双亲委派模型的缺点？</li><li>java 开源序列化框架有哪些？彼此之间有什么区别（优缺点）？</li><li>java.util.concurrent hashmap 相关问题</li><li>JAVA线程sleep和wait方法区别<br><a href="https://jiankunking.blog.csdn.net/article/details/79824353" target="_blank" rel="noopener">https://jiankunking.blog.csdn.net/article/details/79824353</a></li><li>PriorityQueue（优先级队列） 堆相关问题</li><li>常见的负载均衡算法</li><li>java 阻塞队列 相关问题，阻塞具体是如何实现的？</li><li>静态代码块. 构造代码块. 构造函数以及Java类初始化顺序</li><li>java 枚举的实现，内部如何进行存储的？</li><li>静态内部类与普通内部类，在用法. 初始化方面的区别？</li><li>java 原子性 可见性 顺序性是通过什么来保证的?</li><li>java 多线程内共享的模型</li><li>阻塞非阻塞与同步异步</li><li>java nio原理</li><li>读写锁 自旋锁 尝试锁（cas） cas如何保证，查询到修改这个过程是原子的？</li><li>一个类中的静态变量是在类加载的哪个步骤加载的？</li><li>synchronized与ReentrantLock 实现原理区别？</li><li>threadlocal 实现原理？应用场景？</li><li>常见的设计模式</li><li>分布式事务</li><li>线程池工作原理及机制</li><li>线程挂了 保活</li><li>keepalive 保活策略？</li><li>Protocol Buffers 适用场景？</li><li>http tcp 相比多了些什么？有什么不一样的地方？</li><li>http与https区别？加密算法是？</li><li>wait 是释放锁？为什么释放了锁，线程就挂起了。为什么线程wait了就挂起了？</li><li>CMS 垃圾回收</li><li>hashmap 线程不安全 什么时候会出现？会出现什么问题？（hashmap为啥线程不安全？）</li><li>equals 比较原理？</li><li>jvm 内存分布</li><li>arraylist linklist</li><li>interger 为null 转int 会发生什么？</li><li>hashmap与hashset的关系？</li><li>线程与协程的区别？协程的优势？</li><li>JDK8 如何实现协程？</li><li>java lambda 实现原理</li><li>java stream 实现原理</li><li>永久代(permanent generation)与Metaspace</li><li>如何保证GC ROOTS找的全？（比如中G1中）</li><li>G1清理老年代. 年轻代是遍历所有吗？</li><li>可重入锁和不可重入锁？不可重入锁有啥缺陷？</li><li>CPU密集型 Java线程池大小为何会大多被设置成CPU核心数+1？</li><li>什么情况下会出现ClassNotFoundException？</li><li>线程有几种状态？</li><li>如何动态上报JVM信息，以便后期排查OOM等问题？</li><li>ConcurrentHashMap put的时候加锁的是数组上的元素 还是啥？</li><li>Concurrenthashmap中用到的优化技巧？</li><li>LRU如何实现？</li><li>为什么Concurrenthashmap扩容是安全的？</li><li>LinkedHashMap和HashMap 区别？</li><li>CompletableFuture get(long timeout, TimeUnit unit) throws TimeoutException, ExecutionException实现<br><a href="https://medium.com/@sergeykuptsov/how-it-works-in-java-completablefuture-3031dbbca66d" target="_blank" rel="noopener">https://medium.com/@sergeykuptsov/how-it-works-in-java-completablefuture-3031dbbca66d</a><br>64、Java time-based map/cache with expiring keys<br><a href="https://stackoverflow.com/questions/3802370/java-time-based-map-cache-with-expiring-keys" target="_blank" rel="noopener">https://stackoverflow.com/questions/3802370/java-time-based-map-cache-with-expiring-keys</a><br>65、jmap 其实是多个线程 他们之间是怎么通信 dump出数据的？（jmap命令的实现原理）<br>66、GC的年轻代Survivor区，为什么是2个，而不是1个？<br><a href="https://stackoverflow.com/questions/10695298/java-gc-why-two-survivor-regions" target="_blank" rel="noopener">https://stackoverflow.com/questions/10695298/java-gc-why-two-survivor-regions</a><br>简单来说2个Survivor区，就是整理内存碎片的时候方便。<br>67、类加载器及类加载机制</li></ol><h1>MySQL部分</h1><ol><li>mysql 时间 比较无效 原因？</li><li>mysql 数据库 索引 是以什么数据结构形式存储的？</li><li>mysql与sql server 异同点？ 原理上？</li><li>索引顺序对于索引效果的影响？</li><li>数据库索引如何优化（从哪几个方面）？</li><li>mysql优化有哪些？</li><li>比如一个表中有100条数据，a字段的值，是从1到100，我要更新其中的数据，where条件时a&gt;10<br>mysql通过innodb引擎的话，是通过表锁还是行锁？</li><li>mysql mvcc多版本并发控制</li><li>mysql为什么选中B+ TREE而不是B TREE？两种数据结构有什么区别？</li></ol><blockquote><p>B+ 树继承于 B 树，都限定了节点中数据数目和子节点的数目。B 树所有节点都可以映射数据，B+ 树只有叶子节点可以映射数据。<br>单独看这部分设计，看不出 B+ 树的优势。为了只有叶子节点可以映射数据，B+ 树创造了很多冗余的索引（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，而且可以自动平衡，因此 B+ 树的所有叶子节点总是在一个层级上。所以 B+ 树可以用一条链表串联所有的叶子节点，也就是索引数据，这让 B+ 树的范围查找和聚合运算更快。</p></blockquote><ol start="10"><li>mysql 范围查询？索引的数据结构是如何处理的？</li><li>mysql事务提交原理？</li><li>聚集索引 非聚集索引 查询效率？</li><li>mysql 乐观锁 悲观锁</li><li>数据库分库分表</li></ol><h1>基础</h1><ol><li>进程间通信方式有哪些？</li><li>有些信号你能捕获，有些信号你是捕获不了的，捕获不了的信号有哪些？</li><li>zookeeper 可以通过watch，用来做进程间通信，那么zk底层是使用什么方式来实现进程间通信的？依赖操作系统如何实现的？</li><li>socket通信</li><li>keepalive时间限制</li><li>tcp 如何处理粘包问题</li><li>http协议 如何区分header头还有body体</li><li>tcp 协议网络段 协议簇</li><li>一次完整的http请求</li><li>http code 302 304含义</li></ol><h1>线上</h1><ol><li>如何线上debug?比如线上的cpu爆了，这个步骤是？</li><li>线上fd耗光了，如何排查？</li><li>如何定位OOM 问题？</li></ol><h1>Kakfa</h1><ol><li>kafka某个broker上是否可以有无限个topic?或者万级别的topic?</li><li>kafka 设计，还有broker上文件存储</li><li>kakfa是否支持顺序消费消息？</li><li>zk在kafka集群中的作用</li><li>kafka 消费时候可以批量拉取？</li><li>消息队列 选型 为什么选择kafka?</li><li>kafka增加. 删除节点时如何迁移数据？新的数据如何分配？</li><li>kafka写入消息 如何保证回滚或者保证不被消费</li><li>kafka 如何确保消息消费且只消费一次？</li><li>kafka 大批量写入 是怎么传输的？<br>对象缓存池<br><a href="https://www.sohu.com/a/346950666_100123073" target="_blank" rel="noopener">https://www.sohu.com/a/346950666_100123073</a><br><a href="https://github.com/a0x8o/kafka/blob/master/clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPool.java" target="_blank" rel="noopener">https://github.com/a0x8o/kafka/blob/master/clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPool.java</a></li><li>Kafka和RocketMQ存储区别<br><a href="https://www.cnblogs.com/lewis09/p/11168902.html" target="_blank" rel="noopener">https://www.cnblogs.com/lewis09/p/11168902.html</a></li></ol><h1>ElasticSearch</h1><ol><li>在ElasticSearch中，集群(Cluster),节点(Node),分片(Shard),Indices(索引),replicas(备份)之间是什么关系？</li><li>elasticsearch整个建索引. 查询的过程</li><li>elasticsearch如何选举</li><li>ik 是如何进行分词的？</li><li>es Scroll 原理？ Search After原理？</li><li>es 副本作用？</li><li>mysql elasticsearch 查询对比？（比如整个搜索流程）</li><li>elasticsearch match filter 差异点？</li><li>es 评分机制/原理</li></ol><h1>OpenTSDB</h1><ol><li>OpenTSDB与HBase 关系</li></ol><h1>脑经急转弯</h1><ol><li>判断一个整数是2的N次方？</li><li>二叉树拷贝（非递归）</li><li>BitMap算法（应用）</li></ol><h1>其他</h1><ol><li>分布式锁有哪些实现方式？</li><li>分布式事务</li><li>异地多活</li><li>zookeeper集群 当一个节点挂了一天，当再次启动的时候，如何识别哪个是leader？</li><li>有什么知名的开源apm(Application Performance Management)工具吗？</li><li>pinpoint 原理？</li><li>consul template作用？如何与prometheus交互的？</li></ol><h1>金融</h1><ol><li>同业拆借</li><li>信用卡消费一笔钱，是如何到收款人的账户的？（整个流转过程）</li><li>复式记账</li></ol><h1>Spring</h1><ol><li>spring 注入 接口即如何注入一个接口的多个实现类？</li><li>spring 中用到的设计模式？spring中一次完整的http请求链路？</li><li>手写stater</li><li>spring 类自动加载机制</li><li>spring fegin 接口相互调用异常问题解决，有没有熔断啥的配置？</li></ol>]]></content>
      <categories>
        <category>Interview</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Spring AOP与IOC的个人思考</title>
    <url>/spring-aop-ioc-think.html</url>
    <content><![CDATA[<p>在阅读本文前，强烈建议阅读：<br><a href="http://jiankunking.com/java-jdk-aop.html">Java JDK 动态代理（AOP）使用及实现原理分析</a></p><a id="more"></a><p>AOP是Spring提供的关键特性之一。AOP即面向切面编程，是OOP编程的有效补充。使用AOP技术，可以将一些系统性相关的编程工作，独立提取出来，独立实现，然后通过切面切入进系统。从而避免了在业务逻辑的代码中混入很多的系统相关的逻辑——比如权限管理，事物管理，日志记录等等。这些系统性的编程工作都可以独立编码实现，然后通过AOP技术切入进系统即可。从而达到了将不同的关注点分离出来的效果。<br><img data-src="/images/spring-jdk-aop-think/AOP%E7%A4%BA%E6%84%8F.png" alt><br>本文深入剖析Spring的AOP的原理。</p><h1>一、AOP 的实现原理</h1><p>AOP分为静态AOP和动态AOP。</p><p>静态AOP是指AspectJ实现的AOP，他是将切面代码直接编译到Java类文件中。</p><p>动态AOP是指将切面代码进行动态织入实现的AOP。</p><p>Spring的AOP为动态AOP，实现的技术为：JDK提供的动态代理技术 和 CGLIB(动态字节码增强技术)。尽管实现技术不一样，但都是基于代理模式，都是生成一个代理对象。</p><h2 id="1、JDK动态代理">1、JDK动态代理</h2><p>JDK部分解析参考：<br><a href="https://jiankunking.com/java-jdk-aop.html">Java JDK 动态代理（AOP）使用及实现原理分析</a></p><h2 id="2、CGLIB（code-generate-libary）">2、CGLIB（code generate libary）</h2><p>字节码生成技术实现AOP，其实就是继承被代理对象，然后Override需要被代理的方法，在覆盖该方法时，自然是可以插入我们自己的代码的。</p><p><font color="DeepPink"><strong>因为需要Override被代理对象的方法，所以自然CGLIB技术实现AOP时，就必须要求需要被代理的方法不能是final方法，因为final方法不能被子类覆盖。</strong></font></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package net.aazj.aop;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line">import net.sf.cglib.proxy.Enhancer;</span><br><span class="line">import net.sf.cglib.proxy.MethodInterceptor;</span><br><span class="line">import net.sf.cglib.proxy.MethodProxy;</span><br><span class="line"></span><br><span class="line">public class CGProxy implements MethodInterceptor&#123;</span><br><span class="line">    private Object target;    // 被代理对象</span><br><span class="line">    public CGProxy(Object target)&#123;</span><br><span class="line">        this.target = target;</span><br><span class="line">    &#125;</span><br><span class="line">    public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;</span><br><span class="line">        System.out.println(&quot;do sth before....&quot;);</span><br><span class="line">        Object result = proxy.invokeSuper(obj, args);</span><br><span class="line">        System.out.println(&quot;do sth after....&quot;);</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line">    public Object getProxyObject() &#123;</span><br><span class="line">        Enhancer enhancer = new Enhancer();</span><br><span class="line">        // 设置父类</span><br><span class="line">        enhancer.setSuperclass(this.target.getClass());    </span><br><span class="line">        // 设置回调</span><br><span class="line">        enhancer.setCallback(this);    // 在调用父类方法时，回调 this.intercept()</span><br><span class="line">        // 创建代理对象</span><br><span class="line">        return enhancer.create();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface UserService &#123;</span><br><span class="line">    public void addUser(User user);</span><br><span class="line">    public User getUser(int id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class UserServiceImpl implements UserService &#123;</span><br><span class="line">    public void addUser(User user) &#123;</span><br><span class="line">        System.out.println(&quot;add user into database.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public User getUser(int id) &#123;</span><br><span class="line">        User user = new User();</span><br><span class="line">        user.setId(id);</span><br><span class="line">        System.out.println(&quot;getUser from database.&quot;);</span><br><span class="line">        return user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class CGProxyTest &#123;</span><br><span class="line">    public static void main(String[] args)&#123;</span><br><span class="line">         // 被代理的对象</span><br><span class="line">        Object proxyedObject = new UserServiceImpl();   </span><br><span class="line">        CGProxy cgProxy = new CGProxy(proxyedObject);</span><br><span class="line">        UserService proxyObject = (UserService) cgProxy.getProxyObject();</span><br><span class="line">        proxyObject.getUser(1);</span><br><span class="line">        proxyObject.addUser(new User());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">do sth before....</span><br><span class="line">getUser from database.</span><br><span class="line">do sth after....</span><br><span class="line">do sth before....</span><br><span class="line">add user into database.</span><br><span class="line">do sth after....</span><br></pre></td></tr></table></figure><p>它的原理是：生成一个父类<br>enhancer.setSuperclass(this.target.getClass())<br>的子类enhancer.create(),然后对父类的方法进行拦截enhancer.setCallback(this).</p><h1>二、思考</h1><p>从以上两种代理方式可以看出，<font color="DeepPink"><strong>实现AOP的关键是：动态代理，即将需要用的接口、类再包装一层，通过动态修改字节码文件实现各种拦截与通知。</strong></font></p><p><font color="DeepPink"><strong>注意，两者(JDK动态代理、CGLIB)都需要：要代理真实对象的实例。</strong></font></p><p>比如：在Spring MVC的Controller层一般@Autowired是Service接口，但带有@Service标识的却是实现Service接口的实体类，这样对于JDK动态代理来说已经足以生成代理类了(其实，不过是cglib还是jdk的动态代理，你直接@Autowired Service接口实现类，也是可以注入成功的，但不如注入Service接口灵活)，大家在跟踪代码的时候可以看一下Spring注入的bean真正的类型，你就可以发现它是代理生成的实例。</p><p>比如这种：</p><p><img data-src="/images/spring-jdk-aop-think/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B.png" alt></p><p>带有注解标识的接口或者在Spring.XML中配置的bean会在Spring初始化的时候，被Spring通过反射加载实例化到Spring容器中。</p><blockquote><p>做过Client/Server架构开发的朋友应该知道，在Application运行过程中一般都会有一个应用上下文Context，一般将一些系统信息放在里面，比如一些登录信息、WCF连接实例等。这些信息在系统的任何地方都可以取到（其实就是一些顶级变量集合，生命周期最长的一些家伙）。</p></blockquote><blockquote><p>换个角度想一下，如果我们在Application初始化的时候，用反射（获取要代理对象的实例）和动态代理获取有注解标识或者在xml中配置bean的实例，并放到应用上下文Context中，在需要的地方都能取到，这不就是一个简单版的Spring 容器吗？</p></blockquote>]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>JDK</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title>Java HashMap</title>
    <url>/java-hashmap.html</url>
    <content><![CDATA[<blockquote><p>代码基于 Jdk1.8</p></blockquote><a id="more"></a><p>最近在工作用到Map等一系列的集合，于是，想仔细看一下其具体实现。</p><h1>结构</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;</span><br><span class="line">    implements Map&lt;K,V&gt;, Cloneable, Serializable</span><br></pre></td></tr></table></figure><h2 id="抽象类AbstractMap">抽象类AbstractMap</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;</span><br></pre></td></tr></table></figure><p>该类实现了Map接口，具体结构如下：<br><img data-src="/images/java-hashmap/AbstractMap%E7%BB%93%E6%9E%84.png" alt><br>该类代码很简单，不再赘述。</p><h2 id="序列化接口：Serializable">序列化接口：Serializable</h2><p>该接口没有什么好说的，但通过该接口，就解释了为什么HashMap总一些字段是用transient来修饰。</p><blockquote><p>一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p></blockquote><h1>阅读JDK中类注释</h1><h2 id="HashMap是无序的">HashMap是无序的</h2><p>如果希望保持元素的输入顺序应该使用LinkedHashMap</p><h2 id="除了非同步和允许使用null之外，HashMap与Hashtable基本一致。">除了非同步和允许使用null之外，HashMap与Hashtable基本一致。</h2><p>此处的非同步指的是多线程访问，并至少一个线程修改HashMap结构。结构修改包括任何新增、删除映射，但仅仅修改HashMap中已存在项值得操作不属于结构修改。</p><h2 id="初始容量与加载因子是影响HashMap的两个重要因素。">初始容量与加载因子是影响HashMap的两个重要因素。</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public HashMap(int initialCapacity, float loadFactor)</span><br></pre></td></tr></table></figure><p>初始容量默认值：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The default initial capacity - MUST be a power of two.</span><br><span class="line"> */</span><br><span class="line">static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16</span><br></pre></td></tr></table></figure><p>加载因子默认值：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The load factor used when none specified in constructor.</span><br><span class="line"> */</span><br><span class="line">static final float DEFAULT_LOAD_FACTOR = 0.75f;</span><br></pre></td></tr></table></figure><p>容量是HashMap在创建时“桶”的数量，而初始容量是哈希表在创建时分配的空间大小。加载因子是哈希表在其容量自动增加时能达到多满的衡量尺度（比如默认为0.75，即桶中数据达到3/4就不能再放数据了）。</p><blockquote><p>默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。<br>当重新调整HashMap大小的时候，会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。<br>所以 HashMap应该避免在多线程环境下使用。</p></blockquote><p>默认0.75这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。</p><h2 id="存储形式">存储形式</h2><p>链表形式存储？树形结构？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">* This map usually acts as a binned (bucketed) hash table, but</span><br><span class="line">* when bins get too large, they are transformed into bins of</span><br><span class="line">* TreeNodes, each structured similarly to those in</span><br><span class="line">* java.util.TreeMap. Most methods try to use normal bins, but</span><br><span class="line">* relay to TreeNode methods when applicable (simply by checking</span><br><span class="line">* instanceof a node).</span><br></pre></td></tr></table></figure><h1>源码阅读</h1><h2 id="添加元素">添加元素</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Associates the specified value with the specified key in this map.</span><br><span class="line">    * If the map previously contained a mapping for the key, the old</span><br><span class="line">    * value is replaced.</span><br><span class="line">    *</span><br><span class="line">    * @param key key with which the specified value is to be associated</span><br><span class="line">    * @param value value to be associated with the specified key</span><br><span class="line">    * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or</span><br><span class="line">    *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.</span><br><span class="line">    *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map</span><br><span class="line">    *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)</span><br><span class="line">    */</span><br><span class="line">   public V put(K key, V value) &#123;</span><br><span class="line">       return putVal(hash(key), key, value, false, true);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Implements Map.put and related methods</span><br><span class="line">    *</span><br><span class="line">    * @param hash hash for key</span><br><span class="line">    * @param key the key</span><br><span class="line">    * @param value the value to put</span><br><span class="line">    * @param onlyIfAbsent if true, don&apos;t change existing value</span><br><span class="line">    * @param evict if false, the table is in creation mode.</span><br><span class="line">    * @return previous value, or null if none</span><br><span class="line">    */</span><br><span class="line">   final V putVal(int hash, K key, V value, boolean onlyIfAbsent,</span><br><span class="line">                  boolean evict) &#123;</span><br><span class="line">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;</span><br><span class="line">       //hashmap第一次添加元素，调用resize()方法初始化table</span><br><span class="line">       if ((tab = table) == null || (n = tab.length) == 0)</span><br><span class="line">           n = (tab = resize()).length;</span><br><span class="line">       //通过与运算判断tab[hash]位置是否有值</span><br><span class="line">       //从newNode这里可以看出，hashmap中key value是以Node&lt;K,V&gt;实例的形式存放的</span><br><span class="line">       if ((p = tab[i = (n - 1) &amp; hash]) == null)</span><br><span class="line">           tab[i] = newNode(hash, key, value, null);</span><br><span class="line">       //tab[i]有元素，则需要遍历结点后再添加</span><br><span class="line">       else &#123;</span><br><span class="line">           Node&lt;K,V&gt; e; K k;</span><br><span class="line">           // hash、key均等，说明待插入元素和第一个元素相等，直接更新</span><br><span class="line">           if (p.hash == hash &amp;&amp;</span><br><span class="line">               ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">               e = p;</span><br><span class="line">           else if (p instanceof TreeNode)//如果p类型为TreeNode，调用树的添加元素方法(红黑树冲突插入)</span><br><span class="line">               e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span><br><span class="line">           else &#123;</span><br><span class="line">               //不是TreeNode,即为链表,遍历链表，查找给定关键字 </span><br><span class="line">               for (int binCount = 0; ; ++binCount) &#123;</span><br><span class="line">                   if ((e = p.next) == null) &#123;</span><br><span class="line">                   //到达链表的尾端也没有找到key值相同的节点，则生成一个新的Node</span><br><span class="line">                       p.next = newNode(hash, key, value, null);</span><br><span class="line">                       //创建新节点后若超出树形化阈值，则转换为树形存储  </span><br><span class="line">                       if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st</span><br><span class="line">                           treeifyBin(tab, hash);//当桶中链表的数量&gt;=9的时候，底层则改为红黑树实现</span><br><span class="line">                       break;</span><br><span class="line">                   &#125;</span><br><span class="line">                   //如果找到关键字相同的结点  </span><br><span class="line">                   if (e.hash == hash &amp;&amp;</span><br><span class="line">                       ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                       break;</span><br><span class="line">                   //更新p指向下一个节点</span><br><span class="line">                   p = e;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           // e不为空，即map中存在要添加的关键字  </span><br><span class="line">           if (e != null) &#123; // existing mapping for key</span><br><span class="line">               V oldValue = e.value;</span><br><span class="line">               if (!onlyIfAbsent || oldValue == null)</span><br><span class="line">                   e.value = value;</span><br><span class="line">               afterNodeAccess(e);</span><br><span class="line">               return oldValue;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       ++modCount;</span><br><span class="line">       if (++size &gt; threshold)</span><br><span class="line">           resize();//扩容</span><br><span class="line">       afterNodeInsertion(evict);</span><br><span class="line">       return null;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>小注：<br>1、回调</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">afterNodeAccess(e);</span><br><span class="line">afterNodeInsertion(evict);</span><br></pre></td></tr></table></figure><p>是为LinkedHashMap回调准备的。<br>2、计算hash值</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Computes key.hashCode() and spreads (XORs) higher bits of hash</span><br><span class="line"> * to lower.  Because the table uses power-of-two masking, sets of</span><br><span class="line"> * hashes that vary only in bits above the current mask will</span><br><span class="line"> * always collide. (Among known examples are sets of Float keys</span><br><span class="line"> * holding consecutive whole numbers in small tables.)  So we</span><br><span class="line"> * apply a transform that spreads the impact of higher bits</span><br><span class="line"> * downward. There is a tradeoff between speed, utility, and</span><br><span class="line"> * quality of bit-spreading. Because many common sets of hashes</span><br><span class="line"> * are already reasonably distributed (so don&apos;t benefit from</span><br><span class="line"> * spreading), and because we use trees to handle large sets of</span><br><span class="line"> * collisions in bins, we just XOR some shifted bits in the</span><br><span class="line"> * cheapest possible way to reduce systematic lossage, as well as</span><br><span class="line"> * to incorporate impact of the highest bits that would otherwise</span><br><span class="line"> * never be used in index calculations because of table bounds.</span><br><span class="line"> */</span><br><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">	int h;</span><br><span class="line">	return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>‘&gt;&gt;&gt;’：无符号右移，忽略符号位，空位都以0补齐</p><blockquote><p>value &gt;&gt;&gt; num – num 指定要移位值value 移动的位数。</p></blockquote><p>即按二进制形式把所有的数字向右移动对应位数，低位移出（舍弃），高位的空位补零。对于正数来说和带符号右移相同，对于负数来说不同。</p><p>^异或：两个操作数的位中，相同则结果为0，不同则结果为1。</p><p>这也正好解释了为什么HashMap底层数组的长度总是 2 的 n 次方。因为这样（数组长度-1）正好相当于一个“低位掩码”。“异或”操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。<br>以初始长度16为例，16-1=15。<br>2进制表示是00000000 00000000 00001111。<br>和某hash值做“异或”操作如下，结果就是截取了最低的四位值。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">10100101 11000100 00100101</span><br><span class="line">00000000 00000000 00001111</span><br><span class="line">----------------------------------</span><br><span class="line">00000000 00000000 00000101    //高位全部归零，只保留末四位</span><br></pre></td></tr></table></figure><p>更详细的步骤如下：</p><p><img data-src="/images/java-hashmap/%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97.png" alt></p><p>3、存储结构</p><p><img data-src="/images/java-hashmap/hashmap%E7%BB%93%E6%9E%84.png" alt><br><img data-src="/images/java-hashmap/table%E6%95%B0%E7%BB%84.png" alt></p><h2 id="获取元素">获取元素</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns the value to which the specified key is mapped,</span><br><span class="line">    * or &#123;@code null&#125; if this map contains no mapping for the key.</span><br><span class="line">    *</span><br><span class="line">    * &lt;p&gt;More formally, if this map contains a mapping from a key</span><br><span class="line">    * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null :</span><br><span class="line">    * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise</span><br><span class="line">    * it returns &#123;@code null&#125;.  (There can be at most one such mapping.)</span><br><span class="line">    *</span><br><span class="line">    * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt;</span><br><span class="line">    * indicate that the map contains no mapping for the key; it&apos;s also</span><br><span class="line">    * possible that the map explicitly maps the key to &#123;@code null&#125;.</span><br><span class="line">    * The &#123;@link #containsKey containsKey&#125; operation may be used to</span><br><span class="line">    * distinguish these two cases.</span><br><span class="line">    *</span><br><span class="line">    * @see #put(Object, Object)</span><br><span class="line">    */</span><br><span class="line">   public V get(Object key) &#123;</span><br><span class="line">       Node&lt;K,V&gt; e;</span><br><span class="line">       return (e = getNode(hash(key), key)) == null ? null : e.value;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">    * Implements Map.get and related methods</span><br><span class="line">    *</span><br><span class="line">    * @param hash hash for key</span><br><span class="line">    * @param key the key</span><br><span class="line">    * @return the node, or null if none</span><br><span class="line">    */</span><br><span class="line">   final Node&lt;K,V&gt; getNode(int hash, Object key) &#123;</span><br><span class="line">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;</span><br><span class="line">       if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">           //hash &amp; length-1 定位数组下标</span><br><span class="line">           (first = tab[(n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">           if (first.hash == hash &amp;&amp; // always check first node</span><br><span class="line">               ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">               return first;</span><br><span class="line">           if ((e = first.next) != null) &#123;</span><br><span class="line">               //第一个节点是TreeNode,则采用位桶+红黑树结构， </span><br><span class="line">               //调用TreeNode.getTreeNode(hash,key), </span><br><span class="line">               //遍历红黑树，得到节点的value  </span><br><span class="line">               if (first instanceof TreeNode)</span><br><span class="line">                   return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">               do &#123;</span><br><span class="line">                   if (e.hash == hash &amp;&amp;</span><br><span class="line">                       ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                       return e;</span><br><span class="line">               &#125; while ((e = e.next) != null);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       return null;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>树节点的查找：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Calls find for root node.</span><br><span class="line"> */</span><br><span class="line">final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123;</span><br><span class="line">    return ((parent != null) ? root() : this).find(h, k, null);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Finds the node starting at root p with the given hash and key.</span><br><span class="line"> * The kc argument caches comparableClassFor(key) upon first use</span><br><span class="line"> * comparing keys.</span><br><span class="line"> *通过hash值的比较，递归的去遍历红黑树，</span><br><span class="line"> compareableClassFor(Class k)：判断实例k对应的类是否实现了Comparable接口，如果实现了该接口并</span><br><span class="line"> 在某些时候如果红黑树节点的元素are of the same &quot;class C implements Comparable&lt;C&gt;&quot; type  </span><br><span class="line"> *利用他们的compareTo()方法来比较大小，这里需要通过反射机制来check他们到底是不是属于同一个类,是不是具有可比较性.</span><br><span class="line"> */</span><br><span class="line">final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123;</span><br><span class="line">    TreeNode&lt;K,V&gt; p = this;</span><br><span class="line">    do &#123;</span><br><span class="line">        int ph, dir; K pk;</span><br><span class="line">        TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q;</span><br><span class="line">        if ((ph = p.hash) &gt; h)</span><br><span class="line">            p = pl;</span><br><span class="line">        else if (ph &lt; h)</span><br><span class="line">            p = pr;</span><br><span class="line">        else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))</span><br><span class="line">            return p;</span><br><span class="line">        else if (pl == null)</span><br><span class="line">            p = pr;</span><br><span class="line">        else if (pr == null)</span><br><span class="line">            p = pl;</span><br><span class="line">        else if ((kc != null ||</span><br><span class="line">                  (kc = comparableClassFor(k)) != null) &amp;&amp;</span><br><span class="line">                 (dir = compareComparables(kc, k, pk)) != 0)</span><br><span class="line">            p = (dir &lt; 0) ? pl : pr;</span><br><span class="line">        else if ((q = pr.find(h, k, kc)) != null)</span><br><span class="line">            return q;</span><br><span class="line">        else</span><br><span class="line">            p = pl;</span><br><span class="line">    &#125; while (p != null);</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="元素包含containsKey">元素包含containsKey</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the</span><br><span class="line"> * specified key.</span><br><span class="line"> *</span><br><span class="line"> * @param   key   The key whose presence in this map is to be tested</span><br><span class="line"> * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified</span><br><span class="line"> * key.</span><br><span class="line"> */</span><br><span class="line">public boolean containsKey(Object key) &#123;</span><br><span class="line">    return getNode(hash(key), key) != null;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line"> * Implements Map.get and related methods</span><br><span class="line"> *</span><br><span class="line"> * @param hash hash for key</span><br><span class="line"> * @param key the key</span><br><span class="line"> * @return the node, or null if none</span><br><span class="line"> */</span><br><span class="line">final Node&lt;K,V&gt; getNode(int hash, Object key) &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;</span><br><span class="line">    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">        //判断tab[hash]位置是否有值</span><br><span class="line">        (first = tab[(n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">        if (first.hash == hash &amp;&amp; // always check first node</span><br><span class="line">            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">            return first;</span><br><span class="line">        if ((e = first.next) != null) &#123;</span><br><span class="line">            if (first instanceof TreeNode)</span><br><span class="line">                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">            //遍历寻找 </span><br><span class="line">            do &#123;</span><br><span class="line">                if (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                    return e;</span><br><span class="line">            &#125; while ((e = e.next) != null);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br><span class="line"> /**</span><br><span class="line">  * Calls find for root node.</span><br><span class="line">  */</span><br><span class="line">  final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123;</span><br><span class="line">      return ((parent != null) ? root() : this).find(h, k, null);</span><br><span class="line">   &#125;</span><br><span class="line"> 	/**</span><br><span class="line">     * Returns root of tree containing this node.</span><br><span class="line">     * 获取红黑树的根</span><br><span class="line">     */</span><br><span class="line">    final TreeNode&lt;K,V&gt; root() &#123;</span><br><span class="line">        for (TreeNode&lt;K,V&gt; r = this, p;;) &#123;</span><br><span class="line">            if ((p = r.parent) == null)</span><br><span class="line">                return r;</span><br><span class="line">            r = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	/**</span><br><span class="line">     * Finds the node starting at root p with the given hash and key.</span><br><span class="line">     * The kc argument caches comparableClassFor(key) upon first use</span><br><span class="line">     * comparing keys.</span><br><span class="line">     */</span><br><span class="line">    final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123;// k即key，kc为null</span><br><span class="line">        TreeNode&lt;K,V&gt; p = this;</span><br><span class="line">        do &#123;</span><br><span class="line">            int ph, dir; K pk;</span><br><span class="line">            TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q;</span><br><span class="line">            if ((ph = p.hash) &gt; h)// ph存当前节点hash</span><br><span class="line">                p = pl;</span><br><span class="line">            else if (ph &lt; h) // 所查hash比当前节点hash大</span><br><span class="line">                p = pr;// 查右子树</span><br><span class="line">            else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))</span><br><span class="line">                return p;// hash、key均相同，【找到了！】返回当前节点</span><br><span class="line">            else if (pl == null)// hash等，key不等，且当前节点的左节点null</span><br><span class="line">                p = pr;//查右子树</span><br><span class="line">            else if (pr == null)</span><br><span class="line">                p = pl;</span><br><span class="line">           //get-&gt;getTreeNode传递的kc为null。||逻辑或,短路运算,有真即可</span><br><span class="line">           // false || (false &amp;&amp; ？？)</span><br><span class="line">            else if ((kc != null ||</span><br><span class="line">                      (kc = comparableClassFor(k)) != null) &amp;&amp;</span><br><span class="line">                     (dir = compareComparables(kc, k, pk)) != 0)</span><br><span class="line">                p = (dir &lt; 0) ? pl : pr;</span><br><span class="line">            else if ((q = pr.find(h, k, kc)) != null)</span><br><span class="line">                return q;</span><br><span class="line">            else</span><br><span class="line">                p = pl;</span><br><span class="line">        &#125; while (p != null);</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="移除remove">移除remove</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Removes the mapping for the specified key from this map if present.</span><br><span class="line">   *</span><br><span class="line">   * @param  key key whose mapping is to be removed from the map</span><br><span class="line">   * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or</span><br><span class="line">   *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.</span><br><span class="line">   *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map</span><br><span class="line">   *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)</span><br><span class="line">   */</span><br><span class="line">  public V remove(Object key) &#123;</span><br><span class="line">      Node&lt;K,V&gt; e;</span><br><span class="line">      return (e = removeNode(hash(key), key, null, false, true)) == null ?</span><br><span class="line">          null : e.value;</span><br><span class="line">  &#125;</span><br><span class="line">   /**</span><br><span class="line">   * Implements Map.remove and related methods</span><br><span class="line">   *</span><br><span class="line">   * @param hash hash for key</span><br><span class="line">   * @param key the key</span><br><span class="line">   * @param value the value to match if matchValue, else ignored</span><br><span class="line">   * @param matchValue if true only remove if value is equal</span><br><span class="line">   * @param movable if false do not move other nodes while removing</span><br><span class="line">   * @return the node, or null if none</span><br><span class="line">   */</span><br><span class="line">  final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,</span><br><span class="line">                             boolean matchValue, boolean movable) &#123;</span><br><span class="line">      Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index;</span><br><span class="line">      if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</span><br><span class="line">          (p = tab[index = (n - 1) &amp; hash]) != null) &#123;</span><br><span class="line">          Node&lt;K,V&gt; node = null, e; K k; V v;</span><br><span class="line">          if (p.hash == hash &amp;&amp;</span><br><span class="line">          //先比较内存地址，如果地址不一致，再调用equals进行比较</span><br><span class="line">              ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">              node = p;</span><br><span class="line">          else if ((e = p.next) != null) &#123;</span><br><span class="line">              //如果是以红黑树处理冲突，则通过getTreeNode查找</span><br><span class="line">              if (p instanceof TreeNode)</span><br><span class="line">                  node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">              else &#123;</span><br><span class="line">                   //如果是以链式的方式处理冲突，则通过遍历链表来寻找节点</span><br><span class="line">                  do &#123;</span><br><span class="line">                      if (e.hash == hash &amp;&amp;</span><br><span class="line">                          ((k = e.key) == key ||</span><br><span class="line">                           (key != null &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                          node = e;</span><br><span class="line">                          break;</span><br><span class="line">                      &#125;</span><br><span class="line">                      p = e;</span><br><span class="line">                  &#125; while ((e = e.next) != null);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">           //比对找到的key的value跟要删除的是否匹配</span><br><span class="line">          if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                               (value != null &amp;&amp; value.equals(v)))) &#123;</span><br><span class="line">              if (node instanceof TreeNode)</span><br><span class="line">                  ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);</span><br><span class="line">              else if (node == p)</span><br><span class="line">                  tab[index] = node.next;</span><br><span class="line">              else</span><br><span class="line">                  p.next = node.next;</span><br><span class="line">              //已从结构上修改 此列表的次数</span><br><span class="line">              ++modCount;</span><br><span class="line">              --size;</span><br><span class="line">              //回调</span><br><span class="line">              afterNodeRemoval(node);</span><br><span class="line">              return node;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      return null;</span><br><span class="line">  &#125;</span><br><span class="line">      /**</span><br><span class="line">       * Removes the given node, that must be present before this call.</span><br><span class="line">       * This is messier than typical red-black deletion code because we</span><br><span class="line">       * cannot swap the contents of an interior node with a leaf</span><br><span class="line">       * successor that is pinned by &quot;next&quot; pointers that are accessible</span><br><span class="line">       * independently during traversal. So instead we swap the tree</span><br><span class="line">       * linkages. If the current tree appears to have too few nodes,</span><br><span class="line">       * the bin is converted back to a plain bin. (The test triggers</span><br><span class="line">       * somewhere between 2 and 6 nodes, depending on tree structure).</span><br><span class="line">       */</span><br><span class="line">      final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,</span><br><span class="line">                                boolean movable) &#123;</span><br><span class="line">          int n;</span><br><span class="line">          if (tab == null || (n = tab.length) == 0)</span><br><span class="line">              return;</span><br><span class="line">          int index = (n - 1) &amp; hash;</span><br><span class="line">          TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl;</span><br><span class="line">          TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev;</span><br><span class="line">          if (pred == null)</span><br><span class="line">              tab[index] = first = succ;</span><br><span class="line">          else</span><br><span class="line">              pred.next = succ;</span><br><span class="line">          if (succ != null)</span><br><span class="line">              succ.prev = pred;</span><br><span class="line">          if (first == null)</span><br><span class="line">              return;</span><br><span class="line">          if (root.parent != null)</span><br><span class="line">              root = root.root();</span><br><span class="line">          if (root == null || root.right == null ||</span><br><span class="line">              (rl = root.left) == null || rl.left == null) &#123;</span><br><span class="line">              tab[index] = first.untreeify(map);  // too small</span><br><span class="line">              return;</span><br><span class="line">          &#125;</span><br><span class="line">          TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement;</span><br><span class="line">          if (pl != null &amp;&amp; pr != null) &#123;</span><br><span class="line">              TreeNode&lt;K,V&gt; s = pr, sl;</span><br><span class="line">              while ((sl = s.left) != null) // find successor</span><br><span class="line">                  s = sl;</span><br><span class="line">              boolean c = s.red; s.red = p.red; p.red = c; // swap colors</span><br><span class="line">              TreeNode&lt;K,V&gt; sr = s.right;</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = p.parent;</span><br><span class="line">              if (s == pr) &#123; // p was s&apos;s direct parent</span><br><span class="line">                  p.parent = s;</span><br><span class="line">                  s.right = p;</span><br><span class="line">              &#125;</span><br><span class="line">              else &#123;</span><br><span class="line">                  TreeNode&lt;K,V&gt; sp = s.parent;</span><br><span class="line">                  if ((p.parent = sp) != null) &#123;</span><br><span class="line">                      if (s == sp.left)</span><br><span class="line">                          sp.left = p;</span><br><span class="line">                      else</span><br><span class="line">                          sp.right = p;</span><br><span class="line">                  &#125;</span><br><span class="line">                  if ((s.right = pr) != null)</span><br><span class="line">                      pr.parent = s;</span><br><span class="line">              &#125;</span><br><span class="line">              p.left = null;</span><br><span class="line">              if ((p.right = sr) != null)</span><br><span class="line">                  sr.parent = p;</span><br><span class="line">              if ((s.left = pl) != null)</span><br><span class="line">                  pl.parent = s;</span><br><span class="line">              if ((s.parent = pp) == null)</span><br><span class="line">                  root = s;</span><br><span class="line">              else if (p == pp.left)</span><br><span class="line">                  pp.left = s;</span><br><span class="line">              else</span><br><span class="line">                  pp.right = s;</span><br><span class="line">              if (sr != null)</span><br><span class="line">                  replacement = sr;</span><br><span class="line">              else</span><br><span class="line">                  replacement = p;</span><br><span class="line">          &#125;</span><br><span class="line">          else if (pl != null)</span><br><span class="line">              replacement = pl;</span><br><span class="line">          else if (pr != null)</span><br><span class="line">              replacement = pr;</span><br><span class="line">          else</span><br><span class="line">              replacement = p;</span><br><span class="line">          if (replacement != p) &#123;</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent;</span><br><span class="line">              if (pp == null)</span><br><span class="line">                  root = replacement;</span><br><span class="line">              else if (p == pp.left)</span><br><span class="line">                  pp.left = replacement;</span><br><span class="line">              else</span><br><span class="line">                  pp.right = replacement;</span><br><span class="line">              p.left = p.right = p.parent = null;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement);</span><br><span class="line"></span><br><span class="line">          if (replacement == p) &#123;  // detach</span><br><span class="line">              TreeNode&lt;K,V&gt; pp = p.parent;</span><br><span class="line">              p.parent = null;</span><br><span class="line">              if (pp != null) &#123;</span><br><span class="line">                  if (p == pp.left)</span><br><span class="line">                      pp.left = null;</span><br><span class="line">                  else if (p == pp.right)</span><br><span class="line">                      pp.right = null;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          if (movable)</span><br><span class="line">              moveRootToFront(tab, r);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h1>小结</h1><p>在创建 HashMap 时根据实际需要适当地调整 load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，程序员无需改变负载因子的值。</p><p>如果开始就知道 HashMap 会保存多个 key-value 对，可以在创建时就使用较大的初始化容量，如果 HashMap 中 Entry 的数量一直不会超过极限容量（capacity * load factor），HashMap 就无需调用 resize() 方法重新分配 table 数组，从而保证较好的性能。当然，开始就将初始容量设置太高可能会浪费空间（系统需要创建一个长度为 capacity 的 Entry 数组），因此创建 HashMap 时初始化容量设置也需要小心对待。</p><p>HashMap高性能需要以下几点：</p><ul><li>高效的hash算法</li><li>保证hash值到内存地址（数组索引）的映射速度</li><li>根据内存地址（数组索引）可以直接得到相应的值</li></ul>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-JDK-动态代理（AOP）使用及实现原理分析</title>
    <url>/java-jdk-aop.html</url>
    <content><![CDATA[<h1>一、什么是代理？</h1><p>代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。</p><p>代理模式UML图：</p><p><img data-src="/images/spring-jdk-aop/UML.png" alt><br>简单结构示意图：</p><p><img data-src="/images/spring-jdk-aop/%E7%AE%80%E5%8D%95%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt><br>为了保持行为的一致性，代理类和委托类通常会实现相同的接口，所以在访问者看来两者没有丝毫的区别。通过代理类这中间一层，能有效控制对委托类对象的直接访问，也可以很好地隐藏和保护委托类对象，同时也为实施不同控制策略预留了空间，从而在设计上获得了更大的灵活性。Java 动态代理机制以巧妙的方式近乎完美地实践了代理模式的设计理念。</p><h1>二、Java 动态代理类</h1><p>Java动态代理类位于java.lang.reflect包下，一般主要涉及到以下两个类：</p><p>(1)Interface InvocationHandler：该接口中仅定义了一个方法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public object invoke(Object obj,Method method, Object[] args)</span><br></pre></td></tr></table></figure><p>在实际使用时，<font color="DeepPink"><strong>第一个参数obj一般是指代理类，method是被代理的方法，如上例中的request()，args为该方法的参数数组。</strong></font>这个抽象方法在代理类中动态实现。</p><p>(2)Proxy：该类即为动态代理类，其中主要包含以下内容：</p><p>protected Proxy(InvocationHandler h)：构造函数，用于给内部的h赋值。</p><p>static Class getProxyClass(</p><p>ClassLoader loader,</p><p>Class[] interfaces)：获得一个代理类，其中loader是类装载器，interfaces是真实类所拥有的全部接口的数组。</p><p>static Object newProxyInstance(ClassLoaderloader, Class[] interfaces,InvocationHandler h)：返回代理类的一个实例，返回后的代理类可以当作被代理类使用(可使用被代理类的在Subject接口中声明过的方法)</p><p>所谓DynamicProxy是这样一种class：<font color="DeepPink"><strong>它是在运行时生成的class，在生成它时你必须提供一组interface给它，然后该class就宣称它实现了这些interface。</strong></font>你当然可以把该class的实例当作这些interface中的任何一个来用。当然，这个DynamicProxy其实就是一个Proxy，它不会替你作实质性的工作，<font color="DeepPink"><strong>在生成它的实例时你必须提供一个handler，由它接管实际的工作。</strong></font></p><p>在使用动态代理类时，我们必须实现InvocationHandler接口</p><p>通过这种方式，被代理的对象(RealSubject)可以在运行时动态改变，需要控制的接口(Subject接口)可以在运行时改变，控制的方式(DynamicSubject类)也可以动态改变，从而实现了非常灵活的动态代理关系。</p><p>动态代理步骤：</p><ol><li><p>创建一个实现接口InvocationHandler的类，它必须实现invoke方法</p></li><li><p>创建被代理的类以及接口</p></li><li><p>通过Proxy的静态方法</p></li></ol><p>newProxyInstance(ClassLoaderloader,Class[]interfaces,InvocationHandler h)创建一个代理</p><ol start="4"><li>通过代理调用方法</li></ol><h1>三、JDK的动态代理怎么使用？</h1><p>1、需要动态代理的接口：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 需要动态代理的接口</span><br><span class="line"> */</span><br><span class="line">public interface Subject &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 你好</span><br><span class="line">     *</span><br><span class="line">     * @param name</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public String SayHello(String name);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 再见</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public String SayGoodBye();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、需要代理的实际对象</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 实际对象</span><br><span class="line"> */</span><br><span class="line">public class RealSubject implements Subject &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 你好</span><br><span class="line">     *</span><br><span class="line">     * @param name</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public String SayHello(String name) &#123;</span><br><span class="line">        return &quot;hello &quot; + name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 再见</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public String SayGoodBye() &#123;</span><br><span class="line">        return &quot; good bye &quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、调用处理器实现类（有木有感觉这里就是传说中的AOP啊）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 调用处理器实现类</span><br><span class="line"> * 每次生成动态代理类对象时都需要指定一个实现了该接口的调用处理器对象</span><br><span class="line"> */</span><br><span class="line">public class InvocationHandlerImpl implements InvocationHandler &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 这个就是我们要代理的真实对象</span><br><span class="line">     */</span><br><span class="line">    private Object subject;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 构造方法，给我们要代理的真实对象赋初值</span><br><span class="line">     *</span><br><span class="line">     * @param subject</span><br><span class="line">     */</span><br><span class="line">    public InvocationHandlerImpl(Object subject) &#123;</span><br><span class="line">        this.subject = subject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 该方法负责集中处理动态代理类上的所有方法调用。</span><br><span class="line">     * 调用处理器根据这三个参数进行预处理或分派到委托类实例上反射执行</span><br><span class="line">     *</span><br><span class="line">     * @param proxy  代理类实例</span><br><span class="line">     * @param method 被调用的方法对象</span><br><span class="line">     * @param args   调用参数</span><br><span class="line">     * @return</span><br><span class="line">     * @throws Throwable</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class="line">        //在代理真实对象前我们可以添加一些自己的操作</span><br><span class="line">        System.out.println(&quot;在调用之前，我要干点啥呢？&quot;);</span><br><span class="line">        System.out.println(&quot;Method:&quot; + method);</span><br><span class="line">        //当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用</span><br><span class="line">        Object returnValue = method.invoke(subject, args);</span><br><span class="line">        //在代理真实对象后我们也可以添加一些自己的操作</span><br><span class="line">        System.out.println(&quot;在调用之后，我要干点啥呢？&quot;);</span><br><span class="line">        return returnValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、测试</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 动态代理演示</span><br><span class="line"> */</span><br><span class="line">public class DynamicProxyDemonstration &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //代理的真实对象</span><br><span class="line">        Subject realSubject = new RealSubject();</span><br><span class="line">        /**</span><br><span class="line">         * InvocationHandlerImpl 实现了 InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发</span><br><span class="line">         * 其内部通常包含指向委托类实例的引用，用于真正执行分派转发过来的方法调用.</span><br><span class="line">         * 即：要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法</span><br><span class="line">         */</span><br><span class="line">        InvocationHandler handler = new InvocationHandlerImpl(realSubject);</span><br><span class="line"></span><br><span class="line">        ClassLoader loader = handler.getClass().getClassLoader();</span><br><span class="line">        Class&lt;?&gt;[] interfaces = realSubject.getClass().getInterfaces();</span><br><span class="line">        /**</span><br><span class="line">         * 该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例</span><br><span class="line">         */</span><br><span class="line">        Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;动态代理对象的类型：&quot; + subject.getClass().getName());</span><br><span class="line"></span><br><span class="line">        String hello = subject.SayHello(&quot;jiankunking&quot;);</span><br><span class="line">        System.out.println(hello);</span><br><span class="line">//        String goodbye = subject.SayGoodBye();</span><br><span class="line">//        System.out.println(goodbye);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5、输出结果如下：</p><p><img data-src="/images/spring-jdk-aop/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%BC%94%E7%A4%BA%E8%BE%93%E5%87%BA.png" alt></p><h1>四、动态代理怎么实现的？</h1><p>从使用代码中可以看出，关键点在：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br></pre></td></tr></table></figure><p>通过跟踪提示代码可以看出：<font color="DeepPink"><strong>当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用。</strong></font></p><p>也就是说，当代码执行到：subject.SayHello(“jiankunking”)这句话时，会自动调用InvocationHandlerImpl的invoke方法。这是为啥呢？</p><blockquote><p>下面是代码跟分析的过程，不想看的朋友可以直接看结论</p></blockquote><p>以下代码来自:JDK1.8.0_92</p><p>既然生成代理对象是用的Proxy类的静态方newProxyInstance，那么我们就去它的源码里看一下它到底都做了些什么？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Returns an instance of a proxy class for the specified interfaces</span><br><span class="line"> * that dispatches method invocations to the specified invocation</span><br><span class="line"> * handler.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;&#123;@code Proxy.newProxyInstance&#125; throws</span><br><span class="line"> * &#123;@code IllegalArgumentException&#125; for the same reasons that</span><br><span class="line"> * &#123;@code Proxy.getProxyClass&#125; does.</span><br><span class="line"> *</span><br><span class="line"> * @param   loader the class loader to define the proxy class</span><br><span class="line"> * @param   interfaces the list of interfaces for the proxy class</span><br><span class="line"> *          to implement</span><br><span class="line"> * @param   h the invocation handler to dispatch method invocations to</span><br><span class="line"> * @return  a proxy instance with the specified invocation handler of a</span><br><span class="line"> *          proxy class that is defined by the specified class loader</span><br><span class="line"> *          and that implements the specified interfaces</span><br><span class="line"> * @throws  IllegalArgumentException if any of the restrictions on the</span><br><span class="line"> *          parameters that may be passed to &#123;@code getProxyClass&#125;</span><br><span class="line"> *          are violated</span><br><span class="line"> * @throws  SecurityException if a security manager, &lt;em&gt;s&lt;/em&gt;, is present</span><br><span class="line"> *          and any of the following conditions is met:</span><br><span class="line"> *          &lt;ul&gt;</span><br><span class="line"> *          &lt;li&gt; the given &#123;@code loader&#125; is &#123;@code null&#125; and</span><br><span class="line"> *               the caller&apos;s class loader is not &#123;@code null&#125; and the</span><br><span class="line"> *               invocation of &#123;@link SecurityManager#checkPermission</span><br><span class="line"> *               s.checkPermission&#125; with</span><br><span class="line"> *               &#123;@code RuntimePermission(&quot;getClassLoader&quot;)&#125; permission</span><br><span class="line"> *               denies access;&lt;/li&gt;</span><br><span class="line"> *          &lt;li&gt; for each proxy interface, &#123;@code intf&#125;,</span><br><span class="line"> *               the caller&apos;s class loader is not the same as or an</span><br><span class="line"> *               ancestor of the class loader for &#123;@code intf&#125; and</span><br><span class="line"> *               invocation of &#123;@link SecurityManager#checkPackageAccess</span><br><span class="line"> *               s.checkPackageAccess()&#125; denies access to &#123;@code intf&#125;;&lt;/li&gt;</span><br><span class="line"> *          &lt;li&gt; any of the given proxy interfaces is non-public and the</span><br><span class="line"> *               caller class is not in the same &#123;@linkplain Package runtime package&#125;</span><br><span class="line"> *               as the non-public interface and the invocation of</span><br><span class="line"> *               &#123;@link SecurityManager#checkPermission s.checkPermission&#125; with</span><br><span class="line"> *               &#123;@code ReflectPermission(&quot;newProxyInPackage.&#123;package name&#125;&quot;)&#125;</span><br><span class="line"> *               permission denies access.&lt;/li&gt;</span><br><span class="line"> *          &lt;/ul&gt;</span><br><span class="line"> * @throws  NullPointerException if the &#123;@code interfaces&#125; array</span><br><span class="line"> *          argument or any of its elements are &#123;@code null&#125;, or</span><br><span class="line"> *          if the invocation handler, &#123;@code h&#125;, is</span><br><span class="line"> *          &#123;@code null&#125;</span><br><span class="line"> */</span><br><span class="line">@CallerSensitive </span><br><span class="line">public static Object newProxyInstance(ClassLoader loader,</span><br><span class="line">                                          Class&lt;?&gt;[] interfaces,</span><br><span class="line">                                          InvocationHandler h) throws IllegalArgumentException &#123;</span><br><span class="line">        //检查h 不为空，否则抛异常</span><br><span class="line">        Objects.requireNonNull(h);</span><br><span class="line"> </span><br><span class="line">        final Class&lt;?&gt;[] intfs = interfaces.clone();</span><br><span class="line">        final SecurityManager sm = System.getSecurityManager();</span><br><span class="line">        if (sm != null) &#123;</span><br><span class="line">            checkProxyAccess(Reflection.getCallerClass(), loader, intfs);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * 获得与指定类装载器和一组接口相关的代理类类型对象</span><br><span class="line">         */</span><br><span class="line">        Class&lt;?&gt; cl = getProxyClass0(loader, intfs);</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * 通过反射获取构造函数对象并生成代理类实例</span><br><span class="line">         */</span><br><span class="line">        try &#123;</span><br><span class="line">            if (sm != null) &#123;</span><br><span class="line">                checkNewProxyPermission(Reflection.getCallerClass(), cl);</span><br><span class="line">            &#125;</span><br><span class="line">            //获取代理对象的构造方法（也就是$Proxy0(InvocationHandler h)） </span><br><span class="line">            final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);</span><br><span class="line">            final InvocationHandler ih = h;</span><br><span class="line">            if (!Modifier.isPublic(cl.getModifiers())) &#123;</span><br><span class="line">                AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;</span><br><span class="line">                    public Void run() &#123;</span><br><span class="line">                        cons.setAccessible(true);</span><br><span class="line">                        return null;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            //生成代理类的实例并把InvocationHandlerImpl的实例传给它的构造方法</span><br><span class="line">            return cons.newInstance(new Object[]&#123;h&#125;);</span><br><span class="line">        &#125; catch (IllegalAccessException|InstantiationException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125; catch (InvocationTargetException e) &#123;</span><br><span class="line">            Throwable t = e.getCause();</span><br><span class="line">            if (t instanceof RuntimeException) &#123;</span><br><span class="line">                throw (RuntimeException) t;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                throw new InternalError(t.toString(), t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (NoSuchMethodException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>我们再进去getProxyClass0方法看一下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Generate a proxy class.  Must call the checkProxyAccess method</span><br><span class="line"> * to perform permission checks before calling this.</span><br><span class="line"> */</span><br><span class="line">private static Class&lt;?&gt; getProxyClass0(ClassLoader loader,</span><br><span class="line">                                       Class&lt;?&gt;... interfaces) &#123;</span><br><span class="line">    if (interfaces.length &gt; 65535) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;interface limit exceeded&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    // If the proxy class defined by the given loader implementing</span><br><span class="line">    // the given interfaces exists, this will simply return the cached copy;</span><br><span class="line">    // otherwise, it will create the proxy class via the ProxyClassFactory</span><br><span class="line">    return proxyClassCache.get(loader, interfaces);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>真相还是没有来到，继续，看一下 proxyClassCache</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * a cache of proxy classes</span><br><span class="line"> */</span><br><span class="line">private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());</span><br></pre></td></tr></table></figure><p>奥，原来用了一下缓存啊</p><p>那么它对应的get方法啥样呢？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Look-up the value through the cache. This always evaluates the</span><br><span class="line"> * &#123;@code subKeyFactory&#125; function and optionally evaluates</span><br><span class="line"> * &#123;@code valueFactory&#125; function if there is no entry in the cache for given</span><br><span class="line"> * pair of (key, subKey) or the entry has already been cleared.</span><br><span class="line"> *</span><br><span class="line"> * @param key       possibly null key</span><br><span class="line"> * @param parameter parameter used together with key to create sub-key and</span><br><span class="line"> *                  value (should not be null)</span><br><span class="line"> * @return the cached value (never null)</span><br><span class="line"> * @throws NullPointerException if &#123;@code parameter&#125; passed in or</span><br><span class="line"> *                              &#123;@code sub-key&#125; calculated by</span><br><span class="line"> *                              &#123;@code subKeyFactory&#125; or &#123;@code value&#125;</span><br><span class="line"> *                              calculated by &#123;@code valueFactory&#125; is null.</span><br><span class="line"> */</span><br><span class="line">public V get(K key, P parameter) &#123;</span><br><span class="line">    Objects.requireNonNull(parameter);</span><br><span class="line">    expungeStaleEntries();</span><br><span class="line">    Object cacheKey = CacheKey.valueOf(key, refQueue);</span><br><span class="line">    // lazily install the 2nd level valuesMap for the particular cacheKey</span><br><span class="line">    ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey);</span><br><span class="line">    if (valuesMap == null) &#123;</span><br><span class="line">       //putIfAbsent这个方法在key不存在的时候加入一个值,如果key存在就不放入</span><br><span class="line">        ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey,valuesMap = new ConcurrentHashMap&lt;&gt;());</span><br><span class="line">        if (oldValuesMap != null) &#123;</span><br><span class="line">            valuesMap = oldValuesMap;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that</span><br><span class="line">    // subKey from valuesMap</span><br><span class="line">    Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));</span><br><span class="line">    Supplier&lt;V&gt; supplier = valuesMap.get(subKey);</span><br><span class="line">    Factory factory = null;</span><br><span class="line"> </span><br><span class="line">    while (true) &#123;</span><br><span class="line">        if (supplier != null) &#123;</span><br><span class="line">            // supplier might be a Factory or a CacheValue&lt;V&gt; instance</span><br><span class="line">            V value = supplier.get();</span><br><span class="line">            if (value != null) &#123;</span><br><span class="line">                return value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // else no supplier in cache</span><br><span class="line">        // or a supplier that returned null (could be a cleared CacheValue</span><br><span class="line">        // or a Factory that wasn&apos;t successful in installing the CacheValue)</span><br><span class="line"> </span><br><span class="line">        // lazily construct a Factory</span><br><span class="line">        if (factory == null) &#123;</span><br><span class="line">            factory = new Factory(key, parameter, subKey, valuesMap);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        if (supplier == null) &#123;        </span><br><span class="line">            supplier = valuesMap.putIfAbsent(subKey, factory);</span><br><span class="line">            if (supplier == null) &#123;</span><br><span class="line">                // successfully installed Factory</span><br><span class="line">                supplier = factory;</span><br><span class="line">            &#125;</span><br><span class="line">            // else retry with winning supplier</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (valuesMap.replace(subKey, supplier, factory)) &#123;</span><br><span class="line">                // successfully replaced</span><br><span class="line">                // cleared CacheEntry / unsuccessful Factory</span><br><span class="line">                // with our Factory</span><br><span class="line">                supplier = factory;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // retry with current supplier</span><br><span class="line">                supplier = valuesMap.get(subKey);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到它调用了 supplier.get(); 获取动态代理类，其中supplier是Factory,这个类定义在WeakCach的内部。</p><p>来瞅瞅，get里面又做了什么？</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public synchronized V get() &#123; // serialize access</span><br><span class="line">            // re-check</span><br><span class="line">            Supplier&lt;V&gt; supplier = valuesMap.get(subKey);</span><br><span class="line">            if (supplier != this) &#123;</span><br><span class="line">                // something changed while we were waiting:</span><br><span class="line">                // might be that we were replaced by a CacheValue</span><br><span class="line">                // or were removed because of failure -&gt;</span><br><span class="line">                // return null to signal WeakCache.get() to retry</span><br><span class="line">                // the loop</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">            // else still us (supplier == this)</span><br><span class="line"> </span><br><span class="line">            // create new value</span><br><span class="line">            V value = null;</span><br><span class="line">            try &#123;</span><br><span class="line">                value = Objects.requireNonNull(valueFactory.apply(key, parameter));</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                if (value == null) &#123; // remove us on failure</span><br><span class="line">                    valuesMap.remove(subKey, this);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            // the only path to reach here is with non-null value</span><br><span class="line">            assert value != null;</span><br><span class="line"> </span><br><span class="line">            // wrap value with CacheValue (WeakReference)</span><br><span class="line">            CacheValue&lt;V&gt; cacheValue = new CacheValue&lt;&gt;(value);</span><br><span class="line"> </span><br><span class="line">            // try replacing us with CacheValue (this should always succeed)</span><br><span class="line">            if (valuesMap.replace(subKey, this, cacheValue)) &#123;</span><br><span class="line">                // put also in reverseMap</span><br><span class="line">                reverseMap.put(cacheValue, Boolean.TRUE);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                throw new AssertionError(&quot;Should not reach here&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            // successfully replaced us with new CacheValue -&gt; return the value</span><br><span class="line">            // wrapped by it</span><br><span class="line">            return value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>发现重点还是木有出现，但我们可以看到它调用了valueFactory.apply(key, parameter)方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * A factory function that generates, defines and returns the proxy class given</span><br><span class="line"> * the ClassLoader and array of interfaces.</span><br><span class="line"> */</span><br><span class="line">private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123;</span><br><span class="line">    // prefix for all proxy class names</span><br><span class="line">    private static final String proxyClassNamePrefix = &quot;$Proxy&quot;;</span><br><span class="line"> </span><br><span class="line">    // next number to use for generation of unique proxy class names</span><br><span class="line">    private static final AtomicLong nextUniqueNumber = new AtomicLong();</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123;</span><br><span class="line">        Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length);</span><br><span class="line">        for (Class&lt;?&gt; intf : interfaces) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that the class loader resolves the name of this</span><br><span class="line">             * interface to the same Class object.</span><br><span class="line">             */</span><br><span class="line">            Class&lt;?&gt; interfaceClass = null;</span><br><span class="line">            try &#123;</span><br><span class="line">                interfaceClass = Class.forName(intf.getName(), false, loader);</span><br><span class="line">            &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">            if (interfaceClass != intf) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    intf + &quot; is not visible from class loader&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that the Class object actually represents an</span><br><span class="line">             * interface.</span><br><span class="line">             */</span><br><span class="line">            if (!interfaceClass.isInterface()) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    interfaceClass.getName() + &quot; is not an interface&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            /*</span><br><span class="line">             * Verify that this interface is not a duplicate.</span><br><span class="line">             */</span><br><span class="line">            if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123;</span><br><span class="line">                throw new IllegalArgumentException(</span><br><span class="line">                    &quot;repeated interface: &quot; + interfaceClass.getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        String proxyPkg = null;     // package to define proxy class in</span><br><span class="line">        int accessFlags = Modifier.PUBLIC | Modifier.FINAL;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Record the package of a non-public proxy interface so that the</span><br><span class="line">         * proxy class will be defined in the same package.  Verify that</span><br><span class="line">         * all non-public proxy interfaces are in the same package.</span><br><span class="line">         */</span><br><span class="line">        for (Class&lt;?&gt; intf : interfaces) &#123;</span><br><span class="line">            int flags = intf.getModifiers();</span><br><span class="line">            if (!Modifier.isPublic(flags)) &#123;</span><br><span class="line">                accessFlags = Modifier.FINAL;</span><br><span class="line">                String name = intf.getName();</span><br><span class="line">                int n = name.lastIndexOf(&apos;.&apos;);</span><br><span class="line">                String pkg = ((n == -1) ? &quot;&quot; : name.substring(0, n + 1));</span><br><span class="line">                if (proxyPkg == null) &#123;</span><br><span class="line">                    proxyPkg = pkg;</span><br><span class="line">                &#125; else if (!pkg.equals(proxyPkg)) &#123;</span><br><span class="line">                    throw new IllegalArgumentException(</span><br><span class="line">                        &quot;non-public interfaces from different packages&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        if (proxyPkg == null) &#123;</span><br><span class="line">            // if no non-public proxy interfaces, use com.sun.proxy package</span><br><span class="line">            proxyPkg = ReflectUtil.PROXY_PACKAGE + &quot;.&quot;;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Choose a name for the proxy class to generate.</span><br><span class="line">         */</span><br><span class="line">        long num = nextUniqueNumber.getAndIncrement();</span><br><span class="line">        String proxyName = proxyPkg + proxyClassNamePrefix + num;</span><br><span class="line"> </span><br><span class="line">        /*</span><br><span class="line">         * Generate the specified proxy class.</span><br><span class="line">         */</span><br><span class="line">        byte[] proxyClassFile = ProxyGenerator.generateProxyClass(</span><br><span class="line">            proxyName, interfaces, accessFlags);</span><br><span class="line">        try &#123;</span><br><span class="line">            return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);</span><br><span class="line">        &#125; catch (ClassFormatError e) &#123;</span><br><span class="line">            /*</span><br><span class="line">             * A ClassFormatError here means that (barring bugs in the</span><br><span class="line">             * proxy class generation code) there was some other</span><br><span class="line">             * invalid aspect of the arguments supplied to the proxy</span><br><span class="line">             * class creation (such as virtual machine limitations</span><br><span class="line">             * exceeded).</span><br><span class="line">             */</span><br><span class="line">            throw new IllegalArgumentException(e.toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过看代码终于找到了重点：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//生成字节码</span><br><span class="line">byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);</span><br></pre></td></tr></table></figure><p>那么接下来我们也使用测试一下，使用这个方法生成的字节码是个什么样子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package jiankunking;</span><br><span class="line"> </span><br><span class="line">import sun.misc.ProxyGenerator;</span><br><span class="line"> </span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * 动态代理演示</span><br><span class="line"> */</span><br><span class="line">public class DynamicProxyDemonstration &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //代理的真实对象</span><br><span class="line">        Subject realSubject = new RealSubject();</span><br><span class="line"> </span><br><span class="line">        /**</span><br><span class="line">         * InvocationHandlerImpl 实现了 InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发</span><br><span class="line">         * 其内部通常包含指向委托类实例的引用，用于真正执行分派转发过来的方法调用.</span><br><span class="line">         * 即：要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法</span><br><span class="line">         */</span><br><span class="line">        InvocationHandler handler = new InvocationHandlerImpl(realSubject);</span><br><span class="line"> </span><br><span class="line">        ClassLoader loader = handler.getClass().getClassLoader();</span><br><span class="line">        Class[] interfaces = realSubject.getClass().getInterfaces();</span><br><span class="line">        /**</span><br><span class="line">         * 该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例</span><br><span class="line">         */</span><br><span class="line">        Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br><span class="line">        System.out.println(&quot;动态代理对象的类型：&quot;+subject.getClass().getName());</span><br><span class="line"></span><br><span class="line">        String hello = subject.SayHello(&quot;jiankunking&quot;);</span><br><span class="line">        System.out.println(hello);</span><br><span class="line">        // 将生成的字节码保存到本地，</span><br><span class="line">        createProxyClassFile();</span><br><span class="line">    &#125;</span><br><span class="line">    private static void createProxyClassFile()&#123;</span><br><span class="line">        String name = &quot;ProxySubject&quot;;</span><br><span class="line">        byte[] data = ProxyGenerator.generateProxyClass(name,new Class[]&#123;Subject.class&#125;);</span><br><span class="line">        FileOutputStream out =null;</span><br><span class="line">        try &#123;</span><br><span class="line">            out = new FileOutputStream(name+&quot;.class&quot;);</span><br><span class="line">            System.out.println((new File(&quot;hello&quot;)).getAbsolutePath());</span><br><span class="line">            out.write(data);</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;finally &#123;</span><br><span class="line">            if(null!=out) try &#123;</span><br><span class="line">                out.close();</span><br><span class="line">            &#125; catch (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看一下这里代理对象的类型：</p><p><img data-src="/images/spring-jdk-aop/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B.png" alt><br>我们用jd-jui 工具将生成的字节码反编译：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.lang.reflect.InvocationHandler;</span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line">import java.lang.reflect.Proxy;</span><br><span class="line">import java.lang.reflect.UndeclaredThrowableException;</span><br><span class="line">import jiankunking.Subject;</span><br><span class="line"> </span><br><span class="line">public final class ProxySubject extends Proxy implements Subject &#123;</span><br><span class="line">  private static Method m1;</span><br><span class="line">  private static Method m3;</span><br><span class="line">  private static Method m4;</span><br><span class="line">  private static Method m2;</span><br><span class="line">  private static Method m0;</span><br><span class="line">  </span><br><span class="line">  public ProxySubject(InvocationHandler paramInvocationHandler) &#123;</span><br><span class="line">    super(paramInvocationHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final boolean equals(Object paramObject)&#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        return ((Boolean)this.h.invoke(this, m1, new Object[] &#123; paramObject &#125;)).booleanValue();</span><br><span class="line">    &#125; catch (Error|RuntimeException localError)&#123;</span><br><span class="line">        throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String SayGoodBye() &#123;</span><br><span class="line">    try&#123;</span><br><span class="line">      return (String)this.h.invoke(this, m3, null);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String SayHello(String paramString) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return (String)this.h.invoke(this, m4, new Object[] &#123; paramString &#125;);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError)&#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable)&#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final String toString() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return (String)this.h.invoke(this, m2, null);</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  public final int hashCode() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      return ((Integer)this.h.invoke(this, m0, null)).intValue();</span><br><span class="line">    &#125; catch (Error|RuntimeException localError) &#123;</span><br><span class="line">      throw localError;</span><br><span class="line">    &#125; catch (Throwable localThrowable) &#123;</span><br><span class="line">      throw new UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  static</span><br><span class="line">  &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[] &#123; Class.forName(&quot;java.lang.Object&quot;) &#125;);</span><br><span class="line">      m3 = Class.forName(&quot;jiankunking.Subject&quot;).getMethod(&quot;SayGoodBye&quot;, new Class[0]);</span><br><span class="line">      m4 = Class.forName(&quot;jiankunking.Subject&quot;).getMethod(&quot;SayHello&quot;, new Class[] &#123; Class.forName(&quot;java.lang.String&quot;) &#125;);</span><br><span class="line">      m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]);</span><br><span class="line">      m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]);</span><br><span class="line">      return;</span><br><span class="line">    &#125; catch (NoSuchMethodException localNoSuchMethodException) &#123;</span><br><span class="line">      throw new NoSuchMethodError(localNoSuchMethodException.getMessage());</span><br><span class="line">    &#125; catch (ClassNotFoundException localClassNotFoundException) &#123;</span><br><span class="line">      throw new NoClassDefFoundError(localClassNotFoundException.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是最终真正的代理类，它继承自Proxy并实现了我们定义的Subject接口，也就是说：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Subject subject = (Subject) Proxy.newProxyInstance(loader, interfaces, handler);</span><br></pre></td></tr></table></figure><p>这里的subject实际是这个类的一个实例，那么我们调用它的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final String SayHello(String paramString)</span><br></pre></td></tr></table></figure><p>就是调用我们定义的InvocationHandlerImpl的 invoke方法：</p><p><img data-src="/images/spring-jdk-aop/sayhello.png" alt></p><blockquote><p>上面是代码跟分析的过程，不想看的朋友可以直接看结论</p></blockquote><h1>五、结论</h1><p>到了这里，终于解答了：</p><p>subject.SayHello(“jiankunking”)这句话时，为什么会自动调用InvocationHandlerImpl的invoke方法？</p><p>因为JDK生成的最终真正的代理类，它继承自Proxy并实现了我们定义的Subject接口，在实现Subject接口方法的内部，通过反射调用了InvocationHandlerImpl的invoke方法。</p><p>通过分析代码可以看出Java 动态代理，具体有如下四步骤：</p><ol><li><p>通过实现 InvocationHandler 接口创建自己的调用处理器；</p></li><li><p>通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；</p></li><li><p>通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；</p></li><li><p>通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。</p></li></ol><p>演示代码下载：<br><a href="https://github.com/jiankunking/DynamicProxyDemo" target="_blank" rel="noopener">https://github.com/jiankunking/DynamicProxyDemo</a></p>]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title>通过IL分析C#中的委托、事件、Func、Action、Predicate之间的区别与联系</title>
    <url>/csharp-il-delegate-event-func-action-predicate.html</url>
    <content><![CDATA[<p>一直以来都是对于事件与委托比较混淆，而且不太会用。找了个时间，总结了一下，感觉清晰了很多。</p><p>先说一下个人理解的结论吧：</p><blockquote><p>delegate是C#中的一种类型，它实际上是一个能够持有对某个方法的引用的类。</p></blockquote><p>delegate声明的变量与delegate声明的事件，并没有本质的区别，事件是在delegate声明变量的基础上包装而成的，类似于变量与属性的关系（在IL代码中可以看到每一个delegate声明的事件都对应是私有的delegate声明的变量），提升了安全性。</p><p>Action 与Func：这两个其实说白了就是系统定义好的Delegate，他有很多重载的方法，便于各种应用情况下的调用。他在系统的System命名空间下，因此全局可见。</p><p>首先了解一下， ILDasm中图标含义：  <br><img data-src="/images/csharp-delegate/ILDasm.png" alt><br>该图来自：<a href="http://www.cnblogs.com/zery/p/3366175.html" target="_blank" rel="noopener">http://www.cnblogs.com/zery/p/3366175.html</a></p><p>委托创建步骤：</p><ol><li><font color="DeepPink"><strong>用delegate关键字创建一个委托，包括声明返回值和参数类型。</strong></font></li><li><font color="DeepPink"><strong>使用的地方接收这个委托。</strong></font></li><li><font color="DeepPink"><strong>创建这个委托的实例并指定一个返回值和参数类型匹配的方法传递过去。</strong></font></li></ol><h1>一、事件与委托</h1><p>新建一个事件委托测试项目：EventDelegateTest。</p><p>具体代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">namespace EventDelegateTest</span><br><span class="line">&#123;</span><br><span class="line">    public class TestClass</span><br><span class="line">    &#123;</span><br><span class="line">        public delegate int delegateAction();</span><br><span class="line">        public event delegateAction OnActionEvent;</span><br><span class="line">        public delegateAction daNew;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译代码后，使用 Visual Studio 2010自带的ILDASM.EXE：<br><img data-src="/images/csharp-delegate/IL%E5%8F%8D%E6%B1%87%E7%BC%96%E7%A8%8B%E5%BA%8F.png" alt></p><p>打开该dll，可以看到如下信息：<br><img data-src="/images/csharp-delegate/%E5%8F%8D%E7%BC%96%E8%AF%91DLL%E4%BF%A1%E6%81%AF.png" alt></p><p>从上图可以看出如下几点信息：</p><h2 id="1、delegate">1、delegate</h2><p>委托 public delegate int delegateAction();在IL中是以类（delegateAction）的形式存在的<br>.NET将委托定义为一个密封类，派生自基类System.MulticastDelegate，并继承了基类的三个方法:<br><img data-src="/images/csharp-delegate/delegateAction.png" alt></p><h2 id="2、event">2、event</h2><p>public event delegateAction OnActionEvent;在IL中不仅仅对应event OnActionEvent而且还对应一个field OnActionEvent;而field OnActionEvent与 public delegateAction daNew生成的field daNew是一样的.<br><img data-src="/images/csharp-delegate/OnActionEvent.png" alt><br><img data-src="/images/csharp-delegate/daNew.png" alt><br>都是以字段（field ）的形式存在的。<br>双击event OnActionEvent可以看到如下信息：<br><img data-src="/images/csharp-delegate/event-OnActionEvent.png" alt></p><p>在IL中事件被封装成了包含一个add_前缀和一个remove_前缀的的代码段。<br>其中，add_前缀的方法其实是通过调用Delegate.Combine()方法来实现的，组成了一个多播委托；remove_就是调用Delegate.Remove()方法，用于移除多播委托中的某个委托。</p><blockquote><p>也就是说：事件其实就是一个特殊的多播委托。</p></blockquote><p>那么对于事件进行这一次封装有什么好处呢？<br>1、因为delegate可以支持的操作非常多，比如我们可以写onXXXChanged += aaaFunc，把某个函数指针挂载到这个委托上面，但是我们也可以简单粗暴地直接写onXXXChanged = aaaFunc，让这个委托只包含这一个函数指针。不过这样一来会产生一个安全问题：如果我们用onXXXChanged = aaaFunc这样的写法，那么会把这个委托已拥有的其他函数指针给覆盖掉，这大概不是定义onXXXChanged的程序员想要看到的结果。</p><blockquote><p>小注：虽然事件不能直接=某个函数，也不可以直接=null</p></blockquote><p><img data-src="/images/csharp-delegate/event_not_null.png" alt></p><p>2、还有一个问题就是onXXXChanged这个委托应该什么时候触发（即调用它所包含的函数指针）。从面向对象的角度来说，XXX改变了这个事实（即onXXXChaned的字面含义）应该由包含它的那个对象来决定。但实际上我们可以从这个对象的外部环境调用onXXXChanged，这既产生了安全问题也不符合面向对象的初衷。 <br>说到这里对于事件与委托的管理算是说明白了，那么平时常用的Action与Func，与委托又有什么关系呢？</p><h1>二、Action 与Func</h1><p><strong>Action 委托：封装一个方法，该方法具有参数（0到16个参数）并且不返回值。</strong><br>具体形式如下：<a href="https://msdn.microsoft.com/zh-cn/library/system.action(v=vs.110).aspx" target="_blank" rel="noopener">https://msdn.microsoft.com/zh-cn/library/system.action(v=vs.110).aspx</a><br><img data-src="/images/csharp-delegate/Action.png" alt></p><p><strong>Func&lt;T, TResult&gt; 委托：封装一个具有参数（0到16个参数）并返回 TResult 参数指定的类型值的方法。</strong><br>具体形式如下：<a href="https://msdn.microsoft.com/zh-cn/library/bb534960(v=vs.110).aspx" target="_blank" rel="noopener">https://msdn.microsoft.com/zh-cn/library/bb534960(v=vs.110).aspx</a><br><img data-src="/images/csharp-delegate/Func_T_TResult.png" alt></p><p>那么这Action与Func是怎么实现的呢？<br>1、Action（以Action&lt;T1, T2&gt; 委托：封装一个方法，该方法具有两个参数并且不返回值为例）<br>从微软公布的源码中，可以看到，如下实现：<br><img data-src="/images/csharp-delegate/Action_T.png" alt></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public Action&lt;bool,bool&gt;  ac;</span><br></pre></td></tr></table></figure><p>上面这个声明就是：该方法具有两个参数并且不返回值的委托。<br>其余使用方式与委托变量一样。<br>2、Func（以Func&lt;T1, T2, TResult&gt; 委托：封装一个具有两个参数并返回 TResult 参数指定的类型值的方法为例）<br>从微软公布的源码中，可以看到，如下实现：<br><img data-src="/images/csharp-delegate/Func_T_TResult_%E6%BA%90%E7%A0%81.png" alt></p><p>此处，可以看出Func与Action是类似的，唯一的区别就是，Func必须指定返回值的类型，使用方式与委托咱们自己使用委托变量是一样的，直接使用相应参数的Func或者Action声明变量，=或者+=挂载函数（方法即可）<br>这两个其实说白了就是系统定义好的Delegate，他有很多重载的方法，便于各种应用情况下的调用。他在系统的System命名空间下，因此全局可见。</p><h1>三、Predicate</h1><p><strong>是返回bool型的泛型委托，Predicate有且只有一个参数，返回值固定为bool。表示定义一组条件并确定指定对象是否符合这些条件的方法。</strong></p><p>此方法常在集合（Array 和 List<t>）的查找中被用到，如：数组，正则拼配的结果集中被用到。</t></p><p>官方文档：<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.predicate-1?redirectedfrom=MSDN&amp;view=netframework-4.8" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.predicate-1?redirectedfrom=MSDN&amp;view=netframework-4.8</a></p><p>具体用法demo如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">using System;</span><br><span class="line">using System.Collections.Generic;</span><br><span class="line">using System.ComponentModel;</span><br><span class="line">using System.Data;</span><br><span class="line">using System.Drawing;</span><br><span class="line">using System.Linq;</span><br><span class="line">using System.Text;</span><br><span class="line">using System.Windows.Forms;</span><br><span class="line"> </span><br><span class="line">namespace IconTest</span><br><span class="line">&#123;</span><br><span class="line">    public partial class Form2 : Form</span><br><span class="line">    &#123;</span><br><span class="line">        Predicate&lt;int&gt; myPredicate;</span><br><span class="line">        int[] myNum = new int[8] &#123; 12, 33, 89, 21, 15, 29, 40, 52 &#125;;</span><br><span class="line">        public int[] myResult;</span><br><span class="line">        public Form2()</span><br><span class="line">        &#123;</span><br><span class="line">            InitializeComponent();</span><br><span class="line">            myPredicate = delegate(int curNum) 　　　　　　　　　　　　</span><br><span class="line">            &#123;</span><br><span class="line">                if (curNum % 2 == 0)</span><br><span class="line">                &#123;</span><br><span class="line">                    return true;</span><br><span class="line">                &#125;</span><br><span class="line">                else</span><br><span class="line">                &#123;</span><br><span class="line">                    return false;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        private void Form2_Load(object sender, EventArgs e)</span><br><span class="line">        &#123;</span><br><span class="line">            myResult = Array.FindAll(myNum, myPredicate);</span><br><span class="line">        &#125;          </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上例中说明了Predicate的使用，FindAll方法中，参数2即是一个Predicate，在具体的执行中，每一个数组的元素都会执行指定的方法，如果满足要求返回true，并会被存放在结果集中，不符合的则被剔除，最终返回的集合，即是结果判断后想要的集合。<br>Array.FindAll 泛型方法：<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.array.findall?redirectedfrom=MSDN&amp;view=netframework-4.8#System_Array_FindAll__1___0___System_Predicate___0__" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.array.findall?redirectedfrom=MSDN&amp;view=netframework-4.8#System_Array_FindAll__1___0___System_Predicate___0__</a><br>以上代码执行结果为：<br><img data-src="/images/csharp-delegate/Form2_Load.png" alt><br>那么Predicate<t>与委托又有什么关系呢？<br><img data-src="/images/csharp-delegate/Predicate_T.png" alt></t></p><p>从微软源码中可以看出Predicate<t>是返回bool型的泛型委托，从本质上来说与Func、Action、事件、委托变量并无本质区别。</t></p><h1>四、资料</h1><p>参考文章：<br><a href="http://www.zhihu.com/question/28932542" target="_blank" rel="noopener">http://www.zhihu.com/question/28932542</a></p><p>关于事件部分应用注意可以参考：<br><a href="http://www.cnblogs.com/buptzym/archive/2013/03/15/2962300.html" target="_blank" rel="noopener">http://www.cnblogs.com/buptzym/archive/2013/03/15/2962300.html</a></p><p>.NET Framework 源码：<br><a href="https://referencesource.microsoft.com" target="_blank" rel="noopener">https://referencesource.microsoft.com</a><br>Delegate 类:<br><a href="https://docs.microsoft.com/zh-cn/dotnet/api/system.delegate?redirectedfrom=MSDN&amp;view=netframework-4.8" target="_blank" rel="noopener">https://docs.microsoft.com/zh-cn/dotnet/api/system.delegate?redirectedfrom=MSDN&amp;view=netframework-4.8</a></p><p><img data-src="/images/csharp-delegate/%E5%A7%94%E6%89%98%E5%9B%BE%E8%A7%A3.png" alt></p>]]></content>
      <categories>
        <category>C#</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>C#</tag>
        <tag>Delegate</tag>
        <tag>Action</tag>
        <tag>Predicate</tag>
      </tags>
  </entry>
</search>
