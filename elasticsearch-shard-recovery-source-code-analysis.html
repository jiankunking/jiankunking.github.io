<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiankunking.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":320,"display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="带着疑问学源码，第七篇：Elasticsearch 分片恢复分析 代码分析基于：https://github.com/jiankunking/elasticsearch Elasticsearch 8.0.0-SNAPSHOT">
<meta name="keywords" content="原创,ElasticSearch,源码,Shard,Recovery">
<meta property="og:type" content="article">
<meta property="og:title" content="【Elasticsearch源码】 分片恢复分析">
<meta property="og:url" content="https://jiankunking.com/elasticsearch-shard-recovery-source-code-analysis.html">
<meta property="og:site_name" content="衣舞晨风">
<meta property="og:description" content="带着疑问学源码，第七篇：Elasticsearch 分片恢复分析 代码分析基于：https://github.com/jiankunking/elasticsearch Elasticsearch 8.0.0-SNAPSHOT">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2024-01-08T06:49:20.473Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【Elasticsearch源码】 分片恢复分析">
<meta name="twitter:description" content="带着疑问学源码，第七篇：Elasticsearch 分片恢复分析 代码分析基于：https://github.com/jiankunking/elasticsearch Elasticsearch 8.0.0-SNAPSHOT">

<link rel="canonical" href="https://jiankunking.com/elasticsearch-shard-recovery-source-code-analysis.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>【Elasticsearch源码】 分片恢复分析 | 衣舞晨风</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-121070942-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-121070942-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3a234fd6ba55e88f18fe2d8e55dd52c5";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">衣舞晨风</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">150</span></a>

  </li>
        <li class="menu-item menu-item-书籍">

    <a href="/books/" rel="section"><i class="fa fa-th fa-fw"></i>书籍</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">211</span></a>

  </li>
        <li class="menu-item menu-item-友链">

    <a href="/links/" rel="section"><i class="fa fa-external-link-alt fa-fw"></i>友链</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/jiankunking" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jiankunking.com/elasticsearch-shard-recovery-source-code-analysis.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar/avatar.png">
      <meta itemprop="name" content="jiankunking">
      <meta itemprop="description" content="如果你来访我，我不在，请和我门外的花坐一会儿，它们很温暖，我注视他们很多很多日子了。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="衣舞晨风">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          【Elasticsearch源码】 分片恢复分析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-23 20:19:55" itemprop="dateCreated datePublished" datetime="2023-12-23T20:19:55+08:00">2023-12-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-08 14:49:20" itemprop="dateModified" datetime="2024-01-08T14:49:20+08:00">2024-01-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index"><span itemprop="name">ElasticSearch</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>59k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>53 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>带着疑问学源码，第七篇：Elasticsearch 分片恢复分析<br>
代码分析基于：<a href="https://github.com/jiankunking/elasticsearch" target="_blank" rel="noopener">https://github.com/jiankunking/elasticsearch</a><br>
Elasticsearch 8.0.0-SNAPSHOT</p>
</blockquote>
<a id="more"></a>
<h1>目的</h1>
<p>在看源码之前先梳理一下，自己对于分片恢复的疑问点：</p>
<ul>
<li>网上对于ElasticSearch分片恢复的逻辑说法一抓一把，网上说的对不对？新版本中有没有更新？</li>
<li>在分片恢复的时候，如果收到Api _forcemerge请求，这时候，会如何处理?(因为副本恢复的第一节点是复制segment文件)</li>
<li>分片恢复的第二阶段是同步translog,这一步会不会加锁？不加锁的话，如何确保是同步完成了？</li>
</ul>
<blockquote>
<p>如果说看源码有捷径的话，那么找到网上一篇写的比较权威的源码分析文章跟着看，那不失为一种好方法。<br>
下面源码分析部分将参考腾讯云的:<a href="https://cloud.tencent.com/developer/article/1370385" target="_blank" rel="noopener">Elasticsearch 底层系列之分片恢复解析</a>，一边参考，一边印证。</p>
</blockquote>
<h1>源码分析</h1>
<h2 id="目标节点请求恢复">目标节点请求恢复</h2>
<p>先找到分片恢复的入口:<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java#L568" target="_blank" rel="noopener">IndicesClusterStateService.createOrUpdateShards</a></p>
<p>在这里会判断本地节点是否在routingNodes中，如果在，说明本地节点有分片创建或更新的需求，否则跳过。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private void createOrUpdateShards(final ClusterState state) &#123;</span><br><span class="line">        // 节点到索引分片的映射关系，主要用于分片分配、均衡决策</span><br><span class="line">        // 具体的内容可以看下:https://jiankunking.com/elasticsearch-cluster-state.html</span><br><span class="line">        RoutingNode localRoutingNode = state.getRoutingNodes().node(state.nodes().getLocalNodeId());</span><br><span class="line">        if (localRoutingNode == null) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        DiscoveryNodes nodes = state.nodes();</span><br><span class="line">        RoutingTable routingTable = state.routingTable();</span><br><span class="line"></span><br><span class="line">        for (final ShardRouting shardRouting : localRoutingNode) &#123;</span><br><span class="line">            ShardId shardId = shardRouting.shardId();</span><br><span class="line">            // failedShardsCache:https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java#L116</span><br><span class="line">            // 恢复过程中失败的碎片列表；我们跟踪这些碎片，以防止在每次集群状态更新时重复恢复这些碎片</span><br><span class="line">            if (failedShardsCache.containsKey(shardId) == false) &#123;</span><br><span class="line">                AllocatedIndex&lt;? extends Shard&gt; indexService = indicesService.indexService(shardId.getIndex());</span><br><span class="line">                assert indexService != null : &quot;index &quot; + shardId.getIndex() + &quot; should have been created by createIndices&quot;;</span><br><span class="line">                Shard shard = indexService.getShardOrNull(shardId.id());</span><br><span class="line">                if (shard == null) &#123; // shard不存在则需创建</span><br><span class="line">                    assert shardRouting.initializing() : shardRouting + &quot; should have been removed by failMissingShards&quot;;</span><br><span class="line">                    createShard(nodes, routingTable, shardRouting, state);</span><br><span class="line">                &#125; else &#123; // 存在则更新</span><br><span class="line">                    updateShard(nodes, shardRouting, shard, routingTable, state);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>副本分片恢复走的是createShard分支，在该方法中，首先获取shardRouting的类型，如果恢复类型为PEER，说明该分片需要从远端获取，则需要找到源节点，然后调用<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java#L593" target="_blank" rel="noopener">IndicesService.createShard</a>：</p>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html#index-recovery-api-response-body" target="_blank" rel="noopener">RecoverySource的Type</a>有以下几种：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">EMPTY_STORE,</span><br><span class="line">EXISTING_STORE,//主分片本地恢复</span><br><span class="line">PEER,//副分片从远处主分片恢复</span><br><span class="line">SNAPSHOT,//从快照恢复</span><br><span class="line">LOCAL_SHARDS//从本节点其它分片恢复(shrink时)</span><br></pre></td></tr></table></figure>
<p>createShard代码如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">private void createShard(DiscoveryNodes nodes, RoutingTable routingTable, ShardRouting shardRouting, ClusterState state) &#123;</span><br><span class="line">        assert shardRouting.initializing() : &quot;only allow shard creation for initializing shard but was &quot; + shardRouting;</span><br><span class="line"></span><br><span class="line">        DiscoveryNode sourceNode = null;</span><br><span class="line">        // 如果恢复方式是peer，则会找到shard所在的源节点进行恢复</span><br><span class="line">        if (shardRouting.recoverySource().getType() == Type.PEER)  &#123;</span><br><span class="line">            sourceNode = findSourceNodeForPeerRecovery(logger, routingTable, nodes, shardRouting);</span><br><span class="line">            if (sourceNode == null) &#123;</span><br><span class="line">                logger.trace(&quot;ignoring initializing shard &#123;&#125; - no source node can be found.&quot;, shardRouting.shardId());</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            final long primaryTerm = state.metadata().index(shardRouting.index()).primaryTerm(shardRouting.id());</span><br><span class="line">            logger.debug(&quot;&#123;&#125; creating shard with primary term [&#123;&#125;]&quot;, shardRouting.shardId(), primaryTerm);</span><br><span class="line">            indicesService.createShard(</span><br><span class="line">                    shardRouting,</span><br><span class="line">                    recoveryTargetService,</span><br><span class="line">                    new RecoveryListener(shardRouting, primaryTerm),</span><br><span class="line">                    repositoriesService,</span><br><span class="line">                    failedShardHandler,</span><br><span class="line">                    this::updateGlobalCheckpointForShard,</span><br><span class="line">                    retentionLeaseSyncer,</span><br><span class="line">                    nodes.getLocalNode(),</span><br><span class="line">                    sourceNode);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            failAndRemoveShard(shardRouting, true, &quot;failed to create shard&quot;, e, state);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">     * Finds the routing source node for peer recovery, return null if its not found. Note, this method expects the shard</span><br><span class="line">     * routing to *require* peer recovery, use &#123;@link ShardRouting#recoverySource()&#125; to check if its needed or not.</span><br><span class="line">     */</span><br><span class="line">    private static DiscoveryNode findSourceNodeForPeerRecovery(Logger logger, RoutingTable routingTable, DiscoveryNodes nodes,</span><br><span class="line">                                                               ShardRouting shardRouting) &#123;</span><br><span class="line">        DiscoveryNode sourceNode = null;</span><br><span class="line">        if (!shardRouting.primary()) &#123;</span><br><span class="line">            ShardRouting primary = routingTable.shardRoutingTable(shardRouting.shardId()).primaryShard();</span><br><span class="line">            // only recover from started primary, if we can&apos;t find one, we will do it next round</span><br><span class="line">            if (primary.active()) &#123;</span><br><span class="line">                // 找到primary shard所在节点</span><br><span class="line">                sourceNode = nodes.get(primary.currentNodeId());</span><br><span class="line">                if (sourceNode == null) &#123;</span><br><span class="line">                    logger.trace(&quot;can&apos;t find replica source node because primary shard &#123;&#125; is assigned to an unknown node.&quot;, primary);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                logger.trace(&quot;can&apos;t find replica source node because primary shard &#123;&#125; is not active.&quot;, primary);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else if (shardRouting.relocatingNodeId() != null) &#123;</span><br><span class="line">            // 找到搬迁的源节点</span><br><span class="line">            sourceNode = nodes.get(shardRouting.relocatingNodeId());</span><br><span class="line">            if (sourceNode == null) &#123;</span><br><span class="line">                logger.trace(&quot;can&apos;t find relocation source node for shard &#123;&#125; because it is assigned to an unknown node [&#123;&#125;].&quot;,</span><br><span class="line">                    shardRouting.shardId(), shardRouting.relocatingNodeId());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            throw new IllegalStateException(&quot;trying to find source node for peer recovery when routing state means no peer recovery: &quot; +</span><br><span class="line">                shardRouting);</span><br><span class="line">        &#125;</span><br><span class="line">        return sourceNode;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>源节点的确定分两种情况，如果当前shard本身不是primary shard，则源节点为primary shard所在节点，否则，如果当前shard正在搬迁中(从其他节点搬迁到本节点)，则源节点为数据搬迁的源头节点。得到源节点后调用IndicesService.createShard，在该方法中调用方法<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java#L2635" target="_blank" rel="noopener">IndexShard.startRecovery</a>开始恢复。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">public void startRecovery(RecoveryState recoveryState, PeerRecoveryTargetService recoveryTargetService,</span><br><span class="line">                              PeerRecoveryTargetService.RecoveryListener recoveryListener, RepositoriesService repositoriesService,</span><br><span class="line">                              Consumer&lt;MappingMetadata&gt; mappingUpdateConsumer,</span><br><span class="line">                              IndicesService indicesService) &#123;</span><br><span class="line">        // TODO: Create a proper object to encapsulate the recovery context</span><br><span class="line">        // all of the current methods here follow a pattern of:</span><br><span class="line">        // resolve context which isn&apos;t really dependent on the local shards and then async</span><br><span class="line">        // call some external method with this pointer.</span><br><span class="line">        // with a proper recovery context object we can simply change this to:</span><br><span class="line">        // startRecovery(RecoveryState recoveryState, ShardRecoverySource source ) &#123;</span><br><span class="line">        //     markAsRecovery(&quot;from &quot; + source.getShortDescription(), recoveryState);</span><br><span class="line">        //     threadPool.generic().execute()  &#123;</span><br><span class="line">        //           onFailure () &#123; listener.failure() &#125;;</span><br><span class="line">        //           doRun() &#123;</span><br><span class="line">        //                if (source.recover(this)) &#123;</span><br><span class="line">        //                  recoveryListener.onRecoveryDone(recoveryState);</span><br><span class="line">        //                &#125;</span><br><span class="line">        //           &#125;</span><br><span class="line">        //     &#125;&#125;</span><br><span class="line">        // &#125;</span><br><span class="line">        assert recoveryState.getRecoverySource().equals(shardRouting.recoverySource());</span><br><span class="line">        switch (recoveryState.getRecoverySource().getType()) &#123;</span><br><span class="line">            case EMPTY_STORE:</span><br><span class="line">            case EXISTING_STORE:</span><br><span class="line">                executeRecovery(&quot;from store&quot;, recoveryState, recoveryListener, this::recoverFromStore);</span><br><span class="line">                break;</span><br><span class="line">            case PEER:</span><br><span class="line">                try &#123;</span><br><span class="line">                    markAsRecovering(&quot;from &quot; + recoveryState.getSourceNode(), recoveryState);</span><br><span class="line">                    recoveryTargetService.startRecovery(this, recoveryState.getSourceNode(), recoveryListener);</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                    failShard(&quot;corrupted preexisting index&quot;, e);</span><br><span class="line">                    recoveryListener.onRecoveryFailure(recoveryState,</span><br><span class="line">                        new RecoveryFailedException(recoveryState, null, e), true);</span><br><span class="line">                &#125;</span><br><span class="line">                break;</span><br><span class="line">            case SNAPSHOT:</span><br><span class="line">                final String repo = ((SnapshotRecoverySource) recoveryState.getRecoverySource()).snapshot().getRepository();</span><br><span class="line">                executeRecovery(&quot;from snapshot&quot;,</span><br><span class="line">                    recoveryState, recoveryListener, l -&gt; restoreFromRepository(repositoriesService.repository(repo), l));</span><br><span class="line">                break;</span><br><span class="line">            case LOCAL_SHARDS:</span><br><span class="line">                final IndexMetadata indexMetadata = indexSettings().getIndexMetadata();</span><br><span class="line">                final Index resizeSourceIndex = indexMetadata.getResizeSourceIndex();</span><br><span class="line">                final List&lt;IndexShard&gt; startedShards = new ArrayList&lt;&gt;();</span><br><span class="line">                final IndexService sourceIndexService = indicesService.indexService(resizeSourceIndex);</span><br><span class="line">                final Set&lt;ShardId&gt; requiredShards;</span><br><span class="line">                final int numShards;</span><br><span class="line">                if (sourceIndexService != null) &#123;</span><br><span class="line">                    requiredShards = IndexMetadata.selectRecoverFromShards(shardId().id(),</span><br><span class="line">                        sourceIndexService.getMetadata(), indexMetadata.getNumberOfShards());</span><br><span class="line">                    for (IndexShard shard : sourceIndexService) &#123;</span><br><span class="line">                        if (shard.state() == IndexShardState.STARTED &amp;&amp; requiredShards.contains(shard.shardId())) &#123;</span><br><span class="line">                            startedShards.add(shard);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    numShards = requiredShards.size();</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    numShards = -1;</span><br><span class="line">                    requiredShards = Collections.emptySet();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                if (numShards == startedShards.size()) &#123;</span><br><span class="line">                    assert requiredShards.isEmpty() == false;</span><br><span class="line">                    executeRecovery(&quot;from local shards&quot;, recoveryState, recoveryListener,</span><br><span class="line">                        l -&gt; recoverFromLocalShards(mappingUpdateConsumer,</span><br><span class="line">                            startedShards.stream().filter((s) -&gt; requiredShards.contains(s.shardId())).collect(Collectors.toList()), l));</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    final RuntimeException e;</span><br><span class="line">                    if (numShards == -1) &#123;</span><br><span class="line">                        e = new IndexNotFoundException(resizeSourceIndex);</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        e = new IllegalStateException(&quot;not all required shards of index &quot; + resizeSourceIndex</span><br><span class="line">                            + &quot; are started yet, expected &quot; + numShards + &quot; found &quot; + startedShards.size() + &quot; can&apos;t recover shard &quot;</span><br><span class="line">                            + shardId());</span><br><span class="line">                    &#125;</span><br><span class="line">                    throw e;</span><br><span class="line">                &#125;</span><br><span class="line">                break;</span><br><span class="line">            default:</span><br><span class="line">                throw new IllegalArgumentException(&quot;Unknown recovery source &quot; + recoveryState.getRecoverySource());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>对于恢复类型为PEER的任务，恢复动作的真正执行者为<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java#L174" target="_blank" rel="noopener">PeerRecoveryTargetService.doRecovery</a>。在该方法中，首先调用getStartRecoveryRequest获取shard的metadataSnapshot，该结构中包含shard的段信息，如syncid、checksum、doc数等，然后封装为StartRecoveryRequest，通过RPC发送到源节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line">private void doRecovery(final long recoveryId, final StartRecoveryRequest preExistingRequest) &#123;</span><br><span class="line">        final String actionName;</span><br><span class="line">        final TransportRequest requestToSend;</span><br><span class="line">        final StartRecoveryRequest startRequest;</span><br><span class="line">        final RecoveryState.Timer timer;</span><br><span class="line">        try (RecoveryRef recoveryRef = onGoingRecoveries.getRecovery(recoveryId)) &#123;</span><br><span class="line">            if (recoveryRef == null) &#123;</span><br><span class="line">                logger.trace(&quot;not running recovery with id [&#123;&#125;] - can not find it (probably finished)&quot;, recoveryId);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            final RecoveryTarget recoveryTarget = recoveryRef.target();</span><br><span class="line">            timer = recoveryTarget.state().getTimer();</span><br><span class="line">            if (preExistingRequest == null) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    final IndexShard indexShard = recoveryTarget.indexShard();</span><br><span class="line">                    indexShard.preRecovery();</span><br><span class="line">                    assert recoveryTarget.sourceNode() != null : &quot;can not do a recovery without a source node&quot;;</span><br><span class="line">                    logger.trace(&quot;&#123;&#125; preparing shard for peer recovery&quot;, recoveryTarget.shardId());</span><br><span class="line">                    indexShard.prepareForIndexRecovery();</span><br><span class="line">                    final long startingSeqNo = indexShard.recoverLocallyUpToGlobalCheckpoint();</span><br><span class="line">                    assert startingSeqNo == UNASSIGNED_SEQ_NO || recoveryTarget.state().getStage() == RecoveryState.Stage.TRANSLOG :</span><br><span class="line">                        &quot;unexpected recovery stage [&quot; + recoveryTarget.state().getStage() + &quot;] starting seqno [ &quot; + startingSeqNo + &quot;]&quot;;</span><br><span class="line">                    // 构造recovery request </span><br><span class="line">                    startRequest = getStartRecoveryRequest(logger, clusterService.localNode(), recoveryTarget, startingSeqNo);</span><br><span class="line">                    requestToSend = startRequest;</span><br><span class="line">                    actionName = PeerRecoverySourceService.Actions.START_RECOVERY;</span><br><span class="line">                &#125; catch (final Exception e) &#123;</span><br><span class="line">                    // this will be logged as warning later on...</span><br><span class="line">                    logger.trace(&quot;unexpected error while preparing shard for peer recovery, failing recovery&quot;, e);</span><br><span class="line">                    onGoingRecoveries.failRecovery(recoveryId,</span><br><span class="line">                        new RecoveryFailedException(recoveryTarget.state(), &quot;failed to prepare shard for recovery&quot;, e), true);</span><br><span class="line">                    return;</span><br><span class="line">                &#125;</span><br><span class="line">                logger.trace(&quot;&#123;&#125; starting recovery from &#123;&#125;&quot;, startRequest.shardId(), startRequest.sourceNode());</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                startRequest = preExistingRequest;</span><br><span class="line">                requestToSend = new ReestablishRecoveryRequest(recoveryId, startRequest.shardId(), startRequest.targetAllocationId());</span><br><span class="line">                actionName = PeerRecoverySourceService.Actions.REESTABLISH_RECOVERY;</span><br><span class="line">                logger.trace(&quot;&#123;&#125; reestablishing recovery from &#123;&#125;&quot;, startRequest.shardId(), startRequest.sourceNode());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 向源节点发送请求，请求恢复</span><br><span class="line">        transportService.sendRequest(startRequest.sourceNode(), actionName, requestToSend,</span><br><span class="line">                new RecoveryResponseHandler(startRequest, timer));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">     * Prepare the start recovery request.</span><br><span class="line">     *</span><br><span class="line">     * @param logger         the logger</span><br><span class="line">     * @param localNode      the local node of the recovery target</span><br><span class="line">     * @param recoveryTarget the target of the recovery</span><br><span class="line">     * @param startingSeqNo  a sequence number that an operation-based peer recovery can start with.</span><br><span class="line">     *                       This is the first operation after the local checkpoint of the safe commit if exists.</span><br><span class="line">     * @return a start recovery request</span><br><span class="line">     */</span><br><span class="line">    public static StartRecoveryRequest getStartRecoveryRequest(Logger logger, DiscoveryNode localNode,</span><br><span class="line">                                                               RecoveryTarget recoveryTarget, long startingSeqNo) &#123;</span><br><span class="line">        final StartRecoveryRequest request;</span><br><span class="line">        logger.trace(&quot;&#123;&#125; collecting local files for [&#123;&#125;]&quot;, recoveryTarget.shardId(), recoveryTarget.sourceNode());</span><br><span class="line"></span><br><span class="line">        Store.MetadataSnapshot metadataSnapshot;</span><br><span class="line">        try &#123;</span><br><span class="line">            metadataSnapshot = recoveryTarget.indexShard().snapshotStoreMetadata();</span><br><span class="line">            // Make sure that the current translog is consistent with the Lucene index; otherwise, we have to throw away the Lucene index.</span><br><span class="line">            try &#123;</span><br><span class="line">                final String expectedTranslogUUID = metadataSnapshot.getCommitUserData().get(Translog.TRANSLOG_UUID_KEY);</span><br><span class="line">                final long globalCheckpoint = Translog.readGlobalCheckpoint(recoveryTarget.translogLocation(), expectedTranslogUUID);</span><br><span class="line">                assert globalCheckpoint + 1 &gt;= startingSeqNo : &quot;invalid startingSeqNo &quot; + startingSeqNo + &quot; &gt;= &quot; + globalCheckpoint;</span><br><span class="line">            &#125; catch (IOException | TranslogCorruptedException e) &#123;</span><br><span class="line">                logger.warn(new ParameterizedMessage(&quot;error while reading global checkpoint from translog, &quot; +</span><br><span class="line">                    &quot;resetting the starting sequence number from &#123;&#125; to unassigned and recovering as if there are none&quot;, startingSeqNo), e);</span><br><span class="line">                metadataSnapshot = Store.MetadataSnapshot.EMPTY;</span><br><span class="line">                startingSeqNo = UNASSIGNED_SEQ_NO;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (final org.apache.lucene.index.IndexNotFoundException e) &#123;</span><br><span class="line">            // happens on an empty folder. no need to log</span><br><span class="line">            assert startingSeqNo == UNASSIGNED_SEQ_NO : startingSeqNo;</span><br><span class="line">            logger.trace(&quot;&#123;&#125; shard folder empty, recovering all files&quot;, recoveryTarget);</span><br><span class="line">            metadataSnapshot = Store.MetadataSnapshot.EMPTY;</span><br><span class="line">        &#125; catch (final IOException e) &#123;</span><br><span class="line">            if (startingSeqNo != UNASSIGNED_SEQ_NO) &#123;</span><br><span class="line">                logger.warn(new ParameterizedMessage(&quot;error while listing local files, resetting the starting sequence number from &#123;&#125; &quot; +</span><br><span class="line">                    &quot;to unassigned and recovering as if there are none&quot;, startingSeqNo), e);</span><br><span class="line">                startingSeqNo = UNASSIGNED_SEQ_NO;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                logger.warn(&quot;error while listing local files, recovering as if there are none&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line">            metadataSnapshot = Store.MetadataSnapshot.EMPTY;</span><br><span class="line">        &#125;</span><br><span class="line">        logger.trace(&quot;&#123;&#125; local file count [&#123;&#125;]&quot;, recoveryTarget.shardId(), metadataSnapshot.size());</span><br><span class="line">        request = new StartRecoveryRequest(</span><br><span class="line">            recoveryTarget.shardId(),</span><br><span class="line">            recoveryTarget.indexShard().routingEntry().allocationId().getId(),</span><br><span class="line">            recoveryTarget.sourceNode(),</span><br><span class="line">            localNode,</span><br><span class="line">            metadataSnapshot,</span><br><span class="line">            recoveryTarget.state().getPrimary(),</span><br><span class="line">            recoveryTarget.recoveryId(),</span><br><span class="line">            startingSeqNo);</span><br><span class="line">        return request;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>注意，请求的发送是异步的。</p>
<h2 id="源节点处理恢复请求">源节点处理恢复请求</h2>
<p>源节点接收到请求后会调用恢复的入口函数<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java#L165" target="_blank" rel="noopener">PeerRecoverySourceService.messageReceived</a>#recover:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class StartRecoveryTransportRequestHandler implements TransportRequestHandler&lt;StartRecoveryRequest&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void messageReceived(final StartRecoveryRequest request, final TransportChannel channel, Task task) throws Exception &#123;</span><br><span class="line">            recover(request, new ChannelActionListener&lt;&gt;(channel, Actions.START_RECOVERY, request));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>recover方法根据request得到shard并构造RecoverySourceHandler对象，然后调用handler.recoverToTarget进入恢复的执行体：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br></pre></td><td class="code"><pre><span class="line">private void recover(StartRecoveryRequest request, ActionListener&lt;RecoveryResponse&gt; listener) &#123;</span><br><span class="line">        final IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());</span><br><span class="line">        final IndexShard shard = indexService.getShard(request.shardId().id());</span><br><span class="line"></span><br><span class="line">        final ShardRouting routingEntry = shard.routingEntry();</span><br><span class="line"></span><br><span class="line">        if (routingEntry.primary() == false || routingEntry.active() == false) &#123;</span><br><span class="line">            throw new DelayRecoveryException(&quot;source shard [&quot; + routingEntry + &quot;] is not an active primary&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (request.isPrimaryRelocation() &amp;&amp; (routingEntry.relocating() == false ||</span><br><span class="line">            routingEntry.relocatingNodeId().equals(request.targetNode().getId()) == false)) &#123;</span><br><span class="line">            logger.debug(&quot;delaying recovery of &#123;&#125; as source shard is not marked yet as relocating to &#123;&#125;&quot;,</span><br><span class="line">                request.shardId(), request.targetNode());</span><br><span class="line">            throw new DelayRecoveryException(&quot;source shard is not marked yet as relocating to [&quot; + request.targetNode() + &quot;]&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        RecoverySourceHandler handler = ongoingRecoveries.addNewRecovery(request, shard);</span><br><span class="line">        logger.trace(&quot;[&#123;&#125;][&#123;&#125;] starting recovery to &#123;&#125;&quot;, request.shardId().getIndex().getName(), request.shardId().id(),</span><br><span class="line">            request.targetNode());</span><br><span class="line">        handler.recoverToTarget(ActionListener.runAfter(listener, () -&gt; ongoingRecoveries.remove(shard, handler)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">     * performs the recovery from the local engine to the target</span><br><span class="line">     */</span><br><span class="line">    public void recoverToTarget(ActionListener&lt;RecoveryResponse&gt; listener) &#123;</span><br><span class="line">        addListener(listener);</span><br><span class="line">        final Closeable releaseResources = () -&gt; IOUtils.close(resources);</span><br><span class="line">        try &#123;</span><br><span class="line">            cancellableThreads.setOnCancel((reason, beforeCancelEx) -&gt; &#123;</span><br><span class="line">                final RuntimeException e;</span><br><span class="line">                if (shard.state() == IndexShardState.CLOSED) &#123; // check if the shard got closed on us</span><br><span class="line">                    e = new IndexShardClosedException(shard.shardId(), &quot;shard is closed and recovery was canceled reason [&quot; + reason + &quot;]&quot;);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    e = new CancellableThreads.ExecutionCancelledException(&quot;recovery was canceled reason [&quot; + reason + &quot;]&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                if (beforeCancelEx != null) &#123;</span><br><span class="line">                    e.addSuppressed(beforeCancelEx);</span><br><span class="line">                &#125;</span><br><span class="line">                IOUtils.closeWhileHandlingException(releaseResources, () -&gt; future.onFailure(e));</span><br><span class="line">                throw e;</span><br><span class="line">            &#125;);</span><br><span class="line">            final Consumer&lt;Exception&gt; onFailure = e -&gt; &#123;</span><br><span class="line">                assert Transports.assertNotTransportThread(RecoverySourceHandler.this + &quot;[onFailure]&quot;);</span><br><span class="line">                IOUtils.closeWhileHandlingException(releaseResources, () -&gt; future.onFailure(e));</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">            final SetOnce&lt;RetentionLease&gt; retentionLeaseRef = new SetOnce&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            runUnderPrimaryPermit(() -&gt; &#123;</span><br><span class="line">                final IndexShardRoutingTable routingTable = shard.getReplicationGroup().getRoutingTable();</span><br><span class="line">                ShardRouting targetShardRouting = routingTable.getByAllocationId(request.targetAllocationId());</span><br><span class="line">                if (targetShardRouting == null) &#123;</span><br><span class="line">                    logger.debug(&quot;delaying recovery of &#123;&#125; as it is not listed as assigned to target node &#123;&#125;&quot;, request.shardId(),</span><br><span class="line">                        request.targetNode());</span><br><span class="line">                    throw new DelayRecoveryException(&quot;source node does not have the shard listed in its state as allocated on the node&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                assert targetShardRouting.initializing() : &quot;expected recovery target to be initializing but was &quot; + targetShardRouting;</span><br><span class="line">                retentionLeaseRef.set(</span><br><span class="line">                    shard.getRetentionLeases().get(ReplicationTracker.getPeerRecoveryRetentionLeaseId(targetShardRouting)));</span><br><span class="line">            &#125;, shardId + &quot; validating recovery target [&quot;+ request.targetAllocationId() + &quot;] registered &quot;,</span><br><span class="line">                shard, cancellableThreads, logger);</span><br><span class="line">            // 获取一个保留锁，使得translog不被清理</span><br><span class="line">            final Closeable retentionLock = shard.acquireHistoryRetentionLock();</span><br><span class="line">            resources.add(retentionLock);</span><br><span class="line">            final long startingSeqNo;</span><br><span class="line">            // 判断是否可以从SequenceNumber恢复</span><br><span class="line">            // 除了异常检测和版本号检测，主要在shard.hasCompleteHistoryOperations()方法中判断请求的序列号是否小于主分片节点的localCheckpoint，</span><br><span class="line">            // 以及translog中的数据是否足以恢复(有可能因为translog数据太大或者过期删除而无法恢复)</span><br><span class="line">            final boolean isSequenceNumberBasedRecovery</span><br><span class="line">                = request.startingSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO</span><br><span class="line">                &amp;&amp; isTargetSameHistory()</span><br><span class="line">                &amp;&amp; shard.hasCompleteHistoryOperations(&quot;peer-recovery&quot;, request.startingSeqNo())</span><br><span class="line">                &amp;&amp; ((retentionLeaseRef.get() == null &amp;&amp; shard.useRetentionLeasesInPeerRecovery() == false) ||</span><br><span class="line">                   (retentionLeaseRef.get() != null &amp;&amp; retentionLeaseRef.get().retainingSequenceNumber() &lt;= request.startingSeqNo()));</span><br><span class="line">            // NB check hasCompleteHistoryOperations when computing isSequenceNumberBasedRecovery, even if there is a retention lease,</span><br><span class="line">            // because when doing a rolling upgrade from earlier than 7.4 we may create some leases that are initially unsatisfied. It&apos;s</span><br><span class="line">            // possible there are other cases where we cannot satisfy all leases, because that&apos;s not a property we currently expect to hold.</span><br><span class="line">            // Also it&apos;s pretty cheap when soft deletes are enabled, and it&apos;d be a disaster if we tried a sequence-number-based recovery</span><br><span class="line">            // without having a complete history.</span><br><span class="line"></span><br><span class="line">            if (isSequenceNumberBasedRecovery &amp;&amp; retentionLeaseRef.get() != null) &#123;</span><br><span class="line">                // all the history we need is retained by an existing retention lease, so we do not need a separate retention lock</span><br><span class="line">                retentionLock.close();</span><br><span class="line">                logger.trace(&quot;history is retained by &#123;&#125;&quot;, retentionLeaseRef.get());</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // all the history we need is retained by the retention lock, obtained before calling shard.hasCompleteHistoryOperations()</span><br><span class="line">                // and before acquiring the safe commit we&apos;ll be using, so we can be certain that all operations after the safe commit&apos;s</span><br><span class="line">                // local checkpoint will be retained for the duration of this recovery.</span><br><span class="line">                logger.trace(&quot;history is retained by retention lock&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            final StepListener&lt;SendFileResult&gt; sendFileStep = new StepListener&lt;&gt;();</span><br><span class="line">            final StepListener&lt;TimeValue&gt; prepareEngineStep = new StepListener&lt;&gt;();</span><br><span class="line">            final StepListener&lt;SendSnapshotResult&gt; sendSnapshotStep = new StepListener&lt;&gt;();</span><br><span class="line">            final StepListener&lt;Void&gt; finalizeStep = new StepListener&lt;&gt;();</span><br><span class="line">            // 若可以基于序列号进行恢复，则获取开始的序列号</span><br><span class="line">            if (isSequenceNumberBasedRecovery) &#123;</span><br><span class="line">                // 如果基于SequenceNumber恢复，则startingSeqNo取值为恢复请求中的序列号，</span><br><span class="line">                // 从请求的序列号开始快照translog。否则取值为0，快照完整的translog。</span><br><span class="line">                logger.trace(&quot;performing sequence numbers based recovery. starting at [&#123;&#125;]&quot;, request.startingSeqNo());</span><br><span class="line">                // 获取开始序列号</span><br><span class="line">                startingSeqNo = request.startingSeqNo();</span><br><span class="line">                if (retentionLeaseRef.get() == null) &#123;</span><br><span class="line">                    createRetentionLease(startingSeqNo, sendFileStep.map(ignored -&gt; SendFileResult.EMPTY));</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    // 发送的文件设置为空</span><br><span class="line">                    sendFileStep.onResponse(SendFileResult.EMPTY);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                final Engine.IndexCommitRef safeCommitRef;</span><br><span class="line">                try &#123;</span><br><span class="line">                    // Releasing a safe commit can access some commit files.</span><br><span class="line">                    safeCommitRef = acquireSafeCommit(shard);</span><br><span class="line">                    resources.add(safeCommitRef);</span><br><span class="line">                &#125; catch (final Exception e) &#123;</span><br><span class="line">                    throw new RecoveryEngineException(shard.shardId(), 1, &quot;snapshot failed&quot;, e);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                // Try and copy enough operations to the recovering peer so that if it is promoted to primary then it has a chance of being</span><br><span class="line">                // able to recover other replicas using operations-based recoveries. If we are not using retention leases then we</span><br><span class="line">                // conservatively copy all available operations. If we are using retention leases then &quot;enough operations&quot; is just the</span><br><span class="line">                // operations from the local checkpoint of the safe commit onwards, because when using soft deletes the safe commit retains</span><br><span class="line">                // at least as much history as anything else. The safe commit will often contain all the history retained by the current set</span><br><span class="line">                // of retention leases, but this is not guaranteed: an earlier peer recovery from a different primary might have created a</span><br><span class="line">                // retention lease for some history that this primary already discarded, since we discard history when the global checkpoint</span><br><span class="line">                // advances and not when creating a new safe commit. In any case this is a best-effort thing since future recoveries can</span><br><span class="line">                // always fall back to file-based ones, and only really presents a problem if this primary fails before things have settled</span><br><span class="line">                // down.</span><br><span class="line">                startingSeqNo = Long.parseLong(safeCommitRef.getIndexCommit().getUserData().get(SequenceNumbers.LOCAL_CHECKPOINT_KEY)) + 1L;</span><br><span class="line">                logger.trace(&quot;performing file-based recovery followed by history replay starting at [&#123;&#125;]&quot;, startingSeqNo);</span><br><span class="line"></span><br><span class="line">                try &#123;</span><br><span class="line">                    final int estimateNumOps = estimateNumberOfHistoryOperations(startingSeqNo);</span><br><span class="line">                    final Releasable releaseStore = acquireStore(shard.store());</span><br><span class="line">                    resources.add(releaseStore);</span><br><span class="line">                    sendFileStep.whenComplete(r -&gt; IOUtils.close(safeCommitRef, releaseStore), e -&gt; &#123;</span><br><span class="line">                        try &#123;</span><br><span class="line">                            IOUtils.close(safeCommitRef, releaseStore);</span><br><span class="line">                        &#125; catch (final IOException ex) &#123;</span><br><span class="line">                            logger.warn(&quot;releasing snapshot caused exception&quot;, ex);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line"></span><br><span class="line">                    final StepListener&lt;ReplicationResponse&gt; deleteRetentionLeaseStep = new StepListener&lt;&gt;();</span><br><span class="line">                    runUnderPrimaryPermit(() -&gt; &#123;</span><br><span class="line">                            try &#123;</span><br><span class="line">                                // If the target previously had a copy of this shard then a file-based recovery might move its global</span><br><span class="line">                                // checkpoint backwards. We must therefore remove any existing retention lease so that we can create a</span><br><span class="line">                                // new one later on in the recovery.</span><br><span class="line">                                shard.removePeerRecoveryRetentionLease(request.targetNode().getId(),</span><br><span class="line">                                    new ThreadedActionListener&lt;&gt;(logger, shard.getThreadPool(), ThreadPool.Names.GENERIC,</span><br><span class="line">                                        deleteRetentionLeaseStep, false));</span><br><span class="line">                            &#125; catch (RetentionLeaseNotFoundException e) &#123;</span><br><span class="line">                                logger.debug(&quot;no peer-recovery retention lease for &quot; + request.targetAllocationId());</span><br><span class="line">                                deleteRetentionLeaseStep.onResponse(null);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;, shardId + &quot; removing retention lease for [&quot; + request.targetAllocationId() + &quot;]&quot;,</span><br><span class="line">                        shard, cancellableThreads, logger);</span><br><span class="line">                    // 第一阶段</span><br><span class="line">                    deleteRetentionLeaseStep.whenComplete(ignored -&gt; &#123;</span><br><span class="line">                        assert Transports.assertNotTransportThread(RecoverySourceHandler.this + &quot;[phase1]&quot;);</span><br><span class="line">                        phase1(safeCommitRef.getIndexCommit(), startingSeqNo, () -&gt; estimateNumOps, sendFileStep);</span><br><span class="line">                    &#125;, onFailure);</span><br><span class="line"></span><br><span class="line">                &#125; catch (final Exception e) &#123;</span><br><span class="line">                    throw new RecoveryEngineException(shard.shardId(), 1, &quot;sendFileStep failed&quot;, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            assert startingSeqNo &gt;= 0 : &quot;startingSeqNo must be non negative. got: &quot; + startingSeqNo;</span><br><span class="line"></span><br><span class="line">            sendFileStep.whenComplete(r -&gt; &#123;</span><br><span class="line">                assert Transports.assertNotTransportThread(RecoverySourceHandler.this + &quot;[prepareTargetForTranslog]&quot;);</span><br><span class="line">                // 等待phase1执行完毕，主分片节点通知副分片节点启动此分片的Engine:prepareTargetForTranslog          </span><br><span class="line">                // 该方法会阻塞处理，直到分片 Engine 启动完毕。</span><br><span class="line">                // 待副分片启动Engine 完毕，就可以正常接收写请求了。</span><br><span class="line">                // 注意，此时phase2尚未开始，此分片的恢复流程尚未结束。</span><br><span class="line">                // 等待当前操作处理完成后，以startingSeqNo为起始点，对translog做快照，开始执行phase2：</span><br><span class="line">                // For a sequence based recovery, the target can keep its local translog</span><br><span class="line">                prepareTargetForTranslog(estimateNumberOfHistoryOperations(startingSeqNo), prepareEngineStep);</span><br><span class="line">            &#125;, onFailure);</span><br><span class="line"></span><br><span class="line">            prepareEngineStep.whenComplete(prepareEngineTime -&gt; &#123;</span><br><span class="line">                assert Transports.assertNotTransportThread(RecoverySourceHandler.this + &quot;[phase2]&quot;);</span><br><span class="line">                /*</span><br><span class="line">                 * add shard to replication group (shard will receive replication requests from this point on) now that engine is open.</span><br><span class="line">                 * This means that any document indexed into the primary after this will be replicated to this replica as well</span><br><span class="line">                 * make sure to do this before sampling the max sequence number in the next step, to ensure that we send</span><br><span class="line">                 * all documents up to maxSeqNo in phase2.</span><br><span class="line">                 */</span><br><span class="line">                runUnderPrimaryPermit(() -&gt; shard.initiateTracking(request.targetAllocationId()),</span><br><span class="line">                    shardId + &quot; initiating tracking of &quot; + request.targetAllocationId(), shard, cancellableThreads, logger);</span><br><span class="line"></span><br><span class="line">                final long endingSeqNo = shard.seqNoStats().getMaxSeqNo();</span><br><span class="line">                logger.trace(&quot;snapshot for recovery; current size is [&#123;&#125;]&quot;, estimateNumberOfHistoryOperations(startingSeqNo));</span><br><span class="line">                final Translog.Snapshot phase2Snapshot = shard.newChangesSnapshot(&quot;peer-recovery&quot;, startingSeqNo, Long.MAX_VALUE, false);</span><br><span class="line">                resources.add(phase2Snapshot);</span><br><span class="line">                retentionLock.close();</span><br><span class="line"></span><br><span class="line">                // we have to capture the max_seen_auto_id_timestamp and the max_seq_no_of_updates to make sure that these values</span><br><span class="line">                // are at least as high as the corresponding values on the primary when any of these operations were executed on it.</span><br><span class="line">                final long maxSeenAutoIdTimestamp = shard.getMaxSeenAutoIdTimestamp();</span><br><span class="line">                final long maxSeqNoOfUpdatesOrDeletes = shard.getMaxSeqNoOfUpdatesOrDeletes();</span><br><span class="line">                final RetentionLeases retentionLeases = shard.getRetentionLeases();</span><br><span class="line">                final long mappingVersionOnPrimary = shard.indexSettings().getIndexMetadata().getMappingVersion();</span><br><span class="line">                // 第二阶段，发送translog</span><br><span class="line">                phase2(startingSeqNo, endingSeqNo, phase2Snapshot, maxSeenAutoIdTimestamp, maxSeqNoOfUpdatesOrDeletes,</span><br><span class="line">                    retentionLeases, mappingVersionOnPrimary, sendSnapshotStep);</span><br><span class="line"></span><br><span class="line">            &#125;, onFailure);</span><br><span class="line"></span><br><span class="line">            // Recovery target can trim all operations &gt;= startingSeqNo as we have sent all these operations in the phase 2</span><br><span class="line">            final long trimAboveSeqNo = startingSeqNo - 1;</span><br><span class="line">            sendSnapshotStep.whenComplete(r -&gt; finalizeRecovery(r.targetLocalCheckpoint, trimAboveSeqNo, finalizeStep), onFailure);</span><br><span class="line"></span><br><span class="line">            finalizeStep.whenComplete(r -&gt; &#123;</span><br><span class="line">                final long phase1ThrottlingWaitTime = 0L; // TODO: return the actual throttle time</span><br><span class="line">                final SendSnapshotResult sendSnapshotResult = sendSnapshotStep.result();</span><br><span class="line">                final SendFileResult sendFileResult = sendFileStep.result();</span><br><span class="line">                final RecoveryResponse response = new RecoveryResponse(sendFileResult.phase1FileNames, sendFileResult.phase1FileSizes,</span><br><span class="line">                    sendFileResult.phase1ExistingFileNames, sendFileResult.phase1ExistingFileSizes, sendFileResult.totalSize,</span><br><span class="line">                    sendFileResult.existingTotalSize, sendFileResult.took.millis(), phase1ThrottlingWaitTime,</span><br><span class="line">                    prepareEngineStep.result().millis(), sendSnapshotResult.sentOperations, sendSnapshotResult.tookTime.millis());</span><br><span class="line">                try &#123;</span><br><span class="line">                    future.onResponse(response);</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    IOUtils.close(resources);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, onFailure);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            IOUtils.closeWhileHandlingException(releaseResources, () -&gt; future.onFailure(e));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Checks if we have a completed history of operations since the given starting seqno (inclusive).</span><br><span class="line">     * This method should be called after acquiring the retention lock; See &#123;@link #acquireHistoryRetentionLock()&#125;</span><br><span class="line">     */</span><br><span class="line">    public boolean hasCompleteHistoryOperations(String reason, long startingSeqNo)  &#123;</span><br><span class="line">        return getEngine().hasCompleteOperationHistory(reason, startingSeqNo);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>从上面的代码可以看出，恢复主要分两个阶段，第一阶段恢复segment文件，第二阶段发送translog。这里有个关键的地方，在恢复前，首先需要获取translogView及segment snapshot，translogView的作用是保证当前时间点到恢复结束时间段的translog不被删除，segment snapshot的作用是保证当前时间点之前的segment文件不被删除。接下来看看两阶段恢复的具体执行逻辑。phase1:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Perform phase1 of the recovery operations. Once this &#123;@link IndexCommit&#125;</span><br><span class="line">     * snapshot has been performed no commit operations (files being fsync&apos;d)</span><br><span class="line">     * are effectively allowed on this index until all recovery phases are done</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * Phase1 examines the segment files on the target node and copies over the</span><br><span class="line">     * segments that are missing. Only segments that have the same size and</span><br><span class="line">     * checksum can be reused</span><br><span class="line">     */</span><br><span class="line">    void phase1(IndexCommit snapshot, long startingSeqNo, IntSupplier translogOps, ActionListener&lt;SendFileResult&gt; listener) &#123;</span><br><span class="line">        cancellableThreads.checkForCancel();</span><br><span class="line">        //拿到shard的存储信息</span><br><span class="line">        final Store store = shard.store();</span><br><span class="line">        try &#123;</span><br><span class="line">            StopWatch stopWatch = new StopWatch().start();</span><br><span class="line">            final Store.MetadataSnapshot recoverySourceMetadata;</span><br><span class="line">            try &#123;</span><br><span class="line">                // 拿到snapshot的metadata</span><br><span class="line">                recoverySourceMetadata = store.getMetadata(snapshot);</span><br><span class="line">            &#125; catch (CorruptIndexException | IndexFormatTooOldException | IndexFormatTooNewException ex) &#123;</span><br><span class="line">                shard.failShard(&quot;recovery&quot;, ex);</span><br><span class="line">                throw ex;</span><br><span class="line">            &#125;</span><br><span class="line">            for (String name : snapshot.getFileNames()) &#123;</span><br><span class="line">                // MetadataSnapshot:表示从最新的Lucene提交生成的当前目录的快照。</span><br><span class="line">                // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/store/Store.java#L732</span><br><span class="line">                final StoreFileMetadata md = recoverySourceMetadata.get(name);</span><br><span class="line">                if (md == null) &#123;</span><br><span class="line">                    logger.info(&quot;Snapshot differs from actual index for file: &#123;&#125; meta: &#123;&#125;&quot;, name, recoverySourceMetadata.asMap());</span><br><span class="line">                    throw new CorruptIndexException(&quot;Snapshot differs from actual index - maybe index was removed metadata has &quot; +</span><br><span class="line">                            recoverySourceMetadata.asMap().size() + &quot; files&quot;, name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            // 如果syncid相等，再继续比较下文档数，如果都相同则不用恢复</span><br><span class="line">            if (canSkipPhase1(recoverySourceMetadata, request.metadataSnapshot()) == false) &#123;</span><br><span class="line">                final List&lt;String&gt; phase1FileNames = new ArrayList&lt;&gt;();</span><br><span class="line">                final List&lt;Long&gt; phase1FileSizes = new ArrayList&lt;&gt;();</span><br><span class="line">                final List&lt;String&gt; phase1ExistingFileNames = new ArrayList&lt;&gt;();</span><br><span class="line">                final List&lt;Long&gt; phase1ExistingFileSizes = new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">                // Total size of segment files that are recovered</span><br><span class="line">                long totalSizeInBytes = 0;</span><br><span class="line">                // Total size of segment files that were able to be re-used</span><br><span class="line">                long existingTotalSizeInBytes = 0;</span><br><span class="line"></span><br><span class="line">                // Generate a &quot;diff&quot; of all the identical, different, and missing</span><br><span class="line">                // segment files on the target node, using the existing files on</span><br><span class="line">                // the source node</span><br><span class="line">                // 找出target和source有差别的segment</span><br><span class="line">                // https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/store/Store.java#L971</span><br><span class="line">                final Store.RecoveryDiff diff = recoverySourceMetadata.recoveryDiff(request.metadataSnapshot());</span><br><span class="line">                for (StoreFileMetadata md : diff.identical) &#123;</span><br><span class="line">                    phase1ExistingFileNames.add(md.name());</span><br><span class="line">                    phase1ExistingFileSizes.add(md.length());</span><br><span class="line">                    existingTotalSizeInBytes += md.length();</span><br><span class="line">                    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">                        logger.trace(&quot;recovery [phase1]: not recovering [&#123;&#125;], exist in local store and has checksum [&#123;&#125;],&quot; +</span><br><span class="line">                                        &quot; size [&#123;&#125;]&quot;, md.name(), md.checksum(), md.length());</span><br><span class="line">                    &#125;</span><br><span class="line">                    totalSizeInBytes += md.length();</span><br><span class="line">                &#125;</span><br><span class="line">                List&lt;StoreFileMetadata&gt; phase1Files = new ArrayList&lt;&gt;(diff.different.size() + diff.missing.size());</span><br><span class="line">                phase1Files.addAll(diff.different);</span><br><span class="line">                phase1Files.addAll(diff.missing);</span><br><span class="line">                for (StoreFileMetadata md : phase1Files) &#123;</span><br><span class="line">                    if (request.metadataSnapshot().asMap().containsKey(md.name())) &#123;</span><br><span class="line">                        logger.trace(&quot;recovery [phase1]: recovering [&#123;&#125;], exists in local store, but is different: remote [&#123;&#125;], local [&#123;&#125;]&quot;,</span><br><span class="line">                            md.name(), request.metadataSnapshot().asMap().get(md.name()), md);</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        logger.trace(&quot;recovery [phase1]: recovering [&#123;&#125;], does not exist in remote&quot;, md.name());</span><br><span class="line">                    &#125;</span><br><span class="line">                    phase1FileNames.add(md.name());</span><br><span class="line">                    phase1FileSizes.add(md.length());</span><br><span class="line">                    totalSizeInBytes += md.length();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.trace(&quot;recovery [phase1]: recovering_files [&#123;&#125;] with total_size [&#123;&#125;], reusing_files [&#123;&#125;] with total_size [&#123;&#125;]&quot;,</span><br><span class="line">                    phase1FileNames.size(), new ByteSizeValue(totalSizeInBytes),</span><br><span class="line">                    phase1ExistingFileNames.size(), new ByteSizeValue(existingTotalSizeInBytes));</span><br><span class="line">                final StepListener&lt;Void&gt; sendFileInfoStep = new StepListener&lt;&gt;();</span><br><span class="line">                final StepListener&lt;Void&gt; sendFilesStep = new StepListener&lt;&gt;();</span><br><span class="line">                final StepListener&lt;RetentionLease&gt; createRetentionLeaseStep = new StepListener&lt;&gt;();</span><br><span class="line">                final StepListener&lt;Void&gt; cleanFilesStep = new StepListener&lt;&gt;();</span><br><span class="line">                cancellableThreads.checkForCancel();</span><br><span class="line">                recoveryTarget.receiveFileInfo(phase1FileNames, phase1FileSizes, phase1ExistingFileNames,</span><br><span class="line">                        phase1ExistingFileSizes, translogOps.getAsInt(), sendFileInfoStep);</span><br><span class="line"></span><br><span class="line">                // 将需要恢复的文件发送到target node</span><br><span class="line">                sendFileInfoStep.whenComplete(r -&gt;</span><br><span class="line">                    sendFiles(store, phase1Files.toArray(new StoreFileMetadata[0]), translogOps, sendFilesStep), listener::onFailure);</span><br><span class="line"></span><br><span class="line">                sendFilesStep.whenComplete(r -&gt; createRetentionLease(startingSeqNo, createRetentionLeaseStep), listener::onFailure);</span><br><span class="line"></span><br><span class="line">                createRetentionLeaseStep.whenComplete(retentionLease -&gt;</span><br><span class="line">                    &#123;</span><br><span class="line">                        final long lastKnownGlobalCheckpoint = shard.getLastKnownGlobalCheckpoint();</span><br><span class="line">                        assert retentionLease == null || retentionLease.retainingSequenceNumber() - 1 &lt;= lastKnownGlobalCheckpoint</span><br><span class="line">                            : retentionLease + &quot; vs &quot; + lastKnownGlobalCheckpoint;</span><br><span class="line">                        // Establishes new empty translog on the replica with global checkpoint set to lastKnownGlobalCheckpoint. We want</span><br><span class="line">                        // the commit we just copied to be a safe commit on the replica, so why not set the global checkpoint on the replica</span><br><span class="line">                        // to the max seqno of this commit? Because (in rare corner cases) this commit might not be a safe commit here on</span><br><span class="line">                        // the primary, and in these cases the max seqno would be too high to be valid as a global checkpoint.</span><br><span class="line">                        cleanFiles(store, recoverySourceMetadata, translogOps, lastKnownGlobalCheckpoint, cleanFilesStep);</span><br><span class="line">                    &#125;,</span><br><span class="line">                    listener::onFailure);</span><br><span class="line"></span><br><span class="line">                final long totalSize = totalSizeInBytes;</span><br><span class="line">                final long existingTotalSize = existingTotalSizeInBytes;</span><br><span class="line">                cleanFilesStep.whenComplete(r -&gt; &#123;</span><br><span class="line">                    final TimeValue took = stopWatch.totalTime();</span><br><span class="line">                    logger.trace(&quot;recovery [phase1]: took [&#123;&#125;]&quot;, took);</span><br><span class="line">                    listener.onResponse(new SendFileResult(phase1FileNames, phase1FileSizes, totalSize, phase1ExistingFileNames,</span><br><span class="line">                        phase1ExistingFileSizes, existingTotalSize, took));</span><br><span class="line">                &#125;, listener::onFailure);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                logger.trace(&quot;skipping [phase1] since source and target have identical sync id [&#123;&#125;]&quot;, recoverySourceMetadata.getSyncId());</span><br><span class="line"></span><br><span class="line">                // but we must still create a retention lease</span><br><span class="line">                final StepListener&lt;RetentionLease&gt; createRetentionLeaseStep = new StepListener&lt;&gt;();</span><br><span class="line">                createRetentionLease(startingSeqNo, createRetentionLeaseStep);</span><br><span class="line">                createRetentionLeaseStep.whenComplete(retentionLease -&gt; &#123;</span><br><span class="line">                    final TimeValue took = stopWatch.totalTime();</span><br><span class="line">                    logger.trace(&quot;recovery [phase1]: took [&#123;&#125;]&quot;, took);</span><br><span class="line">                    listener.onResponse(new SendFileResult(Collections.emptyList(), Collections.emptyList(), 0L, Collections.emptyList(),</span><br><span class="line">                        Collections.emptyList(), 0L, took));</span><br><span class="line">                &#125;, listener::onFailure);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            throw new RecoverFilesRecoveryException(request.shardId(), 0, new ByteSizeValue(0L), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>从上面代码可以看出，phase1的具体逻辑是，首先拿到待恢复shard的metadataSnapshot从而得到recoverySourceSyncId，根据request拿到recoveryTargetSyncId，比较两边的syncid，如果相同再比较源和目标的文档数，如果也相同，说明在当前提交点之前源和目标的shard对应的segments都相同，因此不用恢复segment文件(<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java#L616" target="_blank" rel="noopener">canSkipPhase1</a>方法中比对的)。如果两边的syncid不同，说明segment文件有差异，则需要找出所有有差异的文件进行恢复。通过比较recoverySourceMetadata和recoveryTargetSnapshot的差异性，可以找出所有有差别的segment文件。这块逻辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">         * Returns a diff between the two snapshots that can be used for recovery. The given snapshot is treated as the</span><br><span class="line">         * recovery target and this snapshot as the source. The returned diff will hold a list of files that are:</span><br><span class="line">         * &lt;ul&gt;</span><br><span class="line">         * &lt;li&gt;identical: they exist in both snapshots and they can be considered the same ie. they don&apos;t need to be recovered&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;different: they exist in both snapshots but their they are not identical&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;missing: files that exist in the source but not in the target&lt;/li&gt;</span><br><span class="line">         * &lt;/ul&gt;</span><br><span class="line">         * This method groups file into per-segment files and per-commit files. A file is treated as</span><br><span class="line">         * identical if and on if all files in it&apos;s group are identical. On a per-segment level files for a segment are treated</span><br><span class="line">         * as identical iff:</span><br><span class="line">         * &lt;ul&gt;</span><br><span class="line">         * &lt;li&gt;all files in this segment have the same checksum&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;all files in this segment have the same length&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;the segments &#123;@code .si&#125; files hashes are byte-identical Note: This is a using a perfect hash function,</span><br><span class="line">         * The metadata transfers the &#123;@code .si&#125; file content as it&apos;s hash&lt;/li&gt;</span><br><span class="line">         * &lt;/ul&gt;</span><br><span class="line">         * &lt;p&gt;</span><br><span class="line">         * The &#123;@code .si&#125; file contains a lot of diagnostics including a timestamp etc. in the future there might be</span><br><span class="line">         * unique segment identifiers in there hardening this method further.</span><br><span class="line">         * &lt;p&gt;</span><br><span class="line">         * The per-commit files handles very similar. A commit is composed of the &#123;@code segments_N&#125; files as well as generational files</span><br><span class="line">         * like deletes (&#123;@code _x_y.del&#125;) or field-info (&#123;@code _x_y.fnm&#125;) files. On a per-commit level files for a commit are treated</span><br><span class="line">         * as identical iff:</span><br><span class="line">         * &lt;ul&gt;</span><br><span class="line">         * &lt;li&gt;all files belonging to this commit have the same checksum&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;all files belonging to this commit have the same length&lt;/li&gt;</span><br><span class="line">         * &lt;li&gt;the segments file &#123;@code segments_N&#125; files hashes are byte-identical Note: This is a using a perfect hash function,</span><br><span class="line">         * The metadata transfers the &#123;@code segments_N&#125; file content as it&apos;s hash&lt;/li&gt;</span><br><span class="line">         * &lt;/ul&gt;</span><br><span class="line">         * &lt;p&gt;</span><br><span class="line">         * NOTE: this diff will not contain the &#123;@code segments.gen&#125; file. This file is omitted on recovery.</span><br><span class="line">         */</span><br><span class="line">        public RecoveryDiff recoveryDiff(MetadataSnapshot recoveryTargetSnapshot) &#123;</span><br><span class="line">            final List&lt;StoreFileMetadata&gt; identical = new ArrayList&lt;&gt;();// 相同的file </span><br><span class="line">            final List&lt;StoreFileMetadata&gt; different = new ArrayList&lt;&gt;();// 不同的file</span><br><span class="line">            final List&lt;StoreFileMetadata&gt; missing = new ArrayList&lt;&gt;();// 缺失的file</span><br><span class="line">            final Map&lt;String, List&lt;StoreFileMetadata&gt;&gt; perSegment = new HashMap&lt;&gt;();</span><br><span class="line">            final List&lt;StoreFileMetadata&gt; perCommitStoreFiles = new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            for (StoreFileMetadata meta : this) &#123;</span><br><span class="line">                if (IndexFileNames.OLD_SEGMENTS_GEN.equals(meta.name())) &#123; // legacy</span><br><span class="line">                    continue; // we don&apos;t need that file at all</span><br><span class="line">                &#125;</span><br><span class="line">                final String segmentId = IndexFileNames.parseSegmentName(meta.name());</span><br><span class="line">                final String extension = IndexFileNames.getExtension(meta.name());</span><br><span class="line">                if (IndexFileNames.SEGMENTS.equals(segmentId) ||</span><br><span class="line">                        DEL_FILE_EXTENSION.equals(extension) || LIV_FILE_EXTENSION.equals(extension)) &#123;</span><br><span class="line">                    // only treat del files as per-commit files fnm files are generational but only for upgradable DV</span><br><span class="line">                    perCommitStoreFiles.add(meta);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    perSegment.computeIfAbsent(segmentId, k -&gt; new ArrayList&lt;&gt;()).add(meta);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            final ArrayList&lt;StoreFileMetadata&gt; identicalFiles = new ArrayList&lt;&gt;();</span><br><span class="line">            for (List&lt;StoreFileMetadata&gt; segmentFiles : Iterables.concat(perSegment.values(), Collections.singleton(perCommitStoreFiles))) &#123;</span><br><span class="line">                identicalFiles.clear();</span><br><span class="line">                boolean consistent = true;</span><br><span class="line">                for (StoreFileMetadata meta : segmentFiles) &#123;</span><br><span class="line">                    StoreFileMetadata storeFileMetadata = recoveryTargetSnapshot.get(meta.name());</span><br><span class="line">                    if (storeFileMetadata == null) &#123;</span><br><span class="line">                        consistent = false;</span><br><span class="line">                        missing.add(meta);// 该segment在target node中不存在，则加入到missing</span><br><span class="line">                    &#125; else if (storeFileMetadata.isSame(meta) == false) &#123;</span><br><span class="line">                        consistent = false;</span><br><span class="line">                        different.add(meta);// 存在但不相同，则加入到different</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        identicalFiles.add(meta);// 存在且相同</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (consistent) &#123;</span><br><span class="line">                    identical.addAll(identicalFiles);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    // make sure all files are added - this can happen if only the deletes are different</span><br><span class="line">                    different.addAll(identicalFiles);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            RecoveryDiff recoveryDiff = new RecoveryDiff(Collections.unmodifiableList(identical),</span><br><span class="line">                Collections.unmodifiableList(different), Collections.unmodifiableList(missing));</span><br><span class="line">            assert recoveryDiff.size() == this.metadata.size() - (metadata.containsKey(IndexFileNames.OLD_SEGMENTS_GEN) ? 1 : 0)</span><br><span class="line">                    : &quot;some files are missing recoveryDiff size: [&quot; + recoveryDiff.size() + &quot;] metadata size: [&quot; +</span><br><span class="line">                      this.metadata.size() + &quot;] contains  segments.gen: [&quot; + metadata.containsKey(IndexFileNames.OLD_SEGMENTS_GEN) + &quot;]&quot;;</span><br><span class="line">            return recoveryDiff;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这里将所有的segment file分为三类：identical(相同)、different(不同)、missing(target缺失)。然后将different和missing的segment files作为第一阶段需要恢复的文件发送到target node。发送完segment files后，源节点还会向目标节点发送消息以通知目标节点清理临时文件，然后也会发送消息通知目标节点打开引擎准备接收translog。</p>
<p><a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java#L902" target="_blank" rel="noopener">sendFiles</a>逻辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">void sendFiles(Store store, StoreFileMetadata[] files, IntSupplier translogOps, ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">        ArrayUtil.timSort(files, Comparator.comparingLong(StoreFileMetadata::length)); // send smallest first</span><br><span class="line"></span><br><span class="line">        final MultiChunkTransfer&lt;StoreFileMetadata, FileChunk&gt; multiFileSender =</span><br><span class="line">            new MultiChunkTransfer&lt;&gt;(logger, threadPool.getThreadContext(), listener, maxConcurrentFileChunks, Arrays.asList(files)) &#123;</span><br><span class="line"></span><br><span class="line">                final Deque&lt;byte[]&gt; buffers = new ConcurrentLinkedDeque&lt;&gt;();</span><br><span class="line">                InputStreamIndexInput currentInput = null;</span><br><span class="line">                long offset = 0;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                protected void onNewResource(StoreFileMetadata md) throws IOException &#123;</span><br><span class="line">                    offset = 0;</span><br><span class="line">                    IOUtils.close(currentInput, () -&gt; currentInput = null);</span><br><span class="line">                    final IndexInput indexInput = store.directory().openInput(md.name(), IOContext.READONCE);</span><br><span class="line">                    currentInput = new InputStreamIndexInput(indexInput, md.length()) &#123;</span><br><span class="line">                        @Override</span><br><span class="line">                        public void close() throws IOException &#123;</span><br><span class="line">                            IOUtils.close(indexInput, super::close); // InputStreamIndexInput&apos;s close is a noop</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                protected FileChunk nextChunkRequest(StoreFileMetadata md) throws IOException &#123;</span><br><span class="line">                    assert Transports.assertNotTransportThread(&quot;read file chunk&quot;);</span><br><span class="line">                    cancellableThreads.checkForCancel();</span><br><span class="line">                    final byte[] buffer = Objects.requireNonNullElseGet(buffers.pollFirst(), () -&gt; new byte[chunkSizeInBytes]);</span><br><span class="line">                    final int bytesRead = currentInput.read(buffer);</span><br><span class="line">                    if (bytesRead == -1) &#123;</span><br><span class="line">                        throw new CorruptIndexException(&quot;file truncated; length=&quot; + md.length() + &quot; offset=&quot; + offset, md.name());</span><br><span class="line">                    &#125;</span><br><span class="line">                    // 注意这里 这里会判断是不是最后一批</span><br><span class="line">                    final boolean lastChunk = offset + bytesRead == md.length();</span><br><span class="line">                    final FileChunk chunk = new FileChunk(md, new BytesArray(buffer, 0, bytesRead), offset, lastChunk,</span><br><span class="line">                        () -&gt; buffers.addFirst(buffer));</span><br><span class="line">                    offset += bytesRead;</span><br><span class="line">                    return chunk;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                protected void executeChunkRequest(FileChunk request, ActionListener&lt;Void&gt; listener) &#123;</span><br><span class="line">                    cancellableThreads.checkForCancel();</span><br><span class="line">                    recoveryTarget.writeFileChunk(</span><br><span class="line">                        request.md, request.position, ReleasableBytesReference.wrap(request.content), request.lastChunk,</span><br><span class="line">                            translogOps.getAsInt(), ActionListener.runBefore(listener, request::close));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                protected void handleError(StoreFileMetadata md, Exception e) throws Exception &#123;</span><br><span class="line">                    handleErrorOnSendFiles(store, e, new StoreFileMetadata[]&#123;md&#125;);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void close() throws IOException &#123;</span><br><span class="line">                    IOUtils.close(currentInput, () -&gt; currentInput = null);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        resources.add(multiFileSender);</span><br><span class="line">        multiFileSender.start();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>第二阶段的逻辑比较简单，只需将translog view到当前时间之间的所有translog发送给源节点即可。</p>
<blockquote>
<p>第二阶段使用当前translog的快照，而不获取写锁(但是，translog快照是translog的时间点视图)。然后，它将每个translog操作发送到目标节点，以便将其重播到新的shard中。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Perform phase two of the recovery process.</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * Phase two uses a snapshot of the current translog *without* acquiring the write lock (however, the translog snapshot is</span><br><span class="line"> * point-in-time view of the translog). It then sends each translog operation to the target node so it can be replayed into the new</span><br><span class="line"> * shard.</span><br><span class="line"> *</span><br><span class="line"> * @param startingSeqNo              the sequence number to start recovery from, or &#123;@link SequenceNumbers#UNASSIGNED_SEQ_NO&#125; if all</span><br><span class="line"> *                                   ops should be sent</span><br><span class="line"> * @param endingSeqNo                the highest sequence number that should be sent</span><br><span class="line"> * @param snapshot                   a snapshot of the translog</span><br><span class="line"> * @param maxSeenAutoIdTimestamp     the max auto_id_timestamp of append-only requests on the primary</span><br><span class="line"> * @param maxSeqNoOfUpdatesOrDeletes the max seq_no of updates or deletes on the primary after these operations were executed on it.</span><br><span class="line"> * @param listener                   a listener which will be notified with the local checkpoint on the target.</span><br><span class="line"> */</span><br><span class="line">void phase2(</span><br><span class="line">        final long startingSeqNo,</span><br><span class="line">        final long endingSeqNo,</span><br><span class="line">        final Translog.Snapshot snapshot,</span><br><span class="line">        final long maxSeenAutoIdTimestamp,</span><br><span class="line">        final long maxSeqNoOfUpdatesOrDeletes,</span><br><span class="line">        final RetentionLeases retentionLeases,</span><br><span class="line">        final long mappingVersion,</span><br><span class="line">        final ActionListener&lt;SendSnapshotResult&gt; listener) throws IOException &#123;</span><br><span class="line">    if (shard.state() == IndexShardState.CLOSED) &#123;</span><br><span class="line">        throw new IndexShardClosedException(request.shardId());</span><br><span class="line">    &#125;</span><br><span class="line">    logger.trace(&quot;recovery [phase2]: sending transaction log operations (from [&quot; + startingSeqNo + &quot;] to [&quot; + endingSeqNo + &quot;]&quot;);</span><br><span class="line">    final StopWatch stopWatch = new StopWatch().start();</span><br><span class="line">    final StepListener&lt;Void&gt; sendListener = new StepListener&lt;&gt;();</span><br><span class="line">    final OperationBatchSender sender = new OperationBatchSender(startingSeqNo, endingSeqNo, snapshot, maxSeenAutoIdTimestamp,</span><br><span class="line">        maxSeqNoOfUpdatesOrDeletes, retentionLeases, mappingVersion, sendListener);</span><br><span class="line">    sendListener.whenComplete(</span><br><span class="line">        ignored -&gt; &#123;</span><br><span class="line">            final long skippedOps = sender.skippedOps.get();</span><br><span class="line">            final int totalSentOps = sender.sentOps.get();</span><br><span class="line">            final long targetLocalCheckpoint = sender.targetLocalCheckpoint.get();</span><br><span class="line">            assert snapshot.totalOperations() == snapshot.skippedOperations() + skippedOps + totalSentOps</span><br><span class="line">                : String.format(Locale.ROOT, &quot;expected total [%d], overridden [%d], skipped [%d], total sent [%d]&quot;,</span><br><span class="line">                snapshot.totalOperations(), snapshot.skippedOperations(), skippedOps, totalSentOps);</span><br><span class="line">            stopWatch.stop();</span><br><span class="line">            final TimeValue tookTime = stopWatch.totalTime();</span><br><span class="line">            logger.trace(&quot;recovery [phase2]: took [&#123;&#125;]&quot;, tookTime);</span><br><span class="line">            listener.onResponse(new SendSnapshotResult(targetLocalCheckpoint, totalSentOps, tookTime));</span><br><span class="line">        &#125;, listener::onFailure);</span><br><span class="line">    sender.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="目标节点开始恢复">目标节点开始恢复</h2>
<h3 id="接收segment">接收segment</h3>
<p>对应上一小节源节点恢复的第一阶段，源节点将所有有差异的segment发送给目标节点，目标节点接收到后会将segment文件落盘。segment files的写入函数为<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java#L498" target="_blank" rel="noopener">RecoveryTarget.writeFileChunk</a>:</p>
<blockquote>
<p>真正执行的位置：<a href="https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/indices/recovery/MultiFileWriter.java#L120" target="_blank" rel="noopener">MultiFileWriter.innerWriteFileChunk</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public void writeFileChunk(StoreFileMetaData fileMetaData, long position, BytesReference content, boolean lastChunk, int totalTranslogOps) throws IOException &#123;</span><br><span class="line">    final Store store = store();</span><br><span class="line">    final String name = fileMetaData.name();</span><br><span class="line">    ... ...</span><br><span class="line">    if (position == 0) &#123;</span><br><span class="line">        indexOutput = openAndPutIndexOutput(name, fileMetaData, store);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        indexOutput = getOpenIndexOutput(name); // 加一层前缀，组成临时文件</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">    while((scratch = iterator.next()) != null) &#123; </span><br><span class="line">        indexOutput.writeBytes(scratch.bytes, scratch.offset, scratch.length); // 写临时文件</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">    store.directory().sync(Collections.singleton(temporaryFileName));  // 这里会调用fsync落盘</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="打开引擎">打开引擎</h3>
<p>经过上面的过程，目标节点完成了追数据的第一步。接收完segment后，目标节点打开shard对应的引擎准备接收translog，<font color="DeepPink"><strong>注意，这里打开引擎后，正在恢复的shard便可进行写入、删除(操作包括primary shard同步的请求和translog中的操作命令)</strong></font>。打开引擎的逻辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line">     * Opens the engine on top of the existing lucene engine and translog.</span><br><span class="line">     * The translog is kept but its operations won&apos;t be replayed.</span><br><span class="line">     */</span><br><span class="line">    public void openEngineAndSkipTranslogRecovery() throws IOException &#123;</span><br><span class="line">        assert routingEntry().recoverySource().getType() == RecoverySource.Type.PEER : &quot;not a peer recovery [&quot; + routingEntry() + &quot;]&quot;;</span><br><span class="line">        recoveryState.validateCurrentStage(RecoveryState.Stage.TRANSLOG);</span><br><span class="line">        loadGlobalCheckpointToReplicationTracker();</span><br><span class="line">        innerOpenEngineAndTranslog(replicationTracker);</span><br><span class="line">        getEngine().skipTranslogRecovery();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private void innerOpenEngineAndTranslog(LongSupplier globalCheckpointSupplier) throws IOException &#123;</span><br><span class="line">        assert Thread.holdsLock(mutex) == false : &quot;opening engine under mutex&quot;;</span><br><span class="line">        if (state != IndexShardState.RECOVERING) &#123;</span><br><span class="line">            throw new IndexShardNotRecoveringException(shardId, state);</span><br><span class="line">        &#125;</span><br><span class="line">        final EngineConfig config = newEngineConfig(globalCheckpointSupplier);</span><br><span class="line"></span><br><span class="line">        // we disable deletes since we allow for operations to be executed against the shard while recovering</span><br><span class="line">        // but we need to make sure we don&apos;t loose deletes until we are done recovering</span><br><span class="line">        config.setEnableGcDeletes(false);// 恢复过程中不删除translog</span><br><span class="line">        updateRetentionLeasesOnReplica(loadRetentionLeases());</span><br><span class="line">        assert recoveryState.getRecoverySource().expectEmptyRetentionLeases() == false || getRetentionLeases().leases().isEmpty()</span><br><span class="line">            : &quot;expected empty set of retention leases with recovery source [&quot; + recoveryState.getRecoverySource()</span><br><span class="line">            + &quot;] but got &quot; + getRetentionLeases();</span><br><span class="line">        synchronized (engineMutex) &#123;</span><br><span class="line">            assert currentEngineReference.get() == null : &quot;engine is running&quot;;</span><br><span class="line">            verifyNotClosed();</span><br><span class="line">            // we must create a new engine under mutex (see IndexShard#snapshotStoreMetadata).</span><br><span class="line">            final Engine newEngine = engineFactory.newReadWriteEngine(config);// 创建engine</span><br><span class="line">            onNewEngine(newEngine);</span><br><span class="line">            currentEngineReference.set(newEngine);</span><br><span class="line">            // We set active because we are now writing operations to the engine; this way,</span><br><span class="line">            // we can flush if we go idle after some time and become inactive.</span><br><span class="line">            active.set(true);</span><br><span class="line">        &#125;</span><br><span class="line">        // time elapses after the engine is created above (pulling the config settings) until we set the engine reference, during</span><br><span class="line">        // which settings changes could possibly have happened, so here we forcefully push any config changes to the new engine.</span><br><span class="line">        onSettingsChanged();</span><br><span class="line">        assert assertSequenceNumbersInCommit();</span><br><span class="line">        recoveryState.validateCurrentStage(RecoveryState.Stage.TRANSLOG);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="接收并重放translog">接收并重放translog</h3>
<p>打开引擎后，便可以根据translog中的命令进行相应的回放动作，回放的逻辑和正常的写入、删除类似，这里需要根据translog还原出操作类型和操作数据，并根据操作数据构建相应的数据对象，然后再调用上一步打开的engine执行相应的操作，这块逻辑如下：</p>
<blockquote>
<p>IndexShard#runTranslogRecovery<br>
=&gt;<br>
IndexShard#applyTranslogOperation</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">// 重放translog快照中的translog操作到当前引擎。</span><br><span class="line">// 在成功回放每个translog操作后，会通知回调onOperationRecovered。</span><br><span class="line"> /**</span><br><span class="line">     * Replays translog operations from the provided translog &#123;@code snapshot&#125; to the current engine using the given &#123;@code origin&#125;.</span><br><span class="line">     * The callback &#123;@code onOperationRecovered&#125; is notified after each translog operation is replayed successfully.</span><br><span class="line">     */</span><br><span class="line">    int runTranslogRecovery(Engine engine, Translog.Snapshot snapshot, Engine.Operation.Origin origin,</span><br><span class="line">                            Runnable onOperationRecovered) throws IOException &#123;</span><br><span class="line">        int opsRecovered = 0;</span><br><span class="line">        Translog.Operation operation;</span><br><span class="line">        while ((operation = snapshot.next()) != null) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                logger.trace(&quot;[translog] recover op &#123;&#125;&quot;, operation);</span><br><span class="line">                Engine.Result result = applyTranslogOperation(engine, operation, origin);</span><br><span class="line">                switch (result.getResultType()) &#123;</span><br><span class="line">                    case FAILURE:</span><br><span class="line">                        throw result.getFailure();</span><br><span class="line">                    case MAPPING_UPDATE_REQUIRED:</span><br><span class="line">                        throw new IllegalArgumentException(&quot;unexpected mapping update: &quot; + result.getRequiredMappingUpdate());</span><br><span class="line">                    case SUCCESS:</span><br><span class="line">                        break;</span><br><span class="line">                    default:</span><br><span class="line">                        throw new AssertionError(&quot;Unknown result type [&quot; + result.getResultType() + &quot;]&quot;);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                opsRecovered++;</span><br><span class="line">                onOperationRecovered.run();</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                // TODO: Don&apos;t enable this leniency unless users explicitly opt-in</span><br><span class="line">                if (origin == Engine.Operation.Origin.LOCAL_TRANSLOG_RECOVERY &amp;&amp; ExceptionsHelper.status(e) == RestStatus.BAD_REQUEST) &#123;</span><br><span class="line">                    // mainly for MapperParsingException and Failure to detect xcontent</span><br><span class="line">                    logger.info(&quot;ignoring recovery of a corrupt translog entry&quot;, e);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    throw ExceptionsHelper.convertToRuntime(e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return opsRecovered;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private Engine.Result applyTranslogOperation(Engine engine, Translog.Operation operation,</span><br><span class="line">                                                 Engine.Operation.Origin origin) throws IOException &#123;</span><br><span class="line">        // If a translog op is replayed on the primary (eg. ccr), we need to use external instead of null for its version type.</span><br><span class="line">        final VersionType versionType = (origin == Engine.Operation.Origin.PRIMARY) ? VersionType.EXTERNAL : null;</span><br><span class="line">        final Engine.Result result;</span><br><span class="line">        switch (operation.opType()) &#123;// 还原出操作类型及操作数据并调用engine执行相应的动作</span><br><span class="line">            case INDEX:</span><br><span class="line">                final Translog.Index index = (Translog.Index) operation;</span><br><span class="line">                // we set canHaveDuplicates to true all the time such that we de-optimze the translog case and ensure that all</span><br><span class="line">                // autoGeneratedID docs that are coming from the primary are updated correctly.</span><br><span class="line">                result = applyIndexOperation(engine, index.seqNo(), index.primaryTerm(), index.version(),</span><br><span class="line">                    versionType, UNASSIGNED_SEQ_NO, 0, index.getAutoGeneratedIdTimestamp(), true, origin,</span><br><span class="line">                    new SourceToParse(shardId.getIndexName(), index.id(), index.source(),</span><br><span class="line">                        XContentHelper.xContentType(index.source()), index.routing()));</span><br><span class="line">                break;</span><br><span class="line">            case DELETE:</span><br><span class="line">                final Translog.Delete delete = (Translog.Delete) operation;</span><br><span class="line">                result = applyDeleteOperation(engine, delete.seqNo(), delete.primaryTerm(), delete.version(), delete.id(),</span><br><span class="line">                    versionType, UNASSIGNED_SEQ_NO, 0, origin);</span><br><span class="line">                break;</span><br><span class="line">            case NO_OP:</span><br><span class="line">                final Translog.NoOp noOp = (Translog.NoOp) operation;</span><br><span class="line">                result = markSeqNoAsNoop(engine, noOp.seqNo(), noOp.primaryTerm(), noOp.reason(), origin);</span><br><span class="line">                break;</span><br><span class="line">            default:</span><br><span class="line">                throw new IllegalStateException(&quot;No operation defined for [&quot; + operation + &quot;]&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>通过上面的步骤，translog的重放完毕，此后需要做一些收尾的工作，包括，refresh让回放后的最新数据可见，打开translog gc：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * perform the last stages of recovery once all translog operations are done.</span><br><span class="line">    * note that you should still call &#123;@link #postRecovery(String)&#125;.</span><br><span class="line">    */</span><br><span class="line">   public void finalizeRecovery() &#123;</span><br><span class="line">       recoveryState().setStage(RecoveryState.Stage.FINALIZE);</span><br><span class="line">       Engine engine = getEngine();</span><br><span class="line">       engine.refresh(&quot;recovery_finalization&quot;);</span><br><span class="line">       engine.config().setEnableGcDeletes(true);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>到这里，replica shard恢复的两个阶段便完成了，由于此时shard还处于INITIALIZING状态，还需通知master节点启动已恢复的shard：</p>
<blockquote>
<p>IndicesClusterStateService#RecoveryListener</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void onRecoveryDone(final RecoveryState state, ShardLongFieldRange timestampMillisFieldRange) &#123;</span><br><span class="line">    shardStateAction.shardStarted(</span><br><span class="line">            shardRouting,</span><br><span class="line">            primaryTerm,</span><br><span class="line">            &quot;after &quot; + state.getRecoverySource(),</span><br><span class="line">            timestampMillisFieldRange,</span><br><span class="line">            SHARD_STATE_ACTION_LISTENER);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此，shard recovery的所有流程都已完成。</p>
<h1>小结</h1>
<h2 id="疑问点1：网上说的对不对？新版本中有没有更新？">疑问点1：网上说的对不对？新版本中有没有更新？</h2>
<p>到这里完整跟着腾讯云的文档走了一遍，主体的流程在Elasticsearch 8.0.0-SNAPSHOT中基本一样，只是部分方法有些调整。</p>
<p>所以下面这个流程还是正确的：</p>
<p>ES副本分片恢复主要涉及恢复的目标节点和源节点，目标节点即故障恢复的节点，源节点为提供恢复的节点。目标节点向源节点发送分片恢复请求，源节点接收到请求后主要分两阶段来处理。第一阶段，对需要恢复的shard创建snapshot，然后根据请求中的metadata对比如果 syncid 相同且 doc 数量相同则跳过，否则对比shard的segment文件差异，将有差异的segment文件发送给target node。第二阶段，为了保证target node数据的完整性，需要将本地的translog发送给target node，且对接收到的translog进行回放。整体流程如下图所示：</p>
<p><img data-src="/images/elasticsearch-shard-recovery-source-code-analysis/%E5%88%86%E7%89%87%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B.png" alt></p>
<h2 id="疑问点2：在分片恢复的时候，如果收到Api-forcemerge请求，这时候，会如何处理">疑问点2：在分片恢复的时候，如果收到Api _forcemerge请求，这时候，会如何处理?</h2>
<p>这部分等看/_forcemerge api的时候，再解答一下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">RestForceMergeAction</span><br><span class="line">=&gt;</span><br><span class="line">TransportForceMergeAction#shardOperation(ForceMergeRequest request, ShardRouting shardRouting)</span><br><span class="line">=&gt;</span><br><span class="line">IndexShard#forceMerge(ForceMergeRequest forceMerge)</span><br><span class="line">=&gt;</span><br><span class="line">InternalEngine#forceMerge</span><br><span class="line"></span><br><span class="line">// https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java#L1900</span><br><span class="line">1. 只合并删除文档</span><br><span class="line">2. 没有限制最大segment数的合并</span><br><span class="line">3. 限制了最大segment数的合并</span><br></pre></td></tr></table></figure>
<p>其实问题不在这里，recovery依赖segment file，当recovery启动后，程序会获取到文件的reader，这时候即使recovery，也不会删除segment file。</p>
<h2 id="疑问点3：片恢复的第二阶段是同步translog-这一步会不会加锁？不加锁的话，如何确保是同步完成了？">疑问点3：片恢复的第二阶段是同步translog,这一步会不会加锁？不加锁的话，如何确保是同步完成了？</h2>
<h3 id="完整性">完整性</h3>
<p>首先，phase1阶段，保证了存量的历史数据可以恢复到从分片。phase1阶段完成后，从分片引擎打开，可以正常处理index、delete请求，而translog覆盖完了整个phase1阶段，因此在phase1阶段中的index/delete操作都将被记录下来，在phase2阶段进行translog回放时，副本分片正常的index和delete操作和translog是并行执行的，这就保证了恢复开始之前的数据、恢复中的数据都会完整的写入到副本分片，保证了数据的完整性。如下图所示：</p>
<p><img data-src="/images/elasticsearch-shard-recovery-source-code-analysis/%E4%BB%8E%E5%88%86%E7%89%87%E6%81%A2%E5%A4%8D%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt></p>
<h3 id="一致性">一致性</h3>
<p>由于phase1阶段完成后，从分片便可正常处理写入操作，而此时从分片的写入和phase2阶段的translog回放时并行执行的，如果translog的回放慢于正常的写入操作，那么可能会导致老的数据后写入，造成数据不一致。ES为了保证数据的一致性在进行写入操作时，会比较当前写入的版本和lucene文档版本号，如果当前版本更小，说明是旧数据则不会将文档写入lucene。相关代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// https://github.com/jiankunking/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java#L993</span><br><span class="line">final OpVsLuceneDocStatus opVsLucene = compareOpToLuceneDocBasedOnSeqNo(index);</span><br><span class="line">if (opVsLucene == OpVsLuceneDocStatus.OP_STALE_OR_EQUAL) &#123;</span><br><span class="line">    plan = IndexingStrategy.processAsStaleOp(index.version(), 0);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1>拓展:如何保证副分片和主分片一致</h1>
<blockquote>
<p>整理自:《Elasticsearch源码解析与优化实战》</p>
</blockquote>
<p>索引恢复过程的一个难点在于如何维护主副分片的一致性。假设副分片恢复期间一直有写操作，如何实现一致呢？<br>
我们先看看早期的做法：在2.0版本之前，副分片恢复要经历三个阶段。</p>
<ul>
<li>phase1：将主分片的 Lucene 做快照，发送到 target。期间不阻塞索引操作，新增数据写到主分片的translog。</li>
<li>phase2：将主分片translog做快照，发送到target重放，期间不阻塞索引操作。</li>
<li>phase3：为主分片加写锁，将剩余的translog发送到target。此时数据量很小，写入过程的阻塞很短。</li>
</ul>
<p>从理论上来说，只要流程上允许将写操作阻塞一段时间，实现主副一致是比较容易的。</p>
<p>但是后来(从2.0版本开始)，也就是引入translog.view概念的同时，phase3被删除。</p>
<p>phase3被删除，这个阶段是重放操作(operations)，同时防止新的写入 Engine。这是不必要的，因为自恢复开始，标准的 index 操作会发送所有的操作到正在恢复中的分片。重放恢复开始时获取的view中的所有操作足够保证不丢失任何操作。</p>
<p>阻塞写操作的phase3被删除，恢复期间没有任何写阻塞过程。接下来需要处理的就是解决phase1和phase2之间的写操作与phase2重放操作之间的时序和冲突问题。在副分片节点，phase1结束后，假如新增索引操作和 translog 重放操作并发执行，因为时序的关系会出现新老数据交替。如何实现主副分片一致呢？</p>
<p>假设在第一阶段执行期间，有客户端索引操作要求将docA的内容写为1，主分片执行了这个操作，而副分片由于尚未就绪所以没有执行。第二阶段期间客户端索引操作要求写 docA 的内容为2，此时副分片已经就绪，先执行将docA写为2的新增请求，然后又收到了从主分片所在节点发送过来的translog重复写docA为1的请求该如何处理？具体流程如下图所示。</p>
<p><img data-src="/images/elasticsearch-shard-recovery-source-code-analysis/01.png" alt></p>
<p>答案是在写流程中做异常处理，通过版本号来过滤掉过期操作。写操作有三种类型：索引新文档、更新、删除。索引新文档不存在冲突问题，更新和删除操作采用相同的处理机制。每个操作都有一个版本号，这个版本号就是预期doc版本，它必须大于当前Lucene中的doc版本号，否则就放弃本次操作。对于更新操作来说，预期版本号是Lucene doc版本号+1。主分片节点写成功后新数据的版本号会放到写副本的请求中，这个请求中的版本号就是预期版本号。</p>
<p>这样，时序上存在错误的操作被忽略，对于特定doc，只有最新一次操作生效，保证了主副分片一致。</p>
<p>我们分别看一下写操作三种类型的处理机制。</p>
<h2 id="1．索引新文档">1．索引新文档</h2>
<p>不存在冲突问题，不需要处理。</p>
<h2 id="2．更新">2．更新</h2>
<p>判断本次操作的版本号是否小于Lucene中doc的版本号，如果小于，则放弃本次操作。</p>
<p>Index、Delete都继承自Operation，每个Operation都有一个版本号，这个版本号就是doc版本号。对于副分片的写流程来说，正常情况下是主分片写成功后，相应doc写入的版本号被放到转发写副分片的请求中。对于更新来说，就是通过主分片将原doc版本号+1后转发到副分片实现的。在对比版本号的时候：</p>
<p>expectedVersion = 写副分片请求中的 version = 写主分片成功后的version</p>
<p>通过下面的方法判断当前操作的版本号是否低于Lucene中的版本号：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// VersionType#isVersionConflictForWrites</span><br><span class="line"> EXTERNAL((byte) 1) &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public boolean isVersionConflictForWrites(long currentVersion, long expectedVersion, boolean deleted) &#123;</span><br><span class="line">            if (currentVersion == Versions.NOT_FOUND) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">            if (expectedVersion == Versions.MATCH_ANY) &#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            if (currentVersion &gt;= expectedVersion) &#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>如果translog重放的操作在写一条&quot;老&quot;数据，则compareOpToLuceneDocBasedOnSeqNo会返回OpVsLuceneDocStatus.OP_STALE_OR_EQUAL。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">private OpVsLuceneDocStatus compareOpToLuceneDocBasedOnSeqNo(final Operation op) throws IOException &#123;</span><br><span class="line">        assert op.seqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO : &quot;resolving ops based on seq# but no seqNo is found&quot;;</span><br><span class="line">        final OpVsLuceneDocStatus status;</span><br><span class="line">        VersionValue versionValue = getVersionFromMap(op.uid().bytes());</span><br><span class="line">        assert incrementVersionLookup();</span><br><span class="line">        if (versionValue != null) &#123;</span><br><span class="line">            status = compareOpToVersionMapOnSeqNo(op.id(), op.seqNo(), op.primaryTerm(), versionValue);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // load from index</span><br><span class="line">            assert incrementIndexVersionLookup();</span><br><span class="line">            try (Searcher searcher = acquireSearcher(&quot;load_seq_no&quot;, SearcherScope.INTERNAL)) &#123;</span><br><span class="line">                final DocIdAndSeqNo docAndSeqNo = VersionsAndSeqNoResolver.loadDocIdAndSeqNo(searcher.getIndexReader(), op.uid());</span><br><span class="line">                if (docAndSeqNo == null) &#123;</span><br><span class="line">                    status = OpVsLuceneDocStatus.LUCENE_DOC_NOT_FOUND;</span><br><span class="line">                &#125; else if (op.seqNo() &gt; docAndSeqNo.seqNo) &#123;</span><br><span class="line">                    status = OpVsLuceneDocStatus.OP_NEWER;</span><br><span class="line">                &#125; else if (op.seqNo() == docAndSeqNo.seqNo) &#123;</span><br><span class="line">                    assert localCheckpointTracker.hasProcessed(op.seqNo()) :</span><br><span class="line">                        &quot;local checkpoint tracker is not updated seq_no=&quot; + op.seqNo() + &quot; id=&quot; + op.id();</span><br><span class="line">                    status = OpVsLuceneDocStatus.OP_STALE_OR_EQUAL;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    status = OpVsLuceneDocStatus.OP_STALE_OR_EQUAL;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return status;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>副分片在InternalEngine#index函数中通过plan判断是否写到Lucene：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// non-primary mode (i.e., replica or recovery)</span><br><span class="line">final IndexingStrategy plan = indexingStrategyForOperation(index);</span><br></pre></td></tr></table></figure>
<p>在 indexingStrategyForOperation函数中，plan的最终结果就是plan =IndexingStrategy.processButSkipLucene，后面会跳过写Lucene和translog的逻辑。</p>
<h2 id="3．-删除">3． 删除</h2>
<p>判断本次操作中的版本号是否小于Lucene中doc的版本号，如果小于，则放弃本次操作。</p>
<p>通过compareOpToLuceneDocBasedOnSeqNo方法判断本次操作是否小于Lucenne中doc的版本号，与Index操作时使用相同的比较函数。</p>
<p>类似的，在InternalEngine#delete函数中判断是否写到Lucene：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final DeletionStrategy plan = deletionStrategyForOperation(delete);</span><br></pre></td></tr></table></figure>
<p>如果translog重放的是一个&quot;老&quot;的删除操作，则compareOpToLuceneDocBasedOnSeqNo会返回OpVsLuceneDocStatus.OP_STALE_OR_EQUAL。</p>
<p>plan的最终结果就是plan=DeletionStrategy.processButSkipLucene，后面会跳过Lucene删除的逻辑。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * the status of the current doc version in lucene, compared to the version in an incoming</span><br><span class="line">   * operation</span><br><span class="line">   */</span><br><span class="line">  enum OpVsLuceneDocStatus &#123;</span><br><span class="line">      /** the op is more recent than the one that last modified the doc found in lucene*/</span><br><span class="line">      OP_NEWER,</span><br><span class="line">      /** the op is older or the same as the one that last modified the doc found in lucene*/</span><br><span class="line">      OP_STALE_OR_EQUAL,</span><br><span class="line">      /** no doc was found in lucene */</span><br><span class="line">      LUCENE_DOC_NOT_FOUND</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\elasticsearch-node-stop-source-code-analysis.html" rel="bookmark">【Elasticsearch源码】 节点关闭分析</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\elasticsearch-node-start-source-code-analysis.html" rel="bookmark">【Elasticsearch源码】 节点启动分析</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\elasticsearch-get-source-code-analysis.html" rel="bookmark">【Elasticsearch源码】 GET分析</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\why-does-elasticsearch-have-poor-update-performance.html" rel="bookmark">【Elasticsearch源码】 更新性能分析</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\elasticsearch-search-source-code-analysis.html" rel="bookmark">【Elasticsearch源码】 检索分析</a></div>
    </li>
  </ul>

        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/reward/wechatpay.png" alt="jiankunking 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/reward/alipay.jpg" alt="jiankunking 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>jiankunking
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://jiankunking.com/elasticsearch-shard-recovery-source-code-analysis.html" title="【Elasticsearch源码】 分片恢复分析">https://jiankunking.com/elasticsearch-shard-recovery-source-code-analysis.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-ND</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat/wechat.jpg">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/原创/" rel="tag"># 原创</a>
              <a href="/tags/elasticsearch/" rel="tag"># ElasticSearch</a>
              <a href="/tags/源码/" rel="tag"># 源码</a>
              <a href="/tags/shard/" rel="tag"># Shard</a>
              <a href="/tags/recovery/" rel="tag"># Recovery</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/org-apache-rocketmq-shaded-io-grpc-statusruntimeexception-deadline-exceeded-clientcall-started-after-deadline-exceeded-2-591386886s-from-now.html" rel="prev" title="记一次RocketMQ Client超时问题排查">
      <i class="fa fa-chevron-left"></i> 记一次RocketMQ Client超时问题排查
    </a></div>
      <div class="post-nav-item">
    <a href="/2023-year-end-summary.html" rel="next" title="2023年终总结">
      2023年终总结 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-number">1.</span> <span class="nav-text">目的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-number">2.</span> <span class="nav-text">源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标节点请求恢复"><span class="nav-number">2.1.</span> <span class="nav-text">目标节点请求恢复</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#源节点处理恢复请求"><span class="nav-number">2.2.</span> <span class="nav-text">源节点处理恢复请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目标节点开始恢复"><span class="nav-number">2.3.</span> <span class="nav-text">目标节点开始恢复</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#接收segment"><span class="nav-number">2.3.1.</span> <span class="nav-text">接收segment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#打开引擎"><span class="nav-number">2.3.2.</span> <span class="nav-text">打开引擎</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#接收并重放translog"><span class="nav-number">2.3.3.</span> <span class="nav-text">接收并重放translog</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-number">3.</span> <span class="nav-text">小结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#疑问点1：网上说的对不对？新版本中有没有更新？"><span class="nav-number">3.1.</span> <span class="nav-text">疑问点1：网上说的对不对？新版本中有没有更新？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#疑问点2：在分片恢复的时候，如果收到Api-forcemerge请求，这时候，会如何处理"><span class="nav-number">3.2.</span> <span class="nav-text">疑问点2：在分片恢复的时候，如果收到Api _forcemerge请求，这时候，会如何处理?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#疑问点3：片恢复的第二阶段是同步translog-这一步会不会加锁？不加锁的话，如何确保是同步完成了？"><span class="nav-number">3.3.</span> <span class="nav-text">疑问点3：片恢复的第二阶段是同步translog,这一步会不会加锁？不加锁的话，如何确保是同步完成了？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#完整性"><span class="nav-number">3.3.1.</span> <span class="nav-text">完整性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一致性"><span class="nav-number">3.3.2.</span> <span class="nav-text">一致性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-number">4.</span> <span class="nav-text">拓展:如何保证副分片和主分片一致</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1．索引新文档"><span class="nav-number">4.1.</span> <span class="nav-text">1．索引新文档</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2．更新"><span class="nav-number">4.2.</span> <span class="nav-text">2．更新</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3．-删除"><span class="nav-number">4.3.</span> <span class="nav-text">3． 删除</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="jiankunking"
      src="/images/avatar/avatar.png">
  <p class="site-author-name" itemprop="name">jiankunking</p>
  <div class="site-description" itemprop="description">如果你来访我，我不在，请和我门外的花坐一会儿，它们很温暖，我注视他们很多很多日子了。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">150</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">211</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jiankunking" title="GitHub → https://github.com/jiankunking" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/jiankunking" title="CSDN → https://blog.csdn.net/jiankunking" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>CSDN</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-nd.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/jiankunking" title="https://blog.csdn.net/jiankunking" rel="noopener" target="_blank">CSDN博客</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">鲁ICP备18016400号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiankunking</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1.2m</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  <script src="/js/local-search.js"></script>












  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '5e2e6dc5bd7af549261d',
      clientSecret: 'f37069692932676f0ad9fbfecb5164aee191fe23',
      repo        : 'blog-comments',
      owner       : 'jiankunking',
      admin       : ['jiankunking'],
      id          : '7cf8678782bce8bb1f02b69bf907bcc3',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
